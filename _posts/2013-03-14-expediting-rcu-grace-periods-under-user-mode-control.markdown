---

title: Expediting RCU grace periods under user mode control
abstract: A technique for supporting user mode specification of Read-Copy Update (RCU) grace period latency to an operating system kernel-level RCU implementation. Non-expedited and expedited RCU grace period mechanisms are provided for invocation by RCU updaters performing RCU update operations to respectively initiate non-expedited and expedited grace periods. An expedited grace period indicator in a kernel memory space is provided for indicating whether a non-expedited RCU grace period or an expedited RCU grace period should be invoked. The non-expedited RCU grace period mechanism is adapted to check the expedited grace period indicator, and if an expedited RCU grace period is indicated, to invoke the expedited grace period mechanism. A communication mechanism is provided for use by a user mode application executing in a user memory space to manipulate the expedited grace period indicator in the kernel memory space, and thereby control whether an expedited or non-expedited RCU grace period should be used.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09348765&OS=09348765&RS=09348765
owner: International Business Machines Corporation
number: 09348765
owner_city: Armonk
owner_country: US
publication_date: 20130314
---
The present disclosure relates to computer systems and methods in which data resources are shared among data consumers while preserving data integrity and consistency relative to each consumer. More particularly the disclosure concerns an implementation of a mutual exclusion mechanism known as read copy update in an energy efficient computing environment.

By way of background read copy update also known as RCU is a mutual exclusion technique that permits shared data to be accessed for reading without the use of locks writes to shared memory memory barriers atomic instructions or other computationally expensive synchronization mechanisms while still permitting the data to be updated modify delete insert etc. concurrently. The technique is well suited to both uniprocessor and multiprocessor computing environments wherein the number of read operations readers accessing a shared data set is large in comparison to the number of update operations updaters and wherein the overhead cost of employing other mutual exclusion techniques such as locks for each read operation would be high. By way of example a network routing table that is updated at most once every few minutes but searched many thousands of times per second is a case where read side lock acquisition would be quite burdensome.

The read copy update technique implements data updates in two phases. In the first initial update phase the actual data update is carried out in a manner that temporarily preserves two views of the data being updated. One view is the old pre update data state that is maintained for the benefit of read operations that may have been referencing the data concurrently with the update. The other view is the new post update data state that is seen by operations that access the data following the update. In the second deferred update phase the old data state is removed following a grace period that is long enough to ensure that the first group of read operations will no longer maintain references to the pre update data. The second phase update operation typically comprises freeing a stale data element to reclaim its memory. In certain RCU implementations the second phase update operation may comprise something else such as changing an operational state according to the first phase update.

It is assumed that the data element list of is traversed without locking by multiple readers and occasionally updated by updaters that delete insert or modify data elements in the list. In the data element B is being referenced by a reader r as shown by the vertical arrow below the data element. In an updater u wishes to update the linked list by modifying data element B. Instead of simply updating this data element without regard to the fact that r is referencing it which might crash r u preserves B while generating an updated version thereof shown in as data element B and inserting it into the linked list. This is done by u acquiring an appropriate lock to exclude other updaters allocating new memory for B copying the contents of B to B modifying B as needed updating the pointer from A to B so that it points to B and releasing the lock. In current versions of the Linux kernel pointer updates performed by updaters can be implemented using the rcu assign pointer primitive. As an alternative to locking during the update operation other techniques such as non blocking synchronization or a designated update thread could be used to serialize data updates. All subsequent post update readers that traverse the linked list such as the reader r will see the effect of the update operation by encountering B as they dereference B s pointer. On the other hand the old reader r will be unaffected because the original version of B and its pointer to C are retained. Although r will now be reading stale data there are many cases where this can be tolerated such as when data elements track the state of components external to the computer system e.g. network connectivity and must tolerate old data because of communication delays. In current versions of the Linux kernel pointer dereferences performed by readers can be implemented using the rcu dereference primitive.

At some subsequent time following the update r will have continued its traversal of the linked list and moved its reference off of B. In addition there will be a time at which no other reader process is entitled to access B. It is at this point representing an expiration of the grace period referred to above that u can free B as shown in .

In the context of the read copy update mechanism a grace period represents the point at which all running tasks e.g. processes threads or other work having access to a data element guarded by read copy update have passed through a quiescent state in which they can no longer maintain references to the data element assert locks thereon or make any assumptions about data element state. By convention for operating system kernel code paths a context switch an idle loop and user mode execution all represent quiescent states for any given CPU running non preemptible code as can other operations that will not be listed here . The reason for this is that a non preemptible kernel will always complete a particular operation e.g. servicing a system call while running in process context prior to a context switch. In preemptible operating system kernels additional steps are needed to account for readers that were preempted within their RCU read side critical sections. In current RCU implementations designed for the Linux kernel a blocked reader task list is maintained to track such readers. A grace period will only end when the blocked task list indicates that is safe to do so because all blocked readers associated with the grace period have exited their RCU read side critical sections. Other techniques for tracking blocked readers may also be used but tend to require more read side overhead than the current blocked task list method.

In four tasks and running on four separate CPUs are shown to pass periodically through quiescent states represented by the double vertical bars . The grace period shown by the dotted vertical lines encompasses the time frame in which all four tasks that began before the start of the grace period have passed through one quiescent state. If the four tasks and were reader tasks traversing the linked lists of or none of these tasks having reference to the old data element B prior to the grace period could maintain a reference thereto following the grace period. All post grace period searches conducted by these tasks would bypass B by following the updated pointers created by the updater.

Grace periods may be synchronous or asynchronous. According to the synchronous technique an updater performs the first phase update operation invokes an RCU primitive such as synchronize rcu to advise when all current RCU readers have completed their RCU critical sections and the grace period has ended blocks waits until the grace period has completed and then implements the second phase update operation such as by removing stale data. According to the asynchronous technique an updater performs the first phase update operation specifies the second phase update operation as a callback using an RCU primitive such as call rcu then resumes other processing with the knowledge that the callback will eventually be processed at the end of a grace period. Advantageously callbacks requested by one or more updaters can be batched e.g. on callback lists and processed as a group at the end of an asynchronous grace period. This allows the grace period overhead to be amortized over plural deferred update operations.

The length of an RCU grace period has performance implications. Although RCU can greatly improve the performance and latency of read side accesses it can in a number of cases degrade update side accesses. This is a design choice the purpose of RCU is to improve read side performance in read mostly situations. In addition on the update side there is a trade off between grace period latency and per update overhead. Longer latencies allow the overhead of a single grace to be amortized over a larger number of updates thereby reducing the per update overhead. In addition the longer latency RCU grace period primitives are typically more energy efficient than are the expedited primitives which must in some cases send IPIs to sleeping CPUs. The Linux Kernel which makes extensive use of RCU is generally tuned to have relatively long grace period latencies although there are expedited primitives that can be used within the kernel to shift the trade off towards high CPU overhead in favor of shorter latencies. However there are times when a trade off towards shorter RCU grace period latencies may be desirable for example during boot time or when starting some networking applications such as the Wireshark network packet analyzer. Applicant submits that it would be particularly beneficial for user mode execution to have a way of specifying RCU grace period latency to RCU and for RCU to have a way of responding to this specification. Preferably such an approach would have the ability to correctly handle overlapping specifications from different user mode tools and use cases.

A method system and computer program product are provided for supporting user mode specification of RCU grace period latency to an operating system kernel level RCU implementation. In an embodiment there is provided a non expedited RCU grace period mechanism for invocation by RCU updaters when performing RCU update operations to initiate a non expedited grace periods and an expedited RCU grace period mechanism for invocation by RCU updaters when performing RCU update operations to initiate expedited grace periods. There is further provided a expedited grace period indicator in a kernel memory space for indicating whether a non expedited RCU grace period or an expedited RCU grace period should be invoked. The non expedited RCU grace period mechanism is adapted to check the expedited grace period indicator and if the expedited grace period indicator indicates that an expedited RCU grace period should be invoked to invoke the expedited grace period mechanism. A communication mechanism is provided for use by a user mode application executing in a user memory space to manipulate the expedited grace period indicator in the kernel memory space and thereby control whether an expedited or non expedited RCU grace period should be used.

In an embodiment the expedited grace period indicator may comprise a counter whose value indicates whether or not an expedited grace period has been requested by the user mode application.

In an embodiment the communication mechanism may comprise a pair of files of an in memory file system the files corresponding to kernel functions that manipulate the expedited grace period indicator. A first one of the files may correspond to a kernel function that manipulates the expedited grace period indicator to indicate a need for an expedited grace period. A second one of the files may correspond to a kernel function that manipulates the expedited grace period indicator to indicate a need for a normal grace period.

In an embodiment the communication mechanism may comprise a device driver that manipulates the expedited grace period indicator.

In an embodiment the communication mechanism may comprise 1 a pair of files of an in memory file system the files corresponding to kernel functions that manipulate the expedited grace period indicator and 2 a device driver that manipulates the expedited grace period indicator. The pair of files and the device driver may be used by the user mode application to request expedited grace periods at different stages of operation of the computer system.

In an embodiment the expedited grace period indicator is set during a system boot mode of said computer system based on a user specified kernel boot parameter.

Turning now to the figures wherein like reference numerals represent like elements in all of the several views illustrates an example multiprocessor computer system that may be used to implement the technique disclosed herein. A uniprocessor computer system could also be used. The computer system includes multiple processors . . . a system bus and a program memory . There are also cache memories . . . and cache controllers . . . respectively associated with the processors . . . . A memory controller is associated with the memory . As shown the memory controller may reside separately from processors . . . e.g. as part of a chipset . Alternatively the memory controller could be provided by plural memory controller instances respectively integrated with the processors . . . as is known in the art .

The computer system may represent any of several different types of computing apparatus. Such apparatus may include but are not limited to general purpose computers special purpose computers portable computing devices communication and or media player devices set top devices embedded systems to name but a few. The processors . . . may each be a single core CPU device. Alternatively the processors . . . could represent individual cores within a multi core CPU device. Each CPU device embodied by any given processor is operable to execute program instruction logic under the control of a software program stored in the memory or elsewhere . The memory may comprise any type of tangible storage medium capable of storing data in computer readable form including but not limited to any of various types of random access memory RAM various flavors of programmable read only memory PROM such as flash memory and other types of primary storage. The processors . . . may be situated within a single computing device or node e.g. as part of a single node SMP system or they may be distributed over plural nodes e.g. as part of a NUMA system a cluster a cloud etc. .

An update operation updater may periodically execute within a process thread or other execution context hereinafter task on any processor . Each updater runs from program instructions stored in the memory or elsewhere in order to periodically perform updates on a set of shared data that may be stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual data updaters that may periodically execute on the several processors . . . . As described in the Background section above the updates performed by an RCU updater can include modifying elements of a linked list inserting new elements into the list deleting elements from the list and other types of operations. To facilitate such updates the processors are programmed from instructions stored in the memory or elsewhere to implement a read copy update RCU subsystem as part of their processor functions. In reference numbers . . . represent individual RCU instances that may periodically execute on the several processors . . . . Any given processor may also periodically execute a read operation reader . Each reader runs from program instructions stored in the memory or elsewhere in order to periodically perform read operations on the set of shared data stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual reader instances that may periodically execute on the several processors . . . . Such read operations will typically be performed far more often than updates this being one of the premises underlying the use of read copy update. Moreover it is possible for several of the readers to maintain simultaneous references to one of the shared data elements while an updater updates the same data element. Embodiments of the updaters and the readers may be preemptible and embodiments of the system may for example support real time operations.

During run time an updater will occasionally perform an update to one of the shared data elements . In accordance the philosophy of RCU a first phase update is performed in a manner that temporarily preserves a pre update view of the shared data element for the benefit of readers that may be concurrently referencing the shared data element during the update operation. Following the first phase update the updater may register a callback with the RCU subsystem for the deferred destruction of the pre update view following a grace period second phase update . As described in the Background section above this is known as asynchronous grace period processing.

The RCU subsystem may handle both asynchronous and synchronous grace periods. Each type of grace period processing entails starting new grace periods and detecting the end of old grace periods so that the RCU subsystem knows when it is safe to free stale data or take other actions . Asynchronous grace period processing further entails the management of callback lists that accumulate callbacks until they are ripe for batch processing at the end of a given grace period. Grace period processing operations may be performed by periodically running the RCU subsystem on each of the several processors . . . in . As is known different aspects of such processing may be variously invoked by an operating system scheduler and an scheduling clock interrupt handler and run in a combination of process context and bottom half context or kernel thread context.

With continuing reference to additional example components of the RCU subsystem include several RCU subsystem support functions namely an RCU reader API Application Programming Interface an RCU updater API and various grace period detection and callback processing functions including an non expedited grace period function A and an expedited grace period function B.

As stated in the Background section above some RCU implementations such as those used in recent versions of the Linux Kernel are generally tuned to have relatively long grace period latencies. In the illustrated embodiment the non expedited grace period function A shown in provides such relatively long grace periods. The synchronize rcu primitive of existing RCU implementations exemplifies this approach. However there are expedited primitives that can be used within the kernel to shift the trade off towards high CPU overhead in favor of shorter latencies. The synchronize rcu expedited primitive of existing RCU implementations exemplifies this approach. In the illustrated embodiment the expedited grace period function B shown in provides such shorter latency grace periods.

As further stated in the Background section above there are times when user mode execution needs to specify a trade off towards shorter RCU grace period latencies for example during boot time or when starting some networking applications such as Wireshark . It would be particularly beneficial for user mode execution to have a way of specifying RCU grace period latency to the RCU subsystem and for the RCU subsystem to have a way of responding to this specification. Preferably such an approach would have the ability to correctly handle overlapping specifications from different user mode tools and use cases.

The present disclosure sets forth a technique that allows a user mode application to specify whether a non expedited grace period or an expedited grace period should be invoked by the RCU subsystem . The general approach is to make the non expedited grace period function A check the expedited grace period indicator and if that indicator is set to a certain value invoke the expedited versions.

The expedited grace period indicator may be implemented in various ways with a simple approach being to use a counter. In that case a counter value of zero could indicate that a normal grace period should be invoked and a non zero value could indicate that an expedited grace period should be invoked. Example operations are shown in . As indicated above these operations are performed by the non expedited grace period function A. Block of this functions checks the expedited grace period indicator and block tests its value. If an expedited grace period is indicated block invokes the expedited grace period function B while bypassing non expedited grace period processing. If an non expedited grace period is indicated block continues with the non expedited grace period processing.

In an embodiment the non expedited grace period function A may be implemented using a modified version of the synchronize rcu primitive found in existing RCU implementations. In that case the following C language code could be used to implement the operations performed by blocks of 

In the foregoing code line implements blocks of and tests the expedited grace period indicator which is a counter named user mode expedite. If the user mode expedite counter has a non zero value line implements block of and calls the expedited grace period function B which in the code is implemented using the synchronize rcu expedited primitive found in existing RCU implementations. If the user mode expedite counter has a zero value line implements block of and continues with the normal grace processing associated with the non expedited grace period function A which may be implemented using the synchronize rcu primitive found in existing RCU implementations.

Turning now to a communication mechanism is provided to enable a user mode application executing in a user memory space to manipulate the expedited grace period indicator in a kernel memory space so that the user mode application can thereby control whether an expedited or a non expedited RCU grace period should be used. The communication mechanism may be implemented in various ways. One approach is to use an in memory file system such as the sysfs facility in the Linux kernel to expose a pair of files that correspond to kernel functions that manipulate the expedited grace period indicator to either indicate a need for either an expedited grace period or a normal grace period. The in memory file system that contains the two files is mounted into a file system tree and the user application is given read write access to the files.

Assuming the expedited grace period indicator is implemented as a counter the kobject attribute A may be written so that a write to sysfs file A increments the counter value either atomically or under an appropriate lock . Conversely the kobject attribute B may be written so that a write to sysf file B decrements the counter value again either atomically or under an appropriate lock . In both cases it may be desirable to check for counter overflow underflow and return an error in those cases. The kobject attributes A and B are also written so that a read from either of sysfs file A or B will return the current value of the expedited grace period indicator . Again this effect can be accomplished with typical use of the Linux kernel s sysfs facility.

Using the foregoing sysfs communication mechanism the user application desiring to reduce RCU grace period latency may write to sysfs file A carry out its operation that requires expedited RCU grace periods and then write to sysfs file B. Appropriate file permissions on sysfs file A and B may be set to prevent unauthorized use of this facility.

One potential disadvantage of the sysfs communication mechanism is that RCU grace period operations can be left expedited if the application aborts prior to the RCU grace period latency being reset. The mechanism is also subject to user application bugs that might inappropriately write or fail to write to one or the other of the two sysfs files A or B.

A way to avoid this problem is to use an alternative communication mechanism implemented by a device driver shown in that operates on the expedited grace period indicator as a dummy device. Assuming the expedited grace period indicator is a counter the driver s open function could increment the counter again either atomically or under an appropriate lock and the driver s close function could decrement the counter yet again either atomically or under an appropriate lock . There are many ways that the user mode application could invoke the device driver . For example a device read operation could be used to increment the counter and a device write operation could be used to decrement the counter. In an alternative embodiment a device write operation could be used to both increment and decrement the counter. For example the first byte written could be interpreted as a signed character specifying the value to increment or decrement. In another alternative embodiment a ioctl operation could be used with a command value specifying either a counter increment or a counter decrement. In a still further alternative embodiment an lseek fd value SEEK CUR command could be used where fd is the file descriptor open to the device in question and value is the amount to increment or decrement the counter with a positive value indicating an increment and a negative value indicating a decrement.

An advantage of using the device driver as a communication mechanism is that if the application aborts the device driver will automatically close the dummy device and reset the expedited grace period indicator to its default state thereby avoiding the problem called out with the sysfs communication mechanism.

Note that the device driver communication mechanism may not be appropriate for system boot because there is no user application that runs for the duration of a boot sequence. However once normal steady state operation commences the device driver communication mechanism will be effective. To address the boot mode issue a kernel boot parameter could be provided that allows users to specify an initial value of the expedited grace period indicator . If no boot parameter is specified a default value could be set e.g. to select non expedited grace periods .

A third communication mechanism that could be used combines the first two communication mechanisms. In particular the device driver communication mechanism could be provided for user mode applications during normal operation of the computer system and the sysfs communication mechanism could be used under special circumstances. One special circumstance might arise during system boot mode where late time boot scripts that need to unconditionally enable expedited RCU grace period operation could use the sysfs technique provided that the sysfs file system has already been set up during an earlier stage of the boot sequence . As another special circumstance warranting use of the sysfs communication mechanism there may be situations where a time based switch between non expedited and expedite RCU grace period operation needs to be made e.g. between expedited grace periods for interactive workloads during the day to ensure rapid response time and non expedited grace periods for batch processing workloads at night to ensure high throughput . A further special circumstance warranting use of the sysfs communication mechanism would be to provide convenient access for prototyping and scripting.

Accordingly a technique for supporting user mode specification of RCU grace period latency to an operating system kernel level RCU implementation. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine useable storage media for use in controlling a data processing system to perform the required functions. Example embodiments of a data processing system and machine implemented method were previously described in connection with . With respect to a computer program product digitally encoded program instructions may be stored on one or more computer readable data storage media for use in controlling a computer or other digital machine or device to perform the required functions. The program instructions may be embodied as machine language code that is ready for loading and execution by the machine apparatus or the program instructions may comprise a higher level language that can be assembled compiled or interpreted into machine language. Example languages include but are not limited to C C assembly to name but a few. When implemented on a machine comprising a processor the program instructions combine with the processor to provide a particular machine that operates analogously to specific logic circuits which themselves could be used to implement the disclosed subject matter.

Example data storage media for storing such program instructions are shown by reference numerals memory and cache of the computer system of . The system may further include one or more secondary or tertiary storage devices not shown that could store the program instructions between system reboots. A further example of data storage media that may be used to store the program instructions is shown by reference numeral in . The data storage media are illustrated as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such data storage media can store the program instructions either alone or in conjunction with an operating system or other software product that incorporates the required functionality. The data storage media could also be provided by other portable data storage media such as floppy disks flash memory sticks etc. or data storage media combined with drive systems e.g. disk drives . As is the case with the memory and the cache of the data storage media may be incorporated in data processing platforms that have integrated random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the data storage media could comprise any electronic magnetic optical infrared semiconductor system or apparatus or device or any other tangible entity representing a machine manufacture or composition of matter that can contain store communicate or transport the program instructions for use by or in connection with an instruction execution system apparatus or device such as a computer. For all of the above forms of data storage media when the program instructions are loaded into and executed by an instruction execution system apparatus or device the resultant programmed system apparatus or device becomes a particular machine for practicing embodiments of the method s and system s described herein.

Although various example embodiments have been shown and described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the disclosure. It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

