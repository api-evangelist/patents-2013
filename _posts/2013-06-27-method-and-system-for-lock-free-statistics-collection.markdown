---

title: Method and system for lock free statistics collection
abstract: Lock free collection of performance data from an application program executing in a computer system having a multi-core central processing unit is described. A data collection mechanism creates a water mark queue that includes a data structure to store an array and plurality of pointers, including head, tail, high water mark and low water mark pointers. A plurality of worker threads is spawned, each configured to collect and store data from the application program. The data collection includes incrementing the head pointer, reading an index from a head element of the array and incrementing the high water mark pointer in a single transaction. A context is retrieved corresponding to the retrieved index. An operation is performed based on information contained in the retrieved context. Subsequently, the tail pointer is incremented, the index is written to a tail element of the array and the low water mark pointer is incremented.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09128749&OS=09128749&RS=09128749
owner: EMC CORPORATION
number: 09128749
owner_city: Hopkinton
owner_country: US
publication_date: 20130627
---
System monitoring is important to ensure a healthy computing environment. Even more important is the application level monitoring to ensure easy and early identification of potential issues so that that application uptime is maintained at a high number. One way to monitor a running application is to collection performance data statistics from programming modules.

Information extracted out of collected monitoring data is used in a wide variety of ways over the lifetime of any application deployment such as identifying connectivity issues module failures troubleshooting a product issue analyzing application performance extracting performance metrics such as response times and run time memory usage building a knowledge base related to usage patterns and or trends and analyzing large amounts of data such as recommendation engines. Often the information that is captured in application monitoring is turned into knowledge which can be used to improve the predictability and or usability of an application program.

Runtime performance data may provide a great deal of insight into potential performance issues with a running application. For example a statistics of execution time of each method or at least critical methods in an application program may be used to identify critical performance bottlenecks and can help system administrators and application architects to take remedial measure to enhance overall system performance. For example if the collected performance data statistics shows that the execution time of a particular method in a monitored application program is gradually increasing the system engineers can analyze the method implementation for possible memory leaks programming or connectivity issues. Such function call level performance data statistics collection provides details about application program running state with real time traffic in production environment.

Solutions are available to instrument application programming code that involves including statistics collection instructions in object code. However these solutions are only useful in non production environments e.g. test environments because code instrumentation causes substantial performance degradation making such solutions unsuitable for production environments. This performance degradation may even be more profound in multi core central processing unit CPU environment due to a need for cache synchronization among multiple cores to maintain data integrity in a multi threaded application execution. In traditional solutions the overhead of probing is so substantial that some commercial profilers even provide methods such as Time Exclusive Probe Overhead to obtain real elapsed time without overhead of probing. Needless to say that due to high overheads of probing these solutions are not suitable for production environments.

Most modern CPUs include memory cache that typically offers substantially faster data read write characteristics compared to CPU main memory. A CPU cache is a cache used by the central processing unit of a computer to reduce the average time to access memory. The cache is a smaller faster memory which stores copies of the data from the most frequently used main memory locations. As long as most memory accesses are cached memory locations the average latency of memory accesses will be closer to the cache latency than to the latency of main memory.

In a multi core CPU execution environment different application threads may be executed by different CPU cores. The following example illustrates cache synchronization and data locking issues in multi core CPU environments.

Suppose an application program has two running threads and the application program includes the following instruction 

Since a normal instruction like this is allowed to run on cached data if both threads attempt to execute this instruction at a same time the results of data increment will be undefined. To ensure well defined behavior when this instruction is executed by the first thread the other thread must be locked from entering this instruction and caches be synchronized among different CPU cores. This extra locking and synchronizing overhead can be quite expensive and can substantially slow down the overall execution of the application program.

If the execution of the application program encounters thread synchronization primitive such as critical section it forces CPU to synchronize its local cache with the main memory as well as synchronization of caches among different CPU cores. This synchronization is an expensive event. In such events the processor cores are forced to discard their own cached copies of the lock so every running thread encounters a cache miss almost every time and must use the bus to fetch the new but unchanged value.

A need for cache synchronization and data locking in some instruction execution scenarios can be avoided by ensuring that only one thread operates on a selected set of data at any given time without using critical sections or other thread synchronization primitives. One or more aspects of the present disclosure addresses providing a lock free collection of application performance statistics in multi core CPU environment using CPU copy and swap CAS instruction.

Compare and Swap is an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory location to a given value and only if they are the same modifies the contents of that memory location to a given new value. This is done as a single atomic operation. In one embodiment an atomic operation means that all sub operations or operation steps are performed in a thread without interferences from any other threads until the atomic transaction completes. When one thread starts performing operation steps within an atomic transaction a second thread competing to perform the same operation is either made to wait or an error is returned when the other thread attempt to perform the operation. The atomicity guarantees that the new value is calculated based on up to date information if the value had been updated by another thread in the meantime the write would fail. The result of the operation must indicate whether it performed the substitution this can be done either with a simple Boolean response this variant is often called compare and set or by returning the value read from the memory location not the value written to it .

Unlike single processor systems in multiprocessor or multi core systems it is usually impossible to disable interrupts on all processors at the same time to achieve atomicity. Even if it were possible two or more processors could be attempting to access the same semaphore s memory at the same time and thus atomicity would not be achieved. The CAS instruction allows any processor to atomically test and modify a memory location preventing such multiple processor collisions.

The subject matter presented herein provides a lock free collection of application runtime statistics including function elapsed times in a multi core CPU execution environment. The lock free collection of such stats introduce substantially reduced overhead compared to traditional solutions thus making the presented methods and systems suitable for incorporation in production execution environments. The subject matter presented herein further provides aggregation of collected stats for a high level monitoring of an application a group of application or an enterprise as a whole.

Prior to describing the subject matter in detail an exemplary hardware device in which the subject matter may be implemented shall first be described. Those of ordinary skill in the art will appreciate that the elements illustrated in may vary depending on the system implementation. With reference to an exemplary system for implementing the subject matter disclosed herein includes a hardware device including a processing unit memory storage data entry module display adapter communication interface and a bus that couples elements to the processing unit .

The bus may comprise any type of bus architecture. Examples include a memory bus a peripheral bus a local bus etc. The processing unit is an instruction execution machine apparatus or device and may comprise a microprocessor a digital signal processor a graphics processing unit an application specific integrated circuit ASIC a field programmable gate array FPGA etc. The processing unit may be configured to execute program instructions stored in memory and or storage and or received via data entry module .

The memory may include read only memory ROM and random access memory RAM . Memory may be configured to store program instructions and data during operation of device . In various embodiments memory may include any of a variety of memory technologies such as static random access memory SRAM or dynamic RAM DRAM including variants such as dual data rate synchronous DRAM DDR SDRAM error correcting code synchronous DRAM ECC SDRAM or RAMBUS DRAM RDRAM for example. Memory may also include nonvolatile memory technologies such as nonvolatile flash RAM NVRAM or ROM. In some embodiments it is contemplated that memory may include a combination of technologies such as the foregoing as well as other technologies not specifically mentioned. When the subject matter is implemented in a computer system a basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer system such as during start up is stored in ROM .

The storage may include a flash memory data storage device for reading from and writing to flash memory a hard disk drive for reading from and writing to a hard disk a magnetic disk drive for reading from or writing to a removable magnetic disk and or an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM DVD or other optical media. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the hardware device .

It is noted that the methods described herein can be embodied in executable instructions stored in a computer readable medium for use by or in connection with an instruction execution machine apparatus or device such as a computer based or processor containing machine apparatus or device. It will be appreciated by those skilled in the art that for some embodiments other types of computer readable media may be used which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges RAM ROM and the like may also be used in the exemplary operating environment. As used here a computer readable medium can include one or more of any suitable media for storing the executable instructions of a computer program in one or more of an electronic magnetic optical and electromagnetic format such that the instruction execution machine system apparatus or device can read or fetch the instructions from the computer readable medium and execute the instructions for carrying out the described methods. A non exhaustive list of conventional exemplary computer readable medium includes a portable computer diskette a RAM a ROM an erasable programmable read only memory EPROM or flash memory optical storage devices including a portable compact disc CD a portable digital video disc DVD a high definition DVD HD DVD a BLU RAY disc and the like.

A number of program modules may be stored on the storage ROM or RAM including an operating system one or more applications programs program data and other program modules . A user may enter commands and information into the hardware device through data entry module . Data entry module may include mechanisms such as a keyboard a touch screen a pointing device etc. Other external input devices not shown may be connected to the hardware device via optional external data entry interface . By way of example and not limitation external input devices may include a microphone joystick game pad satellite dish scanner or the like. In some embodiments external input devices may include video or audio input devices such as a video camera a still camera etc. Data entry module may be configured to receive input from one or more users of device and to deliver such input to processing unit and or memory via bus .

Optionally a display is also connected to the bus via display adapter . Display may be configured to display output of device to one or more users. In some embodiments a given device such as a touch screen for example may function as both data entry module and display . External display devices may also be connected to the bus via optional external display interface . Other peripheral output devices not shown such as speakers and printers may be connected to the hardware device . It should be noted that if the hardware device is incorporated in a server farm environment the display may be coupled to the hardware device remotely.

The hardware device may operate in a networked environment using logical connections to one or more remote nodes not shown via communication interface . The remote node may be another computer a server a router a peer device or other common network node and typically includes many or all of the elements described above relative to the hardware device . The communication interface may interface with a wireless network and or a wired network. Examples of wireless networks include for example a BLUETOOTH network a wireless personal area network a wireless 802.11 local area network LAN and or wireless telephony network e.g. a cellular PCS or GSM network . Examples of wired networks include for example a LAN a fiber optic network a wired personal area network a telephony network and or a wide area network WAN . Such networking environments are commonplace in intranets the Internet offices enterprise wide computer networks and the like. In some embodiments communication interface may include logic configured to support direct memory access DMA transfers between memory and other devices.

In a networked environment program modules depicted relative to the hardware device or portions thereof may be stored in a remote storage device such as for example on a server. It will be appreciated that other hardware and or software to establish a communications link between the hardware device and other devices may be used.

It should be understood that the arrangement of hardware device illustrated in is but one possible implementation and that other arrangements are possible. It should also be understood that the various system components and means defined by the claims described below and illustrated in the various block diagrams represent logical components that are configured to perform the functionality described herein. For example one or more of these system components and means can be realized in whole or in part by at least some of the components illustrated in the arrangement of hardware device . In addition while at least one of these components are implemented at least partially as an electronic hardware component and therefore constitutes a machine the other components may be implemented in software hardware or a combination of software and hardware. More particularly at least one component defined by the claims is implemented at least partially as an electronic hardware component such as an instruction execution machine e.g. a processor based or processor containing machine and or as specialized circuits or circuitry e.g. discrete logic gates interconnected to perform a specialized function such as those illustrated in . Other components may be implemented in software hardware or a combination of software and hardware. Moreover some or all of these other components may be combined some may be omitted altogether and additional components can be added while still achieving the functionality described herein. Thus the subject matter described herein can be embodied in many different variations and all such variations are contemplated to be within the scope of what is claimed.

In the description that follows the subject matter will be described with reference to acts and symbolic representations of operations that are performed by one or more devices unless indicated otherwise. As such it will be understood that such acts and operations which are at times referred to as being computer executed include the manipulation by the processing unit of data in a structured form. This manipulation transforms the data or maintains it at locations in the memory system of the computer which reconfigures or otherwise alters the operation of the device in a manner well understood by those skilled in the art. The data structures where data is maintained are physical locations of the memory that have particular properties defined by the format of the data. However while the subject matter is being described in the foregoing context it is not meant to be limiting as those of skill in the art will appreciate that various of the acts and operation described hereinafter may also be implemented in hardware.

To facilitate an understanding of the subject matter described below many aspects are described in terms of sequences of actions. At least one of these aspects defined by the claims is performed by an electronic hardware component. For example it will be recognized that the various actions can be performed by specialized circuits or circuitry by program instructions being executed by one or more processors or by a combination of both. The description herein of any sequence of actions is not intended to imply that the specific order described for performing that sequence must be followed. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. In an embodiment the computer system includes one or more methods for lock free collection of system performance data.

Even though the present disclosure is described for collecting function call elapsed times the collection of elapsed times and performance statistics as described herein is exemplary. It should be noted that some aspects of the present disclosures may be employed for gathering other types of data statistics such as system logs system variables snapshots of data collected from users or other systems frequently changing data such as stock quotes to name a few without diverting from the core concepts described herein. While the kind of the data that is captured to build a performance statistics dataset is predefined the data that needs to be captured may vary based on the use case that needs to be troubleshot and the context in which the data is evaluated. The kind of the data that is required to troubleshoot any memory bottleneck may not be same as the kind of data that is required for troubleshooting a malfunctioning issue.

In one example the lock free statistics collector is designed to collect elapsed times of function calls that is time taken to execute a function call and aggregate results. Typically one way to collect a function call elapsed time is to call a start instruction and an end instruction provided by the lock free statistics collector at the beginning and at the end respectively of the function call. In other examples abstract methods that includes code to mark start and end of the execution of a function call may be provided for implementation of application program classes or function calls.

The function call elapsed time may be determines by starting a timer at or near the entry point of the function call and stopping the timer at or near the exit point of the function and calculating the difference. The elapsed time may also be calculated by saving the current time e.g. milliseconds elapsed since a pre configured date time at the entry and the exit of the function. The elapsed time may also be calculated in terms of number of cycles the CPU has performed between the entry and the exit of the function call and calculating time elapsed using the CPU frequency. In one embodiment Timestamp counter register of the CPU may also be used for determining elapsed time in that to count CPU cycles efficiently Timestamp counter is incremented on each CPU cycle. In another embodiment programming language default timer function e.g. System.currentTimeMills in Java may be used to measure elapsed clock time.

The lock free statistics collector maintains a thread local variable to collect data from function calls. As thread is spawned the thread puts the collector variable in a map object e.g HashMap in Java programming language using thread id as a key. A plurality of other threads may be spawned similarly. It should be noted that even though Java is mentioned herein several times the lock free statistics collector may be implemented in other programming languages such as C C etc. At runtime the lock free statistics collector adds elapsed time and or other performance variable if the lock free statistics collector is so configured of function call in thread s local collector variable. An aggregation thread may also be spawned and configured to iterate through the map at predefined intervals to collect and persist aggregated data.

The lock free statistics collector includes a water mark memory queue . The water mark memory queue is a special type of memory queue that includes storage for an integer array and a storage for storing a number of memory pointers. The memory pointers includes a head pointer a tail pointer a lower water mark and a high water mark. Memory queues e.g. first In First Out FIFO memory queues using only head and tail pointers are well known in the art therefore a detailed described is being omitted herein.

The water mark memory queue includes two additional pointers low water mark and high water mark pointers. These pointers are used to ensure atomicity of write to or fetch from the water mark queue so that while one thread is either fetching or writing to the water mark queue no other thread can engage the water mark queue .

The index integer array is initialized to a preselected size that is equal to the number of contexts in a collection of context . The collection of context include contexts that includes data structures to maintain connection info and statistics collection variable or pointers thereto . Head and high water mark pointers is initiated to 0 zero and tail and lower water mark pointers are initialized to size of the index array minus one N 1 . In one embodiment the preselected size may be derived from hardware configuration. In another embodiment the preselected size may depends on a software licensing contract. In yet another embodiment the preselected size may be derived from past performance testing data.

A plurality of worker threads are spawned each collecting elapsed time and or other configured variables and performance data from function calls of the application program . Each of the worker threads uses different context from the collection of contexts and a thread in the worker threads fetches a context from the collection of contexts based on an integer fetched from the water mark queue . When the thread completes an operation e.g. updating stats the thread returns the integer that identifies a context in the collection of contexts back into the water mark queue .

In one example the aggregation thread may be included in the lock free statistics collector and may be configured to run at preselected intervals to collect aggregated data from the data collected by the worker threads . The aggregation thread does so by iterating through the collection of contexts and read the collected data therefrom. In some aspects further aggregation calculations may be performed on the aggregation performed by the aggregation thread to increase or decrease granularity based on configurable environment settings. In one embodiment the aggregation thread stores the aggregated data in the storage . Alternatively the aggregated data may be uploaded to an external system via a Web API or FTP protocol. The aggregated data may also be kept in volatile memory accessible to the aggregation thread .

Accordingly at step when the worker thread needs to update the statistics the worker thread queries the water mark queue to obtain a context index or identification from the index array . To ensure that only one worker thread can obtain a context index at any given time the lock free statistics collector uses the CAS instruction which provides an atomic operation at the expense of any one CPU typically. To fetch next context index the head pointer in the water mark queue is incremented the next available index is read from the index array and then high water mark pointer is incremented and all these operations are performed atomically. If another thread needs a context index that threads waits. However since the CAS instruction is typically performed in one CPU cycle the wait is practically negligible.

In one example the method steps a incrementing the head pointer in the water mark queue b reading the next available index from the head element of the index array and c incrementing the high water mark pointer are performed exactly in the stated sequence a to c .

After fetching the context index at step the worker thread fetches a context corresponding to the fetched context index from the collection of contexts . At step the worker thread updates the statistics. In one embodiment the content of the water mark queue is the index array . Initially first element of the water mark queue has value 0 which points to head of the index array and last element of the water mark queue has value N 1 where N is the preselected size or upper bound of the index array which points to the tail of the index array . After the worker thread reads the value from the water mark queue the worker thread uses the value as the index to locate the referenced element.

Upon finishing the operation through the fetched context at step the worker thread returns back the previously fetched index back to the water mark queue in one atomic operation. Accordingly the worker thread increments the tail pointer writes the index to tail element of the water mark queue and then increment the lower water mark pointer. As mentioned above these three steps are performed atomically using the CAS instruction.

In one example the method steps a incrementing the tail pointer in the water mark queue b writing the index to the tail element of the index array and c incrementing the lower water mark pointer are performed exactly in the stated sequence a to c . Further in one example steps to are executed exactly in the stated sequence.

In one example the retrieval and the return of the index may be exemplarily illustrated using the following pseudo code 

The use of the terms a and an and the and similar referents in the context of describing the subject matter particularly in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. Furthermore the foregoing description is for the purpose of illustration only and not for the purpose of limitation as the scope of protection sought is defined by the claims as set forth hereinafter together with any equivalents thereof entitled to. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illustrate the subject matter and does not pose a limitation on the scope of the subject matter unless otherwise claimed. The use of the term based on and other like phrases indicating a condition for bringing about a result both in the claims and in the written description is not intended to foreclose any other conditions that bring about that result. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention as claimed.

Preferred embodiments are described herein including the best mode known to the inventor for carrying out the claimed subject matter. Of course variations of those preferred embodiments will become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventor expects skilled artisans to employ such variations as appropriate and the inventor intends for the claimed subject matter to be practiced otherwise than as specifically described herein. Accordingly this claimed subject matter includes all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is encompassed unless otherwise indicated herein or otherwise clearly contradicted by context.

