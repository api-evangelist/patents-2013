---

title: Test automation API for host devices
abstract: A system is described for testing an application on one or more host devices in a host device farm using an application programming interface (“API”) to send a test package containing an application to a test server. The sending may be initiated by a single action such as a click on a control in a user interface, or may be automatic such as on completion of a build. The test server may then execute and test the application across one or more host devices using one or more testing frameworks. Test results based at least in part on the type of testing framework used in the application may then be provided to a client device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09021443&OS=09021443&RS=09021443
owner: Google Inc.
number: 09021443
owner_city: Mountain View
owner_country: US
publication_date: 20130412
---
With the growing popularity of computing devices there is an increasing demand for applications or apps to run on such devices. These devices may include smartphones tablet computers televisions set top boxes in vehicle computer systems home entertainment systems and so forth. To satisfy this demand programmers are constantly building testing and maintaining applications. To ensure high quality and to identify problems many app developers test their apps before launching them to the public. However app testing may be time and resource intensive particularly in cases where the app is to be tested on many different mobile devices running a variety of mobile operating systems of various versions under various use conditions.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

A wide variety of applications or apps are developed for execution on computing devices including smartphones tablet computers televisions set top boxes in vehicle computer systems home entertainment systems and so forth.

There is an increasing demand for software users to build apps to run on such devices. Software users build test and maintain applications using a variety of development and build tools. Testing provides many benefits including finding and correcting errors improving performance and so forth. Testing may include observing processor usage observing memory allocation programmatic debugging determining usability validating functionality identifying regressions and so forth.

Continuous integration and other application development methodologies encourage frequent testing of ongoing builds of an application. For example code for an application may be checked into a computing device such as a build server which creates a build. In some cases the application s are in the form of executable binaries that have been previously generated from source code by a compiler designed to generate binary executables configured for processing by a processor of a host device. This build may then be used for ongoing development troubleshooting testing and so forth. By increasing the frequency of builds of the application problems with a build may be identified more quickly and the application development process may be improved. Traditional testing systems lack the ability to provide development tools for robust testing of applications executing on actual computing devices. There are potentially tens of thousands of different client devices that can be used to access an application. Owning and maintaining a version of each physical device with different hardware operating system and so forth which may be useful for testing can be expensive and troublesome. Additionally code within each build of the application may be signed in order to allow the application to be tested on real devices. Code signing is the process of digitally signing executables scripts or other pieces of information to provide an assurance as to the identity of a software author or build system. Code signing may also be used to guarantee that the code has not been altered or corrupted after signing and may make use of one or more verification hashes. A binary which has been code signed may contain a number of verification hashes that are checked at various points during execution by a kernel. The kernel is a set of instructions which when executed by a processor operate as an intermediary between applications and the actual data processing done at the hardware level. Verification hashes such as the secure hash algorithms SHA 1 SHA 2 may be used to identify revisions data corruption or tampering to verify digital signatures and so forth. Code signing may be burdensome in software development environments because the code the devices and the operating system versions of those devices may change often.

Therefore software users have had to rely on cumbersome methods for testing including use of software simulators manually provisioning and testing on computing devices connected to a particular user s desktop computer and so forth. Simulators lack the full fidelity provided by execution on the actual computing device resulting in incomplete testing. Manual provisioning and testing with a connected computing device is time and resource intensive and may result in the user s desktop computer being occupied with running the testing process in conjunction with the connected computing device. This disclosure describes embodiments of systems and methods for using an application programming interface API to facilitate automatically testing applications using one or more actual computing devices also known as host devices. An API is a set of routines protocols and tools implemented by a software program that enables the software program to interact with other programs.

A client device such as a desktop computer laptop and so forth may work in conjunction with a build server. The build server may be configured to support development of the application by maintaining and generating one or more builds of the application from source code code provided by users or other sources. These builds may then be sent for testing.

In one implementation when the user is ready to test the application the user may request an access token. The access token is configured to allow a computing device such as a build server or client device to communicate with a test server. The access token may be used by the build server the client device or both to identify the program calling the API and to track how the API is being used. The access token may have a set of access rights on the API associated with it. Generally the access token is short lived and can expire. Thus allowing a user to communicate with the test server for a predetermined amount of time. For example an access token may be valid up to 48 hours or any other amount of time after it has been generated. Therefore users will need to obtain a new access token if the current access token expires. The access token may be submitted with a secure request by the user instead of submitting a username and password. Once a user has an access token requests can be made on the user s behalf by passing the access token as part of the user s request. The access token may be generated by the test server or other computing device.

In one implementation a user sends the application and the access token to a test server using an API. In this implementation the transmission of API requests and responses may be made over Hypertext Transfer Protocol over Secure Socket Layer HTTPS or another encrypted communication path. The test server retrieves the application and validates the type of application and the framework that will be used for testing the application.

Once the application has been retrieved the application may be re signed in order to permit testing and debugging. The re signing either replaces existing digital signatures in the application or adds digital signatures to the application. This may include pseudo signing or generating valid hashes which allow for execution but may not otherwise meet more stringent signing requirements intended by an operating system designer. During the code signing process entitlements may be added to the binary in the applications. Entitlements indicate how an application and features of an application may be accessed by an end user. Examples of entitlements include 

For example when the get task allow and task for pid allow entitlements are set to False it may not possible to run tests on the application or debug the application. To overcome this issue the application may be re signed. In another implementation signature verification may be patched out of the kernel of the executing device such as the host device . Patching out removes the signature verification functionality from the kernel and thus permits installation of un signed code into the application for testing and execution on the host device . Additionally because the binary contains a number of verification hashes that are checked in various locations throughout the kernel verifications hashes are generated which may then be checked and passed by the kernel.

Once the application has been re signed a user may also send a test package and the access token to a test server using an API. The test server receives the test package and validates that the test package corresponds to the framework that will be used for testing the application. Once the test package is verified a user may send a list of one or more device types to be used to run the test. The test package may also include device configuration data such as for example network data memory usage device orientation and geographic location. The test server then configures one or more host devices to execute the application according to the configuration data provided by the user. To this end the test server may test an application across multiple frameworks using one or more host devices.

The host devices used during testing may vary from one another in hardware software configuration and so forth. Additionally the use of a plurality of host devices allows for contemporaneous testing in parallel reducing time to provide test results compared to a sequence of serial tests on a single host device. Finally the use of the actual computing device during testing provides the highest fidelity testing available which is representative of the end user experience which may improve quality of the application as released to the end user.

Once the host devices are configured the test server may install the application on the host devices and execute the test package on each of the host devices. Alternatively the test package may be executed by the test server that communicates with the host devices. This execution may include testing monitoring and so forth configured to generate test results. The test results may include failure reports screenshots for all of the test frameworks logs of each of the host devices user interface information and any additional files that the test creates. The test results may then be returned to the build server the client devices or both. For example the test results can be emailed to a user posted to a uniform resource locator URL associated with the user real time test results can be provided to the user via a keepalive process or the results may be posted to a different URL that is maintained by a different server.

In order to expedite the overall testing process for applications across multiple frameworks and host devices a user of a client device may easily transfer the application and the test package to the test server using an application programming interface API and automatically receive test results.

The application may be a native app a markup language application hybrid app or a browser based application. Native applications are those which are written and compiled for execution on the particular device. For example native applications may be written in a programming language such as C or Objective C and compiled into native code such as a binary executable for use on the device. Markup language applications include one or more instructions in a markup language which may be rendered by a layout engine and one or more instructions in a scripting language which may be interpreted by a scripting language engine during execution. For example a hypertext markup language HTML version 5 or greater markup language application may include HTML cascading style sheets CSS and JavaScript. In some implementations the markup language application may have multiple instances of the UIWebView class references. Hybrid applications include native code and markup language application portions. Browser based applications are processed within a web browser application and are limited in execution. The browser based applications may have only a single UIWebView instance.

The build server may comprise one or more modules such as a source code control module build module and so forth. The source code control module may be configured to provide control of source code check in check out of source code to users and so forth. The build module is configured to take associated source code and generate a build of the application . The application as built comprises source code configured for execution on the host device . In some implementations the application as built may include executable binaries markup language applications and so forth. In some implementations the users may use the build server to implement a continuous integration methodology of software development in which workspaces of the users are merged frequently such as several times per day.

The build server may be configured to implement or work in conjunction with systems implementing one or more of the Rational ClearCase family of tools from IBM Corp the Hudson tool developed at least in part by Kohsuke Kawaguchi and available at hudson ci.org the Jenkins tool as forked from Hudson and promulgated by Kohsuke Kawaguchi which is available at jenkins ci.org Perforce from Perforce Software Inc. of Alameda Calif. or GitHub from GitHub Inc. of San Francisco Calif.

The build server is configured to communicate over one or more networks . The networks may include public networks such as the Internet private networks such as an institutional and or personal intranet or some combination of private and public networks. The networks may also include any type of wired and or wireless network including but not limited to local area networks LANs wide area networks WANs Wi Fi WiMax and mobile communications networks e.g. 3G 4G and so forth . The networks may utilize communications protocols including packet based and or datagram based protocols such as internet protocol IP transmission control protocol TCP user datagram protocol UDP or other types of protocols.

A test server may also communicate over one or more networks . Communication may be established between the build server and the test server . The build server is configured to generate and send an application and a test package along with an access token to the test server . The test package may comprise tests configuration data build information and so forth. The build server may send the application and test package using a uniform resource locator URL which is associated with a particular account on the test server . The URL used by the build server to send the test package may be unique to a particular user group of users build server entity organization and so forth. Alternatively the build server may indicate a raw file path corresponding to the location of the application and the test package on a client device .

The test server comprises a test server API module configured to accept and respond to the application and the test package sent by the build server . In one implementation the exchange of information between the build server and the test server may be encrypted. For example transfers of the application and the test package may use HTTPS.

As described above the build server may be configured to implement or work in conjunction with various systems to support development. In one implementation the build server may implement a Hudson Jenkins build server system with plugins configured to interface with the test server using the test server API module . The plugins may allow for opening a specific host device with an installed specific build of the application as a post build option. The plugins may also allow for automated calls to the test server to interact with particular builds.

In some implementations the test server may be configured to work with various tools such as ClearCase Jenkins Hudson Perforce GitHub and so forth. Similarly the test server and the services provided by the test server may be configured to integrate with various software development kits SDKs . For example integration may be provided for SDKs promulgated by Sencha Inc. of Redwood City Calif. PhoneGap by Adobe Systems of San Jose Calif. AppGyver by AppGyver Inc. of San Francisco Calif. Eclipse by the Eclipse Foundation of Ottawa Ontario and so forth. The test server or portions thereof such as the test server API module may be customized to allow for integration with particular users or entities.

An unpack module may be configured to unpack the test package . This unpacking may include one or more of separating out the executables tests configuration data build information and so forth.

The host devices may include smartphones tablet computers televisions set top boxes in vehicle computer systems home entertainment systems and so forth. The host device farm may include different varieties of host devices . These varieties may reflect differences in hardware software configuration and so forth. For example the host device farm may include host devices from manufacturer A manufacturer B and so forth. Furthermore these host devices may be of different generations capabilities and so forth. Continuing the example the host devices from the manufacturer A may include tablet computers smartphones and so forth.

In some embodiments the test server may employ one or more input output I O interfaces comprising an electrical or optical connection to couple to the one or more host devices in the host device farm . In one embodiment a universal serial bus USB 2.0 or better connection may be used to communicatively couple the host device to the test server . The USB connection may be used to transfer data from the host device to the test server or another test server using TCP as a communication protocol. The data may include the application testing applications screenshots test results diagnostic data and so forth.

The test server may also be configured to receive information associated with all the test frameworks associated with the one or more host devices . This information may include diagnostic output testing outputs screenshots of one or more of the displays of the one or more host devices and so forth. The screenshots may be stored as still images or combined to form a video stream representative of information presented on the display of the host device . The screenshots generated as the one or more host devices execute the application may be received by the test server for analysis presentation to the user stored and so forth.

An application validation module may also be provided in the test server . The application validation module may be executed to validate and verify that the application meets design and development requirements.

Additional details on the application validation module may be found in U.S. patent application Ser. No. 13 631 919 filed on Sep. 29 2012 titled Application Validation Through Object Level Hierarchy Analysis to Manish Lachwani et al. which is incorporated by reference into this disclosure.

The test server may also incorporate a test validation module . The test validation module may be executed to validate and verify that test package is a valid file type for the particular framework that is used for testing the application .

A test result module is configured to generate test results based at least in part on information provided by one or more of the host devices . The test server API module may be used to provide the test results to the build server the client devices or both. In one implementation a user may specify the information that is captured and provided in the test results .

The build server a client device or both may receive the test results . The build server may provide at least a portion of the test results or information based at least in part on the test results to the client devices for presentation to the users . In some implementations the build module may use information in the test results to indicate portions of the application which have passed or failed testing by the test server . The user may also specify how the test results are to be presented to the user . For example at least a portion of the test results may be emailed to an email address provided by a user posted to the URL specified by a user sent to a client device as the test results are generated using a keepalive process or posted to URL associated with an owner of the test server . In some instances test results that are posted to the URL associated with the owner of the test server may be available for viewing by a user for a predetermined amount of time.

The modules of the build server the test server the host devices and so forth are described in this disclosure as separate modules. In some implementations at least a portion of the functionality of these modules may be combined into a single module or incorporated into another module. Furthermore in some implementations the build server the test server and the host device farm may be operated within an organization particular network and so forth. For example a software development company may choose to implement the system for their internal use only.

The build server may include one or more input output I O interface s to allow the build server to communicate with other devices. The I O interface s may couple to one or more I O devices . In some embodiments the I O device s may be physically incorporated with the build server or be externally placed.

The build server may also include one or more network interfaces to enable communications between the build server and other networked devices. Such network interface s may include one or more network interface controllers NICs or other types of transceiver devices configured to send and receive communications over the network s . For example the network interface s may be configured to provide a Wi Fi connection compliant with one or more IEEE 802.11 standards such as 802.11g or 802.11n. The build server may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the build server .

The build server includes one or more memories . The memory comprises one or more computer readable storage media CRSM . The CRSM may be any one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium a mechanical computer storage medium and so forth. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the build server .

The memory may include at least one operating system OS module . The OS module is configured to manage hardware resources such as the I O interface s and network interface s and to provide various services to applications or modules executing on the processor s .

The memory may include a user interface module the application the source code control module the build module or other module s . The user interface module is configured to provide a user interface to the one or more client devices . In some implementations the user interface may comprise a graphical user interface and may be delivered as hypertext markup language HTML data configured for presentation on the client devices .

In some implementations the functionality of the build server may exist across one or more devices. For example a first build server may provide the user interface module while a second build server provides the source code control module a third server provides the build module and so forth.

The memory may also include a datastore to store information for operations of the build server . The datastore may comprise a database array structured list tree or other data structure. In some implementations the datastore may store the test package before transmission to the test server the test results received from the test server and so forth.

The test package may include information including build information executable files custom tests or other data P such as testing configuration data. The build information may provide information indicative of libraries used host devices supported build version number information and so forth for a particular application build. For example the build information may indicate that the test package includes build 5.13.1030.1 which is configured for execution on a particular computing device model from manufacturer A . The executable files may include executable binaries markup language applications and so forth which are configured for execution on the host devices .

The custom tests comprise information indicative of tests test scripts designation portions of the application to test and so forth. For example the user may generate a custom test to exercise particular functionality of the application . These custom tests may comprise unit tests configured for use on the host devices in the host device farm . For example the custom tests may include those developed in the OCUnit testing framework promulgated by sente.ch from Sen te of Switzerland Calabash as promulgated by lesspainful.com of Denmark Frank as promulgated by testingwithfrank.com as associated with ThoughtWorks Inc. of Chicago Ill. The test package may include other data P such as user identification account information and so forth.

Other data may also be stored such as the API URL associated with the test server historical test results version information code check in check out information build status and so forth. To this end the datastore may be configured to store and maintain information relating to the testing of the application including test success rates as well as failure reports augmented with context screenshots to pinpoint causes and activities at various crash times.

The test server may include one or more I O interface s to allow the test server to communicate with other devices. For example the I O interface s may be configured to provide a universal serial bus USB connection to couple to the host device . The I O interfaces may also be known as communication interfaces. 

The I O interface s may couple to one or more I O devices such as described above. In some embodiments the I O device s may be physically incorporated with the test server or be externally placed.

The test server may also include one or more network interfaces to enable communications between the test server and other networked devices such as those depicted in . Such network interface s may include one or more NICs or other types of transceiver devices configured to send and receive communications over the network s . For example the network interface s may be configured to provide a Wi Fi connection compliant with one or more IEEE 802.11 standards such as 802.11g or 802.11n. The test server may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the test server .

The test server may include one or more memories . The memory comprises one or more CRSM as described above. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the test server .

The memory may include at least one OS module . The OS module is configured to manage hardware resources such as the I O interface s and network interface s and to provide various services to applications or modules executing on the processor s .

The memory may store one or more of the test server API module the unpack module the application validation module the test validation module the test result module and so forth.

The test server API module is configured to accept and respond to the test package or other information sent by the client device the build server or both. The test server API module may also be configured to send the test results or other information to the client device build server or both. Use of the test server API module allows the client device and the build server to integrate the testing functionality of the test server into the automated or semi automated testing processes associated with the application build.

The unpack module may be configured to unpack the test package . The unpacking may include one or more of separating out the application build tests configuration data build information and so forth.

The memory may also include the application validation module configured to validate and verify that the application meets design and development requirements. The memory may also incorporate a test file validation module . The test file validation module may be configured to validate and verify that test package is a valid file type for the particular framework that is used for testing the application . The test result module is configured to generate test results based at least in part on information provided by one or more of the host devices . Other modules may also be stored in the memory .

The memory may also include a datastore to store information for operations of the test server . The datastore may comprise a database array structured list tree or other data structure.

The datastore may also include the test package as received from the client device or the build server using the test server API module . Testing frameworks may also be stored in the datastore . Examples of various frameworks include OCUnit UIAutomation KIF Calabash Frank and so forth. These testing frameworks enable users to create tests that automate tasks of testing functionality of the application on one or more host devices . Host device output may also be stored. The host device output comprises information received from the host devices in the host device farm . The host device output is discussed in more detail below with regard to .

The test results may also be stored in the datastore along with other data . The other data may include account information billing preferences test configurations and so forth. The test results may include failure reports screenshots for all of the test frameworks logs of each of the host devices user interface information and any additional files that the test creates. Additionally the test results may include information related to anomalous occurrences during testing of the application that have occurred by various causes other than by defects or bugs in the application . In order to follow up the causes of the failures detailed information on operating environments statuses of the system in use and so forth may also be included in the test results .

Similar to the devices described above the host device may include one or more I O interface s to allow the host device to communicate with other devices. The I O interface may be configured to provide a USB connection.

The I O interface may couple to one or more I O devices . The I O devices may include user input devices such as one or more of a keyboard a mouse a pen a game controller a voice input device a touch input device gestural input device and so forth. The I O devices may include output devices such as one or more of a display a printer audio speakers haptic output device and so forth. In some embodiments the I O devices may be physically incorporated with the host device or be externally placed.

The host device may also include one or more network interfaces configured to send and receive communications over the one or more networks . The host device may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the host device .

The host device may include a hardware based video encoder decoder . While a hardware based video encoder decoder is described in some implementations a hardware based video encoder may be used. The video encoder decoder may be incorporated into a common die with the one or more processors or may be on a separate die. The video encoder decoder may be configured to enable the capture of screenshot data in the H.264 or MPEG 4 Part 10 compliant format.

The host device includes one or more memories . The memory comprises one or more CRSM as described above. The memory may include at least one operating system OS module . The OS module is configured to manage hardware resources such as the I O interfaces and provide various services to applications or modules executing on the one or more processors . The OS module may comprise mobile operating systems configured for execution on mobile computing devices. The operating systems module may implement one or more of iOS from Apple Corp. of Cupertino Calif. Windows Mobile from Microsoft Corp. of Redmond Wash. Android from Google Corp. of Mountain View Calif. and its derivatives from various sources Palm OS from Palm Computing Inc. of Sunnyvale Calif. and its derivatives from various sources BlackBerry OS from Research In Motion Ltd. of Waterloo Ontario Canada or other operating systems such as VxWorks from Wind River Systems of Alameda Calif.

The memory may also include one or more of the application the test package a display capture module a performance debug data capture module an environment adjustment module or other modules .

The application is configured to execute on the host device . For example this may be the application received from the client device or the build server .

In some cases the test package may reside on the host device . In such cases the testing framework may be inserted into the application at runtime.

The display capture module is configured to capture screenshots of the host device display and generate screenshot data . The screenshot data may be generated using the hardware based video encoder decoder . Use of the hardware based video encoder decoder allows for the high fidelity capture and presentation of images presented on the display of the host device . This high fidelity is based on the ability to capture the screenshots at the full resolution and at the full frame rate or redraw rate of the display.

The performance debug data capture module is configured to capture one or more of performance data about the host device code level debug data for apps or other processes running on the host device and so forth. The information may be provided to the build server the user or both.

The environment adjustment module is configured to adjust the host device environment based on input from the test server . The environment includes OS OS version firmware firmware version language in use date time location position orientation and so forth.

The environment adjustment module may modify the location of the host device such that processes running on the host device behave as though the host device were located in a location other than its actual physical location. For example the host device may be located in a test facility in San Francisco Calif. but the OS module of the host device or other applications may report a location of London England.

The environment adjustment module may also generate loads on the one or more processors memory I O devices or a combination thereof. For example the environment adjustment module may be configured to execute an application which consumes 50 of the processor resources and uses enough memory to result in a low memory state in the OS module . The application may then be executed and tested under these loaded conditions.

The other modules may also be included in the host device . These other modules may include but are not limited to other application modules not under test.

The memory also includes a datastore to store information for operations of host device . The datastore may comprise a database array structured list tree or other data structure. The datastore may store the host device output which may comprise the screenshot data generated by the display capture module . The screenshot data may be stored until such data is retrieved from the host device by the test server or overwritten by the display capture module . The host device output may also include device performance and or debug data gathered by performance debug data capture module . As above the data may be stored until retrieved by the test server . Other host device output H may also be stored. Other data may also be stored in the datastore .

The interface may include a summary section describing characteristics of the application build. For example as shown here it may indicate the name of the application ExampleApp the current build number 5.13.1030.1 and the testing framework xyz.framework . In this example the application is configured to use the XYZ framework.

A deploy to test control may be presented. The control is configured to on activation generate and send the test package using the API to the test server for testing without further intervention by the user . The API may plug into the existing code repositories associated with the application and build systems. In some implementations the generation and sending of the test package may be initiated automatically such as at a pre determined time upon check in of all portions of the application upon completion of a process and so forth

A current test parameter section provides information about the current configuration of the tests to be completed. For example the test parameters may specify particular date and time geographic location CPU loading and memory usage to be used during testing network orientation and so forth. For example as shown here the wireless wide area network is set to provide an environment representative of service from ABCCell Corp. with a signal level as received at the host device of 35 .

The current test parameter section may also provide information such as what tests are to be run time frame to provide results how to apply those tests and so forth. For example as shown here the testing level is set to aggressive in which all available tests will be scheduled to run against the application . The user may specify a time requested to deliver such as as soon as possible reduced cost and so forth. For example the as soon as possible may prioritize and conduct tests for the application ahead of other applications which have selected the reduced cost option. The reduced cost option may thus be offered at a lower cost relative to the as soon as possible option given the potential delay in providing the test results . Host device variety may also be specified enabling the application to be tested against all available devices compatible with the application against a certain model and so forth. This allows for testing to be conducted easily and quickly with several models of the host device . For example the host device farm may include legacy host devices which are no longer available for purchase or pre release models of a next generation host device to allow for advance testing.

A configure testing control may be presented. The configure testing control is configured to on activation provide for modification of one or more of the test parameters. In one implementation activation of the configure testing control may present a user interface allowing the user to change the test parameters. For example the user may select options to enable debug options which provide details on UIView.

A test results section provides information based at least in part on the test results as received from the test server . The information may include screenshot data device performance debut data and so forth. For example the user may watch a stream of video taken during a portion of the testing of the application on the one or more host devices to observe behavior during testing. Other information such as UIView details a portion of a UI layout hierarchy dump application load times web site load times and so forth may also be presented. The output of the test results may be configurable to meet the specific requirements of particular users . For example test results may be filtered based at least in part on device type prior to being presented to a user .

At block the test server receives a request for an access token that facilitates communication between the client device or the build server and the test server . The access token may be used by the build server the client device or both to identify the program calling the API and to track how the API is being used. The access token may have a set of access rights on the API associated with it.

At block the test server sends the access token to the client device the build server or both. In one implementation at least a portion of the access token may be generated transmitted or received a third party computing device. The access token may be submitted with a secure request by the user instead of submitting a username and password. Once a user has an access token requests can be made on the user s behalf by passing the access token as part of the user s request.

At block the test server retrieves the application using the API and at block the test server validates the type of application and the testing framework that will be used for testing the application . For example Calabash provides for functional testing of iPhone and iPad apps. To use Calabash the application must be linked to the Calabash framework. Using this example the test server verifies that the application is linked with the calabash.framework .

At block the application is re signed. As described above the code signing process may involve providing entitlements. In one implementation entitlements are provided to turn on get task allow and task for pid allow to enable the application for testing and debugging. For example the following sample code may be used to provide entitlements 

After the entitlements have been provided the application can be signed using these entitlements by using SignEntitlement .

At block the test server retrieves the test package . As described above the test package may comprise the build information one or more executable files custom tests testing configuration data and so forth.

At block the test server validates and verifies that test package is a valid file type for the particular testing framework that is used for testing the application .

At block the test server unpacks the test package . For example the test server may extract and separate the build information the executable files and so forth for processing. This unpacking may include one or more of separating out the executables tests configuration data build information and so forth.

In some implementations the unpacking may be based at least in part on the URL which was used to transfer the test package . For example a particular URL may be associated with tests configured for a particular entity or group within the entity. As described above the test server may use the I O interface such as the USB interface to exchange information with the host device .

At block the test server then configures one or more host devices to execute the application according to the configuration data provided by the user . Each of the host devices may be configured according to the network parameter orientation parameter geographic location parameter memory parameter and other test conditions.

At block the test server initiates testing of the application on one or more of the host devices in the host device farm . The test server may install the application on the host devices and execute the test package on each of the host devices . In implementations involving iOS devices the application may be installed by communicating with the mobile installation proxy executing on an iOS device. In implementations involving Android or other operating systems the application may be installed using a command line utility.

Alternatively the test package may be executed by the test server that communicates with the host devices . As described above the one or more tests may be executed contemporaneously across a plurality of the one or more host devices . For example one hundred different tests may be executed simultaneously on one hundred different host devices .

In one implementation a test script within a test package may access an API between tests. Local APIs to the host devices may be invoked during or between test runs. These local APIs may support one or more of the following calls setLocation setOrientation setNetworkCondition multiTouch gestures Rotation setDeviceMemory clickAndSwitchApp or switchApp. These calls are configured to modify operation of the host device regardless of sensor input. The setLocation call is configured to set a geographic location altitude horizontal accuracy course speed or other position related parameters in the host device . The setOrientation call is configured to set the host device to act as if in a particular physical orientation such as portrait portrait upside down landscape left landscape right face up face down and so forth regardless off actual orientation. The setNetworkCondition call is configured to set the network conditions of the host device such as type of network connected to receive signal strength transmit power and so forth. The multiTouch call is configured to provide inputs which are indicative of one or more touches or other input on a touch sensor of the host device . For example the multiTouch call may simulate a user doing a double tap touch at particular coordinates on the touch sensor. Likewise the gestures call is configured to provide inputs which are indicative of touch gestures on the touch sensor such as pinch close pinch open and so forth. The Rotation call is configured to input which is indicative of a rotation gesture as if the host device had been physically rotated along one or more axes. The setDeviceMemory call sets or removes an amount of available memory on the host device . The ClickAndSwitchApp call is configured to open an application and provide acceptances or denials for the application. For example the ClickAndSwitch call may be used to open an application which asks the user for acceptance of terms and provide an acceptance to the application. The switchApp call allows for the switching of an app to the foreground or into focus.

For example a test script may be implemented to execute an application which searches for stores based on the location of the host device given a location of coordinates of 25.3 South by 131.1 East. The setLocation API call may be invoked to change the location parameter between tests to these coordinates. These tests may be associated with one or more of the test frameworks such as UlAutomation OCunit KIF KIWI and so forth.

In one implementation at least a portion of the one or more host devices configured to test the application may differ from one another by one or more of make model form factor input devices or output devices. In another implementation at least a portion of the one or more host devices configured to test the application may differ from one another by one or more of operating system version installed applications reported geographic location apparent network connectivity or memory usage. For example the host devices may be configured to report during testing a geographic location which differs from their actual location in a facility housing the host device farm .

At block the testing framework is injected into the application at runtime. For example for unit testing Developer Library Frameworks SenTestingKit.framework may be used. An .octest bundle may be created by a user . First the application may be launched using the debugger. For example the following sample code may be used to launch the application using the debugger.

Once the application resumes and runs the debugger the testing framework and the OCUnit framework or portions thereof may be injected into the application . For example the following sample code may be used to inject the testing framework and the OCUnit framework into the application 

At block the test server receives information from one or more of the host devices associated with the execution of the tests. This execution may include testing monitoring and so forth configured to generate test results.

At block the test server generates the test results based at least in part on the host device output . As described above the test results may include failure reports for particular sections of the application screenshots associated with particular tests specified in the test frameworks logs of each of the host devices user interface information and any additional files that the test creates. For example a test in the test framework may have output indicating a failure. The test results may include screenshots associated with the failure contents of memory at the time of the failure simulated user inputs leading up to the failure data being transferred on the network at the time of the failure and so forth.

At block the test server distributes the test results using the API to the client the build server or both. For example the test results may be attached to an email for transmission posted to a URL served to the client device via a keepalive process or posted to URL associated with the owner of the test server .

At block the client device or the build server communicates with the test server to request an access token that allows the client device or the build server to communicate with the test server . The access token may be generated by the test server or a third party computing device.

At block the client device or build server receives the access token from the test server or third party computing device. The access token may be submitted with a secure request by the user instead of submitting a username and password. Once a user has an access token requests can be made on the user s behalf by passing the access token as part of the user s request.

At block a user sends the test package and the access token to a test server using the API . The test package may comprise the application the build information one or more executable files custom tests testing configuration data and so forth. The configuration data may be used to configure one or more of the host devices to enable the application to be tested under various hypothetical network conditions. Such configuration may be manually performed on each of the host devices . In some cases the configuration of the each of the host devices may be through an automated process.

At block the test results are received by client device the build server or both. For example the test results may be attached to an email for transmission posted to a URL served to the client device via a keepalive process or posted to URL associated with the owner of the test server . As described above the test results may include failure reports screenshots for all of the test frameworks logs of each of the host devices user interface information and any additional files that the test creates. In one implementation the test results may be based at least in part on a success rate associated with the test package .

Those having ordinary skill in the art will readily recognize that certain steps or operations illustrated in the figures above can be eliminated combined subdivided executed in parallel or taken in an alternate order. Moreover the methods described above may be implemented as one or more software programs for a computer system and are encoded in a computer readable storage medium as instructions executable on one or more processors. The sample code included in this disclosure is provided by way of illustration.

Separate instances of these programs can be executed on or distributed across separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art readily recognize that the techniques described above can be utilized in a variety of devices environments and situations. Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art and it is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

