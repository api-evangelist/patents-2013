---

title: User interface with real-time visual playback along with synchronous textual analysis log display and event/time index for anomalous behavior detection in applications
abstract: According to one embodiment, a method comprises conducting an analysis for anomalous behavior on application software and generating a video of a display output produced by the application software. The video is to be displayed on an electronic device contemporaneously with display of one or more events detected by the analysis being performed on the application software.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09195829&OS=09195829&RS=09195829
owner: FireEye, Inc.
number: 09195829
owner_city: Milpitas
owner_country: US
publication_date: 20130223
---
This application is related to U.S. Patent Application entitled Framework For Efficient Security Coverage of Mobile Software Applications patent application Ser. No. 13 775 168 filed Feb. 23 2013 the entire contents of which are incorporated herein by reference.

Embodiments of the invention relate to the field of application software testing. More specifically one embodiment of the disclosure relates to a system apparatus and method for providing a user interface to visually display in real time event time indexed video that illustrates simulated operations of an application undergoing anomalous behavior detection analysis and a textual log synchronized with the video in accordance with execution flow.

Normally malware features one or more programs or files that disrupt the operations of an infected electronic device normally by attacking and adversely influencing its operations. In some instances malware may unbeknownst to the user gather and transmit passwords and other sensitive information from the electronic device. In other instances malware may alter the functionality of the electronic device without the user s permission. Examples of different types of malware may include bots computer viruses worms Trojan horses spyware adware or any other programming that operates within the electronic device without permission.

Over the last decade various types of malware detection applications have been introduced in order to uncover the presence of malware within an electronic device especially within software downloaded from a remote source and installed within the electronic device. However these applications neither provide an ability to customize the behavioral analysis nor obtain the benefits of a real time interactive visual display of such analysis.

Various embodiments of the invention relate to a system apparatus and method for providing a user interface to control a real time visual display of an anomalous behavior detection analysis being conducted on simulated operations of application software running within a virtual machine VM emulated run time test and observation environments hereinafter virtual run time environment . For example according to one embodiment the visual display may be video depicting the simulated operations during this detection analysis where the video is synchronized with a textual log displayed with the video.

The video features a multiple order indexing scheme where a first order of indexing permits a user by user interaction to access a particular segment of video in accordance with either a particular playback time in the video or a particular analyzed event. An example of an analyzed event is a test behavior namely a particular behavior being monitored during the anomalous behavior detection analysis. The second order of indexing provides a user during display of the video information related to where the analyzed event occurs within the execution flow of the application software.

Hence the video not only enables an administrator to visually witness anomalous behaviors that suggest the application software under test has malware suspicious code or pernicious code but also provides an administrator with evidence for use in policy enforcement and information to further refine or harden the anomalous behavior detection analysis and or application software.

In the following description certain terminology is used to describe features of the invention. For example in certain situations the terms logic engine and unit are representative of hardware firmware or software that is configured to perform one or more functions. As hardware logic may include circuitry such as processing circuitry e.g. a microprocessor one or more processor cores a programmable gate array a microcontroller an application specific integrated circuit etc. wireless receiver transmitter and or transceiver circuitry semiconductor memory combinatorial logic or other types of electronic components.

As software logic may be in the form of one or more software modules such as executable code in the form of an executable application an application programming interface API a subroutine a function a procedure an applet a servlet a routine source code object code a shared library dynamic load library or one or more instructions. These software modules may be stored in any type of a suitable non transitory storage medium or transitory storage medium e.g. electrical optical acoustical or other form of propagated signals such as carrier waves infrared signals or digital signals . Examples of non transitory storage medium may include but is not limited or restricted to a programmable circuit a semiconductor memory non persistent storage such as volatile memory e.g. any type of random access memory RAM persistent storage such as non volatile memory e.g. read only memory ROM power backed RAM flash memory phase change memory etc. a solid state drive hard disk drive an optical disc drive or a portable memory device. As firmware the executable code is stored in persistent storage.

It is contemplated that an electronic device may include hardware logic such as one or more of the following i processing circuitry ii a communication interface which may include one or more radio units for supporting wireless data transmission reception and or a physical connector to support wired connectivity iii a non transitory storage medium and or iv a display. Types of electronic devices may include mobile electronic devices e.g. cellular smartphones tablets laptop computers netbooks etc. stationary electronic devices e.g. desktop computers servers controllers access points base stations routers etc. that are adapted for network connectivity.

The term transmission medium is a communication path between two or more electronic devices. The communication path may include wired and or wireless segments. Examples of wired and or wireless segments include electrical wiring optical fiber cable bus trace or a wireless channel using infrared radio frequency RF or any other wired wireless signaling mechanism.

The term video is generally defined as a series of successive display images including VM emulated graphical representations screenshots of operations that would have been displayed if an electronic device executed the application software under test test application natively e.g. if the application under test was executed on a mobile device OS . Hence video may have a number of different formats for example a series of graphic images sequenced to represent a series of video frames a series of compressed video frames in compliance with H.264 MPEG 2 or another video format and a series of static images such as slide show that together define a time based sequence. The video may even be vector based graphic representations that collectively produce an animated sequence of images.

The term anomalous behavior is directed to an undesirable behavior occurring during execution of application software where a behavior may be deemed to be undesirable based on customer specific rules manufacturer based rules or any other type of rules formulated by public opinion or a particular governmental or commercial entity. This undesired behavior may include 1 altering the functionality of the device executing that application software in a malicious manner malware based behavior altering the functionality of the device executing that application software without any malicious intent suspicious code based behavior and or 3 providing an unwanted functionality which is generally acceptable in other context pernicious code based behavior . Examples of unwanted functionality by pernicious code may include tracking and or disseminating user activity on the device e.g. websites visited email recipients etc. tracking and or disseminating user location e.g. global satellite positioning GPS location privacy intrusion e.g. accessing certain files such as contact lists or the like.

For instance as illustrative examples an anomalous behavior may include a communication based anomaly such as an unexpected attempt to establish a network communication unexpected attempt to transfer data e.g. GPS data or other location data resulting in a privacy violation contact lists etc. unexpected attempt to activate a video capture device e.g. web camera or unexpected activation of an audio capture device e.g. microphone . Anomalous behavior also may include an execution anomaly for example an unexpected execution of computer program code an unexpected Application Programming Interface API function call an unexpected alteration of a registry key or the like.

Lastly the terms or and and or as used herein are to be interpreted as inclusive or meaning any one or any combination. Therefore A B or C or A B and or C mean any of the following A B C A and B A and C B and C A B and C. An exception to this definition will occur only when a combination of elements functions steps or acts are in some way inherently mutually exclusive.

As this invention is susceptible to embodiments of many different forms it is intended that the present disclosure is to be considered as an example of the principles of the invention and not intended to limit the invention to the specific embodiments shown and described.

Referring to an exemplary block diagram of an embodiment of a communication system is shown. Communication system comprises an anomalous behavior detection device for testing the safety security of application software such as mobile device application software for example. As shown anomalous behavior detection device is communicatively coupled via a transmission medium to an on line store namely one or more servers operating as a source from which application software may be downloaded to anomalous behavior detection device .

Furthermore anomalous behavior detection device is communicatively coupled via a transmission medium to one or more electronic devices N 1 . Through a graphics user interface GUI provided by anomalous behavior detection device an administrator is able to i control the anomalous behavior detection analysis and ii watch in real time VM emulated operations of the test application in concert with analysis of the presence or absence of certain behaviors chosen to be monitored during such operations hereinafter referred to as test behaviors .

As shown in electronic device s may include an electronic device communicatively coupled to transmission medium via a wireless transmission medium . Alternatively electronic device s may include electronic device N 2 that is communicatively coupled to transmission medium via a wired transmission medium . As shown electronic device is a dual mode cellular telephone while electronic device is a computer.

It is contemplated that communication system may represent a dedicated anomalous behavior detection process for a particular network or subnetwork being a part of a larger network. In such a deployment anomalous behavior detection device may be communicatively coupled to a central management system CMS which communicatively couples communication system along with other communication systems. This allows multiple communication systems to operate in tandem and exchange information as needed.

It is further contemplated that anomalous behavior detection device may be deployed to provide cloud computing anomalous behavior detection services. Alternatively anomalous behavior detection device may be deployed as an appliance electronic device integrated as part of a local or enterprise network or any combination thereof.

Referring now to an exemplary block diagram of logic that is implemented within anomalous behavior detection device is shown. Anomalous behavior detection device comprises one or more processors that are coupled to a communication interface logic via a first transmission medium . Communication interface enables communications with other electronic devices over private and or public networks such as a display device used to view the results of the anomalous behavior detection analysis. According to one embodiment of the disclosure communication interface may be implemented as a physical interface including one or more ports for wired connectors. Additionally or in the alternative interface may be implemented with one or more radio units for supporting wireless communications with other electronic devices.

Processor is further coupled to persistent storage via transmission medium . According to one embodiment of the disclosure persistent storage may include video storage unit application analyzer logic graphics user interface GUI logic and identity verification logic . Of course when implemented as hardware logic any of these logic units and or would be implemented separately from persistent memory .

Application analyzer is adapted to conduct testing of the safety security of application software including mobile device application software. Such testing involves at least analysis of one or more test behaviors in response to a sequence of simulated e.g. VM emulated operations performed by the test application. From the analysis of these test behaviors anomalous behaviors may be detected.

During this testing application analyzer also generates video by capturing display images or frames on a continuous or periodic sampling basis produced during simulated operations of the test application during the anomalous behavior detection analysis. As the anomalous behavior detection analysis at least partially involves analysis of a sequence of test behaviors a time stamp is associated with at least a first display image or frame of a video segment for each test behavior being analyzed. This enables the video to be indexed by time and by test behavior. The time stamp along with information directed to the corresponding test behavior is stored within a time stamp storage unit accessible to application analyzer while the video may be stored in video storage unit for later review. Of course time stamps may be applied to every display image or frame to provide greater precision on the location within the video where analysis for particular test behaviors is conducted.

Additionally application analyzer features an index tracking logic that is adapted to track and record which display images or frames of the video corresponds to a particular test behavior being analyzed. For example it is contemplated that index tracking logic may include a table where each entry maintains an identifier or index associated with a particular display image or frame along with a corresponding identifier or index associated with a particular aspect of the test behavior being analyzed. As a result the display of the video is synchronized with the display and illustrated progress of the analyzed test behaviors.

Furthermore after completion of this testing application analyzer assigns a threat score to the test application. The threat score ranging between minima and maxima values e.g. 0 10 represents the severity of the test behavior s detected during the anomalous behavior detection analysis. In other words the threat score may be considered to represent the amount of potential harm that detected anomalous behavior s may cause an electronic device executing that test application.

As further shown in GUI logic provides user interface screen displays for controlling the operational state of application analyzer as describe above. As examples GUI logic enables user control of the anomalous behavior detection analysis by producing a behavior selection display screen see and a behavior ordering display screen see . The behavior selection display screen enables user interaction as to the particular test behaviors for application analyzer to monitor during simulation operations of the test application. The behavior ordering display screen allows the user to place these behaviors into a particular sequence or grouping. Also GUI logic produces user interface display screens to convey the anomalous behavior analysis results including real time display of i video representing simulated operations of the test application in concert with analysis of the presence or absence of anomalous behaviors and or ii textual log synchronized with the display of the video to show the progress and completion of the analyzed events and execution flow. In some embodiments GUI logic generates for display contemporaneously i.e. in a temporally overlapping manner with the video a textual log that provides information as to when each event occurs within an execution flow of the operations of the test application and provides during playback of the video on screen reciprocal graphic interaction between the displayed video and the displayed textual log responsive to a user input.

Identity verification logic is used to control authentication of users seeking to access application analyzer . Furthermore identity verification logic may set access privileges for each authenticated user as certain users may have restricted access to only certain functionality offered by application analyzer . As an example one user may have access to replay video stored in video storage unit but is unable to initiate anomalous behavior analysis testing on application software. Another administrator may have complete access to all functionality offered by application analyzer .

Referring now to an exemplary block diagram of logic within application analyzer of is shown. Herein application analyzer comprises 1 static instrumentation engine 2 Dynamic run time test and observation RTO engine and 3 behavior setting logic . As shown static instrumentation engine and dynamic RTO engine are deployed within the same device. However it is contemplated that static instrumentation engine and dynamic RTO engine may be employed within different devices and or executed by different processors when implemented as software.

Static instrumentation engine receives a test application APPN and generates a representation of the test application that is analyzed with one or more various software analysis techniques e.g. control information analysis or data analysis . Static instrumentation engine then modifies the application code itself to include within itself special monitoring functions and or special stimuli functions operable during execution of the test application in dynamic run time test and observation engine . The monitoring functions report their results to the control logic and the stimuli functions are told what stimuli to generate by control logic . During such analysis by static instrumentation engine video is captured and or other graphics related to the analysis is generated and provided to GUI logic to produce one or more user interface display screens. Furthermore video is stored in video storage unit for subsequent playback.

It is contemplated that static instrumentation engine may be adapted to receive information from dynamic RTO engine in order to instrument the code to better analyze specific behaviors targeted in the heuristics and or probability analysis.

After processing is completed by static instrumentation engine test application is then provided to control logic within dynamic RTO engine . Control logic operates as a scheduler to dynamically control the anomalous behavior detection analysis among different applications and or the same application software among different virtual run time environments. Furthermore control logic maintains time stamp storage unit and index tracking logic as previously described.

In general dynamic RTO engine acts as an intelligent testing function. According to one approach dynamic RTO engine recursively collects information describing the current state of test application and selects a subset of rules corresponding at least in part to the test behaviors set by the user to be monitored during virtual execution of test application . The strategic selection and application of various rules over a number of recursions in view of each new observed operational state permits control logic to resolve a specific conclusion about test application namely a threat score denoting whether the application is safe or unsafe .

As shown in dynamic RTO engine comprises a virtual machine repository that is configured to store one or more virtual machines where P 1 . More specifically virtual machine repository may be adapted to store a single virtual machine VM that can be configured by scheduling functionality within control unit to simulate the performance of multiple types of electronic devices. Virtual machine repository also can store any number of distinct VMs each configured to simulate performance of a different electronic device and or different operating systems or versions for such electronic devices.

One or more virtual run time environments simulate operations of test application to detect anomalous behavior produced by this application. For instance run time environment can be used to identify the presence of anomalous behavior during analysis of simulated operations of test application performed on a virtual machine . Of course there can be multiple run time environments M 2 to simulate multiple types of processing environments for test application .

A virtual machine may be considered a representation of a specific electronic device that is provided to a selected run time environment by control unit . In one example control unit retrieves virtual machine from virtual machine repository and configures virtual machine to mimic an Android based smart phone. The configured virtual machine is then provided to one of the run time environments e.g. run time environment .

As run time environment simulates the operations of test application virtual machine can be closely monitored for any test behaviors set by the user or set by default in behavior setting logic . By simulating the operations of test application and analyzing the response of virtual machine run time environment can identify known and previously unidentified anomalous behavior and report the same through the indexed video and a dynamic textual log.

Besides VM run time environment is provided test application along with an instance of test application App an instance of the type of operating system on which target application will run if deemed sufficiently safe during the dynamic anomalous behavior detection process. Here the use of virtual machines VMs permits the instantiation of multiple additional run time environments each having its own test application and OS instance where the various run time environments are isolated from one another.

As previously described the simultaneous existence of multiple run time environments permits different types of observations tests to be run on a particular test application. That is different instances of the same test application may be provided in different run time environments so that different types of tests observances can be concurrently performed on the same application. Alternatively different test applications can be concurrently tested observed.

For instance a first application may be tested observed in a first run time environment e.g. environment while a second different application is tested observed in another run time environment e.g. environment . Notably instances of different operating system types and even different versions of the same type of operating system may be located in different run time environments. For example an Android operating system instance may be located in first run time test environment while an iOS operating system instance not shown may be located in a second run time test environment . Concurrent testing of one or more test applications whether different instances of the same application or respective instances of different applications or some combination thereof enhances the overall performance of the communication system.

Referring to an exemplary diagram of a flowchart partially illustrating anomalous behavior detection analysis conducted by the application analyzer which generate in real time video that may capture anomalous behavior detected in response to simulated operations of the test application and may provide a visual correlation of the anomalous behavior with the video segment at which it occurred. However prior to conducting this anomalous behavior analysis the anomalous behavior detection device receives a message from an electronic device requesting access to the application analyzer. In response a first user interface login display screen see is provided by GUI logic within the anomalous behavior detection device. After authentication of the user operating the electronic device and or the electronic device initiating the request message the GUI logic fetches heuristic data related to operations previously and currently being performed by the application analyzer. Such heuristic data is provided to the GUI logic to generate textual and or visual representations displayed in a second user interface dashboard display screen see .

Next upon user interaction with the second user interface display screen e.g. selection by the user of a particular object the GUI logic provides a third user interface display screen See that enables a user to select the test application which may be uploaded from a web server or an application database accessible to the application analyzer or retrieved by searching an on line store for that application block . Once the test application is received by the application analyzer a determination is made as to whether default test behaviors are to be used for the anomalous behavior detection analysis blocks and . If not the GUI logic provides user interface display screens that enable modification of the test behaviors through user interaction e.g. by selecting and deselecting listed behaviors that are available for analysis as well as altering the sequence order or groupings in the analysis of the behaviors as set forth in block .

Once the test behaviors for the anomalous behavior detection analysis are set the application analyzer virtually processes the test application to detect anomalous behavior block . The simulated operations conducted during the virtual processing of the test application produce video which is sent to the GUI logic for rendering a fourth user interface display screen in real time block . Additionally a textual log providing information as to what events e.g. test behaviors are being analyzed and when the analyzed events occur within the execution flow of the application software. This information may be provided through the placement and ordering of display objects corresponding to test behaviors alongside the video corresponding to the order of display images or frames rendered during the simulated operations of the test application.

As a result progress changes in the anomalous behavior analysis displayed by the video are synchronized with progress changes shown by the textual log. Concurrently with or subsequent to the supply of the video to the GUI logic the video is provided to video storage unit for storage and subsequent retrieval for playback block .

Referring to an exemplary diagram of a flowchart partially illustrating the replay of video produced by the application analyzer performing anomalous behavior detection analysis is shown where the video is indexed according to the particular test behaviors. As illustrated upon conducting playback of video associated with the anomalous behavior analysis conducted on the test application a determination is made whether the playback is directed to viewing a particular test behavior blocks and . If not the video commences playback at the beginning or at an elapsed start time selected by the user blocks and . However if the playback is directed to viewing video associated with a particular test behavior the application analyzer accesses a time stamp associated with a first frame for a video segment corresponding to the test behavior and uses the time stamp to index a starting point for the video playback block .

Thereafter playback of the video continues unless disrupted by video playback alternation events e.g. Pause Stop Fast Forward Reverse etc. in which playback of the video is haltered to service these events blocks and . Once playback of the video has completed this playback session ends block . The user may be provided the opportunity to commence a new playback session or select another video.

Referring now to an exemplary embodiment of a first user interface Login display screen produced by application analyzer of is shown. Herein in order to gain access to the application analyzer to perform anomalous behavior detection analysis the user initially establishes a network connection with the anomalous behavior detection device. This network connection may be established in accordance Hypertext Transfer Protocol HTTP Request or HTTP Secure HTTPS communication protocols.

As shown an initial request for access to the application analyzer is redirected to login display screen that features at least two entry fields namely a User Name and a Password . The User Name entry field requires the user to enter a registered user name in order to identify the user seeking access to the application analyzer. Password entry field allows the user to enter his or her password.

Once a login object is selected by the user the user name and password are provided to identity verification logic of within anomalous behavior detection device . Once the user is verified by identity verification logic access privileges for that user are set and the user is provided with a second user interface display screen as shown in .

As shown in an exemplary embodiment of second user interface display screen produced by the application analyzer of to operate as a dashboard is shown. Herein dashboard display screen comprises a plurality of areas and that display results of anomalous behavior analysis testing over a selected time period.

For instance first area displays a plurality of objects that provide information directed to application software that has been analyzed or are currently being analyzed with a first selected time period 24 hours . Provided by the application analyzer to the GUI logic for rendering the information associated with these objects identifies 1 number of applications submitted object 2 number of applications analyzed object 3 number of applications currently being analyzed object 4 number of applications analyzed according to customized rule settings object and 5 the number of unsafe applications detected object . Some or all of these numeric values are stored for a period of time that may be set by the manufacturer or the user.

It is contemplated that the first selected time period may be adjusted through a drop down list that features multiple time periods using the current time as a reference e.g. 24 hours ago 1 week ago 1 month ago 3 months ago 1 year ago etc. . However although not shown drop down list may also feature user interaction to select the start and end time periods for the first selected time period.

Second area provides graphical depictions of application software analyzed over a second selected time period which may differ from the selected time period for first display area . As shown a first graphical depiction represents a line graph that identifies different categories of analyzed applications vertical axis analyzed at different times within the selected time period horizontal axis . The different categories include 1 safe applications applications with a threat score not greater than a predetermined threshold 2 unsafe applications applications with a threat score greater than the predetermined threshold and 3 applications submitted for analysis .

A second graphical depiction represents a bar graph directed to applications that have completed their anomalous behavior analysis testing. For this bar graph the horizontal axis represents the measured threat score 0 10 while the vertical axis represents the number of analyzed applications associated with the measured threat score.

A third graphical depiction represents a pie chart also directed to applications that have completed their anomalous behavior analysis testing. A first color denotes those applications having a threat score indicating the application is considered safe for use while a second color denotes those applications having a threat score that identifies them as being unsafe for use.

Third area provides a graphical and or textual depiction entry for each application that has been analyzed or is in the process of being analyzed. Each entry includes a plurality of parameters including at least three or more of the following 1 date the application was submitted 2 application name 3 status safe unsafe complete with error in progress 4 threat score 683 and 5 custom rule matching status . The order of these entries can be adjusted according to submission date alphabetically by application name status and threat score.

With respect to the status parameter currently there are four status levels. As previously mentioned safe is a status level assigned to applications having a threat score no greater than a predetermined threshold while unsafe is a status level assigned to applications having a threat score greater than the predetermined threshold normally indicating the presence of malware or some sort of suspicious or pernicious code causes behaviors unsuitable for the targeted device. Another status level is in progress which indicates that the corresponding application is currently undergoing the anomalous behavior analysis. Lastly complete error is a status level which identifies that an anomalous behavior has been detected but the risk level may widely vary depending on the particular customer.

For instance as an illustrative example for application software that establishes a network connection to a server for upgrades without any malicious intent the assigned level of risk would be minimal for most clients. However where the electronic device is for use by a high ranking governmental official any unknown network connectivity may be assigned a high risk. Hence the test application is assigned to complete error status with medium threat score upon detecting a test behavior that is considered by the anomalous behavior detection analysis as being customer dependent. This status level encourages user interaction e.g. select Go To Details link located next to the threat score to obtain a more detailed explanation of the findings associated with the threat score although more detailed explanations are provided for all status levels.

Referring now to exemplary embodiments of a third user interface display screen which is produced by the application analyzer to provide upload and search capabilities for the test applications to be analyzed for anomalous behavior is shown. Herein illustrates screen display that is generated in response to user interaction e.g. selection of a particular menu object . According to this embodiment of the disclosure third user interface display screen comprises an upload display area a search display area and a submission area .

Upload display area enables the user to enter addressing information e.g. Uniform Resource Locator URL File Transfer Protocol FTP address etc. with an input field . Thereafter once the Submit object is selected an HTTP Request message is sent in order to fetch the test application from the website or database specified by the addressing information.

Search display area features an input field into which the user can enter the name or at least a portion of the name of the test application. For instance as shown in application software entitled XYZ Messenger is input into input field . A drop down list enables the user to select from a list of on line stores from which to search and acquire the XYZ Messenger as the test application. These on line stores may include Google Play store Apple App Store Amazon Appstore Windows Phone store or BlackBerry World app store or combinations of such on line stores. After entering at least a portion of the application name and selecting the on line store a Search object is selected. This activates a web browser to search for the identified application software at websites associated with the selected on line store s .

Referring to if the on line store has a copy of the test application the test application is returned and displayed as object as shown in along with metadata associated with the test application e.g. publisher name size version type OS type supported or user rating . It is contemplated that if the on line store has multiple versions of the test application XYZ Messenger all versions are returned to the application analyzer and displayed. This allows the user interaction as to the particular version to undergo anomalous behavior analysis and based on certain activity such upon selecting the Submit for Analysis object the anomalous behavior analysis of the test application begins. This enables the user to upgrade and downgrade applications to whatever version is desired by the user.

Referring back to submission area displays objects that identify applications that have been analyzed for anomalous behavior or are currently being analyzed for anomalous behavior. It is contemplated that based on user interaction each of these objects may extract either 1 a website or server address from which the application was obtained along with the application name and perhaps its version number for insertion into input field or 2 the application name and perhaps its version number for insertion into input field . This enables the user to conduct searches for updates to the particular application software without having to re enter information to locate that application.

Referring now to an exemplary embodiment of a behavior display screen produced by application analyzer of that lists selectable test behaviors for anomalous behavior analysis is shown. In response to user interaction e.g. after selecting the Submit object within upload display area or Search object and upon retrieval of the test application application analyzer uploads available test behaviors into the GUI logic to produce behavior display screen . As shown behavior display screen comprises information to identify the test application a drop down list identifying a selected operating system e.g. Android 4.2 to be emulated by the VM when conducting the anomalous behavior analysis testing and a listing of test behaviors supported by the application analyzer.

For ease of illustration only some of the test behaviors are set forth in . As a default setting certain test behaviors are pre selected for anomalous behavior analysis although it is contemplated that each listed test behavior may be subsequently selected or deselected by the user. Examples of the test behaviors are shown below in Table A by category and behavior description.

As further shown in six 6 test behaviors are set for the anomalous behavior detection analysis namely 1 send Short Message Service SMS message to any number 2 access suspicious domain 3 add delete files in local storage 4 install other applications 5 record audio and 6 access camera . After the test behaviors are set based on user interaction e.g. the user selects the Start Analysis object the anomalous behavior detection analysis commences.

As further shown in based on user interaction e.g. selection of the create new behavior link the user interactive display screen is provided for sequencing and or grouping of test behaviors for analysis as shown in .

Referring to an exemplary embodiment of a behavior group sequence display screen produced by the application analyzer of is shown. As shown display screen provides a user interaction mechanism for sequencing and or grouping test behaviors for analysis. The sequence and or grouping are used by the application analyzer to customize when test behaviors are monitored during simulated operations of the test application in one or more run time environments.

More specifically sequence based analysis builder provides a listing of test behaviors chosen by the user as illustrated in and allows the user to click and drag any test behavior within listing to alter its position within the listing. The sequence order of the test behaviors from top to bottom defines the order of processing as represented by a textual and graphical representation .

Similarly group sequence based analysis builder enables use of test behaviors to formulate groupings using logical operators AND OR . Test behaviors may be dragged into position along with logical operators .

Referring now to an exemplary embodiment of fourth user interface display screen which is produced by the application analyzer of and illustrates real time activity during the anomalous behavior detection analysis is shown. As illustrated fourth user interface display screen is produced by user interaction such as in response to selection of any Start Analysis objects and of for example. Display screen comprises a plurality of display areas that are dynamically updated during virtual processing of the test application. Such updates may be performed contemporaneous and in real time e.g. 

Video display area is allocated to display video which captures simulated operations of the test application XYZ Messenger during the anomalous behavior detection analysis in concert with analysis of the presence or absence of the selected events. During anomalous behavior analysis of the XYZ Messenger by one or more VMs in a run time environment as illustrated in the application analyzer uploads video to the GUI logic which renders in real time video within video display area . The video may illustrate static and or dynamic testing of XYZ Messenger for anomalous behavior. The progress of the anomalous behavior detection analysis is represented by progress bar where such progress is determined by the application analyzer.

Synchronous with playback of video a textual log is provided to identify the execution flow and which test behaviors have been completed awaiting analysis or currently being analyzed. The display of interface display screen especially the textual log may be conducted in two different types of modes Regular Display mode and Analyst Display mode. In Regular mode the showing listing of only detected anomalous behaviors such as suspicious or important events results for example is conducted. In Analyst Display mode the showing listing of all events occurring in the application including those related to only the execution of the application and those events that would have been forced by the mobile electronic device.

For completed test behaviors during Analyst mode for example a first image check mark is rendered to identify whether the test behavior was not present a second image X is rendered to identify that the test behavior was detected a third image A is rendered where at this point in the analysis the test behavior has not been analyzed yet and a fourth image progress bar is rendered where the test behavior is currently being analyzed. The updating of entries within textual log is synchronized with video being displayed.

Referring to an exemplary embodiment of a user interface display screen produced by the application analyzer of is shown. User interface display screen illustrates completion of the anomalous behavior analysis testing by display of a completion message and a final image or frame of video with no progress bars being present in textual log . Herein completion message is rendered that identifies i whether the test application has been successfully analyzed and 2 whether the test application is safe or unsafe . The findings for each particular test behavior represented by indicia e.g. symbols color etc. along with elapsed time of that test behavior in the video are set forth in the completed textual log .

User interface display screen provides a first object REPLAY that based upon user interaction signals the GUI logic to replay video as shown in . Based on user interaction with first object video is replayed from the start where a time bar positioned below video may be used to replay certain segments of video at selected times. Textual log is synchronized with video to illustrate status of different test behaviors in accordance with the default sequence or sequence selected by the user as illustrated in . The illustration of status may be through images highlighting text description of the test behavior e.g. bold different colors different font type etc. .

In general terms the video replay provides context for each event to explain away or confirm certain anomalous behaviors in light of what image displays screenshots may have been displayed or user interactions that have occurred. Some applications exhibit anomalies which may be viewed verified as unwanted behaviors depending on when where in the application the event occurred e.g. audio recording started when expected or at unexpected time or whether a permission is noted in a manifest . In order to provide such context the displayed images of video may capture the display output of the application software for at least a period of time window before and after an event included in the displayed textual log has occurred.

Referring back one or more displayed test behaviors in textual log are user interactive. When selected by the user the GUI logic replays video starting at the time in the anomalous behavior analysis when monitoring of the selected test behavior commenced. This start time may be obtained by extracted a time stamp associated with the first captured image or frame of video when the anomalous behavior analysis began to monitor for the selected test behavior. For example upon user interaction with a third test behavior in the sequence e.g. add delete files on storage as shown in video data commences with elapsed time of 1 25 minutes with this test behavior as represented by a blank progress bar .

Additionally display screen features a search field that enables the user to search for a particular event or test behavior at a particular point in the video replay. Also an activity graph identifies the activities e.g. number and frequency of API function calls Java events etc. during the testing period for the anomalous behavior detection analysis. The particular activities may be obtained by selecting activity graph to denote a request for deeper analysis of the findings from the anomalous behavior detection analysis.

Referring back to user interface display screen further signals the GUI logic based on user interaction e.g. selection of a second object SHOW DETAILED ANALYSIS by the user to produce a screen display with a summary of test behavior failures as set forth in . Screen display comprises metadata alerts based on test behaviors where the security risk for the test behavior may vary for different customers a listing of permissions requested during the anomalous behavior detection analysis and a scrolling log outlining the success and failures of custom defined rules similar in form to textual log for the test behaviors as shown in .

In the foregoing description the invention is described with reference to specific exemplary embodiments thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the present invention as set forth in the appended claims. The specification and drawings are accordingly to be regarded in an illustrative rather than in a restrictive sense.

