---

title: Automatic sharing of digital multimedia
abstract: Devices and methods for automatic sharing of digital multimedia include, in one embodiment, obtaining factor data affecting a decision on whether or not to enter a digital multimedia sharing mode for an event or meeting; entering the digital multimedia sharing mode based on identifying calendar entry data for the event or meeting stored in a calendar database that satisfies the factor data; storing digital photograph data produced by a camera module while in the sharing mode in a digital multimedia container designated to store digital multimedia for the event or meeting; obtaining participant data for the event or meeting from the calendar entry data; and automatically making the digital photograph data available to the one or more participants based on the participant data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09350774&OS=09350774&RS=09350774
owner: Dropbox, Inc.
number: 09350774
owner_city: San Francisco
owner_country: US
publication_date: 20131216
---
The present invention relates generally to camera equipped computing devices and more particularly to a system and method for automatic sharing of digital multimedia such as digital photograph data and digital video data captured using a camera equipped computing device.

People often take digital photographs and digital videos of events they attend. For example many people use their camera equipped computing devices e.g. camera equipped mobile phones to capture photographs of meetings they participate in sporting events they are fans at weddings they are invited to and other events they attend. Events at which digital photographs or digital videos are captured are often recorded calendared in a digital calendaring application or other event tracking computer application. For example a person may use a calendaring application on their personal computing device for tracking the dates times and locations of business meetings they are scheduled to attend.

In many cases people who capture photographs at an event want to share the captured photographs with other people who also attend the event. For example a participant in a meeting that takes digital photographs of the meeting room whiteboard at various times during the meeting may want to share the photographs of the whiteboard with the other participants at the meeting.

One possible approach for sharing digital photographs captured at an event is for the photographer to send them to the other event attendees as attachments to electronic mail messages or as attachments to text messages. This approach typically requires the photographer to send each photo as an attachment immediately after it is captured and before a next photo is captured or requires the photographer to examine all digital photographs captured during a period of time to identify particular photographs to share. For example an employee that wishes to share photographs captured of a whiteboard during a meeting that took place last week may have to sift through all photographs captured in the interim including possibly personal or other unrelated photographs to identify the photographs taken during the meeting. This approach can be a cumbersome and inefficient way to share digital photographs because it requires the photographer to remember to share each digital photo immediately after it is captured or requires the photographer to individually identify photographs to share from among a collection of photographs which may include other photographs the photographer does not want to share such as personal photographs or photographs captured before after or unrelated to the event. More generally this approach requires the photographer to manually share the captured photographs in a way that the photographer may find inconvenient and tedious.

Therefore users of digital photo capturing devices such as camera equipped mobile phones or other camera equipped computing devices would appreciate ways to more easily share digital photographs captured at events with other event attendees.

For purpose of providing clear examples where appropriate reference numerals are repeated in different figures to indicate corresponding or analogous elements. In addition in the following detailed description embodiments of the invention are described with reference to numerous specific details that may vary from implementation to implementation. The detailed description and the figures are accordingly to be regarded in an illustrative rather than a restrictive sense. Also in the following detailed description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present technology. It will be apparent however that the present technology may be practiced without these specific details. In other instances well known structures and devices are shown in in the figures in block diagram form in order to avoid unnecessarily obscuring the present technology.

The following definitions are offered for purposes of illustration not limitation in order to assist with understanding the discussion that follow.

The terms 3GP and 3GPP refer to a digital multimedia container format defined by the Third Generation Partnership Project 3GPP for 3G Universal Mobile Telecommunications System UMTS multimedia services.

The term and or refers to and encompasses any and all possible combinations of one or more of the associated listed items.

The terms event and meeting refer to a calendar event or calendar meeting involving one or more participants respectively.

The terms event location and meeting location refer to the physical location of an event or meeting respectively such as a conference room other room physical address city campus campus sub region building floor and or building sub region.

The term digital image refers to computer data that represents a two dimensional image captured by a digital camera. The computer data is typically in either a lossy digital image data format e.g. JPEG or a lossless format e.g. TIFF or RAW .

The term digital photograph data refers to computer data that represents one or more digital images captured using an optical sensor and a camera module. A single digital image is referred to herein as a digital photograph or just photograph .

The term digital video data refers to computer data that represents a series of two dimensional digital images frames or video frames to be presented in rapid succession to create the appearance of motion. The video frames may be captured using an optical sensor and a camera module. The digital video data can also include digital audio data that represents audio to be presented as an audible accompaniment to the visual presentation of the video frames. The digital audio data may be captured using a microphone and associated audio circuitry. The computer data is typically formatted according to audio and visual encoding format such as MPEG 4 or 3PG as examples.

The term JPEG stands for Joint Photographic Experts Group and is an industry standard developed to handle color digital images. JPEG is known as a lossy format as it compresses images by blending redundant image pixels to reduce the number of bits required to represent the images in a computer at the expense of image quality.

The term MPEG 4 refers to a method of defining compression of audio and visual AV digital data. MPEG 4 is designated a standard for a group of audio and video coding formats and related technology agreed upon by the ISO IEC Moving Picture Experts Group MPEG ISO IEC JTC1 SC29 WG11 under the formal standard ISO IEC 14496 Coding of audio visual objects.

The terms event participant and meeting participant and participant when being used to refer to an event participant or a meeting participant refer to a person who is an organizer or an invitee of a calendar event or calendar meeting respectively. A participant in an event or meeting may or may not be an attendee at the event or meeting. For example a participant who is an invited to a meeting but declined the meeting invitation may not be an attendee.

The term RAW refers to a proprietary lossless digital image format that allows for full post processing of in camera variables such as white balance saturation and sharpness. Digital images in RAW format generally require more computer storage space than digital images in a lossy format such as JPEG.

The terms TIFF and TIF stand for Tag Image File Format. TIFF is a lossless digital image format that results in very large digital image sizes when stored in a computer. Digital images in TIFF format are often compressed using a lossless compression technique such as LZW a lossless data compression algorithm created by Abraham Lempel Jacob Ziv and Terry Welch.

Typically when digital photographs are captured using a camera equipped computing device the captured photographs are stored in a default photograph repository at the computing device where all captured photographs are stored by default. For example the default repository may be a designated file system folder. Often each of the captured photographs are stored in the default repository as a file with a filename that indicates the capture date and time of the photograph. For example the default repository may store files named IMG0007.jpg or DSC0123 jpg.

Unfortunately use of a default repository for storing captured photographs can make it inconvenient for the user of the computing device to share particular captured photographs. More specifically if the user wants to share photographs captured during a particular period of time the user is required to examine captured photographs stored in the default repository to identify and select photographs to share. Since the default repository may comingle photographs the user wishes to share with ones the user does not want so share such identification and selection can be tedious and time consuming to the user. Further once the user has identified and selected photographs in the default repository to share the user is still required to perform manual steps to share the identified photographs with other persons. Typically these manual steps require the user a to provide user input to the computing device to invoke a function to send the selected photographs as attachments to electronic messages and b to provide additional user input to enter the addresses or identifiers of the recipients or to otherwise select the recipients to receive the electronic messages. In a worst case the user is required to repeat manual steps a and b for each selected photograph to share.

The present technology solves the tedium and inconvenience associated with current approaches for sharing captured digital multimedia by providing a system and method for automatic sharing of digital multimedia such as digital photographs and digital videos captured by a computing device equipped with a camera module. The present technology can include obtaining factor data affecting a decision on whether or not to enter a digital multimedia sharing mode for an event or meeting. The event or meeting can involve one or more participants. A digital multimedia sharing mode can be entered based on determining calendar entry data stored in a calendar database that satisfies the obtained factor data. The calendar entry data can represent the event or meeting involving the one or more participants. Digital photograph data produced by the camera module while in the digital multimedia sharing module can be stored in a digital multimedia container designated to store digital multimedia for the event or meeting. Participant data for the event or meeting can be obtained from the calendar entry data. The obtained participant data can indicate the one or more participants. The identified photograph data obtained can be automatically made available to the one or more participants based on the obtained participant data.

Because the digital photograph data is stored in a digital multimedia container designated to store digital multimedia for the event or meeting digital photograph data for the event or meeting can be stored separately from other digital multimedia data produced by the camera module such as digital multimedia data produced by the camera module when not in the digital multimedia sharing mode. Further because the digital multimedia sharing mode is entered the digital photograph data produced by the camera module while in the digital multimedia sharing mode can be automatically identified as pertaining to the event or meeting and automatically processed accordingly. For example digital photograph data identified as pertaining to a particular meeting can be automatically sent to participants associated with the meeting.

In this detailed description for purposes of provided clear examples the present technology is described in the context of digital photographs and digital photograph data captured and produced by a camera module. It should be understood however the present technology is not limited to providing automatic sharing of only digital photograph data and may be applied according to the general principles and techniques of the present technology described herein to provide automatic sharing of other types of digital multimedia data including digital photograph data digital video data digital audio data and a combinations of digital photograph data digital video data and digital audio data.

While device is a portable or human carry able there is no requirement that the present technology be embodied in a portable computing device. The present technology can also be embodied in non portable computing devices such as a desktop computer a workstation computer or other stationary computing device. More generally it should be appreciated that device is only one example of a camera equipped computing device and a camera equipped computing device in which the present technology is embodied may have more or fewer components or a different arrangement of components than as shown for device in . The various components shown in may be implemented in hardware software or a combination of both hardware and software including one or more signal processing and or application specific integrated circuits ASICs . The components may communicate over one or more communication buses or signal lines .

Further while the present technology may be embodied in a camera equipped computing device the present technology may also be embodied in a computing device that is not equipped or operatively coupled to a camera or other optical sensing device. For example the present technology may be embodied in a smart whiteboard device having a touch sensitive display and that can output or otherwise produce digital photograph data of what is written and or sketched on the smart whiteboard.

Device includes one or more optical sensors . shows an optical sensor coupled to an optical sensor controller in I O subsystem . Optical sensor may include charge coupled device CCD or complementary metal oxide semiconductor CMOS phototransistors. Optical sensor receives light from the environment projected through one or more lens and converts the light to data representing an image. In conjunction with a camera module optical sensor may capture still images or video. In some embodiments an optical sensor is located on the back of device opposite touch screen on the front of the device so that the touch screen display may be used as a viewfinder for either still and or video image acquisition. In some embodiments an optical sensor is located on the front of the device so that the user s image may be obtained for videoconferencing while the user views the other video conference participants on the touch screen display. In some embodiments the position of optical sensor can be changed by the user e.g. by rotating the lens and the sensor in the device housing so that a single optical sensor may be used along with the touch screen display for both video conferencing and still and or video image acquisition.

Memory can include high speed random access memory and can also include non volatile memory such as one or more magnetic disk storage devices flash memory devices or other non volatile solid state memory devices. Access to memory by other components of device such as CPU and peripherals interface can be controlled by memory controller .

Peripherals interface couples the input and output peripherals of device to CPU and memory . One or more processors CPUs run or execute various software programs and or sets of instructions stored in memory to perform various functions for device and to process data. In some embodiments peripherals interface CPU and memory controller are implemented on a single chip such as chip . In other embodiments peripherals interface CPU and memory controller are implemented on separate chips.

RF radio frequency circuitry receives and sends RF signals also called electromagnetic signals. RF circuitry converts electrical signals to from electromagnetic signals and communicates with communications networks and other communications devices via the electromagnetic signals. RF circuitry may include well known circuitry for performing these functions including but not limited to an antenna system an RF transceiver one or more amplifiers a tuner one or more oscillators a digital signal processor a CODEC chipset a subscriber identity module SIM card memory and so forth. RF circuitry may communicate with networks such as the Internet an intranet and or a wireless network such as a cellular telephone network a wireless local area network LAN and or a metropolitan area network MAN and other devices by wireless communication. The wireless communication may use any of a plurality of communications standards protocols and technologies including but not limited to Global System for Mobile Communications GSM Enhanced Data GSM Environment EDGE high speed downlink packet access HSDPA wideband code division multiple access W CDMA code division multiple access CDMA time division multiple access TDMA BLUETOOTH Wireless Fidelity Wi Fi e.g. IEEE 802.11a IEEE 802.11b IEEE 802.11g and or IEEE 802.11n voice over Internet Protocol VoIP Wi MAX a protocol for email instant messaging and or Short Message Service SMS or any other suitable communication protocol including communication protocols not yet developed as of the filing date of this document.

Audio circuitry speaker and microphone provide an audio interface between a user and device. Audio circuitry receives audio data from peripherals interface converts the audio data to an electrical signal and transmits the electrical signal to speaker . Speaker converts the electrical signal to human audible sound waves. Audio circuitry also receives electrical signals converted by microphone from sound waves. Audio circuitry converts the electrical signal to audio data and transmits the audio data to peripherals interface for processing. Audio data may be retrieved from and or transmitted to memory and or RF circuitry by peripherals interface . In some embodiments audio circuitry also includes a headset jack not shown . The headset jack provides an interface between audio circuitry and removable audio input output peripherals such as output only headphones or a headset with both output e.g. a headphone for one or both ears and input e.g. a microphone .

I O subsystem couples input output peripherals on device such as a touch sensitive display and other input control devices to peripherals interface . I O subsystem may include display controller and one or more input controllers for other input or control devices . One or more input controllers receive send electrical signals from to other input or control devices . Other input control devices may include physical buttons e.g. push buttons rocker buttons etc. dials slider switches joysticks click wheels and so forth. In some embodiments input controller s are coupled to any or none of the following a keyboard infrared port USB port and a pointer device such as a mouse. One or more buttons may include an up down button for volume control of speaker and or microphone . One or more buttons may include a push button. A quick press of the push button may disengage a lock of touch screen or begin a process that uses gestures on the touch screen to unlock the device. A longer press of push button may turn power to device on or off. The user may be able to customize a functionality of one or more of the buttons. Touch screen is used to implement virtual or soft buttons and one or more soft keyboards.

Touch screen provides an input interface and an output interface between the device and a user. The display controller receives and or sends electrical signals from to the touch screen . The touch screen displays visual output to the user. The visual output may include graphics text icons video and any combination thereof collectively termed graphics . In some embodiments some or all of the visual output may correspond to user interface objects further details of which are described below.

Touch screen has a touch sensitive surface sensor or set of sensors that accept input from the user based on haptic and or tactile contact. Touch screen and display controller along with any associated modules and or sets of instructions in memory detect contact and any movement or breaking of the contact on touch screen and converts the detected contact into interaction with user interface objects e.g. one or more soft keys icons web pages or images that are displayed on the touch screen. In an exemplary embodiment a point of contact between touch screen and the user corresponds to a finger of the user.

Touch screen may use LCD liquid crystal display technology or LPD light emitting polymer display technology although other display technologies may be used in other embodiments. Touch screen and display controller may detect contact and any movement or breaking thereof using any of a plurality of touch sensing technologies now known or later developed including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with touch screen. The user may make contact with touch screen using any suitable object or appendage such as a stylus a finger and so forth. In some embodiments a user interface displayed on touch screen is designed to work primarily with finger based contacts and gestures which are much less precise than stylus based input due to the larger area of contact of a finger on the touch screen. In some embodiments the device translates the rough finger based input into a precise pointer cursor position or command for performing the actions desired by the user. In some embodiments in addition to or instead of touch screen device may include a touchpad not shown for activating or deactivating particular functions. In some embodiments the touchpad is a touch sensitive area of the device that unlike the touch screen does not display visual output. The touchpad may be a touch sensitive surface that is separate from touch screen or an extension of the touch sensitive surface formed by the touch screen.

Device also includes a power system for powering the various components. Power system may include a power management system one or more power sources e.g. battery alternating current AC a recharging system a power failure detection circuit a power converter or inverter a power status indicator e.g. a light emitting diode LED and any other components associated with the generation management and distribution of power in portable devices.

Device may also include one or more proximity sensors . shows proximity sensor coupled to peripherals interface . Alternately proximity sensor may be coupled to input controller in I O subsystem . In some embodiments proximity sensor turns off and disables the touch screen when the multifunction device is placed near the user s ear e.g. when the user is making a phone call . In some embodiments the proximity sensor keeps the screen off when the device is in the user s pocket purse or other dark area to prevent unnecessary battery drainage when the device is a locked state.

Device may also include one or more accelerometers . shows an accelerometer coupled to peripherals interface . Alternately the accelerometer may be coupled to input controller in the I O subsystem . In some embodiments information is displayed on touch screen display in a portrait view or a landscape view based on an analysis of data received from one or more accelerometers .

In some embodiments the software components stored in memory may include an operating system a communication module or set of instructions a contact motion module or set of instructions a graphics module or set of instructions a text input module or set of instructions a location module or set of instructions a location database a camera module or set of instructions a calendar module or set of instructions a calendar database or set of instructions and a digital multimedia sharing module or set of instructions .

The operating system e.g. APPLE IOS WINDOWS PHONE ANDROID PALM WEBOS SYMBIAN WINDOWS MOBILE BLACKBERRY OS or other operating system includes various software components and or drivers for controlling and managing general system tasks e.g. memory management storage device control power management etc. and facilitates communication between various hardware and software components.

Communication module facilitates communication with other devices over one or more external ports and also includes various software components for handling data received by RF circuitry and or external port . External port e.g. Universal Serial Bus USB FIREWIRE etc. is adapted for coupling directly to other devices or indirectly over a network e.g. the Internet wireless LAN etc. .

Contact motion module may detect contact with touch screen in conjunction with display controller and other touch sensitive devices e.g. a touchpad or click wheel . Contact motion module includes various software components for performing various operations related to detection of contact such as determining if contact has occurred determining if there is movement of the contact and tracking the movement across touch screen and determining if the contact has been broken i.e. if the contact has ceased . Determining movement of the point of contact may include determining speed magnitude velocity magnitude and direction and or an acceleration a change in magnitude and or direction of the point of contact. These operations may be applied to single contacts e.g. one finger contacts or to multiple simultaneous contacts e.g. multitouch multiple finger contacts . In some embodiments contact motion module and display controller also detects contact on a touchpad. In some embodiments contact motion module and controller detects contact on a click wheel.

Graphics module includes various known software components for rendering and displaying graphics on touch screen including components for changing the intensity of graphics that are displayed. As used herein the term graphics includes any object that can be displayed to a user including without limitation text web pages icons such as user interface objects including soft keys digital images videos animations and the like.

Text input module which may be a component of graphics module provides soft keyboards for entering text in various applications e.g. a contacts list application an e mail application an instant messaging application a blogging application a web browser application and any other application that needs text input .

Location module determines the location of the device and provides this information for use in various applications e.g. to camera module as picture video metadata . For example location module can be a geographical positioning system GPS that receives signals from Earth orbiting satellites to determine current geographic position of device . Alternatively location module can be a positioning system that communicates with a network communications system or any other system for determining the physical location or position of device .

Location database may also be stored in memory . Location database can associate location information with geographic coordinates. Geographic coordinates obtained from location module can be used as lookup keys to the location database to obtain location information associated with the geographic coordinates. The location information may include but is not limited to maps or addresses or any other information useful to associate with geographic coordinates. Lookups in location database may not require an exact match between geographic coordinates provided as a key and geographical coordinates in location database associated with location information. Instead it may be possible to obtain location information for given coordinates from location database by determining the geographic coordinates or set of coordinates in location database that are geographically near or nearest the given coordinates.

Camera module may be used to capture still digital images or video including a digital video stream and store them in memory . The location in memory where captured digital photograph data and digital video data is stored by camera module may be controlled by sharing module through an application programming interface API or other messaging interface offered by camera module and or operating system .

Calendar module can include functionality providing typical calendaring functionality such as storing event meeting information presenting event meeting information sending and or receiving event meeting invitations accepting and or declining event meeting invitations and or sending notification of acceptance declination.

Calendar database which may be accessed by calendar module and perhaps by other modules such as sharing module through an application programming interface stores information e.g. metadata concerning various types of calendars as well as data e.g. event data also called meeting data event entry data calendar data calendar entry data calendar event data or calendar meeting data for various calendars. An event entry in calendar database includes information for an event sometimes called a meeting a calendar event or a calendar meeting. Among other data an event entry may include some of or all of the following data for a calendar meeting event 

In some embodiments a separate calendar database is maintained for each of multiple users of device while in other embodiments calendar database records events for multiple users.

Operating system calendar module and or calendar database can provide access to a users calendar entries stored in calendar database to another module such as sharing module . Such access can be provided through an application programming interface API that allows other modules e.g. sharing module to query calendar database and or receive notification of calendar events. The API may allow other modules to retrieve query a user s existing calendar entries adding setting alarms to alert the other modules of upcoming events receive alerts alarms for upcoming events and detect changes to calendar database .

Digital multimedia sharing module can be operable upon execution by CPU to obtain factor data affecting a decision on whether or not to enter a digital multimedia sharing mode for an event or meeting to enter a digital multimedia sharing mode based on identifying calendar entry data for the event or meeting stored in calendar database that satisfies the factor data to store digital photograph data produced by camera module while in the digital multimedia sharing mode in a digital multimedia container designated to store digital multimedia for the event or meeting to obtain participant data for the event or meeting from the calendar entry data and to automatically make the obtained digital photograph data available to one or more participants of the event or meeting based on the obtained participant data.

Each of the above identified modules and applications correspond to a set of instructions for performing one or more functions described above. The modules i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. For example camera module calendar module and sharing module may be combined into a single module. In some embodiments memory stores a subset of the modules and data structure identified above. Further memory may store additional modules and data structures not described above. In some embodiments some or all of a module is implemented by operating system . For example some or all of the functionality described above as provided by communication module contact motion module graphics module text input module location module camera module and or calendar module may instead be provided by operating system .

At block one or more digital multimedia sharing mode entering factors affecting a decision on whether or not to enter a digital multimedia sharing mode for an event or meeting are determined. In general the factors may be used to determine based on calendar entry data for the event or meeting whether the event or meeting is currently taking place or is about to take place whether the camera equipped computing device is at or near the event location or meeting location and whether the user of the camera equipped computing device is an attendee at the event or meeting. Determining a factor can involve the camera equipped computing device obtaining data sometimes referred to herein as factor data representing a circumstance fact or influence that contributes to the decision to enter or not enter a digital multimedia sharing mode for the event or meeting. Obtaining factor data can include the camera equipped computing device determining or detecting the factor data.

One example of possible factor data is current date and time data that may be used to determine based on the calendar entry data for the event or meeting whether the event or meeting is currently taking place or is about to take place. In some embodiments the current date and time data is obtained or determined from the operating system of the camera equipped computing device. For example the operating system may offer a system call interface that the sharing module can invoke or call to obtain or determine the current date and time data. In another embodiments the current date and time data is determined from a network accessible time service or other network service or server capable of providing the current date and time data in response to a network request. In some embodiments the current date and time data indicates all of the following information or a subset or superset thereof 

Another example of possible factor data is current physical location data that may be used to determine based on the calendar entry data for the event or meeting whether the camera equipped computing device is at or near the event location or meeting location. In some embodiments current physical location data is obtained or determined from a physical location module of the camera equipped computing device such as for example a GPS module. In some embodiments the physical location data indicates the following information about the physical location of the camera equipped computing device or a subset or superset thereof 

Yet another example of possible factor data is nearby user device data that may be used to determine based on the calendar entry data for the event or meeting whether the user of the camera equipped computing device is an attendee at the event or meeting. In particular if the devices of other users that are also participants in the event or meeting according to the calendar entry data are nearby the camera equipped computing device of the user then it may be determined that there is a greater probability than otherwise that the user of the camera equipped computing device is an attendee at the event or meeting based on the assumption that the participants will be near each other just before during just after the time of the event or meeting.

In some embodiments nearby devices are detected through interaction with an online or network location service whereby devices periodically communicate physical location information to the location service. From this communicated information the location service can determine devices that are near each other. A device such as the camera equipped computing device that communications physical location information to the location service can query the service to determine other devices that are physically near the querying device e.g. within a specified distance . The physical location information communicated by the devices to the location service can be any information that the location service can use to determine the physical locations of the devices. For example the communicated physical location information may be GPS coordinates. Alternatively the location service may determine the physical location of a device using the service through a triangulation technique such as one used by a Wi Fi positioning system. The location service may also provide the identities of the current logged on users of the nearby device in response to the query if such identify information has been authorized to be shared by the logged on users.

In some embodiments nearby devices are detected without use of an intermediate online service or server. For example nearby devices can detect one another through an exchange of information using a short range radio frequency RF technology such as BLUETOOTH. In this case the nearby devices may not detect their own physical location.

Factor data may be obtained by the camera equipped computing device at a variety of different times. In general factor data may be obtained anytime a decision is needed on whether or not to enter a digital multimedia sharing mode for an event or meeting. In some embodiments factor data is obtained at all of the following times or a subset or superset thereof 

The obtained factor data is not limited to any particular type of factor data or limited to the types of factor data described above. For example factor data may indicate whether the camera equipped computing device has recently changed location determined either by a positioning system e.g. a GPS system or through a device sensor e.g. an accelerometer or altimeter that detects device motion. The recent change in location can be indicative of the user of the camera equipped computing device carrying the device into the conference room or area whether the event or meeting is taking place. As another example factor data obtained from an RF beacon e.g. a wireless access point in a conference room or in a particular area can indicate that the camera equipped computing device has entered the conference room or area.

At block calendar entry data for the event or meeting that satisfies the factor data is identified. Calendar entry data for the event or meeting may be considered to satisfy the factor data if the calendar entry data matches or substantially matches the factor data for a particular mode entering factor a particular combination of mode entering factors or a threshold number of mode entering factors. Calendar entry data may be considered to substantially match the factor data for a mode entering factor if the calendar entry data is within a threshold amount of the factor data. For example calendar entry data specifying that the event or meeting is scheduled to start at 11 00 AM on a particular day may be considered to substantially match current date and time data specifying a time of 10 52 AM on the particular day because the current date and time is within 10 minutes of the scheduled start time. Similarly calendar entry data specifying that that the event or meeting is to take place at a particular event or meeting location may be considered to substantially match current physical location data indicating a physical location within 100 feet of the particular event or meeting location.

In some embodiments calendar entry data for an event or meeting is considered to satisfy the factor data if one some or all of the following conditions are met 

The calendar entry data may be identified by querying a calendar database. For example the calendar database may be queried for calendar entries that match or that otherwise might satisfy the factor data. If multiple such calendar entries are identified then a best matching calendar entry may be identified as the one to enter or possibly enter a digital multimedia sharing mode for. For example calendar entry data for two overlapping meetings one that is about to end and one that has just started may be returned in response to the query. The calendar entry data for one of the two meetings may be identified in favor of the other. For example calendar entry data for the meeting that just started may be identified in favor of the calendar entry data for the meeting that is about to end or vice versa. Alternatively the user of the camera equipped computing device may be prompted through a graphical user interface which of the multiple calendar entries a digital multimedia sharing mode should be entered for.

In some embodiments if multiple possibly conflicting calendar entries satisfy the factor data submitted in the query to the calendar database one of the calendar entries can be selected based on a heuristic that takes into account the proximity of attendees to the event or meeting locations of the multiple calendar entries. For example the calendar entry with the event location or meeting location that the camera equipped computing device is physically closest to can be selected.

Calendar entry data may also be identified in response to receiving an alert or an alarm. For example the sharing module may register with the calendar module to receive a reminder alert or alarm a specified amount of time e.g. 5 10 15 20 or 30 minutes before an event or meeting is scheduled to start according to calendar entry data. The alert or alarm may be associated with a message containing calendar enter data or data for obtaining the calendar entry data from a calendar database.

In response to receiving the alert or alarm a digital multimedia sharing mode for the event or meeting can be entered automatically at the scheduled start time of the event or meeting or automatically entered at a predetermined amount of time e.g. 5 minutes before the event or meeting is scheduled to start. In some embodiments the user of the camera equipped computing device is prompted by the sharing module through a graphical user interface presented on a display of the device to confirm entrance into the digital multimedia sharing mode for the event or meeting. Such prompting can occur at the scheduled start time of the event or meeting or at a predetermined amount of time e.g. 5 minutes before the event or meeting is scheduled to start.

In the case a reminder alert or alarm is received for an event or meeting factor data may or may not be obtained as in step . That is a decision to enter a digital multimedia sharing mode for an event or meeting may be made based on calendar entry data obtained for an event or meeting and not based on factor data. However even in the case a reminder alert or alarm is received for an event or meeting factor data may be obtained to corroborate the decision to enter a digital multimedia sharing mode for an event or meeting. For example the sharing module may perform the following sequence of events 

At block a decision is made whether to enter a digital multimedia sharing mode the event or meeting. As discussed above this decision can be based on factor data obtained at block and calendar entry data identified at block . Alternatively this decision can be based on calendar entry data identified at block and not based on factor data obtained at block in which case the operations of block need not be performed. Also as discussed above in the case where the decision is based on both factor data and calendar entry data the decision to enter a digital multimedia sharing mode for the event or meeting can be made based on how many mode entering factor satisfy match or substantially match the calendar entry data or based on a particular mode entering factor or particular combination of mode entering factors satisfying matching or substantially matching the calendar entry data. Where the decision is based on calendar entry data and not on factor data the decision can be made at or after an alert or alarm is received about an upcoming event or meeting start time. In this case a timer can be set to automatically enter a digital multimedia sharing mode at or just before or just after the scheduled start time of the event or meeting as indicated by the calendar entry data. The set timer can be removed if a subsequent alarm or alert is received indicated that the event or meeting has been canceled. In one alternative when a timer is set to enter a digital multimedia sharing mode for the event or meeting based on a scheduled start time indicated by calendar entry data when the timer is trigged factor data is obtained as in block to corroborate or refute the decision to enter the digital multimedia sharing mode.

If a decision is made to enter a digital multimedia sharing mode for the event or meeting then the process proceeds to block discussed below. Otherwise the process proceeds to block where digital multimedia produced by the camera module of the camera equipped computing device while not in the digital multimedia sharing mode is not specially processed for the event or meeting represented by the calendar entry data identified at block . The process may then start again at some later time at block or block .

If the decision at block was to enter a digital multimedia sharing mode for the event or meeting represented by the calendar entry data identified at block then any digital multimedia produced by the camera module of the camera equipped computing device is stored in a digital multimedia container designated to store digital multimedia for the event or meeting. In this way digital multimedia produced by the camera module while in the digital multimedia sharing mode for the event or meeting can be segregated at the camera equipped computing device from other digital multimedia produced by the camera module while not in the digital multimedia sharing mode for the event or meeting.

The designated digital multimedia container can be a folder in an operating system file system. Alternatively the designated digital multimedia container can be a compressed file archive file in an operating system file system such as a ZIP file archive. More generally the designated digital multimedia container can be any type of data container suitable for storing digital multimedia data. For example the designated digital multimedia container can be a logical data container e.g. a table a row a column an object in a database e.g. a relational database an object database a flat file database .

The designated digital multimedia container can be created specially to store digital multimedia for the event or meeting. When creating the digital multimedia container the container may be given a name that indicates the event or meeting it is designated to store digital multimedia for. For example the name may be based on tile or description information about the event or meeting from the calendar entry data. As an alternative to creating a new digital multimedia container an existing digital multimedia container can be designated to store digital multimedia for the event or meeting. For example if the calendar entry data indicates that the event or meeting is a recurring one and that the current occurrence is the second or subsequent occurrence of the event or meeting then an existing digital multimedia container created for the first occurrence of the event or meeting may be designated to store digital multimedia produced by the camera module for the second and subsequent occurrences of the event or meeting. In this way a single digital multimedia container can be designated to store all digital multimedia produced for all occurrences of the event or meeting.

Storing digital multimedia produced by the camera module in the container designated to store digital multimedia for the event or meeting can include identifying digital multimedia produced by the camera module while in the digital multimedia sharing mode for the event or meeting as pertaining to the event or meeting. Such identification can occur in at least three different ways which are not mutually exclusive of each other.

In a first way the sharing module registers with the camera module to be notified when the camera module captures digital multimedia e.g. digital photograph data . The sharing module can then identify all digital multimedia for which it receives notification from the camera module while in the digital multimedia sharing mode for the event or meeting as digital multimedia pertaining to the event or meeting. All such identified digital multimedia can then be stored in the designated container.

In a second way the sharing module configures the camera module to store all digital multimedia in the designated container. For example when the sharing module enters the digital multimedia sharing mode for the event or meeting the sharing module configures the camera module with the designated container such that the camera module stores all subsequent digital multimedia data it produces in the designated container. Such configuration may be accomplished by the sharing module using an application programming interface offered by the camera module for example. When the sharing module leaves the sharing mode the sharing module can then configure the camera module again to no longer store captured digital multimedia data in the designated container. In this way only digital multimedia produced by the camera module while the sharing module is in the sharing mode is stored in the designated container.

In a third way the sharing module examines the embedded metadata of digital multimedia produced by the camera module for digital multimedia having a captured data and time that is on or after the sharing module enters the sharing mode for the event or meeting and on or before the sharing module exist the sharing mode for the event or meeting. All such digital multimedia data can be moved by the sharing module from the default location where the camera module stores captured digital multimedia data into the designated container. The embedded metadata can be for example exchangeable image file format Exif data inserted by the camera module into the digital multimedia data it produces.

At block participant data for the event or meeting is obtained from the calendar entry data identified at block . This step may be performed any time after step including for example before steps and or . At a minimum the obtained participant data indicate one or more participants in the event or meeting. Such indication may be made in a number of different ways. In one way a participant in an event or meeting is indicated by the participant s name the participant s title the participant s company business organization or affiliation the participant s e mail address the participant s phone number and or other information that uniquely identifies the participant among the participants in the event or meeting. Information identifying a participant obtained from the calendar entry data may be used to identifying other information identifying the participant. For example an e mail address obtained from calendar entry data may be used to lookup other identifiers associated with that e mail address including for example other e mail address phone numbers user identifiers. Such lookup may be made in another database at the camera equipped computing device such as a contacts database or by submitting a network request to a network service.

At block the digital multimedia data stored at block is automatically made available to one or more participants in the event or meeting based on the participant data obtained at block . The digital multimedia data can be automatically made available to all participants in the event or meeting or just a subset of them. For example the digital multimedia data can be made available to all participants to all participants except the organizer of the event or meeting to all participants except the participant that is the user of the camera equipped computing device to all attending participants to all attending participants except the organizer of the event or meeting or to all attending participants except the participant that is the user of the camera equipped computing device. Whether a participant is an attending participant can be determined from the participant data which may indicate whether the participant accepted an invitation to the event or meeting from the organizer i.e. is an attending participant or whether the participant declined the invitation i.e. is not an attending participant .

While in some embodiments the digital multimedia data is made available only to participants in the event or meeting the digital multimedia data is made available to other persons in other embodiments in addition to or instead of participants in the event or meeting. For example the digital multimedia data can be made available to a team manager or supervisor.

The digital multimedia data can be automatically made available as or soon after the digital multimedia data is stored at block . Thus participants in the event or meeting may have access to the digital multimedia data during the event or meeting. Alternatively the digital multimedia data can be automatically made available after exiting the digital multimedia sharing mode for the event or meeting. When the digital multimedia data is automatically made available may be according to user preference or configuration information associated with the sharing module.

The digital multimedia data can be automatically made available in a number of different ways. In one way the sharing module uses an e mail account of the user of the camera equipped computing device to send the digital multimedia data to the participant s as one or more attachments to one or more e mail messages. For example the user may configure the sharing module to use a GMAIL YAHOO or other Simple Mail Transfer Protocol SMTP enabled e mail account of the user to send the e mail messages. In another way the sharing module uses a Simple Message Service SMS or a Multimedia Messaging Service MMS account of the user to send the digital multimedia data to the participant s as one or more attachment s to one or more text messages. More generally the digital multimedia data can be automatically made available in any way that provides a participant electronic access to the digital multimedia data. For example the digital multimedia data can be uploaded to a web server where it can access by a participant using a web browser. As another example the digital multimedia data can be sent to participants via a protocol in the Internet protocol suite such as the HyperText Transfer Protocol HTTP the Transmission Control Protocol over Internet Protocol TCP IP or the Simple Mail Transfer Protocol SMTP . As yet another example the digital multimedia data can be made available to participants through an application executed on the camera equipped computing device.

In one embodiment the digital multimedia data is automatically shared at block with participant s through a content item management server. The digital multimedia data can be shared through the content item management server in at least two different ways which are not mutually exclusive of each other even with respect to same participant.

In a first way the digital multimedia data is uploaded by the camera equipped computing device to the content item management server where it is stored in a server side container. The server side container may be a folder or a named collection of data blocks maintained and managed by the server. The camera equipped computing device then makes a network request of the server to generate a link to the server side container via an network accessible application programming interface API offered by the server. In one embodiment the link is in the form of a Uniform Resource Locator URL that can be shared with the participants for example in an e mail or text message. In response to receiving the network request to generate the link the server generates a unique link to the server side container and sends it to the camera equipped computing device in response to the request. In one embodiment the link is generated by the server in a manner consistent with the techniques described in related U.S. patent application Ser. No. 13 217 944 entitled File Sharing via Link Generation filed Aug. 25 2011 the entire contents of which is hereby incorporated by reference. Upon receiving the unique link the camera equipped computing can automatically make the digital multimedia data uploaded to the server available to the participants by making the unique link available to the participants for example by sending the unique link to the participant s in one or more e mail message and or one or more text messages. The participant s may use the unique link to download the digital multimedia data from the server and or access the digital media multimedia data at the server. For example the participant s may submit the unique link to the server through a web browser and the server in response to receiving the unique link may return web pages that allow the participants to view the digital multimedia data in the web browser and or download the digital multimedia data from the server.

While in some embodiments the unique link is sent to participants after the digital multimedia data has been uploaded to the server the unique link is sent to participants before or during uploading the digital multimedia data to the server. In these other embodiments the unique link may be sent any time after the server side container has been created and before all of the digital multimedia data has been uploaded. If all of the digital multimedia data has yet to be uploaded to the server when a participant submits the unique link to the server the unique link may be used to access and or download the digital multimedia data that has been uploaded and stored in the server side container so far.

While in some embodiments a unique link such as a unique URL is sent to participants a unique identifier of the server side container is sent to participants in other embodiments. The participants receiving the unique identifier may submit the unique identifier to the server for example through a web interface or through an application to access and or download the uploaded digital multimedia data.

In a second way the digital multimedia data is uploaded by the camera equipped computing device to the content item management server where it is stored in a server side container similar to the first way. However instead of sharing the uploaded digital multimedia data with the participants via a unique link the server side container in which the digital multimedia data is stored on the server side is shared with the participant s . To do this the camera equipped computing device may send a network request to the server to share the server side container with identified participant s . To accomplish this it may be required that the user of the camera equipped computing device and the identified participant s have accounts with the server so that the identified participant s can be authenticated by the server. While is some embodiments the user and identified participant s have accounts with the server the user and or identifier participants s do not have accounts with the server in other embodiments. In these other embodiments sharing of the server side container can be accomplished so long as the user and or identified participant s have a verifiable identity such as for example a variable phone number or e mail address. Sharing the server side container in which the digital multimedia data is stored with the identified participant s can cause a synchronization application on the devices of the identified participant s to download the server side container and its contents including the digital multimedia data to the devices.

Turning now to it is a block diagram illustrating an exemplary distributed computer system for automatically sharing digital multimedia data via a content item management server according to certain embodiments of the invention. Computer system includes a plurality of clients . Users of clients also herein called client devices or client systems are participants in an event or meeting. One of the participants sharing participant P is a user of camera equipped computing device . The other participants A B . . . N use a client device . Client devices can be one of a number of different types of computing devices including but not limited to an Internet kiosk a personal digital assistant a cell phone a gaming device a desktop computer a laptop computer a handheld computer or a tablet computer. Client devices and camera equipped device are coupled to network which can be any of a number of networks e.g. Internet intranet local area network wide area network wireless network wired network optical network or a combination of such networks . More generally clients and camera equipped device and content item management servers are coupled to each other via one or more communication networks .

At least camera equipped computing device but optionally also one or more client devices executes a synchronization application . The synchronization application on the camera equipped computing device is at least configured to upload the digital multimedia data to be shared to a respective management server . The synchronization application on other client devices is at least configured to download the digital multimedia data from a respective management server .

While system may have a single content item management server in other embodiments system has multiple content item management servers . For example multiple content item management servers A and B may be hosted by different service providers such as providers A and B respectively. In some embodiments the providers are internet service providers ISPs providing a content item management service. Alternatively some or all of the providers may be dedicated content item management service providers. When system includes multiple management servers the management servers may be coupled together directly or by a local area network LAN or via network or by another type of network.

Management server s may offer a network accessible interface for requesting generation of a unique link for digital multimedia data uploaded to a management server . For example after synchronization application on camera equipped computing device uploads the digital multimedia data to a management server the sharing module may send a network request to the network accessible interface of a management server to generate a unique link for the uploaded digital multimedia data. In response to receiving the request the management server may generate the unique link and send it to the sharing module of the camera equipped computing device . Upon receiving the generated unique link the sharing module can share it with one or more other participants A B . . . N in the event or meeting by sending the unique link to the other participants A B . . . N in one or more e mail messages one or more text messages or otherwise automatically making the unique link available to one the other participants A B . . . N. The other participants A B . . . N may use the unique link to download the digital multimedia data from a respective management server and or access the digital media multimedia data at a respective management server . For example a participant may submit the unique link to a respective management server through a web browser application executing on a respective client device . The respective management server server in response to receiving the unique link may return web pages that allow the participant to view the digital multimedia data in the web browser and or download the digital multimedia data to the respective client device from a management server .

Management server s may also offer a network accessible interface for requesting that the server side container where the uploaded digital multimedia data is stored be shared with other participants . For this it may be required that the other participants with which the server side container is shared have accounts with the content item management service and have the synchronization application installed on their respective client devices . In this example participant B does not have an account with the content item management service and does not have the synchronization application installed on respective client device B. Despite this the digital multimedia data may still be shared with participant B through the content item management service via a unique link as described previously. When a management server receives a request from the camera equipped computing device to share the server side container with other designated participants such as for example participant A a management server signals the synchronization application on the participant s client device to download the server side container including the contained uploaded digital multimedia data to the participant s client device . In this way digital multimedia data uploaded by the camera equipped computing device to a management server can be automatically shared with other participants that also have accounts with the content item management service.

The foregoing description for purpose of explanation has been described with reference to specific embodiments. However the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications to thereby enable other skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the requirements of the particular implementation at hand or the particular use contemplated.

