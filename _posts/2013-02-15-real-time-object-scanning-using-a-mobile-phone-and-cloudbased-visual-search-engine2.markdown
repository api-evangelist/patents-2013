---

title: Real time object scanning using a mobile phone and cloud-based visual search engine
abstract: A system for tagging an object comprises and interface and a processor. The interface is configured to receive an image. The processor is configured to determine a key frame. Determining a key frame comprises determining that the image is stable. The processor is configured to determine a tag for an item in the key frame.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633272&OS=09633272&RS=09633272
owner: Yahoo! Inc.
number: 09633272
owner_city: Sunnyvale
owner_country: US
publication_date: 20130215
---
Mobile phones and smart mobile phones are becoming extremely common. Many people now carry everywhere a device that includes a powerful processor a high resolution video camera and a connection to the Internet. One possible practical application of these devices is image recognition. When a smart phone user is presented with an item that he desires to know more about he can photograph the item and use image recognition software to identify it. Depending on his preferences he may simply be given the name of the object or automatically be connected with search results regarding the object shopping information regarding the object or any other appropriate information. A particularly useful application of this technology is for visually impaired people enabling them to identify objects they are not able to identify themselves without assistance. Frequently when a user takes a photo with a smart phone for the purposes of object identification the user does not take the photo that best enables the object to be identified for instance the image can be blurry or from an angle that makes recognition difficult. This is particularly a problem when assisting blind users as they cannot see the photo image themselves to verify its quality.

The invention can be implemented in numerous ways including as a process an apparatus a system a composition of matter a computer program product embodied on a computer readable storage medium and or a processor such as a processor configured to execute instructions stored on and or provided by a memory coupled to the processor. In this specification these implementations or any other form that the invention may take may be referred to as techniques. In general the order of the steps of disclosed processes may be altered within the scope of the invention. Unless stated otherwise a component such as a processor or a memory described as being configured to perform a task may be implemented as a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. As used herein the term processor refers to one or more devices circuits and or processing cores configured to process data such as computer program instructions.

A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.

Real time object scanning using a mobile phone and cloud based visual search engine is disclosed. A system for tagging an object comprises a processor configured to determine a key frame wherein determining a key frame comprises determining if an image is stable and in the event that the image is stable determining if the image has been stable for a predetermined duration and in the event that the image has been stable for the predetermined duration identifying the current frame as a key frame and determine a tag for an item in the key frame. A memory is coupled to the processor and is configured to provide the processor with instructions. An interface is configured to receive an image e.g. for processing by the processor .

In some embodiments real time object identification is performed using a mobile phone including a camera and a processor. A mobile phone user performs real time object identification by initiating the object identification process e.g. by launching an app and holding their phone steady so the camera captures a steady image of the object of interest. Rather than the user making an indication e.g. pushing a button manually triggering voice triggering etc. that the image is of the desired object the app determines that the image is steady e.g. features of interest are not blurry when the image has been steady for a predetermined duration and when the visual content is sufficiently different from the previous key frames the image is captured and processed. By analyzing each frame of the image stream the app is able to ensure that a high quality image is received for image processing e.g. in focus within the frame etc. . If the app requires the user to push a button to indicate that an image should be captured it is forced to rely on the user to take a good quality image. This is particularly burdensome when the app is used for assisting a blind user who will likely have difficulty taking a high quality image.

In some embodiments an image is steady in the event that an object of interest is within a camera view for a predetermined time. In some embodiments a steady image refers to an image from the perspective of a device with a camera where the image or rather stream of images includes the same subject matter within the view of the camera. In some embodiments the image is received via an interface to be processed. In some embodiments the image or stream of images is steady or within the view of the camera for a predetermined period of time. In some embodiments the predetermined period of time is indicative of a length of time to express the intent of interest in the objects in the view of the camera.

In some embodiments when the object identification process is initiated the processor receives an image stream from the camera. Each image frame is analyzed until a key frame is detected. A key frame comprises an image frame where the image is steady and has been held steady over a predetermined duration and where the visual content is different from the previous key frames. When a key frame is detected the image is provided to object identification software for identifying an object in the image. In some embodiments the object is identified by an automated object identification process. In some embodiments the object is identified by a human object identifier. In some embodiments it is determined whether the object can be identified by an automated object identification process and if not the object is identified by a human object identifier.

In some embodiments the system comprises a processor for image recognition which performs the expensive computation of analyzing a new object and a key frame processor which performs the less expensive identification of frames that are susceptible frames to having a new object. If the frame is identified as being susceptible by the key frame processor the frame is sent on to the image recognition processor.

In the example shown computer vision engines comprises a set of one or more computer vision engines for automatically identifying objects in images received by image tagging system . In various embodiments the computer vision engines use an instance recognition module a classification module an optical character recognition module a face identification module a barcode recognition module a clock recognition module a color detection module or any other appropriate module. In some embodiments each different module utilized by computer vision engines is utilized by a separate computer vision engine. In some embodiments computer vision engines comprise more than one computer vision engine and the separate computer vision engines execute their modules in parallel. In some embodiments computer vision engines utilize information stored in object databases as part of executing computer vision modules. In some embodiments an instance recognition module utilizes object databases as its instance library. In some embodiments a classification module utilizes object databases as its class representation library.

In the example shown human computation module s comprises one or more human computation modules for image recognition. A human computation module for image recognition comprises one or more humans each capable of recognizing images and providing tags for the images. In some embodiments a human computation module relays any tags provided by its humans directly to results processor . In some embodiments a human computation module requests tags from human taggers. In some embodiments a human computation module receives a request for tags from a results processor. In some embodiments the human computation module provides various processing functionality prior to providing the tags to results processor . In various embodiments processing functionality includes determining a status of a human tagger determining a validity of a tag based on a status of a human tagger e.g. valid tag is determined in the event that the tag is received from a tagger indicated as an expert or reliable tagger confirming a validity of a tag based on receipt from multiple human taggers e.g. valid tag is determined in the event that the same tag is received from a majority of taggers or a minimum number of taggers or both marking a tag with a validity status based on a status of a human tagger or any other appropriate processing functionality. In some embodiments human computation module s comprises more than one human computation module. In various embodiments human taggers are divided into separate human computation modules based on specialty experience age location average time to provide results tagger status or any other appropriate tagger classification.

Results processor comprises a results processor for receiving and processing tags from computer vision engines and human computation module s . In the example shown results processor ranks the received tags according to a predetermined ranking algorithm and provides the highest ranked tag or tags to the image tagging system user e.g. the user that originally provided the image . In various embodiments the predetermined ranking algorithm utilizes a module ranking e.g. tags received from a computer vision instance module rank more highly than tags received from a computer vision classification module a module score e.g. tags received from the same module are ranked based on a score assigned to them by the module they are received from or any other appropriate ranking criteria. In some embodiments results processor requests tags from computer vision engines . In some embodiments results processor requests tags from human computation module s . In some embodiments results processor requests tags from human computation module s in the event that computer vision engines are not able to provide tags.

Learning module comprises a module for updating object databases based on the results of an image query. In some embodiments if an instance recognition module or a classification module are able to determine tags for an image based on information stored in object databases without finding an identical image stored in object databases the learning module then stores the image in object databases associated with the determined tags. In some embodiments the learning module determines whether adding the image to object databases will broaden the space of images associated with the determined tag. The learning module may then choose to store the image in object databases only if it does broaden the space of images associated with the tag. In some embodiments if computer vision engines is not able to determine a tag associated with the image but human computation module s is learning module stores the image and associated tag in object databases so that the image can be automatically identified if it is submitted in future queries. In some embodiments learning module processes an image before storing it and any associated tags in object databases . In various embodiments processing comprises background subtraction object geometry processing object class representation creation or any other appropriate processing.

Dashboard comprises an interface for an image tagging system administrator to gain information about the current status of the image tagging system. In the example shown the dashboard system can provide information to a system administrator on image queries tags that have been applied to images system users image taggers and system status as well as allowing the administrator to train the computer vision module by adding images and tags at his discretion.

In some embodiments features are extracted at salient locations such as corners or object contours. A local patch centered around the salient location is encoded. The encoding typically captures histograms of oriented edge energy. The features are compared to the features in the previous frame and are used to compute the optical flow. In some embodiments optical flow is estimated using a Lukas Kanade algorithm. It is determined which feature s is are locked onto. In some embodiments feature s is are used to determine an object tag. In some embodiments determining whether feature s is are locked comprises checking to see if feature s have been found in a previous frame. In some embodiments if feature s have been locked the image is steady and a key frame can be detected. In the event feature s is are locked it is determined if the frame is a key frame. If it is determined that feature s have not been locked feature s is are looked for. In some embodiments it is determined whether feature s have been found. In the event feature s have been found the lock on to feature s is indicated. For example a software module is informed e.g. by passing a message or indication that the feature s are locked and that the process may proceed e.g. to process additional images to determine a key frame . Or for example the lock is stored or recorded e.g. in a data structure or in memory location s . In some embodiments after the lock on to feature s is indicated the next time the process is executed e.g. in response to the next image frame received it will be determined that feature s is are locked. If it is determined that feature s have not been found the process ends. In some embodiments a lack of lock on to features is indicated e.g. stored recorded passed as an indication or variable to a software module etc. .

In some embodiments an accelerometer measurement is used to determine whether there are stable frames. In some embodiments the accelerometer is associated with a mobile phone.

In some embodiments a key frame has different visual content from a previous key frame. In some embodiments a key frame has the same visual content from a previous key frame.

Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive.

