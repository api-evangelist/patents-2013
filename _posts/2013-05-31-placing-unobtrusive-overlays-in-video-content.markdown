---

title: Placing unobtrusive overlays in video content
abstract: Methods and systems for placing an overlay in video content are provided. A method receives video content and input indicating an overlay to be placed in the video. The method determines, based on overlay and video properties, locations where the overlay can be placed. The method presents suggested locations for the overlay and receives a selection of a suggested location. The overlay is placed in the selected location. A system includes memory with instructions for inserting an overlay into video content. The system receives an indication of an overlay to be placed in the video, performs attention modeling on the video to identify zones likely to be of interest to a viewer. The system presents locations within the identified zones where the overlay can be inserted and receives a selection of a location. The system inserts the overlay into the selected location and renders the video with the inserted overlay.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09467750&OS=09467750&RS=09467750
owner: Adobe Systems Incorporated
number: 09467750
owner_city: San Jose
owner_country: US
publication_date: 20130531
---
This disclosure relates generally to computer implemented methods and systems for placing overlays in video content and more particularly relates to placing overlays in unobtrusive locations in video content.

Video content can be distributed from a provider as video on demand VOD time shifted television live television media such as a digital video disc DVD motion pictures distributed to theaters as digital video signals and as electronic content distributed to computing devices. Video content can be broadcast over the air as digital signals transmitted via satellite and streamed downloaded and uploaded via communications networks such as the Internet.

Given the broad distribution of such video content and growing proliferation of viewing and playback devices for viewing such video content providers and distributors of video content often employ video advertising techniques to insert advertisements into video content.

Prior solutions for inserting advertisements into video content include placing linear advertisements into the video content. Linear advertisements are inserted manually or at predetermined points or times within video content. Linear advertisements capture the entire screen the video content is being viewed on and stop or interrupt playback of the video content while the advertisements are playing. Linear advertisements may be inserted as pre rolls to be played before the video content begins playing as mid rolls which requires the video content to be paused at some point in order to play the advertisements or as post rolls played after the video content. Linear advertisements are obtrusive in that they capture the entire screen being used to view video content and interrupt the video content being played.

Another prior solution includes placing non linear advertisements into video content such that the video content is played while simultaneously showing the non linear advertisements. Although non linear advertisements are typically less obtrusive than linear advertisements their reliance on predetermined screen locations still results in obtrusive placements by covering important elements of a video scene being viewed. For example by placing non linear advertisements in predetermined or predefined locations at the bottom or top of a screen important elements of news or sports video content such as captions scrolling text with headlines scores weather and time information statistics stock tickers and other important objects may be obscured or rendered illegible. Non linear advertisements comprise images such as logos and icons and textual data appearing in a predefined portion of a visible frame of video content. Current non linear advertisement placement techniques can also result in incompatible color combinations with respect to adjacent colors in frames of video content the non linear advertisements are placed in. For example current techniques can result in illegible and or garish advertisements due to color combinations that are incompatible with or in stark contrast to adjacent video content.

These prior solutions do not provide automated matching of ovelays with video content based on properties of the video content and the overlay. Traditional advertisement placement techniques do not allow automated determination of unobtrusive locations for placing advertisements based on identification of important objects within video content. These techniques also lack a way for automatic or interactive selection of an advertisement location from amongst alternative unobtrusive locations based on relative saliency of alternative locations.

In one embodiment a method includes receiving at a computing device video content and an indication of an overlay to be placed in the video content. The overlay can be an item of electronic content such as text image and multimedia content. Based at least in part on properties of the overlay and properties of the video content the method determines locations where the overlay can be placed within the video content. The embodiment involves presenting the plurality of locations in a user interface on a display of the computing device as suggested locations for the overlay. The method receives a selection of one of the suggested locations and places the overlay in the selected location.

In another embodiment a system has an input device a display device a processor and a memory. The memory has instructions stored thereon that if executed by the processor cause the processor to perform operations for inserting an overlay into video content. The operations include receiving an indication of an overlay to be placed in the video content. The system performs attention modeling on frames of the video content to identify zones in the video content likely to be of interest to a viewer of the video content. The system presents a user interface on the display device. The user interface indicates locations within the identified zones where the overlay can be inserted into. The system receives via the input device a selection of a location within one of the identified zones. The system inserts the overlay into the selected location and renders the video content with the inserted overlay on the display device.

These illustrative features are mentioned not to limit or define the disclosure but to provide examples to aid understanding thereof. Additional embodiments are discussed in the Detailed Description and further description is provided there. Advantages offered by one or more of the various embodiments may be further understood by examining this specification or by practicing one or more embodiments presented.

Methods and systems are disclosed for placing overlays in unobtrusive locations within video content.

Embodiments disclosed herein provide automated and semi automated methods and systems for inserting overlays such as but not limited to advertisements into multimedia assests such as video content. Although exemplary computer implemented methods and systems are described herein in the context of overlays placed in online video content it is to be understood that the systems and methods can be applied to place overlays within other multimedia assets such as but not limited to video on demand VOD assets i.e. pay per view movies and rental assets subscription video on demand SVOD assets currently airing or future scheduled linear broadcast television programs simultaneous broadcasts simulcasts movies shown in theaters physical media such as digital video discs DVDs and software programs such as video games.

One embodiment provides a system that automates placement of unobtrusive overlays into video content. The video content can be online video content obtained from content providers publishers and distributors. Such online video content can be streaming or downloaded video requested from a website by a video player application executing on a client device. The request from the client device is received at a server associated with a provider s or publisher s web site. Overlays are placed in the requested video content based in part on properties of the video content and properties of overlays available from overlay providers such as advertisers.

Embodiments provide a method and system for inserting overlays into received video content the overlays having been provided by an external entity. The external entity can be an advertising network or other overlay provider. The method and system can receive indications of the overlays via a user interface and overlay processing module. The method and system can be implemented using a video overlay matching module configured to be invoked by or integrated into video editing tools such as but not limited to Adobe Premiere Final Cut Pro from Apple Inc. and iMovie from Apple Inc. The method and system determine non obtrusive locations within the video that the provided overlays can be placed in. Non obtrusiveness can be based on properties of the overlays and properties of frames of the video content. Depending on the duration of an overlay it can appear in frames spanning multiple clips or scenes of the video content. Locations are determined to be non obtrusive if an overlay having certain size dimension color and or translucency properties will not obscure or overlap with important objects in the frames. In embodiments relative saliency of regions within frames of the video content is determined by identifying important objects in the frames. One embodiment determines saliency of regions by performing saliency analysis for frames of the video to identify important objects. The saliency analysis produces a saliency map indicating locations of important objects within frames and regions in the frames containing such objects. An exemplary saliency analysis technique is described below with reference to . In certain embodiments non obtrusive locations are locations within regions that do not include an important object. The non obtrusive locations are presented as suggested locations in an interactive user interface UI .

The UI can present budget or cost information for placing a given overlay in each of the suggested locations. Costs can be expressed in terms of relative importance or salience of the suggested locations i.e. salience costs. Costs can also be expressed in terms of monetary or currency amounts. In embodiments a monetary cost for placing an overlay in a given location can be based at least in part on the salience cost for that location. The cost information can be based in part on the size and duration properties of the overlay as well as properties of the suggested locations within the frames. For example monetary costs of placing longer duration and larger sized overlays may be greater than placing relatively shorter duration or smaller sized overlays in the same location. Also for example the salience cost of placing a given overlay in closer proximity to important objects in the frames may cost more than placing the same overlay farther away from important objects. Further for example the salience costs of placing a given overlay in frames making up more important portions of the video content may be greater that the costs of placing the same overlay in less important portions of the video content. In cases where an overlay can be placed in a relatively highly salient region without overlapping an important object the salience cost of placing the overlay in the high salience region will be greater than the salience cost of placing the same overlay in a less salient region. Relative importance of portions of the video content can be identified based on properties of frames of the video content. For example locations in frames within early portions opening credits key scenes and or prior to scene changes and cut points in the video content may have higher salience and or monetary costs than other locations such as closing end credits and frames following scene changes and cut points. The UI can receive via an input device a selection of one of the suggested locations. The method and system allow a user to preview the video content with overlays inserted into selected locations and optionally select an alternative location.

Another embodiment provides a system configured to automatically transform an inserted overlay so that it blends into the frames that it appears in. The system can automate transformation of inserted overlays so that edges of the overlay are reshaped recolored made translucent made transparent or otherwise transformed in order to better blend in with adjacent pixels in frames of video content the overlay appear in. For example the frames can be scanned to detect substantially straight lines of an object near the overlay and edges of the overlay near the object can be reshaped or distorted to become substantially parallel with the lines. In certain embodiments such reshaphing is done to transform one or more edges of an inserted overlay to be substantially parallel with an object near the overlay that has relatively low salience. The system can also transform inserted overlays so that their color scheme and palette blends into the frames in which the overlay appears.

Yet another embodiment provides a method for automatic placement of overlays into three dimensional 3D video content. The method determines a favorable location for an overlay within the video content where favorability can be based on identified locations of important objects in the 3D video and shape dimension and size properties of the overlay. Favorable locations are locations the overlay can be inserted into such that it will not overlap with important objects. In general favorable locations are in regions with relatively low saliency. Saliency can be determined by performing saliency analysis of frames of the video content in a similar manner as is done with two dimensional 2D video content where locations of important objects along a longitudinal x axis and latitudinal y axis within frames of the video content are determined. In the context of 3D video content additional computations are performed to determine the depth locations of the important objects i.e. their locations along the z axis in 3D space and their depth properties i.e. thicknesses in pixels . The method then transforms the overlay into a 3D overlay by assigning a depth property to the overlay. In one embodiment the overlay is initially assigned an infinite depth so that no location in the forefront of a frame will be suggested that can occlude an important object appearing deeper within the 3D video content. In certain embodiments the 3D overlay can be blended into nearby objects by assigning a depth to the overlay that approximates a depth of one or more nearby 3D objects.

In certain embodiments the overlays can be selected from a plurality of overlay advertisements provided by one or more advertisement networks. In one embodiment an advertisement network can comprise three general categories of entities 1 content providers distributors and other entities who create and offer video content collectively publishers 2 overlay providers advertisers and other entities who are the source of overlays collectively advertisers and 3 viewers subscribers consumers theaters and other entities who request receive and or watch video content offered by publishers collectively viewers .

One embodiment provides an administrator user interface UI that publishers and advertisers can use to upload video content overlays and associated metadata into the system. In certain embodiments references to the video content are provided via the administrator UI instead of full copies of the content. As used herein the term metadata is used to refer to information associated with and generally but not necessarily stored with electronic content items such as video content and overlays that provides information about a property of the electronic content item. Metadata may include information uniquely identifying an electronic content item. Such metadata may describe a storage location or other unique identification of the electronic content item. For example metadata describing a storage location of video content may include a reference to a storage location of a copy of the video content in a server system used by publishers advertisers and users. One example of such a reference is a Uniform Resource Locator URL identifying the storage location on a web server associated with a publisher s web site. Such references can be provided by publishers as an alternative to uploading a copy of the video content to the system via the administrator UI. An exemplary administrator UI is described below with reference to .

An embodiment of the system includes a repository such as a data store or database for storing the uploaded overlays the video content or references thereto and their metadata. An example database is described below with reference to . The metadata can include characteristics and properties of video content and overlays. The video content properties can include but are not limited to genre category rating duration color palette scheme resolution format language options captioning options publisher cast director date timestamp information playback restrictions markers for linear advertisements compatible supported rendering viewing platforms and other properties of video content. Some video content properties such as a genre or publisher can apply to an entire video asset while other properties are relevant to certain portions or frames of the video asset. For example metadata useful for editing or placing overlays in video content such as cut points scene changes opening credits closing end credits and similar information does not apply to every frame in a given video asset. Similarly format properties can indicate whether all or a portion of a video asset is 2D or 3D. Playback restriction properties can include regional or age based restrictions as well as restrictions on a number of viewings or a time limit for viewing i.e. for VOD and rented video content . For a rented video asset a playback restriction property can indicate the length of a video asset rental as a duration i.e. 24 hours . The compatible supported rendering viewing platform properties can indicate minimum requirements for viewing the video content such as supported resolutions compatible video players and supported client device platforms. For example these properties can indicate a minimum display resolution display size operating system OS version and or browser version needed to view the video content.

Some or all of the video content properties can be in the form metadata included as tags keywords data carrying icons or markers stored within the video content. For example the metadata can be included outside of visible areas of frames of the video content. Non limiting examples of metadata for electronic content items can include a title author keywords and the like. Metadata may also describe a relationship between video content and overlays such as how the video content and the overlays can be combined to create edited video content including the overlays. Metadata can also describe when and how an electronic content item was created such as information identifying application used to create the item a timestamp a file type encryption status and other technical information for the item and or access rights for the item. In certain embodiments the metadata can include rendering attributes and their values for video content or an overlay. For example if a rendering attribute is included in metadata for video content the metadata can also include a value for that rendering attribute specific to rendering the content via a video player application that the content is to be viewed with. Depending on the encryption status and or access rights video content may be transmitted to from the publisher via secure network connections or data links. Non limiting examples of such secure connections include connections made using the Secure Sockets Layer SSL protocol or the Transport Layer Security TLS protocol. As would be understood by those skilled in the relevant art s SSL and TLS connections are made via cryptographic protocols to provide communication security over data networks such as the Internet. In additional or alternative embodiments properties can be stored separately from the video content in a repository such as database which is described below with reference to .

The overlay properties can include but are not limited to product service category duration target demographic target region color palette scheme translucency shape format size dimensions resolution language options date timestamp information monetary cost per placement number of prior insertions placements budget expiration and other metadata about the overlay. The format properties can indicate whether the video content and the overlay is 2D or 3D. In cases where the format of overlay is 3D the dimension property includes a depth of the overlay. The size and dimension properties can be in terms of pixels. In cases where an overlay is an advertisement a number of placements can be expressed as a number of times the advertisement has been inserted in video content and this property in combination with the monetary cost per placement and or budget properties can be used to determine if there is any remaining budget for inserting the advertisement into video content. The expiration property can be embodied as an expiration date in order to determine if an overlay is still available for insertion into video content. For example if an overlay includes time sensitive information such as information pertaining to a scheduled event such as but not limited to a sale occurring within a date time range a time sensitive promotion a product release date a television program debut a theatrical movie release or a temporary offer the expiration property can be set accordingly so that the overlay is not inserted into video content after a certain date or time.

According to an embodiment when a user requests video content offered by a publisher who is a member of the advertisement network a rendition of the requested content with overlay advertisements from an advertiser in the network is delivered to the user. The user can request the video content via a smart TV a set top box STB or a video player application such as the exemplary video player described below with reference to . In one embodiment the user can request and view video content in the video player executing on a client device having a display. The video player can have a video player UI that users can interact with to select preview and view video content. The selected video content can be downloaded or streamed to a client device where video player is executing. An exemplary video player UI is described below with reference to . For example in the context of online video content when a user requests video during a visit to a publisher s web site that user will receive some advertisements. Each of the entities benefits from this process as described below.

The overlay provider i.e. an advertiser organization or other entity wishing to convey information via an overlay can publicize and promote items indicated in overlays. For example in embodiments where the overlay provider is an advertiser the advertiser can increase awareness of a service product or brand offered for sale. As would be understood by those skilled in the relevant art s this increased awareness can correspond to increased sales of the service product or branded items indicated in the overlay advertisement. In embodiments overlay providers can be video content providers such as but not limited to television networks web sites and movie film studios who wish to place overlay advertisements promoting their television programs online video content and films.

The video content provider i.e. a distributor publisher or web site can receive revenue from the overlay provider for displaying the overlay provider s overlay in video content offered by the video content provider. In turn this revenue stream can allow video content providers to offer consumers such as subscribers and viewers of the video content additional services. These additional services can include more video content reduced price or free content and or content with increased quality. Where the video content is provided online as electronic content increased quality can be embodied as a higher resolution rendition of the video content and or a rendition of the video content without linear advertisements. In embodiments the revenue stream from overlays enables video content providers to reduce prices for video content. For example reduced price or free renditions of iTunes videos iTunes apps and games containing video content pay per view video assets such as movies and television programs Amazon Video On Demand assets and VOD video content can be offered to consumers. An embodiment avoids placement of poorly targeted overlays having little relevance to a group of consumers viewing video content. Another embodiment avoids placing obtrusive or intrusive overlays which may cause a viewer to ignore the overlays or even choose competitor web sites that offer the services they need. Furthermore this kind of overlay can have a negative impact in the way the advertiser is perceived.

Embodiments can thus address issues related to one or both of overlay matching finding the most suitable overlay for video content and unobtrusive overlay insertion. Besides these issues there are other important aspects that can be addressed in online advertising e.g. deciding what sum an overlay provider or advertiser will pay for a selection i.e. a click on an interactive overlay or advertisement. This can be addressed through a bidding process e.g. bidding on objects to be placed in video content and or by using overlay properties pertaining to budget and monetary cost per placement.

As used herein the term video content refers to any type of audiovisual media that can be displayed or played on television devices projection television systems digital video recorder DVR devices DVD devices game consoles computer implemented video playback devices mobile multimedia devices mobile gaming devices and set top box STB devices. A STB can be deployed at a user s household to provide the user with the ability to control delivery of video content distributed from a provider. Video content can be electronic content distributed to computing devices via communications networks such as but not limited to the Internet.

Edited video content including unobtrusive overlays placed by the exemplary systems and methods disclosed herein can be previewed selected and viewed by various video player devices and platforms used to select and view video content. Such devices can be components of platforms including personal computers smart phones personal digital assistants PDAs tablet computers laptops digital video recorders DVRs remote storage DVRs interactive TV systems and other systems capable of receiving and displaying video content and or utilizing a network connection such as the Internet. An exemplary interactive TV system can include a television communicatively coupled to set top box STB . With reference to exemplary STB client device can include without limitation an Internet Protocol IP based i.e. IPTV STB. References to a client device or video player should therefore be interpreted to include these devices and other similar systems involving display of video content and viewer input.

As used herein the term electronic content refers to any type of media that can be rendered for display or played on mobile and other computing devices. Computing devices include client and server devices such as but not limited to servers desktop computers laptop computers smart phones video game consoles smart televisions tablet computers portable gaming devices personal digital assistants etc. Electronic content can be streamed to downloaded by and or uploaded from computing devices. Electronic content can include multimedia hosted on websites such as web television Internet television standard web pages or mobile web pages specifically formatted for display on computing devices. Electronic content can also include application software developed for computing devices that is designed to perform one or more specific tasks at the computing device.

Video content can be in the form of electronic content streamed from a server system to a web enabled television i.e. a smart television a projection television system or a client computing device. Streaming electronic content can include for example live and on demand audiovisual content provided using a streaming protocol such as but not limited to Internet Protocol television IPTV real time messaging protocol RTMP hypertext transfer protocol HTTP dynamic streaming HDS and HTTP Live Streaming HLS . A server system can provide multiple renditions of video content having different quality levels and language options such as captioning or audio dubbing.

Computer implemented systems and methods are disclosed for placing overlays in unobtrusive locations within video content. In embodiments overlays can include text or multimedia content such as but not limited to advertisements. An interactive user interface UI for an application executed at a client device can be used to select from among suggested locations for overlay placement.

As used herein the term electronic content is used to refer to any type of media that can be rendered for display or use at a computing system television client computing device or other electronic device. Electronic content can include text or multimedia files such as images video audio or any combination thereof. Electronic content can be delivered as streaming video and as downloaded data in a variety of formats such as for example a Moving Picture Experts Group MPEG format an Audio Video Interleave AVI format a QuickTime File Format QTFF a DVD format an Advanced Authoring Format AAF a Material eXchange Format MXF and a Digital Picture Exchange DPX format. Electronic content can also include application software that is designed to perform one or more specific tasks at a computing system or computing device.

As used herein the term rendition is used to refer to a copy of an asset such as video content provided to a video player or client device. Different renditions of electronic content can be encoded at different bit rates and or bit sizes for use by client devices accessing electronic content over network connections with different bandwidths. When the electronic content includes video content different renditions of the video content can include different overlays for viewing on client devices located in different regions. For example a video asset can include multiple renditions of the video as separate video clips where each rendition has a different quality level associated with different bit rates.

As used herein the term asset is used to refer to an item of electronic content included in a multimedia object such as text images videos or audio files. As used herein the term image asset is used to refer to a digital image included in a multimedia object. One example of an image asset is an overlay. As used herein the term video asset is used to refer to a video file included in a multimedia object. Video content can comprise one or more video assets. As used herein the term text asset is used to refer to text included in a multimedia object. Exemplary overlays can be embodied as a text asset an image asset a video asset or a combination of text image and or video assets. For example overlays such as overlays and depicted in can include a text asset such as a name of a company product or service combined with an image asset with a related icon or logo. Also for example overlays can include video assets with animation or a video clip.

For simplicity the terms multimedia asset video asset online video content and video content are herein to refer to the respective assets or contents regardless of their source i.e. publisher distribution means i.e. web site broadcast simulcast or theatrical release format i.e. MPEG high definition 2D 3D or playback means i.e. television client computing device video player projection system DVD player used to view such files and media. For example where the publisher of a video asset is a television network movie film studio or production company the video asset can be a television program or motion picture. Renditions of this video asset can be embodied as streaming or downloadable online video content available from a web site of the publishers or a distributor s web site. Another rendition of the video asset can also be made available as video content on media such as a DVD a DVR recording or VOD obtained via an STB and viewed on a television.

Embodiments can provide a viewer application with different renditions of electronic content being rendered for display or use at a client device based in part on a geographic region or location the client device is associated with. Dynamically switching between different versions of video content can provide the most relevant rendition based on overlays placed within the video content and a region or location of the client device accessing the electronic content via a data network. A viewer application can download stream or otherwise access electronic content via a network. The viewer application can submit a request to preview of view video content to a server having a server side video overlay matching system or module. The video overlay matching system can create a rendition of the requested video content having non obtrusively placed overlays determined to be relevant to a location or region associated with the client device the viewer application is executing on. For example an embodiment can select a rendition of electronic content with overlays having audio and or text in English in response to determining that a client device the viewer application is executing on is located in the United States. In embodiments such location information and or language preferences can be user selected. In other embodiments the location information can be determined automatically based on a Global Positioning System GPS location of the client device a media access control address MAC address of the client device a network address of the client device or other identifying information.

The video overlay matching system can be implemented as one or more modules configured to execute on a server or other computing device. The video overlay matching system can apply one or more placement rules to generate recommendations for suggested overlay locations. A recommendation can include one or more suggested overlay locations and indicate respective salience and or monetary costs for each of the suggested locations. The recommended locations for a rendition of video content to be downloaded or otherwise accessed by the viewer application can be based in part on properties of the video content and the overlay. The cost information can be based on the size prominence and duration of the overlay to be placed in the video content. The cost information can vary based on differing quality of renditions available from a video content provider.

The video overlay matching system can determine location recommendations based on properties of the overlay and frames of the video content the overlay is to be placed in. For example color scheme and color palette properties of an overlay and region within video content frames can be used to identify locations within the regions whose colors are compatible with a given overlay. Such color properties can also be used to transform an overlay so that its edges include colors and hues that blend into surrounding pixels in a location where the overlay is to be placed. The video overlay matching system can also configure the viewer application to select a rendition having overlays deemed to be relevant to a region or physical location of a client device the viewer application is executing on. For example overlay advertisements for tobacco or alcohol products will not be deemed relevant to countries or locations where such advertising is restricted.

As used herein the term network connection refers to a communication channel of a data network. A communication channel can allow at least two computing systems to communicate data to one another. A communication channel can include an operating system of a first computing system using a first port or other software construct as a first endpoint and an operating system of a second computing system using a second port or other software construct as a second endpoint. Applications hosted on a computing system can access data addressed to the port. For example the operating system of a first computing system can address packetized data to a specific port on a second computing system by including a port number identifying the destination port in the header of each data packet transmitted to the second computing system. When the second computing system receives the addressed data packets the operating system of the second computing system can route the data packets to the port that is the endpoint for the socket connection. An application can access data packets addressed to the port.

Another embodiment of a video overlay matching criterion can be a video content utilization rule. The video overlay matcher can apply the video content utilization rule to generate a recommendation based on how the video content is being rendered for display in a video player at the client device. In one embodiment the video content utilization rule can describe a size of a window in which video content is being rendered for display where the described window size is relative to the size of the display device or screen associated with a client device where the video player is executing. For example applying a video content utilization rule may generate a higher recommendation for a viewer application rendering video content for full screen display at a client device. A lower recommendation for a full screen display may produce pixeling pixilation of the video content and included overlays. To this end a lower recommendation on larger displays and a higher recommendation on smaller displays may be as detrimental to user experience as having insufficient screen size for an overlay to be legible on a display of the client device. In another embodiment the video content utilization rule can describe a type of display device for which the client device renders the electronic content. Electronic content rendered for display or use at a first display device included in or in communication with the client device can result in a first recommendation. Video content rendered for display or use at a second display device included in or in communication with the client device can result in a second recommendation. For example a lower recommended bit rate can be generated for video content being rendered for display or use by a client device using a low resolution screen such as the screen of a tablet computer and a higher recommended bit rate can be generated for electronic content being rendered for display or use by the client device using a high resolution display device such as a high definition television coupled to the tablet computer via a high definition multimedia interface HDMI output.

The video overlay matching system can store overlay data in a database and organize the overlay data based on a number of placements for each overlay category duration remaining budget and or remaining number of placements.

The features discussed herein are not limited to any particular hardware architecture or configuration. A computing device can include any suitable arrangement of components that provide a result conditioned on one or more inputs. Suitable computing devices include multipurpose microprocessor based computer systems accessing stored software that programs or configures the computing system from a general purpose computing apparatus to a specialized computing apparatus implementing one or more embodiments of the present subject matter. Any suitable programming scripting or other type of language or combinations of languages may be used to implement the teachings contained herein in software to be used in programming or configuring a computing device.

Referring now to the drawings is a block diagram depicting an example architecture for an overlay placement system implementing certain embodiments. The example architecture includes a server configured to perform server side processing in response to inputs and data received via a front end comprising a publisher UI an advertiser UI and a video player . As shown in server includes three main modules one corresponding to each type of user . The server modules include a video processing module an overlay processing module and a video overlay matching module . Although exemplary modules and shown in are labeled for offline video and advertisement ad processing and online video advertisement matching as discussed below and shown in these modules are not limited to offline video and advertisement processing and online video advertisement matching. Embodiments of the modules shown in can be configured to process any type of overlay including but not limited to advertisements to any type of video content including but not limited to online video.

In one embodiment server is an overlay server providing a platform where publisher users upload video content such as their video assets advertiser users upload overlays such as advertisements and viewer users i.e. end users or consumers of video content who view video assets are shown renditions of video content in video player with non obtrusive overlays inserted. According to this embodiment video processing module extracts information about video content offline after a publisher user uploads the video content via the publisher UI . Such offline video processing includes computing a saliency map and auxiliary matrix for the uploaded video content. For each overlay overlay processing module extracts information about the overlay offline after an advertiser user uploads it via the advertiser UI . A non limiting example of the extracted information includes the color palette scheme of the overlay. In this embodiment video overlay matching module automatically handles overlay selection and placement. In an alternative embodiment overlay selection may be done externally on a remote system or server through a bidding process where an overlay provider or advertiser user specifies how much he would pay to have his overlay shown in certain video content. According to this alternative embodiment the bidding and overlay selection can be based at least in part on a profile of a viewer user who selects the particular video content for viewing within video player .

Another embodiment described below with continued reference to architecture and server provides a platform for fully automated overlay placement for each overlay along with overlay transformations such as for example spatial i.e. reshaping resizing color translucency and or transparency transformations being performed in near real time so that the resulting rendition of selected video content is shown to a viewer user in video player with the automatically placed and transformed overlays. For example one or more edges of an overlay can be transformed so that the edges include colors and hues that blend into surrounding pixels in a location where the overlay is to be placed. Also for example edges of an overlay can be transformed so that they blend into surrounding portions of a video frame by being made translucent or substantially transparent. Such translucency and transparency transformations can increase the degree or percentage of translucency transparency for overlay portions based on how far away in pixels portions of the overlay are from the center of the overlay. In this way an overlay can be increasingly transparent or translucent as the edges of the overlay are approached and substantially opaque around the center of the overlay. The video overlay matching system can also configure the viewer application to select a rendition having overlays deemed relevant to a region or physical location of a client device the viewer application is executing on. For example overlay advertisements for tobacco or alcohol products will not be deemed relevant to countries or locations where such advertising is restricted.

In yet another embodiment a partially automated process implements overlay placement and transformation algorithms inside a video editing tool such as for example Adobe Premiere Final Cut Pro from Apple Inc. or iMovie from Apple Inc. This embodiment generates multiple alternative overlay placements and presents these alternative locations in an interactive UI so that a user such as an advertiser user can manually select the location he considers best so that there is a combination of automatically generated suggestions recommendations of overlay locations combined with optional manual supervision from a user when inserting overlays into video content.

The users of the overlay placement system can include video content publishers overlay providers i.e. advertisers and viewers. Once a publisher uploads video content via a publisher UI the video content is received by server and a video processing module performs various computations in order to be able to quickly retrieve the video content and its properties when necessary. Publisher UI can allow a publisher user to add new video content along with metadata such as but not limited to a brief description title and tags keywords for the uploaded video content. As described below with reference to publisher UI can be invoked from an administrator interface. The keywords inserted via publisher UI can be used by video overlay matching module for selecting appropriate overlays. These keywords can also represent an essential element for which overlay providers such as advertisers may bid on when identifying video content that they want to place their overlays into.

Video processing module can read metadata for the received video content that applies to the entire video in order to categorize the content. For example genre resolution format access control rating and duration properties of the received video content can be indexed and stored in a database with a reference to the video content so that the videos having a certain category can be quickly retrieved from database as needed. In embodiments when video overlay matching module needs to match an overlay that is appropriate to a certain type of video segment the video properties data stored in database by video processing module can be used to quickly locate clips within video content matching the desired criteria. For example video overlay matching module can match overlays appropriate for a high definition 3D sports video clip having a duration of less than 5 minutes that is rated for viewing on a video player in a certain region by a viewer in a given age group to video content meeting these criterion using overlay and video properties data stored in database . Video processing module can also read and store more granular metadata for uploaded video content that does not apply to every segment portion or frame of the video content. Such granular metadata can for example can pertain to properties useful for overlay placement and video editing such as indications of frames including cut points or scene changes.

With continued reference to an advertiser user can interact with the advertiser UI to upload an overlay to server . In an embodiment advertiser UI consists of a form that allows an advertiser user to upload a new overlay along with overlay properties such as keywords representing the desired context or video content in which the overlay should appear. Overlays uploaded via advertiser UI can be interactive in that they can include a selectable hyperlink with a target URL that a viewer can click on while playing video content including the overlay. For such interactive overlays the overlay properties entered via advertiser UI can include the target URL associated with a supplier of a product brand or service indicated in the interactive overlay. For example a viewer using an input device can interact with a video player to click on an interactive overlay in order to navigate to the target URL in a new browser tab window or session. After an overlay has been added using advertiser UI metadata with properties i.e. features of the uploaded overlay are extracted by the overlay processing module which then stores the extracted overlay properties are stored in database .

A viewer user can preview select and watch videos along with the inserted overlays using the video player . In one embodiment video player is embodied as a video content web site that allows visitors to the web site to navigate browse and search a list of videos. Video player allows a viewer user to select video content from the list of videos and view the selected content. Delivery of the selected video content together with its inserted overlays can be accomplished via streaming downloading or pushing i.e. podcasting the content to video player . A non limiting example of a browser based UI for a video player is illustrated in which is described below. When a viewer user requests video content to be viewed on video player the video and overlay properties data previously stored in database can be used by video overlay matching module to rapidly match the requested video with the corresponding overlays and to identify a good location to place the matched overlays. In an embodiment video overlay matching module is configured to perform calculations substantially in real time at the point when a request for a video is received at server from video player .

According to one embodiment of architecture video processing module and overlay processing module perform pre calculations for uploaded and received video content and overlays respectively in order to enable video overlay matching module to expedite matching of video content to overlays. These calculations can be performed offline after the uploads have completed and prior to subsequent matching of video content to overlays. The online matching of video content to overlays is more efficient when video overlay matching module does not need to determine or calculate properties of video content and overlays as matches are being identified. In this way the computations performed by video overlay matching module can be limited to those needed to make a match or connection between particular overlays and video content.

Architecture also allows matching of overlays to videos that takes into account metrics collected for viewer users . For example server can track which videos have been viewed before by a given viewer user or an associated video player so that the matching performed by video overlay matching module takes the particularities of the user into account when selecting and placing overlays.

In an alternative embodiment instead of matching overlays with video content in near real time when a video is requested via video player the video overlay matching module is invoked after each overlay is uploaded via advertiser UI . In this embodiment the matching and location identification computations are performed by video overlay matching module as each overlay is received by overlay processing module .

According to yet another embodiment not shown video overlay matching module is excluded from architecture and its functionality is divided between video processing module and overlay processing module . In this embodiment in addition to indexing and storing video content and overlay properties data in database video processing module and overlay processing module compute everything needed to match an overlay with video content at the time overlays are uploaded via advertiser UI . One way this embodiment could allow for efficient if not real time overlay video matching is by periodically invoking routines to update video overlay associations. For example a scheduled task or job could be run daily hourly or in other periodic increments to match overlays to video content and to determine if any previously identified overlay video matches are no longer valid. The periodic job could identify invalid pairings of overlays and video content in cases where an overlay has expired has depleted its budget or if either the overlay or video content is no longer available. In cases where architecture and server are implemented with a Unix like operating system OS this scheduled task or job can be implemented as a cron job that periodically updates overlay video associations and determines if any previously identified overlay video association are no longer valid.

A computer readable medium may comprise but is not limited to an electronic optical magnetic or other storage device capable of providing a processor with computer readable instructions. Other examples comprise but are not limited to a floppy disk a CD ROM a DVD a magnetic disk a memory chip ROM RAM an ASIC a configured processor optical storage magnetic tape or other magnetic storage or any other medium from which a processor such as processor or processors can read instructions. The instructions may comprise processor specific instructions generated by a compiler and or an interpreter from code written in any suitable computer programming language. Non limiting examples of a suitable programming language can include C C C Visual Basic Java Python Perl JavaScript and ActionScript.

Client devices may also comprise a number of external or internal devices including input devices such as a mouse keyboard stylus touch sensitive interface. Client devices can also comprise an optical drive such as a CD ROM or DVD drive a display device audio speakers one or more microphones or any other input or output devices. For example depicts the client device having a processor a memory and a display device . A display device can include but is not limited to a screen integrated with a client device such as a liquid crystal display LCD screen a touch screen or an external display device such as a monitor.

Although depict video processing module overlay processing module and video overlay matching module as separate modules one or more of these modules can be included as a software module of a single application. Similarly while database is shown in as being hosted locally on server in alternative embodiments database can be hosted on an external server not shown remote from server . For example database can be hosted on a dedicated database server accessible from server via network . Overlay placemen system stores video content overlays and additional information such as video and overlay metadata in database . Some of the additional information may be explicitly specified or input when publishers and overlay providers upload video content and overlays. For example titles descriptions and tags keywords can be entered by publisher and advertiser users at upload time. Other additional information may be computed and stored in database in order to expedite subsequent operations and calculations carried out by video overlay matching module . Descriptions of exemplary functionality of video processing module overlay processing module and video overlay matching module are provided in the following paragraphs.

According to an embodiment video processing module is configured to perform a set of video processing operations one time for a given item of video content after the video content is uploaded to server . In this embodiment the video processing operations are performed once because they are resource intensive requiring relatively large amounts of processing and memory capacity from processor and memory . The video processing operations performed by video processing module can include saliency calculation which involves identifying which regions of video content are more likely to attract viewer user gazes and attention. Since these regions may represent essential spots of the video content they are identified so that video overlay matching module can generally avoid them when inserting overlays. Saliency calculation is described in more detail below with reference to . Video processing module can also perform video segmentation wherein the structure of the video content is and other useful information is extracted from video content at upload time. In one embodiment such information can be stored in database . In cases where it is desirable to avoid placing overlays that span scene transitions i.e. for aesthetic or other reasons video overlay matching module can be configured to use the structure information extracted and stored by video processing module to place overlays so that they do not span multiple scenes. Video processing module can also be configured to perform scene intensity evaluation for uploaded video content. The results of this evaluation can be used to place overlays into relatively more intense scenes while also ensuring that the overlay locations do not overlap with important objects. The scene intensity evaluation can include scene understanding techniques using various heuristics such as estimating motion in scenes as a measure of relative intensity of scenes in uploaded video content. The scene intensity evaluation can also use different channels such as sound to determine relative intensity of scenes in the video content.

In an embodiment video processing module can be configured to perform color palette extraction by identifying a few most representative colors for the video content. In order to have a visually pleasing effect when inserting an overlay it can be preferable to select an overlay that has colors i.e. color scheme or color palette as close as possible to those of a zone of frames the overlay is being inserted into. In additional or alternative embodiments video processing module can be further configured to perform object detection in order to enable better matching between video content and overlays by automatically extracting semantic knowledge from the video content. A non limiting example of such semantic knowledge is knowledge of which objects are present within frames of the video content.

In a similar manner to the above described functionality of video processing module an exemplary overlay processing module can be configured to compute one time information about an overlay after the overlay has been uploaded to server . In an embodiment overlay processing module is invoked after an advertiser user pushes or uploads a new overlay via advertiser UI . According to one embodiment overlay processing module is responsible for storing information about the uploaded overlay in database .

In additional or alternative embodiments instead of invoking or executing video processing module and overlay processing module synchronously as described above calls to these modules can be queued for later execution. In this way the video and or overlay processing functions described above can be processed later well after upload time which can improve the end user experience for a publisher and or advertiser user by expediting uploads of video content and or overlays.

In an embodiment video overlay matching module is invoked when a viewer user user selects a particular video asset or video content for viewing. The selection can be made for example in the user interface of video player executing at client device via interaction with a remote control or other input device at a set top box STB client device via a touch screen display device or other user input at a client device . The selection is then sent as a request from the client device to server via network . In one embodiment when the request for the selected video content is received at server video overlay matching module queries database to find overlays to be inserted into the requested video content. In this embodiment the query results in indications of the overlays and their properties being returned to video overlay matching module where the query includes indications of at least some properties of at least one of the selected video content the requesting client device and the viewer user . Based at least in part on properties of overlays returned by database and properties of the requested video content video overlay matching module also determines some appropriate spatial locations i.e. coordinates within zones or regions of the viewable video content and temporal positions i.e. starting ending points in frames of the video content to insert the overlays. In the exemplary embodiment shown in video overlay matching module consists of two sub modules or components an overlay ranking module or overlay ranker and an overlay scheduler . Exemplary functionality of these components is described below.

According to an embodiment overlay ranker is invoked by video overlay matching module in order to find overlays that are most related to the requested video content i.e. overlays that best fit the video content . In one exemplary implementation overlay ranker consists of two separate parts or subcomponents which each evaluate one of two criterions to determine the degree to which the selected video content and an overlay fit together. The first criterion evaluated is semantic similarity between the selected video content and overlays. Semantic similarity can be based at least in part on keywords and other metadata associated with video content and overlays. Overlay providers such as advertisers may insert keywords along with their overlays in order to express their preference toward having their overlays placed in video content related to certain subject matter. Semantic similarity is evaluated in order to try to match overlays and video content based on their respective tags keywords and other content properties because semantically related overlays are more likely to be of interest to a viewer user .

Semantic matching can involve understanding the contents of a video asset combined with knowledge of the overlays to be placed. Overlays can be annotated with some keywords in order to give hints regarding the kinds of video content that the advertiser user would like the overlays to appear in. Similarly video content may be tagged with keywords or some words could be extracted from the title property or other metadata. Even if a few words are available regarding the genre category and or content of the video asset matching the overlays can include use of an ontology e.g. the WordNet lexical database of English and extract related words using the tags or keywords which would entail obtaining a similarity by analyzing how often two words appear together in a large amount of text. In embodiments using an ontology such as WordNet nouns verbs adjectives and adverbs are grouped by synonymy in groups called synsets. A synset is a group of synonyms forming an equivalence class such that replacing one word in a synset with another word in the same synset does not change the meaning of a phrase including the word. Besides this grouping WordNet also offers semantic relations between synsets. These relationships vary depending on the part of speech. For nouns there are hypernyms Y is a hypernym of X if and only if any X is also an Y hyponyms Y is a hyponym of X if and only if any Y is also an X coordinate terms X and Y are coordinate terms if they share a hypernym holonyms Y is a holonym of X if and only if X is part of Y meronyms Y is a meronym of X if and only if X is a holonym of Y . Similar semantic relations can be defined for verbs hypernyms troponyms entailment coordinate terms adjectives related nouns similar to participle of verb adverbs root adjectives. Wordnet also offers the polysemy count of a word the number of synsets that a word belongs to. If a word belongs to multiple synsets i.e. homonymy then some meanings are probably more frequent than others. This is quantified by frequency score which can be obtained by annotating large amounts of text with the corresponding synset of each word.

Certain embodiments can use additional more elaborate measures developed around WordNet such as for example the Resnik measure that captures the similarity of two words by taking into account the information brought by the most specific concept that subsumes them. For example given two concepts C1 and C2 embodiments may only look at the is a relations going up in a hierarchy until a common parent P is found. Then a measurement of how informative the subsuming concept can be taken by summing up all frequency counts of the words representing or subsumed by that concept i.e. if the hierarchy would contain one top concept which subsumes any other concept then that top concept would have a frequency of 1 and an informativity of 0 . An advantage of using the Resnik measure which employs term frequency against a shortest path to determine semantic similarity is that it is independent of terminology density around concepts on the path. For example if only a few terms exist in a certain domain using the Resnik measure makes it possible to reach general concepts within a very small number of steps. In cases where overlay placement system is provided with a set of keywords tags describing video content and needs to find an overlay that is semantically related based on the keywords tags that describe the overlay these keywords can represent words that would be targeted by the overlay. In terms of information retrieval from database the video keywords represent the database query and the overlay description represents the database records or documents to be retrieved from database .

In cases where multiple overlays are targeting a certain keyword the importance of a semantic match remains important. One embodiment determines when two or more overlays have the same number of keywords and the overlay that matches more keywords with video content is deemed to be the preferable semantic match. In this embodiment when two or more overlays match the same number of keywords the overlay with a shorter description is deemed to be the preferable semantic match. An exemplary formula that satisfies these conditions is expressed as 

One embodiment can use the Resnik method described above in order to measure the word similarity. For example instead of counting how many words are shared between video content and the overlay this embodiment can for each video content keyword or word in the video content description property take into account the most similar word in the overlay description using the Resnik measure which will yield a number between 0 and 1 as the weight. The formula implemented in this embodiment can be expressed as 

A second criterion that can be considered is visual similarity between the selected video content and overlays. Having an overlay blend better into video content can result in a better overall experience for the viewer user which can in turn result in positive implications for the video content publisher and overlay provider i.e. the advertiser . In embodiments the degree of visual similarity between video content and an overlay is based in part on their respective color palettes. For example if an overlay and the video content only contain contrasting colors then they are deemed to not have a high degree of visual similarity. Certain embodiments extract the color palette from the overlays and also from a few frames of video content. In one embodiment based on colors extracted from video content a query is submitted to retrieve overlays from database including overlays with the most similar colors to the extracted video content colors. This embodiment results in selecting visually similar overlays whose insertion into the video content will be less obtrusive leading to a more pleasant experience for a viewer user . The color palette of a video frame or overlay image represents a set of representative colors for the frame or image. Given a video and an overlay a distance is computed by using the overlay and video color palettes. For each color extracted from the video palette an embodiment considers the most similar color in the overlay. In one embodiment color similarity can be based on colors having the smallest Euclidian distance from each other in a hue saturation and brightness HSB or hue saturation and lightness HSL coordinate space. In order to compute the Euclidean distance for an overlay an embodiment adds logarithms of the distances between each color in the video palette and the most similar color from the overlay color palette. This addition can be expressed formulaically as 

Certain embodiments match overlays to particular video based at least in part on visual similarity between an overlay and video content first selecting a number of candidate overlays based on semantic similarity and afterwards filtering the list to use those also having at least some degree of visual similarity. One embodiment sorts overlays in descending order of semantic similarity and only a few of the top performing i.e. most semantically similar overlays are considered for the next stage. In the next stage overlay selection is based on the visual similarity score. Variations of this embodiment can control the outcome of these stages by changing the number of overlays to be considered after the semantic similarity scores are computed. In this way based on both semantic and visual similarity criteria overlay ranker produces a list of overlays ranked according to how well they fit into the selected video content. According to embodiments this ranked list can be stored in memory or in database . In alternative embodiments overlay ranker produces a list of overlays ranked only on one of semantic or visual similarity.

In one embodiment overlay scheduler is invoked by video overlay matching module after overlays have been ranked by overlay ranker . Overlay scheduler then determines spatial and temporal positions for the ranked overlays. Overlay scheduler can be supported by the pre processing previously done for both the overlays and for the selected video content by overlay processing module and video processing module respectively. By using the results of the saliency extraction along with the video and overlay properties previously stored overlay scheduler can expedite placement and scheduling of ranked overlays within the selected video content.

In an embodiment client devices comprise one or more video navigation devices such as but not limited to an input device configured to interact with browser based UI of a video player a touch screen display device and a set top box STB . Exemplary STB client device can include without limitation an Internet Protocol IP based i.e. IPTV STB. Embodiments are not limited to this exemplary STB client device interfacing with network and it would be apparent to those skilled in the art that other STBs and video navigation devices can be used in embodiments described herein as a client device including but not limited to personal computers mobile devices such as smart phones laptops tablet computing devices digital video disc DVD devices or other devices suitable for rendering renditions of video content on display device . Many additional client devices and STB client devices can be used with overlay placement system although only one STB client device is illustrated in . In an embodiment a client device may be integrated with a display device so that the two form a single integrated component. Client devices can include any suitable computing devices for communicating via network rendering the publisher UI advertiser UI and or executing video player .

As shown in each of the client devices is coupled to sever through network . Although not depicted in in an alternative embodiment server can be located separately from database . Client devices receive operational commands from users including commands to initiate uploads of video content via publisher UI commands to initiate uploads of overlays via advertiser UI and commands to navigate to select and view video content via video player . A remote control not shown or other input device may be used to control operation of STB client device . Some STBs may have controls thereon not requiring the use of a remote control. The remote control is configured with buttons to control the STB client device including play a video order a video asset i.e. a pay per view VOD asset add a video asset to a cart retrieve information about video content view cart preview similar video content i.e. more like this etc. In an embodiment the cart is a convenient storage location for quick access to video assets a viewer user is likely to eventually want to order wherein ordering initiates delivery of rendition of the ordered video asset.

It is to be appreciated that the server could provide renditions of any type of audio visual content. Video playing and viewing sessions as described herein refer to any video content that is generally available for delivery to an individual client device with delivery initiated upon an explicit request from that client device . Video viewing sessions may also be referred to as a session herein. Server may also be referred to as a server herein. In an example a video viewing session is one or more of a video content viewing session or a video game session wherein video game assets can be previewed and ordered. In a video viewing session server may provide a rendition of video content stored in database or remotely at a publisher s web server. The rendition will include one or more overlays inserted into non obtrusive locations by video overlay matching module . In a video game session server runs a video game for example on processor and allows a client device to play a preview of the video game remotely.

According to an embodiment overlay placement system displays an administrator UI shown in including publisher UI and advertiser UI and a UI for video player shown in on display device . In embodiments display device may be one or more of a television a network enabled television a monitor the display of a tablet device the display of a laptop the display of a mobile phone or the display of a personal computer. In an embodiment one type of client device is a cable set top box STB connected to a display device . In this embodiment display device may be a television or monitor connected to STB client device

Server can provide renditions of selected video content via the network . Renditions include the video content with inserted overlays matched to the content. In embodiments a particular one of renditions can optionally include overlays matched to video content by video overlay matching module where the matching is based in part on characteristics of a particular one of client devices where a particular one of renditions is to be viewed. Renditions may be resident in any suitable computer readable medium database memory and or memories . In one embodiment a particular one of renditions is provided in a resolution compatible with a particular display device of a client device that requested the video content. In one embodiment the renditions can reside in memory of server . In another embodiment the renditions can be accessed by the server from a remote location via network and provided to the client devices . Each of the renditions can include a copy of some or all of the requested video content encoded at a given bit rate and or bit size appropriate for the requesting client device .

Server can include any suitable computing system for hosting the video content video processing module overlay processing module video overlay matching module and database . As shown in server includes a processor coupled to a memory . In one embodiment server may be a single computing system. In another embodiment server may be a virtual server implemented using multiple computing systems or servers connected in a grid or cloud computing topology. As described below with reference to processor may be a single processor in a multi core multiprocessor system. Such system can be configured to operate alone with a single server or in a cluster of computing devices operating in a cluster or server farm.

Network may be a data communications network such as the Internet. In embodiments network can be one of or a combination of a cable network such as Hybrid Fiber Coax Fiber To The Home Data Over Cable Service Interface Specification DOCSIS Internet Wide Area Network WAN WiFi Local Area Network LAN ATM or any other wired or wireless network. Server may store and stream video content including but not limited to online video television programs television broadcasts simulcasts movies and video games.

Client devices can establish respective network connections with server via network . One or more of publisher UI advertiser UI and or video player can be executed at a client device to establish a network connection via network . The network connection can be used to communicate packetized data representing video content between the client device and server . Server can provide one or more of renditions of video content with overlays to client devices in response to requests for the video content corresponding to the renditions 

For example sever can provide a rendition of requested video content as streaming audiovisual content. Video player can access the streaming audiovisual content by retrieving one or more of renditions via network . Server can provide a rendition as packetized data. Video player can configure the processor to render a retrieved rendition for display on display device .

In response to receiving a request from a client device server and its video overlay matching module can determine overlays and a quality level for a rendition of video content to be retrieved by video player . Video overlay matching module can apply one or more of the video overlay matching criterion to generate a rendition including overlays deemed relevant to the requested video content. In certain embodiments properties of the requesting client device can also be used by video overlay matching module to select overlays. For example if a particular client device is a mobile device overlays related to mobile device s products and services can be inserted into the rendition provided to the client device . Also for example in response to determining that a requesting client device is located in a given geographic region or physical location i.e. based on a Global Positioning System GPS location of the client device a media access control MAC address of the client device a network address of the client device or other identifying information server can provide a rendition of the requested video content with overlays deemed pertinent to the determined location or time zone. Server can also determine an ideal quality level for a rendition based at least in part on determining current communication capabilities network connectivity i.e. download speed and or a hardware profile of the requesting client device .

Video advertising system requires protocols that make it possible to show both a video and separate advertisement media inside video player . illustrates how video advertising system is implemented using such protocols. Other advantages of architecture and overlay placement system include the ability to directly modify video content to render edited video content including placed and transformed overlays. In this way embodiments disclosed herein can display renditions of video content with overlays without requiring protocols such as those used in video advertising system .

As shown in in video advertising system the flow for placing a video advertisement requires several steps and interfaces. In step a video player submits an advertisement request by making an advertisement call to advertisement server . Then in step advertisement server responds with an Extensible Markup Language XML file including a reference to an advertisement and a video advertisement XML parsing module parses the XML file to retrieve the reference to the advertisement. Step and other steps shown in do not incorporate results of any calculations regarding where to place an advertisement. In contrast to video advertising system another advantage of overlay placement system is that calculations can be used to automatically determine unobtrusive locations to place an overlay. Next in step video player retrieves advertisement media referred to in the XML file and renders the advertisement media. According to video advertising system displaying advertisement media typically requires a set of parameters from video player which can require interaction between the video advertisement XML parsing module and video player using an application programming interface API . In video advertising system an API is required for any pre roll advertisement media that runs a script or any interactive clickable advertisement media. In step video player fires impression and activity reporting beacons. Lastly in step the advertisement media is rendered.

In video advertising system a protocol between video player and the advertisement is required. The protocol includes methods that the advertisement must implement and video player must call the methods when certain events occur. Examples of such methods are resizeAd startAd stopAd pauseAd resumeAd collapseAd expandAd. In video advertising system an advertisement can only implement special behavior such as resizing when a method is explicitly called. For example when the screen size on which an advertisement appears changes an advertisement can dynamically choose its layout depending on the available area by implementing this functionality in the resizeAd method. Other advantages of overlay placement system and methods and described below with reference to is that the system and methods do not require the protocol or method calls needed in video advertising system .

In displays are shown with various icons command regions windows toolbars menus and buttons that are used to initiate action invoke routines upload video content upload overlays preview video content select video content for viewing or invoke other functionality. The initiated actions include but are not limited to uploading new video content entering editing video properties deleting video content uploading overlays previewing video content selecting video content for viewing controlling playback of video content and other video and overlay related inputs. For brevity only the differences occurring within the figures as compared to previous or subsequent ones of the figures are described below.

In embodiments the display devices used to display the user interfaces shown in may be displayed via the display interface and the computer display described below with reference to . In certain embodiments the UIs can be configured to be displayed on a touch screen display device . According to embodiments a publisher advertiser and or viewer user can interact with the UIs shown in using input devices such as but not limited to a stylus a finger a mouse a keyboard a keypad a joy stick a voice activated control system or other input devices used to provide interaction between a user and the UIs. As described below with reference to such interaction can be used to indicate an overlay or video asset to be uploaded to navigate through multiple overlays or previously uploaded video assets and to select a video asset to be viewed.

As shown in administrator user interface includes a pane with a videos list . Videos list includes previously uploaded video assets and indicates their properties. In an embodiment videos list is displayed in response to change video information link in publisher menu being selected. In the example embodiment illustrated in for each asset in videos list a preview thumbnail is displayed along with a title description keywords and a URL indicating where the video asset is located. The preview thumbnail includes at least one frame of the video asset and can optionally be implemented as an animated icon that changes over time i.e. is not static . One type of animated icon displays a sequence of frames from the video asset i.e. as a slide show . In some embodiments animation of an animated icon does not necessarily require user interaction or user stimulus and the animation occurs on its own. For example a preview thumbnail can be configured to play e.g. once or repeatedly at least some portion of its associated video content. In one embodiment different points in time or snapshots of the video content are shown in the preview thumbnail. In various embodiments animation is triggered or activated by an input device or mouse rollover i.e. having a mouse stylus finger or other input device hover over or near a preview thumbnail without necessarily clicking on or selecting the thumbnail . In some embodiments an animation plays only once in response to detecting a rollover or hover. In alternative or additional embodiments the video content is played or looped until the rollover or hovering ends i.e. the cursor pointer or input focus is no longer hovering over or near the preview thumbnail .

Videos list also includes an edit link and a delete link for each listed video asset. A publisher user can edit properties of a video asset by using an input device to click edit link . By selecting using an input device delete link a publisher user can delete a video asset from videos list . In certain embodiments such a deletion triggers deletion of the video asset from overlay placement system and its database . If the deletion is successful the publisher user can be informed via an indication within administrator user interface an email message or other communications means.

Administrator user interface also includes an overlay provider menu labeled as an Ads menu in the non limiting example embodiment of which has an add image link and an overlay list link labeled Ads list in the example shown in . After providing login credentials and authenticating to overlay placement system an advertiser user can launch administrator user interface and select using an input device add image link in order to launch a dialog box not shown which allows the publisher to select a local image for an overlay to be uploaded into overlay placement system . By interacting with administrator user interface an advertiser user can select a local image file for an advertisement and enter additional upload information such as but not limited to tags keywords related to the product service and or brand that is the subject of the advertisement. The new overlay is then uploaded in response to a selection of an upload button not shown . One embodiment indicates within administrator user interface whether the overlay was successfully uploaded or not. Other embodiments communicate upload status to the advertiser user via an email message a Short Message Service SMS text message or other communications means.

Although not shown in an embodiment of administrator user interface also includes a pane with an overlay list that is similar to the videos list depicted in and described above. Akin to videos list the overlay list includes previously uploaded overlays and indicates their properties. In one embodiment the overlays list is displayed in response to overlay list link in overlay provider menu being selected. As with videos list a preview thumbnail for each overlay can be displayed along with tags keywords associated with each overlay. Overlay list also includes edit link and delete link for each listed overlay. An advertiser user can edit properties of an overlay by using an input device to click edit link . When an overlay provider no longer wishes to have an overlay placed into video content an advertiser user can select using an input device delete link to delete such an overlay from the overlays list. In certain embodiments deletion of an overlay from the overlays list triggers deletion of the overlay from overlay placement system and its database . If the deletion is successful the advertiser user can be informed via an indication within administrator user interface an SMS message an email message or other communications means.

Besides being usable to control playback of a currently selected video video player user interface allows a viewer user to navigate a videos list to preview select and view other video content. As seen in the videos list can include a preview thumbnail and video properties for a suggested or Random video. In the example embodiment illustrated in for each video asset in the videos list a preview thumbnail is displayed along with video properties including a title description keywords and a URL indicating where the video asset is located. The preview thumbnail includes at least one frame of the listed video asset and can optionally be implemented as an animated icon that displays at least a portion of the associated video content as described above with reference to videos list shown in FIG. . In cases where the preview thumbnail is implemented as an animated icon overlays inserted into a rendition of the video content being previewed can optionally be displayed. For example if a frame or frames of the video content being previewed include inserted overlays those overlays can also be displayed within the preview thumbnail. As seen in video properties of video content in the video list include a clickable actionable link that a viewer user can select using an input device to view a listed video asset.

If there are limited or no predicted locations that the particular overlay size will fit into overlay placement system can optionally present suggested locations where a resized overlay can fit along with the relative monetary and or salience costs of placing the resized overlay in each of the suggested locations. For example in cases where the resized overlay has a smaller size than the original size overlay placement system can also present the lower monetary and or salience cost of placing the smaller resized overlay . Additionally in cases where multiple predicted locations have been identified video overlay matching module can choose the location that also results in a favorable color combination with the specific overlay . Also if multiple predicted locations have been identified video overlay matching module can optionally present the costs of placing the overlay within each of the locations within a UI so that an advertiser user can manually select one of the locations.

Saliency for frames of video content can be calculated in order to detect how salient regions in the frames are. The saliency of regions can be mapped in a saliency map such as the exemplary saliency map shown in . In one embodiment a 2D Fourier transform for an input image such as frame or of video content is computed. Then complex values resulting from the 2D Fourier transform are normalized such that each complex value has a modulus 1. Next an inverse Fourier transform is performed. This way components that appear frequently are reduced while discontinuities are enhanced see e.g. discontinuity in . As a frequent component in the spatial domain corresponds to a greater coefficient at the corresponding position in a frequency domain normalization will lead to diminution of that complex number from the frequency domain and will also lead to suppression of periodical components. In certain embodiments multiple channels can be used to compute saliency by using complex numbers. These embodiments can detect discontinuities by using a generalized Fourier transform such as for example a Quaternion Fourier transform. Quaternions represent generalizations of complex numbers and can take the form Q a b i c j d k where a b c and d are real numbers. By using Quaternions embodiments are able to integrate discontinuities over different maps channels in a natural way. For example three of the four available channels can be used for static image analysis while the fourth channel can incorporate temporal information through the difference between frames where channel 1 represents pixel intensity channel 2 represents red green contrast channel 3 represents yellow blue contrast and channel 4 represents t intensity t 1 that models the motion in the given frame as compared to the previous frame. Regarding channel 3 and red green contrast although the intensity of a red and a green color might be the same red areas contrast with green areas. After executing the above described saliency algorithm for an image such as video frame saliency map is obtained. Embodiments use the saliency maps for multiple video frames to determine the relative salience of regions of the frames where salience quantifies the presence of important objects within the regions.

According to embodiments saliency calculations and maps are based in part on attention modeling. Modeling viewer user attention can be an important consideration in overlay placement because knowing where a viewer user is likely to look or has looked represents an essential clue of knowing a good placement for an overlay. In one embodiment saliency based visual attention modeling is performed for rapid analysis of scenes of video content. In one embodiment multiple feature maps are generated for different type of features in the following way given a feature e.g. intensity a region is deemed to be salient if the feature value in that region is very different compared to surrounding regions in the video frames. For each kind of feature multiple maps are generated by using multiple resolutions sizes at least three different sizes can be considered for center region and for each of these at least two sizes are considered for surrounding regions resulting in a number of at least six maps for each feature. In certain embodiments the features used are intensity color contrast considering red green and yellow blue contrast and orientation considering 0 45 90 and 135 degrees of local orientations . In this way attention modeling can obtain at least six maps for intensity at least twelve maps for color and at least twenty four maps for orientation. These maps can then be combined into a single saliency map such as saliency map .

According to embodiments one or more of the following methods can be employed to compose saliency maps. Simple summing all maps are normalized to a 0 1 interval and then directly added. This is a baseline method and does not typically offer robust results. Normalization according to this technique saliency maps having a prominent maximum compared to other local maxima in the same saliency map become more important. As a result if one feature one point is determined to be very salient then this feature is deemed to be more important than other less salient features. Iterative normalization this technique is similar to normalization except that it is a more biologically related method which can sometime return better results than normalization. Normalization may not be biologically plausible because it uses a global maximum while the neurons in the cortex of a viewer user s brain responsible for analyzing visual signal are known to be only locally connected. As the name implies with iterative normalization an iterative strategy is used that attenuates the regions or zones of frames for which vicinities i.e. adjacent regions in the frames are similar. The iterative normalization technique starts with a saliency map which is normalized into 0 1 and then performs attenuation intensification of some regions in the end the map will not be in 0 1 anymore therefore this method can be viewed as a procedure for offering different weights to different saliency maps . Lastly a learning weights technique can be employed. This is a weight updating strategy that takes into account how well each saliency map emphasizes an identified target in video content. By training for a specific target within video content the saliency maps that better represent or identify that target will receive bigger weights e.g. if the target is red and the background is always green then the color map within the saliency map will become more important .

Certain embodiments use a data driven approach for computing the salience map . Eye tracking data can be recorded for viewer users on a plurality of frames of video content. In order to obtain continuous saliency maps from the eye fixation points frames can be convolved with a Gaussian kernel at each fixation point. A number at least ten positive and at least ten negative of example pixels can be randomly extracted from each frame for training purposes. These points can be obtained from each frame by applying a threshold on the saliency map obtained from eye tracking data considering top 20 pixels as positive examples fixated and bottom 70 as negative examples. In certain embodiments three types of features can be used low level features e.g. contrast orientation midlevel features a classifier can be used to determine pixels on the horizon line high level features using a face detection algorithm such as for example the Viola Jones algorithm . Besides these observations that viewer user gazes tend to be concentrated at the center of the frame was used by taking into account the position of the pixel. All these features can be fed into a Support Vector Machine classifier.

The exemplary attention modeling methods described in the following paragraphs use saliency values and are indirectly related to overlay placement system . These attention modeling techniques can be used in conjunction with the overlay placement system described above with reference to and the methods described below with reference to . Embodiments use saliency in order to retarget frames on different displays e.g. mobile client devices such as tablet computers smart phones laptop computers and portable DVD players . Certain of these embodiments use an attention model that detects the Attention Objects AOs . Each AO is described by the following values ROI region of interest AV attention value and MPS minimal perceivable size . ROI indicates the area where the object is and it is represented as a shape such as a rectangle . AV gives the importance of the object and MPS indicates how small the object can be made while still preserving its characteristics. According to these embodiments saliency maps are generated as described above and then they are combined using iterative normalization strategy described above. When a saliency map is available the AV at each pixel is computed by multiplying each pixels saliency with its brightness and then a Gaussian template is applied knowing that people tend to look at the center of the frame. The MPS of each salient region can be heuristically computed larger regions can be scaled more aggressively . Besides saliency the attention modeling also incorporates top down semantic information by identifying faces and text. These are deemed to attract more attention although they may not be salient from a bottom up perspective . The AV of each face takes into account the face size and position larger faces and faces detected in the center of a frame have a higher AV . In one embodiment the MPS for faces can be fixed at 25 30 750 pixels. Also text can be taken into account. For example the AV of a text region can take into account the text area and the aspect ratio. Text position may not be deemed to be important just the presence of text is determined. In an embodiment a rule based system can be employed to assign weights to these different sources. For example if there are faces with a very high AV then the weight of the face component becomes large. For retargeting embodiments seek to optimize an information fidelity formula that tells how much information is preserved for each AO if its size is too small using MPS then its AV is set to 0.

One embodiment computes a visual attention model for video content skimming by extending a salience map or model for video content analysis. In this embodiment an attention curve is generated in order to perform video content skimming. Video skimming refers to extracting the highlights of a video asset such as a movie. According to this embodiment saliency is used for region based frame retrieval. First in order to calculate salience at each pixel in frames the following algorithm can be used any pixel x is compared to all pixels y in some region zone or neighborhood taking into account color and orientation. The more different the feature in a specific pixel as compared to surrounding pixels the more salient it is deemed. After this step the salient objects are detected. In order to obtain these objects the frame is transformed in grayscale and segmented. Next using entropy theory some video content segments with a high salience are selected. These segments are joined into objects. Finally in order to compute the score of a frame in database this score is used to rank the frames in database for performing a subsequent retrieval from database for each salient object in the original frame the most similar one in the current database frame is detected and a similarity measure is saved or recorded. These values are added resulting therefore in a score for each frame in database .

Embodiments can detect surprising events in video content and can improve temporal placement of overlays based on the detected surprising events. Certain embodiments detect surprising events in video content based on saliency maps and as part of attention modeling. These embodiments define a surprise framework to incorporate elements from two complementary domains saliency and novelty. Here saliency can represent outliers in the spatial domain while novelty works with the temporal domain of video content. In the novelty framework one approach is to assume that each pixel s intensity in a frame comes from a mixture of Gaussians distribution. This way in a video scene containing for example trees waving in wind a new wind gust or change of direction might not cause much novelty whereas a pedestrian or other important object appearing in the video scene would be successfully detected. Embodiments assume that probability distribution is not known beforehand. Instead a Bayesian framework can be used so that every new piece of information in video content frames changes the probability distribution that models what the users expect to see. Divergence between the distributions before and after the new information is seen is used as a measure of how much novelty the information contains.

Other embodiments can employ a user attention model for video summarization. According to these embodiments there are two types of video summarization static video abstract and dynamic video skimming. Static video abstract attempts to obtain a set of key frames from video content that are representative. Dynamic video skimming seeks to find a set of video clips video and audio within video content that represent the entire video asset with a much smaller total length in frames or duration . These embodiments use a framework for video summarization both static and dynamic that treat video content as containing three types of information visual audio and linguistic. Different saliency maps are generated from one or more of these different sources and they are combined in order to generate an attention curve for the video content. The attention curve can be smoothed and the parts of the video asset around local maxima can be used as summary.

The method begins in step where a saliency map is computed for multiple frames of video content . This step can comprise computing a saliency map similar to saliency map for multiple frames as described above with reference to . After the saliency map is computed for the frames control is passed to step .

In step an auxiliary matrix is computed. The auxiliary matrix can be used in method to suggest optimal locations for placing an overlay by minimizing the sum of pixel saliencies which are covered by the overlay over the frames that the overlay appears in. Computing an auxiliary matrix from the saliency map in order to efficiently calculate the salience cost total saliency covered of each placement wherein the auxiliary matrix is obtained by cumulating saliency values can be done starting from the top left pixel of the first frame. One embodiment of step calculates or computes the auxiliary matrix as Auxiliary X Y T sum saliency x y t where the summation is through all x in 1 2 . . . X y in 1 2 . . . Y and t in 1 2 . . . T or 

Certain embodiments may only consider a subset of frames in order to speed up calculations by sampling video content and computing the auxiliary matrix and the saliency maps only for those sampled frames e.g. 5 frames per second . In one embodiment step only considers frames for which salience was calculated and mapped in step . In order to find and suggest an overlay position that minimizes salience cost step can verify each possible placement restricting the overlay to start from one of the frames with computed saliency and suggest or automatically choose a location which leads to a minimal salience value. In order to efficiently compute the salience cost of a given overlay placement step can comprise computing an auxiliary matrix which takes O W H T to compute where W and H represent the dimensions at which the video content is processed and T is the duration or length of the video content in terms of the number of frames . In certain embodiments the auxiliary matrix is computed only once and each placement is evaluated in O 1 . In this embodiment there are O W H T possible placements therefore the overall complexity of this algorithm is O W H T . The auxiliary matrix is constructed in step in order to be able to obtain the salience cost of any placement in O 1 . An exemplary auxiliary matrix is a three dimensional matrix which contains at position x y t the sum of the saliencies of all the pixels in the 1 1 x y rectangle for all video frames from 1 to t. Using the inclusion exclusion principle step is able to calculate the total salience in an arbitrary video volume determined by a possible placement using only a few additions and subtractions in O 1 complexity. In an embodiment step can be performed by video overlay matching module and can be executed by processor of server . After the auxiliary matrix is constructed control is passed to step .

Next in step an overlay size is taken. Initially this can be one of the standard overlay sizes shown in or another size in pixels a given overlay has. After the overlay size is taken control is passed to step .

In step the salience cost for possible placements i.e. locations for the overlay is computed. In one embodiment step first computes the salience cost total saliency covered of every placement i.e. every possible location of an overlay in video content given the overlay size and duration . There can potentially be several hundred million or billions of potential overlay placement locations in one video asset. In one embodiment based at least in part on the auxiliary matrix constructed in step step rapidly calculates unobtrusiveness values of all locations within frames of video content . The computation of salience costs and calculations of unobtrusiveness values can be made quickly through use of the auxiliary matrix. After computing the saliency costs control is passed to step .

In step locations determined to have the lowest salience costs in step are suggested. In this step a plurality of locations e.g. 5 locations with smallest saliency costs are determined. In one embodiment these locations can be shown to a user such as an advertiser user who can then select one of the plurality of locations as the location for the overlay. In alternative embodiments where a fully automated overlay placement is sought a location having the lowest salience cost is selected in step without presenting suggested locations to a user. That is step can find the position with the lowest salience cost and then place the overlay accordingly.

Next in step a determination is made as to whether there are additional overlay sizes and or more overlays to insert. In some embodiments method is only used to determine one final placement for each overlay without resizing the overlay. If it determined that there are additional sizes or overlays control is passed back to step . Otherwise if it is determined that there are no more overlays to place or overlay sizes to select control is passed to step where method ends.

The method begins at step where video content and an indication of overlays are received. This step can comprise receipt of uploaded video assets and overlays at server via publisher UI and advertiser UI and video and overlay processing performed by video processing module and overlay processing module as described above with reference to .

Next in step locations are determined for one or more overlays received in step and salience costs are calculated. In certain embodiments step can comprise allowing overlays to change their position in video content. Changing the position may allow an overlay to avoid overlapping salient regions that could not otherwise be avoided. One procedure for step is to set a speed variable for each overlay penalizing large velocities. The saliency cost function can be defined as Cost salience 

Step can use a stochastic algorithm that tries various random locations starting moment position speed evaluates the salience cost for each of the locations and selects the best performing location. In an embodiment step can be performed by video overlay matching module and creating a saliency map as described above with reference to .

In addition to finding an optimal position for a single overlay in video content an embodiment of step can find locations for multiple overlays in the same video content. One embodiment uses the following greedy selection strategy in order to place multiple overlays in a video first the optimal location is chosen for a first overlay of the one more overlays received in step . In one embodiment overlays can be considered in the order received in step . In another embodiment overlays are considered in the order matched by an overlay selection made by video overlay matching module which can be based at least in part on the color respective color palettes schemes of the overlays and the video content. Locations for each overlay are then determined by only considering the positions that do not overlap with previously placed overlays or other overlays. Overlays are considered to overlap if they appear in the same time i.e. same frames or if the spatial distance in pixels or temporal distance in time or frames between the overlays is below a predefined tunable threshold. In one embodiment an administrator tunable temporal threshold is 1 second. By using this greedy selection strategy step will determine locations such that either overlays do not overlap or more than one overlay will not appear at the same time i.e. in the same frame in video content.

In one embodiment step can also use scene segmentation information obtained from video processing done by video processing module in order to avoid determining locations for overlays that will result in the overlays cross the boundaries between scenes i.e. span multiple scenes or DVD chapters . Timestamp data i.e. in milliseconds for scene and chapter transitions stored in database for video content by video processing module can be used to determine temporal overlay locations that will not span scenes and chapters.

In additional or alternative embodiments step can comprise estimating high interest scenes in order to determine overlay locations in such high interest scenes. For example scenes generating a high interest can be determined based in part on highly dynamic color changes. In cases where there are faster changes in color from one frame to the next frame as compared to other frame sequences in video content the frames with faster more dramatic color changes can be deemed to comprise part of high interest scenes in the video content. After locations for the one or more overlays are determined control is passed to step in cases where the locations are to be presented to a user for manual selection control is passed to step in cases where overlay transformations are to be performed in a fully automated implementation of method or to step in fully automated implementations of method without overlay transformations.

In optional step a plurality of the locations determined in step are presented to a user within a UI as suggested locations. In embodiments step presents an administrator tunable finite number of the highest ranked locations to an advertiser user within administrator UI . In one non limiting embodiment the default number of suggested locations is five. In fully automated overlay placement methods steps are skipped.

In optional step selections of locations for overlays are received and control is optionally passed to step . In an embodiment step can be performed by receiving a selection of a location to place each of the one or more overlays from an advertiser user interacting with administrator UI .

In step transformations for overlays are identified. If it is determined that the overlays need to be or can be transformed to better fit with video content control is passed to step where the identified transformations are applied.

In step the transformations identified in step are applied to the overlays. As described above with reference to the transformations can include spatial i.e. reshaping color translucency transparency and or resizing transformations. In embodiments step can comprise applying two main types of effects so that an overlay fits better into video content received in step . The first type includes spatial transformations that move the corners of an overlay so that it fits better into the context of video content and then apply affine transformation which makes the rectangular overlay become a reshaped overlay with new corners. The second type includes color transformations such as gradually increasing the transparency of the overlay as a function of proximity to edges of the overlay thus making a smooth transition between the overlay and surrounding portions of frames of video content.

Next in step the overlay is placed within the video content at the selected or automatically identified location in order to create edited video content. In an embodiment step can be performed by delivering the overlays to viewer users via HyperText Markup Language 5 HTML5 using the tag or video element of HTML5. This embodiment allows the use of Cascading Style Sheets CSS Shaders which define a filter effects extensibility mechanism and provide rich easily animated visual effects to HTML5 content. In particular it allows applying vertex and fragment shading controls directly on HTML elements including image and video elements in HTML5. In one embodiment this step results in creation of a rendition of the video content to be delivered via network to a video player executing on a client device . After the overlay is placed control is passed to step where method ends.

Numerous specific details are set forth herein to provide a thorough understanding of the claimed subject matter. However those skilled in the art will understand that the claimed subject matter may be practiced without these specific details. In other instances methods apparatuses or systems that would be known by one of ordinary skill have not been described in detail so as not to obscure claimed subject matter.

Although exemplary embodiments have been described in terms of charging apparatuses units systems and methods it is contemplated that certain functionality described herein may be implemented in software on microprocessors such as a processors and included in the client devices and server respectively shown in and computing devices such as the computer system illustrated in . In various embodiments one or more of the functions of the various components may be implemented in software that controls a computing device such as computer system which is described below with reference to .

Aspects of the present invention shown in or any part s or function s thereof may be implemented using hardware software modules firmware tangible computer readable media having logic or instructions stored thereon or a combination thereof and may be implemented in one or more computer systems or other processing systems.

If programmable logic is used such logic may execute on a commercially available processing platform or a special purpose device. One of ordinary skill in the art may appreciate that embodiments of the disclosed subject matter can be practiced with various computer system configurations including multi core multiprocessor systems minicomputers mainframe computers computers linked or clustered with distributed functions as well as pervasive or miniature computers that may be embedded into virtually any device.

For instance at least one processor device and a memory may be used to implement the above described embodiments. A processor device may be a single processor a plurality of processors or combinations thereof. Processor devices may have one or more processor cores. 

Various embodiments of the invention are described in terms of this example computer system . After reading this description it will become apparent to a person skilled in the relevant art how to implement the embodiments using other computer systems and or computer architectures. Although operations may be described as a sequential process some of the operations may in fact be performed in parallel concurrently and or in a distributed environment and with program code stored locally or remotely for access by single or multiprocessor machines. In addition in some embodiments the order of operations may be rearranged without departing from the spirit of the disclosed subject matter.

Processor device may be a special purpose or a general purpose processor device. As will be appreciated by persons skilled in the relevant art processor device may also be a single processor in a multi core multiprocessor system such system operating alone or in a cluster of computing devices operating in a cluster or server farm. Processor device is connected to a communication infrastructure for example a bus message queue network or multi core message passing scheme. In certain embodiments one or more of the processors and described above with reference to overlay placement system server and client devices of can be embodied as the processor device shown in .

Computer system also includes a main memory for example random access memory RAM and may also include a secondary memory . Secondary memory may include for example a hard disk drive removable storage drive . Removable storage drive may comprise a magnetic tape drive an optical disk drive a flash memory or the like. In non limiting embodiments one or more of the memories and described above with reference to server and client devices of can be embodied as the main memory shown in .

The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit may comprise a magnetic tape optical disk etc. which is read by and written to by removable storage drive . As will be appreciated by persons skilled in the relevant art removable storage unit includes a non transitory computer readable storage medium having stored therein computer software and or data.

In alternative implementations secondary memory may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means may include for example a removable storage unit and an interface . Examples of such means may include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system . In non limiting embodiments one or more of the memories and described above with reference to server and client devices of can be embodied as the main memory shown in .

Computer system may also include a communications interface . Communications interface allows software and data to be transferred between computer system and external devices. Communications interface may include a modem a network interface such as an Ethernet card a communications port a PCMCIA slot and card or the like. Software and data transferred via communications interface may be in the form of signals which may be electronic electromagnetic optical or other signals capable of being received by communications interface . These signals may be provided to communications interface via a communications path . Communications path carries signals and may be implemented using wire or cable fiber optics a phone line a cellular phone link an RF link or other communications channels.

As used herein the terms computer readable medium and non transitory computer readable medium are used to generally refer to media such as memories such as main memory and secondary memory which can be memory semiconductors e.g. DRAMs etc. . Computer readable medium and non transitory computer readable medium can also refer to removable storage unit removable storage unit and a hard disk installed in hard disk drive . Signals carried over communications path can also embody the logic described herein. These computer program products are means for providing software to computer system .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs may also be received via communications interface . Such computer programs when executed enable computer system to implement the present invention as discussed herein. In particular the computer programs when executed enable processor device to implement the processes of the present invention such as the steps in the methods and illustrated by the flowcharts of discussed above. Accordingly such computer programs represent controllers of the computer system . Where an embodiment of the invention is implemented using software the software may be stored in a computer program product and loaded into computer system using removable storage drive interface and hard disk drive or communications interface .

In an embodiment the display devices used to display interfaces of video player publisher UI and or advertiser UI may be a computer display shown in . The computer display of computer system can be implemented as a touch sensitive display i.e. a touch screen . Similarly the user interfaces shown in may be embodied as a display interface shown in .

Embodiments of the invention also may be directed to computer program products comprising software stored on any computer readable medium. Such software when executed in one or more data processing device causes a data processing device s to operate as described herein. Embodiments employ any computer readable medium. Examples of computer useable mediums include but are not limited to primary storage devices e.g. any type of random access memory secondary storage devices e.g. hard drives floppy disks CD ROMS DVDs ZIP disks tapes magnetic storage devices and optical storage devices MEMS nanotechnological storage device etc. and communication mediums e.g. wired and wireless communications networks local area networks wide area networks intranets etc. .

Numerous specific details are set forth herein to provide a thorough understanding of the claimed subject matter. However those skilled in the art will understand that the claimed subject matter may be practiced without these specific details. In other instances methods apparatuses or systems that would be known by one of ordinary skill have not been described in detail so as not to obscure claimed subject matter.

Some portions are presented in terms of algorithms or symbolic representations of operations on data bits or binary digital signals stored within a computing device memory such as a computer memory. These algorithmic descriptions or representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. An algorithm is a self consistent sequence of operations or similar processing leading to a desired result. In this context operations or processing involves physical manipulation of physical quantities. Typically although not necessarily such quantities may take the form of electrical or magnetic signals capable of being stored transferred combined compared or otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to such signals as bits data values elements symbols characters terms numbers numerals or the like. It should be understood however that all of these and similar terms are to be associated with appropriate physical quantities and are merely convenient labels. Unless specifically stated otherwise it is appreciated that throughout this specification discussions utilizing terms such as processing computing calculating determining and identifying or the like refer to actions or processes of a computing device such as one or more computers or a similar electronic computing device or devices that manipulate or transform data represented as physical electronic or magnetic quantities within memories registers or other information storage devices transmission devices or display devices of the computing platform.

The system or systems discussed herein are not limited to any particular hardware architecture or configuration. A computing device can include any suitable arrangement of components that provide a result conditioned on one or more inputs. Suitable computing devices include multipurpose microprocessor based computer systems accessing stored software that programs or configures the computing device from a general purpose computing apparatus to a specialized computing apparatus implementing one or more embodiments of the present subject matter. Any suitable programming scripting or other type of language or combinations of languages may be used to implement the teachings contained herein in software to be used in programming or configuring a computing device.

Embodiments of the methods disclosed herein may be performed in the operation of such computing devices. The order of the steps presented in the examples above can be varied for example steps can be re ordered combined and or broken into sub steps. Certain steps or processes can be performed in parallel.

The use of adapted to or configured to herein is meant as open and inclusive language that does not foreclose devices adapted to or configured to perform additional tasks or steps. Additionally the use of based on is meant to be open and inclusive in that a process step calculation or other action based on one or more recited conditions or values may in practice be based on additional conditions or values beyond those recited. Headings lists and numbering included herein are for ease of explanation only and are not meant to be limiting.

While the present subject matter has been described in detail with respect to specific embodiments thereof it will be appreciated that those skilled in the art upon attaining an understanding of the foregoing may readily produce alterations to variations of and equivalents to such embodiments. Accordingly it should be understood that the present disclosure has been presented for purposes of example rather than limitation and does not preclude inclusion of such modifications variations and or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.

