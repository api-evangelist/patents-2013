---

title: Methods and systems for electronic ink projection
abstract: Embodiments of the present disclosure provide methods for transmitting to a display communicatively coupled to a second device electronic ink input data received from a first device. Specifically, embodiments disclosed herein provide translating electronic ink input data based upon one or more output parameters associated with a display. Once the electronic ink input data is translated, electronic ink output data is generated. In certain embodiments, a stream of the electronic ink output data is transmitted to the display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09535646&OS=09535646&RS=09535646
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09535646
owner_city: Redmond
owner_country: US
publication_date: 20130621
---
This application claims priority to U.S. Provisional Patent Application Ser. No. 61 836 466 entitled Methods and Systems for Electronic Ink Projection filed on Jun. 18 2013 which is hereby incorporated by reference in its entirety.

Modern presentation methods and systems rely heavily upon interactive tools for interacting with information within a presentation. Such interactive tools may be utilized with presentation software word processing software and other applications used to present information. Traditionally the use of an application program in a social setting such as a classroom lecture conference or other shared activity involves the transmission of the application program running on a computer to a display such as an external monitor or projector. With the advent of various wired and wireless protocols and standards including but not limited to the Bluetooth and IEEE 802.11 standards connections between various devices make possible a level of interaction beyond the use of interactive tools such as the laser pointer or mouse cursor that are typically used for interacting with information within a presentation.

It is with respect to these and other general considerations that embodiments have been made. Also although relatively specific problems have been discussed it should be understood that the embodiments should not be limited to solving the specific problems identified in the background.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detail Description section. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Embodiments of the present disclosure provide methods for transmitting to a display communicatively coupled to a second device electronic ink input data received from a first device. Specifically embodiments disclosed herein provide translating electronic ink input data based upon one or more output parameters associated with a display. Once the electronic ink input data is translated electronic ink output data is generated. In certain embodiments a stream of the electronic ink output data is transmitted to the display.

Embodiments may be implemented as a computer process a computing system or as an article of manufacture such as a computer program product or computer readable media. The computer program product may be computer storage media readable by a computer system and encoding a computer program of instructions for executing a computer process.

Various embodiments are described more fully below with reference to the accompanying drawings which form a part hereof and which show specific exemplary embodiments. However embodiments may be implemented in many different forms and should not be construed as limited to the embodiments set forth herein rather these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the scope of the embodiments to those skilled in the art. Embodiments may be practiced as methods systems or devices. Accordingly embodiments may take the form of a hardware implementation an entirely software implementation or an implementation combining software and hardware aspects. The following detailed description is therefore not to be taken in a limiting sense.

In embodiments described herein electronic ink e ink and ink refer generally to data representing or recognized as input received from a user s interaction with a touchscreen touch sensitive display or gesture based interface or input device e.g. including but not limited to gesture sensing technology such as technology utilized within the KINECT device by MICROSOFT of Redmond Wash. . Although embodiments within the remainder of this specification describe use of touch sensitive displays e.g. including touchscreens one of skill in the art will recognize that gesture based input devices that is devices that recognize input based upon gestures from hand movement facial movement arm movement and other various types of gesture based input are possible and contemplated within the full inventive scope of this disclosure. In one non limiting example e ink may refer to data representing the X Y coordinates shape pressure or other characteristics of input received from a user interacting with a touchscreen. In another non limiting example e ink may refer to data representing an interpretation of vector graphics or presentation objects drawn on a touch sensitive display. In embodiments described herein a display refers generally to a visual output device. One of ordinary skill in the art will appreciate that display may refer a variety of visual output devices including but not limited to displays utilizing LED LCD CRT plasma and OLED display technology. As described herein displays may incorporate one or more computing devices or components of computing devices including but not limited to processors memory communications interfaces and wireless hardware including technology conforming to various standards such as the Bluetooth and IEEE 802.11 standards. One of skill in the art will further recognize that one or more application programming interfaces APIs may be utilized to represent recognize and or interpret e ink data.

Based on the above the embodiments described herein describe systems and methods for transmitting e ink input data between computing devices for presentation of the e ink input data on one or more displays. That is a user s input with a touch sensitive input device e.g. a mobile phone or tablet computer is typically processed by the device such that the user input may be represented as e ink input data. Accordingly when e ink input data is received by the device the device may transmit the e ink input data to another device or display in order to display the e ink input data e.g. overlaying a currently displayed presentation or application program. For example a mobile device may generate e ink input data in response to receiving touch input from a user. The mobile device may then transmit the e ink input data to another device such as a computer hosting an active presentation such as a presentation within a POWERPOINT application program by MICROSOFT of Redmond Wash. Upon receiving the e ink input data from the mobile device the computer hosting the active presentation displays the e ink input data on an external display projecting the presentation.

In embodiments the first device is a mobile computing device e.g. a mobile phone tablet or laptop computer that includes a touch sensitive display. In an embodiment the first device is communicatively connected to second device via a wireless connection . Further to this embodiment the first device and second device may display in part or in whole a common or shared view or session of an application program such as POWERPOINT WORD or INTERNET EXPLORER application programs by MICROSOFT of Redmond Wash. In an embodiment upon interacting with the touch sensitive display by a user the first device detects the interaction s and processes the interaction s as touch input data. In embodiments the touch input data may represent a series of X Y coordinates detected from the user interaction with the touch sensitive display. For example the touch input data may comprise a data stream of X Y coordinates or information representing the same that represents the interaction of the user with the application program displayed on the first device . In other embodiments the touch input data may represent vector graphics objects or other program or input data that represents the interaction of the user with the application program displayed on the first device . For example the user may interact with the application program on the first device such that the user draws or otherwise interacts with the touch sensitive display displaying a presentation associated with the application program.

In an embodiment the first device may transmit a stream of touch input data to second device which may receive and process the stream of touch input data. In an embodiment a stream of touch input data may be processed to extract or otherwise identify the user s drawing or interaction with the touch sensitive display of the first device . In one embodiment processing may comprise extracting or identifying X Y coordinates that correspond to the user s touch input. In another embodiment processing may comprise extracting or identifying shapes such as vector graphics including the dimensions location characteristics or other properties of such graphics. For example the stream of touch input data may include information identifying the color pressure stroke or shape associated with the touch input or effects e.g. post processing by the first device associated with a user s drawing or interactions with the touch sensitive display of the first device . As another example the stream of touch input may include information identifying the positional dimensional geographic or temporal characteristics of vector graphics or other touch input data associated with the user s drawing or interactions with the touch sensitive display of first device .

In an embodiment second device processes the received touch input data into a data stream for transmission to a display such as for example display . For example processing of the received touch input data from first device may comprise formatting the touch input data for rendering the received data stream on the display . The processing may comprise adjusting e.g. increasing or decreasing the resolution or other display characteristics of the received touch input data stream to correspond to a profile or other display characteristics associated with the display . For example the viewable dimensions of display may be different than the dimensions of the touch sensitive display of the first device and thus may require processing to account for the difference in dimensions between the touch sensitive display and display . As another example the touch input data stream may be received such that it corresponds to a video standard or protocol that may require adjustment or translation into another video standard or protocol for displaying the touch input data on display . As yet another example the touch input data stream may be processed in order to align the touch input with temporal characteristics such as a time duration or period associated with the display of a presentation on the display . In another example the touch input data stream may be processed to identify modify highlight or manipulate presentation objects that may correspond to the presentation objects being displayed by the second device on display . One of skill in the art will recognize that other types of translation and processing are encompassed within the scope of processing by the second device as discussed herein.

Once the ink input data is received flow proceeds to operation in which the ink input data is translated or otherwise processed for display on a different display e.g. a display different from the display communicatively coupled to a device that transmitted the received ink input data stream in operation . In an embodiment translation of the ink input data comprises extracting and analyzing X Y coordinates against one or more characteristics of a display device and or the touch sensitive display or device or both that transmitted the ink input data. For example translation of ink input data may comprise extracting X Y coordinates. The X Y coordinates may correspond to a touch sensitive display having more or less resolution than a display intended for output of the ink input data. In the event an output display has a resolution greater than the touch sensitive display translation of the X Y coordinates may comprise applying algorithms for interpolating expanding or otherwise improving the resolution of points or lines between lower resolution X Y coordinates received from the touch sensitive display. It is also contemplated that translation of X Y coordinates may comprise applying algorithms for reducing the resolution of points or lines where for example the X Y coordinates are received from a touch sensitive display having greater resolution than an output display. In other embodiments translation may comprise alteration of the properties e.g. width texture color pressure stroke shape brush shape fill outlining highlighting etc. of the received ink input data. In another embodiment translation may comprise identifying presentation objects e.g. geometric patterns charts headings text boxes media or other objects that correspond to objects from an application program displaying the presentation on an output display. In yet another embodiment translation of ink input data may comprise recognizing the ink input data and passing through the received ink input data in a format or manner that is substantially similar or the same as how it was received in operation .

Flow of method then proceeds to operation in which ink output data is generated. In an embodiment generation of ink output data comprises integrating ink input data received from operation with a presentation for display. In an embodiment the presentation is actively displayed. In another embodiment the presentation may be later displayed on a display device. In an embodiment the display is a device different from the touch sensitive display and or device from which the received ink input data was received. For example generation of ink output data may comprise an application program such as POWERPOINT incorporating the ink output data as part of an output e.g. a slideshow presentation of slides for presentation on one or more displays. It is also contemplated that generation of ink output data may comprise packaging the translated ink input data from operation into an output stream data structure or package of data for transmission to a display. Generation of the ink output data may comprise preparing or conforming the translated ink input data to one or more standards for display on one or more connected displays.

Once the ink output data is generated flow proceeds to operation in which the ink output data is transmitted to one or more displays. In an embodiment transmission of the ink output data comprises sending the ink output data integrated with or incorporated within data for display of a presentation on one or more display devices. Further to this embodiment the ink output data may be comprised within or as part of an output e.g. a slideshow presentation of slides for presentation on one or more displays. It is also contemplated that the ink output data may be transmitted separate from or interleaved with a presentation transmitted to one or more displays.

In embodiments as discussed previously the second device processes touch input data received from first device . For example processing of the received touch input data from first device may comprise formatting the touch input data for rendering the received data stream on the display . The processing may comprise adjusting e.g. increasing or decreasing the resolution or other display characteristics of the received touch input data stream to correspond to a profile or other display characteristics associated with the display . For example the touch input data stream may be processed in order to align the touch input with temporal characteristics such as a time duration or period associated with the display of a presentation on the display . In another example the touch input data stream may be processed to identify modify highlight or manipulate presentation objects that may correspond to the presentation objects being displayed by the second device on display . One of skill in the art will recognize that other types of translation and processing are encompassed within the scope of processing by the second device as discussed herein.

In an embodiment sixth device comprises a computing device that hosts a presentation within an application program and displays the presentation on a display . In embodiments the plurality of devices e.g. a first device a second device a third device a fourth device and an Nth device where each device comprises a touch sensitive display may transmit a plurality of streams of touch input data to sixth device . In an embodiment the sixth device may receive and process the plurality of streams of touch input data. In an embodiment the plurality of streams of touch input data are processed to extract or otherwise identify a user s drawing or interaction with the plurality of touch sensitive displays corresponding to the plurality of devices e.g. a first device a second device a third device a fourth device and an Nth device . Extraction and identification of a user s drawing or interaction may comprise highlighting with different or identifying colors text or objects each of the plurality of streams of touch input data received from the plurality of devices e.g. a first device a second device a third device a fourth device and an Nth device . For example the sixth device may prepare a touch output data stream or incorporate within the presentation itself such that the touch input data received from a subset of the plurality of devices e.g. first device and second device is highlighted in one color and the touch input data received from another subset of the plurality of devices e.g. third device and fourth device is highlighted using a different color or colors.

It is contemplated that the interaction of the plurality of devices with the sixth device may be synchronous or asynchronous such that the processing and or display of touch input data may depend upon a certain or relative ordering or timing. It is further contemplated that the interactions of the plurality of devices with the sixth device may be either bi directional or uni directional not shown such that when uni directional the plurality of devices would transmit touch input data for display on display in a collaborative many to one e.g. students teacher audience presenter etc. environment. For example the system may comprise an audience participation environment that enables a user from one or more of the plurality of devices e.g. a first device a second device a third device a fourth device and an Nth device to write questions highlight draw upon or otherwise interact with a presentation that is hosted on sixth device and displayed on display .

In an embodiment processing by the sixth device may comprise extracting or identifying X Y coordinates that correspond to a plurality of user touch input. In another embodiment processing may comprise extracting or identifying shapes such as vector graphics including the dimensions location characteristics or other properties of such graphics. For example as discussed previously the streams of touch input data may include information identifying the color pressure stroke or shape associated with the touch input or effects e.g. post processing by the first device associated with a drawing or interaction e.g. a user s interaction with the touch sensitive display of the first device . As another example the stream of touch input may include information identifying the positional dimensional geographic or temporal characteristics of vector graphics or other touch input data associated with a drawing or interaction e.g. a user s drawing or interaction with the touch sensitive display of first device .

In an embodiment the plurality of devices e.g. the first device the second device the third device the fourth device and the fifth device comprise computing devices that may host a presentation session within one or more application programs. For example the plurality of devices e.g. a first device a second device a third device a fourth device and a fifth device may share a peer to peer or other collaborative network connection via the network such that one or more of the plurality of devices may interactively and or asynchronously interact with e.g. share data between one or more of the other plurality of devices. In an embodiment the plurality of devices e.g. the first device the second device the third device the fourth device and the fifth device are connected via wired or wireless not shown connections to a plurality of displays e.g. the first display the second display the third display and the fourth display . In embodiments respective ones of the plurality of devices e.g. the first device the second device the third device the fourth device and the fifth device particularly where each of the respective ones of the plurality of devices comprise a touch sensitive display may transmit a plurality of streams of touch input data to respective others of the plurality of devices. In an embodiment one or more of the plurality of displays e.g. the first display the second display the third display and the fourth display may further comprise a computing device incorporated within the one or more of the plurality of displays.

In an embodiment one or more of the plurality of devices e.g. the first device the second device the third device the fourth device and the fifth device and those of the displays e.g. the first display the second display the third display and the fourth display that incorporate a computing device may process as discussed previously a plurality of streams of touch input data received from one or more of the plurality of devices and the plurality of displays. It is contemplated that the interaction of the plurality of devices with the plurality of displays may be synchronous or asynchronous such that the processing and or display of touch input data may depend upon a certain or relative ordering or timing. It is further contemplated as discussed previously that the interactions of the plurality of devices and the plurality of displays may be either bi directional or uni directional not shown such that bi directional interactions may exist between one or more of the plurality of devices and one or more of the plurality of displays in a collaborative many to many e.g. classroom conference etc. environment. For example the system may comprise a participatory environment that enables real time interaction that permits participating users to write questions highlight draw upon or otherwise interact with a shared presentation.

In an embodiment the second device comprises a computing device that hosts a presentation session within one or more application programs. Further to this embodiment the second device may share a peer to peer or other collaborative network connection via the network such that one or more of the displays e.g. first display second display third display and fourth display may interactively and or asynchronously interact with e.g. share data between the second device . In an embodiment the first device and the second device or both as the case may be may transmit a plurality of streams of touch input data to one or more of the displays e.g. first display second display third display and fourth display where the displays are displaying a presentation from an application program hosted by the first device or second device or both . In an embodiment one or more of the plurality of displays e.g. the first display the second display the third display and the fourth display may further comprise a computing device incorporated within the one or more of the plurality of displays.

As discussed previously it is contemplated that the interaction of the plurality of devices e.g. the first device and the second device with the plurality of displays e.g. first display second display third display and fourth display may be synchronous or asynchronous such that the processing and or display of touch input data may depend upon a certain or relative ordering or timing. It is further contemplated as discussed previously that the interactions of the plurality of devices and the plurality of displays may be either bi directional or uni directional not shown such that bi directional interactions may exist between one or more of the plurality of devices and one or more of the plurality of displays in a collaborative few to many e.g. classroom conference etc. environment. For example the system may comprise a participatory environment that enables real time interactions between first device and second device possibly including one or more of the plurality of the displays incorporating a computing device such that the real time interactions are displayed on the plurality of displays e.g. first display second display third display and fourth display .

Flow of method then proceeds to operation where the computing device hosting the presentation configures one or more output stream parameters for transmitting data received from an input stream for display on a presentation device. In an embodiment configuring of output stream parameters may comprise adjusting storing or otherwise manipulating data necessary for adjusting the resolution or other display characteristics of a received touch input data stream to correspond to a profile or other display characteristics associated with a presentation device e.g. a display . For example the viewable dimensions of a presentation device may be different than the dimensions of the touch sensitive display of a touchscreen device transmitting the received touch input data stream and thus may comprise configuring output stream parameters e.g. data necessary to process the received touch input data and account for the difference in dimensions between the touch sensitive display and presentation device. As another example where a touch input data stream may be received such that it corresponds to a video standard or protocol that may require adjustment or translation into another video standard or protocol for displaying the touch input data on a presentation device configuring output parameters may comprise adjusting storing or otherwise manipulating data necessary for adjusting or translating or both one or more protocols or standards. As yet another example the touch input data stream may comprise configuring output stream parameters necessary for adjusting storing or otherwise manipulating data for processing to align the received touch input with temporal characteristics of a presentation such as a time duration or period associated with the display of the presentation on a presentation device. In another example configuring output steam parameters may comprise adjusting storing or otherwise manipulating data to identify modify highlight or manipulate presentation objects within a generated output stream. One of skill in the art will recognize that configuring output stream parameters may comprise additional or other types of configuration that are encompassed within the scope of the present disclosure as discussed herein.

Flow of method then proceeds to operation where the computing device hosting a presentation or a presentation session in an application program receives a stream of data comprising at least X Y coordinates from a touchscreen device. For example the receiving of X Y coordinates may comprise receiving data indicating an actual a relative or a computed location of an X Y coordinate from a touch sensitive display. Thus receipt of an X Y coordinate may comprise receiving data representing at least two dimensional values e.g. a data structure representing as integers the X axis and Y axis coordinates that correspond to pixels for example of a touch sensitive display. In another example operation may comprise receiving X Y coordinates as relative data that describes the position of a point line or other touchscreen input data with respect to the relative position of other data such as touchscreen input data. It is contemplated that many types of data structures may be received including but not limited to integer and other arrays two dimensional tables etc.

Flow then proceeds to operation where an output stream is generated by conforming X Y coordinates to the output stream parameters. In an embodiment conforming of X Y coordinates may comprise one or more of adjusting the resolution or display characteristics adjusting the dimensions translating or adjusting for a protocol or standard and aligning the received touch input with temporal characteristics of a presentation such as a time duration or period associated with the display of the presentation on a presentation device. In another embodiment conforming X Y coordinates to output stream parameters may comprise algorithmically or programmatically interpreting the received input stream based upon the output stream parameters. For example conforming X Y coordinates may comprise analyzing X Y coordinates to identify vectors objects lines points and other data. As another example generating an output stream by conforming X Y coordinates to output stream parameters may comprise utilizing an application program other than the application program hosting a presentation. As yet another example generating an output stream by conforming X Y coordinates to output stream parameters may comprise integrating the received X Y coordinate data into the output data stream or application program as the case may be that displays the presentation itself.

In an embodiment the output stream generated by operation comprises data different from the data received at operation . For example a generated output stream may represent the received X Y coordinates using data e.g. vector graphics other than the values e.g. integer values representing the X Y coordinates as received. In an embodiment generation of an output stream may thus comprise conforming X Y coordinates to vector data presentation data or some other type or form of data for displaying touch input based upon the X Y coordinates within the presentation or on the display. In another embodiment generation of an output stream comprises conforming X Y coordinates or data representing the same with respect to a plurality of actual or potential presentation device profiles where each of the actual or potential presentation device profiles may comprise different output parameters corresponding to a plurality of presentation devices. Further to this embodiment generation of an output stream may comprise packaging the conformed X Y coordinates or data representing the same within one or more data structures for transmission to the plurality of the presentation devices.

Method flow then proceeds to operation in which the generated output stream is transmitted to one or more presentation devices. In an embodiment a generated output stream conforming to output stream parameters is transmitted to a single presentation device. In another embodiment a plurality of generated output streams conforming to multiple output stream parameters are transmitted to a plurality of presentation devices. Further to this embodiment transmission to a plurality of presentation devices may comprise conforming a received data stream e.g. a touch input data stream to various different output stream parameters e.g. corresponding to configuration differences of different presentation devices.

Flow then proceeds to operation where an output stream is generated by confirming the stream of vector data to output parameters. In an embodiment generation of an output stream comprises conforming vector data to X Y coordinates presentation data or some other type or form of data for displaying the vector data within the presentation or on the display. In another embodiment generation of an output stream comprises conforming vector data with respect to a plurality of actual or potential presentation device profiles where each of the actual or potential presentation device profiles may comprise different output parameters corresponding to a plurality of presentation devices. Further to this embodiment generation of an output stream may comprise packaging the conformed vector data within one or more data structures for transmission to the plurality of the presentation devices.

Flow then proceeds to operation where an output stream is generated by confirming the stream of presentation data to output parameters. In an embodiment generation of an output stream comprises conforming presentation data to X Y coordinates vector data compatible presentation data or some other type or form of data for displaying the presentation data within the presentation or on the display. In another embodiment generation of an output stream comprises conforming presentation data with respect to a plurality of actual or potential presentation device profiles where each of the actual or potential presentation device profiles may comprise different output parameters corresponding to a plurality of presentation devices. Further to this embodiment generation of an output stream may comprise packaging the conformed presentation data within one or more data structures for transmission to the plurality of the presentation devices.

Flow then proceeds to operation in which the synchronization data is extracted from the input stream. In an embodiment extracting the synchronization data comprises filtering for temporal data that corresponds to touch input data within the input stream. One of skill in the art will recognize that other forms of extraction are possible and within the scope of this disclosure.

Flow then proceeds to operation where a computing device that hosts an active presentation compares the synchronization data against the display of the active presentation. In an embodiment comparison of the synchronization data against the active presentation comprises determining whether the received touch input data is temporally aligned or misaligned e.g. being faster or slower when compared to the temporal status of the active presentation. One of skill in the art will recognize that alignment may comprise comparison of finite temporal values comparison of a range or ranges of temporal values or some combination of finite values and ranges. One of skill in the art will also recognize that an error rate or margin may be relied upon when comparing temporal time values and or ranges such that a finite value or range may or may not exceed a threshold error rate or margin in order to account for processing delays network delays etc.

Flow of method then proceeds to operation in which a determination is made whether the received synchronization data is aligned with an active presentation on the presentation display. In embodiments operation comprises a determination whether synchronization data e.g. one or more timestamps is aligned with a timestamps or other temporal data corresponding to the processing of and or display of a presentation on the presentation display. In an embodiment determination of whether synchronization data aligns with an active presentation may comprise a determination that the synchronization meets a predetermined or threshold alignment value or range. Upon determining that synchronization data is aligned with the display of an active presentation on the presentation display flow proceeds to operation where the touch input data is transmitted to the presentation device. Upon a determination that synchronization data is mis aligned with the display of an active presentation on the presentation display flow proceeds to operation where display of the touch input data is suppressed. In embodiments suppression of touch input data according to operation comprises buffering the touch input data until a subsequent determination is made that the synchronization data aligns with the display of the active presentation. For example buffering of the synchronization data may comprise waiting for a time period e.g. several microseconds until the synchronization data aligns e.g. meets a time value or range with the active presentation.

The embodiments and functionalities described herein may operate via a multitude of computing systems including without limitation wired and wireless computing systems mobile computing systems e.g. mobile telephones netbooks tablet or slate type computers and laptop computers . illustrates an exemplary tablet computing device that may execute one or more embodiments disclosed herein. In addition the embodiments and functionalities described herein may operate over distributed systems e.g. cloud based computing systems where application functionality memory data storage and retrieval and various processing functions may be operated remotely from each other over a distributed computing network such as the Internet or an intranet. User interfaces and information of various types may be displayed via on board computing device displays or via remote display units associated with one or more computing devices. For example user interfaces and information of various types may be displayed and interacted with on a wall surface onto which user interfaces and information of various types are projected. Interaction with the multitude of computing systems with which embodiments of the invention may be practiced include keystroke entry touch screen entry voice or other audio entry gesture entry where an associated computing device is equipped with detection e.g. camera functionality for capturing and interpreting user gestures for controlling the functionality of the computing device and the like. and the associated descriptions provide a discussion of a variety of operating environments in which embodiments of the present disclosure may be practiced. However the devices and systems illustrated and discussed with respect to are for purposes of example and illustration and are not limiting of a vast number of computing device configurations that may be utilized for practicing embodiments of the present disclosure described herein.

As stated above a number of program modules and data files may be stored in the system memory . While executing on the processing unit the program modules may perform processes including for example one or more of the stages of the methods described herein. The aforementioned process is an example and the processing unit may perform other processes. Other program modules that may be used in accordance with embodiments of the present disclosure may include electronic mail and contacts applications word processing applications spreadsheet applications database applications slide presentation applications drawing or computer aided application programs etc.

Generally consistent with embodiments of the present disclosure program modules may include routines programs components data structures and other types of structures that may perform particular tasks or that may implement particular abstract data types. Moreover embodiments of the present disclosure may be practiced with other computer system configurations including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like. Embodiments of the present disclosure may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

Furthermore embodiments of the present disclosure may be practiced in an electrical circuit comprising discrete electronic elements packaged or integrated electronic chips containing logic gates a circuit utilizing a microprocessor or on a single chip containing electronic elements or microprocessors. For example embodiments of the present disclosure may be practiced via a system on a chip SOC where each or many of the components illustrated in may be integrated onto a single integrated circuit. Such an SOC device may include one or more processing units graphics units communications units system virtualization units and various application functionality all of which are integrated or burned onto the chip substrate as a single integrated circuit. When operating via an SOC the functionality described herein may be operated via application specific logic integrated with other components of the computing device on the single integrated circuit chip . Embodiments of the present disclosure may also be practiced using other technologies capable of performing logical operations such as for example AND OR and NOT including but not limited to mechanical optical fluidic and quantum technologies. In addition embodiments of the present disclosure may be practiced within a general purpose computer or in any other circuits or systems.

The term computer readable media as used herein may include computer storage media. Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures or program modules. The system memory the removable storage device and the non removable storage device are all computer storage media examples e.g. memory storage. Computer storage media may include RAM ROM electrically erasable read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other article of manufacture which can be used to store information and which can be accessed by the computing device . Any such computer storage media may be part of the computing device . Computer storage media does not include a carrier wave or other propagated or modulated data signal. The computing device may also have one or more input device s such as a keyboard a mouse a pen a sound input device a touch input device etc. The output device s such as a display speakers a printer etc. may also be included. The aforementioned devices are examples and others may be used.

The term computer readable media as used herein may also include communication media. Communication media may be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may describe a signal that has one or more characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media may include wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency RF infrared and other wireless media. The computing device may include one or more communication connections allowing communications with other computing devices . Examples of suitable communication connections include but are not limited to RF transmitter receiver and or transceiver circuitry universal serial bus USB parallel and or serial ports.

Although described herein in combination with the mobile computing device in alternative embodiments features of the present disclosure may be used in combination with any number of computer systems such as desktop environments laptop or notebook computer systems multiprocessor systems micro processor based or programmable consumer electronics network PCs mini computers main frame computers and the like. Embodiments of the present disclosure may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network in a distributed computing environment programs may be located in both local and remote memory storage devices. To summarize any computer system having a plurality of environment sensors a plurality of output elements to provide notifications to a user and a plurality of notification event types may incorporate embodiments of the present disclosure.

One or more application programs may be loaded into the memory and run on or in association with the operating system . Examples of the application programs include phone dialer programs e mail programs personal information management PIM programs word processing programs spreadsheet programs Internet browser programs messaging programs and so forth. The system also includes a non volatile storage area within the memory . The non volatile storage area may be used to store persistent information that should not be lost if the system is powered down. The application programs may use and store information in the non volatile storage area such as e mail or other messages used by an e mail application and the like. A synchronization application not shown also resides on the system and is programmed to interact with a corresponding synchronization application resident on a host computer to keep the information stored in the non volatile storage area synchronized with corresponding information stored at the host computer. As should be appreciated other applications may be loaded into the memory and run on the mobile computing device .

The system has a power supply which may be implemented as one or more batteries. The power supply might further include an external power source such as an AC adapter or a powered docking cradle that supplements or recharges the batteries.

The system may also include a radio that performs the function of transmitting and receiving radio frequency communications. The radio facilitates wireless connectivity between the system and the outside world via a communications carrier or service provider. Transmissions to and from the radio are conducted under control of the operating system . In other words communications received by the radio may be disseminated to the application programs via the operating system and vice versa.

The visual indicator may be used to provide visual notifications and or an audio interface may be used for producing audible notifications via the audio transducer . In the illustrated embodiment the visual indicator is a light emitting diode LED and the audio transducer is a speaker. These devices may be directly coupled to the power supply so that when activated they remain on for a duration dictated by the notification mechanism even though the processor and other components might shut down for conserving battery power. The LED may be programmed to remain on indefinitely until the user takes action to indicate the powered on status of the device. The audio interface is used to provide audible signals to and receive audible signals from the user. For example in addition to being coupled to the audio transducer the audio interface may also be coupled to a microphone to receive audible input such as to facilitate a telephone conversation. In accordance with embodiments of the present disclosure the microphone may also serve as an audio sensor to facilitate control of notifications as will be described below. The system may further include a video interface that enables an operation of an on board camera to record still images video stream and the like.

A mobile computing device implementing the system may have additional features or functionality. For example the mobile computing device may also include additional data storage devices removable and or non removable such as magnetic disks optical disks or tape. Such additional storage is illustrated in by the non volatile storage area .

Data information generated or captured by the mobile computing device and stored via the system may be stored locally on the mobile computing device as described above or the data may be stored on any number of storage media that may be accessed by the device via the radio or via a wired connection between the mobile computing device and a separate computing device associated with the mobile computing device for example a server computer in a distributed computing network such as the Internet. As should be appreciated such data information may be accessed via the mobile computing device via the radio or via a distributed computing network. Similarly such data information may be readily transferred between computing devices for storage and use according to well known data information transfer and storage means including electronic mail and collaborative data information sharing systems.

One skilled in the relevant art may recognize however that the embodiments may be practiced without one or more of the specific details or with other methods resources materials etc. In other instances well known structures resources or operations have not been shown or described in detail merely to avoid obscuring aspects of the embodiments.

The description and illustration of one or more embodiments provided in this application are not intended to limit or restrict the scope of the invention as claimed in any way. The embodiments examples and details provided in this application are considered sufficient to convey possession and enable others to make and use the best mode of claimed invention. The claimed invention should not be construed as being limited to any embodiment example or detail provided in this application. Regardless of whether shown and described in combination or separately the various features both structural and methodological are intended to be selectively included or omitted to produce an embodiment with a particular set of features. Having been provided with the description and illustration of the present application one skilled in the art may envision variations modifications and alternate embodiments falling within the spirit of the broader aspects of the general inventive concept embodied in this application that do not depart from the broader scope of the claimed invention.

