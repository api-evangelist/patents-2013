---

title: Monochromatic edge geometry reconstruction through achromatic guidance
abstract: Many imaging scenarios involve an achromatic image (e.g., a panchromatic image or a near-infrared image) and one or more concurrently captured monochromatic images (e.g., RGB images captured through a Bayer filter array), and the compositing of these images through de-mosaicing and/or pan-sharpening to generate a high-resolution color image. However, in many such scenarios, the monochromatic images may exhibit distortion of edge geometry, resulting in artifacts and/or color distortions near visual edges of the composite image. However, such distortions may be absent from the achromatic image, and edge geometry may be represented as an intensity gradient among respective neighborhoods of achromatic pixels. Presented herein are techniques for reducing such distortions in monochromatic images through iterative adjustment of monochromatic pixel intensity to reflect the gradients of the neighborhoods of the corresponding achromatic pixels. Convergence of such adjustments produces composite images exhibiting accurately reconstructed edge geometry.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09224362&OS=09224362&RS=09224362
owner: Microsoft Technology Licensing, LLC
number: 09224362
owner_city: Redmond
owner_country: US
publication_date: 20130314
---
Within the field of imaging many scenarios involve the generation of a composite image using a set of monochromatic images such as images captured by respective image sensors respectively positioned behind red green and blue color filters of a Bayer filter array. In many such scenarios the pixels of respective input monochromatic images may represent a mosaic and each achromatic pixel of a composite image may be generated through a de mosaicing calculation based on the set of corresponding monochromatic pixels in approximately the same position of the monochromatic images. However many such techniques may result in chromatic inaccuracies or artifacts as the reconstruction of the captured color of each composite pixel from the mosaic of captured monochromatic images may not precisely and accurately reflect the relevant portion of the visible spectrum.

In addition many such scenarios also involve an input achromatic image captured through a different image sensor such as a panchromatic image captured by an unfiltered image sensor that captures a large range of the achromatic spectrum or an infrared or near infrared image captured by an image sensor positioned behind an infrared passing or near infrared passing filter. As a first example the inclusion of achromatic pixels of the achromatic image with the corresponding monochromatic pixels may facilitate accurate per pixel color reconstruction. For example the luminance of a panchromatic pixel may be compared with the composite luminance of the respective monochromatic pixels and a proportional scaling may be applied to adjust the intensity of the monochromatic pixels to match the luminance of the panchromatic pixel. As a second example the monochromatic image may be captured with a higher resolution than the monochromatic images. A pan sharpening technique may be utilized to combine the color data from the lower resolution monochromatic images and the higher resolution of the monochromatic image to produce a high resolution color composite image. As a third example in some types of imaging an achromatic image may capture particular types of information that are not fully captured by the monochromatic images. For example in aerial photography infrared and near infrared images may more accurately reflect edge detail of trees and bodies of water than monochromatic images and the composite image may result in more accurate edge detail for such objects. For these and other reasons many cameras and image processing techniques may utilize a combination of monochromatic and achromatic images to generate composite images having various advantageous properties.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A particular feature of monochromatic imaging that may significantly affect the quality of a composite image generated through de mosaicing and or pan sharpening is a subtle loss of geometry among the objects captured through monochromatic filters. For example the particular shapes orientation and alignment of edges may be distorted by the linear interpolation involved in composite image generation techniques. The resulting composite images may exhibit various forms of visual artifacts around the edges such as Moir patterns and color inaccuracies. However such inaccuracies may not be present in achromatic images. Additionally such edge detail may be exhibited by gradients among neighboring pixels in the achromatic image. Adjusting the pixels of the monochromatic images to according to gradients among neighboring pixels of the achromatic image may produce a composite image exhibiting reduced the edge geometry distortion from the monochromatic images.

Presented herein are techniques for generating a composite image from a set of monochromatic images and an achromatic image that reflect a reconstruction of edge geometry higher chromatic accuracy and a reduction of visual artifacts. In accordance with these techniques the pixels of the monochromatic images may be subjected to an adjustment of the monochromatic pixels to reflect a gradient exhibited in the corresponding pixel and neighboring pixels e.g. a 3 3 grid of the achromatic image. Additionally such adjustment may be performed iteratively incrementally adjusting the monochromatic pixels to reflect the gradient of the achromatic pixels until a convergence of the adjustment is achieved. The present disclosure provides several variations in such techniques as well as mathematical formulae expressing particular calculations that may enable a suitable iterative adjustment in accordance with the techniques presented herein.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Within the field of imaging many scenarios involve the generation of a composite image from a set of monochromatic images. For example many cameras comprise a series of image sensors respectively positioned behind a color filter that transmits light within a particular narrow monochromatic range and a compositing component that combines the color data from the monochromatic images to generate a full color composite image. In particular for each pixel of the composite image such cameras may capture a mosaic of monochromatic pixels such as a grid or cluster of nearby monochromatic pixels and may de mosaic the cluster to produce the full color pixel of the composite image.

Moreover many such scenarios may also supplement the compositing with a different type of image. As a first example a camera may include a panchromatic image that captures light across the visible spectrum e.g. an image sensor not positioned behind a chromatic filter and the compositing may factor the pixels of the panchromatic image into the compositing. For example the monochromatic pixels factored together may unevenly and or incompletely reflect the full range of visible light intensities. The camera may reduce inaccuracies in the intensity of respective composite pixels by comparing the sum of the intensities of the monochromatic pixels and the intensity of the corresponding panchromatic pixel and proportionally scaling the monochromatic pixel intensities to equalize this comparison. As a second example in some types of imaging such as aerial photography particular image details may not be fully captured by the particular monochromatic images such as the edges of trees and or bodies of water. Therefore the camera may also capture an infrared or near infrared image that more accurately captures such details and the compositing of each pixel in the composite image may factor in the corresponding infrared or near infrared pixel in addition to the monochromatic pixels. As a third example some cameras may include monochromatic image sensors that capture comparatively low resolution images and a panchromatic image sensor that captures a high resolution image e.g. in order to reduce the cost or data volume of the monochromatic image sensors since chrominance resolution may be less noticeable or significant for image quality than luminance resolution. Accordingly various compositing techniques pan sharpening techniques may involve factoring together the respective and corresponding low resolution pixels of the monochromatic images to calculate the color for more than one pixel of the panchromatic image to generate a high resolution full color composite image.

As illustrated in the exemplary scenario of many cameras may be configured to utilize a variety of image sensors to capture monochromatic images and one or more achromatic images and may composite the images in order to enhance properties such as color accuracy brightness edge contrast and or resolution.

However one property that many such techniques may not adequately address is a distortion of edge geometry of monochromatic images . In imaging because the contrast of visual edges may be reflected more significantly in luminance than chrominance a composite image composited from monochromatic images may not accurately reflect the geometry of visual edges within the scene and linear interpolation techniques for reconstructing the image of the scene may therefore inaccurately reflect some details of such edges including the shape orientation and or alignment of such edges. The resulting composite image may therefore exhibit some visual artifacts around the edges such as a subtle mottling or speckling of color along visual edges within the composite image .

It may further be noted that an achromatic image of the same scene that focuses on capturing luminance rather than chrominance may be less susceptible to such inaccuracies as the edge geometry may present more significant luminance contrast. Additionally if the achromatic image is captured with higher resolution more data may be available that enables a more precise calculation of such edge geometry. However many compositing techniques utilized by such cameras may not account for such differential accuracy in the achromatic image as compared with the monochromatic images . For example rather than using the more accurate edge details in the achromatic image to detect and reduce the edge inaccuracies in the corresponding pixels of the monochromatic images such compositing techniques may simply factor the corresponding pixels together e.g. as an arithmetic average . That is in such other techniques the adjustment of the monochromatic pixels may only relate to the corresponding achromatic pixel and may obscure rather than conform with the edges and edge details that are encoded in the achromatic image . Accordingly the inaccuracies in the monochromatic images may persist and appear in the composite image .

Presented herein are techniques for generating a composite image composited from one or more monochromatic images and an achromatic image e.g. a panchromatic image or an infrared or near infrared image that include a reconstruction of edge geometry. In accordance with these techniques and as further depicted in the exemplary scenario of it may be appreciated that in the achromatic image an edge may be represented as a gradient of intensity within a neighborhood of the achromatic pixel . Accordingly for each composite pixel in the composite image the corresponding monochromatic pixels of the monochromatic images may be compared not only with the intensity of the corresponding achromatic pixel in the achromatic image but with a gradient of the neighborhood of the achromatic pixel in the achromatic image . Moreover for respective pixels of the composite image an iterative process may be performed to adjust the intensities of the respective corresponding monochromatic pixels of the monochromatic images to reflect the gradient exhibited in the neighborhood of the corresponding achromatic pixel of the achromatic image . This iterative processing may be performed a desired number of times e.g. a fixed number of iterations or until an adjustment convergence is detected and the adjusted monochromatic pixels may be factored together to produce the composite pixel of the composite image .

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. Such computer readable media may include e.g. computer readable storage media involving a tangible device such as a memory semiconductor e.g. a semiconductor utilizing static random access memory SRAM dynamic random access memory DRAM and or synchronous dynamic random access memory SDRAM technologies a platter of a hard disk drive a flash memory device or a magnetic or optical disc such as a CD R DVD R or floppy disc encoding a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein. Such computer readable media may also include as a class of technologies that are distinct from computer readable storage media various types of communications media such as a signal that may be propagated through various physical phenomena e.g. an electromagnetic signal a sound wave signal or an optical signal and in various wired scenarios e.g. via an Ethernet or fiber optic cable and or wireless scenarios e.g. a wireless local area network WLAN such as WiFi a personal area network PAN such as Bluetooth or a cellular or radio network and which encodes a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein.

An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In a first such embodiment the processor executable instructions may be configured to perform a method of generating a composite image from a monochromatic image and at least one monochromatic image such as the exemplary method of . In a second such embodiment the processor executable instructions may be configured to implement systems for generating a composite image from a monochromatic image and at least one monochromatic image such as the image generating component in the exemplary camera illustrated in the exemplary scenario of . Some embodiments of this computer readable medium may comprise a computer readable storage medium e.g. a hard disk drive an optical disc or a flash memory device that is configured to store processor executable instructions configured in this manner. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary method of and or the exemplary camera of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized.

As a first variation of this first aspect the techniques presented herein may be utilized with many types of image processing devices such as cameras servers server farms workstations laptops tablets mobile phones game consoles and network appliances. Such image processing devices may also provide a variety of computing components such as wired or wireless communications devices human input devices such as keyboards mice touchpads touch sensitive displays microphones and gesture based input components automated input devices such as still or motion cameras global positioning service GPS devices and other sensors output devices such as displays and speakers and communication devices such as wired and or wireless network components. Additionally the image processing device may perform the compositing in realtime or near realtime e.g. promptly upon capturing the achromatic image and the at least one monochromatic image or may perform the compositing at a later time e.g. for stored images that were previously captured .

As a second variation of this first aspect these techniques may be utilized in many types of imaging scenarios involving at least one achromatic image and at least one monochromatic image such as aerial imaging low light imaging underwater imaging long exposure imaging such as astronomical photography short exposure imaging time lapse imaging three dimensional and or stereoscopic imaging motion photography such as video and motion capture imaging image recognition imaging such as medical and or security imaging machine vision microscopic imaging such as electron microscopy optical character recognition and gesture recognition.

As a third variation of this first aspect the monochromatic images may respectively involve data from many monochromatic ranges of the visible or invisible electromagnetic spectrum. Additionally the monochromatic image sensors may capture the monochromatic images in many ways such as an array of photosensitive elements that are sensitive only to narrow ranges of the electromagnetic spectrum and filters positioned between the scene and the image sensor .

As a fourth variation of this first aspect the achromatic image may involve achromatic image types e.g. data from many ranges of the visible or invisible electromagnetic spectrum. For example the achromatic image may comprise a panchromatic image representing a panchromatic image type representing a full spectrum luminance intensity. Alternatively the achromatic image may comprise specific visible and or invisible ranges of the electromagnetic spectrum such as an infrared image type or a near infrared image type. That is the achromatic image may encode or include a chrominance component but the techniques presented herein may not use the chrominance component in the adjustment of the monochromatic pixels . Many such spectral ranges may be captured to generate a suitable achromatic image that exhibits gradients usable to reconstruct edge geometry in the at least one monochromatic image . These and other scenarios may be suitable for the application of the techniques presented herein.

A second aspect that may vary among embodiments of these techniques involves the manner of adjusting the monochromatic pixels in view of the gradients exhibited by a neighborhood of the corresponding achromatic pixel .

As a first variation of this second aspect the adjusting may involve various neighborhoods of the achromatic pixel . As a first such example the neighborhood may comprise the directly laterally adjacent set of achromatic pixels e.g. the two achromatic pixels to the left and right of the selected achromatic pixel and or the two achromatic pixels above and below the selected achromatic pixel . As a second such example the neighborhood may comprise the laterally and diagonally adjacent achromatic pixels tot the selected achromatic pixel e.g. a 3 3 grid . As other such examples the neighborhood may comprise a larger grid e.g. a 5 5 grid and or a differently shaped grid e.g. a 3 5 grid . As a fourth such example the gradient may attribute achromatic pixel weights to the neighboring achromatic pixels e.g. based on the magnitude of the gradient e.g. the difference in luminance intensity between the selected achromatic pixel and the neighboring achromatic pixels and or the distance from the selected achromatic pixel to the neighboring achromatic pixel . As a fifth such example gradients may be actively identified in the achromatic image e.g. using an edge detection technique and such edges may be used to adjust the monochromatic pixels of respective monochromatic images .

As a second variation of this second aspect the dimensions of the monochromatic images and or achromatic image may vary both generally and relative to one another. The adjustment may account for such variable dimensions in various ways. As a first such example a monochromatic image may have a lower resolution than the composite image to be generated and respective monochromatic pixels may be factored into more than one composite pixel e.g. distributing the chrominance of a monochromatic pixel fractionally over at least two composite pixels . Conversely the monochromatic image may have a higher resolution than the composite image to be generated and at least two monochromatic pixels may be factored into one composite pixel e.g. averaging the chrominance of such monochromatic pixels optionally with a fractional weight based on the degree of overlap .

As a second example of this second variation a first monochromatic image may comprise a different number of monochromatic pixels corresponding to a composite pixel than the number of corresponding monochromatic pixels in a second monochromatic image . For example in an exemplary Bayer color filter array respective composite pixels are computed from a 2 2 block of monochromatic pixels comprising one red monochromatic pixel one blue monochromatic pixel and two green monochromatic pixels . In order to factor respective monochromatic pixels proportionately into the composite pixel where at least one selected monochromatic image has at least two monochromatic pixels corresponding to respective composite pixels of the composite image to be generated the adjustment of the monochromatic pixels may involve adjusting the at least two monochromatic pixels of the selected monochromatic image according to not only the gradient between the achromatic pixel and neighboring achromatic pixels of the neighborhood but also according to a monochromatic pixel weight that is inversely proportional to a count of the monochromatic pixels of the selected monochromatic image corresponding to the composite pixel . For example in monochromatic images captured according to the Bayer color filter with twice as many green pixels respective green pixels may be factored into the composite pixel with a 50 monochromatic pixel weight as compared with the red monochromatic pixel and the corresponding blue monochromatic pixel .

As a third variation of this second aspect the adjustment of the monochromatic pixels may involve a smoothing weight constant that affects the rate of adjustment of the monochromatic pixels in view of the gradient of the neighborhood of the corresponding achromatic pixel . For example a first smoothing weight may result a more aggressive smoothing that tightly adjusts the monochromatic images toward the gradient of the achromatic image while a second smoothing weight may result in a more gradual and or conservative smoothing. In addition it may be advantageous to select the smoothing weight constant in view of various properties of the achromatic image and or the monochromatic images such as a noise level present in one or several such images. Moreover in some embodiments the smoothing weight constant may be selected by a user of a camera or an image processor while other embodiments may automatically select the smoothing weight constant e.g. in view of a detected noise level of one or more images .

As a fourth variation of this second aspect the adjusting may be applied once or for a specific selected number of iterations. Alternatively the adjusting may be iteratively applied until an adjustment convergence is detected e.g. where a measurement of the adjustment of the monochromatic pixels satisfies a convergence threshold. Such convergence may be detected e.g. based on the magnitude of the adjustments of the monochromatic pixels in respective iterations and or based on a degree of conformity of the monochromatic images and the gradients apparent in the achromatic image .

As a fifth variation of this second aspect the adjusting may be performed according to various calculations. The following mathematical formulae provide some examples of suitable embodiments implementing various aspects and variations of the techniques presented herein.

As a first example of this fifth variation during respective increments of the adjusting the monochromatic pixels of respective monochromatic images may be adjusted according to a first mathematical formula comprising 

As a second example of this fifth variation the adjustment of the monochromatic pixels of respective monochromatic images may be adjusted according to a third mathematical formula comprising 

As a third example of this fifth variation the adjustment of the monochromatic pixels may involve calculating the gradient of the neighborhood of the corresponding achromatic pixel and the smoothing weight constant according to a fourth mathematical formula comprising 

As a fourth example of this fifth variation after completing the adjusting the composite pixels of the composite image may be computed from the adjusted monochromatic pixels according to a fifth mathematical formula comprising 

wherein trepresents a final iteration resulting in an adjustment convergence of the monochromatic pixels e.g. adding back in the intensity of the achromatic pixel that was removed during the initial iteration . These and other variations and mathematical formulae may be applied to achieve the adjusting of the monochromatic pixels in view of the gradients in the neighborhood of the corresponding achromatic pixel in view of the techniques presented herein.

A third aspect that may vary among embodiments of the techniques presented herein involves the generation of the composite image from the adjusted monochromatic pixels .

As a first such variation in addition to more accurate edge geometry and a reduction of visual artifacts the techniques presented herein may result in various effects for the composite image . As a first such example the factoring of the monochromatic pixels during these techniques may result in a de mosaicing of the monochromatic pixels e.g. factoring a 2 2 cluster of red green and blue pixels generated by a Bayer filter array into a full color composite pixel . As a second such example the adjustment of the monochromatic pixels factored together with the achromatic pixels of a potentially higher resolution achromatic image may result in a pan sharpening of the composite image .

As a second such variation various other image processing techniques may be performed before during or after the adjusting of the monochromatic pixels and or the generation of the composite image . As one such example an embodiment may also apply an edge preservation calculation to the composite image such as an anisotropic diffusion edge preservation calculation a bilateral filtering edge preservation calculation and or as vectorial total variation edge preservation calculation. These and other additional calculations and results may result in the composite image generated according to the techniques presented herein.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB Firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

