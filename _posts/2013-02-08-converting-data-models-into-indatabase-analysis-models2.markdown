---

title: Converting data models into in-database analysis models
abstract: Data sets are analyzed to discover trends and determine predictive data models. A data model is determined based on analyzing the data set with a specific algorithm from a set of different analytical algorithms. The data model is stored in a structural file format. The data model is converted into an instantiated object model with the use of a predefined object model. The instantiated object model is converted into an in-database analysis model to score new data within a database system. The scoring is based on the logic in the data model. The in-database analysis model is stored on a database server part of a database system to provide analytical functionality defined in the data model. The new data can be scored with the in-database analysis model. The new data is not extracted from the database system and the scoring is accomplished in-memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09552403&OS=09552403&RS=09552403
owner: SAP SE
number: 09552403
owner_city: Walldorf
owner_country: DE
publication_date: 20130208
---
Data mining and statistical analysis enable users to build predictive models and discover hidden insights in their data. Predictive analysis encompasses a number of analytic techniques. For example large quantities of data can be explored and analyzed by automatic or semi automatic means to discover meaningful patterns and rules present in the analyzed data. Examples of predictions are focused on different challenges such as forecasting future performance sales and costs definition of key influencers trend determination in a business field determination of existing relationships in the analyzed data determination of existing anomalies etc.

Organizations can gain business value by exploring transactional data typically generated within the enterprise or from unstructured data created by external sources e.g. social media historical records . Data used for analysis may be stored in data repositories or databases. For generating a data model based on data an analysis is performed and an algorithm is applied over the data which may be pulled out of the database. Once the data model is created it may be used over new data to make predictions for future events. There are a number of algorithms that can be used when creating the data model decision trees regression factor analysis cluster analysis time series neural nets association rules etc. Such algorithms are provided by different vendors and may be consumed in a data mining application for analysis. For example the open source statistical and data mining language and environment the statistical programming language R provides data scientists with a lot of analytic possibilities. The introduction of in memory technology has reduced the time and cost of data processing. The in memory technology allows working with data stored in random access memory RAM for processing without the traditional data retrieval from the database system. In such manner predictive analysis can be performed against vast volumes of data in real time.

Embodiments of techniques for converting data models into in database analysis models are described herein. In the following description numerous specific details are set forth to provide a thorough understanding of the embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail.

Reference throughout this specification to one embodiment this embodiment and similar phrases means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one of the one or more embodiments. Thus the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

In various embodiments raw data may be obtained analyzed and processed to discover dependencies and to produce structured data. Raw data refers to data that is not modified or processed in any way and exists in a form that the data has been collected. Structured data refers to data that has been analyzed and a structure of the elements of the data connections or relationships between the data elements have been determined. For example structured data may be database data data found in reports and others. Elements of structured data may have relationships with other elements in the data.

In one embodiment the historical data may be read from a data source and be prepared for analysis. The data source storing the historical data may be a data repository. Also the historical data may be stored in a file format such as a Comma Separated Values CSV file format. For accurate results data may need to be prepared and processed before analysis. The preparation steps applied on the analyzed data may be accomplished within the data mining application . In one embodiment the data mining application may include a data preparation component responsible for applying the data preparation steps over the read historical data . In one embodiment data preparation involves checking data for accuracy and missing fields filtering data based on range values filtering data to extract inconsistent or unsuitable data sampling the data to investigate a subset of data manipulating data etc. When a model is created by a data mining application outside of any database such as data mining application the created model the data model may be used over new data stored in an exemplary database system. In one embodiment the data mining application may extract the new data from the database and score the new data with the data model .

For example if we want to make a segmentation analysis the algorithm that may be applied over the data may be a Classification aNd Regression CNR tree algorithm such as the R CNR Tree algorithm provided by the R statistical language. An R CNR Tree model may be generated. Applying the R CNR Tree algorithm hidden insights in the data may be revealed. In another embodiment the data used for the analysis may also be filtered before applying the algorithm. Different properties of the R CNR Tree model such as Output Mode Independent Columns Dependent Columns etc. may be defined within a Properties section part of the data modeling environment . Based on the generated R CNR Tree model a model may be stored within a Saved Models section part of the Components section.

Once a model is created it may be used to make predictions for new data. In one embodiment the model may be considered as a reusable component by training an algorithm using historical data and saving the instance. Typically models may be created to share computed business rules that can be applied to similar data. Another example of a reason to store a generated data model is to use a trained instance of an algorithm without the presence of the historical data which is used for generating the data model. The process of using the model is distinct from the process that creates the model. The process of using a model to make predictions for future trends behavior is also called scoring . A model is typically used multiple times to score data. Other applications may use the scores that are generated e.g. Enterprise Resource Planning ERP Customer Relationship Management CRM and tools such as OnLine Analytical Processing OLAP and data visualization tools. For example a model may be created to predict the probability that a customer may purchase goods from a supermarket if a catalog with a list of goods on promotion is regularly sent to the mailbox. Having the option to score data within a database using an already existing model inside of a database can make the execution of the analysis faster and less cumbersome in terms of memory and time consumption. In one embodiment the generated R CNR Tree model may be exported together with the information within the model into a file in an industry standard format such as Predictive Modeling Markup Language PMML format JavaScript Object Notation JSON format eXtensible Markup Language XML format other. In this manner the model may be shared with other compliant software applications to perform analysis over similar data based on the already generated model. In another embodiment the generated and saved model may be exported converted in a format which may be executable within a database by applying Export to DB functionality.

In one embodiment the logic in the data model is incorporated within the mark up tags used in the structure of the PMML representation. The given example in Table 1 illustrates a tree structure that defines a cluster analysis over a set of analyzed data such as the R CNR Tree . For example the first child tag of each node tag names CompoundPredicate or SimplePredicate represents the split condition of the tree under that node. The child tags named ScoreDistribution define the distribution of data in that node. The child nodes of the current node if any are presented under the Node tag. A leaf node does not contain any child nodes down in the tree hierarchy. The output of the algorithm is cluster values and is represented as a separate node in the PMML file within the Output tags.

In one embodiment the data model may be converted to the in database model native to a database or a runtime environment. The in database model may be a runtime analysis object. The conversion may be accomplished within a data mining application by using an exporting functionality for example the Export to DB in . For example the data model may be exported dynamically into a runtime object such as the in database model that may provide predictive analysis capabilities within a database system. The generated in database model may contain the logic for scoring a set of data with a model in the same manner as the data model without extracting the data from the database system. The logic incorporated in the in database model may be executed on a database level for example on a database server without pulling the data out of the server. In one embodiment the in database model may be created in the database server and may be consumed through a connection e.g. database connectivity service with the database system thus to utilize the processing power of the database server. Hence database servers may provide predictive analysis capabilities to score data through dynamically created in database models converted from pre existing data models. The in database model may be embedded in an exemplary database server thus providing the database server with the analysis capabilities implemented in the data model . Scoring new data may be done without the need of historical data for replicating the logic in the data model . In one embodiment processing new data according to the in database model can be achieved on a database server as part of a database system.

In one embodiment the list of objects may include a mining schema object a node object a model explanation object extensions object targets object output object. The list of objects is not limited to the above mentioned exemplary objects. In one embodiment the data mining schema may give information about the schema that is used for analysis of a data set e.g. historical data . If the generated model has a tree structure such as the R CNR Tree then the node object may represent a node and nodes characteristics in a tree split. In one embodiment the model explanation object may give information about the type of the model the quality and the confidence level defined for the model. In another embodiment the output object may define the characteristics of the output fields. In yet another embodiment the object model may include properties of the model . The list of properties may include a model name an algorithm name a missing value strategy a no child strategy a split strategy etc.

In one embodiment the object models may be such as the object model in . The instantiated object model may be created based on the accumulated information read from the data model . For example if the data model is in a PMML file format the file can be read into Java as a byte stream and be converted into an instantiated object model implemented in Java. The data model in PMML format can be converted to a programming representation of the data model in Java in the form of the instantiated object model . Defined Java objects in the object model may be used for the conversion between the data model to the instantiated object model . For example the data model presented in a PMML format in Table 1 can be converted to an instance of the object model. The data model in Table 1 is a tree model generated based on the R CNR tree algorithm. Table 2 presents part of exemplary Java code that can be used for the conversion. Through specific Java objects different algorithms are distinguished. Required information is extracted with the use of the parseModel method lines 1 10 Table 1 . A list at line 12 Table 1 is created with the models read from the PMML file and the tree model object treeMdl is extracted from the list.

In one embodiment models defined in PMML may be mapped to specific java objects based on predefined mechanism. The result of the conversion can be a specific algorithm object of a data model implemented in a programming language. The Java code between lines 14 to 25 extracts information from the treeMdl model. The information in the treeMdl object can be used by other Java objects. For example information about the mining schema nodes targets etc. is extracted. The result after the conversion is a collection of objects containing the logic implemented into the data model together with the suggested arithmetic operations. The collection of objects may be used to create entities with similar functioning. The instantiated object model may be an example of the instantiated object model .

The process of executing data intensive logic implemented with an imperative language e.g. Java is hard to optimize. In one embodiment if the application logic is executed mainly on the application server data needs to be copied from the database into the application server. Structured Query Language SQL is a declarative set oriented language that may allow parallelized processing of data stored in rows in a table. The SQLScript language is a collection of extensions to SQL. The extensions may be procedural extensions which provide imperative constructs executed in the context of the database. With the use of SQLScript data intensive application logic may be embedded into the database system. In one embodiment the in database analysis model may be defined as a stored procedure written in a database native language. The stored procedure may be defined in SQLScript in the form of a series of SQL statements. The SQLScript may allow pushing data intensive logic into the database to avoid data copies to the application server and leverage parallel execution strategies of the database. In another embodiment the in database analysis model may be stored as a stored procedure on a database system. The body of the procedure may include a sequence of statements that specify a transformation of some data by means of relational operations such as selection projection and binds the result to an output variable of the procedure.

In one embodiment the instantiated object model instance may be converted into the in database analysis model by representing elements objects from the object model instance as conditions. In another embodiment objects from the instantiated object model may be written as a SELECT statement that may return output values defined in the instantiated object model. For example node with id equal to 8 from the model presented in Table 1 may be converted with the use of a predefined object model into an instance of a java object Node and that java object may be converted into an equivalent SQL script CE PROJECTION temp table Staff Margin Turnover CE CALC 1 Integer as PredictedValue row id Margin 

Table 3 is an exemplary in database analysis model defined as a stored procedure in the SQLScript language. Table 3 presents the in database analysis model which is converted from the data model defined in PMML format in Table 1. Each of the leaf nodes in the tree structure from Table 1 is represented by a CE PROJECTION statement in the stored procedure. The outputs of all the projections are put into a union which gives the final result.

Some embodiments may include the above described methods being written as one or more software components. These components and the functionality associated with each may be used by client server distributed or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as functional declarative procedural object oriented lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively the components may be implemented in server and client applications. Further these components may be linked together via various distributed programming protocols. Some example embodiments may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level e.g. a graphical user interface . These first and second computer systems can be configured in a server client peer to peer or some other configuration. The clients can vary in complexity from mobile and handheld devices to thin clients and on to thick clients or even other servers.

The above illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term computer readable storage medium should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term computer readable storage medium should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store encode or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described represented or illustrated herein. A computer readable storage medium may be a non transitory computer readable storage medium. Examples of a non transitory computer readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs DVDs and holographic devices magneto optical media and hardware devices that are specially configured to store and execute such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer readable instructions include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment may be implemented using Java C or other object oriented programming language and development tools. Another embodiment may be implemented in hard wired circuitry in place of or in combination with machine readable software instructions.

A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases such as relational transactional hierarchical multi dimensional e.g. OLAP object oriented databases and the like. Further data sources include tabular data e.g. spreadsheets delimited text files data tagged with a markup language e.g. XML data transactional data unstructured data e.g. text files screen scrapings hierarchical data e.g. data in a file system XML data files a plurality of reports and any other data source accessible through an established protocol such as Open DataBase Connectivity ODBC produced by an underlying software system e.g. ERP system and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams broadcast data and the like. These data sources can include associated data foundations semantic layers management systems security systems and so on.

In the above description numerous specific details are set forth to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components techniques etc. In other instances well known operations or structures are not shown or described in details.

Although the processes illustrated and described herein include series of steps it will be appreciated that the different embodiments are not limited by the illustrated ordering of steps as some steps may occur in different orders some concurrently with other steps apart from that shown and described herein. In addition not all illustrated steps may be required to implement a methodology in accordance with the one or more embodiments. Moreover it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.

The above descriptions and illustrations of embodiments including what is described in the Abstract is not intended to be exhaustive or to limit the one or more embodiments to the precise forms disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. These modifications can be made in light of the above detailed description. Rather the scope is to be determined by the following claims which are to be interpreted in accordance with established doctrines of claim construction.

