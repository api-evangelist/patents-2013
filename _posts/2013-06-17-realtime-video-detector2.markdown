---

title: Real-time video detector
abstract: A request to retrieve data from a client device is intercepted by a video detector. The video detector determines if the request is for retrieving a video file. If the request is for a video file, and the video file is deemed to be transcoded to be displayed on the client device, the video detector forwards the request to a video optimizer along with encoding parameters. Encoding parameters are selected by the video detector based on properties of the client device, networks accessible by the client device, conditions of those networks, properties of the requested video and the type of video requested. The encoding parameters also include a file format type to which the requested video is to be transcoded.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09621606&OS=09621606&RS=09621606
owner: Opera Software Ireland Limited
number: 09621606
owner_city: Dublin
owner_country: IE
publication_date: 20130617
---
This application is a continuation of U.S. application Ser. No. 13 448 227 filed Apr. 16 2012 which claims a benefit of and priority to U.S. Provisional Application No. 61 476 214 filed Apr. 15 2011 both of which are incorporated by reference herein in their entirety.

The disclosure generally relates to the field of encoding videos and more specifically to encoding videos in substantially real time as the video is streamed to a computing device.

Users of computing devices commonly view videos on their computing devices. Conventionally users download video files on their computing device and execute the file to view the video. These conventional methods of viewing content are disadvantageous because they require a user to wait for a file to download before the user can view the file. Moreover it may be unreasonable to expect a user to download each file locate it on the computing device and execute it.

To overcome these shortcomings some systems enable users to stream video files from a hosting server. However applications executing on a client device may not be enabled to stream certain formats of video streams. Additionally the video frames within the video stream may be too large to provide a uninterrupted playback to a mobile computing device with limited computing resources or a poor network connection. This is particularly true with mobile computing devices having poor network connections. As such users of mobile computing devices typically have to wait to stream videos on their devices. The videos that are streamed typically freeze or buffer periodically preventing a user from enjoying uninterrupted playback of a video stream.

Some servers may encode video streams to deliver a lower resolution video to a mobile computing device. However such systems also cause a lag between a user s request and the streaming process. For example such systems are unable to transcode a video stream in real time while streaming the transcoded video to the user. Additionally such systems are typically unable to preserve video control functionality for users such as pause seek and video resolution changes. As such users who wish to stream video files on their mobile computing devices typically have to wait an unreasonable amount of time for a video to load and buffer or they have to suffer through a video that does not provide an uninterrupted playback.

The Figures FIGS. and the following description relate to preferred embodiments by way of illustration only. It should be noted that from the following discussion alternative embodiments of the structures and methods disclosed herein will be readily recognized as viable alternatives that may be employed without departing from the principles of what is claimed.

Reference will now be made in detail to several embodiments examples of which are illustrated in the accompanying figures. It is noted that wherever practicable similar or like reference numbers may be used in the figures and may indicate similar or like functionality. The figures depict embodiments of the disclosed system or method for purposes of illustration only. One skilled in the art will readily recognize from the following description that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles described herein.

Disclosed is a system a method and computer readable medium for detecting a video request. It comprises intercepting a request to retrieve a video from a server wherein the request originates from a client device and is intercepted from a network. Additionally the request is analyzed to determine if the request is for retrieving a video based on information associated with the request. If the request is for a video a profile is selected for the video based on the properties of the video. Additionally the request is analyzed to determine whether to transcode the video for playback on a client device based wherein the determination is made based on values provided in the video profile. If the video is marked for transcoding the video is redirected to an optimizer along with transcoding parameters. The transcoding parameters are selected based on the selected video profile and network connection properties. The optimized video is sent to a client device requesting the video to enable playback therein.

At a high level responsive to a user request a client application executing on the client computing device requests to retrieve content over the network . The video detector intercepts the request and determines if the request is for a video. If the request is not for a video the video detector forwards the request to an appropriate hosting server. If on the other hand the request is for a video the video detector flags the video for transcoding and redirects the flagged request back to the client computing device . The client computing device sends the flagged request over the network wherein the request is routed to the video optimizer . The video optimizer requests the video from the origin server and optimizes the video received from the origin server computing device . The optimized video is sent to the video detector wherein it is forwarded back to the client computing device over the network . A decoder executing on the client computing device may decode the received video stream to playback the stream for a user viewing the client computing device .

The network represents the communication pathways between the client computing device the video detector and the origin server . Although not illustrated in the video optimizer may also be connected to the video detector and the origin server via the network . The network can also utilize dedicated or private communications links that are not necessarily part of the Internet. In one embodiment the network uses standard communications technologies and or protocols. Thus the network can include links using technologies such as Ethernet Wi Fi 802.11 integrated services digital network ISDN digital subscriber line DSL asynchronous transfer mode ATM etc. Similarly the networking protocols used on the network can include multiprotocol label switching MPLS the transmission control protocol Internet protocol TCP IP the hypertext transport protocol HTTP the simple mail transfer protocol SMTP the file transfer protocol FTP etc. In one embodiment at least some of the links use mobile networking technologies including general packet radio service GPRS enhanced data GSM environment EDGE code division multiple access 2000 CDMA 2000 and or wide band CDMA WCDMA . The data exchanged over the network can be represented using technologies and or formats including the hypertext markup language HTML the extensible markup language XML the wireless access protocol WAP the short message service SMS etc. In addition all or some of links can be encrypted using conventional encryption technologies such as the secure sockets layer SSL Secure HTTP and or virtual private networks VPNs . In another embodiment the entities can use custom and or dedicated data communications technologies instead of or in addition to the ones described above.

The client computing device represents any entity operated by a user that receives video streams over a network . The client computing device is sometimes referred to as a mobile device or a display device. In one embodiment the client computing device includes a computer system utilized by an end user to communicate with other computers on the network in order to stream a video file. In other embodiments the client computing device includes a network capable device other than a computer system such as a personal digital assistant PDA a cellular telephone a smartphone a pager a television set top box etc. Although illustrates only one client computing device embodiments of the present invention can have thousands or millions of client devices connected to the network . A client application may be executing on the client computing device . A client application may include any application capable of executing on a client device and interfacing with the network . Examples of client applications include but are not limited to web browsers such as SKYFIRE FIREFOX INTERNET EXPLORER CHROME etc. The client application may interface with a user and receive users requests to playback a video stream. In response to the user request the client application sends a request to stream a video over the network . The video may be encoded on a video optimizer as described in the specification before being streamed to the client computing device . In one embodiment a decoder decodes an incoming encoded video stream and provides it to the client application . The client application may playback the decoded video stream on a display associated with the client computing device . In another instance the encoded video received from the video optimizer may be stored at the client for a later viewing. The encoded video may also be stored at the client in an embodiment wherein the client is a cache or a similar device as known in the art.

A video detector intercepts requests made by the client computing device . In one embodiment the video detector is an inline network appliance connected to the client computing device via the network . In another embodiment the video detector may execute on the client computing device . As an inline network appliance the video detector receives all or a subset of all the traffic sent and received by the client computing device including Hypertext Transfer Protocol HTTP Real Time Messaging Protocol RTMP traffic. In such an embodiment the video detector serves as a network proxy. In one embodiment the video detector is highly available HA and scalable in order to handle many gigabits of traffic per second. In such an embodiment the video detector consists of a network proxy process such as SQUID with the video detector called by SQUID over a local network interface such as Internet Content Adaptation Protocol ICAP . In one embodiment the video detector handles RTMP traffic by using another process integrated into the video detector . In one embodiment another appliance may be a network proxy that calls the video detector via an application programming interface API . Such an embodiment allows the video detector to integrate with an existing network infrastructure. As such the video detector may integrate with load balancers routers and content steering appliances.

In one embodiment the video detector is implemented on a client computing device . As such a client or a software provider is enabled to have a video optimization service without requiring network components. The video detector may execute as a proxy running on the device to intercept HTTP and other protocols to feed through a video detection process. In such an embodiment requests and or responses may be redirected to the video transcoder or file cache directly from the client computing device . In one embodiment client software may call into a service to determine whether to enable optimization or not enabling optimization to be a service that is available to users.

The video optimizer transcodes a video identified by the video detector . The video optimizer communicates with the video detector and the origin server computing device via the network . The video optimizer receives a request to optimize a video from a client computing device and routed by the video detector . The video optimizer may call the origin server computing device to retrieve a requested video and transcodes it. The transcoded video may be streamed to the client computing device via the video detector . In one embodiment the video optimizer interfaces with the client computing device over the network . The origin server computing device is an entity that provides webpages audio video files and or other electronic documents to a client computing device . The web origin server computing device can be for example a major Internet web site operated by a national media outlet a personal blog on a web server operated by a lone individual and or another distributor of web pages. While only one web hosting servers is shown in embodiments of the system can have thousands or millions of different hosting servers. Only one origin server computing device is shown for purposes of clarity. This description uses the term video to refer to any electronic file e.g. document audio or video file and the like served by a origin server computing device regardless of whether the document is technically a video file.

The machine may be a server computer a client computer a personal computer PC a tablet PC a set top box STB a personal digital assistant PDA a cellular telephone a smartphone a web appliance a network router switch or bridge or any machine capable of executing instructions sequential or otherwise that specify actions to be taken by that machine. Further while only a single machine is illustrated the term machine shall also be taken to include any collection of machines that individually or jointly execute instructions to perform anyone or more of the methodologies discussed herein.

The example computer machine includes a processor e.g. a central processing unit CPU a graphics processing unit GPU a digital signal processor DSP one or more application specific integrated circuits ASICs one or more radio frequency integrated circuits RFICs or any combination of these a main memory and a static memory which are configured to communicate with each other via a bus . The computer system may further include graphics display unit e.g. a plasma display panel PDP a liquid crystal display LCD a projector or a cathode ray tube CRT . The computer system may also include alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse a trackball a joystick a motion sensor or other pointing instrument a storage unit a signal generation device e.g. a speaker and a network interface device which also are configured to communicate via the bus .

The storage unit includes a machine readable medium on which is stored instructions e.g. software embodying any one or more of the methodologies or functions described herein. The instructions e.g. software may also reside completely or at least partially within the main memory or within the processor e.g. within a processor s cache memory during execution thereof by the computer system the main memory and the processor also constituting machine readable media. The instructions e.g. software may be transmitted or received over the network via the network interface device .

While machine readable medium is shown in an example embodiment to be a single medium the term machine readable medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database or associated caches and servers able to store instructions e.g. instructions . The term machine readable medium shall also be taken to include any medium that is capable of storing instructions e.g. instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies disclosed herein. The term machine readable medium includes but not be limited to data repositories in the form of solid state memories optical media and magnetic media.

Referring now to it illustrates an embodiment of a video detector in accordance with an embodiment. As noted previously the video detector is structurally configured similarly to the computing machine and further configured as noted herein. The video detector is illustrated as a high level block diagram of modules configured to detect a request to stream video files and to route video request to the video optimizer if appropriate. In one embodiment the video detector includes an identification engine a selection engine a transcode determination engine a URL generator an adaptive bit rate engine a dynamic bit rate adjuster and a health check engine . The modules are configured to function and interoperate as described herein.

The identification engine determines if a request is generated by a client computing device or a response to the client computing device is a video stream. In one embodiment the identification engine looks at filename extensions or other known URL schemes for example a YOUTUBE video fetch to determine if a video feed is requested. In a response path the identification engine looks at mime type or other header information and or the actual payload data to determine if a request is for video feed. For example FLASH video FLV and MPEG 4 MP4 videos are identifiable by looking at 4 or 8 bytes of the payload respectively. FLV files start with F L V and MP4 videos have f t y p in bytes 5 through 8. In one embodiment the selection engine identifies a user agent and a referrer header to determine the type of video request. If the referrer header is for example http .swf the identification engine assumes it was requested by a FLASH player. Some browsers do not insert the referrer header for plug ins so the identification engine may look for the absence of this header to identify a video request. As such the identification engine determines if a fetch request is for a video stream. In one embodiment the identification engine adds a video redirect to optimizer flag to client requests for videos.

In one embodiment although a file or a request may be for a video the identification engine does not identify the request as a video is the request is tagged with a do not transcode flag. For example if a video detector cannot process a video or file the video optimizer may add such a flag so that the video detector does not send the same video back to the video optimizer .

The selection engine selects encoding profiles for each identified video fetch request. The coding profiles may be based on several parameters associated with the requesting client computing device including but not limited to a user agent player version user subscription information including the user s data plan etc. network type WiFi third generation mobile telecommunications protocol 3G fourth generation mobile telecommunications protocol 4G etc. current network state and network congestion. The selected profile comprises of at least one of a flag enabling or disabling transcode or video compression a video width height a video bit rate a video frame rate divisor an audio sample rate and number of channels an audio bit rate and other encoding information such as CODEC and CODEC profile such as H.264 main etc. and a video container destination such as FLV MP4 etc. In one embodiment the selected profile information is provided to the transcode determination engine which determines whether to transcode a video file.

In one embodiment the selection engine selects an encoding profile to optimize playback at the client. The video optimizer may be capable of changing a container format of a video in a transcoding process. For example a FLASH player may playback a variety of encoded videos so an MP4 may be converted to an FLV without causing an error. Since FLV files do not specify in advance all the frame sizes it beneficially permits adaptive transcoding. In addition since a video optimizer can transcode to format that is beneficial to a client situation the selection engine may select an encoding profile to take advantage of hardware accelerated decoding and other client properties.

The transcode determination engine determines whether to transcode a video associated with a fetch request and determines bit rates for the video optimizer . In one embodiment the transcode determination engine makes such a determination based on an encoding profile provided by the selection engine . For example video compression may be enabled or disabled for a particular user based on rate plan etc. as provided in an encoding profile. In one embodiment the transcode determination engine uses this information to along with current network condition information to determine whether to transcode a video. Through communication with a congestion detection element in the network individual flows can be adapted to varying degrees based on congestion.

In one embodiment once a profile is selected by the selection engine the transcode determination engine estimates a source bit rate. For example profile parameters such as duration may be used along with the size of the file to calculate the source bit rate. The estimated bit rate received from the selection engine is compared to the source bit rate wherein if the estimated compression gain is not sufficient or negative the video is marked to be ignored by the video optimizer and is passed on to the client. In one embodiment the profile selection engine is configured for minimum compression gain.

In another embodiment if dimensions of the source video are less than dimensions of a profile the transcode determination engine can use the difference between the areas to compute a smaller bit rate to account for the smaller video dimension. Because a video optimizer does not make dimensions of a video larger transcode determination engine reduces the bit rates accordingly. In one embodiment the reduction is calculated using the ratio of square root of the areas.

The URL generator generates a URL with a domain host providing a redirect request to the video optimizer if the video is deemed to be transcoded by the transcode determination engine . In one embodiment the URL may contain at least one of a video width height a video bit rate a video frame rate divisor an audio sample rate and number of channels an audio bit rate a source URL a user agent of a client a source domain cookie and any other authentication data by the video optimizer . In one embodiment the URL generator rewrites the original response with an HTTP redirect and sets the location header to the new URL. This causes the client to issue a new request to the video optimizer . The video detector also has logic to look for incoming URLs with URLs generated by a video detector so that they are not intercepted again.

The adaptive bit rate engine regulates bitranges available to a client. In one embodiment the adaptive bit rate engine limits bit rates to force a player to adapt to certain bit rate ranges instead of consuming as much bandwidth as possible. Adaptive bit rate ABR players measure network throughput in order to decide which bit rate profile to use. The adaptive bit rate engine may employ rate limiting to force the player to think that the network is congested or slower speed than reality. In one embodiment the bit rate engine applies rate limiting for the requested video segments to the limit specified by the profile selection. Similarly the adaptive bit rate engine uses user profiles for files in a progressive download. The adaptive bit rate engine may also work in conjunction with another network element that performs the rate limiting. In such an instance the ABR engine notifies the network element with a target bit rate to use in a rate limiter.

In another embodiment the adaptive bit rate engine performs manifest file manipulation to limit the available bit rates that are advertised to the client. For substantially real time transcoding the adaptive bit rate engine creates manifest file profiles for bit rate ranges that did not exist previously. For ABR protocol a manifest file advertises to the client computing device the available bit rates a server has available. Through interception and rewriting the manifest file the adaptive bit rate engine can eliminate certain bandwidth profiles and thus leaving the client blind to the existence of these profiles. As such the client computing device switches to the new advertised profiles enabling the adaptive bit rate engine to regulate the video bit rate. If an ABR session does not contain bit rates that are acceptable for a given network user state the adaptive bit rate engine intercepts the manifest file and inserts the additional bit rate profiles and or deletes higher bit rate profiles based on the user profile selected. In one embodiment the video detector sends information to the video optimizer or it may wait until a non existent bit rate segment is requested. The video optimizer can fetch the higher bit rate segment s from the origin server and begin transcoding into the new bit rate. The video optimizer then forwards the segment to the video detector which then forwards it on to the client computing device .

The dynamic bit rate adjuster changes encoding bit rate mid stream. For FLV file format for instance since frame sizes are not indicated in advance the dynamic bit rate adjuster may change the encoding size or a bit rate mid stream. As conditions change in the network the dynamic bit rate adjuster updates the video optimizer to the new conditions. To facilitate this operation the dynamic bit rate adjuster assigns a session ID to each video flow. In one embodiment a load balancer may control transcoders. In such a system the update requests can be sent to an appropriate transcoder because the load balancer can steer traffic to a particular transcoder based on this session ID.

Alternatively the dynamic bit rate adjuster can send broadcast messages to the video optimizer . If the broadcast message contains individual flows or session IDs the transcoders within the video optimizer can still act on a per flow basis. If not the bit rate adjustment is global across all flows. The bit rate adjustment message can take two forms. The first form is a direct encoder adjustment. In this form the dynamic bit rate adjuster sends a new bit rate and possible width height etc. to the transcoder. The transcoder on a video optimizer follows these instructions with some possible exception handling. The second form is an indirect adjustment. In this form the dynamic bit rate adjuster communicates a congestion level or encoding aggressiveness. The transcoder interprets this information and identifies compression settings responsive to the level sent by the dynamic bit rate adjuster .

The health check module queries the video optimizer periodically to identify transcoding capacity. Knowledge of transcoding capacity may help prevent a case where there are insufficient resources for further transcoding or an outage. If there is a period of inactivity the health check module periodically queries the video optimizer to make sure resources are available when needed. A video detector executing on a client computing device may monitor the transcoder response when redirecting a session and re redirect back to the original URL on a failure or the health check module may perform a health check before doing the redirect.

The session tracker tracks all sessions executing on the video optimizer by using session IDs and or URL provided by the video detector . The session tracker may keep track of sessions for dynamic adjustments and for seek operations. In one embodiment if the system wants to address flow specific bandwidth the session tracker may provide an appropriate instance of a transcoder. In another embodiment the session tracker tracks sessions to keep track of requests associated with a seek request. For example when a seek operation such as fast forward occurs the client application on the client computing device aborts a file download requests and starts a new download with a new starting point.

In one embodiment the video detector assigns a unique ID to each session directed to the video optimizer . The sessions may also be stored based on their associated URLs. In another embodiment a sessions s URL and or flow identification such as the IP 4 5 tuple of src dest IP and src dest Port and protocol may be used to track each session.

In one embodiment each new session sent to the transcoder has its session ID or URL stored in a table in the session tracker . The session ID may remain stored in the table as long as the transcoder is still generating data to the user. If the connection drops when they player does a seek or for some other reason the session is placed in a standby state where it is kept for a period of time to see if a new request for the same session comes in. After the timer expires the session is removed from the session table.

In one embodiment the session tracker also keeps track of statistics for the transcoder . Each running instance in the server HTTP transcoder etc. registers itself with the session tracker when a new connection begins processing. The session tracker assigns an ID not the same as session ID for each connection. Since there are multiple request types that can be processed by the video optimizer each unique type is stored in separate state tables or be combined into one large table. A running session can call back into the session tracker to update its statistics on a periodic basis. The session tracker makes this data available through a web interface and or a Simple Network Management Protocol SNMP etc. The session tracker also accumulates long term statistics based on the statistics updates from each instance. These statistics take the form of real time active sessions and long term sessions which use completed sessions. These statistics also track minimum maximum and average statistics for each statistic. When a process completes it de registers itself with the session tracker which can then reclaim the resources associated with that session.

The performance estimator oversees the video optimizer to determine if it is nearing maximum capacity. Because a combination of source and destination CODECs in addition to the source video s complexity are potentially different for every stream the performance estimator cannot look at total connections as an indicator of busy ness . It is also not sufficient to look at Central Processing Unit CPU utilization as CPU utilization can spike to 100 for various reasons during the transcoding process despite the transcoder still have room to handle more sessions. Capping the server to a value less than one hundred percent consequently leaves capacity on the table.

The performance estimator interfaces with a load balancer to allow individual servers to take themselves out of the load balancing pool when they deem they are near capacity. This will leave current sessions and resumed sessions due to seek uninturrepted but new connections will not be sent to the server until some capacity frees up. In one embodiment a load balancer queries the server periodically to get its status. The server can return one of the following results hold off mode indicating that the server has reached capacity and new sessions should be sent there. Existing sessions continue to be sent to the server and processed. Shutdown mode indicates that a server is in the process of shutting down and no new sessions should be sent to it. This can be due to an internal server error or a forced graceful shutdown. During a graceful shutdown existing sessions continue to be sent to the server and processed until they are all completed at which point the actual shutdown can proceed. No hold off mode or shutdown mode may indicate that the system is running properly and can accept new connections. If the server does not respond or responds with an error the load balancer assumes it is down and removes it from the pool. No new or existing sessions will be sent to the server.

In one embodiment an applied algorithm is used by the performance estimator to estimate performance of a server. The algorithm can be embodied as instructions storable on a computer readable storage medium e.g. a memory or disk and executed by one or more processors or controllers . In one embodiment the performance estimator assumes that a given processor core can handle a certain amount of macroblocks or pixels per second. Thus one can empirically measure how many macroblocks per second can be decoded. The performance estimator then measures how many macroblocks can be encoded per second. As a new session starts up the performance estimator looks at a file to be decoded and an output configuration. By looking at the video dimensions and frame rates the performance estimator can get an estimate of how many macroblocks per second of decode and encode are needed. The first order equation to calculate utilization proceeds as follows 

As such the performance estimator calculates a reasonable first order approximation of the server s current utilization. Additional factors can also be employed to take into account CODEC type. Some CODECs may be computationally simpler than others. Additionally there may be other non linear effects such as resource starvation that may affect utilization rates. The server may have memory bandwidth or other hardware limitations that may prevent it from reaching full capacity. These can simply be added as factors to the equation provided above.

In one embodiment the performance estimator considers processor hyper threading HT . HT allows one processor core to act as multiple virtual cores. The HT cores are not full cores however and they share resources. This can cause problems with higher resolution video. For instance some Intel XEON processors cannot perform two 1080P decode operations on two HT cores that share the same physical core. Performance drops off dramatically if this is attempted. To handle this 1080P videos are allowed to use even numbered cores to decode. This means that a total number of 1080P sessions are half the number of processor cores.

In one embodiment after the performance estimator calculates a server s utilization it compares the utilization to a threshold value to see if a hold off flag should be asserted. This threshold is in percent and can be above 100 if desired. It is noted that in one embodiment if server can run at higher than 100 capacity the transcode operations may not keep up with real time.

In one embodiment the HTTP server identifies a request type and associates an appropriate media handler to handle the transaction. Most transcoding sessions come to the video optimizer as HTTP sessions. In one embodiment RTMP sessions are handled as FLV progressive download. Other network interfaces may be used if needed. In one embodiment the HTTP server parses incoming requests to extract the settings passed from the video detector including bit rates resolution etc. The incoming request may also contain the original requested URL and cookies or the RTMP connect message payload.

Once the HTTP server has determined the request type it associates a media handler to handle the transaction. A media handler is responsible for handling most of the network protocol specific communication. The output of the media handler is binary data in the form requested by the video detector including FLASH FLV for example. The HTTP server packages this data into a proper HTTP response.

One complication of FLASH video is that the FLASH player does not accept chunk encoded data. This means that either Content Length encoding is used or connection close. Connection close allows an encoder to skip specifying the content length in advance which is typically unknown since transcoding is performed in real time. The consequence of this is that the FLASH player typically does not allow seek operations. Alternatively a guess may be provided. This value can be larger than the actual value and most browsers handle this properly if a connection is closed when a transfer is finished.

The HTTP server makes an educated guess for the content length based on the source file. As an estimate the HTTP server may use the original content length. The HTTP server also looks at the source bit rate compared to a bit rate target. The ratio of these two can be used as a starting point for the output content length. The HTTP server may pad the frames the ensure the target is not exceeded. If the source file is in MP4 format the HTTP server gets an estimate by using an MP4 algorithm described below.

The FLASH media handler handles FLASH HTTP progressive download. In one embodiment the FLASH media handler fetches a source file from a origin server computing device using information provided by the video detector . For example the FLASH media handler receives URL user agent and cookies information from the video detector and passes the information to the transcoding engine . In one embodiment as the transcoding engine transcodes the source file the FLASH media handler reads the transcoded output data and encapsulates the output data into a FLV or a MP4 container. In other embodiments the transcoding engine encapsulates the transcoded output data. In addition the FLASH media handler is also enable to resume transcoding sessions that are stopped because of a seek operation is executed by a user on a client computing device .

The seek handler handles seeks operations executed by a user on a client computing device in one of three ways described herein. It is noted that when a user executes a seek operation a current transcode operation is suspended and a new file download and transcode operation is initiated. In a first embodiment the seek handler downloads a new file associated with the seek operation. The download operation includes metadata headers including CODEC headers duration etc. In such an instance the new file is sent to the transcode engine to be transcoded without any knowledge of the previous session.

In a second embodiment a new file download operation may only have partial header information but does not have other metadata which the transcoding engine can use to identify the source file s properties. In such an instance a start time or a seek time of a video is determined by identifying a time stamp of the video. The seek handler retrieves metadata from the previously suspended transcode operation and provides metadata and time stamp data to the transcoding engine to initiate a transcoding process at a time associated with the time stamp. In a third embodiment a new file download is a range offset. The range offset may be a raw offset into the source file. In such an instance metadata headers are unavailable however frame headers may be included if available. In such an embodiment the suspended session s metadata is reused and provided to the transcoding engine to transcode the new file. In embodiments wherein a previous or suspended session s metadata is used the seek handler performs a session transfer by making a copy of the suspended session s metadata and passing it to the new session s handler. In one embodiment the metadata is created as file output is formed by a media encapsulator such as the FLASH media handler . In such an instance FLV or MP4 headers are created at the start of the file and frame headers needed during the file transcode process.

The metadata handler provides metadata associated with a video to the transcoding engine . For FLV videos at least one of the following metadata fields are passed to the transcoding engine a sourcedata meta tag used by GOOGLE video for example to track a source of the video file a canseekontime meta tag instructing a FLASH player that seek on time operations can be performed an aktimeoffset parameter used to indicate a startime of the video keyframe meta tags providing seek points of the video to a FLASH player in one embodiment the source frame s keyframes are passed to the transcoding engine and not the transcoded file s key frames because the FLASH payer uses this data to send seek requests to the original server based on the original file s properties cuepoints meta tags which also provide seek points to a player haskeyframe and canseektoend meta tags. In addition the metadata handler generates metadata fields if the source file does not have them. For example the metadata handler may create starttime and duration fields for videos to be transcoded.

In an embodiment wherein MP4 source files are to be transcoded the metadata handler converts MP4 metadata fields to FLV metadata fields if the MP4 source file needs to be re containerized. In an embodiment where MP4 is the output format the MP4 metadata fields are preserved in the output file by the metadata handler . Below is a list of metadata fields. The first entry in NamePairs is an MP4 name a second entry is an FLV name and the third is the scaling factor 

In one embodiment the transcoding engine transcodes input videos based on parameters provided by the video detector and the metadata provided by the appropriate media handler. In one embodiment a transcode rate may be predetermined as provided by a video detector or by a media handler. If however the predetermined rate is less than a transcoding rate possible the transcoding engine uses the frame rate of the output video to modulate the transcoding rate. In such an instance the transcoder transcodes at a nominal frame rate of the video during a transcoding session. For example if an output file is 15 frames per second fps the transcoder may not run any faster than 15 fps. In one instance the transcoding engine may transcode at a faster rate to prevent stalls in the client s media player.

In one embodiment the transcoder operates in a turbo mode by using a fast start mechanism in conjunction with transcoding at a nominal frame rate of the video during a transcoding session. For example when a new session starts or a seek operation is executed the transcoding engine transcodes a video at a fast rate for a number of frames to prime the network and the player s receive buffer. In one embodiment transcoding engine transcodes at a high rate for the first 150 frames of a video.

In one embodiment of a transcoding engine uses third party libraries for transcoding. In such instances the transcoding engine runs a transcoding operation in a separate process from the primary server process because the third party libraries may not be stable. Thus if a transcoding operation causes a crash or memory corruption the damage is limited to that session and other users and the server itself are not affected. In order to accomplish this the video optimizer creates a shared memory object to pass data between the video optimizer and the transcoding engine . The source file is written to the transcoding engine through the shared memory. This can either be the raw data or the video optimizer can write to disk and then tell the transcoding engine about the current state through the shared memory. Data created by the transcoding engine is written to the shared memory by the transcoding engine. The video optimizer then reads this data and sends it over the network to the client computing device .

In one embodiment the transcoding engine transcodes a video file at an adaptive rate. As described in the specification the transcoding engine starts transcoding using a profile. As the transcoding runs the transcoding engine can alter the audio and or video bit rate based on network conditions. There may be a device in the network that can signal congestion or target bit rates to the transcoder or the transcoding engine may make the decisions on its own. In either case the transcoding engine can change its encoding settings in real time based on this feedback. For example every few seconds the transcoding engine picks a new target bit rate and future frames can be encoded with the new values.

In order to monitor the network for adaptive transcoding the transcoding engine determines if a network stack is filling up when sending data to a client over a network. If the network is filling up the bit rates can be lowered. An example of a network check is to see if network write requests are backing up. If the video optimizer uses TCP the TCP send buffers will fill up and additional network sends will have to be postponed until there is room in the buffers. In one embodiment the transcoding engine uses this property to increase the bit rates delivered to a client computing device . For example if the network does not appear congested the bit rates can be gradually increased while checking for backup. In one embodiment the transcoding engine uses turbo mode described above before or in conjunction with a bit rate increase to generate several frames quickly. If those frames make it through the network without issues the bit rate may be increased.

In one embodiment the network conditions may be determined by sending an unaltered video stream to a device on a network. For example a video detector or another device on the network may request the video optimizer to forward an unaltered video stream. In such an instance the transcoding engine can monitor network throughput without transcoding to identify any network congestion. In one embodiment the transcoding engine samples the network throughput to determine network congestion or capacity. In one embodiment the video detector may sample the unaltered video throughput to determine network conditions.

If the client receives an HTTP redirect request the client sends the request over the network. The HTTP redirect request is routed to the video optimizer . In one embodiment the video detector may monitor the traffic and or requests from the client device as the HTTP redirect request is routed the video optimizer . In such a configuration the video optimizer only sees requests for video files that need to be transcoded and are associated with a HTTP redirect request . As such the video optimizer is not burdened with all the requests generated by a client computing device .

The video optimizer forwards the video HTTP get requests to the origin server computing device and receives a video file from the origin server computing device . The video optimizer transcodes the video file to a format usable by the client device and based on network conditions for sending the optimized video to the client. In one embodiment the video detector intercepts the optimized video and forwards to the client. As such the client receives the optimized video for substantially real time playback on an application executing on the client computing device .

In one embodiment responsive to an HTTP get request to an origin server computing device the video optimizer receives a HTTP error from the origin server computing device as opposed to a video file. In such an instance the video optimizer appends a do not transcode flag to the HTTP redirect request received from the client computing device . The HTTP redirect request with the do not transcode flag is sent to the client computing device wherein the client re sends the request out over the network with the do not transcode flag. Because of the do not transcode flag in such an instance the video detector and the video optimizer do not intercept the request and it is propagated to the origin server computing device wherein the origin server computing device responds appropriately to the request. In another embodiment video detector detects the presence of the do not transcode flag from the HTTP response headers in the video optimizer s response. It then stores that in a state cache that is used to remember that the video optimizer could not optimize the video. When the client computing device re requests the original file the video detector inspects its state cache and detects the do not optimize state based on URL . As such the video detector is prevented from sending the request back to the video optimizer . Entries in the state cache time out after the duration of the video or the duration multiplied by a constant factor e.g. 2.0.

The client device sends the received HTTP redirect request with over a network wherein the HTTP redirect request is routed to the video optimizer . In one embodiment the video detector monitors network traffic coming from the client including the HTTP redirect request . The video optimizer generates a full request and forwards it to the origin server computing device . Responsive to the full request the video optimizer receives a response from the origin server computing device . The video optimizer performs a profile check on the received response to determine if the response is a video. If the response is not a video the video optimizer appends an origin server flag to the response and forwards it to the client computing device .

In an embodiment wherein the profile check determines that the response is a video the video optimizer transcodes the video and sends the optimized video to the client over a network. In one embodiment the video optimizer may comprise an egress cache to store the transcoded file as the transcode process begins on the video optimizer . If a new request from client comes in for a portion of the file that has already been transcoded the request can be satisfied directly from the egress cache without having to re transcoded the video again. In an embodiment wherein a seek request is provided by the client the profile check determines whether a byte range requested in the seek request exists in the egress cache . It the byte range does not exists in the egress cache the video may be transcoded from before or at the seek point as described in the specification. In one embodiment the video is transcoded from or before the seek point until it reaches a byte range provided in the egress cache of another transcoding session. As such the profile check prevents two transcoding sessions from transcoding a same portion of the file. In one embodiment the egress cache is populated even if the client disconnects enabling new request for the same file to be satisfied by the egress cache . For instance if the transcoding is stopped at a byte range when a user disconnects the transcoded file may not be useful to another user who may view the transcoded file to a later point. In one embodiment an ingress cache maintains files downloaded from the origin server computing device . Thus if another request for the same file is received from the client computing device the file is retrieved from the ingress cache as opposed to from the origin server computing device .

The process continues by determining whether the new request is associated with or is a seek function of an existing session . If the new request is not associated with an existing session the video optimizer transcodes the new request as described in the specification in reference to . If the new request is associated with an existing session the process transfers metadata information from the existing session. If the new request is for an FLV file which includes header indicating the file is an FLV file but does not contain any other metadata the process appends metadata to the transcoded file associated with the seek operation.

As illustrated in in one embodiment the client computing device sends a TCP 1935 request to an RTMP server . The RTMP server converts the request to an HTTP POST PUT request and sends it the video optimizer . The video optimizer uses the HTTP POST PUT request to generate an RTMP request on the origin server computing device . In such an instance the video optimizer emulates a client computing device . Responsive to the RTMP request the video optimizer receives a response from the origin server. Upon receiving the response the video optimizer creates files based on the response and transcodes the response data . The optimized video is sent to the RTMP server wherein the RTMP server believes it is receiving the optimized data from a file based interface as opposed to stream based interface. The RTMP server forwards the optimized video to the client for streaming RTMP video on the client.

Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter herein.

Certain embodiments are described herein as including logic or a number of components modules or mechanisms for example as described in . Modules may constitute either software modules e.g. code embodied on a machine readable medium or in a transmission signal or hardware modules. A hardware module is tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more hardware modules of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a hardware module that operates to perform certain operations as described herein.

In various embodiments a hardware module may be implemented mechanically or electronically. For example a hardware module may comprise dedicated circuitry or logic that is permanently configured e.g. as a special purpose processor such as a field programmable gate array FPGA or an application specific integrated circuit ASIC to perform certain operations. A hardware module may also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

Accordingly the term hardware module should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily configured e.g. programmed to operate in a certain manner or to perform certain operations described herein. As used herein hardware implemented module refers to a hardware module. Considering embodiments in which hardware modules are temporarily configured e.g. programmed each of the hardware modules need not be configured or instantiated at any one instance in time. For example where the hardware modules comprise a general purpose processor configured using software the general purpose processor may be configured as respective different hardware modules at different times. Software may accordingly configure a processor for example to constitute a particular hardware module at one instance of time and to constitute a different hardware module at a different instance of time.

Hardware modules can provide information to and receive information from other hardware modules. Accordingly the described hardware modules may be regarded as being communicatively coupled. Where multiple of such hardware modules exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses that connect the hardware modules. In embodiments in which multiple hardware modules are configured or instantiated at different times communications between such hardware modules may be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware modules have access. For example one hardware module may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware module may then at a later time access the memory device to retrieve and process the stored output. Hardware modules may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The various operations of example methods described herein may be performed at least partially by one or more processors that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processors may constitute processor implemented modules that operate to perform one or more operations or functions. The modules referred to herein may in some example embodiments comprise processor implemented modules.

Similarly the methods described herein may be at least partially processor implemented. For example at least some of the operations of a method may be performed by one or processors or processor implemented hardware modules. The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the processor or processors may be located in a single location e.g. within a home environment an office environment or as a server farm while in other embodiments the processors may be distributed across a number of locations.

The one or more processors may also operate to support performance of the relevant operations in a cloud computing environment or as a software as a service SaaS . For example at least some of the operations may be performed by a group of computers as examples of machines including processors these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. application program interfaces APIs . 

The performance of certain of the operations may be distributed among the one or more processor not only residing within a single machine but deployed across a number of machines. In some example embodiments the one or more processors or processor implemented modules may be located in a single geographic location e.g. within a home environment an office environment or a server farm . In other example embodiments the one or more processors or processor implemented modules may be distributed across a number of geographic locations.

Some portions of this specification are presented in terms of algorithms or symbolic representations of operations e.g. as described with on data stored as bits or binary digital signals within a machine memory e.g. a computer memory or storage . These algorithms or symbolic representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. As used herein an algorithm is a self consistent sequence of operations or similar processing leading to a desired result. In this context algorithms and operations involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions herein using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or a combination thereof registers or other machine components that receive store transmit or display information.

As used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. For example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the invention. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for a system and a process for providing streaming optimized video to a client computing device and thereby providing an uninterrupted video playback session to a user through the disclosed principles herein. For example the server encodes the text and image data such that the text data does not lose any resolution and can be rendered perfectly at any zoom level on the client device. Image data is considered less important to the browsing experience however as is delivered as a low resolution image data which may appear blocky and stretched out during an intermediate stage after the zoom in and before a hi resolution image is retrieved and delivered to the client device. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications changes and variations which will be apparent to those skilled in the art may be made in the arrangement operation and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims.

