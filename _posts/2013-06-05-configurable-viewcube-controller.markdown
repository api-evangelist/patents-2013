---

title: Configurable viewcube controller
abstract: A method, apparatus, system, and computer program product provide the ability to display representative properties of a three-dimensional scene view. A 3D scene and a 3D representation of a coordinate system of the 3D scene are displayed. Different faces of the 3D representation represent and correspond to different viewpoints of the 3D scene. Different statistics for features of the 3D scene are reflected on the different faces of the 3D representation based on the viewpoint corresponding to each face. Manipulation of the 3D representation identifies and selects a different viewpoint of the 3D scene which is then reoriented accordingly.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09043707&OS=09043707&RS=09043707
owner: Autodesk, Inc.
number: 09043707
owner_city: San Rafael
owner_country: US
publication_date: 20130605
---
This application claims the benefit under 35 U.S.C. Section 119 e of the following co pending and commonly assigned U.S. provisional patent application s which is are incorporated by reference herein 

Provisional Application Ser. No. 61 658 294 filed on Jun. 11 2012 by Gunjan Porwal entitled CONFIGURABLE VIEWCUBE CONTROLLER .

This application is related to the following co pending and commonly assigned patent application which application is incorporated by reference herein 

U.S. patent application Ser. No. 11 729 211 filed on Mar. 28 2007 now U.S. Pat. No. 7 782 319 issued on Aug. 24 2010 entitled THREE DIMENSIONAL ORIENTATION INDICATOR AND CONTROLLER by Anirban Ghosh et. al .

The present invention relates generally to three dimensional 3D graphics applications and in particular to a method apparatus and article of manufacture for providing access to multiple views using a single orientation controller widget.

When working with three dimensional 3D data i.e. in a graphics application a number of orientations of the data are needed by the user to provide a better understanding of the shape and size of the geometry being viewed. Accessing a number of views of the data is difficult and involves several user steps with prior art methods. In addition prior art controllers that are used to view the orientation contain a limited amount of information. What is needed is a method and capability to easily view multiple different orientations as well as information about such a potential orientation. Such problems may be better understood with an explanation of prior art graphics applications and orientation view capabilities.

Typical 3D authoring applications allow users to create manipulate and view 3D geometry on two dimensional displays. By rendering a view of the virtual scene from a particular viewpoint a 2D image can be shown on the display. While this allows a rich and effective means of simulating the experience of viewing real 3D objects and scenes controlling the viewpoint and understanding the position of the viewpoint relative to the object is a significant task for the user.

Early primitive 3D graphics applications were command line driven allowing users to directly enter and query the numerical position orientation and other properties of a virtual camera which defined a particular viewpoint. With the advent of graphical user interfaces GUIs numerical entry and query were largely replaced by graphical representations of the 3D camera in the scene and direct manipulation of it either while viewing through the camera or while looking at it through another camera. In addition preset viewpoints commonly used in the drafting and design fields such as top view side view etc. could be selected through menus. However there are many shortcomings to this approach and more advanced scene orientation methods are possible.

One prior art methodology developed by the assignee of the present application provides for the use of a viewcube also referred to as CubeCompass and is described in U.S. Pat. No. 7 782 319 identified above and incorporated by reference herein. The viewcube is a cube icon representing different viewpoints in a three dimensional 3D scene. When the view of the scene is changed by the user the view cube rotates to show the orientation of the new view. Accordingly current viewcube controllers provide a convenient way of seeing the camera angle of an existing scene or model in the viewport. The viewcube provides a handy way of knowing whether the scene model is being viewed from front back left right top left top right and so on. However such viewcubes do not provide any additional information for the scene apart from camera angle.

Embodiments of the invention make use of the viewcube and the ability to display more information to the user by putting certain information directly on the cube that might inform a user about that view before the view is changed. For example information about lighting scene complexity number of vertices or faces might be added directly to the cube face corresponding to that view. Alternatively some sort of color coding might be used. In this regard embodiments of the invention provide a new way for viewing statistics for a viewport scene by providing additional information in a viewcube controller.

In the following description reference is made to the accompanying drawings which form a part hereof and which is shown by way of illustration several embodiments of the present invention. It is understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

Embodiments of the invention provide a new way for viewing statistics for a viewport scene by providing additional information in a viewcube controller.

In one embodiment the computer operates by the general purpose processor A performing instructions defined by the computer program under control of an operating system . The computer program and or the operating system may be stored in the memory and may interface with the user and or other devices to accept input and commands and based on such input and commands and the instructions defined by the computer program and operating system to provide output and results.

Output results may be presented on the display or provided to another device for presentation or further processing or action. In one embodiment the display comprises a liquid crystal display LCD having a plurality of separately addressable liquid crystals. Alternatively the display may comprise a light emitting diode LED display having clusters of red green and blue diodes driven together to form full color pixels. Each liquid crystal or pixel of the display changes to an opaque or translucent state to form a part of the image on the display in response to the data or information generated by the processor from the application of the instructions of the computer program and or operating system to the input and commands.

In various embodiments of the invention the display is a 3D display device which may comprise a 3D enabled display e.g. 3D television set or monitor a head mounted display e.g. a helmet or glasses with two small LCD or OLED organic light emitting diode displays with magnifying lenses one for each eye active or passive 3D viewers e.g. LC shutter glasses linearly polarized glasses circularly polarized glasses etc. etc. In this regard any technique that may be utilized to view 3D stereoscopic images is represented by display . Further one or more stereoscopic cameras may be configured to communicate with computer to enable a 3D display on 3D display .

The 3D image may be provided through a graphical user interface GUI module . Although the GUI module is depicted as a separate module the instructions performing the GUI functions can be resident or distributed in the operating system the computer program or implemented with special purpose memory and processors.

In one or more embodiments the display is integrated with into the computer and comprises a multi touch device having a touch sensing surface e.g. track pod or touch screen with the ability to recognize the presence of two or more points of contact with the surface. Examples of multi touch devices include mobile devices e.g. iPhone Nexus S Droid devices etc. tablet computers e.g. iPad HP Touchpad portable handheld game music video player console devices e.g. iPod Touch MP3 players Nintendo 3DS PlayStation Portable etc. touch tables and walls e.g. where an image is projected through acrylic and or glass and the image is then backlit with LEDs .

Some or all of the operations performed by the computer according to the computer program instructions may be implemented in a special purpose processor B. In this embodiment the some or all of the computer program instructions may be implemented via firmware instructions stored in a read only memory ROM a programmable read only memory PROM or flash memory within the special purpose processor B or in memory . The special purpose processor B may also be hardwired through circuit design to perform some or all of the operations to implement the present invention. Further the special purpose processor B may be a hybrid processor which includes dedicated circuitry for performing a subset of functions and other circuits for performing more general functions such as responding to computer program instructions. In one embodiment the special purpose processor B is an application specific integrated circuit ASIC .

The computer may also implement a compiler that allows an application or computer program written in a programming language such as COBOL Pascal C FORTRAN or other language to be translated into processor readable code. Alternatively the compiler may be an interpreter that executes instructions source code directly translates source code into an intermediate representation that is executed or that executes stored precompiled code. Such source code may be written in a variety of programming languages such as Java Perl Basic etc. After completion the application or computer program accesses and manipulates data accepted from I O devices and stored in the memory of the computer using the relationships and logic that were generated using the compiler .

The computer also optionally comprises an external communication device such as a modem satellite link Ethernet card or other device for accepting input from and providing output to other computers .

In one embodiment instructions implementing the operating system the computer program and the compiler are tangibly embodied in a non transient computer readable medium e.g. data storage device which could include one or more fixed or removable data storage devices such as a zip drive floppy disc drive hard drive CD ROM drive tape drive etc. Further the operating system and the computer program are comprised of computer program instructions which when accessed read and executed by the computer cause the computer to perform the steps necessary to implement and or use the present invention or to load the program of instructions into a memory thus creating a special purpose data structure causing the computer to operate as a specially programmed computer executing the method steps described herein. Computer program and or operating instructions may also be tangibly embodied in memory and or data communications devices thereby making a computer program product or article of manufacture according to the invention. As such the terms article of manufacture program storage device and computer program product as used herein are intended to encompass a computer program accessible from any computer readable device or media.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with the computer .

A network such as the Internet connects clients to server computers . Network may utilize ethernet coaxial cable wireless communications radio frequency RF etc. to connect and provide the communication between clients and servers . Clients may execute a client application or web browser and communicate with server computers executing web servers . Such a web browser is typically a program such as MICROSOFT INTERNET EXPLORER MOZILLA FIREFOX OPERA APPLE SAFARI GOOGLE CHROME etc. Further the software executing on clients may be downloaded from server computer to client computers and installed as a plug in or ACTIVEX control of a web browser. Accordingly clients may utilize ACTIVEX components component object model COM or distributed COM DCOM components to provide a user interface on a display of client . The web server is typically a program such as MICROSOFT S INTERNET INFORMATION SERVER Web server may host an Active Server Page ASP or Internet Server Application Programming Interface ISAPI application which may be executing scripts. The scripts invoke objects that execute business logic referred to as business objects . The business objects then manipulate data in database through a database management system DBMS . Alternatively database may be part of or connected directly to client instead of communicating obtaining the information from database across network . When a developer encapsulates the business functionality into objects the system may be referred to as a component object model COM system. Accordingly the scripts executing on web server and or application invoke COM objects that implement the business logic. Further server may utilize MICROSOFT S Transaction Server MTS to access required data stored in database via an interface such as ADO Active Data Objects OLE DB Object Linking and Embedding DataBase or ODBC Open DataBase Connectivity .

Generally these components all comprise logic and or data that is embodied in or retrievable from device medium signal or carrier e.g. a data storage device a data communications device a remote computer or device coupled to the computer via a network or via another data communications device etc. Moreover this logic and or data when read executed and or interpreted results in the steps necessary to implement and or use the present invention being performed.

Although the terms user computer client computer and or server computer are referred to herein it is understood that such computers and may be interchangeable and may further include thin client devices with limited or full processing capabilities portable devices such as cell phones notebook computers pocket computers multi touch devices and or any other devices with suitable processing communication and input output capability.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with computers and .

Embodiments of the invention are implemented as a software application on a client or server computer . Further as described above the client or server computer may comprise a thin client device or a portable device that has a multi touch based and or 3D enabled display capability.

It is very useful for a designer or rendering artist to easily determine various parameters related to the model or scene the designer artist is working on. To provide such capability embodiments of the invention propose that the look of the viewcube controller can be configured with different statistics as per the requirements desires of the user. Thus the viewcube controller can be configured to display statistics for different features such as scene complexity possible rendering time number of vertices in the model or scene etc.

If color is the property of the viewcube controller that is modified based on the statistics the viewcube controller may be assigned color s corresponding to the best and worst values with colors defined for intermediate values. For example if the option is set to fastest rendering time the viewcube controller can be colored in green yellow and red similar to a heat map showing that the camera angles with the fastest rendering time will be colored green the camera angles with medium rendering time will be colored yellow and the camera angles with the slowest rendering time with be colored red. Other intermediate colors can also be defined depending on the precision required by the user. For example a viewcube controller camera angle with 40 of fastest rendering time could be colored between red and yellow. When the viewcube controller is colored this way the user can then rotate the viewcube controller to see which angles provide the fastest rendering time and which ones provide the slower rendering time.

Further if the user is interested in rendering the scene in the shortest possible time the user can lock the camera angle for the scene based on input from viewcube controller . In this regard in the preferences for the viewcube controller there could be an option for automatically changing the camera angle for every frame to automatically adjust to the option set.

Another embodiment of the invention is that the settings on the viewcube controller could be a combination of different parameters such as rendering time rendering quality scene complexity etc. These parameters can be combined in different manners in the viewcube controller . For example the viewcube controller can display both a color map that shows the rendering time and another property say opacity or texture for rendering quality . This way the user can see two or more than two scene properties at the same time.

Another feature of this viewcube controller could be that the appearance of the controller could keep changing as the scene is updated. Thus as the user keeps modifying the scene or model the appearance of the controller is continuously updated in synchronization i.e. dynamically in real time with the changes that are happening on screen.

In view of the above embodiments of the invention overcome the problems of the prior art. More specifically in the prior art the values provided in the viewport were in the form of written text or presented as a dynamic graph on the viewport or profiler panel. In contrast embodiments of the invention present a novel approach of viewing different parameters related to the scene. Additional useful functionalities are provided for the already existing viewcube controller . Most existing icons or controllers only provide a single piece of information. However embodiments of the present invention make it possible for the user to see multiple pieces and types of information related to the scene as the user is working on the scene without opening up any additional panels.

At step a 3D representation e.g. a cube of a coordinate system of the 3D scene is displayed. Such a 3D representation has different faces that represent and correspond to different viewpoints of the 3D scene. Different statistics for features and or combinations of features of the 3D scene are reflected on the different faces of the 3D representation based on the viewpoint corresponding to each face . The statistics may reflect consist of estimated rendering times e.g. of the 3D scene from the viewpoints corresponding to the different faces estimated quality of rendering e.g. of the 3D scene from the viewpoints corresponding to the different faces a number of visible vertices in the 3D scene from the viewpoints corresponding to the different faces etc.

Step may further include displaying a graphical user interface comprising selectable options for the features selecting one or more of the options and modifying the statistics displayed on the different faces based on the selected options.

The statistics that are displayed on the faces of the 3D representation may consist of be based on colors. For example the colors displayed on the different faces may be based on a heat map with a first color e.g. red corresponding to a first statistic a second color e.g. green corresponding to a second statistic and a third color e.g. yellow corresponding to a third intermediate statistic.

At step the 3D scene is reoriented e.g. dynamically in real time based on the different viewpoint identified and selected from the manipulation of the 3D representation . In addition as modifications to the 3D scene are performed the 3D representation may be dynamically updated in real time to reflect such changes e.g. if new objects are added thereby increasing the estimated rendering time the 3D representation may be updated to reflect the increase.

This concludes the description of the preferred embodiment of the invention. The following describes some alternative embodiments for accomplishing the present invention. For example any type of computer such as a mainframe minicomputer or personal computer or computer configuration such as a timesharing mainframe local area network or standalone personal computer could be used with the present invention.

The foregoing description of the preferred embodiment of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

