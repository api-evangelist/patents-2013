---

title: Adaptive composite intra prediction for image and video compression
abstract: A method for encoding a video stream with at least one frame having a plurality of blocks of pixels including a current block. The method includes identifying, peripheral to the current block, a first set of pixels and a second set of pixels in the at least one frame, wherein the first set of pixels has been coded; determining whether the second set of pixels has been coded; and determining, for the current block, a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been coded.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09628790&OS=09628790&RS=09628790
owner: GOOGLE INC.
number: 09628790
owner_city: Mountain View
owner_country: US
publication_date: 20130103
---
Digital video streams may represent video using a sequence of frames or still images. Digital video can be used for various applications including for example video conferencing high definition video entertainment video advertisements or sharing of user generated videos. A digital video stream can contain a large amount of data and consume a significant amount of computing or communication resources of a computing device for processing transmission or storage of the video data. Various approaches have been proposed to reduce the amount of data in video streams including compression and other encoding techniques.

Implementations of systems methods and apparatuses for encoding and decoding a video signal using adaptive composite intra prediction are disclosed herein.

One aspect of the disclosed implementations is a method for encoding a video with at least one frame having a plurality of blocks of pixels including a current block. The method includes identifying peripheral to the current block a first set of pixels and a second set of pixels in the at least one frame wherein the first set of pixels has been coded determining whether the second set of pixels has been coded and determining for the current block a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been coded.

Another aspect of the disclosed implementations is a method for decoding at least one frame in an encoded video stream the frame having a plurality of blocks including a current block. The method includes identifying peripheral to the current block a first set of pixels and a second set of pixels in the at least one frame wherein the first set of pixels has been decoded determining whether the second set of pixels has been decoded and determining for the current block a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been decoded.

Another aspect of the disclosed implementations is an apparatus for encoding a frame in a video stream with at least one frame having a plurality of blocks including a current block. The apparatus includes a memory and a processor configured to execute instructions stored in the memory to identify peripheral to the current block a first set of pixels and a second set of pixels in the at least one frame wherein the first set of pixels has been coded determine whether the second set of pixels has been coded and determine for the current block a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been coded.

Digital video is used for various purposes including for example remote business meetings via video conferencing high definition video entertainment video advertisements or sharing of user generated videos. Video encoding and decoding codec can use various compression schemes. These compression schemes may include breaking a video image into blocks and generating a digital video output bitstream using one or more techniques to limit the information included in the output. A received bitstream can be decoded to re create the blocks and the source images from the limited information.

Encoding a video stream or a portion thereof such as a frame or a block can include using temporal and spatial similarities in the video stream to improve coding efficiency. For example a current block of a video stream may be encoded based on a previously encoded block in the video stream by predicting motion and color information for the current block based on the previously encoded block and identifying a difference residual between the predicted values and the current block.

Intra prediction can include using video data that has been previously encoded and reconstructed to predict the current block in the same frame. The predicted block is deducted from the current block and the difference i.e. the residual can be transformed quantized and entropy encoded to be included in a compressed video stream.

In some instances intra prediction makes use of video data above and or to the left of the current block to determine the prediction block for the current block. In many codec schemes such as the ones that use raster scanned coding video data above and to the left of the current block have been previously coded i.e. coded prior to the current block and thus available for use during intra prediction of the current block.

In implementations of this disclosure composite intra prediction modes can be used for intra prediction of the current block. Based on whether some or all sides peripheral to the current block have available video data a composite intra prediction mode can use a different set of equations to produce the prediction block. For example when it is determined that the video data in a column of pixels to the right of the current block has been coded or otherwise available for prediction the encoder can use this additional information to improve the quality of intra prediction. Since the composite intra prediction mode can produce different prediction blocks based on the availability of surround pixels without requiring additional signaling cost the overall coding efficiency is improved.

These and other examples are now described with reference to the accompanying drawings. is a schematic of a video encoding and decoding system in which aspects of the disclosure can be implemented. An exemplary transmitting station can be for example a computer having an internal configuration of hardware including a processor such as a central processing unit CPU and a memory . CPU is a controller for controlling the operations of transmitting station . CPU can be connected to the memory by for example a memory bus. Memory can be read only memory ROM random access memory RAM or any other suitable memory device. Memory can store data and program instructions that are used by CPU . Other suitable implementations of transmitting station are possible. For example the processing of transmitting station can be distributed among multiple devices.

A network connects transmitting station and a receiving station for encoding and decoding of the video stream. Specifically the video stream can be encoded in transmitting station and the encoded video stream can be decoded in receiving station . Network can be for example the Internet. Network can also be a local area network LAN wide area network WAN virtual private network VPN a cellular telephone network or any other means of transferring the video stream from transmitting station to in this example receiving station .

Receiving station can in one example be a computer having an internal configuration of hardware including a processor such as a CPU and a memory . CPU is a controller for controlling the operations of receiving station . CPU can be connected to memory by for example a memory bus. Memory can be ROM RAM or any other suitable memory device. Memory can store data and program instructions that are used by CPU . Other suitable implementations of receiving station are possible. For example the processing of receiving station can be distributed among multiple devices.

A display configured to display a video stream can be connected to receiving station . Display can be implemented in various ways including by a liquid crystal display LCD a cathode ray tube CRT or a light emitting diode display LED such as an OLED display. Display is coupled to CPU and can be configured to display a rendering of the video stream decoded in receiving station .

Other implementations of the encoder and decoder system are also possible. For example one implementation can omit network and or display . In another implementation a video stream can be encoded and then stored for transmission at a later time by receiving station or any other device having memory. In one implementation receiving station receives e.g. via network a computer bus or some communication pathway the encoded video stream and stores the video stream for later decoding. In another implementation additional components can be added to the encoder and decoder system . For example a display or a video camera can be attached to transmitting station to capture the video stream to be encoded.

At the next level single frame can be divided into a set of blocks which can contain data corresponding to in some of the examples described below a 4 4 pixel group in frame . Block can also be of any other suitable size such as a block of 16 8 pixels a block of 8 8 pixels a block of 16 16 pixels a block of 8 8 pixels or of any other size. Unless otherwise noted the term block can include a macroblock a subblock i.e. a subdivision of a macroblock a segment a slice a residual block or any other portion of a frame. A frame a block a pixel or a combination thereof can include display information such as luminance information chrominance information or any other information that can be used to store modify communicate or display the video stream or a portion thereof.

When video stream is presented for encoding each frame within video stream can be processed in units of blocks. Referring to at intra inter prediction stage each block can be encoded using either intra prediction i.e. within a single frame or inter prediction i.e. from frame to frame . In either case a prediction block can be formed. The prediction block is then subtracted from the block to produce a residual block also referred to herein as residual .

Intra prediction also referred to herein as intra prediction or intra frame prediction and inter prediction also referred to herein as inter prediction or inter frame prediction are techniques used in modern image video compression schemes. In the case of intra prediction a prediction block can be formed from samples in the current frame that have been previously encoded and reconstructed. In the case of inter prediction a prediction block can be formed from samples in one or more previously reconstructed reference frames.

The prediction block is then subtracted from the block the difference i.e. the residual is then encoded and transmitted to decoders. Image or video codecs may support many different intra and inter prediction modes each image block can use one of the prediction modes to provide a prediction block that is most similar to the block to minimize the information to be encoded in the residual. The prediction mode for each block can also be encoded and transmitted so a decoder can use the same prediction mode s to form prediction blocks in the decoding and reconstruction process.

The prediction mode can be selected from one of multiple intra prediction modes. The multiple intra prediction modes can include for example DC prediction mode horizontal prediction mode vertical prediction mode true motion prediction mode which can also be referred to as TM PRED or one or more composite intra prediction mode such as the ones described in . In one implementation of DC prediction mode a single value using the average of the pixels in a row above a current block and a column to the left of the current block can be used to predict the current block. In one implementation of horizontal prediction each column of a current block can be filled with a copy of a column to the left of the current block. In one implementation of vertical prediction each row of a current block can be filled with a copy of a row above the current block. In one implementation of TrueMotion prediction in addition to the row above the current block and the column to the left of the current block TM PRED uses the pixel P above and to the left of the block. Horizontal differences between pixels in the row above the current block starting from P are propagated using the pixels from the column to the left of the current block to start each row. In some implementations of the composite intra prediction modes in addition to the row above or the column to the left of the current block or pixel P a row to the right or a column below the current block or any pixels to the top right bottom left or bottom right of the current block may also be used to predict the current block. Other intra prediction modes can also be used.

The prediction mode can also be selected from one of multiple inter prediction modes using one or more reference frames including for example last frame golden frame alternative reference frame or any other reference frame in an encoding scheme. The inter prediction modes can include for example ZERO MV mode in which a block from the same location within a reference frame is used as the prediction block NEW MV mode in which a motion vector is transmitted to indicate the location of a block within a reference frame to be used as the prediction block NEAREST MV mode in which no motion vector is transmitted and the current block uses the last non zero motion vector used by previously coded blocks to generate the prediction block. When an inter prediction mode of NEW MV is selected a motion vector can be encoded which describes the position of the prediction block relative to the current block e.g. offsets of the coordinates . When an inter prediction mode is selected a motion vector can be encoded which describes the position of the prediction block relative to the current block e.g. offsets of the coordinates .

Next still referring to transform stage transforms the residual into a block of transform coefficients in for example the frequency domain. Examples of block based transforms include the Karhunen Lo ve Transform KLT the Discrete Cosine Transform DCT Walsh Hadamard Transform WHT and the Singular Value Decomposition Transform SVD . In one example the DCT transforms the block into the frequency domain. In the case of DCT the transform coefficient values are based on spatial frequency with the lowest frequency e.g. DC coefficient at the top left of the matrix and the highest frequency coefficient at the bottom right of the matrix.

Quantization stage converts the block of transform coefficients into discrete quantum values which are referred to as quantized transform coefficients using a quantizer value or quantization levels. The quantized transform coefficients are then entropy encoded by entropy encoding stage . The entropy encoded coefficients together with other information used to decode the block which can include for example the type of prediction used motion vectors and quantization value are then output to compressed bitstream . Compressed bitstream can be formatted using various techniques such as variable length encoding VLC and arithmetic coding. Compressed bitstream can also be referred to as an encoded video stream and the terms will be used interchangeably herein.

The reconstruction path in shown by the dotted connection lines can be used to provide both encoder and a decoder described below with the same reference frames to decode compressed bitstream . The reconstruction path performs functions that are similar to functions that take place during the decoding process that are discussed in more detail below including dequantizing the quantized transform coefficients at dequantization stage to generate dequantized transform coefficients and inverse transforming the dequantized transform coefficients at inverse transform stage to produce a derivative residual block i.e. derivative residual . At reconstruction stage the prediction block that was predicted at intra inter prediction stage can be added to the derivative residual to create a reconstructed block. In some implementations loop filtering stage can be applied to the reconstructed block to reduce distortion such as blocking artifacts.

Other variations of encoder can be used. For example a non transform based encoder can quantize the residual block directly without transform stage . In another implementation an encoder can have quantization stage and dequantization stage combined into a single stage.

When compressed bitstream is presented for decoding the data elements within compressed bitstream can be decoded by the entropy decoding stage using for example Context Adaptive Binary Arithmetic Decoding to produce a set of quantized transform coefficients. Dequantization stage dequantizes the quantized transform coefficients and inverse transform stage inverse transforms the dequantized transform coefficients to produce a derivative residual that can be identical to that created by reconstruction stage in encoder . Using header information decoded from compressed bitstream decoder can use intra inter prediction stage to create the same prediction block as was created in encoder e.g. at intra inter prediction stage .

At reconstruction stage the prediction block can be added to the derivative residual to create a reconstructed block that can be identical to the block created by reconstruction stage in encoder . In some implementations loop filtering stage can be applied to the reconstructed block to reduce blocking artifacts. Deblocking filtering stage can be applied to the reconstructed block to reduce blocking distortion and the result is output as output video stream . Output video stream can also be referred to as a decoded video stream and the terms will be used interchangeably herein.

Other variations of decoder can be used to decode compressed bitstream . For example decoder can produce output video stream without deblocking filtering stage .

Method of operation can be implemented using specialized hardware or firmware. Some computing devices can have multiple memories multiple processors or both. The steps of method of operation can be distributed using different processors memories or both. Use of the terms processor or memory in the singular encompasses computing devices that have one processor or one memory as well as devices that have multiple processors or multiple memories that can each be used in the performance of some or all of the recited steps.

Implementations of method of operation can include for example receiving a video stream including a frame having blocks of video data including a current block at a step identifying a first set of pixels and a second set of pixels peripheral to the current block in the frame at a step determining whether the second set of pixels has been coded at a step and determining for the current block a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been coded at a step .

At step a video stream including a frame having multiple blocks of video data including a current block can be received by a computing device such as transmitting station . Received as used herein includes acquired obtained read or received in any manner whatsoever. The video data or stream can be received in any number of ways such as by receiving the video data over a network over a cable or by reading the video data from a primary memory or other storage device including a disk drive or removable media such as a CompactFlash CF card Secure Digital SD card or any other device capable of communicating video data. In some implementations video data can be received from a video camera connected to the computing device.

At step a first set of pixels and a second set of pixels peripheral to the current block can be identified from the frame. The first set of pixels can include pixels from previously coded blocks in the frame. For example the first set of pixels can be identified from a block above to the left or to the above left of the current block in the frame. The second set of pixels can be identified from a block below to the right the above right the below right or the below left of the current block in the same frame. The first or second set of pixels can be for example a set of reconstructed pixels determined using the reconstruction path in at encoder .

The first or second set of pixels can be identified from a single block or multiple blocks peripheral to the current block. For example the first set of pixels can include pixels from a single block such as the block to the left of the current block and the second set of pixels can include pixels from multiple blocks such as the block to the right of the current block and the block below the current block.

In some implementations a composite intra prediction mode can be identified for the current block the first set of pixels and the second set of pixels can be identified based the composite prediction mode. As will be described in detail below the composite intra prediction mode can use different equations to produce a prediction block based on which sides of the current block have available pixel values for prediction. The composite intra prediction mode itself can be encoded and transmitted in the video stream.

In some implementations the first set of pixels can include one or more rows of pixel values above the current block or one or more columns of pixel values to the left of the current block or a pixel from a block to the top left of the current block or any combination thereof. In other implementations data from rows or columns not immediately adjacent to the current block including data from blocks that are not adjacent to the current block can be included in the first set of pixels. The second set of pixels can include a column of pixel values to the right of the current block a row of pixel values below the current block a pixel from a block to the bottom right of the current block a pixel from a block to the top right of the current block or a pixel from a block to the bottom left of the current block or any combination thereof.

At step whether the second set of pixels has been coded can be determined. If the second set of pixels has been coded prior to the current block the second set of pixels may be available to use for predicting the current block. If the second set of pixels has not been coded the second set of pixels may not be available to use for predicting the current block. In some implementations encoder may use a scanning order other than the raster scanning order which allows the blocks associated with the second set of pixels to be coded prior to the current block.

At step a prediction block can be determined for the current block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been coded.

If it has been determined at step that the second set of pixels has not been coded only the first set of pixels may be used to determine the prediction block. For example at least a portion of the first set of pixels e.g. a row a column or a pixel can be used to determine the prediction block for the current block.

If it has been determined at step that the second set of pixels has been coded the second set of pixels and the first set of pixels can both be used to determine the prediction block. For example at least a portion of the first set of pixels and at least a portion of the second set of pixels can be used to determine the prediction block based on the determination that the second set of pixels has been coded.

In some implementations a set of weighted values can be identified for the at least a portion of the first set of pixels and the at least a portion of the second set of pixels. For example different weight values can be associated with different pixels in the first and second sets of pixels. The prediction block can be determined based on the set of weighted values and the corresponding pixel values in the first and second set of pixels as shown by the examples in .

Although not shown in the residual which can be determined based on the difference between the current block and the prediction block such as the prediction block determined at step can be encoded. For example the residual can be quantized at quantization stage and entropy coded at entropy encoding stage . The encoded video stream can be transmitted stored further processed or a combination thereof. For example the encoded video stream can be stored in a memory such as the memory or shown in . The encoded video stream can also be transmitted to a decoder such as the decoder shown in .

Method of operation is depicted and described as a series of steps. However steps in accordance with this disclosure can occur in various orders or concurrently. Additionally steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore not all illustrated steps may be required to implement a method of prediction using composite intra prediction modes.

As shown in the first set of pixels which can be identified at step can include a set of previously coded pixels. For example the first set of pixels can include a column of 4 pixels L LA to the immediate left of current block a row of 4 pixels A A immediately above of current block or a pixel C to the above left of current block or any combination thereof. However other previously coded pixels values not shown in can also be used.

The second set of pixels can include a set of pixels as shown in . For example the second set of pixels can include a column of 4 pixels R R to the immediate right of current block a row of 4 pixels B B below the current block 3 pixels C C to the top right C below left C and below right C corner of current block or any combination thereof.

In one example a composite intra prediction mode for vertical prediction can be described as follows 

ELSE 1 2 3 4 1 wherein Pij is the predicted value for pixel Xij in the current block row A and row B are rows of 4 pixels immediately above and below the current block respectively Wa and Wb are weighted values associated with row A and row B.

In this example when it is determined that row B i.e. the row below current block is not available i.e. has not been coded row A can be used for determining the predicted values Pij for current block . When it is determined that row B is available i.e. has been coded both rows A and B can be used for determining the predicted values Pij of the prediction block. The weighted values Wa Wa Wa and Wb Wb Wb can be adjusted for different applications.

In another example a composite intra prediction mode for horizontal prediction can be described as follows 

ELSE 1 2 3 4 2 wherein Pij is the predicted value for pixel Xij in the current block column L and column R are columns of 4 pixels to the immediate left and right of the current block respectively Wl and Wr are weighted values associated with column L and column R.

In this example when it is determined that column R i.e. the column to the right of current block is not available i.e. has not been coded column L can be used for determining the predicted values Pij of the prediction block for current block . When it is determined that column R is available i.e. has been coded both columns L and R can be used for determining the predicted values Pij of the prediction block. The weighted values Wl Wl Wl and Wr Wr Wr can be adjusted for different applications.

ELSE 1 3 4 3 4 3 wherein Pij is the predicted value for pixel Xij in the current block row A and row B are rows of 4 pixels immediately above and below the current block respectively column L and column R are columns of 4 pixels to the immediate left or right of the current block respectively.

In this example the equations in 3 do not include weighted values. However weighted values such as Wa Wb Wl Wj in 1 and 2 can be applied to rows A B and columns L R in 3 . Other weighted values can also be used.

Implementations of decoding the encoded video stream can include for example receiving encoded video stream at a step identifying an encoded current block from an frame in the encoded video stream at a step identifying a first set of pixels and a second set of pixels in the frame at a step determining whether the second set of pixels has been decoded at a step determining a prediction block using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been decoded at a step and decoding the encoded current block using the prediction block at a step .

At step a computing device such as receiving station may receive encoded video stream such as compressed bitstream . The encoded video stream which may be referred to herein as the encoded video data can be received in any number of ways such as by receiving the video data over a network over a cable or by reading the video data from a primary memory or other storage device including a disk drive or removable media such as a DVD CompactFlash CF card Secure Digital SD card or any other device capable of communicating a video stream.

At step an encoded current block can be identified from a frame in the encoded video stream. The encoded current block can be for example a block that has been encoded at encoder using any of the composite intra prediction modes described herein such as the composite horizontal or vertical prediction mode described in .

At step a first set of pixels and a second set of pixels peripheral to the encoded current block can be identified from the frame in the video stream.

The first set of pixels can include pixels from previously decoded blocks in the frame such as a block from the same frame as the current block that has been decoded prior to the current block. For example the first set of pixels can be identified from a block above to the left or to the above left of the current block in the same frame. The second set of pixels can be identified for example from a block below to the right above right below right or below left of the current block in the same frame.

In some implementations a composite intra prediction mode can be identified for the current block and the first set of pixels and the second set of pixels can be identified based the composite prediction mode. The composite intra prediction mode can be decoded from the video stream. The composite prediction modes can include any of the examples described in or any other applicable composite prediction mode.

The first or second set of pixels can be identified from a single block in the frame or multiple blocks peripheral to the current block in the same frame. For example the first set of pixels can include pixels from multiple blocks such as the block to the left of the current block and the block above the current block the second set of pixels can also include pixels from multiple blocks such as the block to the right of the current block and the block below the current block.

In some implementations the first set of pixels can include one or more rows of pixel values above the current block or one or more columns of pixel values to the left of the current block or both. For example the first set of pixels can include one of a column of pixels from the block to the left of the current block a row of pixels from a block above the current block a pixel from a block to the top left of the current block or any combination thereof. In other implementations data from rows or columns not immediately adjacent to the current block including data from blocks that are not adjacent to the current block can be included in the first set of pixels.

In some implementations the second set of pixels can include one of a column of pixels from a block to the right of the current block a row of pixels from a block below the current block a pixel from a block to the bottom right of the current block a pixel from a block to the top right of the current block or a pixel from a block to the bottom left of the current block or any combination thereof.

At step whether the second set of pixels has been decoded can be determined. If the second set of pixels has been decoded prior to the current block the second set of pixels may be available to use for predicting the current block. If the second set of pixels has not been decoded prior to the current block the second set of pixels may not be available to use for predicting the current block. In some implementations decoder may use a scanning order other than the raster scanning order which allows the blocks such as a block to the right or below the current block associated with the second set of pixels to be decoded prior to the current block.

At step a prediction block is determined using the first set of pixels and the second set of pixels based on the determination of whether the second set of pixels has been decoded.

If the second set of pixels has been determined as not having been decoded only the first set of pixels may be used to determine the prediction block. For example at least a portion of the first set of pixels can be used to determine the prediction block for the current block.

If the second set of pixels has been determined as having been decoded both the second set of pixels and the first set of pixels can be used to determine the prediction block. For example at least a portion of the first set of pixels and at least a portion of the second set of pixels can be used to determine the prediction block based on the determination that the second set of pixels has been decoded.

In some implementations a set of weighted values can be identified for the at least a portion of the first set of pixels and the at least a portion of the second set of pixels. For example different weight values can be associated with different pixels in the first and second sets of pixels. The prediction block can be determined based on the set of weighted values and the corresponding pixel values in the first and second set of pixels. For example the prediction block for the composite intra prediction modes described in can be determined using the equations 1 2 or 3 using the weighted values and the first or second set of pixels or both.

At step the encoded current block can be decoded using the prediction block. For example the encoded current block can be entropy decoded at entropy decoding stage dequantized at dequantization stage and inverse transformed at inverse transform stage to determine a derived residual. The derived residual can be added to the prediction block determined for the current block at step to reconstruct the current block at reconstruction stage . A frame can be reconstructed from the reconstructed blocks and the output can be an output video stream such as the output video stream shown in and may be referred to as a decoded video stream.

Method of operation is depicted and described as a series of steps. However steps in accordance with this disclosure can occur in various orders or concurrently. Additionally steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore not all illustrated steps may be required to implement a method in accordance with the disclosed subject matter.

The implementations of encoding and decoding described above illustrate some exemplary encoding and decoding techniques. However encoding and decoding as those terms are used herein could mean compression decompression transformation or any other processing or change of data.

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Moreover use of the term an implementation or one implementation or an implementation or one implementation throughout is not intended to mean the same implementation or implementation unless described as such.

A computing device implementing the techniques disclosed herein and the algorithms methods instructions etc. stored thereon and or executed thereby can be realized in hardware software or any combination thereof including for example IF cores ASICS programmable logic arrays optical processors programmable logic controllers microcode microcontrollers servers microprocessors digital signal processors or any other suitable circuit or other information processing device now existing or hereafter developed. In the claims the term processor should be understood as encompassing any of the foregoing hardware either singly or in combination. The terms signal and data are used interchangeably.

Further in some implementations for example the techniques described herein can be implemented using a general purpose computer processor with a computer program that when executed carries out any of the respective methods algorithms and or instructions described herein. In addition or alternatively for example a special purpose computer processor can be utilized which can contain specialized hardware for carrying out any of the methods algorithms or instructions described herein.

In some implementations transmitting station and receiving station can for example be implemented on computers in a screencasting system. Alternatively transmitting station can be implemented on a server and receiving station can be implemented on a device separate from the server such as a hand held communications device i.e. a cell phone . In this instance transmitting station can encode content using an encoder into an encoded video signal and transmit the encoded video signal to the communications device. In turn the communications device can then decode the encoded video signal using a decoder . Alternatively the communications device can decode content stored locally on the communications device i.e. content that was not transmitted by transmitting station . Other suitable transmitting station and receiving station implementation schemes are available. For example receiving station can be a generally stationary personal computer rather than a portable communications device and or a device including an encoder may also include a decoder .

Further all or a portion of implementations of the present invention can take the form of a computer program product accessible from for example a computer usable or computer readable medium. A computer usable or computer readable medium can be any device that can for example tangibly contain store communicate or transport the program for use by or in connection with any processor. The medium can be for example an electronic magnetic optical electromagnetic or a semiconductor device. Other suitable mediums are also available.

The above described embodiments implementations and aspects have been described in order to allow easy understanding of the present invention and do not limit the present invention. On the contrary the invention is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structure as is permitted under the law.

