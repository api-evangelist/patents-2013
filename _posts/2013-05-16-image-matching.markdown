---

title: Image matching
abstract: A method performed by a system. The method includes comparing at least one query image received from a mobile device with a plurality of planes stored in a memory, matching the query image with at least one of the plurality of planes, and determining a location based on the matching of the query image with the at least one plane. Comparing the at least one query image with the plurality of planes includes executing a warping function between the at least one query image and the plurality of planes to determine at least a first matching score for matching the at least one query image with at least one of the plurality of planes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09075826&OS=09075826&RS=09075826
owner: Hewlett-Packard Development Company, L.P.
number: 09075826
owner_city: Houston
owner_country: US
publication_date: 20130516
---
Digital imaging devices and wireless communication technologies have seen dramatic improvements over the past years. Increasing number of today s mobile users carry multiple mobile devices. Various mobile devices such as Internet enabled tablets smart phones and laptops have become essential personal accessories connecting users to friends work and entertainment. These mobile devices have various features can generate digital images and can be used for different personal or professional purposes. Users now have more functionality choices and expect to use their mobile devices not only as communication tools but also as data and guidance systems.

In the following detailed description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific examples in which the disclosed subject matter may be practiced. It is to be understood that other examples may be utilized and structural or logical changes may be made without departing from the scope of the present disclosure. The following detailed description therefore is not to be taken in a limiting sense and the scope of the present disclosure is defined by the appended claims. Also it is to be understood that the phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. The use of including comprising or having and variations thereof herein is meant to encompass the items listed thereafter and equivalents thereof as well as additional items. It should also be noted that a plurality of hardware and software based devices as well as a plurality of different structural components may be used to implement the disclosed methods and systems.

As used herein the terms mobile device and wireless device may be used interchangeably and refer to any one of various smart phones e.g. iPhone cellular telephones tablets e.g. iPAD laptop computers personal data assistants PDA s VoIP phones wireless enabled entertainment systems and other similar electronic devices that include a processor a camera and are capable of sending and receiving images and wireless or wired communication signals.

As used herein the term communication interface refers to various protocols available to any of the wireless devices to communicate with each other and with a network. In particular the communications interface may include Wi Fi Bluetooth 3G 4G and any other comparable communications interfaces.

As used herein the term automatically refers to acting or operating in a manner essentially independent of external human influence or control. A system or an element of a system may have the capability to start operate perform functions etc. independently of specific requests or regulations.

As used herein the term plane refers to a planar region or a surface in an imaged area e.g. a scene of an indoor environment. The planes are constructed or determined from a plurality of images or maps by using different imaging techniques and methods. The images used to construct the planes correspond to a specific location e.g. a scene such as a meeting room cubicle area corridor class room etc. of an environment e.g. office building college building or complex etc. . Therefore each plane is associated with a specific image location in the environment. As described in additional detail below plurality of planes from a plurality of images are collected and stored in a memory. In some examples the planes are stored with at least image texture information and plane location information i.e. coordinates of the plane in the imaged environment .

As used herein the terms pixel domain validation or pixel domain validation analysis may be used interchangeably and refer to directly comparing the image texture of a query image generated by a mobile device with the image texture of at least one of plane selected from a plurality of planes stored in a memory. In some examples directly comparing the image texture of a query image with the image texture of at least one plane includes taking in consideration possible color and intensity changes of the query image and the plane viewpoint and camera specifications.

With the improvements in digital imaging devices and wireless communication technologies many users of mobile devices expect to utilize their mobile devices to immediately determine a location e.g. indoor or outdoor in an environment. One option that can be offered to such users is finding a location based on a photo i.e. a digital image also called a query image in this description captured with the mobile device. This process is also called image based localization. While the methods and systems discussed herein primarily describes indoor image based localization the methods can be also applied for determining an outdoor location. Finding indoor location by using an image captured with a mobile device can be both faster and more accurate than common localization methods based on Wi Fi and magnetic fields. While a picture can be taken instantly Wi Fi and magnetic field based methods typically require a warm up period before accuracy can be established. From a deployment perspective integrated cameras are universal in mobile devices and typically have a general application programming interface API that works across different manufacturers or wireless providers. In contrast compasses are not universal in mobile devices and are rarely present in laptops. There is no general API to access low level Wi Fi information for accurate location computation.

Nonetheless there are two fundamental challenges in image based localization based on an image captured with a mobile device. First indoor environments are often designed to have similar appearances e.g. cubicle areas in offices . This means that highly discriminating algorithms are required to determine indoor location. Second when an image based method for determining indoor location is used a picture can be taken from an arbitrary camera pose and focal length. When those parameters are known or can be estimated it is generally computationally feasible to infer a location from a three dimensional 3D model of an earlier captured environment. However it is generally very difficult or not possible to determine camera pose and focal length parameters from a single picture that generally is a two dimensional 2D image.

This description is directed to systems methods and machine readable storage medium for determining a location based on a captured query image from a mobile device i.e. image based localization method . The proposed systems and methods support accurate image based localization when camera pose and focal length information is not available. In particular the description proposes a system to capture different locations corridors meeting rooms lounges etc. of various environments i.e. buildings etc. that will be searched by using a collection of planar surfaces i.e. planes that are associated with a specific location i.e. specific meeting room portion of a corridor etc. in an environment. A database is created that includes a plurality of planes that are generated from a plurality of images. As described in additional detail below the images can be captured and processed to retrieve the planes or the planes can be retrieved from detailed figures representing specific indoor environment e.g. building plans construction plans etc. 

In one example the proposed method is performed by a system and includes comparing at least one query image received from a mobile device with a plurality of planes stored in a memory. The planes are generated from a plurality of images corresponding to locations in an environment and each plane is associated with a location in the environment. Comparing the at least one query image with the plurality of planes includes executing a warping function between the at least one query image and the plurality of planes. In some examples executing the warping function includes geometric analysis of matching feature descriptors between the at least one query image and the plurality of planes to determine a matching score for matching the at least one query image with at least one of the plurality of planes. The warping function can involve warping i.e. transforming either the query image or selected matching planes using a 3 3 homography matrix to compare the planes from the memory with portions of the query image and to determine a matching score. The method further includes matching the query image with at least one of the plurality of planes and determining a location based on the matching of the query image with the at least one plane. Additionally comparing the at least one query image with the plurality of planes can further include performing pixel domain validation analysis.

The proposed methods and systems rely on using extracted planes of the environment to determine a location based on an image captured with a mobile device. Because indoor environments typically contain an abundance of planes these methods introduce several advantages. For example the methods can accurately determine indoor location e.g. meeting room cubicle etc. without using any non planar structure in their analysis. Further considering that the camera pose and the focal length of the mobile device generating the image are fixed but generally unknown the proposed methods execute a warping function that includes geometric analysis of matching feature descriptors between the image from the mobile device and the plurality of planes to determine a location. Since all points on a 3D plane are related to pixels in a query image through a single 3 3 homography matrix the methods can use many points to reliably estimate projection matrix of a plane and to match it to an image from a mobile device to determine a location.

The mobile device belongs to and is operated by a user not shown to allow the user to communicate with other users and or to perform image based localization via the device . In the illustrated example the mobile device is a smart phone. However the mobile device may also include a tablet a laptop computer or any other mobile device that includes a camera and can generate images. In alternative examples the user can own or operate more than one mobile device and can decide which device to use to perform image based localization. The mobile device includes a camera not shown that is operable to capture images and send them to the computer via the network . Further the mobile device includes at least one communication interface that is used to connect with the other mobile devices or to the network . The communication interfaces of the mobile device may include a Wi FI interface a Bluetooth interface a 3G interface a 4G interface a near filed communication NFC interface and any other suitable interface.

The wireless access points A C may include any type of access point that allows a communication between the mobile device and the network . In the illustrated example the wireless access points of the system include a 3G tower A a Wi FI access point B and a 4G tower C. In alternative examples the system can include other suitable access points. Each access point has an associated coverage area not shown . It is to be understood that the various access points may have different power levels and consequently may have different coverage areas.

The network is configured to connect the computing device and the mobile device so the device can transmit query images not shown to the computing device and the computing device can transmit signals and information to the mobile devices via the cloud. The network may include any suitable type or configuration of network to allow the computing device to communicate with the mobile device or other wireless devices not shown . For example the network may include wide area network WAN e.g. a TCP IP based network a cellular network such as for example a Global System for Mobile Communications GSM network a General Packet Radio Service GPRS network a Code Division Multiple Access CDMA network an Evolution Data Optimized EV DO network an Enhanced Data Rates for GSM Evolution EDGE network a 3GSM network a 4GSM network a Digital Enhanced Cordless Telecommunications DECT network a Digital AMPS IS 136 TDMA network or an Integrated Digital Enhanced Network iDEN network etc. . The network can further include a local area network LAN a neighborhood area network NAN a home area network HAN a personal area network PAN a public switched telephone network PSTN an Intranet the Internet or any other suitable network.

The computing device provides functionality to perform image based localization based on a query image sent from the mobile device to the computing device . As described in additional detail below in one example the computing device compares at least one image received from the mobile device to a plurality of planes that are stored in a memory. Alternatively the query image may be acquired by the mobile device and may be sent to the computing device via another device or system in the cloud. The planes are associated with different locations e.g. meeting rooms cubicle areas corridors class rooms etc. of an indoor environment e.g. office building or complex college building or complex etc. . Using a warping function and a pixel domain validation analysis the computing device matches the query image with at least one of the plurality of planes to determine a location of the user sending the image based on the matching of the query image with the at least one plane.

The communication interface enables the computing device and the system to communicate with a plurality of networks. The input interfaces can process content e.g. images from the mobile device or another external device system. In one example the input interfaces include at least a media interface . In other examples the input interface can include additional interfaces. The media interface receives media input e.g. a query image from a mobile device e.g. the mobile device or another system and can include for example a connector interface a storage device interface or a local or wireless communication port which receives the media input from the mobile device. In addition to the query image from the mobile device the media input may include for example a document a video a slide show or presentation or other media content. For example media input from other devices systems can be used to create or supplement a plane database stored in the memory .

The processor includes a control unit and may be implemented using any suitable type of processing system where at least one processor is configured to execute computer readable instructions stored in the memory . The memory includes any suitable type number and configuration of volatile or non transitory machine readable storage media configured to store instructions and data. Examples of machine readable storage media in the memory include read only memory ROM random access memory RAM e.g. dynamic RAM DRAM synchronous DRAM SDRAM etc. electrically erasable programmable read only memory EEPROM flash memory hard disk an SD card and other suitable magnetic optical physical or electronic memory devices. The memory may also be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor .

The memory may also store an operating system such as Mac OS MS Windows Unix or Linux network applications and various modules e.g. an image based localization module . The operating system can be multi user multiprocessing multitasking multithreading and real time. The operating system can also perform basic tasks such as recognizing input from input devices such as a keyboard a keypad or a mouse sending output to a projector and a camera keeping track of files and directories on medium controlling peripheral devices such as disk drives printers image capture device and managing traffic on the bus . The network applications include various components for establishing and maintaining network connections such as computer readable instructions for implementing communication protocols including TCP IP HTTP Ethernet USB and FireWire.

The machine readable storage media are considered to be an article of manufacture or part of an article of manufacture. An article of manufacture refers to a manufactured component. Software stored on the machine readable storage media and executed by the processor includes for example firmware applications program data filters rules program modules and other executable instructions. The control unit is configured to retrieve from the machine readable storage media and execute among other things instructions related to the control processes and methods described herein.

In one example the user account module provides instructions that allow a user to register the mobile device and any other mobile devices with the system . That way the system recognizes devises that belong to the same user and can determine a location of the user based on an image sent by one of the mobile devices at any given time. During his or her first use of the system a user creates a user account i.e. a profile by providing personal information to the system via a user interface not shown . A user may enter the information via the user interface of the mobile devices or a user interface connected to the computing device . After creating an account the user registers the at least one mobile device associated with that user by providing information about the device and the user e.g. preferred locations favorite environments etc. . At any time the user can update his or her account by adding or removing devices . It is to be understood that the systems and methods described herein may be configured to determine location based on a query image without a user registration of the mobile device .

As explained in additional details below the image based localization module provides various computer readable instruction components for comparing at least one query image received from the mobile device with a plurality of planes stored in the memory matching the query image with at least one of the plurality of planes and determining a location based on the matching of the query image with the at least one plane.

Information and data associated with the system the wireless device and other systems devices can be stored logged processed and analyzed to implement the control methods and processes described herein. In addition to the data acquisition module the memory includes a data logger or recorder and a datacenter . The DAQ module is configured to receive information or data from various external devices or systems. In one example the DAQ module receives or acquires images or planes associated with specific locations e.g. hallways meeting rooms cubicle areas etc. of indoor environments e.g. office buildings school buildings hotels etc. . The DAQ module can receive a plurality of images captured from multiple depth cameras that include details of the specific indoor environment.

The information gathered by the DAQ module is provided to the data logger or recorder . The data logger or recorder is configured to store the information e.g. images planes building plans maps etc. in the datacenter for further storage and processing. In one example the datacenter is included in the memory of the computing device . In another example the datacenter is a remote datacenter i.e. not located in the computer . In that example the data logger or recorder provides the information through a network e.g. the network to the datacenter .

First the control unit detects all possible lines or straight edges of planes in the received depth image e.g. by applying a Canny Edge Detector and using a Progressive Probabilistic Hough Transform . Next the control unit traverses all line pairs e.g. by using a J linkage algorithm to determine if a line joining the mid point of the two edges lies on a plane. By using the plane rendering module the control unit then constructs planes for each possible line pairs and merges all possible planes in an image. As shown in in some examples at least one or a plurality of planes can be constructed from a single image. Alternatively where an image does not include planes the control unit does not construct any planes. As mentioned above each plane is associated with a specific location e.g. cubicle area corridor rooms etc. of the indoor environment e.g. building etc. and that location can be later provided to a user based on a comparison between a captured query image and the stored planes.

The plurality of planes P is stored in the datacenter to form a plane database. The maps for the plurality of environments are also stored in the datacenter . Since every depth image Id is segmented into planar regions R1 R2 . . . Ri the corresponding planes P1 P2 . . . Pi for each image Id include the following information 1 

where Iis the corresponding image texture of the region Ri fis a list of features descriptors in the image texture I xis a list of 2D homogeneous coordinates for each descriptor in f and locis the location of the region Ri in the map for the specific environment e.g. office building etc. . Therefore each plane P regardless whether is directly received by the system or constructed by the processor is stored in the datacenter with at least image texture information and plane location information i.e. coordinates defining the location of the plane . From the image texture Ithe control unit can determine the feature descriptors for each plane or region. Various methods can be used to determine the local feature descriptors. In addition the control unit can organize the determined feature descriptors for each plane into k d trees.

Therefore the information and data stored in the datacenter can be accessed by the computing device for processing and analysis. For example the computing device is configured to process and analyze the planes stored in the datacenter to determine a location of a user based on at least one query image acquired by the user s mobile device . In one example the mobile device directly sends the query image to the computing device . Alternatively the mobile device may acquire the image and the image may be sent to the computing device via another system.

As noted above the control unit is configured to retrieve from the machine readable storage media and execute among other things instructions related to the control processes and methods described herein. When executed the instructions cause the control unit to construct a plurality of planes for a plurality of images and to store the planes in the memory . Further the instructions cause the control unit to process a query image received from the mobile device and to identify feature descriptors of the query image. In addition the instructions cause the control unit to compare the query image with the plurality of planes by using geometric analysis of matching feature descriptors between the query image and the plurality of planes and to compute a matching score to match the query image with at least one of the plurality of planes by performing pixel domain validation. Finally instructions cause the control unit to determine a location based on the highest matching score.

The following paragraphs describe methods for determining a location based on an image generated by a mobile device the method being performed by the processor of the computing device . The proposed methods assist users with accurate image based localization and allow them to immediately determine their indoor location by using the camera of their mobile devices.

The method may be executed in the form of instructions encoded on a non transitory machine readable storage medium executable by the processor . In one example the instructions for the method are stored in the image based localization module .

The method begins in step where the control unit compares at least one query image Iq received from a mobile device with a plurality of planes stored in the memory . As noted above the plurality of planes can be generated or constructed from a plurality of images and each plane is associated with an image location in the indoor environment. In one example comparing the at least one query image Iq with the plurality of planes includes executing a warping function between the at least one query image and the plurality of planes. Executing the warping function involves geometric analysis of matching feature descriptors.

Further comparing the at least one query image Iq with the plurality of planes may also include performing pixel domain validation analysis. As mentioned above the computing device can receive at least one image captured with the mobile device . For instance when a user walks into a large office or university campus and she wants to determine her exact location the user may take a photo with her mobile device e.g. a smart phone tablet etc. and use the photo to perform image based localization.

Next at step the control unit matches the query image Iq with at least one of the plurality of planes. In one example matching of the query image with at least one of the plurality of planes includes determining at least one matching score based on the warping function i.e. on the geometric analysis of the matching feature descriptors and the pixel domain validation analysis. Finally at step the control unit determines a location based on the matching of the query image with the at least one plane. In one example the control unit selects a plane with the highest matching score to determine the location.

During the execution of the method the query image Iq is compared to all planes stored in the datacenter . First in step the control unit computes or identifies feature descriptors f f . . . f for the query image Iq where the feature descriptors are identified as f. The control unit can use various different algorithms or processes e.g. scale invariant feature transform SIFT speeded up robust features SURF etc. to compute the feature descriptors J of the query image Iq. Next in step the control unit compares the feature descriptors fof the query image Iq with the feature descriptors for all planes stored in the datacenter e.g. by using the Best bin first algorithm or another available algorithm . In step the control unit determines if there are any matching feature descriptors between the query image and the stored planes. If there are no matching feature descriptors at step the control unit sends an error message to the user e.g. No location found etc. . Then the user takes another query image and the computing device receives the new query image at step .

If the control unit determines that there are matching feature descriptors between the query image and the planes stored in the memory the control unit executes a warping function between the at least one query image and the plurality of planes at step . In one example executing the warping function includes geometric analysis of matching feature descriptors between the at least one query image and the plurality of planes to determine a first matching score for matching the at least one query image with at least one of the plurality of planes. By initially determining whether there are matching feature descriptors between the query image and the plurality of planes steps and the method removes unnecessary data i.e. feature descriptors to be analyzed in the geometric analysis of matching descriptors at step .

In one example the control unit performs the warping function between the at least one query image and the plurality of planes as follows. The control unit first stores the correspondent list of matching descriptors as a set of vectors C c c c c . . . c c where c fand c f. Since the feature descriptors in the plane Pi are coplanar the corresponding cand cshould be related by a 3 3 homography matrix H which is determined by the warping function e.g. random sample consensus RANSAC or another similar function .

In other words instead of independently matching all feature descriptors between the query image and the plurality of planes and counting the number of matches the control unit executes a warping function that involves geometric analysis of the matching feature descriptors determined at steps and between the query image and the plurality of planes. Specifically the control unit warps i.e. transforms either the query image or the selected matching planes using a 3 3 homography matrix Hto compare the planes from the memory with portions of the query image which may include more than one planes and to determine a first matching score at step . The first matching score matches the at least one query image with at least one of the plurality of planes.

By using the warping function the control unit performs geometric analysis of the matching feature descriptors between the query image and the plurality of planes i.e. when either the query image or the planes are warped by comparing not only the matching feature descriptors but also the distance between these feature descriptors to determine the first matching score. Thus the first matching score represents the number of aligned pairs of feature descriptors between the query image and the least one plane or a plurality of planes where applicable and the distance between the aligned feature descriptors. As a result at step the control unit selects at least one plane from the plurality of planes stored in the memory for pixel domain validation analysis based on the geometric analysis of the matching feature descriptors i.e. based on the first matching score . In other words the control unit selects planes at least one but possibly more than one that have the highest first matching score for further analysis e.g. pixel domain validation analysis . As described below it is also possible that there are planes that match the query image based on the geometric analysis of the matching feature descriptors.

In one example the first matching score is calculated as follows. As noted above the first matching score is determined based on aligned i.e. matching pairs of feature descriptors between the query image and the plurality of planes and the calculated distance between the matching pairs. Ideally matching pairs of feature descriptors between the query image and a plane should align perfectly after warping either the plane or the image. However in practice there are some misalignments between the warped images. The number of feature descriptor pairs that conforms to the planar assumption after warping can be computed as the number of pairs with dissimilarity score gless than a threshold T where gis given by the maximum error when feature descriptor in one perspective is projected onto a different perspective. The following formula is used to calculate the dissimilarity score g max 2 

where xand xare the homogeneous coordinates of the feature descriptors cand con their associated images respectively. Further . represents the Euclidean distance between the matching feature descriptor pairs of the query image and the plane. Therefore formula 2 proposes warping the query image to a plane and checking the misalignment distance and warping the plane to the query image and again checking the misalignment distance. After that the larger misalignment between the plane and the query image is selected as the dissimilarity score for that plane. When the false matches are removed an updated homography matrix H is obtained using the remaining correspondence pairs of feature descriptors. Therefore the method creates a refined list of planes that is selected for pixel domain validation analysis.

In step the control unit determines if at least one plane is selected for pixel domain validation analysis. If no planes were selected for pixel domain validation analysis based on the geometric analysis of the matching feature descriptors i.e. on the first matching score the control unit performs steps and . On the other hand if at least one plane from the plurality of planes stored in the memory is selected based on the geometric analysis of the matching feature descriptors the control unit performs pixel domain validation analysis on the at least one plane or a plurality of planes where more than one is selected .

In one example the control panel can determine location based on the query image only by executing the warping function and performing geometric analysis of matching feature descriptors between the at least one query image and the plurality of planes. In other words the first matching score may be sufficient to match the query image to at least one of the planes and to determine a location based on the plane location steps and . For example the control unit can select the plane with the highest first matching score from the plurality of analyzed planes to determine a location of the user. As noted above each plane has a plane location that is associated with a specific location in the indoor environment. By selecting a matching plane the control unit can retrieve the plane location from the memory and can send the location to the user s mobile device e.g. as a portion of the building s map pointing to the specific location of the plane in the building . In the described situation the control unit may not perform pixel domain validation analysis of the planes selected based on the first matching score.

In other examples at step the method continues with performing pixel domain validation analysis of the planes selected based on the geometric analysis of matching feature descriptors i.e. based on the first matching score . Pixel domain validation analysis can include directly comparing the image texture of the query image generated by the mobile device with the image texture of the plane selected based on the geometric analysis of the matching feature descriptors. In some examples directly comparing the image texture a query image with the image texture of at least one plane includes considering possible color and intensity changes of the query image and the plane viewpoint and camera specifications.

Instead of using the number of matching feature descriptor pairs to compare the selected planes with the query image pixel domain validation analysis compares image textures i.e. how well the pixels in the planes match the query image after the warping function is performed . There are two main benefits to that approach. First when the number of matching feature descriptor pairs between the query image and a plain is small the chance of false random match is not insignificant but can be readily eliminated by comparing the image textures. Second even when the number of matching feature descriptor pairs between the query image and a plain is large it is difficult to determine the correct plane out of two similar looking planes in different locations using only the matching feature descriptor pairs since they are subject to inconsistency of feature selection. In contrast pixel domain validation analysis can be more accurate by considering the image textures i.e. all pixels available without resampling.

In one example pixel domain validation analysis is performed as follows. First for all planes that were selected based on the geometric analysis of the matching feature descriptors the control unit computes the following normalized texture 

where I is the texture for the plane Pi and are respectively the mean and variance of the plane and and are the mean and variance of the corresponding region in the query image Iq. This normalization is performed for each of the three color channels which are chosen to be in the RGB color space to minimize correlation. The normalization is required to account for differences in illumination color intensity viewpoint camera specifications etc. between the query image and the planes. The control unit can use different methods for computing the texture of the planes e.g. structured approach statistical approach etc. .

Next the control unit compares the Euclidean distance between the aligned pixels of I and Iq i.e. between the texture of the plain and the texture of the query image . At step the control unit determines a second matching score based on the pixel domain validation. If the geometric analysis of the matching feature descriptors identified only one plane for pixel domain validation analysis pixel domain validation is only performed for that plane. If however more than one plane from the plurality of planes stored in the memory is selected based on the geometric analysis of the matching feature descriptors the control unit determines a second matching score for all these planes based on the pixel domain validation. In one example the second matching score for each selected planel Pi is computed as the ratio of matched image textures i.e. pixels to non matched image textures R 0 1.

Based on the second matching score the control unit matches the query image Iq to at least one of the planes by going to step . For example the control unit can select the plane with the highest second matching score from the plurality of planes that were analyzed using pixel domain validation to match the query image to that plane. Next the control image determines a location based on the plane by going to step . As described above the control unit can retrieve the plane location associated with the selected matching plane from the memory and can send the location e.g. as a portion of the building s map pointing to the location to the users mobile device . Therefore in one example comparing the query image to the plurality of planes stored in a memory includes both executing a warping function and performing a pixel domain validation analysis. Further matching the query image with at least one of the plurality of planes is based on the warping function by selecting at least one plane for further analysis and the pixel domain validation analysis. By executing these steps the system offers a robust image based localization method for determining a location.

In some examples after pixel domain validation analysis is performed the control unit determines that there are multiple high second matching scores i.e. multiple planes with similarly high scores . If the multiple high second matching scores point to the same location on the map of the environment that is not an issue. However in some example the multiple high second matching scores can point to different locations of the environment. Therefore the control unit cannot determine one specific location on the map of the environment saved in the memory . This can happen in highly repetitive environments such cubicles in office buildings. In step the control unit determines a whether there are multiple high second matching scores based on the pixel domain validation that disagree or point to different locations. If there are no multiple high second matching scores that point to different locations the control unit proceeds to steps and to match the query image Iq with least one of the planes by selecting the plane with the highest second matching score and to determine a location based on the matched plane.

On the other hand when the control unit determines that there are multiple high second matching scores pointing to different locations based on the pixel domain validation the control unit computes a weighted score and uses the weighted score to compute a refined second matching score to determine a location of the query image at step . Generally planes in different locations that have similarly high second matching score have similar image textures. Having similar image textures makes it difficult to determine which is the correct plane that matches the query image. Therefore in one example a weighted score is computed by reducing the weight of the similar textures. For example two cubicle walls may be identical except for a small region containing different name plates. A more discriminating or defined score can be computed by applying a smaller weight to the common image texture of the planes.

Specifically given a set of planes circumflex over P i.e. at least two planes that has a high second matching score the control unit computes normalized textures circumflex over I for the set of planes and compares that to the textures of the query image Iq. In one example the control unit counts the number of times each pixel in the query image Iq scores a match. The final per pixel weight for each pixel x y of the query image Iq is computed as a logistic function of the pixel count Cx y 

where a and b are constants that control how fast weights drop off as Cx y increases with normalization so that 1 when Cx y 1. In one example a and b can be 4 and 0.6 respectively. However other parameters or other weight functions can be adopted for different application needs. Finally a refined second matching score is computed as 

Therefore the control unit uses the computed weighted score to further compute a refined second matching score using the ratio of matched image textures i.e. pixels to non matched image textures. Based on the refined second matching score the control unit proceeds to steps and to match the query image Iq with least one of the planes by selecting the plane with the highest refined second matching score and to determine a location based on the matched plane.

The control unit is also operable to automatically update the plurality of planes in the memory based on the matching the query image with at least one of the plurality of planes. For dynamic indoor environments offices schools etc. it is common for objects to be rearranges added or removed which makes a scene i.e. a plurality of planes to differ from the original scene with the original planes stored in the memory. Instead of frequently reimaging the indoor environment and uploading new planes to the memory the control panel automatically updates the datacenter can be updated by using the matching query images.

In one example the control unit keeps a count for each pixel in every plane stored in the memory i.e. pixel resolution . When a plane is chosen as the matching plane to the query image the control panel updates the count for its pixels by giving a high score for matching pixels between the plane and the query image and a low score for mismatched pixels. In such a way if a sub region i.e. a plane in a location of an environment has changed since the last imaging of the environment the count for this changed region in a plane would be smaller than the count for the other parts of the plane. After receiving a smaller count from multiple query images the changed region would generally have a sizably smaller count.

In one example the described method is implemented as follows. First the control unit increases the count of a plane by 1 if a pixel of the selected plane matches a pixel in the query image and by 2 1 2 if the pixel is mismatched in the query image. After a plane has been matched to a number of query images by the system the control panel examines the distribution of count in that plane to detect if objects have been removed. If a pixel s count value is significantly smaller than the other pixels in a plane or smaller than an average of count values for a plane the control unit determines that the pixel is moved and that pixel is not considered for future matching. This information about the pixel s count value is propagated to all other planes with the same location. Through homography mapping between different planes the corresponding pixels can be located and updated accordingly.

Therefore the proposed systems methods and instructions stored in non transitory machine readable storage medium offer a robust real time method for image based localization. The proposed methods can determine a location based on a query image captured with a mobile device regardless the camera pose or focal length even in a repetitive indoor environment that includes similar characteristics.

