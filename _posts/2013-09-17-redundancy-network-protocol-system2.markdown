---

title: Redundancy network protocol system
abstract: A redundancy network protocol system may include a server to manage one or more virtual internet protocol address (VIP) profiles. Each VIP profile may be shared across one or more neighboring servers. The neighboring servers may be in the same broadcast domain or distributed to be multiple Layer 3 hops away from one another. The redundancy network protocol system may monitor server health and reachability and further manage the server health and reachability to achieve redundancy. The system may be used to provide high availability to selected applications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09571603&OS=09571603&RS=09571603
owner: Cisco Technology, Inc.
number: 09571603
owner_city: San Jose
owner_country: US
publication_date: 20130917
---
The present disclosure relates to server clusters and more specifically to maintaining virtual internet protocol address VIP profiles among servers of the server clusters.

High availability clusters are groups of computers typically servers which support server applications that can be reliably utilized with a minimum of down time. High availability within an application space is also to ensure that an application service remains available even after a failure such as hardware software or otherwise. For example applications that implement communication over internet protocol IP over a cluster may redirect IP traffic to an alternate server in the cluster in an event a primary server in the cluster cannot process or handle the requests. Other examples of applications benefitting from high availability include database applications financial applications web sites and back to back user agents B2BUA among various others.

By way of introduction the example embodiments described below include a device and method to monitor component health and reachability and further to manage component health reachability and server application redundancy. The device and method may be used to provide high availability to selected applications.

According to a first aspect a server may maintain VIP profile corresponding to an application. The VIP profile may be shared between the server and a neighboring server which is at least one router hop away from the server. The server may be configured to determine a first priority associated with the server and a second priority associated with the neighboring server and compare the first priority and the second priority. The server may be further configured to select the neighboring server as an active server of the VIP profile based on the second priority being greater than the first priority. The active server may be the server that handles a client request directed to the VIP profile

In a second aspect a method at a first server may include monitoring receipt of a status message at a predetermined socket address and identifying a second server based on the status message such that the second server is one or more router network hops away from the first server and the first server and the second server may be participating in a VIP profile cluster. The method may further include comparing a first priority associated with the first server and a second priority associated with the second server. The second priority may be extracted from the status message. Based on comparing the priorities and the first priority being greater than the second priority the method may include selecting the first server as an active server of the VIP profile cluster.

In a third aspect a non transitory computer readable storage medium is provided where the storage medium includes instructions that may discover neighboring servers located in a broadcast domain by listening for an advertisement message from each of the neighboring servers at a predetermined destination address and add an identity of each of the neighboring servers to a neighbor list in response to a respective advertisement message from each of the neighboring servers wherein the neighboring servers are one or more router hops away from each other. The instructions may further monitor a reachability value associated with each of the neighboring servers and further monitor a priority value associated with each of the neighboring servers. The instructions may further be directed to selection of an active server of the VIP profile from the neighbor list based on the reachability value and the priority value of in response to addition of a neighboring server to the neighbor list.

It is to be understood that the following description of examples of implementations are given only for the purpose of illustration and are not to be taken in a limiting sense. The partitioning of examples in function blocks modules or units shown in the drawings is not to be construed as indicating that these function blocks modules or units are necessarily implemented as physically separate units. Functional blocks modules or units shown or described may be implemented as separate units circuits chips functions modules or circuit elements. Alternatively or in addition one or more functional blocks or units may also be implemented in a common circuit chip circuit element or unit.

The system may include at least a server along with additional servers such as server server and a server . The servers and may also be referred to as nodes. Each server may participate in one or more VIP profiles such as VIP profile VIP profile and VIP profile . Each of the VIP profiles and may be shared across a combination of the servers and with one of the servers being selected as an active server. The system provides each of the VIP profiles and with a unique VIP. For example the VIP profile may be assigned the VIP 10.1.1.1 the VIP profile may be assigned the VIP 200.1.2.3 and the VIP profile may be assigned the VIP 100.50.50.10.

The VIP profile may be a group of servers including the server and the server allocated to a server application with the server as the active server. The active server may handle client requests directed to the application . The application may implement high availability and benefit from having the group of servers with the VIP. The VIP may be portable among the servers of the VIP profile. In the event that a server can no longer process or handle a request for the application the VIP may be moved to another server allowing for a transparent recovery by the other server handling the request. The set of servers being shared by a VIP profile may be referred to as a VIP profile cluster. The servers in a VIP profile may also be referred to as neighboring servers of the VIP profile or the VIP profile cluster. Except the active server of the VIP profile cluster all other neighboring servers may be standby servers and marked INACTIVE for the VIP profile cluster. Such sharing of the VIP profiles may be achieved by using a redundancy network protocol. depicts the active server of each VIP profile in bold.

The VIP profile may be shared across the servers and with the server as the active server. The VIP profile may correspond to an application . As another example also illustrates a VIP profile allocated to an application and the VIP profile being shared across the servers and and the server being the active server for the VIP profile . Thus as an example the server and the server are neighboring servers that share the VIP profile as well as the VIP profile .

Each of the applications and may be a database application a web site an enterprise wide application a load balancing application or a back to back user agent B2BUA application or any application being executed on one or more servers. The VIP profile may be configured so that the application has high availability. This may be achieved by selecting the server as the active server shown in bold for the VIP profile which handles requests from the clients directed to the VIP of the VIP profile . In response to a failure at the server the VIP profile may select the server as the active server. Further when the server is functioning again or if another server is added to the VIP profile the active server for the VIP profile may be reselected from among the servers sharing the VIP profile . The active server for the VIP profile may be reselected in response to removal of any of the servers sharing the VIP profile from the VIP profile . Alternately or in addition the application may be load balanced across the server and the server . Load balancing involves distributing client requests across multiple servers by a load balancer. The load balancer may be a separate device. Alternately the load balancer may be an application corresponding to another VIP profile such as VIP profile . In the above example client requests to the application may be distributed to the servers and the server that share the VIP profile . The load balancer may balance the load across the VIP profile based on the configuration of the load balancer. The load balancer may determine if the cluster of servers in the VIP profile is functioning without any errors by querying the active server for overall cluster health. The load balancer may be access and use information provided by neighbor discovery performed by the VIP profile as a way to auto provision the neighboring servers of the VIP profile for load balancing. Additionally in response to the auto provisioning by the load balancer the neighboring servers of the VIP profile may benefit from singleton election and control by maintaining an instance of a session of the application across each of the neighboring servers of the VIP profile .

The processor may perform tasks of the server and control the operation of the server . The processor may work in conjunction with the frameworks and to manage various aspects of the VIP profiles and . The memory may include instructions executable by the processor . The memory may also store data from the modules of the server such as a neighbor list that contains an identity of each neighboring server in each of the VIP profiles the server participates in. The memory may also contain one neighbor list per VIP profile containing the identity of each neighboring server participating in a corresponding VIP profile. The memory may also contain statistics on messages received from neighboring servers such as a last time a message was received number of neighboring servers and also local statistics regarding state such as transitions from active to inactive server and vice versa time of last state changed and tracking object statistics such as execution time number of successful executions and causes of failures.

The NIC may enable communication over a network. The NIC may be hardware such as an embedded component as part of a circuit board a computer mother board a router an expansion card a printer interface a USB universal serial bus device or as part of any other hardware. The network may be a packet based network. The network may include a local area network LAN a wireless local area network WLAN a WI FI a registered trademark of Wireless Ethernet Compatibility Alliance Inc. of Austin Tex. network a personal area network PAN a wide area network WAN the Internet an IP network any other communications network or any combination thereof. The network may utilize any protocol of 3G 4G EDGE 4G LTE Bluetooth a registered trademark of Bluetooth Sig Inc. of Kirkland Wash. WiMax a registered trademark of WiMax Forum of San Diego Calif. GPRS UMTS HSDPA HSPA or any other protocol or any combination thereof.

The framework may include modules that manage the VIP profile . The framework may include at least a VIP profile manager a neighbor manager a reachability monitor a graceful close monitor and an application manager . Each module described herein such as the VIP profile manager the neighbor manager the reachability monitor the graceful close monitor and the application manager is hardware or a combination of hardware and software. For example each module may include and or initiate execution of an application specific integrated circuit ASIC a Field Programmable Gate Array FPGA a circuit a digital logic circuit an analog circuit a combination of discrete circuits gates or any other type of hardware or combination thereof. Accordingly as used herein execution of a module by a processor can also refer to logic based processing by the module that is initiated directly or indirectly by a processor to complete a process or obtain a result. Alternatively or in addition each module can include memory hardware such as at least a portion of a memory for example that includes instructions executable with a processor to implement one or more of the features of the module. When any one of the modules includes instructions stored in memory and executable with the processor the module may or may not include a processor. In some examples each unit may include only memory storing instructions executable with the processor to implement the features of the corresponding module without the module including any other hardware. Because each module includes at least some hardware even when the included hardware includes software each module may be interchangeably referred to as a hardware unit such as the VIP profile manager hardware unit the neighbor manager hardware unit the reachability monitor hardware unit the graceful close monitor hardware unit and the application manager hardware unit.

The frameworks and may function similar to the framework . The framework may include modules that manage the VIP profile such as a VIP profile manager a neighbor manager a reachability monitor a graceful close monitor and an application manager . The framework may include modules that manage the VIP profile such as a VIP profile manager a neighbor manager a reachability monitor a graceful close monitor and an application manager . Each of the frameworks and may operate independent of each other since each of the VIP profiles the server participates in are independent of each other. Thus a failure or other event on the server in regard to the VIP profile does not trigger the VIP profiles and to respond.

The VIP profile manager may manage or administer the VIP profile by performing at least the steps shown in .

At step the neighbor manager may discover all the neighboring servers in the VIP profile . Such discovery may involve monitoring for and receiving a periodic status message from the neighboring servers. The periodic status message may also be referred to as a keepalive message or an advertisement message. In step based on the discovered neighboring servers the profile manager may maintain the neighbor list that contains identities of all the neighboring servers in the VIP profile . The neighbor list may be a database. The neighbor list may be stored using one or more tables and or one or more lists. In step the neighbor manager may periodically transmit the keepalive message to the neighboring servers at a predetermined time interval. The predetermined time interval may be synchronized to be consistent among the neighboring servers. The predetermined time interval may be user defined in a configuration file of the VIP profile. A destination address of the keepalive message may be broadcast multicast and or unicast address. The keepalive message may be transmitted and received via user datagram protocol UDP or any other communication protocol.

The keepalive message received from a transmitting neighboring server may be encoded for example as shown in . The keepalive message contains information regarding at least a version a priority field a keepalive interval a preemption value an active status a neighbor count an authentication string a VIP field a source IP address and a subgroup identifier string . The version may indicate a format used by the keepalive message. In other examples other formats and or protocols that provide similar information may be used for the keepalive message.

The priority field may indicate a preference such as a value of the transmitting neighboring server as the active server of the VIP profile. In an example where values are used to indicate the preference a higher value may be considered more preferred. A predefined value such as zero may indicate that the transmitting neighboring server is in discovery mode identifying all the neighboring servers. The priority field may have a value within a specified range such as 0 255. The priority value may be set to a maximum value indicated by configuration settings once the discovery mode is completed. In other examples any other values or data may be used to indicate varying degrees of preference. The priority value may be further updated or adjusted by tracking objects. Each tracking object may have a decrement or increment value associated by which the priority value may be modified on execution of the tracking object. The priority value may be incremented on successful execution of the tracking object and decremented in response to failure of execution of the tracking object. For example the server may start off with a priority value set to zero while the server is in the discovery stage. On completion of the discovery stage the priority value may be set to 100 which may be set as the maximum priority value by the configuration settings. During this time the tracking object may begin execution on server startup. Initially the tracking object may be considered in a failed state till indication of a successful execution. If the decrement value associated with the tracking object is 10 the priority value may be set to 90 after discovery completes 100 10 90 . Upon a successful execution of the tracking object the priority value would be restored by the decrement value thus restoring the priority value to 100. The priority value may never exceed the maximum value indicated by the configuration settings. Similarly the priority value may never be below a minimum value indicated by the configuration settings. If the execution of the tracking object may lead to the priority value moving beyond either extreme suggested by the configuration settings the priority value is capped at either the minimum value or the maximum value.

The keepalive interval may be a length of time after which the transmitting neighboring server transmits the periodic keepalive message. The keepalive interval may be an indicator of a period of time such as milliseconds. In an example a value of the keepalive interval may be in a specified range such as 25 65535 and set to a default value such as 5 seconds. The neighboring servers of any VIP profile may synchronize the keepalive interval among themselves.

A preemption value indicates whether the transmitting neighboring server performs preemption. The neighboring servers of any VIP profile may synchronize the preemption value among themselves. The active status may indicate whether the transmitting neighboring server is the active server of the VIP profile. Only one neighboring server of any VIP profile may be the active server of that VIP profile. Even in case of the application corresponding to the VIP profile being load balanced the VIP profile may have one active server which may be the singleton root authority for the neighboring servers of the VIP profile.

The neighbor count may be the number of current neighboring servers of the transmitting neighboring server. Any server may determine the neighbor count based on a number of keepalive messages received by that server. The server with the neighbor count of value zero may indicate that the server is not receiving any keepalive messages which may indicate an error. Neighbors with the neighbor count of zero may be excluded from a process to select the active server of the VIP profile. The neighbor count may be limited to a predetermined number of neighboring servers such as 65535.

The authentication string may be any predetermined string of digits such as a zero padded string that any of the servers may use to determine that the keepalive message is from one of the neighboring servers of one of the VIP profiles the server is participating in. In an example the authentication string may be a UTF 7 string of 32 octets. All neighboring servers of the VIP profile may have a similar authentication string and in some examples the servers of the VIP profile may have the same authentication string . The VIP field may provide the address assigned to the VIP profile. The address may be for example an IPv4 or an IPv6 address. The VIP field of the keepalive message transmitted by the neighboring servers of the VIP profile may contain the same address. In an example the VIP field may be a UTF 7 string 46 octets in size.

The source address may provide an address of the NIC of the transmitting neighboring server. In an example the source address may contain a UTF 7 string 46 octets in size. The source address may be for example an IPv4 or IPv6 address.

The subgroup identifier string value may convey a subgrouping within the VIP profile that may differ from one neighboring server to another. The subgroup identifier string may be used by the VIP profile manager to determine a subgroup of the neighboring servers in the VIP profile. The VIP profile manager may perform additional steps when communicating with the neighboring servers in the subgroup. Such additional steps may include real time replication of application data associated with the application at the neighboring servers in the subgroup. Neighboring servers in a subgroup may also be identified by load balancers as servers among which to balance traffic directed to the active server in the event that the active server fails or is unable to handle the traffic. In case the subgroup is not identified the load balancer may default to using other servers in the VIP profile . Alternately the load balancer may identify another subgroup in the VIP profile and determine the neighboring servers to load balance the traffic based on such information. The load balancer may determine which of the above option to take based on a sticky configuration.

Additional fields may be added to the keepalive message such as meta data user defined data and data that may facilitate tracking objects of the neighboring servers. Further all fields of the keepalive message may have a predefined length. In another example a field of the keepalive message may be of variable length the current length value of the field indicated by another field of the keepalive message. If contents of a particular field are not of the predefined length the contents may be zero padded. Different versions of the keepalive message may have additional or lesser number of fields. Further a different version of the keepalive message may include and interpret a field in a different way.

The neighbor manager may monitor a predetermined socket or a predetermined port for the keepalive or status message from the neighboring servers of the VIP profile such as the server . The neighboring servers may be located on the same broadcast domain as the server . The neighboring servers may be zero network hops away. Alternately or additionally if the neighboring server is located one or more network hops away the server may receive the keepalive message from the server as a multicast or a unicast message directed to the IP address of the NIC . A network hop may constitute a router or some other Layer 3 network device along a data path from the server to the server . A hop count may indicate a number of such intermediate devices encountered along the data path from the server to the server . In one example system the hop count along the data path from the server to the server may be greater than one. Unicast neighboring servers may be detected as being unicast if a receiving socket is bound to unicast. When a neighboring server is detected as unicast keepalive messages may be automatically forwarded over unicast to the neighboring server which does not require additional configuration. If the keepalive message is received from the neighboring server on a unicast socket then the neighboring server is considered unicast and therefore a return keepalive message to the neighboring server may be transmitted via unicast. In case the keepalive message is received as part of a broadcast the neighboring server may be considered zero network hops away. In such a case the return keepalive message is transmitted via a predetermined broadcast address. Further yet if the keepalive message is received as part of a multicast the neighboring server may be considered zero or more network hops away. In this case the return keepalive message may be transmitted via a predetermined multicast address.

In response to receiving the keepalive message from the neighboring servers in an example the framework may perform at least the steps shown in . After receiving the keepalive message in step in step the framework determines if the keepalive message received is the one transmitted by the server itself and ignores the keepalive message if it is indeed from self. In step the neighbor manager may determine if the VIP profile has been configured and in a valid state on the server . The neighbor manager may ignore the keepalive message if the VIP profile has not been validly configured as enabled. During maintenance the VIP profile may be disabled instead of being de configured. This allows for a fast startup of the corresponding application on completion of the maintenance. The neighbor manager may further in step authenticate the keepalive message based on the authentication string included in the keepalive message. In step the neighbor manager may synchronize the keepalive interval of the server and the server . The neighbor manager may update the period to send the keepalive message to the keepalive interval associated with the server if the latter is smaller. In step the neighbor manager may synchronize the preemption value between the server and the server . For example if the preemption value associated with the server is TRUE and the preemption value associated with the server is FALSE the preemption value of the server may be updated to TRUE.

In step the neighbor manager may first determine if the server is already identified in the neighbor list corresponding to the VIP profile . If this is the first time that the neighbor manager received the keepalive message from the server the neighbor manager may add an identity of the server to the neighbor list. The received information from the keepalive message may be stored under an entry object for the server in the neighbor list. The neighbor list may also hold run time statistics for the server . For example the neighbor count a number of keepalive messages received from the server last time a keepalive message was received from the server and the priority of the server may be stored in the entry object of the server in the neighbor list. The neighbor manager may leave the neighbor list unchanged if the server is already identified in the neighbor list. The neighbor manager may update the information stored in the entry object of the server if such updated information is received via the keepalive message. The neighbor manager may also keep track of a number of intervals since the server has sent the keepalive message. When a predetermined number of consecutive intervals are missed the neighbor manager may remove the identity of the server from the neighbor list of the VIP profile by contacting the VIP profile manager .

Step corresponds to a process of neighbor selection in which the neighbor manager may select the active server for the VIP profile from among those listed in the neighbor list. The neighbor manager may loop through all the neighboring servers listed in the neighbor list to determine a best candidate for the active server. illustrates an example flowchart of steps involved with a first neighboring server in the neighbor list. Initially the neighbor manager may select any of the neighboring servers on the neighbor list as the best candidate. Step may be initiated in response to receipt of a keepalive message. Alternately step may be initiated in response to an unsuccessful attempt made to transmit the keepalive message to the first neighboring server. The neighbor manager may maintain a count of attempts made to transmit the keepalive message to the first neighboring server. Every time the neighbor manager receives the keepalive message from the first neighboring server the count corresponding to the first neighboring server may be reset else a count of attempts to transmit the keepalive message to the first neighboring server is incremented. If the count of attempts to transmit the keepalive message to the first neighboring server has crossed a threshold value the neighbor manager may determine in to remove the first neighboring server from the neighbor list and move on to a next neighboring server on the neighbor list. Alternately In the neighbor manager may determine if the first neighboring server should be removed from the neighbor list in response to a neighbor age associated with the first neighboring server. The neighbor age may reflect passage of a number of time intervals since an attempt to transmit the keepalive message to the first neighboring server. The neighbor manager may remove the first neighboring server in response to the neighbor age of the first neighboring sever having crossed a predetermined threshold. In step the neighbor manager may compare a priority of the best candidate first priority with a priority of the neighboring server second priority obtained from the priority field of the keepalive message received. In step the neighbor manager may determine whether the second priority is greater than the first priority. If that is the case step may select the neighboring server as the best candidate for active server of the VIP profile based on the second priority being greater than the first priority. If the first priority is greater than the second priority the best candidate does not get changed. Instead if it is determined in step that the first priority and the second priority are equal the neighbor manager may further compare as in step an IP address allocated to the best candidate with the IP address allocated to the neighboring server. The IP address allocated to the neighboring server can be obtained from the source IP address of the keepalive message received from the neighboring server. In step the neighbor manager may select the neighboring server as the active server of the VIP profile if the IP address associated with the neighboring server is lower than the IP address associated with the best candidate. The two IP address values may be compared numerically by comparing at the bit level. The best candidate may remain unchanged if the IP address associated with the best candidate is lower than the IP address associated with the neighboring server. In step the neighbor manager processes the next neighboring server in the neighbor list.

Unidirectional neighboring servers could result in suboptimal neighbor selection or in some cases a selection of the active server that not all neighboring servers are aware of. Unicast neighbors may pose increased possibility that neighboring server could be unidirectional in communication. The system may mitigate this issue by decrementing the priority associated with the neighboring server that has a neighbor count different than other neighboring servers. The more the neighboring server has similar neighbor count equal the less the decrement value. The neighbor count can also be used to invalidate the neighboring server if the neighboring server has the neighbor count of zero. The priority may be decremented by a decrement value initiated to a user defined value provided in the profile configuration. The decrement value may further be updated based on the difference between the neighbor counts of the neighboring servers and number of the keepalive messages received by the neighboring servers. An example logic to update the decrement value may be 

The following example involving neighboring servers Node 1 Node 2 and Node 3 walks through the above logic. Assume Node 1 and Node 2 have bi directional communication but node 3 cannot communicate to nodes 1 and 2 but can receive the keepalive messages from other servers and can communicate via the network. The priority values of the three neighboring servers before execution of the above logic may be 

The above logic when executed reduces the priority of node 3. the state of the VIP profile after the execution of the logic would be as follows 

The selection of the active server based on the above steps may result in preemption of the active server during a predetermined event such as a critical production time. Whether such preemption occurs may be controlled by the preemption setting that is synchronized among the neighboring servers of the VIP profile . If the preemption value on all the neighboring servers is disabled the neighbor selection may not select a new active server unless the current active server is first deactivated. With preemption enabled the neighbor selection selects the new active server based on the steps described earlier. By default the preemption setting may be enabled. Preemption may not desirable during predetermined events such as the critical production times. The system may control when preemption takes place by maintaining a preemption window. The maintenance window may be a predefined length of time during which the priority of the server cannot be changed. The preemption window may also be referred to as a maintenance window. The maintenance window may be observed periodically. The VIP profile manager may decrement the priority of the server only if following conditions are met 

The VIP profile manager may keep track of a transition counter that indicates a number of times the server may have switched between being the active server and the inactive server of the VIP profile . The transition counter may increment when the state changes from ACTIVE to INACTIVE. The maintenance window may not apply if the priority of the server is being updated in response to a failure of the server. The above conditions reduce the priority of the active server only after the VIP profile has had a transition between ACTIVE and INACTIVE during the non maintenance window period. The user defined value and the configured priority may be obtained from the configuration file of the VIP profile .

The server determines in step if the server is selected as the active server of the VIP profile the VIP profile manager in step may transmit a gratuitous address resolution protocol GARP message to all devices on the same subnet as the VIP of the VIP profile . The GARP message may advertise a change in MAC address for the VIP to the MAC address of the server . If all the neighboring servers in the VIP profile are on the same subnet they all may update their respective address tables accordingly.

A possible error state may result if two neighboring servers the servers and falsely believe they each should become the active server for the VIP profile . Such a state may be referred to as split brain. This can result in database corruption and or data loss. The reachability monitor may prevent a split brain situation. The reachability monitor may ensure that the server is a valid high availability server by monitoring a reachability of the server . The monitoring may involve periodically or non periodically measuring the reachability of the server . The reachability may be measured by counting the number of unique network hops for a given set of IP addresses. A user defined min hops value may be used to determine if the server has network visibility to qualify as the valid high availability server. The reachability monitor may record routed network hops using internet control message protocol ICMP time to live TTL . In the case of split brain if the reachability of the server is below min Hops then the server may not be selected as the active server for the VIP profile even if the server is the only server available.

Monitoring the reachability may involve generating packets for each TTL value up to a user defined max TTL. Thus a max TTL of 10 may imply that 10 packets would be transmitted with TTL in each packet set incrementally. All packets may be transmitted at once in a non blocking fashion. If min hops is 3 then 3 unique TTL time exceeded messages from network hops may be expected. The network hops may not be sequential in order to meet the minimum. The end station destination may not be counted. The reachability may be a number of unique network hops encountered or visited in this process. Routing loops may be de duped and therefore repeated duplicate responses for different TTL s would be treated as 1 hop. The reachability monitor may coordinate with the profile monitor to disable sending and processing the keepalive messages for ALL VIP profiles the server participate in if the reachability does not meet the min Hops. When the reachability of the server is below the min Hops the profile monitor may further make the server inactive for all the VIP profiles and the server participates in. Alternately every VIP profile may have a setting that may result in the reachability of the server being ignored for the VIP profile.

The profile monitor may be a module that may monitor the VIP profiles the server participates in the VIP profiles and . The profile monitor may periodically cycle through the VIP profiles and . illustrates a flowchart of a sequence of steps that may be followed by the profile monitor for each of the VIP profiles. For instance when the profile monitor encounters the VIP profile in step the profile monitor determines if the VIP profile is a new VIP profile. If so configuration information for the VIP profile is updated in step . In step the profile monitor determines if it is time to transmit the keepalive message to the neighboring servers of the VIP profile . If it is not time to transmit the keepalive message for the encountered VIP profile the profile monitor returns to the loop to process a next VIP profile in step . If it is time to transmit the keepalive message for the VIP profile the profile monitor coordinates with the neighbor manager to transmit the keepalive message to the neighboring servers of the VIP profile in step . In step the neighbor manager determines if the keepalive message was sent successfully. The neighbor manager may maintain in step a number of attempts the neighbor manager has made to transmit the keepalive message to the neighboring servers of the VIP profile . After a predefined threshold value of number of unsuccessful attempts to transmit the keepalive message has been crossed in step the neighbor manager in step may select a new active server of the VIP profile . In steps and the profile monitor determines if the server was selected as the active server for any of the VIP profiles and if so transmits a GARP advertisement as discussed earlier. Alternately if in step it is determined that the server was changed to inactive from being the active server for any of the profiles in step the profile monitor coordinates with the NIC to dissociate the VIP of such a profile from the NIC . The server can be the active server for more than one VIP profiles or may not be the active server for any VIP profile.

The profile monitor may also execute action scripts and the tracking objects included in the application manager by coordinating with the application manager whenever the server becomes ACTIVE or INACTIVE for any of the VIP profiles the server is participating in. Action scripts may be used for provisioning the application processes. For example a database action script may promote and demote a database accordingly. The profile monitor may further execute tracking objects in a continuous loop. The tracking objects may be scripts that result in a pass or a fail. The result may be printed to a standard output associated with the server such as the STDOUT mechanism provided by Linux systems. The tracking objects may be configured to ignore all result strings except a pair of predefined strings or patterns to identify the pass and the fail state respectively. By default a tracking object may start in a fail state. The fail state may be cleared when the tracking object outputs the string corresponding to the pass state. Each tracking object may be assigned a decrement value used to decrement the priority of the server when the tracking object is considered failed.

The typical tracking object may go through at least the steps illustrated in the flowchart of . At step the tracking object determines if the script is still running. In steps and the tracking objects may restart the script automatically after a predetermined restart interval of time is elapsed. In case the restart interval has not elapsed a next tracking object may be processed. The predetermined restart interval may be provided by the configuration file for the VIP profile and may be set to 30 seconds by default. Tracking objects may be event driven instead of being interval based. This allows immediate notification when the tracking object detects a problem without having to wait for the next interval or missed intervals. In step the tracking object may poll data resulting from the execution of the script. If in step the script closes during the execution due to an error or any other reason in step a corresponding closed counter may be incremented and the priority associated with the server may be decremented if the tracking object was in the pass state. If the script corresponding to the tracking object puts the tracking object in a fail state in step the priority associated with the server may be decremented and a fail counter may be incremented in step . The tracking object may be marked as failed when the tracking object first starts if the tracking object terminates or if the tracking object sends a fail pattern. Subsequent failures do not get subtracted from the priority. Only the first one is subtracted. The tracking object may maintain the pass or fail state to prevent decrementing the priority more than once. When the tracking object writes the pass pattern in step the priority associated with the server is incremented by the decrement value and a pass counter is incremented in step . The tracking objects may log any related statistics such as running time the failure counter the pass counter and the close counter. The tracking object may log the statistics in a corresponding statistics file. The tracking object may ensure that the corresponding statistics file exists before it executes the corresponding script. In case the corresponding statistics file does not exist the tracking object may create one. Alternately the statistics may be stored directly in the memory . The statistics may be made available to the action scripts the tracking objects or administrators via a graphical user interface or a third party application via an application programming interface API . The API may provide queries to read or write the statistics to the statistics file or to the memory . The API may further provide retrieval of status and various metrics associated with the server.

The system may overcome such issues without having to replicate TCP states such as window sizes sequence numbers connections and any other TCP states. The graceful close monitor may implement such a graceful close via a proper TCP FIN FIN ACK handshake close. Such graceful closing of the TCP connection even mid transmission may report an end of file EOF indication to the client application resulting in a retry instead of an error message such as a server internal error. Applications on the client side may honor this as a normal close even if abrupt and simply reconnect to continue. In step the graceful close monitor may monitor TCP packets being directed to the VIP associated with the VIP profile . The graceful close monitor maintains a flow recorder for each TCP connection from the VIP to the client. In step the graceful close monitor may determine if a TCP packet is from a new client and whether a corresponding new flow recorder needs to be initiated in step . The flow recorder may contain a retransmission count which is a number of times a particular TCP packet has been transmitted to the VIP. In step the graceful close monitor increments the retransmission count in response to a duplicate of the particular TCP packet determined in step . Retransmissions may be a sign that the server application is unable to handle the request. This may indicate an application failure or that a socket does not exist. If the retransmission count exceeds a predetermined threshold value in step the graceful close monitor may close the TCP connection to the client in step . The VIP profile configuration may provide the predetermined threshold value. The predetermined threshold value may be changed by a user by modifying the configuration file.

Closing the connection gracefully may involve purging the flow recorder. The graceful close may further involve sending an ACK message to the client in response to FIN message from the client. In case a SYN flag is set in the packet from the client a RST message may be sent to the client with a window size of zero. Else the graceful close monitor may send a FIN and ACK data to the client. Every time a FIN message is sent the graceful close monitor may increment a corresponding FIN counter. The graceful closing may be performed passively allowing the application to start responding at any time. If the application responds the graceful close monitor may allow that packet to reach the VIP and withhold doing the graceful close. Further the graceful close monitor may configure the server to NOT send TCP reset messages which is the default response for operating systems such as Linux when a TCP packet with the ACK flag set arrives and no connection socket exists. The graceful close monitor may return a RST message instead of a FIN close message if the packet received monitored has the SYN flag set. Thus in case of packets that have the ACK flag set the graceful close monitor may close the corresponding TCP connection using FIN FIN ACK.

The graceful close monitor may monitor the TCP packets on a separate thread. The monitoring may also involve monitoring kernel events that indicate opening and or closing sockets on the server by linking to the kernel events. Monitoring a socket table may not be sufficient and further in case of multiple sockets may be slow. Therefore the graceful close monitor may monitor the TCP packets via packet capture interfaces provided by the operating system of the server.

The VIP profile manager may further be configured to advertise the VIP associated with the VIP profile . VIP addresses in a broadcast environment may be from a directly connected subnet. This may enable a router to use address resolution protocol ARP to discover which host has the active VIP. For same subnet deployments where the VIP and all neighbors are within the same subnet broadcast domain the VIP profile manager may advertise the change in MAC address for the VIP via a GARP message to all devices on the same subnet. The MAC address may be a virtual MAC address set to a predetermined value.

In a deployment where the VIP is floating between subnets or when there are unicast neighboring servers the VIP may need to be re routed to a different router than the subnet the VIP aggregates to. A floating IP address may be assigned to the VIP profile so that the client of the application need not know the IP address of the active server and may direct any requests to the floating IP address. The VIP profile manager may ensure that the client requests to the floating IP address are directed to the server that is currently selected as the active server. Further in such deployments next hop aliasing may be used where routers may need to use a floating static route or dynamically learned route pointing to the directly connected reachable by ARP preferred IP address of the active server that should receive the traffic for the floating VIP. The VIP profile manager may associate an extra IP address with the VIP profile to be used as a next hop address solely for next hop forwarding. The next hop address may be from within the subnet as configured on the IP address of the NIC . The next hop address may not accept inbound connections and may not be monitored by the graceful close monitor . The next hop address may filter incoming traffic to allow internet control message protocol ICMP to from the same subnet and block all other data. The next hop address may be used for tracking the next hop reachability by the routers. The routers may implement IP service level agreements SLA ICMP probes to monitor if the next hop address is reachable or not. If the next hop address stops responding then the router may dynamically remove the route. The floating static route allows the router to move the VIP 32 or VIP 128 route from one router to another as needed. Likewise the other router that starts to have reachability to the next hop may start to advertise the route. This enables the network to learn where the VIP is active.

In the deployment scenario where the VIP is not within the same subnet or when there is at least one neighbor that is a unicast neighbor the VIP profile may also advertise the VIP associated with the VIP profile to the routers using a border gateway protocol BGP . Further the profile monitor may dynamically advertise the VIP of the VIP profile for which the server is the active server and to withdraw advertisements of the VIP associated with the VIP profile for which the server is made inactive. Users may modify community policy settings related to the BGP in the configuration file. The profile monitor may perform advertising in compliance with protocols such as BGPv4. In case of BGP the VIP associated with the VIP profile may be advertised in addition to the static route to the active server. A router may know the IP address of the active server by BGP configuration. The VIP may be advertised via BGP dynamically via the BGP configuration. In the case of next hop alias the router may only know about the next hop alias and the VIP in terms of the advertisement for the VIP and the router may be configured statically with the floating static route for the VIP pointing to the next hop address of the next hop alias.

Every server may maintain the configuration file that provides various predetermined and user defined values. Users can update the configuration file to modify policy settings and other preferences. An example structure of the configuration file is illustrated in . The configuration file on a given server may contain separate sections for each of the VIP profiles that server participates in. The configuration file stores the information that is included in the keepalive message as well as the destination address and or port where the keepalive message may be transmitted to. The configuration file may store such information related to each VIP profile a server participates in. The configuration file may also store action scripts and tracking objects that may be executed in response to predetermined time intervals or in response to predetermined events. The configuration file further may also store information used by the graceful close monitor . The configuration file may also store remote procedure calls that allow third party applications to interact with the system . Such remote procedure calls may be stored in XML format such as XML RPC REST JSON or SNMP. The configuration file may have additional information that may be used by the system . The configuration file may further store settings for the API that third party applications may use to interact with the system .

Various embodiments described herein can be used alone or in combination with one another. The foregoing detailed description has described only a few of the many possible implementations of the present disclosure. For this reason this description of example embodiments is intended by way of illustration and not by way of limitation.

