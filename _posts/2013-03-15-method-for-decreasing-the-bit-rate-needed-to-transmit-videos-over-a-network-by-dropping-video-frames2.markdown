---

title: Method for decreasing the bit rate needed to transmit videos over a network by dropping video frames
abstract: An aspect of the disclosure is directed to transmitting a reduced stream of encoded video frames. An original stream of encoded video frames is analyzed, a plurality of frames are removed without re-encoding encoded video frames to generate the reduced stream of encoded video frames, and the reduced stream and metadata describing the plurality of removed frames are transmitted. An aspect of the disclosure is directed to creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames. The reduced stream of encoded video frames is received, the plurality of removed frames is identified based on metadata related to the reduced stream, a plurality of replacement frames are generated, and the plurality of replacement frames are added to the reduced stream of encoded video frames to recreate the new version of the original stream of encoded video frames.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09578333&OS=09578333&RS=09578333
owner: QUALCOMM Incorporated
number: 09578333
owner_city: San Diego
owner_country: US
publication_date: 20130315
---
The disclosure is directed to decreasing the bit rate needed to transmit videos over a network by dropping video frames.

Wireless communication systems have developed through various generations including a first generation analog wireless phone service 1G a second generation 2G digital wireless phone service including interim 2.5G and 2.75G networks and third generation 3G and fourth generation 4G high speed data Internet capable wireless services. There are presently many different types of wireless communication systems in use including Cellular and Personal Communications Service PCS systems. Examples of known cellular systems include the cellular Analog Advanced Mobile Phone System AMPS and digital cellular systems based on Code Division Multiple Access CDMA Frequency Division Multiple Access FDMA Time Division Multiple Access TDMA the Global System for Mobile access GSM variation of TDMA and newer hybrid digital communication systems using both TDMA and CDMA technologies.

More recently Long Term Evolution LTE has been developed as a wireless communications protocol for wireless communication of high speed data for mobile phones and other data terminals. LTE is based on GSM and includes contributions from various GSM related protocols such as Enhanced Data rates for GSM Evolution EDGE and Universal Mobile Telecommunications System UMTS protocols such as High Speed Packet Access HSPA .

Due to the ever increasing amount of data being transmitted over data networks such as 3G and 4G networks carriers are struggling to meet user s data needs. This is exacerbated by the quantity of video streaming done over the network to mobile devices.

Various aspects of the disclosure are directed to transmitting a reduced stream of encoded video frames. Various other aspects of the disclosure are directed to creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames.

A method of transmitting a reduced stream of encoded video frames includes analyzing a stream of encoded video frames removing a plurality of frames from the stream of encoded video frames without re encoding the encoded video frames to generate the reduced stream of encoded video frames and transmitting the reduced stream of encoded video frames and metadata describing the plurality of removed frames.

A method of creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames includes receiving the reduced stream of encoded video frames wherein the reduced stream of encoded video frames was created by removing a plurality of frames from the original stream of encoded video frames identifying the plurality of removed frames based on metadata related to the reduced stream of encoded video frames generating a plurality of replacement frames based on the identified plurality of removed frames and adding the plurality of replacement frames to the reduced stream of encoded video frames to recreate the new version of the original stream of encoded video frames.

An apparatus for transmitting a reduced stream of encoded video frames includes logic configured to analyze a stream of encoded video frames logic configured to remove a plurality of frames from the stream of encoded video frames without re encoding the encoded video frames to generate the reduced stream of encoded video frames and logic configured to transmit the reduced stream of encoded video frames and metadata describing the plurality of removed frames.

An apparatus for creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames includes logic configured to receive the reduced stream of encoded video frames wherein the reduced stream of encoded video frames was created by removing a plurality of frames from the original stream of encoded video frames logic configured to identify the plurality of removed frames based on metadata related to the reduced stream of encoded video frames logic configured to generate a plurality of replacement frames based on the identified plurality of removed frames and logic configured to add the plurality of replacement frames to the reduced stream of encoded video frames to recreate the new version of the original stream of encoded video frames.

An apparatus for transmitting a reduced stream of encoded video frames includes means for analyzing a stream of encoded video frames means for removing a plurality of frames from the stream of encoded video frames without re encoding the encoded video frames to generate the reduced stream of encoded video frames and means for transmitting the reduced stream of encoded video frames and metadata describing the plurality of removed frames.

An apparatus for creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames includes means for receiving the reduced stream of encoded video frames wherein the reduced stream of encoded video frames was created by removing a plurality of frames from the original stream of encoded video frames means for identifying the plurality of removed frames based on metadata related to the reduced stream of encoded video frames means for generating a plurality of replacement frames based on the identified plurality of removed frames and means for adding the plurality of replacement frames to the reduced stream of encoded video frames to recreate the new version of the original stream of encoded video frames.

A non transitory computer readable medium for transmitting a reduced stream of encoded video frames includes at least one instruction to analyze a stream of encoded video frames at least one instruction to remove a plurality of frames from the stream of encoded video frames without re encoding the encoded video frames to generate the reduced stream of encoded video frames and at least one instruction to transmit the reduced stream of encoded video frames and metadata describing the plurality of removed frames.

An non transitory computer readable medium for creating a new version of an original stream of encoded video frames from a reduced stream of encoded video frames includes at least one instruction to receive the reduced stream of encoded video frames wherein the reduced stream of encoded video frames was created by removing a plurality of frames from the original stream of encoded video frames at least one instruction to identify the plurality of removed frames based on metadata related to the reduced stream of encoded video frames at least one instruction to generate a plurality of replacement frames based on the identified plurality of removed frames and at least one instruction to add the plurality of replacement frames to the reduced stream of encoded video frames to recreate the new version of the original stream of encoded video frames.

Various aspects are disclosed in the following description and related drawings. Alternate aspects may be devised without departing from the scope of the disclosure. Additionally well known elements of the disclosure will not be described in detail or will be omitted so as not to obscure the relevant details of the disclosure.

The words exemplary and or example are used herein to mean serving as an example instance or illustration. Any aspect described herein as exemplary and or example is not necessarily to be construed as preferred or advantageous over other aspects. Likewise the term aspects of the disclosure does not require that all aspects of the disclosure include the discussed feature advantage or mode of operation.

Further many aspects are described in terms of sequences of actions to be performed by for example elements of a computing device. It will be recognized that various actions described herein can be performed by specific circuits e.g. application specific integrated circuits ASICs by program instructions being executed by one or more processors or by a combination of both. Additionally these sequence of actions described herein can be considered to be embodied entirely within any form of computer readable storage medium having stored therein a corresponding set of computer instructions that upon execution would cause an associated processor to perform the functionality described herein. Thus the various aspects of the disclosure may be embodied in a number of different forms all of which have been contemplated to be within the scope of the claimed subject matter. In addition for each of the aspects described herein the corresponding form of any such aspects may be described herein as for example logic configured to perform the described action.

A client device referred to herein as a user equipment UE may be mobile or stationary and may communicate with a radio access network RAN . As used herein the term UE may be referred to interchangeably as an access terminal or AT a wireless device a subscriber device a subscriber terminal a subscriber station a user terminal or UT a mobile terminal a mobile station and variations thereof. Generally UEs can communicate with a core network via the RAN and through the core network the UEs can be connected with external networks such as the Internet. Of course other mechanisms of connecting to the core network and or the Internet are also possible for the UEs such as over wired access networks WiFi networks e.g. based on IEEE 802.11 etc. and so on. UEs can be embodied by any of a number of types of devices including but not limited to PC cards compact flash devices external or internal modems wireless or wireline phones and so on. A communication link through which UEs can send signals to the RAN is called an uplink channel e.g. a reverse traffic channel a reverse control channel an access channel etc. . A communication link through which the RAN can send signals to UEs is called a downlink or forward link channel e.g. a paging channel a control channel a broadcast channel a forward traffic channel etc. . As used herein the term traffic channel TCH can refer to either an uplink reverse or downlink forward traffic channel.

Referring to UEs 1 . . . N are configured to communicate with an access network e.g. the RAN an access point etc. over a physical communications interface or layer shown in as air interfaces and or a direct wired connection. The air interfaces and can comply with a given cellular communications protocol e.g. Code Division Multiple Access CDMA Evolution Data Optimized EV DO Evolved High Rate Packet Data eHRPD Global System of Mobile Communication GSM Enhanced Data rates for GSM Evolution EDGE Wideband CDMA W CDMA Long Term Evolution LTE etc. while the air interface can comply with a wireless IP protocol e.g. IEEE 802.11 . The RAN includes a plurality of access points that serve UEs over air interfaces such as the air interfaces and . The access points in the RAN can be referred to as access nodes or ANs access points or APs base stations or BSs Node Bs eNode Bs and so on. These access points can be terrestrial access points or ground stations or satellite access points. The RAN is configured to connect to a core network that can perform a variety of functions including bridging circuit switched CS calls between UEs served by the RAN and other UEs served by the RAN or a different RAN altogether and can also mediate an exchange of packet switched PS data with external networks such as Internet . The Internet includes a number of routing agents and processing agents not shown in for the sake of convenience . In UE N is shown as connecting to the Internet directly i.e. separate from the core network such as over an Ethernet connection of WiFi or 802.11 based network . The Internet. can thereby function to bridge packet switched data communications between UE N and UEs 1 . . . N via the core network . Also shown in is the access point that is separate from the RAN . The access point may be connected to the Internet independent of the core network e.g. via an optical communication system such as FiOS a cable modem etc. . The air interface may serve UE 4 or UE 5 over a local wireless connection such as IEEE 802.11 in an example. UE N is shown as a desktop computer with a wired connection to the Internet such as a direct connection to a modem or router which can correspond to the access point itself in an example e.g. for a WiFi router with both wired and wireless connectivity .

Referring to an application server is shown as connected to the Internet the core network or both. The application server can be implemented as a plurality of structurally separate servers or alternately may correspond to a single server. As will be described below in more detail the application server is configured to support one or more communication services e.g. Voice over Internet Protocol VoIP sessions Push to Talk PTT sessions group communication sessions social networking services etc. for UEs that can connect to the application server via the core network and or the Internet .

While internal components of UEs such as the UEs A and B can be embodied with different hardware configurations a basic high level UE configuration for internal hardware components is shown as platform in . The platform can receive and execute software applications data and or commands transmitted from the RAN that may ultimately come from the core network the Internet and or other remote servers and networks e.g. application server web URLs etc. . The platform can also independently execute locally stored applications without RAN interaction. The platform can include a transceiver operably coupled to an application specific integrated circuit ASIC or other processor microprocessor logic circuit or other data processing device. The ASIC or other processor executes the application programming interface API layer that interfaces with any resident programs in the memory of the wireless device. The memory can be comprised of read only memory ROM or random access memory RAM electrically erasable programmable ROM EEPROM flash cards or any memory common to computer platforms. The platform also can include a local database that can store applications not actively used in memory as well as other data. The local database is typically a flash memory cell but can be any secondary storage device as known in the art such as magnetic media EEPROM optical media tape soft or hard disk or the like.

Accordingly an aspect of the disclosure can include a UE e.g. UE A B etc. including the ability to perform the functions described herein. As will be appreciated by those skilled in the art the various logic elements can be embodied in discrete elements software modules executed on a processor or any combination of software and hardware to achieve the functionality disclosed herein. For example ASIC memory API and local database may all be used cooperatively to load store and execute the various functions disclosed herein and thus the logic to perform these functions may be distributed over various elements. Alternatively the functionality could be incorporated into one discrete component. Therefore the features of the UEs A and B in are to be considered merely illustrative and the disclosure is not limited to the illustrated features or arrangement.

The wireless communication between the UEs A and or B and the RAN can be based on different technologies such as CDMA W CDMA time division multiple access TDMA frequency division multiple access FDMA Orthogonal Frequency Division Multiplexing OFDM GSM or other protocols that may be used in a wireless communications network or a data communications network. As discussed in the foregoing and known in the art voice transmission and or data can be transmitted to the UEs from the RAN using a variety of networks and configurations. Accordingly the illustrations provided herein are not intended to limit the aspects of the disclosure and are merely to aid in the description of various aspects of the disclosure.

Referring to the communication device includes logic configured to receive and or transmit information . In an example if the communication device corresponds to a wireless communications device e.g. UE A or B the logic configured to receive and or transmit information can include a wireless communications interface e.g. Bluetooth WiFi 2G CDMA W CDMA 3G 4G LTE etc. such as a wireless transceiver and associated hardware e.g. an RF antenna a MODEM a modulator and or demodulator etc. . In another example the logic configured to receive and or transmit information can correspond to a wired communications interface e.g. a serial connection a USB or Firewire connection an Ethernet connection through which the Internet can be accessed etc. . Thus if the communication device corresponds to some type of network based server e.g. the application the logic configured to receive and or transmit information can correspond to an Ethernet card in an example that connects the network based server to other communication entities via an Ethernet protocol. In a further example the logic configured to receive and or transmit information can include sensory or measurement hardware by which the communication device can monitor its local environment e.g. an accelerometer a temperature sensor a light sensor an antenna for monitoring local RF signals etc. . The logic configured to receive and or transmit information can also include software that when executed permits the associated hardware of the logic configured to receive and or transmit information to perform its reception and or transmission function s . However the logic configured to receive and or transmit information does not correspond to software alone and the logic configured to receive and or transmit information relies at least in part upon hardware to achieve its functionality.

Referring to the communication device further includes logic configured to process information . In an example the logic configured to process information can include at least a processor. Example implementations of the type of processing that can be performed by the logic configured to process information includes but is not limited to performing determinations establishing connections making selections between different information options performing evaluations related to data interacting with sensors coupled to the communication device to perform measurement operations converting information from one format to another e.g. between different protocols such as .wmv to .avi etc. and so on. For example the processor included in the logic configured to process information can correspond to a general purpose processor a digital signal processor DSP an ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor but in the alternative the processor may be any conventional processor controller microcontroller or state machine A processor may also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration. The logic configured to process information can also include software that when executed permits the associated hardware of the logic configured to process information to perform its processing function s . However the logic configured to process information does not correspond to software alone and the logic configured to process information relies at least in part upon hardware to achieve its functionality.

Referring to the communication device further includes logic configured to store information . In an example the logic configured to store information can include at least a non transitory memory and associated hardware e.g. a memory controller etc. . For example the non transitory memory included in the logic configured to store information can correspond to RAM flash memory ROM erasable programmable ROM EPROM EEPROM registers hard disk a removable disk a CD ROM or any other form of storage medium known in the art. The logic configured to store information can also include software that when executed permits the associated hardware of the logic configured to store information to perform its storage function s . However the logic configured to store information does not correspond to software alone and the logic configured to store information relies at least in part upon hardware to achieve its functionality.

Referring to the communication device further optionally includes logic configured to present information . In an example the logic configured to present information can include at least an output device and associated hardware. For example the output device can include a video output device e.g. a display screen a port that can carry video information such as USB HDMI etc. an audio output device e.g. speakers a port that can carry audio information such as a microphone jack USB HDMI etc. a vibration device and or any other device by which information can be formatted for output or actually outputted by a user or operator of the communication device . For example if the communication device corresponds to UE A or UE B as shown in the logic configured to present information can include the display A of LIE A or the touchscreen display B of UE B. In a further example the logic configured to present information can be omitted for certain communication devices such as network communication devices that do not have a local user e.g. network switches or routers remote servers etc. . The logic configured to present information can also include software that when executed permits the associated hardware of the logic configured to present information to perform its presentation function s . However the logic configured to present information does not correspond to software alone and the logic configured to present information relies at least in part upon hardware to achieve its functionality.

Referring to the communication device further optionally includes logic configured to receive local user input . In an example the logic configured to receive local user input can include at least a user input device and associated hardware. For example the user input device can include buttons a touchscreen display a keyboard a camera an audio input device e.g. a microphone or a port that can carry audio information such as a microphone jack etc. and or any other device by which information can be received from a user or operator of the communication device . For example if the communication device corresponds to UE A or UE B as shown in the logic configured to receive local user input can include the keypad A any of the buttons A or B through B the touchscreen display B etc. hi a further example the logic configured to receive local user input can be omitted for certain communication devices such as network communication devices that do not have a local user e.g. network switches or routers remote servers etc. . The logic configured to receive local user input can also include software that when executed permits the associated hardware of the logic configured to receive local user input to perform its input reception function s . However the logic configured to receive local user input does not correspond to software alone and the logic configured to receive local user input relies at least in part upon hardware to achieve its functionality.

Referring to while the configured logics of through are shown as separate or distinct blocks in it will be appreciated that the hardware and or software by which the respective configured logic performs its functionality can overlap in part. For example any software used to facilitate the functionality of the configured logics of through can be stored in the non transitory memory associated with the logic configured to store information such that the configured logics of through each performs their functionality i.e. in this case software execution based in part upon the operation of software stored by the logic configured to store information . Likewise hardware that is directly associated with one of the configured logics can be borrowed or used by other configured logics from time to time. For example the processor of the logic configured to process information can format data into an appropriate format before being transmitted by the logic configured to receive and or transmit information such that the logic configured to receive and or transmit information performs its functionality i.e. in this case transmission of data based in part upon the operation of hardware i.e. the processor associated with the logic configured to process information .

Generally unless stated otherwise explicitly the phrase logic configured to as used throughout this disclosure is intended to invoke an aspect that is at least partially implemented with hardware and is not intended to map to software only implementations that are independent of hardware. Also it will be appreciated that the configured logic or logic configured to in the various blocks are not limited to specific logic gates or elements but generally refer to the ability to perform the functionality described herein either via hardware or a combination of hardware and software . Thus the configured logics or logic configured to as illustrated in the various blocks are not necessarily implemented as logic gates or logic elements despite sharing the word logic. Other interactions or cooperation between the logic in the various blocks will become clear to one of ordinary skill in the art from a review of the aspects described below in more detail.

The various embodiments may be implemented on any of a variety of commercially available server devices such as server illustrated in . In an example the server may correspond to one example configuration of the application server described above. In the server includes a processor coupled to volatile memory and a large capacity nonvolatile memory such as a disk drive . The server may also include a floppy disc drive compact disc CD or DVD disc drive coupled to the processor . The server may also include network access ports coupled to the processor for establishing data connections with a network such as a local area network coupled to other broadcast system computers and servers or to the Internet. In context with it will be appreciated that the server of illustrates one example implementation of the communication device whereby the logic configured to transmit and or receive information corresponds to the network access points used by the server to communicate with the network the logic configured to process information corresponds to the processor and the logic configuration to store information corresponds to any combination of the volatile memory the disk drive and or the disc drive . The optional logic configured to present information and the optional logic configured to receive local user input are not shown explicitly in and may or may not be included therein. Thus helps to demonstrate that the communication device may be implemented as a server in addition to a UE implementation as in A or B as in .

Due to the ever increasing amount of data being transmitted over data networks such as 3G and 4G networks carriers are struggling to meet user s data needs. This is exacerbated by the quantity of video streaming done over the network to mobile devices.

Because a video is composed of many frames still pictures video files tend to be large. Video compression algorithms used to reduce the size of a video file typically classify frames as I frames P frames and B frames. An I frame an intra coded picture is a fully specified image that requires no decoding. A P frame a predicted picture holds only the changes in the image from the previous frame and requires decoding in context of the preceding frame. P frames are also referred to as delta frames. A B frame can use both previous and forward frames for data reference to get the highest amount of data compression. illustrates an exemplary video broken down into I frames and P frames .

The size of a video file can be reduced on a server by implementing a form of video degradation that drops certain frames. The dropped frames can be either I frames P frames or B frames. The degraded video is sent to a. UE along with metadata describing the degradation performed. The original video is reproduced on the UE by filling in the missing frames using morphing. Morphing is a technique by which multiple frames can be regenerated based on key differences between two more widely spaced frames. This provides several advantages such as less data being sent over the network very limited processing on the server side and less buffering time on the client side.

Alternatively frames can be replaced using computer vision for motion tracking. In that case items in a frame can be tracked and moved in the frame accordingly.

The UE sends a request for a video to the application server . If the video is not stored on the application server the application server sends a request for the video over the Internet or other similar network to the remote server storing the video. The remote server not shown sends a response including the video to the application server . The video file may be compressed into I and P frames by the remote server or the application server . The application server processes the received video using the video processor the data analyzer and the frame dropper as described below. The application server sends a response including the processed video to the UE . The UE processes the received video using the video processor the frame morpher and the frame adder as described below.

At the UE sends a request to the application server to get a video. At the application server sends a notification to the UE that it supports frame dropping. At the UE sends a yes or no response indicating whether or not it supports the frame recreation. At if the UE does not support frame recreation then the application server sends the original video file. If however the UE does support frame recreation then at the frame dropper drops frames that can be recreated at the UE . At the application server sends the video minus the dropped frames to the UE . At the UE receives the video and passes it to the video processor . At the frame adder detects the dropped frames recreates the dropped frames and adds the recreated frames back into the received video file to recreate the original video file.

Although the signaling diagram of is illustrated as being performed by the application server and the UE it may be performed by any server and client devices. As such a server device may include a UE transmitting a video to another device and the client device may include a server receiving a processed video from another device.

If however at the client determines that it does support recreating dropped frames then at the client sends a yes response to the server. At the client receives the video from the server with certain frames dropped.

At the client via a video processor such as video processor processes the headers and stores information about which frames need to be added back into the video file. At the client receives a packet of video data and builds a frame. At the client determines whether or not the frame is the beginning of a dropped sequence of frames. This may be indicated in metadata received with the video file that identifies or describes the dropped frames. If the frame is the beginning of a sequence then at the client via a frame adder such as frame adder stores the frame as the beginning of a dropped frame sequence.

If however the client determines that the frame is not the beginning of a dropped frame sequence then at the client determines whether or not the frame is the first frame after a dropped sequence. If it is not then the flow returns to . If it is then at the client via the frame adder stores the frame as the end of a dropped frame sequence. At the frame adder recreates the missing frames using the frame at the beginning of the dropped frame sequence stored at and the first frame after the dropped frame sequence stored at . The frame adder recreates the frames by morphing the frame at the beginning of the dropped frame sequence into the first frame after the dropped frame sequence. At the frame adder returns the created frames to the video processor .

The client receives the I frames and and uses them to recreate the 10 dropped P frames. The client creates the first group of five dropped P frames by morphing the I frame into the I frame . The client creates the second group of five dropped P frames by morphing the I frame into the I frame . The resulting sequence of frames is now a 13 frame sequence just as the original sequence of frames was a 13 frame sequence.

The client receives the I frames and and uses them to recreate the 11 dropped P frames. The client creates the 11 dropped P frames by morphing the I frame into the I frame . The resulting sequence of frames is now a 13 frame sequence the same as the original sequence of frames .

Table 1 illustrates an example of the frames the client could add based on the number of frames the server drops.

Table 2 illustrates an example of the frames the client could add based on the number of frames the server drops.

The following is a specific example of the frame dropping algorithm for the MP4 video format. illustrates an exemplary MP4 file hierarchy . MP4 files are composed of atoms. Each atom contains data necessary to decode the video. The mdat atom contains the actual video data frames . The stbl atom contains various headers necessary for the decoding. The stts header includes the number of samples the stss header includes the I frames identified by their number in the sequence the stsc header includes the number of samples in each chunk the stsz header includes the size of each frame and the stco header includes number of chunks and their offsets.

The server can drop frames in an MP4 video file by retrieving the mdat atom looping through it frame by frame deleting P frames and updating the stts stss stsc stsz and stco headers . The server can identify P frames by identifying I frames from the stss header . That is the server knows which frames are I frames from the stss header meaning that any frame not listed in the stss header is a P frame or at least is not an I frame.

On the client side a modified data atom under the moov atom contains a flag indicating whether or not the video stream has been edited and thus needs to be morphed and a secondary field indicating the new size of the mdat atom . For each trak the meta atom indicates the remaining frames identified by their frame number. This information can also be used to determine the number of frames to morph in between the frames that were kept. Also for each trak a new stco header includes an offset table for the data if it has been edited to be morphed.

Alternatively the headers might contain special fields dedicated to the option of dropping and morphing headers. In this case each of the individual headers would not need to be edited only the flag indicating whether or not the frames had been dropped would need to be edited. If any frames have been dropped the flag is set and the client can refer to the dedicated headers in order to know how to put the video back together.

The following is a list of dedicated headers that might be added a dedicated mdat field with the size of the data that remains as well as dedicated stts stss stsc stsz and stco headers. Another added header might be the number of frames to morph in between the frames that were kept.

To put the video back together the client checks whether or not the flag is set. For the video data the client reads the frames sequentially using the morphed stco header or the dedicated header s . The client finds the first frame and reads the frame size count bytes using the size from the atom header or the size table. The client then reads until the next frame. The client reads in the next frame s size count bytes using the size from the atom header or the size table as with the previous frame. The client then determines if it needs to morph in missing frames based on the meta atom or the new stco header that includes the offsets table. If the client determines that it needs to morph in missing frames then it morphs in the number of missing frames. If however the client determines that it does not need to morph in missing frames then it plays the frame normally. The client then repeats the process until the final frame.

To deal with the video s audio the audio for a sequence of frames such as frame sequences can be considered as part of the first frame. The audio can then be played at a slower rate than the frame is played. This would use a new table indicating the size of each frame as the sum of the first frame plus the audio of all dropped frames.

While the aspects above have been described primarily with reference to 1 EV DO architecture in CDMA2000 networks GPRS architecture in W CDMA or UMTS networks and or EPS architecture in LTE based networks it will be appreciated that other aspects can be directed to other types of network architectures and or protocols.

Those of skill in the art will appreciate that information and signals may be represented using any of a variety of different technologies and techniques. For example data instructions commands information signals bits symbols and chips that may be referenced throughout the above description may be represented by voltages currents electromagnetic waves magnetic fields or particles optical fields or particles or any combination thereof.

Further those of skill in the art will appreciate that the various illustrative logical blocks modules circuits and algorithm steps described in connection with the aspects disclosed herein may be implemented as electronic hardware computer software or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules circuits and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the present disclosure.

The various illustrative logical blocks modules and circuits described in connection with the aspects disclosed herein may be implemented or performed with a general purpose processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor but in the alternative the processor may be any conventional processor controller microcontroller or state machine. A processor may also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The methods sequences and or algorithms described in connection with the aspects disclosed herein may be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module may reside in RAM flash memory ROM EPROM EEPROM registers hard disk a removable disk a CD ROM or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user terminal e.g. UE . In the alternative the processor and the storage medium may reside as discrete components in a user terminal.

In one or more exemplary aspects the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that can be accessed by a computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also any connection is properly termed a computer readable medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of medium. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

While the foregoing disclosure shows illustrative aspects of the disclosure it should be noted that various changes and modifications could be made herein without departing from the scope of the disclosure as defined by the appended claims. The functions steps and or actions of the method claims in accordance with the aspects of the disclosure described herein need not be performed in any particular order. Furthermore although elements of the disclosure may be described or claimed in the singular the plural is contemplated unless limitation to the singular is explicitly stated.

