---

title: NLP-based entity recognition and disambiguation
abstract: Methods and systems for entity recognition and disambiguation using natural language processing techniques are provided. Example embodiments provide an entity recognition and disambiguation system (ERDS) and process that, based upon input of a text segment, automatically determines which entities are being referred to by the text using both natural language processing techniques and analysis of information gleaned from contextual data in the surrounding text. In at least some embodiments, supplemental or related information that can be used to assist in the recognition and/or disambiguation process can be retrieved from knowledge repositories such as an ontology knowledge base. In one embodiment, the ERDS comprises a linguistic analysis engine, a knowledge analysis engine, and a disambiguation engine that cooperate to identify candidate entities from a knowledge repository and determine which of the candidates best matches the one or more detected entities in a text segment using context information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09613004&OS=09613004&RS=09613004
owner: VCVC III LLC
number: 09613004
owner_city: Seattle
owner_country: US
publication_date: 20130717
---
The present disclosure relates to methods techniques and systems for entity identification using natural language processing and in particular to methods and systems for recognizing and disambiguating named entities using natural language processing knowledge repositories and or other contextual information.

With the proliferation of information generated daily and accessible to users over the Web the need for intelligent electronic assistants to aid in locating and or discovering useful or desired information amongst the morass of data is paramount. The use of natural language processing to search text to correctly recognize people places or things is fraught with difficulties. First natural language is ambiguous. Almost every English word or phrase can be a place name somewhere in the world or a name of a person i.e. a person name . Furthermore many entities share the same name. For example there are more than 20 cities named Paris in the United States. A person named Will Smith could refer to the Hollywood movie actor and musician the professional football player in the NFL or many other people. Recognizing non celebrity names has become more important with the exponential growth of the Web content especially user created content such as blogs Wikipedia and profiles on social network sites like MySpace and FaceBook. Second an entity could be mentioned or referred to in many different ways e.g. pronouns synonyms aliases acronyms spelling variations nicknames etc. in a document. Third various knowledge sources about entities e.g. dictionary encyclopedia Wikipedia gazetteer etc. exist and the size of these knowledge bases are extensive e.g. millions of person names and place names . The sheer quantity of data is prohibitive for many natural language processing techniques.

Embodiments described herein provide enhanced computer and network assisted methods techniques and systems for recognizing and disambiguating entities in arbitrary text using natural language processing. Example embodiments provide an entity recognition and disambiguation system an ERDS and process that based upon input of a text segment automatically determines e.g. makes a best analysis of identifying which entities are being referred to by the text using both natural language processing techniques and analysis of information gleaned from contextual data in the surrounding text. The text segment may comprise a portion or all of a document and may be part of a larger composite collection. In at least some embodiments supplemental or related information that can be used to assist in the recognition and or disambiguation process can be retrieved from knowledge repositories such as an ontology knowledge base.

Entities refer generally herein to people places or things. Entities are determined based upon recognizing mentions of entities and disambiguating those that potentially correspond to more than one entity. Entity disambiguation refers to the process for differentiating which entity is being referred to in a given piece of text when a recognized entity may correspond to more than one entity. The recognition and disambiguation process may further set up a correspondence between the determined entities and their corresponding entries stored in a knowledge repository and return a list of identified entities. In addition the identified entities may be ranked and or grouped based on their relevance importance to the input text.

Once the entities in the input text are identified the results of the recognition and disambiguation process can be used to present useful information such as to summarize information in an underlying Web page to present supplemental related data etc. For example a listed of ordered or ranked entities can be provided along side information presented for other purposes such as in conjunction with other information presented to a user while perusing web pages to research or otherwise discover useful information. In addition links to other related information can be provided based upon the knowledge acquired by the ERDS while performing entity identification. For example the coordinates of place names could be retrieved and as a result the recognized place names could be displayed on a map. Also the identified entities in a document e.g. their links could be automatically highlighted so that further information on the entities could be easily accessed e.g. the links could automatically point to knowledge source entries . Further better summarization of document content could be provided for example by listing the top ranked entities in juxtaposition to the document targeting advertising toward the top ranked entities etc. A variety of other uses could be similarly employed to integrate the results of entity recognition and disambiguation techniques.

The ERDS or entity recognition and disambiguation process may be made available as a standalone module such as a widget pop up window etc. embedded in other programs or modules provided as a service accessed via an application programming interface API etc. In other contexts the recognition and disambiguation process used in an ERDS may be incorporated in powerful indexing and search tools such as those used to provide relationship searches that find information based upon natural language analysis rather than merely keyword searching.

Additional example embodiments that include different user interfaces for presenting and manipulating determined entities and or the information connected to such entities are described in co pending U.S. patent application Ser. No. 12 288 349 entitled NLP BASED CONTENT RECOMMENDER filed Oct. 16 2008 and issued as U.S. Pat. No. 8 700 604 on Apr. 15 2014 and herein incorporated by reference in its entirety.

In the Entity Recognition and Disambiguation System comprises a linguistic analysis engine a knowledge analysis engine a disambiguation engine a document data repository and a knowledge data repository . The ERDS may optionally comprise an NLP parsing preprocessor potentially as a separate component especially in instances where a third party or off the shelf processor is integrated into the system. The ERDS analyzes text segments from text documents to automatically determine the various entities contained in them and potentially outputs entity identifiers .

In some embodiments the entity identifiers are stored as links in the text documents and setup correspondences with entity information stored in one or more knowledge repositories e.g. ontology knowledge bases. In addition in some embodiments the entity information is stored and indexed in the document data repository for example to assist in performance of relationship searching along with other data indexed from the documents . This is particularly useful in embodiments that embed the ERDS as part of a larger document storage and indexing system for searching. The linguistics analysis engine receives text from the text documents which has been potentially preprocessed by preprocessor and determines characteristics about the entities mentioned but not yet resolved in the documents . The knowledge analysis engine matches these characters to find possible candidate entities in a vast array of knowledge information represented in part by the knowledge data . The disambiguation engine resolves which possible candidate entity is the most likely entity being referred to in the text and returns indications of the identified resolved entities.

One or more embodiments of an ERDS may incorporate an existing natural language processing technology and relationship search technology called InFact . The InFact NLP based relationship search technology now referred to as the Evri relationship search technology is described in detail in U.S. patent application Ser. No. 11 012 089 filed Dec. 13 2004 which published on Dec. 1 2005 as U.S. Patent Publication No. 2005 0267871A1 and which is hereby incorporated by reference in its entirety. The InFact Evri relationship search and indexing technology defines data structures techniques and systems for natural language processing that preprocess and store document information in one or more annotated phrase clause or sentence based indexes. The annotations store tag based information along with the terms of a clause or sentence so that existing keyword based search engines can be leveraged to perform natural language based processing instead of simple keyword searching. The tag based information may include one or more of parts of speech tags grammatical role tags ontological information entity tags and other types of information. The InFact Evri relationship search technology also defines methods systems and techniques for performing relationship queries as opposed to traditional keyword based searching. These relationship queries leverage NLP to allow users to discover information regarding how a particular entity relates or is otherwise associated with other entities. Accordingly the recognition and disambiguation process used in an ERDS also may be incorporated into an InFact Evri text analysis and indexing system and can be invoked during the indexing of documents to identify and store entity related information.

In block the process performs natural language parsing and linguistic analysis preprocessing of each sentence in the input document to turn the text into structured information. The term document as used herein refers to any portion or all of one or more text segments.

In block it detects recognizes potential entity names by combining evidence from multiple levels based on a more sophisticated syntactic and semantic analysis as opposed to simple keyword based matching. As the result a profile is built for each entity mentioned in the text that characterizes the entity s properties based upon the document content.

Then in block the process performs an ontology lookup on each potential entity name using an ontology lookup service. The ontology lookup service provides the capability given a name and its attributes to retrieve all matching ontology entries. To perform this processing for each detected entity a search is performed against the ontology repository which is likely to return multiple matches or candidate entries in the ontology repository that potentially match the name entity profile . The result of this processing is one or more candidate entities.

In block the process then performs an entity disambiguation process for the candidate entries. The entity disambiguation step determines the correct entity that the text is likely referring to from among the multiple candidate entries in the ontology or determines that none of the candidate entries is correct . This disambiguation process is performed by examining the candidate s attributes specified in the ontology and comparing them to contextual information extracted from the text i.e. the profiles derived from the text . What results is one or more identified entities.

Then in block the identified disambiguated entities are ranked based on certain criteria e.g. frequency of occurrence in the document or grouped based on their common characteristics e.g. places that belong to same region or people with the same profession . The entity recognition and disambiguation process for the received input is then complete.

In addition in some embodiments that integrate these techniques with InFact Evri relationship search and indexing technology in block the matching ontology entries to the identified entities are stored as annotations of phrases within the sentence level indices to support queries against them. They may also be stored at other level indices in some other embodiments. The InFact Evri search and indexing technology supports queries of the annotated entities and their relationships. To do so the indexing and storage mechanism stores each sentence of a document as a series of clauses annotated by one or more tags wherein the tags may include entity tag information grammatical role information syntactic parts of speech roles etc. The structure and use of these inverted indexes is described further in U.S. Patent Publication No. 2005 0267871A1.

As illustrated in the entity recognition and disambiguation process generates several intermediate results in the process of identifying entities. The following example is illustrative 

Next after block an entity profile is constructed for Will Smith. The entity profile describes the characteristics of the entity as specified in the text. Table 2 shows the constructed entity profile.

This entity profile is then looked up in the ontology data repositories. Using the name Will Smith as query the process finds three matches candidate entities from the ontology repository after block as shown below in Table 3. Each entry in the ontology specifies a number of attributes i.e. type role related entities . Other attributes may be available.

Finally the candidate entities are disambiguated. The disambiguation process block matches Will Smith s profile collected from the text against the three ontology matching entries and determines that Will Smith the football player is the correct entity the text refers to. Multiple algorithms are available to make this determination. A few of them are described further below. The following identified entity shown in Table 4 results.

Example embodiments described herein provide applications tools data structures and other support to implement an entity recognition and disambiguation system and or process to be used for assisting in the locating and understanding of relevant information. Other embodiments of the described techniques may be used for other purposes.

In the following description numerous specific details of one example embodiment are set forth such as data formats and code sequences etc. in order to provide a thorough understanding of the described techniques. The described approaches and algorithms may be used alone or in combination to implement an NLP based recognition and disambiguation system. In some embodiments both natural language processing and knowledge based approaches are used. In other embodiments only some of the approaches or capabilities are incorporated. The embodiments described also can be practiced without some of the specific details described herein or with other specific details such as changes with respect to the ordering of the code flow different code flows etc. Thus the scope of the techniques and or functions described are not limited by the particular order selection or decomposition of steps described with reference to any particular routine.

Also although certain terms are used primarily herein other terms could be used interchangeably to yield equivalent embodiments and examples. For example it is well known that equivalent terms in the natural language processing field and in other similar fields could be substituted for such terms as document text etc. In addition terms may have alternate spellings which may or may not be explicitly mentioned and all such variations of terms are intended to be included.

As described in a primary function of an ERDS is to recognize and disambiguate entities present in specified text. This function may be provided for example as part of an indexing and storage process for performing relationship searches such as available through the InFact Evri NLP relationship search technology. Once the entities are resolved recognized and disambiguated appropriate indications of the entities e.g. entity tags may be stored in the indexes that represent the clause sentence document structures so that matches against those entities may be found efficiently.

Additional detailed information on the InFact Evri indexing and storage techniques and use of them for searching structured and unstructured data is available in several patents publications and patent applications including U.S. Pat. No. 7 398 201 U.S. Patent Publication No. 2005 0267871A1 U.S. Patent Publication No. 2007 0156669A1 and U.S. patent application Ser. No. 12 049 184 filed Mar. 14 2008 which are incorporated herein by reference in their entireties.

The following sections describe each aspect of the entity recognition and disambiguation process and ERDS component interactions in more detail.

As mentioned in block of the input text segment document etc. is pre processed for example using the NLP parsing preprocessor of . The preprocessor takes input text and produces one or more data structures that contain the structure of regions e.g. paragraphs sentences as well as associated meta tags e.g. publisher URL topic categories such as Politics Entertainment etc. 

Once pre processed the resulting structures are sent to the linguistic analysis engine for example engine of to recognize all of the entities in the inputted text see e.g. block of . is an example flow diagram of the steps of the entity recognition process based upon linguistic analysis of the input text. The entity recognition process detects entities mentioned in the input text and links together multiple occurrences of same entity. The process consists of three sub steps. In step syntactic analysis of sentences e.g. producing a parse tree of each sentence is performed. In step the process detects entity occurrences in the syntactic structure resulting from step the parse tree . In step the process resolves coreferences of the same entity for example determines which pronouns refer to which entities. Each of these steps is described in more detail next.

Given a sentence or clause a syntactic parser e.g. the InFact Evri dependency parser is used to produce a parse tree. A parse tree represents the syntax of a sentence as a tree structure and typically captures the following information 

When used with a dependency parser such as the InFact Evri dependency parser the produced parse tree is a dependency tree which is a type of parse tree representation. It represents the whole parse tree as a list of head modifier relations e.g. verb subject relations adjective noun modifier relations etc. . As a result each sentence can be decomposed into one or more of the subject action object triples SAO triplets along with their descriptive modifiers. is an example illustration of SAO triplets along with descriptive modifiers. SAO triplet contains a subject an action and an object along with their respective modifiers and .

The descriptive modifiers and include immediate modifiers of a noun including appositive nominative genitive prepositional adjective modifiers as well as normalized long distance dependencies e.g. predicate nominative the is a relation . The subject action object event triplets indicates entities roles in an event as source or target and their interactions with other entities.

One of the benefits of using the InFact Evri dependency tree parsing is that it explicitly handles long distance dependency in a normalized way. is a schematic illustration of long distance dependency recognition. In the examples shown in in clause president is identified as direct modifier of head noun Washington even though there are many words between the pair of words. Similarly in clause city is a direct modifier of the head noun Alexandria. These kind of long distance descriptive modifier relations are difficult to capture by methods based on a finite state model such as regular expression n gram language model or Hidden Markov Model which represent sentence structure as a sequence of words. Accordingly use of the InFact Evri dependency tree parsing improves accuracy of entity recognition.

Using the phrases and syntactic structures the SAO triplets produced by the previous stage step of the entity recognition process then performs detection of proper nouns by examining evidence from multiple levels some examples of which are described here. Proper nouns also called proper names are nouns representing unique entities such as London or John as distinguished from common nouns which describe a class of entities such as city or person . This entity detection recognition step detects the proper nouns and assigns them into a number of general categories e.g. people place organization date number money amount etc. . Other categories could be similarly supported.

More specifically this step of entity recognition first rules out words or phrases with part of speech tags other than noun such as verb preposition and adjective. Many words have multiple senses e.g. a word could be used as a verb or noun . The recognition process resolves such ambiguity through part of speech tagging during the sentence parsing process.

Proper names are usually capitalized in English. They also have certain internal structures e.g. a person name may have the structure of given name followed by family name . The entity detection step step applies lexical analysis to the words and phrases from the produced dependency tree that have not been ruled out to detect proper names from phrases. The analysis is based on a combination of dictionary entries and a set of regular expression patterns. Examples of such patterns that are recognized include 

Furthermore the entity recognition process can recognize certain types of proper names based on their modifiers by detecting occurrence of the above mentioned keyword indicators. For example title words e.g. senator congressman president present in modifiers usually indicate the head noun is a person name.

In contrast the examples below illustrate that the word Sofia can be tagged as a city based on its modifiers instead of as a person name 

Names appearing together through conjunctions e.g. and or or as a list more than likely belong to the same entity type. For example if an unknown name appears together with a list of person names the entity recognition process labels the unknown name as a person name. Similarly given a list of names Moses Lake George Wenatchee the entity recognition process determines that George is likely a place name rather than a person name based on the recognition that its conjunctions are place names.

An entity is often referred to in many different ways and at different locations in a segment of text. The entity recognition process applies a document level coreference resolution procedure step to link together multiple occurrences mentions that designate the same entity.

In a given document an unambiguous name is often mentioned in the beginning then some form of acronyms or aliases are used in the rest of the document. These aliases are often localized and may not be available from a domain lexicon or have ambiguous meanings. For example Alaska refers to Alaska Airlines Portland refers to Portland Me. and UT refers to University of Texas instead of the state of Utah. 

For each potential anaphora e.g. each pronoun the entity recognition process determines its antecedent the entity the anaphora refers to using the following steps 

1. Determine the proper context for this kind of anaphora. For example the context for a pronoun is usually no more than two sentences.

2. Inspect the context surrounding the anaphora e.g. pronoun for candidate antecedents nouns and the entities to which they refer that satisfy a set of consistency restrictions. For example if the current pronoun is she then only the Person entities with gender female or unknown will be considered as candidate entities. Each antecedent noun at this point has a corresponding entity associated with it from the other analysis sub steps.

3. Assign scores to each antecedent based on a set of weighted preferences e.g. distance between the antecedent and the anaphora in the parse tree .

4. Choose as the candidate entity for the pronoun the entity that corresponds to the antecedent noun with the highest score.

After performing syntactic analysis entity detection of proper nouns and resolving coreferences the entity recognition process has determined to which named entities the text probably refers. These are referred to as recognized entities or recognized named entities. It will be understood that variations of these steps could also be supported such as different rules for determining which antecedent is likely the best candidate entity.

Again referring to once one or more named entities have been recognized in the text corresponding entity profiles are built as part of block by processing each named entity in relation to the document to determine characteristics for each named entity. It is from these characteristics and other information that the entity recognition and disambiguation process hence the ERDS can decipher which precise entity is being referred to. In one example embodiment for each entity the ERDS builds an entity profile of the named entity by collecting the following information by examining each mention direct e.g. by name or indirect e.g. through a pronoun of the entity in the document 

Once the context information is collected the ERDS further assigns more specific roles e.g. politician musical artist movie actor tennis player etc. to each entity profile. There are several ways to gain additional information that assists with assigning roles. For example title words such as mayor senator presidential candidate appearing as descriptive modifiers likely indicate that the entity has been used in a politician role. Roles can also be indicated by the actions that entities are involved in. For example in the clause JFK was assassinated JFK is a person name while in the clause arrive at JFK JFK is more likely a place name.

In addition the collected information for an entity can be compared to known roles in order to match the entity to its most likely role i.e. category . Table 5 below illustrates two clusters of people based on their action patterns collected from a set of news articles.

In Table 5 it can be observed that football quarterbacks and tennis players are distinguishable based on their action patterns. Accordingly given an unknown person name if the entity s associated actions match closer to for example the action patterns of known football players then this person is more likely to refer to a football player than other types of players.

Using this technique the ERDS can assign entity profiles to one or more predefined categories roles in this scenario using inductive learning techniques to automatically construct classifiers based on labeled training data. The training data is a set of entities that have been manually assigned corresponding categories.

Therefore for each category there is a set of positive examples as well as negative examples entities that don t belong to a particular category . Each profile can then be represented as a feature vector of terms collected from the entity s modifiers and actions. The terms can be weighted in a number of ways such as 

Table 6 below illustrates an example of two feature vectors collected from a segment of text. In this example the number in each cell indicates the frequency the term column occurs in the profile of an entity row collected from the text. Table 6 demonstrates that the action profile of an entity named Peyton Manning is more similar to those of known quarterbacks see example above than to the profile of Will Smith.

Given a set of labeled feature vectors the ERDS builds a binary classifier true or false for each category e.g. role . The binary classifier can then be directly compared to a generated entity profile to determine whether the entity profile is one or is not one of a designated category. A number of machine learning algorithms can be used to construct the classifiers such as Nearest Neighbors Decision Trees Support Vector Machines Maximum Entropy Models and Rocchio s. In one embodiment the building of category classifiers is done before new text is processed.

When processing a text segment the ERDS performs the same feature extraction on each recognized entity to generate feature vectors. Then the trained classifiers are applied to the extracted feature vectors to determine matches. Corresponding categories are then assigned to each recognized entity based on the classifier output i.e. true or false for each category . An entity can be assigned zero one or more categories. At the end of this stage corresponding to the end of block in a set of candidate entities are produced based upon the assigned categories.

Referring again to in block the entity recognition and disambiguation process as performed by the ERDS maps the entity profiles of detected entity mentions to candidate entities i.e. entries specified in knowledge bases to assist in the resolution of which precise entity is being referred to disambiguation . In order to perform this mapping it is helpful to first understand how the knowledge bases are organized and how corresponding knowledge base entries are discovered. Disambiguation is described further below.

Knowledge about entities can come from many different sources e.g. gazetteers for geographic location names databases of person names census data etc. and appear in very different formats. The size of the knowledge bases can be very large. For example the gazetteer produced by the National Geospatial Intelligence Agency NGA alone contains information about millions of geographic locations that are outside of the United States. Therefore it is not practical to access the knowledge sources directly nor it is efficient to search for entities from the sources. Accordingly the InFact Evri search technology has developed and uses an ontology as an repository to integrate such information from multiple heterogeneous sources. The ontology repository provides a unified interface for finding entities and corresponding information that is derived from multiple sources and stored in the repository. For many purposes the entity locating or lookup process needs to be real time substantially real time or near real time. Other types of knowledge repositories for combining the information from the multiple sources and for providing a consistent interface to potentially heterogeneous information may be used as well including other types of data structures other than databases inverted indices etc. For the examples described herein inverted ontology indices have yielded efficient results.

The ontology repository contains a list of entities and information about the entities. Each ontology entry may contain information such as one or more of the following information data 

 1 An off line indexing component that creates inverted indices of the ontology entries in order to enable efficient searching. The indexing is scalable to large size broad coverage data knowledge repositories such as a knowledge base .

 2 An on line search component that given an entity name as query as well as certain attributes of the entity returns all matching ontology entries.

To be practicable for use with the entity recognition and disambiguation system process the on line search ontology lookup preferably has very low latency so that processing each document can be fast which could involve many lookups . An inverted index is an index structure storing a mapping from words to their locations in a set of documents. The goal is to optimize the speed of the query to quickly find the documents where word X occurs. Inverted index data structures are often used in document retrieval systems such as Web search engines . For use with the ERDS each ontology entry is considered a document and the entity names and attributes of the ontology entry are treated as terms i.e. keywords in the document. Thus when keywords for example from the entity profiles are specified to the ontology search component the search component retrieves all documents i.e. ontology entries with matching terms entity names and attributes . Using the inverted indexing structure the system can scale to large ontology sizes perform rapid lookups across potentially thousands hundreds of thousands or millions of entities matching a particular criterion.

During the ontology lookup a search usually specifies an entity name e.g. Will Smith as well as certain attribute constraints associated with the entity e.g. football player . The search can be handled using at least two basic approaches 

For each ontology entry the ontology may store related entities that can be leveraged as additional context clues during the entity disambiguation process described in the next section . The list of related entities can be generated in a number of ways including at least the following 

A number of techniques are available to automatically determine related entities from a large corpus of text documents. One technique involves the periodic execution of IQL InFact Query Language now referred to as EQL for Evri Query Language based tip queries which result in related entities based on a relevance ranking of clause level entity binding. As additional unstructured text arrives into the system related entities may change. The InFact Evri tip system dynamically evolves the related entities as the text changes. Example tip systems are explained in more depth in U.S. Patent Publication No. 2007 0156669A1 and U.S. patent application Ser. No. 12 049 184 filed Mar. 14 2008.

In addition to clause level entity relations another automated technique leverages word or entity co occurrence via techniques such as latent semantic regression LSR across the incoming unstructured text to provide additional context hints such as terms or entities which tend to occur near the entity of interest. See for example U.S. Pat. No. 6 510 406 issued Jan. 21 2003 U.S. Pat. No. 6 757 646 issued Jun. 29 2004 U.S. Pat. No. 7 051 017 issued May 23 2006 and U.S. Pat. No. 7 269 598 issued Sep. 11 2007.

Once the possible candidate ontology entities entries in the ontology repository or other knowledge repository have been retrieved which could be many since often entities share the same name the next step is to determine which of the entities is actually being referred to by the entity mention in the text. The disambiguation process matches the characteristics of the entity described in the text against the attributes of the entities retrieved from the ontology to make this determination. In one example embodiment the disambiguation process determines a ranking of the candidates by computing ranking scores based on a combination of several factors optionally revisiting the ranking as additional information is gleaned.

More specifically in block the process determines whether there are additional entities from the text to be disambiguated and if so continues with block else continues with block . In block the disambiguation process gets the next entity from the text segment to process. In block the disambiguation process matches the characteristics of the entity being processed to the matching candidate entities one or more entries in the ontology and finds the best possible match. As further described below this matching process may be solved as a classification problem. In embodiments that delay processing of unresolved entities in block the process returns the best matching candidate or returns the text segment entity back to the list to be resolved later.

In block the disambiguation process updates the ranking of candidate entities based upon information learned in the process. For example the ranking may be updated as a result of matching the characteristics of the entity described in the text against the attributes of the candidate entities retrieved from the ontology. As the disambiguation process examines each entity in the document more information is gained about other entities in the document. Therefore in some embodiments it makes sense to revisit the previously resolved entities to check whether to update the previous decision in light of new information. Examples are provided below. The disambiguation process then returns to the beginning of the loop in block .

If there were no more entities in the text to disambiguate then in block the process continues with block . Here in embodiments that support a multi pass approach the process determines whether more passes are needed and if so returns to the beginning of the loop in block . If not the process continues in block to return the best matching candidates for all entities and ends. These best matching candidate entities are considered the identified entities in .

The default ranking preferences of matching candidates block is based on each candidate s popularity or importance. For example a city with a large population or a capital e.g. Paris France is typically ranked higher than other cities unless there is evidence indicating otherwise. Similarly a celebrity is more likely to match a person name than a less known person with an identical name.

 1 Using a statistical approach which considers how frequently an entity is mentioned is a large corpus of text e.g. news articles web blogs etc. as well as how much information exists about the entity in the knowledge sources. For example the more famous a person the more likely that detailed information is available about the person in the knowledge repository.

In block the disambiguation process examines the characteristics of the entity described in the text against the attributes of the candidate entities retrieved from the ontology to determined the best matching candidate entity. One approach to the disambiguation process is to use classification algorithms to distinguish between various candidate entities.

In a classification problem each data instance is assigned a class. A classification model is constructed based on training data and this model can be used to assign a class to a an unseen data instance. The classification model is constructed based on features properties of data instances. For disambiguation purposes each entity can be assigned to either a RELEVANT or a NON RELEVANT class.

The classification model is built based on manually extracted ground truth i.e. facts that are known . For example to construct a classification model the text in a given document is processed and candidate entities are presented to a human annotator. The annotator then assigns a class to each candidate entity RELEVANT or NON RELEVANT . This classification together with feature vectors that represent the training data candidate entries are stored in a machine readable format. Based on this stored data a classification model is built using statistical and machine learning techniques.

Once the classification model is constructed for disambiguation purposes the disambiguation process can then classify newly observed data instances such as to distinguish between the candidate entities. Newly observed data instances i.e. the feature vectors generated therefore can be compared to the stored data using the learning algorithms that implement the classification model. Those that compare more favorably will emerge as better candidates.

More specifically to perform such disambiguation as described above the disambiguation process extracts candidate entities based on string matches to entities in the ontology repository. For example the string Will Smith may match ontology entries for an actor singer a football player a British comedian a cricket player or it may represent none of these people. Further the matching process may apply anaphora resolution to resolve acronyms first and last names or abbreviations to full names of entities.

Without anaphora resolution one would have to disambiguate Smith between movies with this title music albums or multiple people with this same last name. When anaphora resolution is applied the number of possible candidates may be reduced based on a full name of an entity.

In addition to reducing the number of candidates the disambiguation process may be enriched through discovered aliases. For example when the process discovers that CIA is an alias for Culinary Institute of America it is are able to disambiguate CIA to the Culinary Institute and not to the Central Intelligence Agency.

Through coreferencing and anaphora resolution the recognition and disambiguation process resolves that Smith in the third sentence refers to Will Smith and does not further consider candidate entities with the name Smith and no first name. Through natural language processing the entity recognition process establishes that Will Smith is a person that Will Smith is a male and that he is football defensive end. It also determines that the string Will Smith is a noun and is a subject in the sentence.

As described in the previous section each entity in a knowledge repository is associated with a particular role or entity type. Examples of roles include being an actor an album a band a city a football player a movie etc. Each entity may also have other associated properties which can be stored in the knowledge repository for later retrieval during the classification process. For example Will Smith the football player may have associated properties such as the name of the team s that he plays for and his birthplace. Meanwhile Will Smith the movie actor may have associated properties such as the names of the movies he starred in. Accordingly such attributes associated with a subject can help aid in future identification and in the classification of which Will Smith has been located tagged or otherwise referred to.

For each of the candidate entities matched from the knowledge repository the disambiguation process constructs a feature vector using 

Such feature vectors are then analyzed using the machine learning and statistical learning capabilities of the previously constructed classification model to classify each feature vector to determine the more likely candidates. For example in Table 8 the Relevant column is populated after the feature vector is run through the classification model. Thereafter one or more selected feature vectors also can be stored in machine readable form and used to further inform the model.

Note that in some cases a large number of potential candidates may exist for an entity. In such cases it may be beneficial to apply a multi level approach to classification. According to one approach the disambiguation process may filter possible candidate entities based on relevant entities that exist in the text and then apply the classification model to classify only entities that pass the filter step. Also different data structures such as inverted indices may be used to speed up the filtering process. In addition only a portion of or additional characteristics may be generated as part of the feature vector to compare with the recognized entity under examination.

As the disambiguation process examines the various entities in the document and performs disambiguation it collects more evidence especially regarding related entities which can be used to modify the initial disambiguation decisions or to complete unresolved entity disambiguations. For example given the text Hawks dominate 49ers in San Francisco the term Hawks is ambiguous. It could refer to the NFL team Seattle Seahawks or the NBA basketball team Atlanta Hawks or perhaps many others things. Unable to resolve Hawks the disambiguation process may choose to leave it as is and move on to other entities. Only after it processes and resolves other names in the context e.g. observes that San Francisco 49ers is an NFL football team it has sufficient evidence that the context relates to NFL football. After that determination the disambiguation process can return to the disambiguation of Hawks and assert higher confidence to the candidate Seattle Seahawks. One method to accomplish such latent resolution is by maintained a list of unresolved entities. Another method is to perform multiple passes of the resolution process from the beginning. Other approaches are also usable.

In one example embodiment the disambiguation process adopts a multi pass process that iteratively updates the scores assigned to each candidate. During each iteration it examines the names in a document sequentially and performs disambiguation based on the contextual evidence collected thus far. The process continues until there is no new evidence produced or until the number of iterations reaches some determined or predetermined limit. To detect this condition the process checks whether or not the disambiguation of any entities within the context have changed. If so any new information is included to the subsequent disambiguation of other entities. If not the disambiguation process completes.

Updating the disambiguation results is based on assumptions such as the existence of parallelism and focus in the surrounding context. Parallelism means similar entities within the same context are more likely to have the same type. For example when Ali is mentioned together with a list of known movie titles one could be fairly confident that it refers to the name of a movie in this context instead of a person. Geographic focus or a document s main subject can be computed through a majority vote from entities in the context. For example suppose a text segment mentions several place names such as Salem Portland and Vancouver where each name is fairly ambiguous. Table 9 below shows the top and second candidates resolved after the first pass 

Based on the recognition that all three names have candidates as cities near the Portland Oreg. area Vancouver Wash. lies just north of Portland Oreg. the updating process could boost the scores for those candidates. As a result the disambiguation process would select the second candidate for Salem and Vancouver.

The final result of this process block is a list of entities e.g. phrases in the text linked to their most appropriate ontology entries. A link in this sense may be any form of reference or identification of the corresponding ontology entry.

After the entity recognition and disambiguation process many entities could be identified from a given document. Instead of simply listing all the entities an example embodiment of the recognition and disambiguation system may organize or summarize the entities within a document see block of by for example 

Given a list of entities tagged in a document this process ranks the entities based on their relevance to the main subject or focus of the document. Features extracted for such a ranking process may include one or more of the following features 

A ranking score can be computed based on a weighted combination of one or more of the above factors. In some embodiments the ERDS builds a regression model to automatically determine the values of the weights that should be assigned to each factor. A regression method models the relationship of a response variable ranking score in this case to a set of predicting factors. In preparation the ERDS first collects a set of training data that consists of a set of documents where the ranking of the top entities in each document has been manually verified. Then using the training data it automatically estimates parameters i.e. weights of the regression model. Then when presented with a previously unseen document the ERDS can then apply the regression model to entities found in the document and predict each entity s ranking score.

The recognition and disambiguation system can also organize the resulting entities by grouping them based on certain properties associated with the entities. One property for grouping purposes is an entity s type. For example entities can be grouped into categories such as places people and organizations. The groupings can be further organized into an hierarchy. For example place names can be further grouped into cities countries regions etc. Accordingly given a document the entities identified in the document can be viewed as groups in different granularities of the hierarchy.

Another property for grouping is the part of or member of relation. For example given an article describing football games the players mentioned in the text can be grouped according to the football teams they belong to. Similarly for place names they can be grouped based on the countries or regions they are part of.

Other grouping and or ranking techniques can similarly be incorporated and used by the ERDS to present the entities resulting from the disambiguation process.

Computing system may comprise one or more server and or client computing systems and may span distributed locations. In addition each block shown may represent one or more such blocks as appropriate to a specific embodiment or may be combined with other blocks. Moreover the various blocks of the RDS may physically reside on one or more machines which use standard e.g. TCP IP or proprietary interprocess communication mechanisms to communicate with each other.

In the embodiment shown computer system comprises a computer memory memory a display one or more Central Processing Units CPU Input Output devices e.g. keyboard mouse CRT or LCD display etc. other computer readable media and network connections . The RDS is shown residing in memory . In other embodiments some portion of the contents some of or all of the components of the RDS may be stored on and or transmitted over the other computer readable media . The components of the RDS preferably execute on one or more CPUs and perform entity identification recognition and disambiguation as described herein. Other code or programs and potentially other data repositories such as data repository also reside in the memory and preferably execute on one or more CPUs . Of note one or more of the components in may not be present in any particular implementation. For example some embodiments embedded in other software may not provide means for other user input or display.

In a typical embodiment the RDS includes a linguistic analysis engine a knowledge analysis engine a disambiguation engine an NLP parsing engine or preprocessor an RDS API a data repository or interface thereto for storing document NLP and disambiguation data and a knowledge data repository for example an ontology index for storing information from a multitude of internal and or external sources. In at least some embodiments the NLP parsing engine preprocessor is provided external to the RDS and is available potentially over one or more networks . Other and or different modules may be implemented. In addition the RDS may interact via a network with applications or client code that uses results computed by the RDS one or more client computing systems and or one or more third party information provider systems such as purveyors of information used in knowledge data repository . Also of note the knowledge data may be provided external to the RDS as well for example in an ontology knowledge base accessible over one or more networks .

In an example embodiment components modules of the RDS are implemented using standard programming techniques. However a range of programming languages known in the art may be employed for implementing such example embodiments including representative implementations of various programming language paradigms including but not limited to object oriented e.g. Java C C Smalltalk functional e.g. ML Lisp Scheme etc. procedural e.g. C Pascal Ada Modula etc. scripting e.g. Perl Ruby Python JavaScript VBScript etc. declarative e.g. SQL Prolog etc. etc.

The embodiments described use well known or proprietary synchronous or asynchronous client sever computing techniques. However the various components may be implemented using more monolithic programming techniques as well for example as an executable running on a single CPU computer system or alternately decomposed using a variety of structuring techniques known in the art including but not limited to multiprogramming multithreading client server or peer to peer running on one or more computer systems each having one or more CPUs. Some embodiments are illustrated as executing concurrently and asynchronously and communicating using message passing techniques. Equivalent synchronous embodiments are also supported by a RDS implementation.

In addition programming interfaces to the data stored as part of the RDS e.g. in the data repositories and can be made available by standard means such as through C C C and Java APIs libraries for accessing files databases or other data repositories through scripting languages such as XML or through Web servers FTP servers or other types of servers providing access to stored data. The data repositories and may be implemented as one or more database systems file systems or any other method known in the art for storing such information or any combination of the above including implementation using distributed computing techniques.

Also the example RDS may be implemented in a distributed environment comprising multiple even heterogeneous computer systems and networks. For example in one embodiment the modules and and the data repositories and are all located in physically different computer systems. In another embodiment various modules of the RDS are hosted each on a separate server machine and may be remotely located from the tables which are stored in the data repositories and . Also one or more of the modules may themselves be distributed pooled or otherwise grouped such as for load balancing reliability or security reasons. Different configurations and locations of programs and data are contemplated for use with techniques of described herein. A variety of distributed computing techniques are appropriate for implementing the components of the illustrated embodiments in a distributed manner including but not limited to TCP IP sockets RPC RMI HTTP Web Services XML RPC JAX RPC SOAP etc. . Other variations are possible. Also other functionality could be provided by each component module or existing functionality could be distributed amongst the components modules in different ways yet still achieve the functions of a RDS.

Furthermore in some embodiments some or all of the components of the RDS may be implemented or provided in other manners such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the system components and or data structures may also be stored as contents e.g. as executable or other machine readable software instructions or structured data on a computer readable medium e.g. as a hard disk a memory a computer network or cellular wireless network or other data transmission medium or a portable media article to be read by an appropriate drive or via an appropriate connection such as a DVD or flash memory device so as to enable or configure the computer readable medium and or one or more associated computing systems or devices to execute or otherwise use or provide the contents to perform at least some of the described techniques. Some or all of the system components and data structures may also be transmitted as contents of generated data signals e.g. by being encoded as part of a carrier wave or otherwise included as part of an analog or digital propagated signal on a variety of computer readable transmission mediums including wireless based and wired cable based mediums and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly embodiments of the present disclosure may be practiced with other computer system configurations.

All of the above U.S. patents U.S. patent application publications U.S. patent applications foreign patents foreign patent applications and non patent publications referred to in this specification and or listed in the Application Data Sheet including but not limited to U.S. Provisional Patent Application No. 60 980 747 entitled NLP BASED ENTITY RECOGNITION AND DISAMBIGUATION filed Oct. 17 2007 and U.S. Non Provisional Patent Application No. 12 288 158 entitled NLP BASED ENTITY RECOGNITION AND DISAMBIGUATION filed Oct. 15 2008 and published under U.S. Patent Publication No. 2009 0144609 on Jun. 4 2009 are incorporated herein by reference in their entirety.

From the foregoing it will be appreciated that although specific embodiments have been described herein for purposes of illustration various modifications may be made without deviating from the spirit and scope of this disclosure. For example the methods techniques and systems for entity recognition and disambiguation are applicable to other architectures other than an InFact Evri architecture or a Web based architecture. For example other systems that are programmed to perform natural language processing can be employed. Also the methods techniques and systems discussed herein are applicable to differing query languages protocols communication media optical wireless cable etc. and devices such as wireless handsets electronic organizers personal digital assistants portable email machines game machines pagers navigation devices such as GPS receivers etc. .

