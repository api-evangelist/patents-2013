---

title: Debugging a high performance computing program
abstract: Methods, apparatus, and computer program products are disclosed for debugging a high performance computing program by gathering lists of addresses of calling instructions for a plurality of threads of execution of the program, assigning the threads to groups in dependence upon the addresses, and displaying the groups to identify defective threads.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08813037&OS=08813037&RS=08813037
owner: International Business Machines Corporation
number: 08813037
owner_city: Armonk
owner_country: US
publication_date: 20130228
---
This application is a continuation application of and claims priority from U.S. patent application Ser. No. 11 360 346 filed on Feb. 23 2006.

This invention was made with Government support under Contract No. B519700 awarded by the Department of Energy. The Government has certain rights in this invention.

The field of the invention is data processing or more specifically methods apparatus and computer program products for debugging a high performance computing program.

The development of the EDVAC computer system of 1948 is often cited as the beginning of the computer era. Since that time computer systems have evolved into extremely complicated devices. Today s computers are much more sophisticated than early systems such as the EDVAC. Computer systems typically include a combination of hardware and software components application programs operating systems processors buses memory input output devices and so on. As advances in semiconductor processing and computer architecture push the performance of the computer higher and higher more sophisticated computer software has evolved to take advantage of the higher performance of the hardware resulting in computer systems today that are much more powerful than just a few years ago.

As computer software has become more sophisticated the complexity of developing computer software has also increased. Increased complexity of computer software often produces defects in the software that a developer must identify and correct such as for example generating incorrect output or hanging during execution. Generating incorrect data may result from incorrect input or bad data processing. Computer software that hangs during execution most often results from a bad calling sequence among the program subroutines.

When computer software hangs during execution a developer typically needs to obtain an overview of the state of the entire software program in order to identify the specific cause of the software defect. To obtain such an overview a developer often utilizes computer software called a debugger. A debugger is used to analyze software defects or to optimize performance of other computer software. A debugger allows a user to follow the flow of program execution and inspect the state of a program at any point by controlling execution of the program being debugged. A debugger typically allows a user to track program variables execute a thread of execution step by step stop execution of a thread at a particular line number in computer source code stop execution of a thread when certain conditions are satisfied or examine a thread s calling sequence of subroutines.

Current debuggers adequately aid a developer in debugging a computer software program composed of a relatively small number of threads of execution such as for example software programs executing on single processor or small multi processor computer systems. Current debugger however do not provide a developer an efficient mechanism for debugging a special class of computer software programs called high performance computing programs. A high performance computing program is a computer software program composed of a massive number of threads of execution. Typically each thread of a high performance computing environment executes on a dedicated processor such that the threads of a high performance computing program execute in parallel on a massive number of processors to solve a common problem. Current debuggers do not provide adequate means of debugging these high performance computing programs because these debuggers are not aware that the threads of a high performance computing program often perform similar operations. Consequently current debuggers require a developer to manually sort through individual threads of execution to identify the defective threads. Often a high performance computing program may however contain over one hundred thirty thousand threads of execution such as for example a high performance computing program executing on the IBM BlueGene L supercomputer. Such a high performance computing program makes manually identifying defective threads a near impossible task.

In response to the challenges associated with debugging a computer program composed of numerous threads of execution some current debuggers implement the concept of thread groups based on the type classification of the thread under execution. In typical high performance computing programs however most of the threads have the same worker thread type classification. As such the benefits of having groups based on a type classification of a thread often do not accrue to developers debugging a high performance computing program.

Methods apparatus and computer program products are disclosed for debugging a high performance computing program by gathering lists of addresses of calling instructions for a plurality of threads of execution of the program assigning the threads to groups in dependence upon the addresses and displaying the groups to identify defective threads.

The foregoing and other objects features and advantages of the invention will be apparent from the following more particular descriptions of exemplary embodiments of the invention as illustrated in the accompanying drawings wherein like reference numbers generally represent like parts of exemplary embodiments of the invention.

Exemplary methods apparatus and products for debugging a high performance computing program according to embodiments of the present invention are described with reference to the accompanying drawings beginning with . sets forth a network diagram illustrating an exemplary system for debugging a high performance computing program according to embodiments of the present invention. The system of operates generally for debugging a high performance computing program according to embodiments of the present invention by gathering lists of addresses of calling instructions for a plurality of threads of execution of the program assigning the threads to groups in dependence upon the addresses and displaying the groups to identify defective threads. The system of also operates generally for debugging a high performance computing program according to embodiments of the present invention by inferring function names associated with the current values of program counters for a plurality of threads of the program. The system of also operates generally for debugging a high performance computing program according to embodiments of the present invention by inferring function names and line numbers in source code associated with the current values of program counters for a plurality of threads of the program.

Debugging a high performance computing program according to embodiments of the present invention occurs using a debugger. A debugger is a computer program that is used to analyze software defects in another computer program or to optimize performance of another computer program. A debugger assists in the analysis of software defects and optimization of performance by controlling a computer processor s execution of a computer program. Examples of debuggers that may be improved to operate according to embodiments of the present invention include the GNU Project Debugger the Absoft Fx2 Debugging Solution the Etnus TotalView Debugger or any other debugger as will occur to those of skill in the art. The example system of includes a high performance computing program executing in a high performance computing environment . A high performance computing program is computer program instructions for data processing implementing a massive number of threads of execution for parallel processing in a high performance computing environment. A thread of execution is a sequence of computer program instructions executed by a computer processor. A high performance computing environment is massively parallel computer hardware operating to simultaneously execute a plurality of threads of execution using a massive number of processing nodes. A high performance computing environment may include for example computer clusters computing grids supercomputers and so on.

In the system of the high performance computing environment includes nodes connected to network through wireline connection . Each node is an embedded computer system that consists of at least one processor computer memory and a link to a network that connects the nodes together. Nodes communicate with each other by passing messages developed using a programming model such as for example the Message Passing Interface MPI OpenMP model the Unified Parallel C UPC model and so on. In the example of each node simultaneously executes a thread of the high performance computer program assigned for execution in the high performance computing environment by a program manager .

Embedded computer systems such as nodes in the example of present special problems for a software developer because embedded systems lack keyboards screens disk drives and other helpful user interfaces and storage devices that typically aid a developer in debugging a program. In the example system of therefore each node includes an On Chip Debugger OCD . Each OCD is computer hardware generally used to monitor and control nodes . Specifically each OCD controls a node s execution of a thread of execution. An OCD controls a node s execution of the thread by reading and writing data into registers and memory locations of a node and by operating hardware interrupts on the node.

In the system of the high performance computing environment also includes service node connected to network through wireline connection and connected to OCDs through control network . Service node is an embedded computer system having installed upon it node management services . The node management service is computer program instructions for managing nodes . In the example system of the node management service manages nodes using OCDs . Using OCDs the node management service operates generally for booting nodes installing software on nodes monitoring nodes and controlling program execution on nodes . The node management service communicates with the OCDs through a data communications connection implemented using for example the Joint Test Action Group JTAG protocol.

JTAG is the IEEE 1149.1 standard entitled Standard Test Access Port and Boundary Scan Architecture for testing and debugging printed circuit boards integrated circuits and embedded systems using boundary scan technology. First standardized in 1990 the electronics industry has widely adopted JTAG. Although JTAG was designed for printed circuit boards JTAG is primarily used for testing sub blocks of integrated circuits and serves as a useful mechanism for debugging embedded systems by providing a convenient back door into the system. Using the backdoor created by the JTAG protocol the node management service may manage nodes by reading or writing to any address in the computer memory of nodes reading or writing to any register in the processors of nodes and sending interrupts to suspend and reset the processors of node . Although the connection between the node management service and nodes is described with reference to a JTAG connection such description is for explanation and not for limitation. The node management service may also communicate with nodes using other communications protocols useful in debugging a high performance computing program such as for example the Inter Integrated Computer IC Bus protocol.

The system of also includes a workstation connected to network through wireline connection . The workstation has installed upon it a debugger module . The debugger module is a set of computer program instructions for debugging a high performance computing program according to embodiments of the present invention. In the example of the debugger module operates generally by gathering lists of addresses of calling instructions for a plurality of threads of execution of the program assigning the threads to groups in dependence upon the addresses and displaying the groups to identify defective threads. The debugger module also operates generally by inferring function names associated with the current values of the program counters for threads of execution of the program. The debugger module also operates generally by inferring function names and line numbers in source code associated with the current values of the program counters for threads of execution of the program.

In the example of the debugger module debugs the high performance computing program through the node management service installed on the service node . The debugger module communicates with the node management service through a Node Management Service Application Programming Interface API provided by the node management service . The Node Management Service API API provides functions to the debugger module for controlling nodes that read or write to any address in the computer memory of nodes that read or write to any register in the processors of nodes and that send interrupts to suspend and reset the processors of node .

The Node Management Service API may be implemented as functions contained in dynamically linked libraries or statically linked libraries available to the debugger module . Implementations of the Node Management Service API used by debugger module may communicate with the node management service through network by calling member methods of a CORBA object or member methods of remote objects using the Java Remote Method Invocation RMI Application Programming Interface API .

 CORBA refers to the Common Object Request Broker Architecture a computer industry specifications for interopable enterprise applications produced by the Object Management Group OMG . CORBA is a standard for remote procedure invocation first published by the OMG in 1991. CORBA can be considered a kind of object oriented way of making remote procedure calls although CORBA supports features that do not exist in conventional RPC. CORBA uses a declarative language the Interface Definition Language IDL to describe an object s interface. Interface descriptions in IDL are compiled to generate stubs for the client side and skeletons on the server side. Using this generated code remote method invocations effected in object oriented programming languages such as C or Java look like invocations of local member methods in local objects.

The Java Remote Method Invocation API is a Java application programming interface for performing remote procedural calls published by Sun Microsystems. The Java RMI API is an object oriented way of making remote procedure calls between Java objects existing in separate Java Virtual Machines that typically run on separate computers. The Java RMI API uses a remote interface to describe remote objects that reside on the server. Remote interfaces are published in an RMI registry where Java clients can obtain a reference to the remote interface of a remote Java object. Using compiled stubs for the client side and skeletons on the server side to provide the network connection operations the Java RMI allows a Java client to access a remote Java object just like any other local Java object.

The system of includes server connected network through wireline connection . Server has installed upon it a program manager . The program manager is computer program instructions that manage the execution of the high performance computing program across the nodes of the high performance computing environment . In the example of the program manager assigns a thread of the high performance computing program to each node for execution in the high performance computing environment .

The system of also includes server connected to network through wireline connection . Server has installed upon it a file server . The file server is computer program instructions that manage the access to files hosted on server by the nodes in the high performance computing environment .

The system of also includes server connected to network through wireline connection . Server has installed upon it a database . Database contains configuration data representing all the hardware in the high performance computing environment operational data representing programs and program history of programs assigned for execution in the high performance computing environment environmental data representing current values for all the hardware components in the high performance computing environment and error data representing hardware and software errors detected in the high performance computing environment .

The arrangement of servers and other devices making up the exemplary system illustrated in are for explanation not for limitation. Data processing systems useful according to various embodiments of the present invention may include additional servers routers other devices and peer to peer architectures not shown in as will occur to those of skill in the art. Networks in such data processing systems may support many data communications protocols including for example the Transmission Control Protocol TCP the Internet Protocol IP the HyperText Transfer Protocol HTTP the Wireless Access Protocol WAP the Handheld Device Transport Protocol HDTP and others as will occur to those of skill in the art. Various embodiments of the present invention may be implemented on a variety of hardware platforms in addition to those illustrated in .

Debugging a high performance computing program in accordance with the present invention is generally implemented with computers that is with automated computing machinery. In the system of for example all the nodes servers and communications devices are implemented to some extent at least as computers. For further explanation therefore sets forth a block diagram of automated computing machinery comprising an exemplary computer useful in debugging a high performance computing program according to embodiments of the present invention. The computer of includes at least one computer processor or CPU as well as random access memory RAM which is connected through a system bus to processor and to other components of the computer.

Stored in RAM is a debugger module a set of computer program instructions for debugging a high performance computing program according to embodiments of the present invention. The debugger module operates generally by gathering lists of addresses of calling instructions for a plurality of threads of execution of the program assigning the threads to groups in dependence upon the addresses and displaying the groups to identify defective threads. In addition the debugger module operates generally by inferring function names associated with the current values of the program counters for threads of execution of the program. The debugger module also operates generally by inferring function names and line numbers in source code associated with the current values of the program counters for threads of execution of the program.

Also stored in RAM is an operating system . Operating systems useful in computers according to embodiments of the present invention include UNIX Linux Microsoft XP AIX IBM s i5 OS and others as will occur to those of skill in the art. Operating system and debugger module in the example of are shown in RAM but many components of such software typically are stored in non volatile memory also.

Computer of includes non volatile computer memory coupled through a system bus to processor and to other components of the computer . Non volatile computer memory may be implemented as a hard disk drive optical disk drive electrically erasable programmable read only memory space so called EEPROM or Flash memory RAM drives not shown or as any other kind of computer memory as will occur to those of skill in the art.

The example computer of includes one or more input output interface adapters . Input output interface adapters in computers implement user oriented input output through for example software drivers and computer hardware for controlling output to display devices such as computer display screens as well as user input from user input devices such as keyboards and mice.

The exemplary computer of includes a communications adapter for implementing data communications with other computers . Such data communications may be carried out serially through RS 232 connections through external buses such as the Universal Serial Bus USB through data communications networks such as IP networks and in other ways as will occur to those of skill in the art. Communications adapters implement the hardware level of data communications through which one computer sends data communications to another computer directly or through a network. Examples of communications adapters useful for determining availability of a destination according to embodiments of the present invention include modems for wired dial up communications Ethernet IEEE 802.3 adapters for wired network communications and 802.11b adapters for wireless network communications.

For further explanation sets forth a flow chart illustrating an exemplary method for debugging a high performance computing program according to embodiments of the present invention that includes gathering lists of addresses of calling instructions for a plurality of threads of execution of the program assigning the threads to groups in dependence upon the addresses and displaying the groups to identify defective threads. In the example of gathering lists of addresses of calling instructions for a plurality of threads of execution of the program may be carried out by gathering stack tracebacks for a plurality of threads of execution of the program where each stack traceback includes a list of addresses of calling instructions as discussed with below reference to . Gathering lists of addresses of calling instructions for a plurality of threads of execution of the program may also be carried out by retrieving current values of program counters for a plurality of threads of execution of the program at the time of gathering the stack tracebacks as discussed below with reference to .

In the example of assigning the threads to groups in dependence upon the addresses may be carried out by iteratively assigning to a group threads having identical subsets of the lists of addresses of calling instructions. Iteratively assigning to a group threads having identical subsets of the lists of addresses of calling instructions may be carried out as discussed below with reference to .

In the example of displaying the groups to identify defective threads may be carried out by displaying a group for an iteration and a count of the threads assigned to the group for the iteration as discussed below with reference to . Displaying the groups to identify defective threads may also be carried out by inferring a function name associated with a calling instruction address located at a position in a list corresponding to an iteration as discussed below with reference to the .

For further explanation sets forth a flow chart illustrating an exemplary node and an exemplary method for gathering lists of addresses of calling instructions for a plurality of threads of execution of the program used to explain debugging a high performance computing program according to embodiments of the present invention. In the method of gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program includes gathering stack tracebacks for a plurality of threads of execution of a high performance computing program. In the example of each stack traceback includes a list of addresses of calling instructions. A stack traceback is a series of stack frames on a stack that provides a traceable history of all previous functions called in the current execution tree. Gathering stack tracebacks for a plurality of threads of execution of a high performance computing program may be carried out by storing the gathered stack tracebacks for a plurality of threads of execution of a high performance computing program in stack traceback tables for each thread of execution. The stack traceback tables associate an iteration with an address of a calling instruction. The iteration represents a stack frame in a stack created during execution of a thread of a high performance computing program from which an address of a calling instruction is gathered . The address of a calling instruction represents the location in computer memory of a calling instruction in a function represented by a stack frame.

A calling instruction is a computer program instruction that transfers execution control of a processor from one function of a program to another function. A calling instruction typically corresponds to a return instruction. A return instruction is a computer program instruction that returns execution control of a processor to the function that contains the corresponding calling instruction. The following segment of pseudocode illustrates examples of calling instructions and return instructions.

This example is said to be pseudocode because the example is an explanation rather than a working model that is set forth in the form of computer source code. This example demonstrates calling instructions and return instructions useful in debugging a high performance computing program according to embodiments of the present invention. In the example above line of the pseudocode depicts a calling instruction that transfers execution control to function . Similarly line of the pseudocode depicts a calling instruction that transfers execution control from function to function . Line of the pseudocode depicts a calling instruction that transfers execution control from function to function . Line of the pseudocode depicts a calling instruction that transfers execution control from function to function . Line of the pseudocode depicts a return instruction from funtion that returns execution control to funtion . Line of the pseudocode depicts a return instruction from funtion that returns execution control to funtion . Line of the pseudocode depicts a return instruction from funtion that returns execution control to funtion . Line of the pseudocode depicts a return instruction from funtion that transfers execution control to the function containing the calling instruction depicted in line . In this specification a function containing a calling instruction is referred to as a calling function. In the example above therefore function function and function are calling functions. Readers of skill in the art will recognize that the computer source code in this example is presented in line. Such a presentation is purely for purposes of explanation. The return instruction for the function calling instruction would normally occur at line instead of line . Similarly the instruction for the function calling instruction would normally occur at line instead of line and the instruction for the function calling instruction would normally occur at line instead of line .

To keep track of the calling instructions and return instructions in a thread of execution the node in the example of includes a stack for the thread. Stack is a data storage and control flow structure that stores information regarding the current execution state of the functions of a thread of execution. Each function s execution state is represented in stack using a data structure called a stack frame . The stack operates using a Last In First Out LIFO principle. As the processor executes a calling instruction the processor creates a stack frame representing the function called by the calling instruction on the top of the stack. When the processor executes a return instruction of a function the processor removes the stack frame representing the function from the top of the stack and resumes executing the function represented by the next stack frame at the top of the stack at the return point stored in the stack frame. In the example of stack contains stack frames representing the functions function function function and function discussed above.

Each stack frame in the example of includes a frame handle . A frame handle is location in computer memory that represents the location in the stack of a stack frame representing a function. In the example of the frame handles of function function function and function in stack are represented by Frame Frame Frame and Frame respectively. The frame handle of a stack frame stores a frame pointer to the frame handle of the adjacent stack frame closer to the base of the stack. A frame pointer is an address in computer memory of the location of the beginning of a stack frame associated with an instance of a function. Each stack frame in the stack therefore is linked to the preceding stack frame. In the example of Frame stores a frame pointer to Frame Frame stores a frame pointer to Frame and Frame stores a frame pointer to Frame . Because Frame is a frame handle to the stack frame at the base of the stack no frame handle of a previous frame exists to which Frame may point. Frame may therefore store a value of 0 to indicate that Frame is the base of the stack.

Each stack frame in the example of also includes an address of a calling instruction. The address of a calling instruction is the location in computer memory of a calling instruction. When a processor executes a calling instruction the processor pushes the address of the calling instruction onto the top of the stack before creating a new frame on the top of the stack to represent the function called by the calling instruction. The address of the calling instruction is stored as part of the stack frame representing the calling function. The address of the calling instruction provides a return point for resuming execution in the calling function when the processor executes a return instruction in the function called by the calling instruction. In the example of Call Instruction Address is the return point for the function represented by the stack frame having a frame handle at Frame Call Instruction Address is the return point for the function represented by the stack frame having a frame handle at Frame and Call Instruction Address is the return point for the function represented by the stack frame having a frame handle at Frame . The stack frame having a frame handle at Frame does not have an address of a calling instruction because processor is executing the function represented by the stack frame having a frame handle at Frame . That is the processor has not executed a calling instruction in the function represented by the stack frame having a frame handle at Frame . Although the example of depicts stack frames containing only a frame handle and address of a calling instruction such a depiction is for explanation and not for limitation. In fact stack frames useful in debugging a high performance computing application may also contain current values for the registers of a processor arguments and local variables for the functions represented by the stack frames local variable of the function represented by the previous stack frame and so on.

In the example of node includes a frame pointer register a stack pointer register and a program counter register . The frame pointer register represents a register in the processor of a node that stores the address in computer memory of the frame handle for the stack frame at the top of the stack. The frame pointer register provides a reference point for a processor to access the data contained in the stack frame at the top of the stack using offsets from the value of the frame pointer register . The stack pointer register represents a register in the processor of a node that stores the address in computer memory of the top of the stack . When a processor pushes data onto the stack the processor first increases the value of the stack pointer register by one and then stores the new top value into the location stored in the stack pointer register . When a processor pops data off of the stack the processor first reads the top value from the location stored in the stack pointer register and then decreases the value of the stack pointer register by one. The program counter register represents a register in the processor of a node that stores the address in computer memory of the next computer program instruction for execution by the processor.

In the example of gathering the stack tracebacks from each thread may be carried out by iteratively traversing through the stack frames in the stack of each thread and reading the address of the calling instruction of each stack frame. The iterative traversal through the stack frames begin at the frame handle of the stack frame at the top of the stack located at the address stored in the frame pointer register . A value of 0 for the iteration marks the beginning point of the iterative traversal through the stack and therefore corresponds to the top stack frame in the stack . In the first iteration the address stored in the frame handle of the stack frame at the top of the stack points to the frame handle of the second stack frame from the top of the stack. A value of 1 for the iteration therefore corresponds to the second stack frame from the top of the stack . In the second iteration the address stored in the frame handle of the second stack frame from the top of the stack points to the frame handle of the third stack frame from the top of the stack . A value of 2 for the iteration therefore corresponds to the third stack frame from the top of the stack . In the third iteration the address stored in the frame handle of the third stack frame from the top of the stack points to the frame handle of the fourth stack frame from the top of the stack and so on until the base of the stack is reached as indicated by a value of 0 stored in frame handle at the base of the stack . In stack traceback tables in the example of a value for the iteration of 1 represents the stack frame having a frame handle at Frame a value for the iteration of 2 represents the stack frame having a frame handle at Frame and a value for the iteration of 3 represents the stack frame having a frame handle at Frame .

As the gathering step iteratively traverses the stack frames of a stack gathering the stack tracebacks from each thread may be carried out by reading the address of the calling instruction of a stack frame at the memory location obtained by subtracting the size of a frame handle storage location from the frame handle of a stack frame. In the example of the value of Call Instruction Address is read from the location obtained by subtracting the size of a frame handle storage location from Frame . Similarly the value of Call Instruction Address is read from the location obtained by subtracting the size of a frame handle storage location from Frame . The value of Call Instruction Address from the location obtained by subtracting the size of a frame handle storage location from Frame . In the example of gathering the stack tracebacks from each thread therefore stores Call Instruction Address Call Instruction Address and Call Instruction Address from the stack into the stack traceback table corresponding to a thread executing on a processor of node .

In the method of gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program also includes retrieving current values of program counters for a plurality of threads of execution of the program at the time of gathering the stack tracebacks. A debugger may store the retrieved current values of program counters in program counters . Program counters represent the program counter registers of each processor executing a thread of execution of a high performance computing program.

For further explanation sets forth a flow chart illustrating a further exemplary method for debugging a high performance computing program according to embodiments of the present invention that includes gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program. Gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program may be carried out by gathering stack tracebacks for a plurality of threads of execution of the program in the manner described with reference to . Each stack traceback in the example of includes a list of addresses of calling instructions. Gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program may be carried out by storing the gathered stack tracebacks for a plurality of threads of execution of the program into a stack traceback table .

The example of includes a stack traceback table that associates a thread identifier with an iteration an address of a call instruction a function name and a group identifier . The thread identifier represents a thread of a high performance computing program executing on a processor of a node. The iteration represents a stack frame in a stack created during execution of a thread of a high performance computing program from which an address of a calling instruction is gathered . The address of a calling instruction represents the location in computer memory of a calling instruction in a function represented by a stack frame. The function name represents the symbolic name assigned to a function in computer source code. The group identifier represents the group to which a thread is assigned in dependence upon the addresses of the calling instructions associated with the thread identifier of the thread.

In the example of gathering lists of addresses of calling instructions for a plurality of threads of execution of a high performance computing program may be carried out by retrieving current values of program counters for a plurality of threads of execution of the program at the time of gathering the stack tracebacks in the manner described with reference to . Retrieving current values of program counters for a plurality of threads of execution of the program at the time of gathering the stack tracebacks may be carried out by storing the retrieved current values of program counters in program counters . Program counters represent the program counter registers of each processor executing a thread of execution of a high performance computing program.

The method of also includes inferring function names associated with the current values of the program counters . Inferring function names associated with the current values of the program counters may be carried out using a symbol table . The symbol table is a table or group of tables that provide a mapping between the symbolic names and statements within computer source code and the memory locations of the computer machine code derived from those symbolic names and statements. The symbol table is typically generated during the compilation and linking process of computer source code. Symbol table may provide a variety of useful mapping features. Symbol table may provide mapping between an address of a computer program instruction and the source statement in computer source code. Symbol table may also provide mapping between a data address and a statically allocated variable to show the name of the variable assigned to the address. In addition symbol table may provide mapping between a source statement in computer source code and an instruction address range to provide the ability to step through a source statement. Using a symbol table therefore inferring function names associated with the current values of the program counters may be carried out by looking up the current values of the program counters in the symbol table and retrieving the function names associated with the range of addresses containing the current values of the program counters .

The method of also includes inferring function names and line numbers in source code associated with the current values of the program counters . Similar in operation to inferring function names discussed above inferring function names and line numbers in source code associated with the current values of the program counters may be carried out using the symbol table . Inferring function names and line numbers associated with the current values of the program counters may be carried out by looking up the current values of the program counters in the symbol table and retrieving the function names and line numbers associated with the current values of the program counters . In the example of inferring function names and line numbers in source code associated with the current values of the program counters may be carried out by storing the inferred function names and line numbers in a program counter table .

The example of includes a program counter table that associates a thread identifier with a program counter a function name a line number and a group identifier . The thread identifier represents a thread of a high performance computing program executing on a processor of a node. The program counter represents a program counter register of a processor executing a thread of execution of a high performance computing program. The function name represents the symbolic name assigned to a function in computer source code that maps to the computer program instruction located at the address contained in the program counter . The group identifier represents the group to which a thread is assigned in dependence upon the function name associated with the thread identifier of the thread.

The method of also includes assigning the threads to groups in dependence upon the addresses . Groups represent the groups to which a thread of execution is assigned. Groups may be implemented for threads associated with the same addresses of calling instructions the same function name the same line number and so on.

In the method of assigning the threads to groups in dependence upon the addresses includes iteratively assigning to a group threads having identical subsets of the lists of addresses of calling instructions. Readers will recall that the iteration represents a stack frame in a stack from which an address of a calling instruction is gathered . Iteratively assigning to a group threads having identical subsets of the lists of addresses of calling instructions may be carried out by identifying the values for the address of a calling instruction associated with the same value for iteration and assigning the threads having the same value for the address of a calling instruction to the same group using group identifier . If a group does not exist for a particular value of the address of a calling instruction the step of iteratively assigning may be carried out by creating a group for threads having the particular value for the address of a calling instruction. After assigning the threads to groups using a first value for iteration the step of iteratively assigning may then be carried out by assigning the threads to groups using the next value for iteration and so on until the threads to groups using all values for iteration have been assigned.

In the method of assigning the threads to groups in dependence upon the addresses also includes assigning threads to a group in dependence upon the functions names and line numbers associated with program counters of the threads. Assigning threads to a group in dependence upon the functions names and line numbers associated with program counters of the threads may be carried out by assigning threads having the same value for the function name and the same value for the line number to the same group using group identifier . If a group does not exist for a particular value for the function name and a particular value for the line number the step of assigning may be carried out by creating a group for threads having the particular value for the function name and the particular value for the line number .

The method of also includes displaying the groups to identify defective threads. A defective thread is a thread of execution executing in a manner different than other similar threads executing in a high performance computing environment. Defective threads may exist because of software or hardware defects. In the method of displaying the groups to identify defective threads includes displaying a group associated with a function name and a line number and a count of the threads assigned to the group associated with the function name and the line number . Displaying a group associated with a function name and a line number and a count of the threads assigned to the group associated with the function name and the line number may be carried out using a graphical user interface displayed on display screen . In the example of displaying a group associated with a function name and a line number and a count of the threads assigned to the group associated with the function name and the line number may include sorting the displayed groups according to the count of the threads assigned to the group .

In the method of displaying the groups to identify defective threads also includes inferring a function name associated with a calling instruction address located at a position in a list corresponding to an iteration . Inferring a function name associated with a calling instruction address located at a position in a list corresponding to an iteration may be carried out using symbol table . Using symbol table inferring function names associated with a calling instruction address located at a position in a list corresponding to an iteration may be carried out by looking up the current values of the calling instruction address in the symbol table and retrieving the function names associated with a calling instruction address . In the example of inferring a function name associated with a calling instruction address located at a position in a list corresponding to an iteration may be carried out by storing the inferred function names in the stack traceback table .

In the method of displaying the groups to identify defective threads includes displaying a group for an iteration and a count of the threads assigned to the group for the iteration . Displaying a group for an iteration and a count of the threads assigned to the group for the iteration may be carried out using a graphical user interface displayed on display screen . In the example of displaying a group for an iteration and a count of the threads assigned to the group for the iteration may include sorting the displayed groups according to the count of the threads assigned to the group .

For further explanation of displaying groups to identify defective threads sets forth a line drawing of an example of a graphical user interface GUI useful in debugging a high performance computing program according to embodiments of the present invention. In the example of GUI includes a stack tracebacks section . The stack traceback section of GUI provides a stack traceback text box in which the GUI displays groups of threads assigned to groups in dependence upon addresses of calling instructions or in dependence upon the function name associated with the current values of program counter registers. In the example of the GUI displays the groups for an iteration and a count of the threads assigned to the group for the iteration.

In the stack traceback text box of the example of numbered lines and depict function names associated with the current values of program counters of threads of a high performance computing program. Line of text box indicates that the program counter register of one node of the 4096 nodes in the high performance computing environment contains the address of a computer program instruction in the MPI BCAST BCast function. Line of text box indicates that the program counter register of 127 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the MPI BCAST Advance function. Line of text box indicates that the program counter register of 3968 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the MPI BARRIER SendRecv function.

In the stack traceback text box of the example of numbered lines and depict function names associated with values of calling instruction addresses located at a position in a list corresponding to the first iteration through the stacks of threads of a high performance computing program. Line of text box indicates that the calling instruction address of 128 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the MPI BCAST function. Line of text box indicates that the calling instruction address of 3968 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the MPI BARRIER function.

In the stack traceback text box of the example of numbered line depicts function names associated with values of calling instruction addresses located at a position in a list corresponding to the second iteration through the stacks of threads of a high performance computing program. Line of text box indicates that the calling instruction address of 4096 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the processData function.

In the stack traceback text box of the example of numbered line depicts function names associated with values of calling instruction addresses located at a position in a list corresponding to the third iteration through the stacks of threads of a high performance computing program. Line of text box indicates that the calling instruction address of 4096 nodes of the 4096 nodes in the high performance computing environment contained the address of a computer program instruction in the main function.

In the example of GUI includes a source code section . The source code section of GUI provides a source code text box in which a debugger displays source code that includes function names and line numbers associated with current values of the program counters of threads of a high performance computing program. In the example of cursor of source code text box points to the MPI BCAST function and line of the source code inferred from the value of the program counter register .

In the example of GUI includes a registers section for displaying information regarding the current state of the registers of a processor of a node running a high performance computing program. The registers section of a GUI displays a current node drop down list . A user operates the current node drop down list to display the registers of the processor of the selected node executing a thread of the high performance computing program. The registers section of a GUI displays a program counter register a stack pointer register and a frame pointer register . The program counter register represents a register in the processor of the node selected in the current node drop down list that stores the address in computer memory of the next computer program instruction for execution by the processor. In the example of a GUI displays retrieved current values of program counters for a plurality of threads of execution of a high performance computing program at the time of gathering the stack tracebacks depicted in a stack tracebacks section . The stack pointer register represents a register in the processor of the node selected in the current node drop down list that stores the address in computer memory of the top of the stack. The frame pointer register represents a register in the processor of the node selected in the current node drop down list that stores the address in computer memory of the frame handle for the stack frame at the top of the stack.

Exemplary embodiments of the present invention are described largely in the context of a fully functional computer system for debugging a high performance computing program. Readers of skill in the art will recognize however that the present invention also may be embodied in a computer program product disposed on signal bearing media for use with any suitable data processing system. Such signal bearing media may be transmission media or recordable media for machine readable information including magnetic media optical media or other suitable media. Examples of recordable media include magnetic disks in hard drives or diskettes compact disks for optical drives magnetic tape and others as will occur to those of skill in the art. Examples of transmission media include telephone networks for voice communications and digital data communications networks such as for example Ethernets and networks that communicate with the Internet Protocol and the World Wide Web. Persons skilled in the art will immediately recognize that any computer system having suitable programming means will be capable of executing the steps of the method of the invention as embodied in a program product. Persons skilled in the art will recognize immediately that although some of the exemplary embodiments described in this specification are oriented to software installed and executing on computer hardware nevertheless alternative embodiments implemented as firmware or as hardware are well within the scope of the present invention.

It will be understood from the foregoing description that modifications and changes may be made in various embodiments of the present invention without departing from its true spirit. The descriptions in this specification are for purposes of illustration only and are not to be construed in a limiting sense. The scope of the present invention is limited only by the language of the following claims.

