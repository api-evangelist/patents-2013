---

title: Systems and methods for performing haptic conversion
abstract: Systems and methods for haptic conversion are described. One disclosed method includes the steps of: determining a characteristic of a target user interface device having a target haptic output device, determining a source haptic effect associated with a source user interface device having a source haptic output device; converting the source haptic effect to a target haptic effect, the conversion based at least in part on the characteristic of the target haptic output device, and generating a haptic signal associated with the target haptic effect, the haptic signal configured to cause the target haptic output device to output the target haptic effect.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09558637&OS=09558637&RS=09558637
owner: Immersion Corporation
number: 09558637
owner_city: San Jose
owner_country: US
publication_date: 20130910
---
The present invention generally relates to haptic feedback and more particularly to systems and methods for performing haptic conversion.

Touch enabled devices have become increasingly popular. For instance mobile and other devices may be configured with touch sensitive displays so that a user can provide input by touching portions of the touch sensitive display. And the touch sensitive device may make use of haptic effects for example haptic effects configured to augment a visual or auditory effect. This type of haptic effect can be used to provide information to the user. However at times the effect may be designed for a particular type of device but be output by a different type of device. Performing a haptic conversion in such a case may enable the device to provide haptic information that would otherwise be lost to a user.

Embodiments of the present disclosure include devices configured to output haptic effects and further configured to perform a haptic conversion. These haptic effects may include but are not limited to vibrations changes in texture changes in coefficient of friction and or simulation of boundaries obstacles or other discontinuities that can be perceived through use of an interface device. Some software applications may be designed to output haptic effects in specialized devices e.g. to specific types of actuators. Since not all devices comprise the same type of actuators systems for haptic conversion may increase the compatibility of software with a broader range of devices. Devices that comprise haptic conversion may be more user friendly and may provide a more compelling user experience.

In one embodiment a method for haptic conversion comprises determining a characteristic of a target user interface device having a target haptic output device determining a source haptic effect associated with a source user interface device having a source haptic output device converting the source haptic effect to a target haptic effect the conversion based at least in part on the characteristic of the target haptic output device and generating a haptic signal associated with the target haptic effect the haptic signal configured to cause the target haptic output device to output the target haptic effect.

This illustrative embodiment is mentioned not to define the limits of the present subject matter but to provide an example to aid understanding thereof. Illustrative embodiments are discussed in the Detailed Description and further description is provided there. Advantages offered by various embodiments may be further understood by examining this specification and or by practicing one or more embodiments of the claimed subject matter.

Example embodiments are described herein in the context of systems and methods for haptic conversion. Those of ordinary skill in the art will realize that the following description is illustrative only and is not intended to be in any way limiting. Other embodiments will readily suggest themselves to such skilled persons having the benefit of this disclosure. Reference will now be made in detail to implementations of example embodiments as illustrated in the accompanying drawings. The same reference indicators will be used throughout the drawings and the following description to refer to the same or like items.

In the interest of clarity not all of the routine features of the implementations described herein are shown and described. It will of course be appreciated that in the development of any such actual implementation numerous implementation specific decisions must be made in order to achieve the developer s specific goals such as compliance with application and business related constraints and that these specific goals will vary from one implementation to another and from one developer to another.

In one embodiment a mobile phone includes a haptic output device or actuator such as an eccentric rotating mass motor. The phone s user wishes to play a video game on her phone and so she executes the game.

Many such games are designed for game consoles. A game console typically includes one or more controllers that include multiple haptic actuators for providing haptic effects. For example an actuator may include two motors for outputting dual vibration effects. In the illustrative embodiment software on the mobile phone acts as a conversion layer for the haptic effects output by the game. While the conversion software in the illustrative embodiment is present in the phone the conversion software may be contained in other components such as a peripheral in communication with the phone. For example the peripheral may be a wearable device such as Google glass.

The conversion layer receives the haptic effect signal generated by the game. The conversion layer then determines the haptic capabilities of the mobile phone or of any peripherals in communication with the mobile phone. For example the mobile phone described above in the illustrative embodiment includes a single ERM eccentric rotating mass for outputting vibration effects. The conversion layer uses information about the haptic output device in the mobile phone to determine how to render the haptic effect. For instance it may determine how to represent the two motor effect generated by the game using the single ERM present in the phone.

Once the conversion layer has determined how to represent the effect on the phone the conversion layer generates a haptic signal to be sent to the ERM in the mobile phone and then communicates the signal to the ERM. The ERM then outputs the effect to the user of the mobile phone enhancing play of the game on the mobile phone.

This illustrative example is given to introduce the reader to the general subject matter discussed herein. The invention is not limited to this example. The following sections describe various additional non limiting embodiments and examples of devices systems and methods for parameter modification of haptic effects.

The smartphone includes a housing . The housing contains electronic components such as a processor and memory for executing programming code and for interacting with a user. The program code stored and executed on the phone may be used to implements methods of various embodiments of the present disclosure.

The smartphone also includes a display . The display may be a touch sensitive display capable of detecting user interactions with the smartphone . As a user interacts with the smartphone the smartphone may output effects to alert the user to various interactions. For example in one embodiment the smartphone executes a gaming application that allows a user to play a game displayed on the display of smartphone . As various actions take place in the game the game may generate haptic effects that are appropriate for the various events occurring in the game and the smartphone may output effects that are generated based on the effects output by the game.

The electronic device can be any device that is capable of receiving user input e.g. a mobile phone a tablet a music player a wearable device or a laptop computer. In another embodiment electronic device may comprise a multifunction controller. For example a controller for use in a kiosk ATM or other computing device. Further in one embodiment electronic device may comprise a controller for use in a vehicle.

The processor is in communication with the memory and in the embodiment shown both the processor and the memory are disposed within the housing . The touch sensitive display which comprises or is in communication with a touch sensitive surface is partially disposed within the housing such that at least a portion of the touch sensitive display is exposed to a user of the electronic device . In some embodiments the touch sensitive display may not be disposed within the housing . For example the electronic device may be connected to or otherwise communicate with a touch sensitive display disposed within a separate housing. In some embodiments the housing may comprise two housings that are slidably coupled to each other pivotably coupled to each other or releasably coupled to each other. In other embodiments the housing may comprise any number of housings.

In the embodiment shown in the touch sensitive display is in communication with the processor and is configured to provide signals to the processor and or the memory and to receive signals from the processor and or memory .

The processor may comprise a microprocessor a digital signal processor DSP an application specific integrated circuit ASIC field programmable gate arrays FPGAs and state machines. Such processors may further comprise programmable electronic devices such as PLCs programmable interrupt controllers PICs programmable logic devices PLDs programmable read only memories PROMs electronically programmable read only memories EPROMs or EEPROMs or other similar devices

The memory can comprise any suitable tangible and non transitory computer readable medium such as RAM ROM EEPROM or the like that embodies program components that configure operation of the computing device. In some embodiments memory is configured to store program code or data or both for use by the processor which is configured to execute program code stored in memory and to transmit signals to and receive signals from the touch sensitive display . In the embodiment shown in the processor is in communication with the communication interface and is configured to receive signals from the communication interface and to output signals to the communication interface to communicate with other components or devices such as one or more electronic devices. In addition the processor is in communication with haptic output device and haptic output device and is further configured to output signals to cause haptic output device or haptic output device or both to output one or more haptic effects.

Furthermore the processor is in communication with sensor and is configured to receive signals from sensor . For example processor may receive one or more signals from sensor corresponding with one or more interactions with the electronic device . For instance one or more sensor signals may be received by processor from sensor when a user of the electronic device moves or shakes the device such as when playing a video game. As another example one or more sensor signals can be received by processor from sensor when a user presses a location on the touch sensitive display and or when a user makes a gesture on touch sensitive display . In some embodiments processor can receive sensor information from one or more sensors such as sensor to derive or otherwise determine one or more interactions. Interactions can include but are not limited to a contact a series of contacts a gesture a contact above a predetermined threshold a contact below a predetermined threshold a movement of the device a vibration a shake any other suitable interaction or a combination thereof.

In embodiments processor receives one or more sensor signals from one or more input devices integrated into the electronic device connected to the electronic device and or in communication with the electronic device . For example the processor may receive one or more sensor signals from a touch sensitive surface of the touch sensitive display . As another example the processor may receive one or more sensor signals from an input device such as a keyboard a mouse a touchpad a trackball a microphone a touch sensitive surface a gaming peripheral such as a Bluetooth enabled game controller a button a trigger and or another suitable input device that is integrated into the electronic device connected to the electronic device and or in communication with the electronic device . A sensor signal may comprise information such as one or more contacts locations pressures gestures key presses and or other information indicating how a user is interacting with one or more input devices. Numerous other embodiments are disclosed herein and variations are within the scope of this disclosure.

The processor may then utilize the information it receives from one or more sensors such as sensor to determine one or more effects to output. For example the first sensor signal may indicate an interaction with electronic device and the processor may use the information in the sensor signal to determine one or more effects that should be output. For example the processor may determine that one or more audio effects one or more visual effects and or one or more haptic effects should be output based at least in part on information received from one or more sensor signals.

Once the processor determines one or more effects to output the processor can generate one or more output signals. For example in one embodiment the processor may determine a haptic effect and generate a haptic signal to be output to haptic output device and or which then output the haptic effect. In some embodiments the haptic signal may be interpreted by the haptic output device interface which in turn can transmit a haptic signal to the haptic output device or haptic output device .

In some embodiments of the present disclosure the haptic output device that would typically be present in the platform for which an application was designed i.e. the source haptic output device may not be available on the target interface device . For example in one embodiment the application may be designed to operate with a LRA linear resonant actuator but the target interface device may instead comprise a piezoelectric actuator. In such an embodiment the haptic signal may be converted from the source haptic effect to a target haptic effect before the signal is transmitted to the target haptic output device or haptic output device or both.

For example in one embodiment the haptic output device interface may access a data store in memory that contains characteristics of haptic output devices . The haptic output device interface can then use the characteristics to determine what types of effects haptic output devices are capable of generating and convert the haptic signal from the original source haptic effect to a target effect. In some embodiments this target effect may comprise an effect that represents the source and at the same time is capable of being output by the target haptic output devices . Further details regarding such conversions are provided below.

Various source haptic output devices and environments may be utilized such as DualShock Console PC DirectX Android IOS touchsense wheels joysticks steering wheels and web browser. Also various target devices including single and multiple actuator devices and target environments may be used. For example the following devices and environments may be utilized in various embodiments single or multiple actuator devices multiple devices using a mobile phone and a mobile peripheral standard haptic actuators ERM LRA high definition actuators Piezo EAP etc. deformation actuators friction based touch screens electrostatic vibration gaming chairs and directional devices. In one embodiment in which multiple users are interacting such as in a multiplayer game one player may be utilizing one environment such as an iPhone while a second player is utilizing a second environment such as an Android OS phone.

The device illustrated in is merely illustrative and in various other embodiments the electronic device may comprise or be in communication with fewer or additional components and or devices than shown in . For example other user input devices such as a mouse a keyboard a camera and or other input device s may be contained within the electronic device or in communication with the electronic device . As another example electronic device may comprise or otherwise be in communication with one two three or more sensors and or one two three or more haptic output devices. In another embodiment electronic device may not comprise a communication interface . In yet another embodiment electronic device may not be in communication with haptic output device . Numerous other embodiments are disclosed herein and variations are within the scope of this disclosure.

Various other components may also be modified. For example in some embodiments sensor is partially or fully disposed within housing . As another example haptic output device may be disposed within the housing of the electronic device . In one embodiment the electronic device is not in communication with haptic output device and does not comprise communication interface . In another embodiment the electronic device does not comprise a touch sensitive display or a communication interface but comprises a touch sensitive surface e.g. a touchpad and is in communication with an external display. Thus in various embodiments the electronic device may comprise or be in communication with any number of components such as in the various embodiments disclosed herein as well as variations that would be apparent to one of skill in the art.

The electronic device in includes a touch sensitive display that comprises a touch sensitive surface. In some embodiments a touch sensitive surface may be overlaid on the touch sensitive display . In other embodiments the electronic device may comprise or be in communication with a display and a separate touch sensitive surface. In still other embodiments the electronic device may comprise or be in communication with a display and may comprise or be in communication with other user input devices such as a mouse a keyboard buttons knobs slider controls switches wheels rollers other manipulanda or a combination thereof.

In some embodiments one or more touch sensitive surfaces may be included on or disposed within one or more sides of the electronic device . For example in one embodiment a touch sensitive surface is disposed within or comprises a rear surface of the electronic device . In another embodiment a first touch sensitive surface is disposed within or comprises a rear surface of the electronic device and a second touch sensitive surface is disposed within or comprises a side surface of the electronic device .

In the embodiment shown in the touch sensitive display provides a mechanism for a user to interact with the electronic device . For example the touch sensitive display detects the location or pressure or both of a user s finger in response to a user hovering over touching or pressing the touch sensitive display all of which may be referred to as a contact in this disclosure .

In one embodiment a contact can occur through the use of a camera. For example a camera may be used to track movements such as the viewer s eye movements as the reader views the content displayed on the display of the electronic device . In this embodiment haptic effects may be triggered based at least in part on the viewer s eye movements. For example a haptic effect may be output when a determination is made that the viewer is viewing content at a particular location of the display . In some embodiments the touch sensitive display may comprise be coupled to be connected with or otherwise be in communication with one or more sensors that determine the location pressure a size of a contact patch or any of these of one or more contacts on the touch sensitive display .

For example in one embodiment the touch sensitive display comprises or is in communication with a mutual capacitance system. In another embodiment the touch sensitive display comprises or is in communication with an absolute capacitance system. In some embodiments the touch sensitive display may comprise or be in communication with a resistive panel a capacitive panel infrared LEDs photodetectors image sensors optical cameras or a combination thereof. Thus the touch sensitive display may incorporate any suitable technology to determine a contact on a touch sensitive surface such as for example resistive capacitive infrared optical thermal dispersive signal or acoustic pulse technologies or a combination thereof. In embodiments a determined haptic effect is modified or otherwise configured based at least in part on interactions and or other information received from one or more sensors that can be used to determine one or more interactions.

In the embodiment shown in haptic output devices and are in communication with the processor and are configured to provide one or more haptic effects. For example in one embodiment when a haptic signal is provided to haptic output device haptic output device or both by the processor the respective haptic output device s outputs a haptic effect based on the actuation signal. For example in some embodiments the processor is configured to transmit a haptic signal to haptic output device the haptic signal comprising an analog drive signal. In some embodiments the processor is configured to transmit a command to haptic output device wherein the command includes parameters to be used to generate an appropriate drive signal to cause the haptic output device to output the haptic effect. In other embodiments different signals and different signal types may be sent to each of one or more haptic output devices. For example in some embodiments a processor may transmit low level drive signals to drive a haptic output device to output a haptic effect. Such a drive signal may be amplified by an amplifier or may be converted from a digital to an analog signal or from an analog to a digital signal using suitable processors or circuitry to accommodate the particular haptic output device being driven.

A haptic output device such as haptic output devices or can be any component or collection of components that is capable of outputting one or more haptic effects. For example a haptic output device can be one of various types including but not limited to an eccentric rotational mass ERM actuator a linear resonant actuator LRA a piezoelectric actuator a voice coil actuator an electro active polymer EAP actuator a memory shape alloy a pager a DC motor an AC motor a moving magnet actuator an E core actuator a smartgel an electrostatic actuator an electrotactile actuator a deformable surface an electrostatic friction ESF device an ultrasonic friction USF device or any other haptic output device or collection of components that perform the functions of a haptic output device or that are capable of outputting a haptic effect. Multiple haptic output devices or different sized haptic output devices may be used to provide a range of vibrational frequencies which may be actuated individually or simultaneously. Various embodiments may include a single or multiple haptic output devices and may have the same type or a combination of different types of haptic output devices.

In still other embodiments haptic output device may apply electrostatic friction or attraction for example by use of an electrostatic surface actuator to simulate a texture on the surface of touch sensitive display . Similarly in some embodiments haptic output device may use electrostatic attraction to vary the friction the user feels on the surface of touch sensitive display . For example in one embodiment haptic output device may comprise an electrostatic display or any other device that applies voltages and currents instead of mechanical motion to generate a haptic effect.

In some embodiments one or more haptic output devices are directly or indirectly in communication with electronic device such as via wired or wireless communication. In one embodiment the electronic device can be placed in a vehicle or is integrated into a vehicle and one or more haptic output devices are embedded into the vehicle. For example one or more haptic output devices may be embedded in a seat steering wheel pedal etc. of the vehicle. In some embodiments instead of having haptic output device and or haptic output device or in addition to having haptic output device and or haptic output device the electronic device has one or more other output devices. For example the electronic device may have a speaker and or a display. In one embodiment the electronic device has one or more haptic output devices one or more speakers and one or more displays. Numerous other embodiments are disclosed herein and variations are within the scope of this disclosure.

In various embodiments one or more haptic effects may be produced in any number of ways or in a combination of ways. For example in one embodiment one or more vibrations may be used to produce a haptic effect such as by rotating an eccentric mass or by linearly oscillating a mass. In some such embodiments the haptic effect may be configured to impart a vibration to the entire electronic device or to only one surface or a limited part of the electronic device. In another embodiment friction between two or more components or friction between at least one component and at least one contact may be used to produce a haptic effect such as by applying a brake to a moving component such as to provide resistance to movement of a component or to provide a torque. In order to generate vibration effects many devices utilize some type of actuator and or other haptic output device. Known haptic output devices used for this purpose include an electromagnetic actuator such as an Eccentric Rotating Mass ERM in which an eccentric mass is moved by a motor a Linear Resonant Actuator LRA in which a mass attached to a spring is driven back and forth or a smart material such as piezoelectric electro active polymers or shape memory alloys.

In other embodiments deformation of one or more components can be used to produce a haptic effect. For example one or more haptic effects may be output to change the shape of a surface or a coefficient of friction of a surface. In an embodiment one or more haptic effects are produced by creating electrostatic forces and or ultrasonic forces that are used to change friction on a surface. In other embodiments an array of transparent deforming elements may be used to produce a haptic effect such as one or more areas comprising a smartgel. Haptic output devices also broadly include non mechanical or non vibratory devices such as those that use electrostatic friction ESF ultrasonic surface friction USF or those that induce acoustic radiation pressure with an ultrasonic haptic transducer or those that use a haptic substrate and a flexible or deformable surface or those that provide projected haptic output such as a puff of air using an air jet and so on. In some embodiments a haptic effect is a kinesthetic effect. U.S. patent application Ser. No. 13 092 484 describes ways that one or more haptic effects can be produced and describes various haptic output devices. The entirety of U.S. patent application Ser. No. 13 092 484 filed Apr. 22 2011 is hereby incorporated by reference.

In the communication interface is in communication with the processor and provides wired or wireless communications from the electronic device to other components or other devices. For example the communication interface may provide wireless communications between the electronic device and a wireless sensor or a wireless actuation device. In some embodiments the communication interface may provide communications to one or more other devices such as another electronic device to allow users to interact with each other at their respective devices. The communication interface can be any component or collection of components that enables the multi pressure touch sensitive input electronic device to communicate with another component or device. For example the communication interface may comprise a PCI network adapter a USB network adapter or an Ethernet adapter. The communication interface may communicate using wireless Ethernet including 802.11a g b or n standards. In one embodiment the communication interface can communicate using Radio Frequency RF Bluetooth CDMA TDMA FDMA GSM WiFi satellite or other cellular or wireless technology. In other embodiments the communication interface may communicate through a wired connection and may be in communication with one or more networks such as Ethernet token ring USB FireWire 1394 fiber optic etc. In some embodiments electronic device comprises a single communication interface . In other embodiments electronic device comprises two three four or more communication interfaces. Thus in embodiments electronic device can communicate with one or more components and or devices through one or more communication interfaces. In other embodiments an electronic device may not comprise a communication interface .

The embodiment shown in depicts a single sensor . In some embodiments multiple sensors can be used. Additionally a sensor may be housed in the same component as the other components of the electronic device or in a separate component. For example in some embodiments the processor memory and sensor are all comprised in an electronic device such as a portable music player a portable telephone and or a wearable device. In some embodiments a sensor is placed in component separate from another component that houses the memory and or processor. For instance a wearable sensor may be in communication with the processor and memory or an electronic device via a wired or wireless connection.

In some embodiments the electronic device may comprise two or more housing components such as in a clamshell arrangement or in a slidable arrangement. For example in one embodiment electronic device may comprise a clamshell configuration with a touch sensitive display disposed in each of the portions of the clamshell. Furthermore in embodiments where the electronic device comprises at least one touch sensitive surface on one or more sides of the electronic device or in embodiments where the electronic device is in communication with an external touch sensitive surface the display may or may not comprise a touch sensitive surface. In some embodiments one or more touch sensitive surfaces may have a flexible touch sensitive surface. In other embodiments one or more touch sensitive surfaces may be rigid. In various embodiments the electronic device may comprise both flexible and rigid touch sensitive surfaces.

The housing of the electronic device shown in provides protection for at least some of the components of electronic device . For example the housing may be a plastic casing that protects the processor and memory from foreign articles such as rain dirt or dust. In some embodiments the housing protects the components in the housing from damage if the electronic device is dropped by a user. The housing can be made of any suitable material including but not limited to plastics rubbers or metals. Various embodiments may comprise different types of housings or a plurality of housings. For example in some embodiments electronic device may be a portable device handheld device toy gaming console handheld video game system gamepad game controller desktop computer portable multifunction device such as a cell phone smartphone personal digital assistant PDA eReader portable reading device handheld reading device laptop tablet computer digital music player remote control medical instrument etc. In embodiments the electronic device may be embedded in another device such as a vehicle wrist watch other jewelry arm band gloves etc. Thus in embodiments the electronic device is wearable. In some embodiments the electronic device may be embedded in another device such as for example the console of a car or a steering wheel. Numerous other embodiments are disclosed herein and variations are within the scope of this disclosure.

The game controller includes controls such as buttons and joysticks for use in controlling a game or other software executing on the mobile telephone . In some embodiments the game controller includes one or more haptic output devices such as those shown in . In other embodiments the haptic output device is contained within the mobile telephone and effects are transmitted to the game controller via the mobile telephone . Various other embodiments are also possible.

The communication interface provides the user interactions to a haptic effect generator . The haptic effect generator may be for example a game program for executing a game running on the device . In embodiments of the present disclosure the haptic effect generator may be designed for devices that include different haptic output device capabilities than those available with device . For example if the haptic effect generator is a game program the haptic effect generator may be designed to output haptic effects to a game controller having two similarly sized eccentric rotating mass motors designed to produce vibrations in a game controller. However in one embodiment the device may include for example a single haptic output device . Further in some embodiments the single haptic output device may be of a different type than that for which the game was originally designed.

The device in also comprises a haptic conversion layer . In some embodiments the haptic conversion layer may include one or more hardware and software components for converting a haptic effect from a source haptic output device to the target haptic output device . For example the haptic conversion layer may include one or more data stores for determining one or more characteristics of haptic output device . The characteristics may include for example the number and types of haptic output devices in communication with contained within or coupled to the device as well as specific operating characteristics of those haptic output devices e.g. time to accelerate time to decelerate maximum or minimum available power maximum or minimum available operating frequency etc. . The haptic conversion layer can utilize the characteristics to determine how to represent the haptic effect as produced by the source haptic output device when provided by the target haptic output device .

The haptic conversion layer may comprise an application programming interface API and may be in communication with or utilize one or more existing API s to implement the method illustrated in . The haptic conversion layer may also be implemented as a separate chip incorporated into the target device or into an interface between the target device and a peripheral. In some embodiments the haptic conversion layer includes a data store for storing user preferences. In such an embodiment the user may be able to tune the effects generated on the target device by for example increasing or decreasing the magnitude with which effects are converted.

The signal that is generated by the haptic conversion layer is then provided to the haptic output device interface . The haptic output device interface then provides an appropriate signal to the haptic output device . For example in one embodiment the haptic conversion layer provides a high level command to the haptic output device interface . The haptic output device interface then generates a signal that can be sent to the haptic output device to cause a haptic effect to be generated. Numerous other embodiments are disclosed herein and variations are within the scope of this disclosure.

Embodiments of the present disclosure may implement a conversion layer that takes haptic commands from various different sources and maps them according to the capabilities of the current haptic device. For example the conversion layer may provide the ability to create haptics according to the capabilities of the target device but using different sources of haptic calls such as a dual shock controller or touch sensitive device. For example in one embodiment a device according to the present disclosure may allow a user controlling a console game with a mobile device to feel the game s haptic output without the game developer changing the original dual actuator effect code.

In the embodiment shown in the process begins when a processor receives the first sensor signal s . For example the processor may receive a sensor signal indicating that a user has interacted with a control displayed on a touch sensitive display .

The processor next determines a characteristic of a target user interface device . For example the processor may determine that the target user interface device includes a single haptic output device . The processor may further determine the type of haptic output device . For example the processor may determine that the haptic output device is a vibrating motor. In other embodiments during initialization or at some other point the processor performs testing to determine what types of haptic effects the target haptic output device is capable of performing.

Various characteristics may be utilized to convert the haptic effects. For example an embodiment may take into account the rise time fall time and maximum force a particular motor can deliver in a target interface device. Another embodiment may take into account the type of feedback that can be output by a target interface device such as a vibration or deformation. In some embodiments the processor may be configured to access a data store e.g. memory comprising a map of the duration magnitude and envelope of the source and target motors. In some embodiments the processor may also convert the haptic effect from an effect configured to operate with a dual actuator source to a haptic effect configured to operate with a single actuator target. For instance in one embodiment the duration and magnitude being sent to two actuators may be averaged and then sent to the single actuator in order to provide an effect. In some embodiments one or more of the target actuators may be the same or similar to one or more of the source actuators. In such a case the mapping between any two actuators may be a simple direct mapping.

In one embodiment the target actuator may have a greater haptic capability than the source actuator. In such an embodiment an augmented mapping could occur. For example an embodiment in which a dual ERM DualShock is mapped to one piezo actuator could use pulsing vibration mapping parameters to simulate both the large and small ERM motors or average that feeling if both are playing in the source effect but additional audible range frequency mapping could be applied for the piezo mapping that is not possible with the slower ERM actuators. In another embodiment in which a DualShock is mapped to a kinesthetic feedback device such as a rumblepad or racing wheel the source haptic effect could have additional directional haptic mapping applied to the target actuation. In yet another example an embodiment in which a DualShock is mapped to a single actuator that is capable of providing both vibrational and temperature based haptics would allow for an augmented haptic mapping having vibration as well as temperature parameters e.g. warmer for large motor mappings and cooler for smaller motor mappings.

In yet another example a source vibration command is modified for a target deformation actuator. For instance a high frequency vibration may be converted to a small motion haptic effect. And a low frequency vibration is converted to a large motion effect. In some embodiments a design tool is used to determine effects on a source platform such as a PC and map those effects to a target platform such as Android.

In the embodiments described herein a designer of a user interface is able to design haptic effects for a program for use on a particular device. Subsequently if the user interface is executed on a different device platform than the one for which the effects were designed then the effects are automatically converted to the new platform without the need for the designer to take additional steps to enable the appropriate effects on the new platform. For instance a game designer is able to design a game for play on a gamepad for a PC and upon execution of the same game on a mobile phone the haptic effects are automatically converted so that the effects on the mobile phone correspond to the effects that the designer originally specified.

The processor next determines a source haptic effect . In some embodiments the source haptic effect may comprise a haptic effect generated by an application prior to conversion. For example the designer of a game may associate a certain haptic effect with a particular occurrence in a game. For instance if an explosion occurs the game may be designed to output a high magnitude relatively long duration vibration through both eccentric rotating mass motors in a game controller. In some embodiments however application developer may have designed the haptic effect to be output using specific types of haptic output devices. In some embodiments the user interface device may not comprise these types of haptic output devices.

The processor next converts the source haptic effect to a target haptic effect . In some embodiments the conversion is based on the one or more characteristics of the target user interface device determined at . The conversion will attempt a conversion that represents the source haptic effect on the target user interface device given the characteristic s of the target user interface device . In some embodiments this conversion may be configured to compensate for factors such as the number of haptic output devices the type of haptic output devices the available bandwidth of haptic output devices the available power of the haptic output devices and factors associated with the source haptic effect.

In embodiments of the present disclosure a processor maps source effects for a source device having M source actuators to destination effects for a destination or target device having N destination actuators. In one embodiment if each source effect address only one source actuator and each destination effect address only one destination actuator the processor may perform the following steps for each source effect map the source effect to a destination effect addressing the destination actuator that can reproduce the source effect given source actuator performance characteristics and destination actuator performance characteristics over the dynamic range of the source effect. For instance if a source effect is a low frequency effect and the target includes a destination actuator that is capable of outputting the same or similar effect as the source actuator the processor maps the source effect to a destination effect on that particular target actuator. In another embodiment of mapping from M to N actuators directional spatial information may be preserved. For example if a right to left directional haptic effect is used as a source haptic effect the same right to left directional effect may be preserved for the target effect even though the target device may have less or more actuators.

The processor then generates a haptic signal associated with the target effect . This signal can then be output to one or more haptic output devices to allow the user to experience the effect. While the target device is described as having a single haptic output device multiple haptic output devices may be present. And the haptic signal that is generated may be generated for one some or all of the haptic output devices present on the target user interface device .

The methods systems and devices discussed above are examples. Various configurations may omit substitute or add various procedures or components as appropriate. For instance in alternative configurations the methods may be performed in an order different from that described and or various stages may be added omitted and or combined. Also features described with respect to certain configurations may be combined in various other configurations. Different aspects and elements of the configurations may be combined in a similar manner. Also technology evolves and thus many of the elements are examples and do not limit the scope of the disclosure or claims.

Specific details are given in the description to provide a thorough understanding of example configurations including implementations . However configurations may be practiced without these specific details. For example well known circuits processes algorithms structures and techniques have been shown without unnecessary detail in order to avoid obscuring the configurations. This description provides example configurations only and does not limit the scope applicability or configurations of the claims. Rather the preceding description of the configurations will provide those skilled in the art with an enabling description for implementing described techniques. Various changes may be made in the function and arrangement of elements without departing from the spirit or scope of the disclosure.

Also configurations may be described as a process that is depicted as a flow diagram or block diagram. Although each may describe the operations as a sequential process many of the operations can be performed in parallel or concurrently. In addition the order of the operations may be rearranged. A process may have additional steps not included in the figure. Furthermore examples of the methods may be implemented by hardware software firmware middleware microcode hardware description languages or any combination thereof. When implemented in software firmware middleware or microcode the program code or code segments to perform the necessary tasks may be stored in a non transitory computer readable medium such as a storage medium. Processors may perform the described tasks.

Having described several example configurations various modifications alternative constructions and equivalents may be used without departing from the spirit of the disclosure. For example the above elements may be components of a larger system wherein other rules may take precedence over or otherwise modify the application of the disclosure. Also a number of steps may be undertaken before during or after the above elements are considered. Accordingly the above description does not bound the scope of the claims.

The use of adapted to or configured to herein is meant as open and inclusive language that does not foreclose devices adapted to or configured to perform additional tasks or steps. Additionally the use of based on is meant to be open and inclusive in that a process step calculation or other action based on one or more recited conditions or values may in practice be based on additional conditions or values beyond those recited. Headings lists and numbering included herein are for ease of explanation only and are not meant to be limiting.

Embodiments in accordance with aspects of the present subject matter can be implemented in digital electronic circuitry in computer hardware firmware software or in combinations of the preceding. In one embodiment a computer may comprise a processor or processors. The processor comprises or has access to a computer readable medium such as a random access memory RAM coupled to the processor. The processor executes computer executable program instructions stored in memory such as executing one or more computer programs including a sensor sampling routine selection routines and other routines to perform the methods described above.

Such processors may comprise a microprocessor a digital signal processor DSP an application specific integrated circuit ASIC field programmable gate arrays FPGAs and state machines. Such processors may further comprise programmable electronic devices such as PLCs programmable interrupt controllers PICs programmable logic devices PLDs programmable read only memories PROMs electronically programmable read only memories EPROMs or EEPROMs or other similar devices.

Such processors may comprise or may be in communication with media for example tangible computer readable media that may store instructions that when executed by the processor can cause the processor to perform the steps described herein as carried out or assisted by a processor. Embodiments of computer readable media may comprise but are not limited to all electronic optical magnetic or other storage devices capable of providing a processor such as the processor in a web server with computer readable instructions. Other examples of media comprise but are not limited to a floppy disk CD ROM magnetic disk memory chip ROM RAM ASIC configured processor all optical media all magnetic tape or other magnetic media or any other medium from which a computer processor can read. Also various other devices may include computer readable media such as a router private or public network or other transmission device. The processor and the processing described may be in one or more structures and may be dispersed through one or more structures. The processor may comprise code for carrying out one or more of the methods or parts of methods described herein.

While the present subject matter has been described in detail with respect to specific embodiments thereof it will be appreciated that those skilled in the art upon attaining an understanding of the foregoing may readily produce alterations to variations of and equivalents to such embodiments. Accordingly it should be understood that the present disclosure has been presented for purposes of example rather than limitation and does not preclude inclusion of such modifications variations and or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.

