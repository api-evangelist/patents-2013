---

title: Structured illumination microscopy optical arrangement including projection artifact supression element
abstract: A structured illumination microscopy optical arrangement includes a projection path and an imaging path. The imaging path includes an imaging sensor and imaging optical elements. The projection path includes a light generator, a pattern generating element such as a spatial light modulator (SLM), and projection optical elements including an output lens and a projector artifact suppression element (PASE) located in the projection path between the SLM and the output lens. The PASE may include birefringent material which splits respective light rays of the structured illumination pattern source light to provide at least one replication of the structured illumination pattern with an offset transverse to the projection path. The offset replication of the structured illumination pattern increases the accuracy of the system by reducing spatial harmonic errors and spurious intensity variations due to projector pixel gap artifacts which may otherwise produce errors in resulting Z-height measurements.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09182583&OS=09182583&RS=09182583
owner: Mitutoyo Corporation
number: 09182583
owner_city: Kanagawa
owner_country: JP
publication_date: 20131115
---
The invention relates generally to metrology systems and more particularly to systems utilizing structured illumination microscopy methods to obtain measurements of inspected objects.

Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions to allow workpiece inspection. One exemplary prior art system that can be characterized as a general purpose off line precision vision system is the commercially available QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the QVPAK 3D CNC Vision Measuring Machine User s Guide published January 2003 and the QVPAK 3D CNC Vision Measuring Machine Operation Guide published September 1996 each of which is hereby incorporated by reference in their entirety. This type of system is able to use a microscope type optical system and move the stage so as to provide inspection images of either small or relatively large workpieces at various magnifications.

Accuracies in the micron or sub micron range are often desired in such systems. This is particularly challenging with regard to Z height measurements. Z height measurements along the optical axis of the camera system are generally derived from a best focus position such as that determined by an autofocus tool. Determining a best focus position is a relatively complex process that generally depends on combining and or comparing information derived from multiple images. Thus the level of precision and reliability achieved for Z height measurements is often less than that achieved for the X and Y measurement axes where measurements are typically based on feature relationships within a single image. Recently known techniques generally referred to as structured illumination microscopy SIM methods are being incorporated in microscopic measurement and inspection systems in order to increase their measurement resolution and or accuracy beyond the optical limits normally associated with simple imaging e.g. to the micron and submicron level. 

Briefly many SIM methods include projecting a pattern of light stripes onto a workpiece in a first image and then shifting that pattern on the workpiece transversely to the stripes in a second image and so on for a third image or more. The resulting images may be analyzed according to known methods to improve the surface measurement resolution as described in greater detail below. Such techniques may enhance X Y and or Z measurements. However the systems and methods used in known structured illumination pattern SIP generating subsystems e.g. for forming and shifting the patterns have so far limited the economy versatility and or resolution and accuracy improvements of practical SIM systems in undesirable ways. In some methods of analysis it is desirable for the stripes to exhibit a sinusoidal intensity profile across the stripes. In some systems the SIM methods utilize sinusoidal patterns created by a digital mirror device DMD spatial light modulator SLM positioned in the projection path and the optics project sinusoidal fringes onto a workpiece that is being measured. One advantage of such controllable digital SLM systems is that the size of the projected fringes can be adapted to be nearly optimum for any desired resolution and or imaging optics and or field of view. However one disadvantage when the sinusoidal fringes are created with a digital SLM is that some of the higher harmonics of the fundamental sinusoidal frequency may be created and transferred by the optics through to the final light stripe images. The resulting height maps HM may contain effects from these higher harmonic artifacts including Z height errors which appear as approximately periodic ripples which interfere with the accuracy of the measurements produced by the system. Thus an improved method for economically utilizing SIM techniques based on controllable digital SLM s while reducing the production of error artifacts e.g. Z height ripples would be desirable.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

A structured illumination microscopy SIM optical arrangement is provided for obtaining measurements of inspected objects. In various implementations the SIM optical arrangement includes a projection path and an imaging path. The imaging path includes an imaging sensor and a set of imaging optical elements while the projection path includes a light generator a pattern generating element and a set of projection optical elements including an output lens and a projector artifact suppression element. The projector artifact suppression element may be configured such that its presence does not substantially alter the numerical aperture that would otherwise be provided by the projection optical elements of the SIM system.

In various implementations the pattern generating element may comprise a controllable spatial light modulator SLM comprising an SLM pixel array having a characteristic SLM pixel pitch along a first direction. The pattern generating element receives radiation that is emitted from the light generator and is controlled for generating a structured illumination pattern as an output. In one specific implementation the SLM pixel array may comprise a reflective digital light processing array. The set of projection optical elements directs the structured illumination pattern to provide structured illumination pattern source light to illuminate a field of view where a workpiece may be located and includes an output lens that outputs the structured illumination pattern source light to the field of view. The set of imaging optical elements receives structured illumination pattern workpiece light that results from the structured illumination pattern source light having been reflected by or transmitted through a workpiece and images the structured illumination pattern workpiece light along the imaging path toward the imaging sensor which includes an imaging pixel array. The set of imaging optical elements includes an objective lens that inputs the structured illumination pattern workpiece light from the workpiece. In various implementations the output lens and the objective lens may be the same lens. The projector artifact suppression element is located in the projection path between the pattern generating element and the output lens and is configured to split respective light rays of the structured illumination pattern source light and thereby provide at least one replication of the structured illumination pattern with an offset transverse to the projection path.

The projector artifact suppression element may be configured to split respective rays of the structured illumination pattern source light into a respective ordinary ray and a respective extraordinary ray such that an ordinary ray structured illumination pattern continues along the projection path and at least one extraordinary ray structured illumination pattern is the replication of the structured illumination pattern which continues along the projection path with an offset from the ordinary ray structured illumination pattern transverse to the projection path. The projector artifact suppression element may include at least one or two layers of birefringent material and may be configured to provide at least two replications of the structured illumination pattern with an offset transverse to the projection path. The structured illumination pattern may be a fringe pattern with the long direction of the fringes extending along a direction that is transverse to the direction of the offset of the replication of the structured illumination pattern.

An SLM pixel array may include gaps between adjacent pixels and the projector artifact suppression element may at least partially reduce intensity variations in the imaging pixel array due to gap image artifacts arising from gaps between adjacent pixels in the SLM pixel array. In one implementation the projector artifact suppression element is configured to reduce the intensity variations in the imaging pixel array based on replicating the gap image artifacts in the at least one replication of the structured illumination pattern such that due to the offset more pixels in the imaging pixel array receive similar amounts of the gap image artifacts.

Those skilled in the art will appreciate that the controlling computer system may generally consist of any computing system or device. Suitable computing systems or devices may include personal computers server computers minicomputers mainframe computers distributed computing environments that include any of the foregoing and the like. Such computing systems or devices may include one or more processors that execute software to perform the functions described herein. Processors include programmable general purpose or special purpose microprocessors programmable controllers application specific integrated circuits ASICs programmable logic devices PLDs or the like or a combination of such devices. Software may be stored in memory such as random access memory RAM read only memory ROM flash memory or the like or a combination of such components. Software may also be stored in one or more storage devices such as magnetic or optical based disks flash memory devices or any other type of non volatile storage medium for storing data. Software may include one or more program modules which include routines programs objects components data structures and so on that perform particular tasks or implement particular abstract data types. In distributed computing environments the functionality of the program modules may be combined or distributed across multiple computing systems or devices and accessed via service calls either in a wired or wireless configuration.

The vision components portion includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. The machine vision inspection system is also described in commonly assigned U.S. Pat. Nos. 7 454 053 7 324 682 8 111 905 and 8 111 938 which are each incorporated herein by reference in their entireties.

The vision components portion includes an optical assembly portion light sources and and a workpiece stage having a central transparent portion . The workpiece stage is controllably movable along X and Y axes that lie in a plane that is generally parallel to the surface of the stage where a workpiece may be positioned. The optical assembly portion includes a camera system an interchangeable objective lens and may include a turret lens assembly having lenses and . Alternatively to the turret lens assembly a fixed or manually interchangeable magnification altering lens or a zoom lens configuration or the like may be included.

The optical assembly portion is controllably movable along a Z axis that is generally orthogonal to the X and Y axes by using a controllable motor that drives an actuator to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece . Of course in other embodiments the stage could be moved along the Z axis relative to a static optical assembly in a known manner. The controllable motor is connected to the input output interface via a signal line .

A workpiece or a tray or fixture holding a plurality of workpieces which is to be imaged using the machine vision inspection system is placed on the workpiece stage . The workpiece stage may be controlled to move relative to the optical assembly portion such that the interchangeable objective lens moves between locations on a workpiece and or among a plurality of workpieces .

As will be described in more detail below for certain SIM operations the workpiece may be illuminated by SIP source light provided from the structured illumination pattern generating portion . The structured illumination pattern generating portion configures the structured illumination pattern that is output to the workpiece . One or more of a stage light a coaxial light structured illumination pattern generating portion and a surface light e.g. a ring light may emit source light and or respectively to illuminate the workpiece or workpieces . The light source may emit source light and the structured illumination pattern generating portion may emit SIP source light along a shared path including a beamsplitter as described in greater detail with reference to . The source light is reflected or transmitted as workpiece light and the workpiece light is used for imaging passes through the interchangeable objective lens and the turret lens assembly and is gathered by the camera system . The image of the workpiece s captured by the camera system is output on a signal line to the control system portion . The light sources and the structured illumination pattern generating portion may be connected to the control system portion through signal lines or buses and respectively. To alter the image magnification the control system portion may rotate the turret lens assembly along axis to select a turret lens through a signal line or bus .

In various exemplary embodiments the optical assembly portion is movable in the vertical Z axis direction relative to the workpiece stage using a controllable motor that drives an actuator a connecting cable or the like to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece captured by the camera system . The term Z axis as used herein refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor when used is connected to the input output interface via a signal line .

As shown in in various exemplary embodiments the control system portion includes a controller the input output interface a memory a workpiece program generator and executor and a power supply portion . Each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface may include a position control element and a speed acceleration control element although such elements may be merged and or indistinguishable. The lighting control interface includes lighting control elements which control for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system . The lighting control interface also includes a lighting control element that in the illustrated embodiment works in conjunction with the structured illumination pattern SIP generating portion to provide structured illumination during image acquisitions and particularly during SIM mode image acquisitions as described in greater detail below.

The memory may include an image file memory portion a SIM SIP memory portion a workpiece program memory portion that may include one or more part programs or the like and a video tool portion . The video tool portion includes video tool portion and other video tool portions e.g. which determine the GUI image processing operation etc. for each of the corresponding video tools and a region of interest ROI generator that supports automatic semi automatic and or manual operations that define various ROIs that are operable in various video tools included in the video tool portion .

In the context of this disclosure and as known by one of ordinary skill in the art the term video tool generally refers to a relatively complex set of automatic or programmed operations that a machine vision user can implement through a relatively simple user interface e.g. a graphical user interface editable parameter windows menus and the like without creating the step by step sequence of operations included in the video tool or resorting to a generalized text based programming language or the like. For example a video tool may include a complex pre programmed set of image processing operations and computations which are applied and customized in a particular instance by adjusting a few variables or parameters that govern the operations and computations. In addition to the underlying operations and computations the video tool comprises the user interface that allows the user to adjust those parameters for a particular instance of the video tool. For example many machine vision video tools allow a user to configure a graphical region of interest ROI indicator through simple handle dragging operations using a mouse in order to define the location parameters of a subset of an image that is to be analyzed by the image processing operations of a particular instance of a video tool. It should be noted that the visible user interface features are sometimes referred to as the video tool with the underlying operations being included implicitly.

The video tool portion also includes Z height measurement tools portion which provides various operations and features related to Z height measurement operations as described in greater detail below. In one embodiment the Z height measurement tools portion may include Z height tools and Z height tools SIM SIP mode control . The Z height tools may include an autofocus tool and a multipoint autofocus tool for example. The Z height tools SIM SIP mode control may govern certain aspects of image stack acquisition and related structured light pattern generation operations in conjunction with the Z height tools that are configured in a mode that determines best focus heights and or Z height measurements based on SIM techniques e.g. as described further below .

Briefly the Z height measurement tools portion may perform at least some operations similarly to known Z height measurement tools for example performing operations in learn mode and run mode for generating all or part of a focus curve and finding its peak as a best focus position. Additional Z height measurement tool operations may also be performed as will be described in greater detail below.

Alternative configurations are also possible for the Z height measurement tools portion . For example the Z height tools may provide additional Z height measurement tool elements or the Z height tools may have a selectable mode option which controls whether they are configured to operate in a conventional contrast based analysis mode that uses conventionally lighted images e.g. using the light source to provide source light or a SIM based analysis mode that uses images lighted with specific structured illumination patterns e.g. using the structured illumination pattern generating portion to provide SIP source light . In either case the SIM SIP mode control may provide operations that govern the user interface and interrelationships of the Z height measurement tool elements in a manner that corresponds to their operating mode and or use of SIM image acquisition and analysis techniques. More generally it will be appreciated that such techniques may be implemented in any now known or later developed form that is operable in conjunction with the machine vision inspection system to provide the features described herein in relation to measurement operations based on SIM image acquisition and analysis techniques.

The signal line from the camera system and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller or elsewhere that initiates image acquisition. One or more display devices e.g. the display of and one or more input devices e.g. the joystick keyboard and mouse of can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various graphical user interface GUI features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera system and or to directly control the vision system components portion . The display devices may display user interface features associated with the video tools

In operation the light generator may emit light through a first part of the SIP optical portion such that it is properly configured e.g. collimated to illuminate an illumination area of the pixel array of the SLM . The SLM may then generally transmit partially transmit or block light according to known methods to transmit or project a desired pattern along an optical path through the remainder of the SIP optical portion . As shown in the projected pattern is output from the SIP optical portion to be input to the beamsplitter where it is directed as coaxial light through the objective lens to provide SIP source light to illuminate the field of view.

In some embodiments the SLM may comprise a reflective or transmissive LCD type array such as a micro display graphics array from Forth Dimension Displays headquartered in Dalgety Bay Fife Scotland United Kingdom which includes an LCD pixel array that may generally be controlled by conventional video signals if desired and may be used to display an electronically generated 8 bit grayscale pattern that may transmit partially transmit or block the light through any given pixel of the pattern depending on its grayscale value. However in various implementations the SLM may comprise an arrangement of any now known or later developed type of controllable reflective shutters that can provide controllable light deflection in a desired pattern. One type of controllable reflective shutter array that may be used includes liquid crystal on silicon LCOS micro display products available for example from Forth Dimension Displays headquartered in Dalgety Bay Fife Scotland. Various implementations may generally incorporate another type of array which is digital micro mirror device DMD . DMD s and associated components are available for example from Texas Instruments DLP Products Plano Tex. DLP generally stands for digital light processing which is associated with the fact that the array elements in DMD devices are either in an on position or off position and projected transmitted grayscale patterns must be generated over a time as an accumulated sequence of superimposed binary patterns.

In various embodiments the light generator may be used in a strobe illumination mode of operation to provide a combination of a very fast light generator response time in the s or ns range at suitable optical power levels. One example of a light generator may include one or more high intensity light emitting diodes LEDs such as one of the LEDs in the Luxeon product line available from Philips Lumileds Lighting Company of San Jos Calif.

In the embodiment shown in the SLM may be a commercially available DMD and the SLM controller portion may be a companion digital controller chip such as the chip sets available from Texas Instruments DLP Products referenced above. The SLM controller portion may respond to desired grayscale pattern definitions or requests and generate the synchronized control signals to the SLM and the light generator that provide the accumulated sequence of superimposed binary patterns that generate the desired grayscale pattern over time. As described in more detail in the previously incorporated 116 application commercial SLM controllers may have certain deficiencies and in the illustrated embodiment the TSP may be used in conjunction with the SLM controller portion to overcome or reduce these deficiencies for example by allowing the grayscale control finer than 256 bits and or other advantages in some embodiments or implementations. In various embodiments the TSP may receive grayscale pattern and exposure level requests or control signals from the SIP lighting control element and or the SIM SIP memory portion which may store predetermined or learned control signal configurations or parameters related to various desired patterns over the line or bus . The TSP may then process the received signals and send multiple incremental grayscale pattern requests to the SLM controller portion such that the SLM controller portion may generate each of the incremental grayscale patterns with 256 bit resolution over time using its native control routines and circuits to control the SLM and the light generator . The TSP may thus control an overall image exposure achieved by the multiple incremental grayscale patterns because it may control the number of incremental requests within an image integration period of the camera with which it may exchange control signals over the line . In various embodiments some of the incremental requests may be for identical patterns and or exposure increments. In some embodiments one or more of the incremental requests may be for different patterns and or exposure increments. Greater than 256 bit grayscale resolution for the illumination pattern may be achieved in this manner if desired. In general it is desirable that the TSP provides dedicated processing and deterministic timing in relation to the control signals it receives and or sends to various components. In some embodiments the TSP may therefore comprise a programmable logic array or the like. In some optional embodiments rather than the SLM controller portion directly controlling the light generator the line may be omitted and a light control timing signal from the SLM controller portion may be output to the TSP on the line and the TSP may control the light generator over the line based on the timing signal from the SLM controller portion . This may allow providing additional features and or precise customized control of the light generator within the timing window required by the native operations of the SLM controller portion . Various features and operations outlined above are described in greater detail below.

The diagram illustrates a pattern subdivision exposure sequence comprising a plurality of respective pattern portions P1 P4 also referred to as subdivision pattern portions exposed using respective iteration intensities of radiation from a light generator during respective iteration subdivision times T1 T4 respectively. The pattern subdivision exposure sequence builds a simple 4 bit gray level sine wave pattern for the purpose of illustrating the basic principles that are described below.

The diagram includes corresponding elements that are vertically aligned along pixel columns across light stripe . A truncated plan view shows a roughly sinusoidal gray level intensity variation GLV across the single structured illumination light stripe LS1 which is a stripe extending along the direction Ys. The lighter and darker shadings across the stripe LS represent the accumulated exposure or net intensity resulting from the intensity pattern subdivision exposure sequence which is designated PatIter k indicating that it may correspond to a complete grayscale pattern exposure iteration or increment k e.g. k 1 2 3 etc. as described further below. This particular stripe is lightest along the pixel column d and darkest along pixel columns a and a . Immediately above the plan view representation of PatIter k is a graph schematically representing the contributions to the net intensity profile across the PatIter k. The graph uses crosshatch patterns that are coded to be the same as the crosshatch patterns used to indicate the pixel columns that are activated to provide the respective subdivision pattern portions P1 P4 during respective subdivision times T1 T4. It is assumed that the light generator is set to the same intensity for each of the times T1 T4 such that the accumulated intensity is proportional to the times. The times T1 T4 are binary subdivisions that is T3 2 T4 T2 2 T3 and T1 2 T2. It is shown that the pixels of the brightest column d are on in each of the subdivision pattern portions P1 P4 to provide the net intensity ni4. The pixels of the next brightest columns c and c are on in each of the subdivision pattern portions except P2 to provide the net intensity ni3. The pixels of the next brightest columns b and b are on only in the subdivision pattern portions P3 and P4 to provide the net intensity ni2 and the darkest columns a and a are on only in the subdivision pattern portion P to provide the net intensity ni1. The timing diagram shows that the total time to generate the gray level strip pattern PatIter k is TIter k assuming negligible time between the time periods T1 T4 for the purposes of this illustration. It will be appreciated that latency times delays and the like may be calibrated or determined for particular machines light generators voltage levels etc. by design and or experiment and the results calibrated or stored e.g. in the SIM SIP memory portion such that a combination of timing operating voltages and the like that provide a desired or calibrated illumination level may be readily determined and or compensated for e.g. in the operation of the SIP controller .

The typical native control method outlined above may be used in DLP controllers e.g. in a digital DMD controller which adjust the overall time TIter k and or the light generator intensities used during the subdivision times to achieve a desired net gray level intensity pattern.

A general transfer function for a sine pattern exposure during a single image as outlined above with reference to may be expressed as 

The typical native control method outlined above adjusts the overall time TIter k which is equivalent to increasing each of the times Ti and or the light generator intensities Li used during the subdivision times to achieve a desired net gray level intensity pattern increase. However as described in the 116 application this approach may lead to certain deficiencies and the SIM measurement accuracy may be sensitive to some selections of these variables that would be of no consequence in many other applications. Therefore the typical native control method for DLP s may be inadequate for certain high resolution precision machine vision inspection operations and certain high accuracy SIM applications in particular for which related problems and solutions are described in greater detail in the 116 application.

As shown in a series A of three phase shifted images I1a I3a that is with the illumination pattern phase shifted are captured at a vertical position Za. The small image of the optical system in shows that the projected illumination arising from the source SA as well as the imaging system are focused at a plane FP and the Z height Za is far from FP. As a result the corresponding modulation depth MDa is relatively small. As shown in a series B of three phase shifted images I1b I3b are captured at a vertical position Zb. The small image of the optical system in shows that the projected illumination arising from the source SA and well as the imaging system are focused at a plane FP and the Z height Zb is closer to FP than was Za. As a result the corresponding modulation depth MDb is relatively larger than MDa. As shown in a series C of three phase shifted images I1c I3c are captured at a vertical position Zc. The small image of the optical system in shows that the projected illumination arising from the source SA as well as the imaging system are focused at a plane FP and the Z height Zc is approximated at FP. As a result the corresponding modulation depth MDc is approximately as large as possible.

As shown in the modulation depths MDa MDc are plotted against their corresponding Z heights labeled vertical sample position and a modulation depth curve MC is fitted to the plotted points. The peak of the modulation depth curve MC indicates the Z height where the corresponding pixel location on the workpiece is in focus.

The SIM techniques outlined above are known to be capable of producing high resolution Z height measurements with high lateral resolution. However as will be apparent to one skilled in the art the accuracy of the techniques depends at least in part on the accuracy of the fringe images e.g. the fidelity of the projected sinusoidal fringes and the resulting images and of any resulting height maps that may be produced as part of the measurement process. As will be described in more detail below with respect to various Z height ripple effects may be caused by various projection and or imaging artifacts which may negatively affect the accuracy. It will be appreciated that due to the high resolution potential of the SIM technique that even very small erroneous variations in the intensity and or intensity profile will be significant to the resulting accuracy.

In the implementation of the amount of projector pixel gap image artifacts corresponding to the projected pixel gaps PGx and PGy that are received by the individual pixels of the imaging pixel array IPP may cause significant intensity variations from pixel to pixel. As specific representative examples a first imaging pixel IP1 is illustrated as receiving no pixel gap image artifact and no corresponding intensity reduction corresponding to a projected pixel gap while a second imaging pixel IP2 is illustrated as receiving a pixel gap image artifact and an intensity reduction corresponding to only an X direction projected pixel gap PGx and a third imaging pixel IP3 is illustrated as receiving a pixel gap image artifact and an intensity reduction corresponding to both X and Y direction projected pixel gaps PGx and PGy. Such varying gap image artifacts are problematic in that they cause erroneous periodic intensity variations in the resulting SIM images which results in corresponding Z height errors resembling periodic ripples in surface height maps that are produced by the SIM system.

Importantly inaccuracies may also result due to spatial harmonics included in a coarse resolution sine wave pattern carried by the projected pixel pattern PPP. More specifically an idealized schematically represented output signal S1 which is illustrated below the projected pixel pattern PPP comprises a coarse sine wave with a period PER1 which extends over the width of approximately four columns of the projected pixel pattern PPP. As indicated the coarse sine wave signal S1 varies over only three distinct signal levels and is schematically representative of one simplified example implementation of signals which may be utilized in the SIM technique of the configuration of . Due to the coarse nature of the sine wave signal S1 a relatively high spatial harmonic content may be present which may result in inaccuracies in the corresponding measurements that are produced. As will be described in more detail below with respect to according to principles disclosed herein such inaccuracies from these harmonic content effects may be reduced through the utilization of one or more replicated projected pixel patterns. Thus it will be appreciated that the principles disclosed herein may be used to address either of these causes of inaccuracy or artifacts separately and or in combination.

The pixel representations of the replicated projected pixel pattern RPP have spacings between them designated as X direction projected pixel gaps RGx and Y direction projected pixel gaps RGy. One result of adding the replicated projected pixel pattern RPP in the specific embodiment of is that the pixels of the imaging pixel array IPP receive a more consistent amount or a more uniform distribution of the projector pixel gap image artifacts. As a specific representative example the imaging pixel IP1 is illustrated as receiving a pixel gap image artifact and an intensity reduction corresponding to both X direction and Y direction projected pixel gaps RGx and RGy in contrast to where no pixel gap image artifact or intensity reduction corresponding to projected pixel gaps were received by the imaging pixel IP1. The imaging pixel IP2 which in was shown to receive a pixel gap image artifact and intensity reduction corresponding to only an X direction projected pixel gap PGx in is shown to also receive a pixel gap image artifact and an intensity reduction corresponding to a Y direction projected pixel gap RGy. The imaging pixel IP3 is shown to receive the same signal effects corresponding to the X and Y direction projected pixel gaps PGx and PGy as were illustrated in . Thus each of the imaging pixels IP1 IP2 and IP3 is illustrated in as receiving similar common mode signal effects from two projected pixel gaps through the utilization of the replicated projected pattern pixels RPP.

It will be appreciated that even in an implementation where an identical number of pixel gap image artifacts are not received by each of the pixels of the imaging pixel array IPP the effects of the projected pixel gaps may be reduced to some degree through the utilization of the replicated projected pixel pattern RPP. In some implementations the suppression of the projected pixel gap effects may be considered to be achieved by making the projected pixel gap effects at least partially a common mode effect in a majority of the pixels of the imaging pixel array IPP. In the embodiment of the projected pattern shifts PPSx and PPSy are indicated as being approximately one half of the projector pattern pixel pitch PPx and PPy respectively although in other implementations different fractions of the projected pixel pitch may be utilized. It will be appreciated that in various implementations different projected pattern widths and pixel pitches may be utilized according to the needs of the workpiece magnification workpiece characteristics desired field of view etc. As will be described in more detail below with respect to and in various embodiments it may be desirable that a projector artifact suppression element that is utilized to replicate the projected pixel pattern may be dimensioned in relation to the projected pixel pitch rather than the imaging pixel pitch.

As indicated previously in addition to the above described issues that arise from the projected pixel gaps the replication of the projected pixel pattern may also address issues related to the high spatial harmonic content described above with respect to the signal S1. As shown in a signal S2 is illustrated beneath the projected pixel pattern PPP and the replicated projected pixel pattern RPP. The signal S2 will be understood to correspond to a portion of an output produced by image pixels due to the combination of the pixel patterns PPP and RPP and is shown to have a period PER2 with a width equal to approximately four columns of the projected pixel pattern PPP. The signal S2 is shown to have a finer spatial resolution than the signal S1 in that while the signal S1 was shown to vary over only three distinct signal levels the signal S2 is shown to vary over five distinct signal levels and in increments that are only as wide. This difference is due to the shifted location of the replicated projected pixel pattern RPP for which the energy indicated in the signal S1 may be considered to be split between the projected pixel pattern PPP and the replicated projected pixel pattern RPP in the implementation of . This results in a better distribution of the energy levels in the signal S2 as indicated by the higher resolution sine wave shape. This higher resolution sign wave corresponds to a lower spatial harmonic content which results in higher accuracies for the corresponding SIM Z height measurements that are produced.

As shown in in one specific example implementation the projector artifact suppression element PASE includes three layers L1 L2 and L3. As shown in outer surfaces S1 and S2 of the first and third layers L1 and L3 may be designated as the outer surfaces of the projector artifact suppression element PASE. In one specific example implementation the overall thickness of the projector artifact suppression element PASE may be approximately 2.2 mm. includes a table indicating other specific dimensions and properties for the layers L1 L2 and L3 of the implementation . As shown in all of the layers L1 L3 are indicated as being made of quartz. The first layer is indicated as having a thickness of 0.92 0.05 mm an orientation angle of 45 1 and a rotation angle of 0 1 . The second layer L2 is indicated as having a thickness of 0.65 0.05 mm an orientation angle of 45 1 and a rotation angle of 45 1 . The third layer L3 is indicated as having a thickness of 0.65 0.05 mm an orientation angle of 45 1 and a rotation angle of 45 1 . In one implementation the second and third layers L2 and L3 may consist of birefringent material. The first layer L1 may thus cause a first split in a first direction in incoming light rays with the second and third layers L2 and L3 causing a second split in a second direction in the light rays e.g. in total effect splitting an original light ray OLR into the four light rays R11 R21 R12 and R22. The dimensions in the example above are exemplary only and not limiting. More generally in various other embodiments the thicknesses of the various birefringent layers may be on the order of 100 micrometers to 1 millimeter or more.

As shown in in one implementation the four light rays R11 R21 R12 and R22 that are produced by the projector artifact suppression element PASE are approximately evenly separated along the X and Y axes. The offset along the X axis e.g. between the light rays R11 and R21 and between the light rays R12 and R22 is represented as an X direction desired suppression element shift DSESx. Similarly the offset along the Y axis i.e. between the light rays R11 and R12 and between the light rays R21 and R22 is represented as a Y direction desired suppression element shift DSESy. In one specific example implementation DSESx DSESy 5.4 microns.

In general the selection of a range or in which to locate the projector artifact suppression element PASE may be determined in accordance with various tradeoffs associated with certain design factors. For example in certain implementations it may be beneficial to locate the projector artifact suppression element in a region where the light rays are collimated e.g. where fewer aberrations may result . It may also be beneficial for the projector artifact suppression element to be located in the projection path before demagnification is performed e.g. resulting in relatively less complex and inexpensive fabrication . In certain implementations such benefits may be mutually exclusive and or unable to be obtained in a single location.

For example in one implementation for the first range the light is not collimated however the focal ratio may be relatively large such that the calculated effect on spherical aberration and astigmatism may be relatively low and placement in this range may result in relatively less complex and inexpensive fabrication. With regard to the range the light rays are converging and diverging i.e. are not collimated and it may be desirable to place the projector artifact suppression element somewhere near but not coincident with the intermediate image plane IMA1. Placing the projector artifact suppression element near the intermediate image plane IMA1 allows the size of the glass to be minimized e.g. to reduce tolerance requirements flatness etc. but also requires that the placement be distant enough so that no ghost reflections become present in the projected pattern. These requirements may make the fabrication relatively more expensive and complex for a placement in this range . In the third range the light may be collimated and may not impart aberrations but may require relatively expensive elements to achieve a desired separation distance and fabrication. In one specific example implementation the thicknesses of the birefringent layers may be on the order of 150 250 microns in thickness thus requiring super thin quartz layers. Regardless of these tradeoffs any of the ranges or may be utilized with the selection generally depending on a balance between reducing the complexity and expense of the fabrication and increasing the desired level of accuracy for the system.

In general other aspects of the design of the structured illumination pattern generator of will be understood in the context of the following discussion. As described above with respect to the signals S1 and S2 of the sinusoidal fringes of the system are created with a digital SLM device and some higher harmonics of the fundamental sinusoidal frequency may be transferred by the optics through to the final image in each scan step of the stack. As noted above the resulting height maps may contain these higher harmonic artifacts as ripples . In addition as also described above the SLM and resulting projected pixel pattern have gaps between each pixel and the gap pitch can beat at two different values relative to the imaging pixel array pitch each causing respective Z height error ripples .

In contrast to the techniques described above with respect to where a projector artifact suppression element is utilized to address such issues an alternative approach for optically filtering resulting ripples such as those described above would be to reduce the projection side numerical aperture NA appreciably. However in certain implementations this approach would have negative implications for aspects such as the selection of the SLM resolution e.g. higher fringe frequencies telecentricity e.g. finite pupil distances collection lens complexity e.g. higher field angles and throughput e.g. lower illumination . Another possible alternative approach would be to utilize a higher resolution SLM e.g. a high definition system where more pixels are utilized to create the sine pattern . However in certain implementations various drawbacks of such an approach could include the higher field angles would require higher quality projection optics e.g. at higher cost the SLM would be correspondingly more expensive to produce and such a configuration would not address the above described effects of the mismatch of SLM pixel pitch and gap against the imaging pixel pitch. Another alternative approach that has been used in some applications is defocusing the projected pattern. However in applications where a stack of SIM images are acquired by scanning through a focus range to determine a 3 D surface topography this is not a practical approach. Another alternative approach that could be utilized would involve fabricating fixed chrome on glass fringe patterns that are free of gap artifacts and or provide sine waves with lower spatial harmonic content. However in certain implementations various drawbacks of such an approach could include the orientation and or pattern size of the fixed pattern cannot be adjusted or optimized for particular workpieces and or objective lenses or magnifications or the like. Furthermore sine wave pattern masks with sufficiently low spatial harmonic content may be expensive to fabricate.

In contrast to all of the above described alternative approaches it will be appreciated that the techniques described above with respect to including the utilization of a projector artifact suppression element may provide better results including less expensive fabrication and higher accuracy measurements. In particular the above described techniques utilizing the projector artifact suppression element achieve various advantages by not substantially altering the numerical aperture NA that would otherwise be provided by the set of projection optical elements of the SIM system. That is the projection optics utilizing the projector artifact suppression element are able to reduce the modulation transfer function i.e. decrease the spatial harmonic content without reducing the numerical aperture so as to maintain good optical sectioning capability and throughput and to allow for fringe frequencies that are compatible with an intermediate format SLM.

At block a set of imaging optical elements are utilized to receive structured illumination pattern workpiece light that results from the structured illumination pattern source light having been reflected by or transmitted through a workpiece. In various implementations the set of imaging optical elements comprises an objective lens that inputs the structured illumination pattern workpiece light from the workpiece. At block the set of imaging optical elements are utilized to image the structured illumination pattern workpiece light along the imaging path toward an imaging sensor. In various implementations the imaging sensor comprises an imaging pixel array.

The various embodiments described above can be combined to provide further embodiments. All of the U.S. patents and U.S. patent applications referred to in this specification are incorporated herein by reference in their entirety. Aspects of the embodiments can be modified if necessary to employ concepts of the various patents and applications to provide yet further embodiments.

Although the embodiments described above have emphasized the utility of a projector artifact suppression element in combination with a pattern generating element that comprises a controllable spatial light modulator which may be controlled to alter or reconfigure a structured light pattern it should be appreciated that a projector artifact suppression element according to principles disclosed herein may also provide benefits and advantages outlined herein when used in combination with a fixed pattern generating element such as a reflective or transmissive mask. For example inaccuracies due to certain fabrication errors or limited spatial resolution and or low sine wave gray level resolution or the like may be reduced.

These and other changes can be made to the embodiments in light of the above detailed description. In general in the following claims the terms used should not be construed to limit the claims to the specific embodiments disclosed in the specification and the claims but should be construed to include all possible embodiments along with the full scope of equivalents to which such claims are entitled.

