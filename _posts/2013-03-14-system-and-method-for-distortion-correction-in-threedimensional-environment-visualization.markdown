---

title: System and method for distortion correction in three-dimensional environment visualization
abstract: A method for graphics in a three-dimensional virtual environment corresponding to a physical environment around a vehicle includes photographs in a plurality of directions extending outward from the vehicle, generating sensor data corresponding to a relative distance from the vehicle and a direction from the vehicle of an object in the physical environment, generating a default three-dimensional projection surface centered around a virtual representation of the vehicle in a virtual environment, deforming the three-dimensional projection surface at relative locations and distances corresponding to the sensor data, projecting the plurality of photographs onto the deformed three-dimensional projection surface, and displaying graphics corresponding to the deformed three-dimensional projection surface with the plurality of projected photographs with a display device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08892358&OS=08892358&RS=08892358
owner: Robert Bosch GmbH
number: 08892358
owner_city: Stuttgart
owner_country: DE
publication_date: 20130314
---
This disclosure relates generally to the field of computer graphics and more specifically to systems and methods that display three dimensional graphics.

Many modern software applications display three dimensional representations of graphical objects and scenes as part of a user interface. Three dimensional 3D graphics are used in a wide range of applications including video games simulations virtual reality applications geospatial information applications and applications for mapping and navigation. In many applications 3D graphics are more useful than two dimensional 2D graphics at depicting real world environments and locations because the normal interaction between humans and the real world occurs in three dimensions.

In one form of 3D graphics different objects in a scene are formed from a large number of polygons. The polygons form shapes and structures in a 3D scene. Since most computing devices only display graphics with a two dimensional display the 3D graphics are converted into a rasterized array of two dimensional pixels for display. The 2D display depicts portions of the three dimensional scene in a manner similar to a camera taking a two dimensional photograph of 3D scenes in the real world. Many 3D graphics systems and application programming interfaces APIs including the Open Graphics Library OpenGL and the Direct 3D APIs provide common structures and interfaces to specialized graphics hardware for generation of 3D images in an efficient manner. The 3D software interacts with general purpose and specialized digital computing hardware that generates the 3D graphics in an efficient manner. In particular graphical processing units GPUs are hardware components that are configured to generate polygons and other graphical effects that form a 3D scene. Modern computing devices typically execute software with a combination of instructions for a central processing unit CPU and a GPU to generate the 3D scene and enable interaction with the 3D scene in some software applications. In some hardware embodiments the functionality of the CPU and GPU are merged together physically and optionally logically into a single a system on a chip SoC device.

As the computational power and sophistication of digital computing hardware and software have increased the use of 3D graphics has expanded to a wide range of applications. For example many motor vehicles include in vehicle information systems with computer systems that include the hardware and software systems for the display of 3D graphics. Modern motor vehicles often include one or more cameras and video display devices that display video of the environment surrounding the vehicle for assisting the vehicle operator in driving and parking the vehicle. While existing systems typically show video from a single camera with a two dimensional view of the environment outside the vehicle a 3D graphics implementation composites multiple photographs from one or more cameras in the vehicle to generate a 3D view of the environment around the vehicle. The 3D graphics view can include animation of the environment around the vehicle as the vehicle moves and as objects in the field of view of the cameras move. One challenge in generating a 3D environment is that the composition of 2D pictures from the cameras often results in an inaccurate rendering of the 3D environment. For example if the vehicle is parking next to a mailbox on a side of a street the mailbox is much closer to the vehicle than surrounding buildings or other features in the environment. The depiction of the 3D environment however projects both the mailbox and all other features onto a uniform 3D surface such as a fishbowl hemispherical surface. The resulting 3D images include the objects in the photographs but the 3D scenes do not provide realistic depth perception of objects surrounding the vehicle to the vehicle operator. Consequently improvements to in vehicle information systems that enable more realistic 3D representations of physical environments around the vehicle would be beneficial.

In one embodiment a method for displaying a virtual environment corresponding to a physical environment around a vehicle has been developed. The method includes generating data corresponding to a plurality of photographs of the physical environment surrounding the vehicle taken in a plurality of directions extending outward from the vehicle generating sensor data corresponding to a relative distance from the vehicle and a direction from the vehicle of an object in the physical environment generating a default three dimensional projection surface centered around a virtual representation of the vehicle in a virtual environment deforming the three dimensional projection surface at a location in the virtual environment corresponding to the object in the sensor data projecting the plurality of photographs onto the deformed three dimensional projection surface and displaying graphics corresponding to the deformed three dimensional projection surface with the plurality of projected photographs with a display device.

In another embodiment a system that displays a virtual environment corresponding to a physical environment around a vehicle has been developed. The system includes a camera system configured to generate data corresponding to a plurality of photographs of the physical environment taken in a plurality of directions extending outward from the vehicle a sensor system configured to generate sensor data corresponding to a relative distance from the vehicle and direction from the vehicle of an object in the physical environment a display device and a processor operatively connected to the camera system the sensor system and the display device. The processor is configured to receive the data corresponding to the plurality of photographs generated by the camera system receive the sensor data corresponding to the shape relative distance from the vehicle and direction from the vehicle of the object generate a default three dimensional projection surface centered around a virtual representation of the vehicle in a virtual environment deform the three dimensional projection surface at relative locations and distances corresponding the sensor data project the plurality of photographs onto the deformed three dimensional projection surface and display graphics corresponding to the deformed three dimensional projection surface with the plurality of projected photographs with the display device.

For the purposes of promoting an understanding of the principles of the embodiments disclosed herein reference is now be made to the drawings and descriptions in the following written specification. No limitation to the scope of the subject matter is intended by the references. The present disclosure also includes any alterations and modifications to the illustrated embodiments and includes further applications of the principles of the disclosed embodiments as would normally occur to one skilled in the art to which this disclosure pertains.

As used herein the term object refers to any physical entity that is visible to one or more cameras in a vehicle for display using a display device in the vehicle. Objects include but are not limited to terrain features immobile bodies such as curbs mailboxes light posts and parking meters and mobile bodies including other vehicles pedestrians animals and the like. As used herein the term terrain feature refers to objects that are typically immobile and remain in place for an extended length of time. Terrain features include natural terrain such as hills valleys cliffs and the like. Terrain features also include normally immobile structures such as roads parking lots and buildings. In some embodiments predetermined map data include three dimensional models for terrain features. For example geographic databases store polygon model data corresponding to the sizes shapes and locations of terrain features in the physical world for display in mapping programs and other software applications.

As used herein the term proxy refers to predetermined polygon data and optionally color texture and lighting data that enable display of graphical depictions of physical objects. For example a proxy for a vehicle includes 3D model data for a graphical depiction of a physical vehicle that is displayed in a virtual environment to provide information about the location of the vehicle in relation to other objects in the environment around the vehicle to occupants of the vehicle. Other proxies include template polygon data that correspond to approximations of shapes for common objects that occur in the physical world. For example proxy template models include triangular and quadrilateral prisms cylinders pyramids spheroids ellipsoids and other polygon model data that approximate the shapes of objects in the physical world.

As used herein the term projection surface refers to an arrangement of polygons in a 3D virtual environment that form a surface for display of one or more photographs that are generated by cameras in the vehicle. In one embodiment the projection surface is a continuous mesh formed from polygons that form a curved surface such as a hemisphere that extends outward from a location corresponding to the cameras in the vehicle that generate the photographic data. During operation of an in vehicle information system a display device depicts all or a portion of the projection surface with photographs taken by the cameras arranged on the polygons of the projection surface. The two dimensional photograph data are projected into the 3D environment through the texturing process. As described below an in vehicle information system deforms the polygons in the projection surface to approximate the shapes of objects that are visible in the photographic data of the environment around the vehicle. The deformation of the 3D projection surface reduces distortion of the objects that are visible in the environment around the vehicle to provide occupants of the vehicle with a more realistic view of the 3D environment around the vehicle.

In the in vehicle information system the processor includes one or more integrated circuits that implement the functionality of a central processing unit CPU and graphics processing unit GPU . In some embodiments the processor is a system on a chip SoC that integrates the functionality of the CPU and GPU and optionally other components including the memory global positioning system and network device into a single integrated device. In one embodiment the CPU is a commercially available central processing device that implements an instruction set such as one of the x86 ARM Power or MIPs instruction set families. The GPU includes hardware and software for display of both 2D and 3D graphics. In one embodiment the CPU and GPU include hardware or software modules for processing photographic image data that are received from the in vehicle cameras . In one embodiment processor includes software drivers and hardware functionality in the GPU to generate 3D graphics using the OpenGL OpenGL ES or Direct3D graphics application programming interfaces APIs . For example the GPU includes one or more hardware units including geometry processing units pixel shader units vertex shader units fragment shader units texture units and image rasterization units for the generation of a rasterized 2D depiction of a 3D virtual environment. During operation the CPU and GPU execute stored programmed instructions that are retrieved from the memory . In one embodiment the stored programmed instructions include operating system software and one or more software application programs including a visualization program that enables occupants of the vehicle to view a 3D representation of objects around the vehicle that are visible to the in vehicle cameras .

The memory includes both non volatile memory and volatile memory. The non volatile memory includes solid state memories such as NAND flash memory magnetic and optical storage media or any other suitable data storage device that retains data when the in vehicle information system is deactivated or loses electrical power. The volatile memory includes static and dynamic random access memory RAM that stores software and data including graphics data and map feature data during operation of the in vehicle information system . In in vehicle information system the memory stores photographic texture data a 3D terrain feature objects data cache programmed instructions 3D projection surface geometry data 3D proxy template data a point cloud data history cache and 3D vehicle proxy data .

In the memory the photographic texture data include digital data corresponding to a plurality of photographs that the in vehicle cameras generate corresponding to the environment and objects around the vehicle . As described below the processor generates a mosaic from a plurality of individual photographs and projects the photographic images onto a deformed projection surface to generate a 3D graphical depiction of the environment around the vehicle.

The 3D terrain feature objects data cache stores polygon data corresponding to one or more terrain features in the environment around the vehicle . The terrain feature polygon models are stored in association with geographic coordinates for the corresponding terrain features. In one configuration the 3D terrain feature objects cache stores the polygon data for a plurality of terrain features in a large geographic region for use in multiple applications including mapping navigation and visualization applications. In another embodiment the in vehicle information system retrieves terrain feature model data from a larger online3D terrain feature geography database and the 3D terrain feature objects data cache stores the polygon model data for a comparatively small region around the vehicle . Examples of online terrain feature databases include online mapping and navigation services that present 3D geography and building data to the in vehicle information system using for example an HTML or XML based data format. The processor is configured to use the 3D terrain feature object data models to deform a projection surface for the environment around the vehicle to reflect the terrain features around the vehicle accurately.

The 3D proxy template data include polygon models corresponding to a range of generic shapes for objects that are commonly depicted in the photographic data from the in vehicle cameras . For example the 3D template model data include polygon models having many basic geometric volume shapes such as rectangular prisms cylinders cones pyramids spheroids ellipsoids and the like. The processor uses the 3D proxy templates data to deform the projection surface using the predetermined 3D proxy template polygon models instead of more complex shapes that are formed using range data generated by the range sensors .

In the memory the stored point cloud data cache holds a plurality of point clouds that the range sensors generated during earlier operation of the in vehicle information system . The in vehicle information system retains cached point cloud data for a predetermined length of time or invalidates the data when the vehicle moves by more than a predetermined distance if the vehicle drives to a new location instead of moving around a small area such as a parking space. In one embodiment the processor compares the point cloud for the identified object to the point cloud data that are stored in the memory beginning with the stored data for point clouds that were most recently identified. Each set of point cloud data in the point cloud data cache is stored in association with one of the 3D proxy templates in the memory . During operation the processor uses the associated 3D proxy template to deform the projection surface at a location corresponding to the identified point cloud data.

In the memory the 3D vehicle proxy data correspond to a polygon model and other associated graphical data that enable the in vehicle information system to generate a 3D graphical depiction of the vehicle in a virtual environment. The 3D vehicle proxy data enable the in vehicle information system to display graphics corresponding to the vehicle in relation to the locations of objects that are visible in the photographic data from the in vehicle cameras .

The in vehicle information system includes one or more display devices . In one embodiment the display device is a liquid crystal display LCD organic light emitting diode display OLED or other suitable display device that generates image output for the vehicle occupants. Displays are commonly mounted in a dashboard or other fixed location in the vehicle. In an alternative embodiment the display device is a head up display HUD that is projected onto a windshield of a vehicle or projected onto goggles or glasses that are worn by an occupant in the vehicle. In an embodiment where the in vehicle information system is a handheld mobile electronic device the display is typically an LCD or organic LED OLED flat panel display that is housed in the mobile electronic device.

In the in vehicle information system the global positioning system GPS identifies a location of the vehicle for use in navigation applications. In one embodiment the GPS includes a radio receiver that receives signals from orbiting navigation satellites. Commercially available satellite GPS receivers are integrated in some in vehicle information systems and many mobile electronic devices include satellite GPS receivers as well. In an alternative embodiment the global positioning system receives signals from terrestrial transmitters including WWAN and WLAN transmitters. The global positioning system identifies a location of the vehicle using triangulation or other geolocation techniques. Some embodiments include receivers for both satellite GPS and terrestrial signals. In some embodiments the global positioning system further includes an inertial navigation system that assists in identifying the location of the vehicle if signals from the satellite or terrestrial transmitters are unavailable. Additionally a compass or other orientation finding device that is integrated with the GPS enables the processor to identify the orientation of the vehicle such as whether the vehicle is pointing in a northerly southerly eastwardly or westwardly direction. During operation the processor receives data from the GPS to identify a geographic location of the vehicle . The processor selects a portion of the virtual environment and structures in the virtual environment that correspond to the identified geographic location of the vehicle for display during a navigation operation.

In the embodiment of the processor sends and receives data using the network device . In a vehicle the network device is often a wireless network device such as a wireless wide area network WWAN device which communicates with radio transceivers in a cellular or other wide area data network while the vehicle is in motion. The network device optionally includes a wireless local area network WLAN device for communication with shorter range wireless local area networks. Examples of WLAN devices include the IEEE 802.11 family of protocols and Bluetooth protocols. In some embodiments the network device includes a wired network connection such as Ethernet or USB for use when the vehicle is parked or for interfacing with another computing device in the compartment of the vehicle. In the in vehicle information system the processor optionally retrieves 3D terrain feature model data from the online 3D terrain feature geography database through a wireless data network .

The cameras include one or more digital camera devices that generate photographic image data of the environment around the vehicle . An in vehicle camera refers to a camera that is placed on the vehicle in a position that provides a view of at least a portion of the environment outside the vehicle. Common configurations of in vehicle cameras including roof mounted cameras and cameras that are mounted on other external locations of the vehicle including near the sides and bumpers of the vehicle. The cameras include but are not limited to color monochrome low light and infrared cameras that generate image data of the environment around the vehicle in a wide range of lighting conditions. In one configuration the cameras are arranged around the vehicle in substantially fixed positions to generate a mosaic of multiple photographs. The processor merges the mosaic photographs to generate panoramic photographic image data of at least a portion of the environment around the vehicle including objects that the vehicle could contact during operation. In another configuration an in vehicle camera is operatively connected to one or more actuators that pan tilt and optionally translate the camera along a predetermined path to generate the multiple photographic images of the environment around the vehicle . Still another configuration includes a combination of fixed cameras and moveable digital cameras to generate the photographic image data of the environment around the vehicle . The processor stores the mosaic photographic data in the memory as photographic texture data . As described below the GPU projects the photographic texture data onto a deformed projection surface in a virtual environment to form a visual representation of the environment around the vehicle .

The in vehicle information system is operatively connected to one or more range sensors . The range sensors include one or more active and passive range finding devices. Some embodiments of active range finding sensors include but are not limited to RADAR including millimeter wave RADAR light detection and ranging LIDAR ultrasonic range sensing devices and the like. As is known in the art RADAR sensors emit radio waves with many short range RADAR systems using radio waves in the millimeter wavelength range. LIDAR sensors emit light beams. The light beams are optionally coherent light beams which are also referred to as laser light. Ultrasonic sensors emit sound waves at ultrasonic frequencies that are above the hearing range of most humans. Each of the active range finding sensors described above generates a transmission signal such as radio waves laser light beams or ultrasonic waves and identifies the range to an object with reference to an amount of time that is taken to receive a corresponding return signal that is reflected from the object when the transmission signal reaches the object. In one configuration of the in vehicle information system the active range sensors are configured to rotate and pan to sweep the environment around the vehicle in the same regions where the cameras generate digital photographic data. In one embodiment one or more actuators move one or more of the range sensors to sweep the environment. In another embodiment a phased array transmitter steers transmission signals from the range finding device electronically without requiring a mechanical actuator. In still another embodiment a large number of fixed position range sensors arranged around the vehicle generate range data with sufficient resolution to enable the in vehicle information system to identify the location and approximate shape of objects in the environment around the vehicle .

Other embodiments of the range finding sensors include passive range finding sensors such as stereoscopic cameras which are also referred to as depth cameras. In another passive range finding configuration the range finding cameras are positioned in a non stereoscopic arrangement but the processor operates the cameras while the vehicle is in motion. The processor identifies the speed of the vehicle using for example a speedometer or the GPS to identify a distance that the vehicle moves between the times when two successive sets of photographic data that are generated by the cameras . The processor identifies the range to different objects in the environment around the vehicle using the two sets of photographic data in the same manner as two sets of images that are generated by a stereoscopic camera with a predetermined offset between the lenses in the stereoscopic cameras.

Using either passive or active sensors the in vehicle information system typically receives the range data corresponding to objects in the environment around the vehicle as a point cloud. As used herein the term point cloud refers to a plurality of locations in a 3D space centered around the range finding sensor where a small portion of an object is detected. In one embodiment the location of each point is identified with a set of 3D coordinate data using for example a Cartesian coordinate system with x y z coordinates corresponding to a relative width height and depth respectively of the location from the vehicle . In alternative embodiments the coordinates are stored using spherical coordinates cylindrical coordinates or any other 3D coordinate system that is known to the art. For example using a LIDAR range sensor a brief transmission from a laser in the LIDAR sensor reflects from a small portion of the surface of an object in the environment around the vehicle . The processor identifies a relative orientation of the LIDAR range sensor during the transmission of the laser light and identifies a relative direction and distance of the portion of the object from the LIDAR range sensor with reference to the orientation of the sensor predetermined location of the sensor on the vehicle and identified range to the object. The processor converts the identified range and orientation data to 3D coordinates in a virtual environment around the vehicle . In an embodiment where the range sensors include passive range finding cameras the processor identifies corresponding pixel locations in the photographic image data from multiple images and identifies the range to a small portion of the object using for example triangulation between the first and second images. The processor identifies multiple corresponding pixels between the multiple sets of image data to form the point cloud coordinates using passive range sensors.

The in vehicle information system generates a large number of points in various locations throughout the environment around the vehicle to identify the distance and approximate shape of objects in the environment around the vehicle . In some instances objects that are visible to the cameras are located beyond an effective range of the range finding sensors . For example the cameras may photograph a distant hill that is beyond the effective detection range of the range finding sensors . As described below objects that are beyond the range of the range finding sensors are either projected onto a default 3D polygon surface object that represents the environment around the vehicle or additional terrain feature data can be used to distort the default 3D surface object to conform to the shape of the distant terrain features.

In the illustrative embodiment of process begins with generation of a 3D projection surface around a graphical representation of the vehicle block . In the in vehicle information system the memory stores 3D projection surface geometry data corresponding to a default projection surface that is generated around a 3D proxy model of the vehicle . In one embodiment the 3D projection surface is an inverted hemisphere with the apex of the inverted hemisphere representing a location of the vehicle. In other embodiments the default projection surface is generated as a sphere semi ellipsoid rectangular prism cylinder or other projection surface that is suitable for use in displaying photographic images generated by the in vehicle cameras . The memory also stores the 3D vehicle proxy data which include geometry color texture and lighting data to enable the GPU to generate a graphical depiction of the vehicle in the 3D virtual environment. depicts an illustrative view of a hemispherical projection surface and a vehicle proxy model .

Process continues as the in vehicle information system generates photographic data of the environment around the vehicle including both mobile and immobile objects and terrain feature objects using the in vehicle cameras block . The photographic data typically include either multiple photographs that are generated by multiple cameras that are arranged around the vehicle or multiple photographs from a single camera that is operatively connected to one or more actuators to generate photographs in different directions from the vehicle .

As described above the processor is configured to merge multiple photographs to form a mosaic of photographic data for a continuous view of at least a portion of the environment around the vehicle . For example in one embodiment the cameras are located in predetermined positions around the vehicle with some degree of overlap between the fields of view for neighboring cameras. Each camera generates photographic image data including a rectangular array of pixels. The processor identifies predetermined pixel coordinates in two photographic images in the region of overlap between the digital cameras that generated the respective photographic images and combines the non overlapping portions of the two photographic images into a larger photographic image. The processor continues merging photographic image data for multiple photographs to form a panoramic image. In embodiments where a single camera generates multiple images the processor operates the camera actuators to move the camera to predetermined positions with overlap between the field of view for the camera between successive positions and generates the mosaic image for the overlapping images in a similar manner. In some vehicle embodiments the mosaic image corresponds to a 360 region around the front back and sides of the vehicle including a vertical field of view that includes bumpers and other portions of the vehicle that may come onto contact with external objects as the vehicle moves. In another embodiment the cameras include fields of view covering only a portion of the environment around the vehicle such as a 180 region behind the vehicle and the mosaic image corresponds to the limited region in the fields of view of the cameras.

During process the in vehicle information system generates range data corresponding to objects around the vehicle before during or after the generation of the photographic data of the objects around the vehicle block . In the in vehicle information system the depth sensors generate range data for multiple objects that are within the fields of view of the cameras . As described above the processor generates a point cloud corresponding to objects in the environment around the vehicle with reference to the data received from the sensors. depicts an illustrative point cloud in a virtual environment around the vehicle . In the virtual environment includes a 3D projection surface which is formed in the inverted hemispherical shape with an apex of the inverted hemisphere projection surface corresponding to a location of the vehicle omitted for clarity . In the processor identifies a point cloud including a plurality of points such as points and which correspond to portions of an object in the physical environment around the vehicle . As depicted in the data point in the point cloud is located within the inverted hemisphere polygon mesh of the projection surface while the data point is located outside the inverted hemisphere polygon mesh of the projection surface . The points in the point cloud form an approximation of the size and shape of an object in the physical environment around the vehicle as detected by the depth sensors. As described in more detail below during process the processor deforms the shape of the projection surface to enable the generation of a 3D graphical depiction of the object corresponding to the point cloud with reduced distortion to the shape of the object.

Referring again to the process of the in vehicle information system optionally identifies objects only with reference to the data from the range sensors without using a location service to identify terrain feature objects around the vehicle block and the process continues with the processing described below with reference to block . In another configuration the in vehicle information system is configured to receive additional data corresponding to terrain features that are stored in a terrain feature database and are accessed with reference to an identified geographical location of the vehicle block . In the in vehicle information system the GPS device receives signals from multiple external transmitters including satellite transmitters terrestrial transmitters or both to identify geographical coordinates for the vehicle block . The processor retrieves polygon geometry data that correspond to one or more terrain feature objects in the environment around the vehicle in a terrain feature database.

During process the processor uses the identified geographic coordinates from the GPS to retrieve the polygon data for terrain features that are near the vehicle block . In one embodiment of the in vehicle information system the processor retrieves the geometry data for the identified terrain features from the 3D terrain features objects data cache . Some in vehicle information system embodiments include mapping software applications that store 3D terrain feature data in the memory for use in displaying maps and providing navigation information. In another embodiment of the in vehicle information system the online geography database stores 3D terrain feature model data and the processor generates a query for the database using the geographic coordinates for the vehicle that are received from the GPS . The 3D terrain feature geography database retrieves 3D model data for terrain feature objects around the location of the vehicle and the in vehicle information system receives the 3D terrain feature object data through the data network using the network device . The processor optionally stores the 3D terrain feature data from the database in the 3D terrain features cache for temporary use while the vehicle remains within a geographic region that includes the identified terrain feature objects and corresponding terrain feature object data.

Referring again to process continues with deformation of the projection surface to conform to objects in the environment around the vehicle block . The data corresponding to objects include point clouds that are identified for objects using the ranging sensors and optionally geometry data for the terrain features that are located in the environment around the vehicle . In an embodiment where the in vehicle information system retrieves terrain feature model data corresponding to terrain feature objects around the vehicle the processor deforms the projection surface to conform to the polygon models of the terrain features. For example depicts a projection surface that extends from a location of a vehicle proxy model in a 3D virtual environment. The polygon corresponds to a terrain feature in the physical environment around the building. The processor translates vertices in the polygons of the projection surface onto the surface of the polygon to deform the projection surface . depicts the deformed projection surface with a portion of the vertices in the polygons that form the projection surface translated to conform to the surface of the terrain feature model polygon .

In addition to deforming the projection surface to conform to the terrain feature models the processor deforms the projection surface to approximate the surface shapes of objects in the environment around the vehicle that the in vehicle information system identifies from the point cloud data received from the range sensors . During process different configurations of the in vehicle information system perform two different processes to deform the projection surface from the default shape to a shape that approximates the surfaces of the identified objects in the environment around the vehicle . One process deforms the projection surface using an optimization method based on the point cloud data. Another process identifies a predetermined 3D proxy template model corresponding to the point cloud data and deforms the projection surface to conform to the 3D proxy template model. The optimization and template deformation processes are described below with reference to and respectively.

During process the in vehicle information system identifies a group of points in a point cloud that correspond to an object in the environment around the vehicle block . In one embodiment the point cloud includes all range points that are generated in the environment around the vehicle. The point cloud data may correspond to one or more objects that are proximate to the vehicle and the in vehicle information system deforms one or more regions of the projection surface with reference to the entire point cloud. In another embodiment the processor identifies groups of points in the point cloud data that correspond to an individual object using for example a K means clustering algorithm or another clustering algorithm edge detection algorithms and other classification algorithms that are known to the art.

The identified points in the point cloud that correspond to the object approximate the shapes and sizes of the object as viewed from the vehicle but the individual locations in the point cloud are not always reliable indicators of the overall shape of the object. For example the ranging sensors are susceptible to returning incorrect range data for some points in the data point cloud due to noise in the environment around the vehicle or to noise in the ranging sensors hardware. For example dust or other contaminants in the atmosphere around the vehicle can generate false range results for some data points in the point cloud. Additionally the individual range data points that are generated by the range sensors are often of insufficient resolution to generate a highly accurate shape corresponding to the surface of the identified object.

During process the processor applies a minimal energy optimization process with a smoothness constraint to deform vertices in the projection surface into a surface shape that approximates the surface of the object in the identified point cloud data block . As described above the point cloud data are typically of insufficient accuracy and resolution to deform the projection surface to the individual point cloud coordinates. Instead the processor applies a minimum energy optimization process to deform some of the vertices in the polygons of the projection surface to form a deformed surface that approximates the shape of the point cloud coordinates while also maintaining a predetermined degree of smoothness. The minimum energy optimization process attempts to minimize the distance between the surface and the points in the point cloud where the distance between the projection surface and the points is modeled as energy and the optimization function attempts to minimize the energy. The optimization function also uses the predetermined smoothness factor as a constraint on the optimization process to prevent deformation of the projection surface into a jagged surface with discontinuities that are generated if the processor simply deforms the projection surface to intersect the coordinates of each point in the point cloud. During process the processor performs the process to deform the projection surface for one or more objects that are identified in the environment around the vehicle .

Referring to and the point cloud is displayed with the projection surface in prior to the deformation process . depicts another view of the point cloud after the processor deforms the projection surface to form the projection surface . The projection surface is deformed to correspond to the approximate shape of the coordinates formed by the points in the point cloud but the processor maintains a minimum surface smoothness for the deformed projection surface during the minimum energy optimization process. In the example of the processor deforms the projection surface by translating the locations of selected vertices in the polygon mesh that forms the projection surface . In another embodiment of the process the processor generates additional polygons or removes additional polygons in the polygon mesh that forms the projection surface during the optimization process. In some embodiments the processor also generates curves such as Bezier and B spline curves in the projection surface to maintain the smoothness of the deformed projection surface.

The smoothness constraint in the minimum energy operation also refers to smoothness of a surface deformation over time during operation of the in vehicle information system . For example in one embodiment the range sensors generate point clouds of range data several times every second and the cameras generate photographic data several times a second for video display of the environment around the vehicle . The processor performs the optimization process for deforming the projection surface to the point cloud data using the deformed projection surface that was generated from an earlier set of point cloud data to reduce the effects of random noise in the point cloud data and provide a stable display of objects in the environment around the vehicle. For example if the vehicle is stationary or moving at a low rate of speed then the projection surface corresponding to objects around the vehicle does not change by a large amount over a short length of time. The processor constrains the deformation of the projection surface to limit the changes that are made to the previously generated deformation surface to reduce the effects of transient noise in the point cloud data during the optimization process.

During process the in vehicle information system identifies a group of points in a point cloud that correspond to an object in the environment around the vehicle block . The in vehicle information system identifies the object in the virtual environment in process in the same manner as the processing described above with reference to block of the process . Process continues by determining whether the identified point cloud data for the object have a sufficiently high similarity to stored point cloud data in the point cloud data history cache block . In one embodiment the processor searches the stored point cloud data beginning with the point cloud data that were most recently generated by the range sensors and stored in the memory to identify similar objects using temporal locality. In another embodiment the processor extracts one or more features from the 3D point cloud data and generates hashes corresponding to the extracted features. The processor stores the hashes in the point cloud history cache in association with the corresponding 3D proxy template data . The extracted features are more stable than individual point clouds and the processor extracts the same features from subsequently generated point cloud data from the range sensors . The processor then identifies the same hash value for the extracted features and retrieves the corresponding proxy template data for the point cloud data.

If the processor does not identify a stored point cloud data that exceeds the predetermined similarity threshold block then the processor performs a full search through the stored 3D proxy template data to identify one of the 3D proxy templates having the greatest similarity to the identified point cloud data block . The full search process includes a comparison between the point cloud and the polygon model data corresponding to the polygon data for the 3D proxy template models that are stored in the memory . In one embodiment the processor scales the sizes either or both of the point cloud data and the 3D proxy template model data to normalize the size between the point cloud data and the 3D proxy template model. The processor subsequently identifies a best fit process to identify an error between the locations of the data points in the point cloud and the surface of the 3D proxy template without modifying the relative locations of the data points in the point cloud. In a greedy search configuration for the full search the processor identifies one of the 3D proxy template models having the minimum error in comparison to the point cloud data after comparing each of the 3D proxy templates to the point cloud data. In a non greedy search configuration the processor identifies the first 3D proxy template model with an error that is below a predetermined error threshold in response to the comparison with the point cloud data.

If the processor identifies point cloud data in the point cloud data cache with a degree of similarity that exceeds the predetermined threshold block then the processor identifies the 3D proxy template that is already associated with the identified point cloud data in the memory block . In the in vehicle information system the memory stores the point cloud data history cache in association with the predetermined 3D proxy template data . The processor performs a lookup using the stored association to identify the 3D proxy template.

Process continues as the processor updates the point cloud history cache with the point cloud data for the identified object and the association between the point cloud data and the identified 3D proxy template data block . The processor stores the newly identified point cloud data and 3D proxy template association in the memory to enable more efficient identification of similar point clouds during continuing operation of the in vehicle information system . In one embodiment if the processor identifies that the newly identified point cloud data correspond to existing point cloud data that are stored in the point cloud data history cache then the processor replaces the previously stored point cloud data with the newly generated point cloud data.

Process continues with deformation of the projection surface to correspond to the identified 3D proxy template for the generated point cloud data block . During the deformation process the processor positions the 3D proxy template object at a location and with an orientation that corresponds to the point cloud data in the virtual environment around the vehicle . Because the 3D proxy template model is a regular polygon the processor translates one or more vertices in the polygons that form the projection surface onto the surface of the 3D proxy template to deform the projection surface. For example as depicted in and the point cloud in the virtual environment around the vehicle location has a form that corresponds to a cylinder 3D proxy template model . The processor translates selected vertices on the projection surface of to the surface of the cylinder to deform the projection surface into the deformed projection surface including a shape that corresponds to the identified 3D proxy cylinder for the point cloud data .

During the process different embodiments of the in vehicle information system use either or both of the processes and to deform the projection surface during the process . In one configuration the process typically generates deformations to the projection surface that more accurately reflect the shape of the object but requires a larger number of computations and potentially more time to perform the optimization process for the deformation. The process generates the deformations for the projection surface with fewer computations using the predetermined template polygon models but the surfaces of the predetermined template polygon models are not necessarily as accurate as the deformations that are generated using the optimization process .

Referring again to process continues as the processor projects the photographic image data onto the projection surface including portions of the projection surface that are deformed to correspond to objects in the environment around the vehicle block . In the in vehicle information system one or more texture units in the GPU project the photographic texture data onto the polygons in the deformed projection surface. The shape of the deformed projection surface corresponds to the identified objects that are proximate to the vehicle . The stored photographic texture data include the photographic representations of the objects and the GPU projects the photographs for the objects onto the corresponding deformed portions of the projection surface.

Process continues with generation of a visual depiction of at least a portion of the projection surface including a 3D proxy model corresponding to the vehicle on a display device in the vehicle block . In the in vehicle information system the processor generates a two dimensional depiction of a portion of the 3D virtual environment through the display device . In another embodiment the display device is a 3D display device including but not limited to a 3D display screen or a head mounted 3D display device. In the in vehicle information system the GPU retrieves the stored 3D vehicle proxy data to generate a graphical depiction of the vehicle in the virtual environment.

The display of the 3D proxy for the vehicle in the virtual environment aids the occupants of the vehicle in finding the distance between the vehicle and the objects in the environment around the vehicle and to identify the orientation of the vehicle relative to the other objects in the environment around the vehicle . For example in one mode of operation the operator of the vehicle views the display that the process generates to assist in parking the vehicle in proximity to other vehicles and objects around a parking space. Process enables the in vehicle information system to generate a visual depiction of the objects around the vehicle with greater accuracy to aid the vehicle operator in parking the vehicle in an appropriate manner.

It will be appreciated that variants of the above disclosed and other features and functions or alternatives thereof may be desirably combined into many other different systems applications or methods. Various presently unforeseen or unanticipated alternatives modifications variations or improvements may be subsequently made by those skilled in the art that are also intended to be encompassed by the following claims.

