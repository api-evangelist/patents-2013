---

title: System and method to maximize server resource utilization and performance of metadata operations
abstract: An MDS (metadata server) in a distributed storage system includes data servers (DSs) storing file contents and one or more MDSs performing metadata operations in response to metadata requests of different types, the MDS including a controller having a processor and a memory, the MDS storing file system metadata. The controller is configured to: classify the metadata operations into different categories, which include a normal category and one or more special categories different from the normal category, the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS; for each special category, partition each metadata operation into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS; and dynamically assign resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09197703&OS=09197703&RS=09197703
owner: HITACHI, LTD.
number: 09197703
owner_city: Tokyo
owner_country: JP
publication_date: 20130624
---
The present invention relates generally to storage systems and more particularly to system and method to maximize server resource utilization and performance of metadata operations.

Distributed file systems and parallel file systems involve a plurality of servers cooperating with each other in order to complete the processing of file system requests from clients.

In one consideration a parallel file system such as pNFS parallel network file system includes a plurality of Data Servers DSs to process read write requests while a dedicated Metadata Server MDS processes all metadata requests. A client first establishes connection to the MDS. Then it performs a file open operation on the interested file to obtain the location information such as IP address of the DS file identifier on the DS etc. After knowing the location information and the identifier the client sends read write requests directly to the DS. It is the MDS s responsibility to obtain file identifiers from all the DSs as part of the operations such as file open and file create. Hence for certain metadata operations there is a need for MDS to DS communication typically called the Control Path Protocol CPP . While processing such operations existing systems block the thread servicing an operation during the CPP procedure and hence the resources e.g. CPU memory etc. assigned to the thread cannot be utilized to service other operations. This leads to under utilization of MDS resources and thereby reduces the overall metadata access performance by a single MDS.

Although separating metadata and read write service capabilities to MDS and DS respectively greatly improves read write performance by providing high throughput parallel I O HPC applications and streaming applications leverage such architectures a typical HPC workload contains more than 50 of metadata operations. Hence MDS server performance is critical in improving overall file system performance as seen by the clients. Virtualized multiple metadata server cluster solutions have been proposed to provide distributed metadata service to increase overall metadata access performance. However even in such a solution each MDS is underutilized during CPP communication. Thus there is a need to provide a solution to effectively utilize MDS resources during CPP communication.

In another consideration multiple MDS solutions which provide global namespace and a virtualized view of MDSs need MDS to MDS communication for certain metadata requests such as directory create and directory listing. As an illustration in some multiple MDS solution where metadata distribution is at the directory level a create directory operation may need to create the directory at another MDS other than the one receiving the create directory request. During such MDS to MDS communication threads block as aforementioned and leads to underutilization of MDS resources.

Exemplary embodiments of the invention provide a solution to effectively utilize MDS resources for metadata operations requiring server to server communication including the aforementioned CPP communication and MDS to MDS communication. In general a solution which can improve metadata server resource utilization during any server to server communication is desired. Specific embodiments are directed to a method to maximize server resource utilization and performance of metadata operations by classifying the metadata operation into different categories normal category and plurality of special categories and partitioning the metadata server program into a plurality of stages for special categories of metadata operations and dynamically assigning resources to each of the partitioned stage based on the monitored client workload of various metadata request categories.

Existing solutions can be classified into two categories. The first approach is to reduce the server to server traffic and the second approach is to maximize utilization of server resources by resource management strategies.

In the first approach the server to server traffic is avoided for metadata operations by either a prefetching technique or by a caching technique. US2010 0161585 uses a prefetching technique to reduce MDS to DS CPP communication during file creation. In this technique data server resources are created and all resource information required to identify the file are pre fetched and stored in the MDS. When the client requests for file creation the MDS uses one of the pre allocated data server resources and maps that resource to the requested file creation. This avoids the CPP communication during file creation and hence improves file creation performance. However such a technique only caters to file creation performance but MDS resources are underutilized during other metadata operations involving CPP communication such as file open file close file remove etc. U.S. Pat. No. 7 827 192 uses a caching technique to reduce CPP communication. For metadata operations requiring CPP communication the MDS uses the cached data server resource information and avoids the actual CPP communication. However such techniques are only suitable for read only metadata operations but cannot solve underutilization problem during update or create metadata operations. Similar caching techniques have been proposed to reduce other server to server traffic such as MDS to MDS but they only improve performance for read only requests.

Using the second approach the metadata resources are utilized efficiently by using resource management techniques using information collected by monitoring current resource utilization and or client workload. U.S. Pat. No. 8 091 089 monitors resource utilization of multiple instances of metadata server programs running on a single machine and manages resource allocation among those instances efficiently. For example if one instance of metadata server program is underutilizing its resources the resource management program de allocates underutilized resources and assigns it to other instances of metadata server program which are using their currently assigned resources to the limit. U.S. Pat. No. 8 145 759 performs similar resource management technique to effectively assign resources to different applications running on the server. In this technique the number of client requests to each server application is monitored. Upon receiving a configuration change request for an application the resource management program increases or decreases server resources dedicated to that application based on the current assignment current number of client requests and new resource limit. Such resource management techniques effectively reduce underutilization of server resources by dynamically managing resources across different instances of the program. However they do not consider different categories of client requests for the same server program and do not allocate resources to different stages of the same server program which is critical to solve the identified problem because processing time for different metadata operations vary significantly due to server to server communication required for some of those operations .

This invention can be used to design metadata servers to improve maximize MDS resources utilization and thereby increasing metadata access performance. In specific examples the invention can be used to design metadata servers on dedicated physical machine such as those in asymmetric architecture e.g. pNFS or to design metadata server program on symmetric distributed file system and symmetric clusters.

An aspect of the present invention is directed to an MDS metadata server in a distributed storage system which includes a plurality of data servers DSs storing file contents and one or more MDSs performing a plurality of metadata operations in response to metadata requests of different types the MDS including a controller having a processor and a memory the MDS storing file system metadata. The controller is configured to classify the metadata operations into different categories which include a normal category and one or more special categories which are different from the normal category the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS for each of the one or more special categories partition each of the metadata operations into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS and dynamically assign resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.

In some embodiments the classifying comprises classifying the metadata operations into different categories based on type and amount of processing required for each category. The one or more special categories of metadata operations comprise at least one of i a first special category of metadata operations that require communication between the MDS and one or more of the plurality of DSs or ii a second special category of metadata operations that require communication between the MDS and one or more other MDSs. The stages for the first special category of metadata operations comprise the primary stage and a pNFS manager stage for performing pNFS related metadata management including preparing requests to be sent to the DSs an MDS DS asynchronous client stage for sending asynchronous requests to the DSs an asynchronous DS processing stage which is performed on the DSs for processing asynchronous requests from the MDS and sending a response back to the MDS after processing completes a DS response aggregator stage for receiving responses from the DSs and aggregating all the received responses to a single context representing a corresponding metadata operation and a secondary metadata processor stage for post processing on the MDS. The stages for the second special category of metadata operations comprise the primary stage and an MDSC manager stage for performing MDS cluster management including preparing requests to be sent to the one or more other MDSs an inter MDS asynchronous client stage for sending asynchronous requests to the one or more other MDSs an asynchronous inter MDS processing stage which is performed on the one or more other MDSs an MDS response aggregator stage for receiving responses from the plurality of MDSs and aggregating all the received responses to a single context representing a corresponding metadata operation a secondary metadata processor for post processing on the MDS.

In specific embodiments the partitioning comprises partitioning each metadata operation into a plurality of stages each of which i involves communication with a component external to the MDS or ii involves a processing logic that is modularly different from its preceding processing logic and its succeeding processing logic. A stage which involves communication with a component external to the MDS has a processing logic that treats the external component with which the stage of the metadata operation communicates as an asynchronous server component.

In some embodiments the dynamically assigning resources comprises monitoring metadata workload of the normal category and the one or more special categories to obtain a number of metadata operations for each category and a total number of metadata operations for all categories calculating for each special category a ratio of the number of metadata operations for said each special category to the total number of metadata operations for all categories obtained from the monitoring calculating a processing time for each of the normal category and the one or more special categories and allocating a plurality of threads representing units of execution across all the stages by considering i an estimated processing time for each stage ii the calculated ratio for each special category iii the calculated processing time for each category and iv a total number of threads allocated to the MDS. The threads allocated to a particular special category are assigned to each stage involved in the particular special category in the ratio of the estimated processing time of each stage relative to the processing time of all the stages of the particular special category.

In specific embodiments the controller is configured to identify from the one or more special categories of metadata operations one or more candidate metadata operations to be executed in batch mode. The one or more candidate metadata operations each i has a potential to be batched together in a single network call to perform similar metadata operations speculatively or ii has a potential to be locally completed asynchronously within the MDS and at a later point in time to be batched together with similar metadata operations to complete inter server processing between the MDS and one or more external components.

In some embodiments the controller is configured i when the one or more candidate metadata operations each has a potential to be batched together in a single network call to perform similar metadata operations speculatively to identify data structures required to be stored in the memory of the MDS in order to perform a batch operation to speculatively fetch information from the external component or ii when the one or more candidate metadata operations each has a potential to be locally completed asynchronously within the MDS and at a later point in time to be batched together with similar metadata operations to complete inter server processing between the MDS and one or more external components to identify a data consistency protocol for batch mode execution involving asynchronous processing.

In specific embodiments the controller is configured to count a total number of each candidate metadata operation to be executed in batch mode based on monitoring the metadata workload and when the total number of a particular candidate metadata operation exceeds a preset threshold for the particular candidate metadata operation select the particular candidate metadata operation to be executed in batch mode. The dynamically assigning resources comprises monitoring metadata workload of the normal category and the one or more special categories to obtain a number of metadata operations for each category and a total number of metadata operations for all categories calculating for each special category a ratio of the number of metadata operations for said each special category minus a number of metadata operations for said each special category which have been selected to be executed in batch mode to the total number of metadata operations for all categories obtained from the monitoring calculating a processing time for each of the normal category and the one or more special categories and allocating a plurality of threads representing units of execution across all the stages by considering i an estimated processing time for each stage ii the calculated ratio for each special category iii the calculated processing time for each category and iv a total number of threads allocated to the MDS.

Another aspect of the invention is directed to a method of managing resources of an MDS metadata server in a distributed storage system which includes a plurality of data servers DSs storing file contents and one or more MDSs performing a plurality of metadata operations in response to metadata requests of different types the MDS including a controller having a processor and a memory the MDS storing file system metadata. The method comprises classifying the metadata operations into different categories which include a normal category and one or more special categories which are different from the normal category the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS for each of the one or more special categories partitioning each of the metadata operations into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS and dynamically assigning resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.

These and other features and advantages of the present invention will become apparent to those of ordinary skill in the art in view of the following detailed description of the specific embodiments.

In the following detailed description of the invention reference is made to the accompanying drawings which form a part of the disclosure and in which are shown by way of illustration and not of limitation exemplary embodiments by which the invention may be practiced. In the drawings like numerals describe substantially similar components throughout the several views. Further it should be noted that while the detailed description provides various exemplary embodiments as described below and as illustrated in the drawings the present invention is not limited to the embodiments described and illustrated herein but can extend to other embodiments as would be known or as would become known to those skilled in the art. Reference in the specification to one embodiment this embodiment or these embodiments means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the invention and the appearances of these phrases in various places in the specification are not necessarily all referring to the same embodiment. Additionally in the following detailed description numerous specific details are set forth in order to provide a thorough understanding of the present invention. However it will be apparent to one of ordinary skill in the art that these specific details may not all be needed to practice the present invention. In other circumstances well known structures materials circuits processes and interfaces have not been described in detail and or may be illustrated in block diagram form so as to not unnecessarily obscure the present invention.

Furthermore some portions of the detailed description that follow are presented in terms of algorithms and symbolic representations of operations within a computer. These algorithmic descriptions and symbolic representations are the means used by those skilled in the data processing arts to most effectively convey the essence of their innovations to others skilled in the art. An algorithm is a series of defined steps leading to a desired end state or result. In the present invention the steps carried out require physical manipulations of tangible quantities for achieving a tangible result. Usually though not necessarily these quantities take the form of electrical or magnetic signals or instructions capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers instructions or the like. It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as processing computing calculating determining displaying or the like can include the actions and processes of a computer system or other information processing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system s memories or registers or other information storage transmission or display devices.

The present invention also relates to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes or it may include one or more general purpose computers selectively activated or reconfigured by one or more computer programs. Such computer programs may be stored in a computer readable storage medium including non transient medium such as but not limited to optical disks magnetic disks read only memories random access memories solid state devices and drives or any other types of media suitable for storing electronic information. The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs and modules in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform desired method steps. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein. The instructions of the programming language s may be executed by one or more processing devices e.g. central processing units CPUs processors or controllers.

Exemplary embodiments of the invention as will be described in greater detail below provide apparatuses methods and computer programs for improving server resource utilization and performance of metadata operations.

MDSs are servers or devices which manage the namespace of the file system contain metadata of the files and directories and provide service to metadata operations initiated by clients . In addition MDSs may communicate with other MDSs or DSs for the following reasons. MDSs communicate with DSs in order to map the files in the namespace with the physical data present in DSs . Such information is used to process some metadata operations initiated by clients . MDSs may communicate with other MDSs to provide a global namespace while processing some metadata operations initiated by the client .

DSs are servers or devices which store data or file contents. DSs process requests mainly Read and Write from clients . DSs also process requests from MDSs to provide details and location of the file contents on DSs .

Clients are devices such as PCs or other application servers which have network file system client program. Clients communicate with MDSs to access modify file system namespace and obtain metadata information including location of DSs and identifiers of files or data on DSs . Clients communicate with DSs to read and write data or file contents.

The processor represents a central processing unit that executes computer programs. The NFS protocol module is responsible for both client and server functionality of NFS protocol such as NFSV4.1 . As a client NFS protocol module sends requests to DSs and as a server provides service to metadata operations initiated from clients . The network interface connects the MDS to the network for communication with DSs and clients . The workload information table the pre fetched DS FH table the pre fetched metadata table and the pre fetched MDS FH table are read and written to by the programs in system memory . The storage interface connects the storage management module to a storage device over the storage area network SAN or to an internal hard disk drive HDD for raw data storage. The storage management module organizes raw data onto a metadata volume which contains directories and files representing file metadata and location of file contents . The directories and files are read and written to by file system program . Commands and data are communicated between the processor and other components of the MDS over a system bus .

Referring back to after classifying the list of metadata operations into categories in step the following is performed in step . For each metadata operation category identified in step the metadata operation processing is split into a plurality of stages. The task of splitting the processing into multiple stages is performed at the time of designing the MDS itself. Step provides an exemplary set of policies using which this task is performed. As per the first policy operation processing is split into a stage if that part of the processing involves communication with a component external to the MDS . In addition it is critical to design the logic of such a stage as an asynchronous client component and design the corresponding external component with which this stage communicates as an asynchronous server component such as asynchronous DS program and inter MDS asynchronous server program G . The second policy in step recommends splitting the part of processing into a stage if that part of processing is modularly functionally different from its preceding and succeeding processing logic. The policies listed in step can be extended or modified based on the specific MDS design requirements. As an example a policy can be defined to split the processing into a stage if that part of processing needs a write to a heavily accessed hard disk drive. In step the average processing time required for each stage is estimated either based on empirical analysis using previously profiled data on an MDS with similar machine configuration or by theoretical hypothesis. The list of metadata operation categories the list of stages for each category and the estimated processing time are recorded in a table. This table is referred to as the work distribution table .

The special type A category consists of six stages. The second stage is pNFS manager which is responsible for performing pNFS related metadata management including preparing requests to be sent to DSs . The estimated processing time for pNFS manager is A t2 . The third stage is MDS DS asynchronous client which is responsible for sending asynchronous requests to DSs . After the asynchronous request is acknowledged by DS the resources allocated to that metadata operation are free to be used for the subsequent metadata operations. The estimated processing time for MDS DS asynchronous client is A t3 . The fourth stage is asynchronous DS processing performed on DSs . In this stage DSs processes asynchronous requests from MDS and sends a response back to MDS after processing completes. The estimated processing time for asynchronous DS processing is DS t4 . However it is to be noted that during this time no resource is allocated for the corresponding metadata operation on MDS . The fifth stage is DS response aggregator which is responsible for receiving responses from plurality of DSs and aggregating all the responses to a single context representing the corresponding metadata operation. The estimated processing time for DS response aggregator is A t5 . The last stage is secondary metadata processor which is responsible for post processing on MDS for special category type A operations. The estimated processing time for secondary metadata processor A is t6 A.

The special type B category consists of six stages. The first stage is primary metadata processor . The second stage is MDSC manager which is responsible for performing MDS cluster management including preparing requests to be sent to other MDSs . The estimated processing time for MDSC manager is B t2 . The third stage is inter MDS asynchronous client which is responsible for sending asynchronous requests to one or more second MDSs . After the asynchronous request is acknowledged by a second MDS the resources allocated to that metadata operation are free to be used for the subsequent metadata operations. The estimated processing time for inter MDS asynchronous client is B t3 . The fourth stage is asynchronous inter MDS processing which is performed on one or more second MDSs . In this stage the second MDS processes asynchronous requests from first MDS and sends a response back to first MDS after processing completes. The estimated processing time for asynchronous inter MDS processing is MDS t4 . Again it is to be noted that during this time no resource is allocated for the corresponding metadata operation on first MDS . The fifth stage is MDS response aggregator which is responsible for receiving responses from a plurality of MDSs and aggregating all the responses to a single context representing the corresponding metadata operation. The estimated processing time for MDS response aggregator is B t5 . The last stage is secondary metadata processor A which is responsible for post processing on MDS for special category type B operations. The estimated processing time for secondary metadata processor A is t6 A.

In step the operation context is sent to the workload monitoring program . In step A the thread is released. Other steps of the program are explained while describing processing of special type A B category operations.

Referring back to the asynchronous DS program on the DS provides the asynchronous functionality for requests received from the MDS . After the request is processed on the DS a response which also includes the context ID is sent to the MDS . The response from each DS is received by the DS response aggregator program H on the MDS . shows the process flow from the asynchronous DS processing stage to the DS response aggregator stage and then to the secondary metadata processor stage A to produce a response to the client .

Referring back to the inter MDS asynchronous server program G on the second MDS provides the asynchronous functionality for requests received from the first MDS . After the request is processed on the second MDS a response which also includes the context ID is sent to the first MDS . The response from the second MDS is received by the MDS response aggregator program I on the first MDS . shows the process flow from the inter MDS asynchronous server stage to the MDS response aggregator stage and then to the secondary metadata processor stage A to produce a response to the client .

Referring back to of the exemplary steps performed by the secondary metadata processor program J to complete the secondary metadata processor A stage in step the secondary metadata processor program J iteratively checks if there is any incoming operation and loops back if NO. If YES in step a thread is assigned from a secondary metadata processor thread pool . If there is no thread available the secondary metadata processor A stage stalls until a thread is available. Step performs the rest of the compound operation processing. For the directory creation metadata operation GETFH GETATTR RESTOREFH and GETATTR are processed. In step a response is sent to the client which initiated this metadata operation. In step the thread is released.

The next step after step or step is . In step the thread allocation is calculated for each of the programs which process one of the stages for metadata operations. The programs are B C D E F H I and J. The rationale behind the below thread allocation scheme is to allocate threads across all the stages such that all metadata operations are fairly processed. For example allocating relatively more threads to the primary metadata processor stage can improve normal metadata operation but impact the performance of special type A and special type B category metadata operations. The vice versa allocation not only impacts normal operation performance but also leads to underutilization of threads allocated to special category type A and type B stages. This is because due to shortage of threads in the primary metadata processor stage there are not enough metadata operations reaching special type A and type B stages. A fair and efficient way to allocate the threads across all the stages is by considering the following information 

4. Total number of threads allocated to MDS e.g. shown in . This value is statically defined at the time of designing MDS based on hardware configuration on which the MDS would be deployed number of CPUs system memory etc. estimated maximum workload etc.

The description of a second embodiment of the present invention will mainly focus on the differences from the first embodiment.

In the first embodiment although efficient resource allocation is made for fair servicing of different categories of metadata operations special type A and special type B category may still suffer from network overhead due to MDS DS or inter MDS communication. In this embodiment batch mode of execution is presented for certain metadata operations belonging to special type A and type B categories. This mode of execution can improve the performance of special type A and type B category operations which are executing in batch mode and the performance of normal category metadata operations significantly.

The batch mode execution needs to be designed separately for specific metadata operations. Each of such metadata operation may need specific data structures to be stored in the system memory . In this embodiment designs for four metadata operations namely file creation directory creation get file layout and get file attributes are presented but extensions can be made to accommodate batch mode for other metadata operations. The decision to design these four operations to work in batch mode is made after studying the application workload during the design phase of MDS . In the presented embodiment batch mode execution for four operations is designed after studying the typical behavior of HPC and scientific application workload.

For example HPC applications tend to create large number of files and directories in parallel at the beginning of the application. Due to the involvement of multiple servers in processing these operations it may lead to lower MDS performance during that time. Hence to increase the performance of time consuming metadata operations such as file and directory creation batch mode execution speculatively creates additional files or directories and fetches corresponding handles in advance. The subsequent file or directory creation operations complete much faster as the corresponding handles are locally available on the MDS where the operation is received and there is no need for inter server communication. In the present embodiment the trigger for entering batch mode execution for file creation and directory creation is when the rate of receiving those operations is greater than a pre defined threshold.

For get file layout and get file attributes batch mode execution there is a challenge. As the operations are requesting specific file information the MDS would be unaware of which file information would be requested in the subsequent operations. However after studying the typical HPC and scientific application workload it is observed that large number of get file layout or get file attributes are received by the MDS in parallel for files under a specific directory. Hence batch mode execution speculatively fetches corresponding file information for files under a single directory. In the present embodiment the trigger for entering batch mode execution for get file layout and get file attributes is when the rate of receiving those operations under a specific directory is greater than a pre defined threshold.

Another example of batch mode execution could be deletion of file or directory. In a distributed environment deletion operation may need clean up of related information on some other server requiring an inter server communication. However in batch mode execution such operations may be locally completed on the MDS that receives the operation and a reply is sent back to the client . Such processing commonly known as asynchronous processing may involve delayed inter server communication. For example after a certain number of deletions the MDS may cumulatively perform a clean up of all the deleted files or directories on other servers using a single network call. Batch mode execution for deletion may also need to take care of data inconsistencies across multiple servers. In the present invention batch mode execution for file or directory deletion is not described in detail but has been mentioned here to illustrate one of many possible extensions of batch mode execution.

If NO in step step is performed to check if any similar batch mode operation was already sent to further stages which would get the desired information for this operation. To make this decision step needs to maintain a history of batch mode operations that are sent to further stages. The information that needs to be maintained depends on the operation itself. For example if the operation is file creation or directory creation only the number of currently pre fetched FH count is required. This number also includes the FH count that would be pre fetched from an outstanding batch mode file creation or directory creation which was sent to further stages. If this pre fetched file handle count is greater than a predefined threshold then the result of step is YES otherwise the result is NO. The threshold can be a design choice or a configurable number at the time of system deployment.

If the operation is get file layout or get file attributes more details are required. Stage needs to maintain a table containing a list of parent FHs for which the batch mode get file layout or get file attributes was initiated. The table needs to also contain for each parent FH a file identifier range of children whose metadata is already pre fetched. If the current operation s parent FH is listed in this table and if the range of children that have been pre fetched includes the current FH then the result of step result is YES otherwise the result is NO.

If YES in step the operation context is stored in the pending operation context table A in step . If NO in step the operation context is sent to further processing stages depending upon the operation s category. For example file creation and get file layout which belong to special type A category are sent to the pNFS manager program C and directory creation and get file attributes which belong to special type B category are sent to the MDSC manager program D.

Referring back to the operation context with batch mode flag set to 1 is forwarded to either the pNFS manager stage or the MDSC manager stage and then to the MDS DS asynchronous client stage or the inter MDS asynchronous client stage.

In step if an operation context list is found step is performed. In step for each operation context in the operation context list pre fetched information from the corresponding pre fetched information tables and are assigned. For example if the metadata operation is file creation for each operation context in the operation context list DS FHs from the pre fetched DS FH table are updated to the operation context s DS response data. If the metadata operation is get file layout for each operation context in the operation context list the pre fetched metadata table is looked up. First the operation context s parent FH is matched in the parent FH column. Then the operation context s current FH is matched in the children FH column. Then the corresponding file layout is assigned to the operation context s DS response data. In step each operation context in the operation context list is sent to the secondary metadata processor program J for further processing. Then the program performs step of .

In step if no operation context list is found then the program performs step . In step the program stores the pre fetched information in the corresponding pre fetched information table and then perform step of .

In step if an operation context list is found step is performed. In step for each operation context in the operation context list pre fetched information from the asynchronous MDS response are assigned. For example if the metadata operation is directory creation for each operation context in the operation context list MDS FH from the pre fetched MDS FH table is updated to operation context s MDS response data. If the metadata operation is get file attributes for each operation context in the operation context list the pre fetched metadata table is looked up. First the operation context s parent FH is matched under the parent FH column. Then the operation context s current FH is matched under the children FH column. Next the corresponding file attributes are assigned to the operation context s MDS response data. In step each operation context in the operation context list is sent to the secondary metadata processor program J for further processing. Then step is performed where the pre fetched information is stored in the corresponding pre fetched information table . However only pre fetched FHs which are unassigned in step are stored in the pre fetched MDS FH table. The program then performs step of .

From the description of to one can clearly see that most operations which are in batch execution mode need to be processed only in the primary metadata processor stage. Periodically a batch mode operation will be forwarded to further stages with batch mode flag set to 1 which will pre fetch metadata information from the DS or some other MDSs in the anticipation that many similar metadata operations would follow. Similar metadata operations which follow will benefit from the pre fetched metadata information.

Based on the thread allocation scheme used in first embodiment most metadata operations which are executing in batch mode only use threads allocated to the primary metadata processor program B. The threads allocated to further stages are underutilized. Hence a modified thread allocation scheme is presented in this embodiment.

Finally step D is similar to steps to of . The only difference is that in step the ratios are calculated considering non batch mode special category operations i.e. the number of metadata operation for a particular special category minus the number of metadata operations for that particular special category which have been selected to be executed in batch mode . The reason for this change is that operations that are executing in batch mode complete processing in the primary metadata processor stage itself excluding an infrequent speculatively executing batch operation . In other words this change enforces the thread allocation scheme to consider operations executing in batch mode as a normal category operation. This scheme of thread allocation makes full use of otherwise underutilized threads in stages and A dedicated for batch mode operations of special type A and type B categories. This thread allocation scheme improves the performance of batch mode operations and normal category operations significantly.

The description of a third embodiment of the present invention will mainly focus on the differences from the previous embodiments.

In the first embodiment clients first access the metadata from MDSs and then file contents directly from DSs . In other words MDSs are not participating in the file content access path. However a client may not have the capability to differentiate the process of metadata access and file contents access i.e. to send metadata operations to MDSs and send file content operations to DSs . Instead a client may send both metadata operations and file content operations to MDSs . Therefore in the third embodiment the MDSs will serve both metadata access and file content access from clients .

The description of a fourth embodiment of the present invention will mainly focus on the differences from the previous embodiments.

In the above described embodiments an MDS maintains location information of file contents and a Client uses the location information to access file contents stored in DSs through NFS protocol module . In the fourth embodiment a MDS a DS and a Client can also be equipped with a block access protocol module such as iSCSI Internet Small Computer System Interface and FCOE Fibre Channel over Ethernet . An MDS can store location information of file contents in such a way that a Client can access file contents via either NFS protocol module or block access protocol module.

Of course the system configurations illustrated in are purely exemplary of information systems in which the present invention may be implemented and the invention is not limited to a particular hardware configuration. The computers and storage systems implementing the invention can also have known I O devices e.g. CD and DVD drives floppy disk drives hard drives etc. which can store and read the modules programs and data structures used to implement the above described invention. These modules programs and data structures can be encoded on such computer readable media. For example the data structures of the invention can be stored on computer readable media independently of one or more computer readable media on which reside the programs used in the invention. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include local area networks wide area networks e.g. the Internet wireless networks storage area networks and the like.

In the description numerous details are set forth for purposes of explanation in order to provide a thorough understanding of the present invention. However it will be apparent to one skilled in the art that not all of these specific details are required in order to practice the present invention. It is also noted that the invention may be described as a process which is usually depicted as a flowchart a flow diagram a structure diagram or a block diagram. Although a flowchart may describe the operations as a sequential process many of the operations can be performed in parallel or concurrently. In addition the order of the operations may be re arranged.

As is known in the art the operations described above can be performed by hardware software or some combination of software and hardware. Various aspects of embodiments of the invention may be implemented using circuits and logic devices hardware while other aspects may be implemented using instructions stored on a machine readable medium software which if executed by a processor would cause the processor to perform a method to carry out embodiments of the invention. Furthermore some embodiments of the invention may be performed solely in hardware whereas other embodiments may be performed solely in software. Moreover the various functions described can be performed in a single unit or can be spread across a number of components in any number of ways. When performed by software the methods may be executed by a processor such as a general purpose computer based on instructions stored on a computer readable medium. If desired the instructions can be stored on the medium in a compressed and or encrypted format.

From the foregoing it will be apparent that the invention provides methods apparatuses and programs stored on computer readable media for improving server resource utilization and performance of metadata operations. Additionally while specific embodiments have been illustrated and described in this specification those of ordinary skill in the art appreciate that any arrangement that is calculated to achieve the same purpose may be substituted for the specific embodiments disclosed. This disclosure is intended to cover any and all adaptations or variations of the present invention and it is to be understood that the terms used in the following claims should not be construed to limit the invention to the specific embodiments disclosed in the specification. Rather the scope of the invention is to be determined entirely by the following claims which are to be construed in accordance with the established doctrines of claim interpretation along with the full range of equivalents to which such claims are entitled.

