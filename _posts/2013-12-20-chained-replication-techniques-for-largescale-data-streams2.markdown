---

title: Chained replication techniques for large-scale data streams
abstract: A replication chain comprising one or more replication nodes of a multi-tenant stream management system is assigned to store data records of a partition of a particular data stream. A data record of the partition is received at a selected replication node of the replication chain. In a sequential order, a respective replica of the data record is stored at each replication node of the chain. An acknowledgement of a successful storage of the data record is provided after the replications are completed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639589&OS=09639589&RS=09639589
owner: Amazon Technologies, Inc.
number: 09639589
owner_city: Reno
owner_country: US
publication_date: 20131220
---
As the costs of data storage have declined over the years and as the ability to interconnect various elements of the computing infrastructure has improved more and more data pertaining to a wide variety of applications can potentially be collected and analyzed. For example mobile phones can generate data indicating their locations the applications being used by the phone users and so on at least some of which can be collected and analyzed in order to present customized coupons advertisements and the like to the users. The analysis of data collected by surveillance cameras may be useful in preventing and or solving crimes and data collected from sensors embedded at various location within airplane engines automobiles or complex machinery may be used for various purposes such as preventive maintenance improving efficiency and lowering costs.

The increase in volumes of streaming data has been accompanied by and in some cases made possible by the increasing use of commodity hardware. The advent of virtualization technologies for commodity hardware has provided benefits with respect to managing large scale computing resources for many types of applications allowing various computing resources to be efficiently and securely shared by multiple customers. For example virtualization technologies may allow a single physical computing machine to be shared among multiple users by providing each user with one or more virtual machines hosted by the single physical computing machine. Each virtual machine can be thought of as a software simulation acting as a distinct logical computing system that provides users with the illusion that they are the sole operators and administrators of a given hardware computing resource while also providing application isolation and security among the various virtual machines. Furthermore some virtualization technologies are capable of providing virtual resources that span two or more physical resources such as a single virtual machine with multiple virtual processors that spans multiple distinct physical computing systems. In addition to computing platforms some large organizations also provide various types of storage services built using virtualization technologies. Using such storage services large amounts of data can be stored with desired durability levels.

Despite the availability of virtualized computing and or storage resources at relatively low cost from various providers however the management and orchestration of the collection storage and processing of large dynamically fluctuating streams of data remains a challenging proposition for a variety of reasons. As more resources are added to a system set up for handling large streams of data for example imbalances in workload between different parts of the system may arise. If left unaddressed such imbalances may lead to severe performance problems at some resources in addition to underutilization and hence wastage of other resources. Clients may also be concerned regarding the security of their streaming data or the results of analyzing streaming data if such data or results are stored at facilities that the clients do not control. The failures that naturally tend to occur with increasing frequency as distributed systems grow in size such as the occasional loss of connectivity and or hardware failure may also have to be addressed effectively to prevent costly disruptions of stream data collection storage or analysis. Some clients may also be concerned about the possibility of duplicates being introduced into their data streams which could in some cases lead to application errors.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Various embodiments of methods and apparatus for managing the creation storage retrieval and processing of large scale data streams designed to handle hundreds or even thousands of concurrent data producers and data consumers are described. The term data stream as used herein refers to a sequence of data records that may be generated by one or more data producers and accessed by one or more data consumers where each data record is assumed to be an immutable sequence of bytes. A stream management service SMS may provide programmatic interfaces e.g. application programming interfaces APIs web pages or web sites graphical user interfaces or command line tools to enable the creation configuration and deletion of streams as well as the submission storage and retrieval of stream data records in some embodiments. Some types of stream operations such as stream creation or deletion or the kinds of dynamic repartitioning operations described below that involve interactions with SMS control components may be referred to as control plane operations herein while operations such as data record submissions storage and retrievals that typically e.g. under normal operating conditions do not require interactions with control components may be referred to herein as data plane operations. Dynamically provisioned sets of compute storage and networking resources may be used to implement the service in some such embodiments based for example on various partitioning policies that allow the stream management workload to be distributed in a scalable fashion among numerous service components as described below in further detail. The acronym SMS may be used herein to refer to a stream management service and also to a stream management system comprising the collection of virtual and or physical resources used to implement a stream management service.

Some customers of the SMS may develop applications that directly invoke the SMS programmatic interfaces in various embodiments. In at least some embodiments however in addition to the SMS interfaces a higher level abstraction or application level processing framework may be provided for customers which may simplify various aspects of stream processing for those clients that do not wish to develop applications using the lower level stream management functions supported directly by the SMS. Such a framework may provide its own programmatic interfaces built for example on top of the SMS interfaces enabling customers to focus more on the business logic to be implemented using stream records than on lower level stream management operations. The higher level framework may be implemented as a stream processing service SPS with its own control plane and data plane components in some embodiments which may provide advanced functionality such as automated resource provisioning for stream processing automated failovers of processing nodes the ability to construct arbitrary stream processing workflow graphs support for ephemeral streams dynamic repartitioning based on workload changes or other triggering conditions and so on. In at least some embodiments either the stream management service the stream processing service or both services may be implemented as multi tenant managed network accessible services in a virtualization environment. That is various physical resources such as computer servers or hosts storage devices networking devices and the like may at least in some cases be shared among streams of different customers in such embodiments without necessarily making the customers aware of exactly how the resources are being shared or even making a customer aware that a given resource is being shared at all. Control components of the managed multi tenant stream management and or processing managed services may dynamically add remove or reconfigure nodes or resources being used for a particular stream based on various applicable policies some of which may be client selectable. In addition the control components may also be responsible for transparently implementing various types of security protocols e.g. to ensure that one client s stream application cannot access another client s data even though at least some hardware or software may be shared by both clients monitoring resource usage for billing generating logging information that can be used for auditing or debugging and so on. From the perspective of clients of the managed multi tenant service s the control administrative functionality implemented by the service s may eliminate much of the complexity involved in supporting large scale streaming applications. In some scenarios customers of such multi tenant services may be able to indicate that they do not wish to share resources for at least some types of stream related operations in which case some physical resources may be designated at least temporarily as being single tenant for those types of operations i.e. limited to operations performed on behalf of a single customer or client .

A number of different approaches may be taken to the implementation of SMS and or SPS control plane and data plane operations in various embodiments. For example with respect to control plane operations in some implementations a redundancy group of control servers or nodes may be set up. The redundancy group may include a plurality of control servers of which one server is designated as a primary server responsible for responding to administrative requests regarding various streams while another server may be designated to take over as the primary in the event of a triggering condition such as a failure at or loss of connectivity to the current primary. In another implementation one or more tables created at a network accessible database service may be used to store control plane metadata such as partition maps for various streams and various ingestion storage or retrieval nodes may be able to access the tables as needed to obtain the subsets of metadata required for data plane operations. Details regarding various aspects of the SPS and the SMS data plane and control plane functionality in different embodiments are provided below. It is noted that in some embodiments in which a stream management service is implemented a stream processing service providing higher level primitives may not necessarily be implemented. In other embodiments only high level programmatic interfaces of a stream processing service may be exposed to customers and lower level stream management interfaces used by the may not be made available to clients.

According to some embodiments a stream management system may comprise a plurality of independently configurable subsystems including a record ingestion subsystem primarily responsible for obtaining or collecting data records a record storage subsystem primarily responsible for saving the data record contents in accordance with applicable persistence or durability policies and a record retrieval subsystem primarily responsible for responding to read requests directed at the stored records. A control subsystem may also be implemented in some embodiments comprising one or more administrative or control components responsible for configuring the remaining subsystems e.g. by dynamically determining and or initializing the required number of nodes for each of the ingestion storage and retrieval subsystems at selected resources such as virtual or physical servers. Each of the ingestion storage retrieval and control subsystems may be implemented using a respective plurality of hardware and or software components which may collectively be referred as nodes or servers of the subsystems. The various resources of an SMS may thus be logically said to belong to one of four functional categories ingestion storage retrieval or control. In some implementations respective sets of control components may be established for each of the other subsystems e.g. independent ingestion control subsystems storage control subsystems and or retrieval control subsystems may be implemented. Each such control subsystem may be responsible for identifying the resources to be used for the other nodes of the corresponding subsystem and or for responding to administrative queries from clients or from other subsystems. In some implementations pools of nodes capable of performing various types of SMS and or SPS functions may be set up in advance and selected members of those pools may be assigned to new streams or new processing stages as needed.

Stream partitioning policies and associated mappings may be implemented in at least some embodiments e.g. to distribute subsets of the data records between different sets of ingestion storage retrieval and or control nodes. For example based on the partitioning policy selected for a particular data stream as well as on other factors such as expectations of record ingestion rates and or retrieval rates a control component may determine how many nodes e.g. processes or threads should be established initially i.e. at stream creation time for ingestion storage and retrieval and how those nodes should be mapped to virtual and or physical machines. Over time the workload associated with a given stream may increase or decrease which among other triggering conditions may lead to repartitioning of the stream. Such re partitioning may involve changes to various parameters such as the function to be used to determine a record s partition the partitioning keys used the total number of partitions the number of ingestion nodes storage nodes or retrieval nodes or the placement of the nodes on different physical or virtual resources. In at least some embodiments the repartitioning may be implemented dynamically without interrupting the flow of the data records using techniques described below in further detail. Different partitioning schemes and repartition triggering criteria may be used for different data streams in some embodiments e.g. based on client provided parameters or on heuristics of the SMS control nodes. In some embodiments it may be possible to limit the number and or frequency of reparations e.g. based on client preferences the expected lifetime of a stream or other factors.

A number of different record ingestion policies and interfaces may be implemented in different embodiments. For example in some embodiments clients e.g. executable components or modules configured to invoke the programmatic interfaces of the SMS on behalf of customers of the SMS may utilize either in line submission interfaces or by reference submission interfaces. For in line submissions the contents or body of the data record may be included as part of the submission request in such embodiments. In contrast in a by reference submission request an address such as a storage device address a database record address or a URL Uniform record Locator may be provided from which the contents or body of the data record can be obtained. In some implementations a hybrid submission interface may also or instead be supported in which up the first N bytes of the data record may be included in line while the remaining bytes if any are provided by reference. In such a scenario short records whose bodies are less than N bytes long may be fully specified by the submission request while portions of longer records may have to be obtained from the corresponding address.

In addition to the different alternatives for specifying record contents during ingestion in some embodiments a variety of acknowledgement or de duplication related ingestion policies may also be implemented. For example for some stream applications clients may wish to ensure that each and every data record is ingested reliably by the SMS. In large distributed stream management environments packets may be lost or various failures may occur from time to time along the path between the data producers and the ingestion nodes which could potentially result in some submitted data being lost. In some embodiments therefore an SMS may implement an at least once ingestion policy in accordance with which a record submitter may submit the same record one or more times until a positive acknowledgement is received from the ingestion subsystem. Under normal operating conditions a record may be submitted once and the submitter may receive an acknowledgement after the receiving ingestion node has obtained and stored the record. If the acknowledgement is lost or delayed or if the record submission request itself was lost the submitter may resubmit the same data record one or more times until eventually an acknowledgement is received. The ingestion node may for example generate an acknowledgement for each submission regardless of whether it is a duplicate or not based on an expectation that the record would not be resubmitted if an acknowledgement had already been received by the submitter. The ingestion node may however be responsible in at least some embodiments for recognizing that the same data record has been submitted multiple times and for avoiding storing new copies of the duplicate data unnecessarily. In some embodiments a decentralized technique for de duplication may be used in which local de duplication tables are instantiated at each ingestion node to store de duplication signatures for only the partitions to which the ingestion node. A number of optimization techniques may be used to limit the sizes of the local de duplication tables as described below in further detail.

In one embodiment at least two versions of an at least once ingestion policy may be supported one version which may be termed at least once ingestion no duplication in which the SMS is responsible for de duplicating data records i.e. ensuring that data is stored at the SMS storage subsystem in response to only one of a set of two or more submissions and one version in which duplication of data records storage by the SMS is permitted which may be termed at least once duplication permitted . The at least once duplication permitted approach may be useful for stream applications in which there are few or no negative consequences of data record duplication and or for stream applications that perform their own duplicate elimination. Other ingestion policies may also be supported such as a best effort ingestion policy in which acknowledgements are not required for every data record submitted. The loss of a few data records may be acceptable if a best effort ingestion policy is in effect in at least some embodiments. Clients may select which ingestion policies they wish to use for various streams in various embodiments.

With respect to the storage of stream records a number of alternative policies may also be supported in at least some embodiments. For example a client may be able to choose a persistence policy from among several supported by the SMS which governs such aspects of record storage as the number of copies of a given data record that are to be stored the type of storage technology e.g. volatile or non volatile RAM rotating disk based storage solid state devices SSDs network attached storage devices and the like to be used for the copies and so on. For example if a client selects an N replica persistence policy to disk based storage a data record submission may not be considered complete until N copies of the record have been safely written to N respective disk devices. A chained replication technique may be used in some embodiments in which the N copies are written to N storage locations in sequential order as described below in further detail. In at least some embodiments in which disk based storage devices are used the SMS storage subsystem may attempt to write incoming data records of a given partition sequentially to disk e.g. to avoid the performance impact of disk seeks. Sequence numbers may be generated for and stored with data records using various techniques as described below including for example timestamp based techniques that enable ordered record retrieval based on ingestion times. Data records of a given partition may be stored together e.g. contiguously on disk and separately from the data records of other partitions in at least some embodiments. In some implementations in accordance with a retention policy selected by a client or by the SMS or a de duplication time window policy indicating the time period subsequent to a submission of any given data record during which the SMS may be required to ensure that no duplicates of that given data record are stored in the SMS storage subsystem even if some duplicates are submitted at least some data records may be archived to a different types of storage service and or deleted after a time period from the SMS. Such removal operations may be referred to herein as stream trimming . Clients may submit stream trimming requests in some embodiments e.g. notifying the SMS that specified data records are no longer needed and can therefore be deleted from the perspective of the client submitting the trimming request or explicitly requesting the deletion of specified data records. In scenarios in which there may be multiple clients consuming the data records of a given stream the SMS may be responsible for ensuring that a given record is not deleted or trimmed prematurely before it has been accessed by all the interested consumers. In some implementations if there are N data consumers of a given stream before deleting a given record R of the stream he SMS may wait until it has determined that all N data consumers have read or processed R. The SMS may determine that R has been read by all the consumers based on respective trimming requests from the consumers for example or based on respective indications of how far within the stream the data consumers have progressed. In some embodiments some types of data consumers such as testing related applications may accept the deletion of at least a small subset of data records before they have been accessed. Accordingly applications may be able to notify the SMS regarding the acceptability of data deletion prior to retrieval in at least some embodiments and the SMS may schedule deletions in accordance with the notifications. In some embodiments an archival policy may be implemented e.g. as part of the data retention policy indicating for example the types of storage devices to which stream data records should be copied and the scheduling policies to be used for such copies.

In at least some embodiments a plurality of programmatic interfaces may also be supported for record retrieval. In one embodiment an iterator based approach may be used in which one programmatic interface e.g. getIterator may be used to instantiate and position an iterator or cursor at a specified logical offset e.g. based on sequence number or timestamp within a partition of a stream. A different programmatic interface such as getNextRecords may then be used to read a specified number of data records sequentially starting from the current position of the iterator. The instantiation of an iterator may in effect allow a client to specify an arbitrary or random starting position for record retrieval within the stream partition. If a client wishes to read data records in a random access pattern in such an embodiment the client may have to repeatedly create new iterators. In rotating disk based storage systems disk seeks required for frequent random accesses may impact I O response times significantly. Accordingly as an incentive to clients to read stream data records sequentially rather than randomly different e.g. higher billing rates may be applied to random read accesses than are applied to sequential read accesses in at least some embodiments. Thus for example a client may be billed X currency units per getIterator call and Y currency units per record retrieved via getNextRecords with X Y in some implementations. When alternative client interfaces are supported for other operation categories such as ingestion in at least some embodiments the billing rates or prices for the alternatives may also differ e.g. a client may be charged more for a by reference submission request than for an online submission request just as a client may be charged more for random reads than for sequential reads. Other factors may also influence billing in various embodiments such as the sizes of the data records the distribution of write versus read requests over time the persistence policies selected and so on.

According to some embodiments a stream processing service SPS may allow clients to specify arbitrarily complex processing workflows comprising numerous processing stages in which the output of the processing performed at a given stage may be used as input for zero or more other stages. Partitioning policies similar to those described for the SMS for ingesting storing and retrieving data records may be used to divide the processing workload among a plurality of worker nodes at various stages in some embodiments. In one such embodiment programmatic SPS interfaces may be implemented enabling clients to specify various configuration settings for any given stage including for example the input data source s for the stage e.g. one or more streams from which data records are to be retrieved together with the partitioning policies for the streams the processing operations to be performed at the stage and a descriptor or specification for output or result distribution from the stage e.g. whether the output is to be saved to storage locations sent to a network endpoint or fed into one or more other processing stages in the form of a different stream . In at least some embodiments the processing operations specified for an SPS stage may be idempotent that is if a given processing operation is performed multiple times on the same input data the result of the operation does not differ from the result that would have been obtained if the operation were performed just once. Recoveries from failures e.g. a worker node failure at an SPS stage may be simplified if the processing operations are idempotent as described below in further detail. According to some embodiments non idempotent processing operations may be permitted at some or all SPS stages.

Based at least in part on configuration information such as the input stream partitioning policies and then nature of the processing operations received via the SPS programmatic interfaces in various embodiments SPS control servers may determine how many worker nodes are to be set up initially for various stages of a processing workflow. The performance capabilities of the resources to be used for the worker nodes e.g. the virtual or physical machines being used may also be taken into account when determining the initial number and placement of the worker nodes. The selected number of worker nodes which may in some implementations each comprise an executable thread or an executable process may be instantiated. Each worker node may be configured for example to obtain data records from the appropriate input sources e.g. from retrieval nodes of one or more stream partitions perform the specified processing operations on the data records and transmit the results of the processing to the specified output destination s . In addition in at least some embodiments a checkpoint scheme may be implemented in accordance with which a given worker node may be configured to store progress records or checkpoints indicative of the portion of a partition that has been processed at that worker node with the assumption that the partition records are being processed sequentially. The worker node may for example write a progress record to persistent storage periodically in some implementations e.g. once every N seconds or once every R data records have been processed and or in response to checkpoint requests from an SPS control server.

The progress records may be used for rapid recovery from worker node failures in some embodiments. For example an SPS control server may monitor the health status of the various worker nodes over time e.g. using a heartbeat mechanism and or by monitoring resource utilization levels such as CPU utilization I O device utilization or network utilization levels . In response to a determination by the SPS control server that a particular worker node is in an undesired or unhealthy state e.g. if it is unresponsive or overloaded a replacement worker node may be instantiated to take over the responsibilities of the particular worker node. The replacement worker node may access the most recent progress record stored by the replaced worker node to identify the set of data records that the replacement worker node should process. In embodiments in which the processing operations are idempotent even if some operations are repeated e.g. because the most recent progress record was written some time prior to the replacement worker s instantiation the overall results of the processing would not be affected by the failure and replacement. In some implementations in addition to storing progress records indicating the subset of a given stream or partition that has been processed by it a worker node may also be configured to store accumulated application state information. For example if a stream processing workflow is responsible for determining client billing amounts for a particular service based on analyzing streaming data records that indicate service usage metrics a worker node may periodically store the cumulative billing amounts determined for various clients.

In at least some embodiments the SPS control servers may also be configured to respond to various other triggers such as changing workload levels or detected workload imbalances e.g. if the ingestion rates for one partition become disproportionately higher than those of others by initiating other actions such as requesting dynamic repartitioning of the input streams for various stages changing the number of worker nodes assigned to a given partition at a given stage. assigning higher performance worker nodes to some stages or transferring worker nodes from one physical resource to another physical resource with a different performance capability. In some embodiments e.g. in response to a determination by an SPS control server that a best effort recovery policy is to be implemented for a given stage rather than a checkpoint based recovery policy progress records of the type described above may not be stored by worker nodes of at least some SPS stages. In some implementations of such a best effort recovery policy a replacement worker node may simply process new data records as they are received without requiring access to progress records. In some embodiments if a client wishes to implement a best effort recovery policy at an SPS stage the stream processing operations performed at the stage need not necessarily be idempotent. In some embodiments in which non idempotent processing operations are to be performed on stream records at an SPS stage checkpoint based recovery may not be supported and a different recovery scheme such as best effort recovery may be used. In at least one embodiment only idempotent stream processing operations may be allowed at SPS stages.

The data records of some streams may contain sensitive or confidential information or the processing operations performed at the SPS stages may comprise the use of proprietary algorithms whose discovery by competitors may be problematic. Clients may thus be concerned about the security of various categories of stream management and processing operations especially if the operations are performed using resources located at provider network data centers that are not fully controlled by the clients themselves. Networks set up by an entity such as a company or a public sector organization to provide one or more network accessible services such as various types of cloud based database computing or storage services accessible via the Internet and or other networks to a distributed set of clients may be termed provider networks herein. In some embodiments clients may be able to choose from among a plurality of security related options for their data streams. As described above a combined SPS and SMS configuration may comprise nodes belonging to a number of different functional categories such as control nodes for the SMS and or the SPS SMS ingestion nodes SMS storage nodes SMS retrieval nodes and SPS processing or worker nodes. The security related choices made available to clients may include options for placement or locations of various types of nodes in some embodiments. For example in one embodiment a client may be able to request that SPS worker nodes for one or more processing stages of a stream workflow be implemented at computing devices located on client owned facilities even if the stream records are initially collected and or stored using resources located at a provider network. In response to such placement requests nodes of different functional categories for a given stream may be instantiated at respective resource sets with differing security characteristics or profiles.

The resource sets may differ from one another in various security related characteristics in different embodiments including for example physical location physical security protocols being used e.g. who has physical access to the resources network isolation levels e.g. the extent to which network addresses of the resources are visible to various entities multi tenancy versus single tenancy and so on. In some embodiments clients may be able to establish isolated virtual networks IVNs within a provider network with a given client being given substantial control over networking configurations of various devices included within that client s IVN. In particular clients may be able to restrict access to the network addresses e.g. Internet Protocol or IP addresses assigned to various servers or compute instances within their IVNs. In such embodiments clients may request that certain subsets of their SMS or SPS nodes be instantiated within specified IVNs. In embodiments in which provider network resources such as virtualization instance hosts which may typically be configured as multi tenant hosts are being used for various categories of SMS or SPS nodes a client may request that some set of nodes be instantiated on instance hosts that are restricted to implementing instances belonging to that client alone i.e. some SMS or SPS nodes may be implemented at instance hosts configured as single tenant hosts .

In some embodiments as another security related option clients may request that the data records of a particular stream be encrypted before they are transmitted over a network link e.g. before being ingested at the SMS between the ingestion and storage subsystems between the storage and retrieval subsystems between the retrieval subsystems and the SPS worker nodes and or between the worker nodes and the SPS output destinations. Clients may specify the encryption algorithms to be used in some embodiments. In one embodiment secure networking protocols such as TLS Transport Layer Security or SSL secure sockets layer protocols may be used for data record transmissions and or for transmitting SPS processing results.

In at least some embodiments a given data record as stored in an SMS may comprise a data portion e.g. data portions A B C D and E of DRs A B C D and E respectively and a sequence number SN e.g. SNs A B C D and E of DRs A B C D and E respectively . The sequence number may be indicative of the order in which the DRs are received at a stream management system or at a particular node of a stream management system in the depicted embodiment. The data portions may comprise immutable un interpreted byte sequences in some implementations that is once a write operation is completed the contents of the DR generated as a result of the write may not be changed by the SMS and in general the SMS may not be aware of the semantics of the data. In some implementations different data records of a given stream may comprise different amounts of data while in other implementations all the data records of a given stream may be of the same size. In at least some implementations nodes of the SMS e.g. ingestion subsystem nodes and or storage subsystem nodes may be responsible for generating the SNs . As described below in further detail the sequence numbers of the data records need not always be consecutive. In one implementation clients or data producers may provide as part of a write request an indication of a minimum sequence number to be used for the corresponding data record. In some embodiments data producers may submit write requests that contain pointers to or addresses of the data portions of the data records e.g. by providing a storage device address such as a device name and an offset within the device or a network address such as a URL from which the data portion may be obtained.

The stream management service may be responsible for receiving the data from the data producers storing the data and enabling data consumers to access the data in one or more access patterns in various embodiments. In at least some embodiments the stream may be partitioned or sharded to distribute the workload of receiving storing and retrieving the data records. In such embodiments a partition or shard may be selected for an incoming data record based on one or more attributes of the data record and the specific nodes that are to ingest store or retrieve the data record may be identified based on the partition. In some implementations the data producers may provide explicit partitioning keys with each write operation which may serve as the partitioning attributes and such keys may be mapped to partition identifiers. In other implementations the SMS may infer the partition ID based on such factors as the identity of the data producer the IP addresses of the data producers or even based on contents of the data submitted. In some implementations in which data streams are partitioned sequence numbers may be assigned on a per partition basis for example although the sequence numbers may indicate the order in which data records of a particular partition are received the sequence numbers of data records DR and DR in two different partitions may not necessarily indicate the relative order in which DR and DR were received. In other implementations the sequence numbers may be assigned on a stream wide rather than a per partition basis so that if sequence number SN assigned to a data record DR is lower than sequence number SN assigned to data record DR this would imply that DR was received earlier than DR by the SMS regardless of the partitions to which DR and DR belong.

The retrieval or read interfaces supported by an SMS may allow data consumers to access data records sequentially and or in random order in various embodiments. In one embodiment an iterator based set of read application programming interfaces APIs may be supported. A data consumer may submit a request to obtain an iterator for a data stream with the initial position of the iterator indicated by a specified sequence number and or a partition identifier. After the initiator is instantiated the data consumer may submit requests to read data records in sequential order starting from that initial position within the stream or the partition. If a data consumer wishes to read data records in some random order a new iterator may have to be instantiated for each read in such embodiments. In at least some implementations the data records of a given partition or stream may be written to disk based storage in sequence number order typically using sequential write operations that avoid disk seeks. Sequential read operations may also avoid the overhead of disk seeks. Accordingly in some embodiments data consumers may be encouraged to perform more sequential reads than random reads using pricing incentives e.g. random access read operations such as iterator instantiations may have higher associated billing rates than sequential access read operations.

In at least some embodiments at least some of the nodes of the subsystems and processing stages shown in may be implemented using provider network resources. As noted earlier networks set up by an entity such as a company or a public sector organization to provide one or more network accessible services such as various types of cloud based database computing or storage services accessible via the Internet and or other networks to a distributed set of clients may be termed provider networks herein. Some of the services may be used to build higher level services for example computing storage or database services may be used as building blocks for a stream management service or a stream processing service. At least some of the core services of a provider network may be packaged for client use in service units called instances for example a virtual machine instantiated by a virtualized computing service may represent a compute instance and a storage device such as a block level volume instantiated by a storage service may be referred to as a storage instance or a database management server may be referred to as a database instance . Computing devices such as servers at which such units of various network accessible services of a provider network are implemented may be referred to as instance hosts or more simply as hosts herein. Nodes of the ingestion subsystem the storage subsystem the retrieval subsystem the SMS control system the processing stages and or the SPS control subsystem may comprises threads or processes executing at various compute instances on a plurality of instance hosts in some embodiments. A given instance host may comprise several compute instances and the collection of compute instances at a particular instance host may be used to implement nodes for various different streams of one or more clients. Storage instances may be used for storing the data records of various streams in some embodiments or as destinations of the results of stream processing stages. Over time control subsystem nodes may modify the populations of other subsystems dynamically in response to various triggering conditions e.g. by adding or removing nodes changing the mappings of nodes to processes or compute instances or instance hosts or re partitioning a given stream while still continuing to receive store and process data records as described below with reference to and .

In the context of embodiments in which provider network resources are used for stream related operations the term client when used as the source or destination of a given communication may refer to any of the computing devices processes hardware modules or software modules that are owned by managed by or allocated to an entity such as an organization a group with multiple users or a single user that is capable of accessing and utilizing at least one network accessible service of a provider network. Clients of one service may themselves be implemented using resources of another service e.g. a stream data consumer a client of a stream management service may comprise a compute instance a resource provided by a virtualized computing service .

A given provider network may include numerous data centers which may be distributed across different geographical regions hosting various resource pools such as collections of physical and or virtualized computer servers storage servers with one or more storage devices each networking equipment and the like needed to implement configure and distribute the infrastructure and services offered by the provider. A number of different hardware and or software components some of which may be instantiated or executed at different data centers or in different geographical regions may collectively be used to implement each of the services in various embodiments. Clients may interact with resources and services at the provider network from devices located at client owned or client managed premises or data centers external to the provider network and or from devices within the provider network. It is noted that although provider networks serve as one example context in which many of the stream management and processing techniques described herein may be implemented those techniques may also be applied to other types of distributed systems than provider networks e.g. to large scale distributed environments operated by a single business entity for its own applications.

As indicated above in at least some embodiments an SPS may utilize SMS programmatic interfaces to build higher level functionality that can more easily be used by SPS clients to implement the desired business logic for various stream based applications. When considering the differences between SPS and SMS functionality an analogy may be helpful SPS functions may in general be compared to programming language constructs in higher level languages such as C while SMS functions may in general be compared to the assembly language instructions to which the programming language constructs are translated by a compiler. It may be possible to implement the same operations using the assembly language instructions directly but programming in the higher level language may typically be easier for many categories of customers or users. Similarly it may be possible to implement various applications using the primitives provided by an SMS but it may be easier to do so using SPS features. SPS processing operations such as idempotent processing operations performed on data records may be implemented on the data contents of the stream records while the SMS operations are performed to acquire store and retrieve the records themselves usually without considering the contents of the records. illustrates examples of respective sets of programmatic interfaces that may be implemented at an SMS an SPS according to at least some embodiments. A number of different application programming interfaces APIs are indicated for both the SMS and the SPS by way of example. The APIs illustrated are not intended to be exhaustive lists of those supported in any given implementation and some of the illustrated APIs may not be supported in a given implementation.

As indicated by arrow SPS clients may invoke SPS programmatic interfaces to configure processing stages. Various types of SPS programmatic interfaces may be implemented in different embodiments. For example a createStreamProcessingStage API may enable clients to request the configuration of a new processing stage for a specified input stream such that worker nodes of the stage are each configured to perform a set of idempotent operations specified in the interface invocation and to distribute the results to destinations indicated by an output distribution descriptor or policy. In some versions of the createStreamProcessingStage API or its equivalent a client may request the creation of the input stream as well while in other versions an input stream may have to be created before the processing stage is created. A recovery policy may be specified for the worker nodes indicating for example whether a checkpoint based recovery technique is to be used or a best effort recovery technique is preferred. In some embodiments an initializeWorkerNode API may be supported to request the explicit instantiation of worker nodes at a specified stage. In embodiments in which checkpoint based recovery is implemented a saveCheckpoint API may be supported to allow clients to request that progress records be generated by worker nodes.

Various types of SPS output management APIs may be supported in different embodiments such as a setOutputDistribution API by which a client may indicate one or more streams to be created using the results of the processing operations performed at a specified stage and the particular partitioning policies to be used for the newly created streams. Some processing stages may be configured primarily for repartitioning e.g. one partitioning function PF that maps data records to N partitions based on record attribute set A may be in use for an input stream S and a processing stage may be used to implement a different partitioning function PF to map those same data records to N partitions using either a different attribute set A or the same attribute set A . Some SPS APIs such as linkStages may be used to configure arbitrary graphs e.g. directed acyclic graphs comprising a plurality of stages. In some embodiments connectors to third party or open source stream processing frameworks or services may be supported. In one such embodiment an SPS stage may be used to prepare data records e.g. by appropriately formatting results of the processing operations performed at the stage for consumption by existing third party or open source systems. An API such as createThirdPartyConnector may be used to set up such connectors in the depicted embodiment and the appropriate transformations of the results of the SPS stage into a format compatible with the third party system may be performed by one or more connector modules instantiated as a result of a createThirdPartyConnector invocation.

The SPS may invoke SMS APIs to perform at least some of its functions as indicated by arrow . The SMS APIs may include for example createStream and deleteStream to create and delete a stream respectively and getStreamInfo to obtain metadata for a stream such as the network addresses of various types of nodes responsible for a given partition in the depicted embodiment. A putRecord interface may be used to write data records while the getIterator and getNextRecords interfaces may be used for non sequential and sequential reads respectively. A repartitionStream interface may be used to request dynamic repartitioning of a specified stream in some embodiments. Clients that wish to do so may invoke the SMS APIs directly as indicated by arrow . As indicated earlier various other SMS and or SPS APIs may also be implemented in other embodiments and some of the APIs listed in may not be implemented in some embodiments.

In various embodiments programmatic interfaces other than APIs may also or instead be implemented for either the SPS or the SMS. Such interfaces may include graphical user interfaces web pages or web sites command line interfaces and the like. In some cases web based interfaces or GUIs may use the APIs as building blocks e.g. a web based interaction may result in the invocation of one or more APIs at control components of the SMS or SPS. illustrates an example web based interface that may be implemented to enable SPS clients to generate graphs of stream processing stages according to at least some embodiments. As shown the interface comprises a web page with a message area a graph menu area and a graph design area .

Users may be provided general instructions regarding the construction of stream processing graphs in message area as well as links to enable used to learn more about stream concepts and primitives. A number of graphical icons may be provided as part of a stream processing graph toolset in menu area . For example clients may be allowed to indicate as inputs or outputs of various SPS processing stages persistent streams ephemeral streams or connectors to third party processing environments. With respect to the SPS SMS for which the web based interface is implemented a persistent stream may be defined as a stream whose data records are stored on persistent storage devices such as disks non volatile RAMs or SSDs and an ephemeral stream may be defined as one whose data records need not be stored at persistent storage devices. An ephemeral stream may be created for example from the output of an SPS stage that is expected to be consumed as input by a different SPS stage at which a best effort recovery policy is to be implemented.

Two types of processing stages are supported in the example SPS graph construction web page stages in which checkpoint based worker node recovery is used e.g. each worker node saves progress records at intervals and in the event of failure of a particular worker node a replacement node refers to the failed node s progress records to determine which data records to start processing and stages in which best effort recovery is used e.g. replacement worker nodes do not refer to progress records but simply start processing new data records as they are received . Details regarding the processing operations to be performed at each stage may be entered by clicking on the corresponding icon in the graph construction area as indicated by the instructions in message area . In addition to icons for streams connectors and processing stages the menu area also includes icon type indicating third party or external stream processing systems and icon type indicating nodes of a storage service that may be implemented at a provider network whose resources are being used for the processing stages.

In the example scenario shown in a client has constructed a graph comprising three processing stages and within graph design area . Processing stage which is configured to use checkpoint based recovery uses a persistent stream as input. Output or results of the processing at stage is sent to two destinations in the form of a different persistent stream that forms the input of stage and in the form of an ephemeral stream that forms the input of stage . Stages and both use best effort recovery policies for their worker nodes. The output of stage is sent in the form of an ephemeral stream to storage service node . The output of stage is sent via a connector to a third party processing system . A save graph button may be used to save a representation of the processing stage graph e.g. in any appropriate format such as JSON JavaScript Object Notation XML Extensible Markup Language or YAML. Arbitrarily complex processing workflows may be constructed using tools similar to those shown in in various embodiments. The workflows created using such tools may subsequently be activated and such activations may result in invocations of SMS APIs for example to obtain data records for a processing stage such as stage of getIterator and or getNextRecords interfaces may be invoked on stream .

The incoming data records may be directed to respective ingestion and or storage nodes based on a partitioning policy in the depicted embodiment. Similarly record retrieval may also be partition based e.g. one or more retrieval nodes may be designated for responding to read requests directed to records of a given partition. For some streams data producers may be required to provide an explicit partition key with each data record write request. For other streams the SMS may be able to distribute the data records according to a partitioning scheme that relies on metadata or attributes other than explicitly supplied partition keys for example identification information pertaining to the submitting data producer may be used as a partition key or a portion or all of the submitting data producer s IP address may be used or a portion of the data being submitted may be used. In some implementations for example a hash function may be applied to a partition key to obtain an integer value of a certain size such as a 128 bit integer. The total range of positive integers of that size e.g. from 0 to 2 128 1 may be divided into N contiguous sub ranges with each sub range representing a respective partition. Thus in such an example any given partition key determined or supplied for a data record would be hashed to a corresponding 128 bit integer and the contiguous sub range of 128 bit integers to which that integer belongs may indicate the partition to which the data record belongs. Further details about partitioning policies and their use are provided below with respect to .

The set of nodes responsible for ingesting or accepting the data records of the particular partition storing the data records and responding to read requests for the particular partition are collectively referred to as ISR ingestion storage and retrieval nodes for the partition in . The notation Sj Pk is used to indicate the kth partition of stream Si. In the illustrated embodiment ISR nodes A are configured for ingesting storing and retrieving records of partition S P ISR nodes B are set up for records of partition S P ISR nodes C are set up for records of partition S P ISR nodes K are set up for records of partition S P and ISR nodes L are set up for records of partition S P. In some embodiments a give node of an ingestion subsystem a storage subsystem or a retrieval subsystem may be configured to handle data records of more than one partition or more than one partition of more than one stream . In some embodiments the records of a single partition of a given stream may be ingested stored or retrieved by more than one node. The number of ingestion nodes designated for a given partition Sj Pk may in at least some cases differ from the number of ingestion nodes designated for a different partition Sj P and may also differ from the number of storage nodes designated for Sj Pk and or the number of retrieval nodes designated for Sj Pk. With respect to ingestion and or retrieval SMS control nodes may implement APIs such as getStreamInfo in some embodiments to allow clients to determine which nodes are responsible for which partitions. The mappings between data records and partitions and between partitions and ISR nodes or control nodes configured may be modified over time as described below in the discussion regarding dynamic repartitioning.

In some embodiments several different programmatic interfaces may be implemented for retrieving or reading stream data records from a given partition. As shown in some retrieval interfaces may be implemented for non sequential accesses such as getIterator to instantiate an iterator or read cursor at or after a data record with a specified sequence number or getRecord to read a data record with a specified sequence number . Other retrieval interfaces may be implemented for sequential retrieval such as getNextRecords an interface requesting that N records be read from the current position of an iterator in order of increasing sequence number . In rotating disk based storage systems as mentioned earlier sequential I O may in many cases be much more efficient than random I O because the number of disk head seeks required on average per I O may typically be much lower for sequential I O than for random I O. In many embodiments the data records of a given partition may be written in sequence number order and as a result sequential read requests based on sequence number ordering e.g. using getNextRecords or a similar interface may be much more efficient than random read requests. In at least some embodiments therefore different billing rates may be set for sequential versus non sequential retrieval interfaces for example clients may be charged more for non sequential reads.

The received data records may be directed to any of several front end nodes e.g. A B or C in the depicted embodiment. In at least some embodiments the load distributor may not be aware of the partitioning policy in use for the data records and the front end node may therefore be chosen for a given data record using round robin load balancing or some other general purpose load balancing algorithm rather than partition based load balancing. The front end nodes may be aware of the partitioning policies for various streams and may interact with the ingestion control nodes to obtain the identities of the specific back end ingestion node e.g. A B or C that is configured for a given partition s data records. Thus in the depicted embodiment the front end nodes may each transmit data records to a plurality of back end nodes based on the respective partitions to which the data records belong. As noted earlier the partition to which a data record belongs may be determined based on any combination of various factors such as a partition key supplied by the data producer one or more other attributes such as the identity or address of the data producer or the contents of the data.

The back end nodes may each receive data records belonging to one or more partitions of one or more streams and transmit the data records to one or more nodes of the storage subsystem. The back end nodes may be referred to as PUT servers in some embodiments in which the data is submitted via HTTP HyperText Transfer Protocol PUT web service APIs. A given back end node may determine the set of storage subsystem nodes to which its data records are to be transmitted by submitting a query to a control node which in turn may submit a corresponding query to a control node of the storage subsystem in embodiments in which control functions for the different subsystems are handled by separate sets of nodes .

In at least some embodiments a number of different ingestion acknowledgement policies may be supported such as an at least once ingestion policy or a best effort ingestion policy. In an at least once policy the data producers may require positive acknowledgements for each data record submitted and may repeatedly submit the same data record if an acknowledgement of the first submission is not received until an acknowledgement is eventually received. In the best effort ingestion policy positive acknowledgements may not be required for at least some data records submitted although the ingestion subsystem may still provide occasional acknowledgements or may respond to explicit requests for acknowledgements from the data producers . In some embodiments in which the ingestion subsystem is required to provide acknowledgements to the data producers the back end ingestion node responsible for a given data record may wait until the required number of replicas of the data records have been successfully created at the storage subsystem e.g. in accordance with a persistence policy established for the stream before generating an acknowledgement. In various embodiments a sequence number may be generated by the ingestion subsystem for each data record received e.g. indicative of the order in which that record was ingested relative to other records of the same partition or stream and such a sequence number may be returned to the data producer as an acknowledgement or as part of an acknowledgement. Further details regarding sequence numbers are provided below with reference to and . The acknowledgement and or sequence number may be transmitted back to the data producer via a front end node in some implementations. In at least one implementation the at least once policy may be implemented between the front end and the back end nodes of the ingestion subsystem itself e.g. a given front end node may repeatedly submit a data record to the appropriate back end node until the back end node provides an acknowledgement.

Ingestion control nodes may be responsible for among other functions instantiating the front end and back end nodes monitoring the health and workload levels of the nodes orchestrating failovers as needed providing responses to queries regarding which nodes are responsible for a given partition or to policy related queries for ingestion related configuration operations resulting from dynamic repartitioning of streams. The number of ingestion control nodes designated for a given set of one or more streams may itself be changed over time in some embodiments e.g. one or more master control nodes may be responsible for reconfiguring the control node pool as needed. In some embodiments in which redundancy groups are set up for ingestion front end or back end nodes as described below in further detail with respect to and the control nodes may be responsible for keeping track of which nodes are primaries and which are non primary for detecting the triggering conditions for failover and for selecting replacements when failovers are required. It is noted that the multi layered ingestion subsystem architecture illustrated in may not be implemented in some embodiments e.g. only a single set of ingestion nodes may be configured in some scenarios.

Persistence policies may differ from one another in various ways in different embodiments. For example a persistence policy P applied to stream Sj may differ from a policy P applied to stream Sk in a the number of replicas of each data record to be stored b the type of storage device or system on which the replicas are to be stored e.g. whether replicas are to be stored in volatile memory non volatile caches rotating disk based storage solid state drives SSDs storage appliances of various kinds RAID redundant arrays of inexpensive disks of various kinds in database management systems at nodes of a storage service implemented by a provider network and so forth c the geographical distribution of the replicas e.g. whether the stream data is to be made resilient to large scale failures or certain types of disasters by placing replicas in different data centers d the write acknowledgement protocol e.g. if N replicas are to be stored how many of the N copies have to be written successfully before an acknowledgement should be provided to the ingestion node and or e whether in cases in which multiple replicas of data records are to be stored the replicas should be created in parallel or sequentially. In some cases in which multiple replicas are to be stored as in the case of data record D a given storage node may transmit the data record to another storage node e.g. storage node E sends data record D for further replication to storage node F and storage node F sends it on to storage node G . In other cases in which a multiple replica persistence policy is used as in the case of data record B for which two in memory replicas are to be stored the ingestion node may initiate the multiple replications in parallel. In at least some embodiments the client s chosen persistence policy may not specify the type of storage location to be used for stream data records instead the SMS may select the appropriate types of storage technology and or locations based on various criteria such as cost performance proximity to data sources durability requirements and so on. In one embodiment either the client or the SMS may decide to use different storage technologies or storage location types for different partitions of a given stream or for different streams.

In the example shown in the persistence policy applied to stream S or at least partition S P of stream S is a single replica in memory policy while for stream S a two parallel replica in memory policy is applied. Accordingly an in memory replica A of data record A is created at storage node A while two in memory replicas A and B corresponding to data record B are created in parallel at storage nodes B and C. For stream S s data record C a single on disk replica A is created. For stream S a sequential three replica on disk policy is applicable and as a result respective on disk replicas A B and C are created sequentially at storage nodes E F and G. Various other types of persistence policies may be applied to data streams in different embodiments. Nodes of the retrieval subsystem may obtain the data records from the appropriate storage nodes in response to invocations of various types of retrieval APIs by data consumers.

In the depicted embodiment a retrieval node may interact with one or more storage nodes and also respond to retrieval requests received from one or more SPS worker nodes . For example data records of partitions S P e.g. data record K and S P e.g. data record L are read from storage node A by retrieval node A and provided to worker nodes A and K respectively. Data records of partition S P such as M are read by retrieval node B from storage node A and provided to worker node K. Data records of partition S P are read by retrieval node C from storage node B and provided to worker node B and also to other data consumers e.g. data consumers that directly invoke SMS retrieval APIs instead of interacting with the SMS via an SPS .

In at least some embodiments some or all of the retrieval nodes may implement respective caches such as cache A at retrieval node A cache B at retrieval node B and cache C at retrieval node C in which data records of various partitions may be retained temporarily in anticipation of future retrieval requests. Retrieval control nodes may be responsible for implementing a number of retrieval policies including for example caching policies e.g. how large a cache should be configured for a given partition how long data records should be cached storage node selection policies e.g. which particular storage node should be contacted first to obtain a given data record in scenarios in which multiple replicas of data records are stored and so on. In addition retrieval control nodes may be responsible for instantiating and monitoring retrieval nodes responding to queries regarding which retrieval nodes are responsible for which partitions initiating or responding to re partitioning operations and so on.

In the illustrated example SPS comprises two processing stages A and B. SPS control nodes may be responsible for instantiating worker nodes at the various processing stages such as worker node A to process records of partition S P worker node B to process records of partition S P and worker node K to process records of partitions S P and S P. The SPS control nodes may implement programmatic interfaces such as those illustrated in and enabling SPS clients to design processing workflows. Various checkpoint policies may be implemented for different processing stages or workflows indicating when or if worker nodes are to store progress records indicating how far along they are in processing their respective partitions the types of storage devices to be used for the progress records and so on. Failover recovery policies may indicate the triggering conditions or threshold that are to lead to replacing a worker node with a different node and whether best effort recovery is to be used or checkpoint based recovery is to be used for a given processing stage. In at least some embodiments the SPS control nodes may interact with various types of SMS control nodes e.g. to identify the retrieval nodes from which data records of a given stream are to be obtained to establish new ephemeral or persistent streams that may be required for a particular processing workflow and so on. In at least one embodiment clients may interact with the SPS control nodes to instantiate streams e.g. instead of utilizing SMS control interfaces some clients may wish to invoke only higher level SPS interfaces. It is noted that although separate sets of control nodes are shown in for the SMS ingestion storage and retrieval subsystems and for the SPS stages in at least some embodiments a given control node may be used for several of the subsystems and or the SPS.

In at least some embodiments redundant groups of nodes may be configured for one or more subsystems of an SMS. That is instead of for example configuring one retrieval node for retrieving data records for a stream partition Sj Pk two or more nodes may be established for such retrievals with one node being granted a primary or active role at a given point in time while the other node or nodes are designated as non primary nodes. The current primary node may be responsible for responding to work requests e.g. requests received either from clients or from nodes of other subsystems. The non primary node or nodes may remain dormant until a failover is triggered e.g. due to a failure loss of connectivity to the primary or other triggering conditions at which point a selected non primary may be notified by a control node to take over the responsibilities of the previous primary. The primary role may thus be revoked from the current incumbent primary node during failover and granted to a current non primary node. In some embodiments non primary nodes may themselves take over as primary when a determination is made that a failover is to occur e.g. explicit notifications may not be required. Such redundant groups of nodes may be set up for ingestion storage retrieval and or control functions at an SMS in various embodiments and a similar approach may also be taken for worker nodes at an SPS in at least some embodiments. Such groups comprising at least one primary node and at least one non primary node for a given function may be referred to as redundancy groups or replication groups in some embodiments. It is noted that redundancy groups of storage nodes may be implemented independently of the number of physical copies of the data records that are stored e.g. the number of replicas to be stored of a data record may be determined by a persistence policy while the number of storage nodes that are configured for the corresponding partition may be determined based on redundancy group policies.

In some embodiments a provider network may be organized into a plurality of geographical regions and each region may include one or more availability containers which may also be termed availability zones herein. An availability container in turn may comprise one or more distinct locations or data centers engineered in such a way e.g. with independent infrastructure components such as power related equipment cooling equipment physical security components that the resources in a given availability container are insulated from failures in other availability containers. A failure in one availability container may not be expected to result in a failure in any other availability container thus the availability profile of a resource instance or control server is intended to be independent of the availability profile of resource instances or control servers in a different availability container. Various types of applications may be protected from failures at a single location by launching multiple application instances in respective availability containers or in the case of some SMSs and SPSs distributing the nodes of a given redundancy group across multiple availability containers. At the same time in some implementations inexpensive and low latency network connectivity may be provided between resources such as the hosts or compute instances used for SMS and SPS nodes that reside within the same geographical region and network transmissions between resources of the same availability container may be even faster. Some clients may wish to specify the locations at which their stream management or stream processing resources are reserved and or instantiated e.g. at either the region level the availability container level or a data center level to maintain a desired degree of control of exactly where various components of their applications are run. Other clients may be less interested in the exact location where their resources are reserved or instantiated as long as the resources meet the client requirements e.g. for performance high availability and so on. Control nodes located in one availability container or data center may be able to remotely configure other SMS or SPS nodes in other availability containers or other data centers in some embodiments that is a particular availability container or data center may not need to have local control nodes to manage the SMS SPS nodes.

Console services and associated with the SMS and SPS respectively may provide easy to use web based interfaces for configuring stream related settings in provider network in the depicted embodiment. A number of additional services at least some of which may be used by the SMS and or the SPS may be implemented in provider network using resources spread over one or more data centers or across one or more availability containers. For example a virtual computing service may be implemented enabling clients to utilize selected amounts of computing power packaged as compute instances of various different capability levels and such compute instances may be used to implement SMS and or SPS nodes. One or more storage services may be implemented enabling clients to store and access data objects with desired data durability levels e.g. either via a block device volume interface or via a web services interface. The storage objects may be attachable to or accessible from the compute instances of service and may be used to implement various stream persistence policies at SMS storage subsystems in some embodiments. In one embodiment one or more database services such as a high performance key value database management service or a relational database service may be implemented at the provider network and such a database service may be used for storing stream data records by SMNS storage subsystems and or for storing metadata of control subsystems ingestion subsystems storage subsystems retrieval subsystems or processing stages.

In at least some embodiments the users of the SMS and or the SPS may be provided a number of security related options for data streams enabling clients to select the security profiles of resources e.g. virtual or physical machines to be used for the various functional categories such as ingestion storage retrieval processing and or control. Such options may include for example choices regarding the types of physical locations of the resources used for various nodes e.g. whether provider network facilities are to be used or client owned facilities are to be used which may have different security characteristics than provider network facilities choices regarding encryption of stream data and or network isolation choices in various parts of the stream handling infrastructure. Some clients may be concerned about the possibility of intruders or attackers obtaining access to valuable proprietary business logic or algorithms for example and may wish to implement stream processing worker nodes using computing devices within client owned promises. The types of resources to be used for implementing a set of SMS and or SPS nodes may be referred to herein as the placement destination types for those nodes. illustrates a plurality of placement destination types that may be selected for nodes of an SMS or an SPS according to at least some embodiments.

Placement destinations may be selected within provider network for some types of SMS SPS functional categories e.g. ingestion storage retrieval control or processing and outside provider network for other types of SMS SPS functional categories in the depicted embodiment. Within provider network some resources such as compute instances storage instances or database instances may be implemented using multi tenant instance hosts . Such multi tenant instance hosts at each of which SMS or SPS nodes for one or more clients may be instantiated may form a first category A of placement destination types. To avoid having to share physical resources with other clients some clients may request that their SMS SPS nodes be implemented using instance hosts restricted to a single client. Such single tenant instance hosts may form placement category type B . Single tenant instance hosts may be preferable from the perspective of some clients for several reasons. As multi tenant instance hosts may include compute instances belonging to other clients there may be a higher probability of security attacks from another client s instances in multi tenant instance hosts than in single tenant instance hosts. In addition the noisy neighbor phenomenon in which one client s compute instance CI running on multi tenant host experiences a surge in workload and starts consuming a large proportion of the host s compute cycles or other resources thus potentially impacting the performance of another client s applications running on a different compute instance CI may also be avoided when single tenant instance hosts are used.

Isolated virtual networks IVNs such as IVN A and B may represent another category C of placement destination types in the depicted embodiment. An IVN may be created at the request of a provider network client in some embodiments as the logical equivalent of a private network built using provider network resources but with network configuration being controlled largely by the client. For example the client may decide the IP addresses to be used within an IVN without having to be concerned about the possibility of duplicating IP addresses that may already be in used outside the IVN. Implementing various types of SMS and SPS nodes in one or more IVNs may add an extra level of network security to the management and or processing of a client s stream data in the depicted embodiment. In some cases a given client may wish to place one functional category of SMS SPS nodes in one IVN and a different functional category in a different IVN. A given IVN may comprise either single tenant instance hosts multi tenant instance hosts or both types of instance hosts in various embodiments. In some embodiments another set of placement destination type choices or security profile choices using resources of the provider network not shown in may be available to at least some clients. In embodiments in which clients can acquire and use compute instances from a provider network s virtualized computing service for stream related operations the compute instances may be used in one of two modes. In one mode a client may provide to an SPS or an SMS the executable program or programs to be run at compute instances configured as SPS worker nodes or at ingestion storage or retrieval nodes and let the SMS or SPS run the programs and manage the nodes. This first mode may be referred to as a stream service managed mode of using compute instances for stream operations. In the other mode a client may wish to run the executable programs and manage the compute instances with less support from the SPS or SMS. This second mode may be referred to as a client managed mode of using compute instances for stream operations. These two modes of operation may thus represent additional choices with respect to client selectable placement destination types or security profiles. A client may opt for the client managed mode if for example the executable program is likely to require debugging including single stepping that can best be performed by subject matter experts from the client s organization while the stream service managed mode may be a reasonable choice for more mature code that is not likely to require debugging. In some embodiments different pricing policies may apply to these two modes.

A number of placement options may be supported at facilities external to the provider network in the embodiment shown in . For example hosts on which SMS libraries and or SPS libraries are installed may be used for stream management or processing from within client facilities e.g. client owned data centers or premises A or B with the two types of client facilities differing in their manner of connectivity to the provider network. Client facility A is linked to provider network via at least some shared Internet links i.e. the network traffic of other entities may also flow over some of the links between client facility A and the provider network . In contrast some client facilities such as B may be linked to the provider network via special unshared dedicated physical links which may sometimes be referred to as direct connect links These two different types of client premises comprise placement destination options D and E respectively in the terminology used in . In some embodiments portions of the SMS and or SPS may also be implementable at third party facilities e.g. data centers used but not owned or managed by clients of the SMS SPS and such third party premises may be designated as placement destination type F . In at least some of the client and or third party premises the SMS and or SPS libraries may have to be obtained from the provider network and installed on the hosts to be used for the SMS SPS nodes. In at least one embodiment nodes of all the different functional categories may be implemented externally to the provider network with the help of the appropriate libraries. The different placement destination types may differ from one another in various security related aspects in different embodiments such as the network isolation features implemented intrusion detection functionality supported physical security policies implemented supported encryption levels and so on. Accordingly each of the various destination types may be considered to have a respective security profile which may differ from the security profile of the other placement destinations in one or more ways. In some embodiments clients of the SMS and or SPS may select respective placement destination types for different subsystems or node sets programmatically e.g. by sending a request to one or more control nodes of the SMS or SPS as illustrated in . It is noted that in some embodiments and for certain types of stream applications clients may wish to control placement destination types not just for security reasons but also for performance and or functionality reasons. For example the noisy neighbor phenomenon described above may be avoided by using dedicated client premise resources or single tenant instance hosts. In some embodiments clients may have special purpose or proprietary hardware and or software that they wish to use for SPS stages or SMS nodes where the functional capabilities or performance levels achievable using such components cannot easily be replicated at a provider network or are simply not supported at the provider network. A client may have access at an external data center to a computer server with supercomputer level processing capabilities for example which may be able to perform SPS processing at a much higher rate than would be possible using provider network resources alone. Enabling a client to select the placement destinations for various nodes may allow such special purpose devices or software to be used.

Similarly in a client s SMS security option request comprises a number of elements that indicate the client s security preferences for one or more streams with specified identifiers . Placement destination type preferences for ingestion nodes storage nodes and retrieval nodes may be indicated in elements and respectively. PDT preferences for ingestion control nodes storage control nodes and retrieval control nodes may be indicated by elements and respectively. Encryption preferences for data records e.g. whether and or how encryption is to be implemented for the data records as they are transmitted from one category of node to another may be indicated via element . Using security option requests such as those shown in clients may be able to choose the locations e.g. within the provider network or external to the provider network and various other security profile components for different parts of their stream management and processing environment.

It is noted that the choice of node placement destinations may be offered for other reasons than security in at least some embodiments. For example a client may wish to have some types of SMS or SPS nodes implemented at single tenant hosts for performance reasons e.g. to avoid the noisy neighbor problems indicated earlier rather than primarily for security reasons. Placement choices may be changed in at least some embodiments during the lifetime of a stream e.g. a client may initially allow SMS nodes to be instantiated at multi tenant instance hosts but may wish to move at least some subset of the nodes to single tenant instance hosts later. Different pricing policies may be applied to the different security related options in at least some embodiments e.g. it may cost more to implement SMS nodes of a particular functional category at a IVN than at multi tenant instance hosts outside IVNs or it may cost more to implement SMS nodes at single tenant instance hosts than at multi tenant instance hosts.

For many types of stream applications data records may be received at the SMS at very high rates from a plurality of data producers and data consumers may typically wish to access stored data records in the order in which the records were generated. Especially in environments in which rotating magnetic disks are used as the storage devices for stream data records as mentioned earlier sequential I O access patterns for both reads and writes may have significant performance advantages over random I O access patterns. In several embodiments stream specific or partition specific sequence numbers may be assigned to data records as they are received by the SMS and sequential retrieval operations based on sequence numbers may be supported. illustrates example interactions between a stream data producer and an ingestion subsystem of an SMS according to at least some embodiments. The stream data producer may submit a data record to an ingestion subsystem and in the depicted embodiment the ingestion subsystem may respond with a sequence number that has been chosen for the submitted record. In at least some embodiments an ingestion node may obtain a portion of the sequence number from the storage subsystem e.g. the sequence number may be determined subsequent to the storage of the received data record in accordance with the applicable persistence policy in such embodiments and the storage subsystem may generate a numerical sequence indicator of its own for the data record and provide that indicator for inclusion in the larger sequence number assigned to the data record by the ingestion node.

Sequence numbers may be implemented in various embodiments to provide a stable consistent ordering of data records and to enable repeatable iteration over records by data consumers. Sequence numbers assigned to the data records of a particular partition may increase monotonically over time although they need not be consecutive in at least some implementations. In various embodiments sequence numbers may be assigned with at least some subset of the following semantics a sequence numbers are unique within a stream i.e. no two data records of a given stream may be assigned the same sequence number b sequence numbers may serve as indexes into the stream s data records and may be used to iterate over data records within a given stream partition c for any given data producer the order in which the data producer successfully submitted data records is reflected in the sequence numbers assigned to the data records and d sequence numbering for data records with a given partition key value retain the monotonically increasing semantics across dynamic repartitioning operations e.g. the sequence numbers assigned to data records with a partition key value K after a repartitioning may each be larger than any of the sequence numbers that were assigned to data records with that partition key value K prior to the dynamic repartitioning. Dynamic repartitioning is described in further detail below with respect to . 

In some embodiments a data producer may wish to influence the selection of the sequence number selected for at least some data records. For example a data producer may wish to demarcate boundaries or separators within the assigned sequence numbers of a stream so that it becomes easier for data consumers of that stream to submit read requests targeted at particular subsets of the stream. In some implementations the data producer may submit an indication of a minimum sequence number together with a record and the SMS may select a sequence number in accordance with the requested minimum that also conforms to the sequence number semantics discussed above.

Data records of a given partition may typically be written e.g. to disk in sequence number order often using large sequential write operations. In some embodiments as indicated earlier iterator based programmatic interfaces may be implemented to allow data consumers to read data records in sequence number order. illustrates examples of ordered storage and retrieval of stream data records at an SMS according to at least some embodiments. Six data records A F of a partition Sj Pk the kth partition of a stream Sj are shown stored in sequence number order. As illustrated the sequence numbers may not be consecutive in at least some embodiments e.g. because the manner in which the values are assigned to the timestamp portions or the subsequence numbers discussed above may not always result in consecutive values for those elements.

In the example shown in a data consumer has requested an iterator to be created specifying a starting sequence number 865 . In response to the request the SMS has initialized Iterator1 positioned at the data record with the nearest sequence number that is higher than or equal to the requested starting sequence number. In this case data record C with sequence number has been selected as the iterator s starting position as the next lower sequence assigned to data record B is smaller than the starting sequence number in the consumer s request. The getIterator interface may be considered the logical equivalent of a request to set a cursor at a requested position within the partition and the getNextRecords interface may be used to then read data records starting from the cursor position e.g. to move the cursor along the stream in sequence number order. In the illustrated example a data consumer has invoked the getNextRecords interface with parameter iterator set to Iterator1 and maxNumRecords the maximum number of data records to return set to 3. Accordingly the SMS retrieval subsystem returns the data records C D and E in that order to the data consumer. The iterator Iterator1 may be moved to a new position e.g. to data record F after the getNextRecords call completes and subsequent getNextRecord invocations for the same iterator may return data records starting with F. The semantics of the getIterator call may differ in some embodiments e.g. instead of positioning the iterator at the data record with the nearest sequence number higher than or equal to the specified sequenced number the iterator may be positioned at the nearest data record with highest sequence number equal to or lower than the requested sequence number in some embodiments. In another embodiment clients may have to specify an existing sequence number in the getIterator call e.g. an error may be returned if a record with the requested sequence number doesn t exist in the stream.

As described earlier the workload related to ingestion storage retrieval and processing of the records of a given stream may be subdivided and distributed among several nodes in various embodiments in accordance with various partitioning and repartitioning policies. illustrates an example of a stream partition mapping and corresponding configuration decisions that may be made for SMS and SPS nodes according to at least some embodiments. When a particular data stream is created or initialized e.g. in response to a client s invocation of a createStream API a partitioning policy may be activated for the stream which may be used to determine the partition of which any given data record of the stream is to be considered a member. The particular nodes of the ingestion subsystem the storage subsystem the retrieval subsystem and any relevant SPS stages that are to perform operations for a given data record may be selected on the basis of the record s partition. In one embodiment at least a subset of the control nodes used for a given data record may be selected based on the partition as well. In at least some embodiments dynamic repartitioning of a data stream may be supported as part of the partitioning policy e.g. in response to triggering conditions indicated in the policy or in response to explicit requests.

In various embodiments the partition selected for a given data record may be dependent on a partitioning key for the record whose value may be supplied by the data producer either directly e.g. as a parameter of a write or put request or indirectly e.g. the SMS may use metadata such as the identifier or name of the data producer client an IP address of the data producer or portions of the actual contents of the data record as a partition key . One or more mapping functions may be applied to the data record partition key or attribute to determine the data record partition identifier in the embodiment shown in . In one implementation for example a given partition identifier may represent a contiguous range over the space of 128 bit integer values such that the union of the ranges for all the partitions of the stream may cover all possible values a 128 bit integer can assume. In such an example scenario one simple mapping function may generate a 128 bit hash value from the partition key value s or selected attribute value s of the data record and the partition identifier may be determined based on the particular contiguous range within which the hash value happens to lie. In some implementations the contiguous ranges may at least initially be equal in size in other implementations different partitions may correspond to contiguous ranges that may differ in size from one another. Repartitioning may also result in adjustments to the range boundaries in one implementation. Other partitioning functions may be used in different implementations.

If the data stream undergoes dynamic repartitioning as discussed below in further detail the partition to which records with a particular key are mapped may change. Thus in at least some embodiments SMS and or SPS control nodes may have to keep track of several different mappings that apply to a stream during the lifetime of the stream. In some embodiments metadata such as a timestamp validity range or a sequence number validity range may be stored by the control nodes for each partition mapping. The timestamp validity range may for example indicate that a particular mapping M applies from the stream s creation time until time T that a different mapping M applies from T to T and so on. When responding to read requests directed at a stream the retrieval nodes may have to first determine which mapping is to be used depending for example on the sequence number indicated in a read request and then use that mapping to identify the appropriate storage nodes.

The SMS and SPS control nodes may be responsible for mapping partitions to resources at several different granularities in at least some embodiments. For example as shown in example implementations of in one implementation each ingestion storage retrieval or processing worker node may be implemented as a respective process or a respective thread of execution within a server virtual machine such as a Java Virtual Machine JVM or a compute instance and each JVM or compute instance may be instantiated at a particular physical host. In some embodiments multiple JVMs may be launched within a single compute instance adding another layer of resource mapping decisions. Thus for a given partition one or more control nodes may select which particular resources are to be used as ingestion nodes storage nodes retrieval nodes or processing stage worker nodes e.g. nodes A or B for stages PS or PS respectively . The control nodes may also determine the mappings of those nodes to servers such as ingestion servers storage servers retrieval servers or processing servers and the mappings between servers and hosts such as ingestion hosts storage hosts retrieval hosts or SPS hosts A B . In some implementations a partition mapping may be considered to comprise identification information e.g. resource identifiers at each of various resource granularities e.g. node server and host granularities illustrated an indication of the data record attributes being used as input to the function or functions as well as the functions themselves. The control servers may store representations of the partition mapping in a metadata store and in some embodiments may expose various APIs such as getPartitionInfo APIs or other programmatic interfaces to provide the mapping information to data producers data consumers or to the nodes of the SMS subsystems or the SPS.

The mappings of data records to partitions and from the partitions to the resources may be further complicated in some embodiments by various factors such as a a given node server or host may be designated responsible for multiple partitions in some embodiments or b failures or other triggers may result in new nodes servers or hosts being assigned to a given partition or set of partitions. In addition as indicated above and described below partition mappings for a given stream may be modified dynamically over time while the stream records continue to be handled by the SMS and or SPS nodes. As a result several versions of mapping metadata may be retained for a given stream at least temporarily in some embodiments each corresponding to a different period of time.

At time T stream S is dynamically repartitioned in the example timeline of . Data records continue to arrive and be handled by the SMS and the SPS in the depicted embodiment irrespective of when the repartitioning occurs neither the SMS nor the SPS need to be taken offline. The repartitioning may be initiated as a result of any of a number of factors e.g. in response to a detection of an overload condition at an ingestion storage retrieval or processing node in response to a detection of a skew or imbalance between workload levels at different hosts of the various subsystems or in response to a request from a data consumer or a data producer client. In the depicted embodiment a new mapping PM takes effect at time T or shortly after T as indicated by the validity range start timestamp setting shown for PM. In at least some implementations a different set of data record attributes may be used for partitioning data records than were used before the repartitioning. In some cases an additional partitioning attribute may be submitted by the data producer e.g. at the request of the SMS while in other cases the additional attribute may be generated by an SMS ingestion node. Such additional attributes may be referred to as salted attributes and the technique of using additional attributes for repartitioning may be referred to as salting . In one example implementation an overloaded ingestion server may indicate to a data producer e.g. to the SMS client library code being executed by the data producer that for repartitioning a randomly selected small integer value be provided in additional to the previously used partition key. The combination of the original partition key and the salted additional integer may subsequently be used to distribute the ingestion workload among a different set of ingestion nodes. In some embodiments the retrieval nodes and or data consumers may have to be informed regarding the additional attributes being used for repartitioning. Such additional attributes may not be used for repartitioning in at least some implementations.

In the embodiment shown in the new partition mapping results in different partitions being selected for at least some of the data records received after T relative to the partition selected for the same key before T. DRP is submitted after T with the partition key value Alice DRQ is submitted after T with the partition key value Bill and DRR is submitted after T with the partition key value Charlie . Using the PM mapping DRP is designated a member of partition P DRQ is designated a member of partition P while DRR is designated a member of partition P in the illustrated example scenario. In the depicted embodiment none of the example data records shown as being received after T are designated as members of the previously used partition P instead completely new partitions may be used after the repartitioning. In some embodiments at least some previously used partitions may continue to be used after repartitioning. For each of the new partitions P P and P different nodes may be designated for ingestion storage retrieval and or processing. For example nodes S R and W may be configured for partition P nodes IS S R and P may be configured for partition P and nodes S R and P may be configured for partition P. In some embodiments the same storage node may be used for a record with a particular partition key or attribute after repartitioning as was used for such records before repartitioning but a different storage location within that node e.g. a different disk a different disk partition or a different SSD may be used after the repartitioning.

During at least some time period after the dynamic repartitioning at T retrieval requests may continue to be retrieved for data records that were processed by the SMS ingestion and or storage subsystems prior to the repartitioning. In at least some cases the requested data records may have to be retrieved based on the PM mapping which was in effect at the time that the data records were ingested. Accordingly as indicated in for the purposes of data retrieval both PM and PM may continue to be used for some time after T. In at least some implementations data records may eventually be deleted from the stream as they age and the older partition mappings may also be discarded eventually e.g. when all the corresponding data records have themselves been deleted. In some embodiments instead of or prior to being deleted stream records may be archived e.g. based on client selected archival policies to a different set of storage locations or devices such that the partition mappings used by the SMS may still be usable to retrieve the records after archival. In such embodiments partition mappings such as PM and PM may be retained for as long as they are needed to support retrieval requests directed to the archival storage. In some archival implementations different retrieval approaches may be used that do not require the stream partition mappings to be retained e.g. new indexes may be created for the archived data records . In some embodiments a partition such as P that was being used prior to a repartitioning but to which writes are no longer directed after the repartitioning may at some point after the repartitioning be closed for reads e.g. the equivalent of an end of partition reached error message may be provided in response to retrieval requests.

In some implementations a given data stream may be divided into numerous e.g. hundreds or thousands of partitions. Consider an example case in which a stream S is initially divided into 1000 partitions P P . . . P. In the event that an overload condition corresponding to one partition say P is detected it may be worthwhile to change the initial mapping of data records to P but the mapping of the other partitions need not need to be changed. In one approach two new partitions P and P may be created via a repartitioning operation. Records received after the repartitioning whose attributes would originally i.e. on the basis of the original mapping have resulted in their membership in P may be mapped to either P or P after the repartitioning thus distributing the workload of P among two partitions. The remaining partitions e.g. P P and P P may not need to be modified. As only a small subset of partitions are affected by such a repartitioning in at least some embodiments a combined data structure such as a directed acyclic graph of partition entries or a tree of partition entries may be generated and stored. Each entry may indicate a partitioning function output range and a validity time range the time period during which the entry s partitioning information is to be considered valid . Assume in the example above that the repartitioning involving P was performed at time T while the stream S and its initial mapping was created at time T. In such a scenario the validity time period for the entry regarding P would be T to T the validity time periods for P and P would be T onwards and the validity time time periods for the remaining partitions would be T onwards . Using such a combined data structure may lead to a substantial reduction in the amount of memory or storage used for partition mapping metadata in at least some implementations. In the above example a split of partition P into two new partitions was discussed. In at least some implementations partitions may also be merged during repartitioning e.g. two adjacent partitions for which relatively few retrieval requests were received or relatively few records were submitted may be merged into a single partition. For any given point in time the partition to which a data record belongs may be determined unambiguously using the partitioning function and the validity time range information. Over time the combined data structure may evolve as more splits and or merges are performed but the total space required for the partitioning metadata may depending of course on how often splits occur and how many partitions are affected by the splits on average not increase dramatically. In contrast in a different implementation each time a repartitioning occurs the entire set of unchanged metadata for a stream may be replicated and combined with entries for the partitions affected by repartitioning. The storage and memory requirements for partition mapping metadata may increase at a much faster rate in the latter implementation especially if the older mappings may have to be retained for at least some time after repartitioning as described above.

In at least some embodiments in which sequence numbers that comprise timestamp values such as the timestamp value shown in are used a special type of sequence number transition may be implemented for dynamic repartitioning. Assume by way of example that a timestamp based sequence number scheme similar to that shown in is being used for a stream S in which new timestamp values are generated every second for inclusion in the sequence numbers. In at least some implementations in which dynamic repartitioning is supported the sequence numbers assigned after the dynamic repartitioning may all use a different set of timestamp values starting with a selected initial timestamp value corresponding to the repartition event than were used before the dynamic repartitioning. For example if the timestamp value in use at the time the dynamic repartitioning is committed i.e. put into effect was Tk any new sequence numbers issued after the commit may be required to use timestamp values Tk 1 onwards. Since sequence number values encode the timestamp value in at least some of their higher order bits in the scheme used in ensuring that repartition events correspond to timestamp boundaries as described may in turn simplify the bookkeeping involved in identifying the mappings to be used in response to a retrieval request. Thus in such implementations when a retrieval request specifying a particular sequence number is received the timestamp value may be extracted from that sequence number and it may be easily determined whether the post repartitioning mapping should be used or the pre repartitioning mapping should be used. If the extracted timestamp value is lower than the initial timestamp selected for the repartition the pre repartitioning mapping may be used and if the extracted timestamp value is equal to or higher than the initial timestamp value selected for the reparation the post repartitioning mapping may be used.

In some embodiments data producers may be required to submit explicit partition keys with write requests while in other embodiments the inputs to be used for the partitioning functions may be determined based on metadata associated with the write requests such as the identity of the data producers the IP addresses from which the data records are received or from the contents of the data records themselves. In at least one implementation clients may optionally supply partition identifiers in the data record submissions and additional partitioning functions may not be required in such an implementation.

A number of different factors may be taken into account when determining or configuring the initial set of nodes for ingestion storage and retrieval functions for the stream element . For example the partition mapping itself which may determine how many partitions the stream is divided into and the relative expected sizes of the partitions information about the expected ingestion rates and or retrieval rates if such information is available durability persistence requirements for the stream data records and or high availability requirements for the various subsystems which may result in the setting up of redundancy groups similar to those illustrated in may influence the number and placement of the nodes of the different subsystems. In addition in embodiments in which clients may indicate placement destination type preferences for various categories of nodes as illustrated in and such preferences may also play a role in determining the resources to be used for the SMS and or SPS nodes. In at least some embodiments respective pools of nodes capable of performing ingestion storage and or retrieval functions may be set up in advance and control components may assign selected members of such pools to each new stream that is created. In other embodiments at least in some cases new ingestion storage or retrieval nodes may have to be instantiated when a stream is created or initialized.

At the ingestion nodes in the depicted embodiment records may be received via any of a set of programmatic interfaces implemented for data record submission element including for example in line submission interfaces in which the data is included in the submission requests and by reference submission interfaces in which an address is provided in the submission requests from which the data can be retrieved by the SMS ingestion nodes or the SMS storage nodes e.g. using web service requests or other interfaces . Any of a number of different types of programmatic interfaces may be provided in different embodiments for each of the ways of submitting records e.g. respective application programming interfaces APIs may be supported for in line versus by reference submission web pages or web sites may be established graphical user interfaces may be implemented or command line tools may be developed. In at least some embodiments the SMS may assign a sequence number to each ingested record e.g. indicative of the order in which the records are ingested or stored and the sequence numbers may be usable for retrieval requests by data consumers. At the retrieval subsystem nodes record retrieval requests may be received via any of a set of implemented programmatic retrieval interfaces and contents of the requested data records may be provided in response element . For non sequential access the interfaces may include for example getIterator requesting an iterator to be instantiated at a position selected within a partition based on a sequence number indicated in the getIterator invocation or getRecordWithSequenceNumber to obtain a data record with a specified sequence number . For sequential access interfaces such as getNextRecords requesting a number of records in order starting from a current position of an iterator or from a specified sequence number may be implemented. In at least some embodiments different retrieval interfaces may have different billing rates associated with them e.g. the per record billing rates for sequential retrieval may be set lower than the per record billing rates for non sequential retrieval. The different submission interfaces may also have different billing rates in some embodiments e.g. by reference submissions may cost more per record than inline submissions.

Over time control nodes or specialized billing servers may collect usage metrics for the different programmatic interfaces implemented at the various subsystems of the stream management service element . The metrics may include for example invocation counts of the different programmatic interfaces the total number of records ingested or retrieved which may differ from invocation counts for at least some interfaces such as getNextRecords that can be used to retrieve multiple records with a single invocation the total amount of data ingested or retrieved and so on. Billing amounts to be charged to the clients that own the stream or clients that produce and or consume data from the stream may optionally be generated based at least in part on the usage metrics and the respective billing rates associated with the programmatic interfaces element . In at least some embodiments the billing activities may be asynchronous with respect to the stream ingestion retrieval operations e.g. a bill may be generated at the end of a monthly billing period based on the metrics collected during the month.

Any of a number of different recovery policies may be implemented for SPS stages in some embodiments including for example a checkpoint based recovery policy or a best effort recovery policy. In one embodiment a client may use a programmatic interface to select recovery policies for different SPS stages. At stages for which a checkpoint based recovery is used worker nodes may be configured to store progress records or checkpoints at intervals indicating how far along in a stream partition they have reached for example the sequence numbers of the most recently processed records may be stored as indicators of the progress . The progress records may be used later during recovery operations after failures as described below with reference to . In a best effort recovery policy progress records need not be stored and replacement worker nodes configured in response to a failure may simply process new data records as they are received. Within a given SPS stage graph or workflow in some embodiments different recovery policies may be applied to different stages.

An SPS control server may receive e.g. via one of the programmatic interfaces indicated in element an indication of the idempotent operation Op to be performed at a particular stage PS of a stream S in accordance with a partitioning policy PPol with the results of the processing to be distributed in accordance with output distribution descriptor DDesc element . The number of worker nodes to be configured for state PS and the virtual or physical resources needed for the nodes may be determined e.g. based on various factors such as the Ppol the complexity of the idempotent operations Op and the performance capabilities of the resources to be used for the worker nodes element .

The worker nodes may then be instantiated and configured element e.g. as processes or threads at selected virtual or physical machine resources. In one simple implementation for example one worker node may initially be assigned for each partition of S. A given worker node may be configured to a receive data records from the appropriate subset of S s retrieval nodes b perform Op on the received data records c optionally e.g. based on the recovery policy for PS store progress records checkpoints indicating which set of partition records have been processed and d transmit output to destinations indicated by DDesc e.g. as inputs to intermediate persistent or ephemeral streams or directly to other processing stages or storage systems . It is noted that at least in some embodiments the SPS processing may not necessarily generate any output that has to be transmitted elsewhere on an ongoing basis. For example some SPS applications may simply serve as temporary repositories of data records and or may implement query interfaces enabling users to view the data records. Such an application may manage its own output e.g. output may be generated in response to received queries and not in accordance with a distribution descriptor. A logging related SPS application may retain the last day s log records collected from a large scale distributed system for example enabling clients to view logging data for debugging or analysis purposes. Accordingly in some embodiments output distribution descriptors need not be specified for at least some stages of an SPS for at least some streams or for at least some partitions. The worker nodes may then initiate retrieving and processing data records as per their respective configuration settings element . The SPS control nodes may monitor the health status e.g. using responsiveness checks such as a heartbeat protocol of the worker nodes as well as various other metrics such as the resource utilization levels at the resources being used for the worker nodes element in at least some embodiments. The information collected from the worker nodes may be used to determine whether a failover is required e.g. if a worker node should be replaced and a recovery policy implemented as described below.

In some embodiments an installable SPS client library may be provided to those clients that wish to implement SPS worker nodes at client owned premises and or at client selected resources of the provider network. The client library may also allow SPS clients to select the extent to which they wish to use various control plane features of an SPS managed service such as health monitoring functions automated workload monitoring and balancing security management dynamic repartitioning and the like. is a flow diagram illustrating aspects of operations that may be performed in response to invocations of components of a client library for configuration of stream processing worker nodes according to at least some embodiments. As shown in element an SPS client library may be provided e.g. via download from a web site of a multi tenant SPS managed service configurable to perform the kinds of operations illustrated in . The library may include a number of executable components and or components that can be linked to client applications. Some library components may enable clients to select register with the SPS managed service or specify desired properties of various worker nodes at which stream processing operations of one or more SPS stages are to be performed. For example one client may wish to use their own set of compute instances implemented at a virtual computing service of a provider network for the worker nodes while another client may wish to use computing devices located at the client s own data center such as special purpose devices not supported by the provider network for processing stream records. Clients may bring worker nodes online on an as needed basis at their own premises or using compute instances of the virtual computing service as desired. In addition to or instead of such an on demand instantiation of worker nodes in some embodiments clients may preconfigure pools of potentially re usable worker nodes that can be deployed when needed. In some implementations a library component may be executed or invoked to allow a client to register with the SPS managed service a particular process or thread instantiated by the client as a worker node of a specified stage for which subsequent control plane operations may be handled by the SPS managed service. In one embodiment the client may also be able to select from among different levels of control plane responsibilities to be handled by the SPS managed service for the worker nodes for example one client may wish to use their own custom modules to monitor worker node health while another client may wish to utilize the SPS managed service for monitoring worker node health and taking the appropriate actions if a failure is detected.

The SPS managed service may receive an indication that a particular client wishes to use the client library for configuring worker nodes and or control plane operations of a particular SPS stage PS element . PS itself may be designed using programmatic interfaces included in the library or using programmatic interfaces exposed by the SPS managed service similar to the web based interface illustrated in . The client may also indicate the streams whose data is to be retrieved for use as input by PS. Optionally in at least some embodiments the client may indicate control plane settings for PS e.g. whether the client wants to use the service s health monitoring capabilities for the nodes or is willing to use custom health monitoring tools element . Depending on the preferences indicated by the client one or more nodes of the SMS and or SPS to be configured for the client s use may be determined element . Network connectivity may be established between the client s worker nodes to the SMS SPS nodes and or other configuration operations may be performed to enable the flow of data records and processing results as desired. Data records may be provided to SP worker nodes upon receiving retrieval requests and desired control plane operations if any were requested by the client may be performed as needed. It is noted that at least in some embodiments a similar approach enabling clients to control the extent to which they wish to use the control plane functionality of various subsystems of an SMS managed service may also or instead be implemented.

If a best effort recovery policy is to be used at the SPS stage at which the particular worker node was active as determined in element the replacement worker node may simply start processing additional data records as they become available element e.g. no record of the replaced worker node s progress need be examined. If a checkpoint based recovery policy is to be used an indication of the location e.g. a storage device address or a URL at which the replacement worker node may access the progress records stored by the replaced worker node may be provided element . The replacement worker node may retrieve the most recent progress record stored by the replaced node and use the progress record to determine the set of data records on which the replacement worker node should perform the idempotent operations of the stage element . In such a checkpoint based recovery policy depending on the duration between the last progress record and the time at which the replacement worker node is instantiated as well as on the rate at which the replaced worker node had processed additional records subsequent to the progress record being stored some number of data records may be processed more than once. If the operations being performed are idempotent such repeat operations may have no negative effects in at least some embodiments. After the replacement worker node has performed the repeat recovery operations based on the earlier stored progress record in at least some embodiments the replacement worker thread may store its own progress record indicating that recovery is complete and may start normal worker thread operations on newly received data records element .

A client s security profile choices or preferences regarding nodes of one or more functional categories for a stream S may be received via the security related programmatic interfaces. For example the client may select one security profile for nodes of functional category FC e.g. the client may wish to implement SPS worker nodes at client owned premises and a different security profile for nodes of a different functional category FC e.g. the client may be willing to implement SMS ingestion nodes or storage nodes at provider network data centers element . In some cases a client may decide to set up nodes of all the different functional categories with the same security profile. The SMS and or the SPS may define default placement destination types for the various functional categories in some embodiments e.g. unless a client indicates otherwise nodes of all the functional categories may be set up within isolated virtual networks of a provider network.

The nodes of the different functional categories may then be configured based on the client s preferences for security profiles and or locations or based on default settings for the functional categories for which the client does not provide preferences element . The configuration may involve for example selecting the appropriate physical hosts or machines and instantiating the appropriate compute instances virtual machines processes and or threads for the nodes of the different functional categories and establishing the appropriate network connections between the nodes. In some embodiments executable library components for the different stream management and processing functions may be provided for installation at hosts external to the provider network as part of the configuration.

According to at least some embodiments encryption modules may be activated at one or more categories of the nodes e.g. in accordance with the client s expressed encryption preferences or based on default encryption settings element . The nodes of the various functional categories may then be activated so that the stream data is ingested stored retrieved and or processed as desired by the client element .

As the data records of the stream are received their respective partitions may be determined based on the supplied keys and or other attributes and the appropriate set of ingestion storage and retrieval nodes may be selected for the identified partition element . In at least some embodiments respective sequence numbers may be generated for the data records e.g. indicative of the sequence in which the records of a given partition were received element . The sequence numbers may comprise a number of elements in some implementations such as timestamp values e.g. the number of seconds elapsed since a well known epoch such as 00 00 00 UTC Jan. 1 1970 subsequence values obtained from a storage subsystem version numbers of the SMS software and or the partition identifiers. The sequence numbers may be provided to the data producers in some embodiments e.g. to acknowledge the successful ingestion of the submitted data records. The sequence numbers may also be used by data consumers to retrieve the data records of a stream or a partition in ingestion order in some embodiments.

The data records may be stored in sequence number order in at least some embodiments at the storage nodes to which they are directed based on the partitioning policy element . In embodiments in which rotating magnetic disks storage devices are used sequential writes may typically be used to save the received data records to disk thereby avoiding disk seek latencies. In at least some implementations non volatile buffers may be used as write caches prior to storing the records to disk e.g. to further decrease the probability of disk seeks. In response to requests for reads of multiple data records ordered by sequence number e.g. invocations of getNextRecords or similar interfaces the data records may later be read using sequential reads from the storage devices element .

A modified partition mapping different from the mapping in use at the time of the repartitioning decision may be generated for the stream element . The changed mapping may map data records with a particular partition key to a different partition than data records with the same key were mapped to before the repartitioning in at least some embodiments. Some partitions typically heavily used partitions may be split while other typically lightly used partitions may be merged depending on the triggering conditions for the repartitioning and or on observed workload metrics. A different partitioning function may be used after the repartitioning than before the repartitioning in some embodiments e.g. a different hash function or a different approach to the subdivision of hash function results into partitions may be used. In some implementations for example in which the partitions correspond to contiguous ranges of 128 bit integers the 128 bit integer space may be divided into a different set of sub ranges after the repartitioning. In at least some embodiments new sets of ingestion storage retrieval processing or control nodes may be assigned to the newly created partitions. In some implementations a space efficient combined data structure may be used to represent both the initial mapping and the modified mapping element . For example a directed acyclic graph or tree structure may be stored in which each entry contains an indication of a partitioning function output range e.g. the range of a partitioning hash function s results that correspond to a given partition and a validity time range so that only the records corresponding to modified partitions need to be altered as a result of a repartitioning. Entries for partitions that remain unaltered during a repartitioning may not need to be modified in the data structure. The new nodes may be configured to implement the modified partition mapping element . In at least some embodiments since retrieval requests for data records stored on the basis of the earlier mapping may continue to be received for at least some time the previous nodes and the previous mapping may be retained for some time. When a read request specifying a particular sequence number or timestamp is received element a determination may be made e.g. at a control node or at a retrieval node as to whether the read request is to be satisfied using the new partition mapping or the previous partition mapping. The selected mapping may then be used to identify the appropriate storage node from which the requested data is to be obtained.

A request may be received via one of the programmatic interfaces indicating a particular ingestion policy to be used for a specified stream element . Ingestion nodes may be instantiated in accordance with the partitioning policy in effect for the stream element . When one or more submissions of the same data record are received at an ingestion node element different actions may be taken dependent on the ingestion policy in effect. If the at least once ingestion policy is in use as determined in element an acknowledgement may be sent to the data producer for each of the one or more submissions but the data record may be saved only once at the storage subsystem . It is noted that in accordance with the persistence policies in effect for the stream N replicas of a given record may be stored in some cases but if a given data record is submitted M times the replicas may be generated only for one of the submissions i.e. the total number of record replicas stored would still be N and not N M. If a best effort ingestion policy were in effect as also detected in element the data record may still be saved once at a storage device but no acknowledgement need be sent to the data producer element . In at least some embodiments client billing amounts may optionally be determined based at least in part on the ingestion policy selected element . As noted earlier in some embodiments two versions of an at least once ingestion policy may be supported. In one version similar to that illustrated in the SMS may be responsible for de duplicating data records i.e. ensuring that data is stored at the SMS storage subsystem in response to only one of a set of two or more submissions . In a different version of at least once ingestion duplication of data records by the SMS may be permitted. The latter approach may be useful for stream applications in which there are few or no negative consequences of data record duplication and or for stream applications that perform their own duplicate elimination.

A set of ingestion nodes may be determined or configured to receive the data records of the selected stream from data producers and a set of storage nodes may be configured to implement the selected persistence policy element . When a data record is received at an ingestion node element one or more copies of the data record may be stored based on the selected persistence policy at selected storage devices by the storage nodes responsible for the partition to which the data record belongs element . In at least some implementations billing amounts may optionally and or asynchronously be determined based on the specific persistence policies selected by the client element .

In some embodiments a substantial portion or all of the control plane functionality of an SPS may be implemented in a decentralized manner e.g. by the worker nodes within a given SPS stage coordinating various control operations such as partition assignment to the worker nodes responses to dynamic repartitioning health monitoring and or load balancing via a shared data structure such as a database table. A given worker node W may inspect entries within the shared data structure to determine for example which partitions of the stage s input streams if any are currently not being processed. If such a partition P is found W may update an entry in the shared data structure to indicate that W will perform the stage s processing operations on P s records. Other worker nodes may learn that W is assigned to process P records and may therefore assign different partitions to themselves. Worker nodes may periodically or occasionally submit queries to the SMS control plane to determine the current partition maps in effect for the input stream and update the shared data structure to indicate map changes e.g. as a result of repartitioning as necessary. Load balancing and other operations may also be coordinated via the shared data structure in various embodiments as described below. In some such decentralized implementations dedicated control nodes may not be required for the SPS thereby reducing the overhead required to implement SPS workflows. Such decentralized SPS control plane implementations may be especially popular with budget conscious customers that utilize SPS client libraries to implement various aspects of stream processing e.g. at compute instances within the provider network that are assigned to the customers or at locations outside the provider network. Decentralized SPS control plane techniques may also be used in embodiments in which client libraries are not used e.g. when all the resources used for the SMS and SPS are configured within a provider network. An SPS at which the worker nodes implement some or all of the SPS control plane functions for at least some processing stages may be referred to herein as a decentralized control SPS .

A given worker node may be configured to select by examining the entries in the PA table a particular partition on which to perform the processing operations of the stage. In one implementation the worker node A may scan the entries in the PA table A until it finds an entry of an unassigned partition Pk and may attempt to assign the partition Pk to itself by updating the entry e.g. by inserting the worker node s identifier into one of the columns of the entry. Such an insertion may be considered analogous to locking the partition by the worker node. Depending on the type of database service being used different approaches to managing potentially concurrent writes to PA table entries e.g. by two or more worker nodes that happen to identify an unassigned partition at close to the same time may be used.

In one embodiment a non relational multi tenant database service of a provider network may be used which supports strong consistency and conditional write operations without necessarily supporting relational database transaction semantics. A conditional write operation may be used in such a case for the updates by the worker nodes. Consider an example in which a column worker node ID is used to indicate the identifier of the particular worker node assigned to a partition in the PA table and that the column s value is set to null if no worker node is assigned to the partition. In such a scenario a worker node with identifier WID may request the logical equivalent of the following if in the entry for partition Pk worker node ID is null then set worker node ID for that entry to WID . If such a conditional write request succeeds the worker node with identifier WID may assume that partition Pk is assigned to it. The worker node may then start retrieving data records of partition Pk e.g. using record retrieval interfaces of SMS retrieval subsystem as indicated by arrows e.g. arrows A B K and L for worker nodes A B K and L respectively and performing the processing operations on the retrieved records. If the conditional write fails the worker node may resume a search for a different unassigned partition. In other embodiments database services such as relational databases that support transactions may be used and the transaction functionality may be used to implement the equivalent of the conditional write operations e.g. to ensure that only one of a plurality of concurrent or near concurrent attempts to assign a partition to a worker node succeeds and that the worker nodes involved in such concurrent attempts are reliably informed of their success or failure. Synchronization techniques that rely neither on conditional writes nor on transaction support may be used in some embodiments. In some implementations a database service may not be used instead a locking service may be used by the worker nodes to acquire exclusive access for updates to the entries in persistent data structures analogous to the PA tables.

Other worker nodes may examine the entries in the PA table determine which partitions are unassigned and may eventually succeed in assigning one or more partitions to themselves. In this way the processing workload for the partitions of the stage s input stream or streams may eventually be distributed among themselves by the stage s worker nodes.

The initial partition mapping of any given stream may change over time e.g. as a result of the dynamic repartitioning operations described earlier. Accordingly in the embodiment depicted in one or more of the worker nodes may occasionally or in response to triggering conditions as described below submit requests to the SMS control subsystem of their stage s input stream s to obtain the current partition metadata. In some implementations such requests may comprise invocations of SMS control plane APIs such as the invocations of a getStreamInfo API indicated by arrows A B K and L. The SMS control subsystem may for example respond with an up to date list of partitions of the stream and or other details such as the validity time periods of the partitions. If the partition information provided by the SMS control subsystem does not match the entries in the PA table the PA table may be modified by the worker node e.g. by inserting or deleting entries for one or more partitions. Such requests to the SMS control subsystem may typically be much less frequent than the record retrieval requests and or the database read or write operations in at least some embodiments as indicated by the label infrequent of arrow A. For example once it is assigned a partition a worker node may typically keep retrieving and processing that partition s data records until the partition data is fully consumed e.g. if the owner of the stream closes the stream or if the partition is closed as a result of dynamic repartitioning or until some other low probability circumstance is encountered e.g. if a different worker node requests a transfer of the partition due to detected load imbalance as discussed below . Thus the overhead associated with invoking the getStreamInfo or similar APIs may typically be quite small in various embodiments even if a substantial amount of information is provided in response to any given invocation as might be the case if hundreds or thousands of partitions are defined for a stage s input stream .

Some of the key workload management operations of a decentralized control SPS environment may thus be summarized as follows in the embodiment depicted in a selecting based at least in part on accessing a database table by a first worker node of a stream processing stage a particular partition of an input data stream of the stream processing stage on which to implement a set of processing operations defined for that stage b writing into a particular entry stored in the table an indicator of an assignment of the particular partition to the first worker node c retrieving by the first worker node records of the particular partition using programmatic record retrieval interfaces implemented at a multi tenant stream management service d implementing by the first worker node the set of processing operations on the records of the particular partition e determining by a second worker node based at least in part on the particular entry in the particular database table that the first worker node is assigned to perform the set of processing operations on the particular partition and f selecting by the second worker node a different partition on which to perform the set of processing operations. If and when a worker node determines that no more records remain in a partition assigned to it the worker node may request metadata on the input stream from the SMS control subsystem and may update the PA table if the metadata indicates a discrepancy.

It is noted that the partition list maintained by the SMS control subsystem e.g. as part of the partition entry tree graph or other combined data structure described earlier may at least at some points in time include more partitions than are included in the PA table in some embodiments. In the depicted example the partition list includes partitions P P P P and P of which P and P are shown in a closed state as a result of repartitioning while P P and P are shown as active i.e. partitions whose data records are currently being retrieved and processed . The PA table includes entries for the active partitions in the depicted embodiment and does not include entries for the closed partitions which may have been deleted by worker nodes when they obtained responses to getStreamInfo invocations after the repartitioning took place for example . At least in some implementations not all the currently open partitions of the stream may necessarily have respective entries in the PA table at a given point in time instead for example only a subset of those partitions that are currently assigned or being processed may be represented.

In the example scenario illustrated in partitions P and P are assigned to worker nodes with identifiers W and W respectively while P is currently unassigned. The health indicator column may store different types of values in different implementations. In some implementations the worker nodes may be responsible for periodically e.g. once every N seconds or according to a schedule based on some set of heuristics updating the contents of the health indicator columns in the PA entries of their assigned partitions to indicate that the worker nodes are active and able to continue their retrieval and processing operations. In an indication of the most recent time that the worker node for that entry updated the health indicator column last modified time may be stored e.g. worker W is shown as having modified the entry at 02 24 54 and 53 seconds on Dec. 1 2013. Other worker nodes may use the last modified time value to determine whether the assigned worker node is healthy or not in some embodiments e.g. if X seconds or minutes have elapsed as defined in a failover policy for the stage the assigned worker node may be assumed to be unhealthy or inaccessible and the partition may be reassigned. In other implementations a counter may be used as a health indicator e.g. if the counter value has not changed in Y seconds the assigned worker node may be deemed a candidate for failover or a last read time value indicating when the assigned worker node last read the entry may be used.

In at least some embodiments a workload level indicator value may be stored in the entry e.g. by the assigned worker node such as the number of records processed during some recent time interval e.g. in the five minutes prior to the last modified time recent performance related metrics of the worker node such as CPU utilization memory utilization storage utilization and the like. Such workload level indicator values may be used in some embodiments by the worker nodes to determine whether load imbalances exist as described below with respect to and to take actions in response to detected imbalances. For example a worker node Wk may determine that its workload level is above the average workload level and may un assign one of its partitions or may request a dynamic repartitioning alternatively the worker node Wk may determine that its workload is too low relative to that of other worker nodes or partitions and may assign additional partitions to itself. Thus using the columns of the PA table indicated in worker nodes may perform some of the same types of control plane functions in the depicted embodiment that may typically be performed by dedicated SPS control nodes in centralized control SPS implementations

As the worker nodes come online they may each access PAT to try to find partitions that are unassigned. For example worker node W may examine PAT and find that partition P is unassigned element . W may then update P s entry in PAT e.g. using a conditional write request or a transactional update request depending on the type of database service being used to indicate that P is assigned to W element . Having updated the table W may initiate retrieval of data records of P using SMS retrieval subsystem interfaces element and may perform the processing operations of the stage PS on the retrieved records.

Meanwhile at some point in time a different worker node W may access PAT in its own attempt to find unassigned partitions element . W may determine based on W s earlier update that P is already assigned but that a different partition P is not assigned. In some embodiments a determination by W that the current assignee worker node of P is unhealthy or inactive e.g. based on the health indicator column in P s entry may also lead W to select P. Thus in at least some embodiments either an unassigned state or a determination of an unhealthy state of a current worker node may be used to select a given partition for reassignment or initial assignment . W may then attempt to update PAT to assign P to itself element . If the update succeeds W may start retrieving P records using SMS retrieval interfaces element and performing the appropriate processing operations defined for the stage.

As mentioned earlier the worker nodes in a decentralized control SPS may typically infrequently obtain partition mapping information from the SMS and use such information to update the PA table if necessary. illustrates aspects of operations that may be performed by worker nodes of a stream processing stage to update a partition assignment table based on information obtained from a stream management service control subsystem according to at least some embodiments. As shown in element during worker node initialization or in response to various triggering conditions such as the closing of one of the partitions assigned to it a worker node W may submit a request to the SMS control subsystem to obtain the latest or current partition list or the active partition list. In some implementations a getStreamInfo or similar API may be invoked for this purpose. Other triggering conditions may be used in some embodiments e.g. the worker nodes may each be configured to obtain fresh partition lists after random amounts of time or in response to unexpected drops or increases in workload levels. The partition list returned by the SMS may be compared with the entries in the PA table for the partition element . If a discrepancy is found e.g. if there is some partition in the freshly obtained partition list that is not in the PA table or if there is an entry in the PA table that is not in the SMS s list the worker node may insert or delete entries in the PA table to resolve the discrepancy in the depicted embodiment element . Additional coordination may be required if an entry that is targeted for deletion currently has an assigned worker node in some implementations e.g. the assigned worker node may be notified either directly or via the PA table itself. 

After the discrepancy is rectified or if no discrepancy was detected the worker node W may select a set of partitions on which it should perform the stage s processing operations element and may update the PA table accordingly. In some cases depending on the triggering condition that led to the partition list being retrieved W may already have one or more partitions assigned to it and may not need to make changes to its assignments or update the PA table. W may then proceed to retrieve the data records of its assigned partition or partitions and process the records without having to interact with the SMS control subsystem or changing the number of entries in the PA table element . Eventually when a triggering condition is detected e.g. when the equivalent of an end of partition reached response is received to a retrieval request indicating that the a partition is closed W may again send a request to the SMS control subsystem for fresh partition information and the operations of elements onwards may be repeated.

W may then compare its own workload based for example on the number of partitions assigned to W and or the per partition workload level indicators to some or all of the metrics. In general any of three types of conclusions may be drawn that W is overloaded that W is under loaded or that W s workload is neither too high nor too low. Workload levels that are too high or too low may be defined by policies selected by the clients on whose behalf the stage is configured in some embodiments or using some default set of heuristics in other embodiments. If W determines that its workload is too low element e.g. below some minimum load threshold T a busier or more highly loaded worker node Wk may be identified element . W may then initiate a process of transferring one or more partitions Pm from Wk to itself element e.g. by attempting to modify the Pm entry in the PA table requesting such a modification which may result in a notification being generated for Wk or by requesting Wk directly.

If W determines that its workload is too high element e.g. above a maximum threshold T it may identify one or more of its assigned partitions Pn to relinquish i.e. to release for assignment by other worker nodes element . W may then modify the appropriate entries in the PA table e.g. by removing its identifier from the assignee column of the entry for Pn element . If W s workload was neither too high nor too low or after W has taken the kinds of actions described above to increase or decrease its workload W may resume processing records of the partitions to which it is assigned element . Operations corresponding to elements onwards may be repeated when and if conditions triggering another load balancing analysis are met. It is noted that in the operations illustrated in W is shown as initiating workload changes only when it detects an imbalance with respect to its own workload. In other embodiments W may initiate rebalancing actions if it detects imbalances among other worker nodes than itself e.g. if it determines that W has a much lower workload level than W. In some implementations W may request or initiate dynamic repartitioning e.g. by invoking a repartitionStream SMS API such as that shown in or its equivalent if and when it detects workload imbalances. In some embodiments the kinds of operations illustrated in may be performed by a newly configured worker node e.g. when new nodes are added to a stage after the stage has already been in operation for some time the new nodes may indirectly notify the existing nodes of their presence by requesting reassignment of partitions from heavily loaded existing nodes. In some embodiments decentralized control techniques similar to those described above for SPS worker nodes may also or instead be used at one or more SMS subsystems e.g. the nodes of the ingestion storage or retrieval subsystems may coordinate their workloads using shared data structures similar to the PA tables.

For some types of stream applications clients may prefer that if the same data is submitted more than once by a data producer the SMS should recognize and eliminate duplicates. In large scale streaming environments in which hundreds or thousands of data producers submit their data records over network paths with potentially varying levels of reliability and varying transfer latencies a given data producer may end up submitting the same data again if for example a timely acknowledgement is not received for a previous submission. If the SMS is able to detect and remove duplicates less storage may be used for the stream as a whole and data consumers such as SPS applications may not have to devote resources to de duplication. A number of different approaches to de duplication at one or more SMS subsystems may be taken in different embodiments.

As indicated above a number of SMS ingestion nodes may be configured to receive stream data records in accordance with various stream partitioning policies in some embodiments. illustrates aspects of a decentralized de duplication mechanism that may be employed at the ingestion subsystem of a stream management system according to at least some embodiments. The mechanism may be considered decentralized in that duplicate detection and elimination may be performed at a per partition granularity without having to access stream wide data structures. As shown ingestion subsystem may comprise ingestion nodes e.g. A and B each responsible for handling data submission requests for one or more partitions of one or more streams submitted by data producers e.g. A or B using SMS client library . For example ingestion node A may be responsible for handling submissions of at least partition Sj Pk the kth partition of stream Sj in the depicted embodiment while ingestion node B may be configured to receive data records of at least partition Sj Pn the nth partition of stream Sj . Both data producers may submit data belonging to any partition in the depicted embodiment.

Each of the ingestion nodes may instantiate one or more local de duplication tables e.g. local de duplication table A for partition Sj Pk at node A and local de duplication table B for partition Sj Pn at node B. Each local de duplication table may include respective de duplication signature entries for some number of data records of the corresponding partition. Since the data records of a given partition would always be directed to the same ingestion node in accordance with the stream s partitioning policy at least in the absence of failovers which may be dealt with by reconstructing de duplication tables at newly configured replacement ingestion nodes as described below in the depicted embodiment the local de duplication tables may generally suffice for duplicate detection and a centralized repository of de duplication information is not required. Different types of de duplication signatures may be employed in various implementations to efficiently detect duplicate submissions. A de duplication signature may for example comprise a result of a function applied to at least a portion of the data indicated by a data producer in a given submission request or a result of a function applied to a de duplication key included in a submission request. In at least one embodiment data producers may simply include a de duplication signature as an element of a submission request and the supplied signature may be stored in the de duplication table. In order to check whether a submission request comprises duplicate data the ingestion node may check whether the signature corresponding to the request is already present in the local de duplication table subject to certain caveats with respect to de duplication time windows or session specific high water marks as described below . If the signature is present and if the previously submitted data record with the same signature has been saved at the SMS storage subsystem the submission request may be rejected as a duplicate. If the signature is not found in the local de duplication table a corresponding data entry for the data submitted by the data producer may be generated and either immediately or eventually as part of a batched write written to the storage subsystem of the SMS. De duplication signatures e.g. part or all of the entries of the local de duplication tables may also be written to the storage subsystem e.g. as part of the sequence records described below or separately from the sequence records. As also described below the saved de duplication signatures may be used during recovery in the event of a failure of an ingestion node. In some embodiments a log of the write requests and or other requests submitted by the ingestion nodes to the storage subsystem may be maintained at a different storage location or locations than the sequence records. In some such embodiments de duplication signatures may be saved as part of such a log instead of being saved together with the sequence records. The separate log may be used to reconstruct de duplication tables subsequent to a replacement of a failed or unreachable ingestion node instead of having to extract the de duplication signatures from the SMS storage subsystem. In at least some embodiments the data entries e.g. data entries A and B at ingestion node A and respectively may be written in batches rather than individually to the storage subsystem thus reducing the number of network transfers needed and also allowing more of the data to be written using efficient sequential write operations. It is noted that in embodiments in which a layered architecture similar to that shown in is used for the ingestion subsystem the ingestion nodes that perform de duplication operations may correspond to the back end nodes of .

In at least some implementations the local de duplication tables and or the data records may be stored in volatile memory e.g. volatile memory A and volatile memory B at the ingestion nodes e.g. in portions of the main memories of respective computing devices being used for the ingestion nodes. Maintaining de duplication signatures within fast main memory may help reduce the time taken to perform de duplication checks e.g. relative to implementations in which disk based storage is used for the de duplication tables in such embodiments.

Several approaches may be used to limit the amount of the de duplication metadata that has to be stored at any given time at an ingestion node. In one embodiment de duplication time windows may be defined for various data streams which enable the ingestion nodes to reject submission requests that are too old according to the time windows. For example for at least some stream S the local clocks at data producers and the ingestion nodes may be assumed to be at least loosely synchronized and each data submission request SR may indicate a corresponding submission time ST from the perspective of the data producer. When an ingestion node receives SR at a receive time RT with RT being determined using the ingestion node s clock the difference RT ST may be computed. If the difference exceeds a de duplication time window DTW defined for S or at least for the partition to which the data submission is directed the submission may be rejected as stale without checking the local de duplication table. If the difference does not exceed the de duplication time window the de duplication table may be checked to ascertain whether the submission is a duplicate and the submission may still be rejected if it is a duplicate otherwise if it is not deemed a duplicate the submission may be accepted Thus in such an embodiment the ingestion nodes may in effect be required to store de duplication signatures only for records received within the applicable de duplication time window and may be able to prune or discard older signatures. In this way the amount of memory or storage that has to be used for the local de duplication tables may be kept within reasonable limits. The de duplication time windows may be defined at different granularities in different embodiments e.g. a single window may be used by default for all streams respective windows may be defined for different streams or respective windows may be defined for respective partitions. In some implementations the de duplication time windows may be set to a few hours e.g. to encompass the time it may take a given failed data producer to be restarted and complete recovery operations. The durations of the de duplication time windows may also be estimated based on other factors in some embodiments such as the size of main memory available for the de duplication tables at ingestion nodes the sizes of the de duplication signatures the expected rate of submissions and so on. In embodiments in which de duplication time windows are used the de duplication tables may be pruned i.e. entries that were stored at a time that no longer lies within the time window as measured from the current time may be removed using one or more asynchronous cleaner processes or threads. In some embodiments in addition to or instead of using de duplication time windows per session sequence numbers may be used to prune local de duplication tables as described below in the context of .

In the event that a given ingestion node fails or is no longer reachable in at least some embodiments a replacement ingestion node may be configured e.g. by a control server of the SMS. In embodiments in which local de duplication tables are maintained in volatile memory the replacement ingestion node may be required to retrieve de duplication metadata from persistent storage and construct its own local de duplication table e.g. as part of recovery operations corresponding to the failure. If a de duplication time window is defined for the partition for which the replacement ingestion node is responsible only those de duplication signatures for records received within the de duplication time window may have to be read to populate the local de duplication table

If the submission is not stale a de duplication table entry may be added to the local de duplication table in the depicted embodiment. The entry may include a de duplication signature of the data as well as a write confirmation pending flag in some embodiments. The write confirmation pending flag of an entry may be set e.g. to True at the time that a write request for the corresponding data contents is transmitted to the SMS storage subsystem. Depending on the data durability or replication policy in effect for the partition it may take some time for the data to be saved at the appropriate storage locations e.g. multiple replicas of the data may be stored in a sequential manner at different storage nodes located in respective data centers as described below with respect to . Until a confirmation is received from the storage subsystem that the write has been committed or completed successfully at the required number of storage locations or until an indication is received that the write could not be committed successfully at the required number of storage locations and hence should be deemed to be aborted or failed the write confirmation pending flag may remain set. If a confirmation is received that the write succeeded the write confirmation pending flag may be unset e.g. set to False . If the write fails and a duplicate submission was not received for the same data contents in the interim the entry may be deleted from the de duplication table.

If a duplicate submission is received while the write confirmation pending flag is set the duplicate submission may be queued in some embodiments e.g. a decision as to whether the submission should be rejected as a duplicate or not may be deferred until the response to the write request is received from the storage subsystem. If the write eventually succeeds the duplicate request may be rejected if the write eventually fails the duplicate submission may be treated as though it were a new submission e.g. a write request may be submitted and the write confirmation pending flag may remain set.

As described above de duplication time windows may be used to control the amount of de duplication metadata that has to be maintained at ingestion nodes in some embodiments and also to limit the recovery time after a failure or replacement of an ingestion node. In one embodiment another technique involving session specific sequence numbers SSSNs different from the partition wide sequence numbers or discussed earlier may be used for further space optimizations with respect to de duplication tables. Session specific sequence numbers may be used either in combination with or independently of de duplication time windows in various embodiments. illustrates examples of interactions between data producers and ingestion nodes of a stream management system in which session specific sequence numbers are used to prune local de duplication tables according to at least some embodiments.

In the embodiment shown in the communications between a given data producer and a given ingestion node with respect to a given partition may be designated a client session . Thus a client session may typically be uniquely identifiable by a triplet data producer partition ingestion node . Within a client session a session specific sequence number SSSN may be assigned by the data producer for each data submission request e.g. using a monotonically increasing integer session counter or some similar technique. In addition each data producer may maintain an acknowledgement high water mark HWM for each of its sessions indicating the highest SSSN for which a write acknowledgement has been received. The SSSN may be included in the submission request . The write acknowledgements returned to the data producer by the ingestion node may also indicate the SSSN of the acknowledged submission request.

For example data producers A and B transmit submission requests A and B respectively to ingestion node comprising data A and B respectively to be added to stream partition Sj Pk. The submission requests include a respective SSSN e.g. A and B for data producers A and B generated using counters A and B respectively and respective de duplication information entries such as submission timestamps and or de duplication signatures or keys A and B . In addition the submission requests also include respective current high water marks HWMs e.g. HWM A in submission request A derived from HWM A and HWM B in submission request B derived from HWM B that indicate the highest SSSN for which the data producer has received an acknowledgement from the ingestion node at the time that the submission request is transmitted. The write acknowledgements e.g. A and B transmitted to the data producers by the ingestion node include the SSSNs of the submissions being acknowledged which may be used by the data producers to update the values of their respective HWMs . In addition in the depicted embodiment the acknowledgements may also include the partition wide sequence numbers e.g. A and in acknowledgements A and B that are generated based on the order within the partition Sj Pk as a whole not just within a given client session in which the data submission requests are received by the ingestion subsystem. Thus the write acknowledgements may include two different independent sequence numbers a session specific sequence number and a partition wide sequence number in the depicted embodiment.

The inclusion of the current HWM in the submission request may allow the ingestion node to delete entries from its de duplication table more aggressively than if just a de duplication time window were being used. The ingestion node may maintain its own session related metadata for partition Sj Pk indicating for example how many data producers have ongoing sessions and the most recent session HWMs received from each such data producer. The data entries stored by the ingestion node may also have session identifying information. The ingestion node may use the current HWM values provided in a submission request from a particular data producer to identify entries a generated by the same session and b with lower SSSNs than the current HWM value. An assumption underlying the SSSN based technique is that since the data producer has already received acknowledgements for submissions with SSSNs lower than the HWM the probability of the data producer submitting corresponding duplicate submissions is extremely low or zero . Such entries may therefore be discarded from the local de duplication table as indicated by arrow . In embodiments in which the SSSN technique is used together with de duplication time windows entries may still be pruned from the local de duplication table on the basis of the time windows as well. In various implementations the more aggressive pruning permitted by the use of SSSNs may result in much smaller de duplication tables on average and may therefore help speed up de duplication checks and recovery operations as well.

In at least some embodiments the ingestion node may utilize the SSSNs to provide additional feedback via the write acknowledgements to the data producers regarding missing data record submissions e.g. submissions that may have been dropped or damaged during transit to the ingestion node over a network. Consider the following example scenario in which the SSSNs of a given session are implemented as consecutive integer values an ingestion node maintains corresponding to each data producer a data structure such as a bitmap or bit array in which it keeps track of some number e.g. or of most recent submission requests from that data producer . When the ingestion node receives a new submission request from that data producer with a current HWM value H and an SSSN value S the ingestion node may quickly be able to tell using the data structure the specific SSSNs if any between H and S for which corresponding submission requests have not yet been received at the ingestion node. The ingestion node may then include a list of such missing submission requests within the write acknowledgement sent for the submission with SSSN S. Such a missing submission request list may be used by the data producer to re submit the missing requests.

It is noted that in at least some embodiments a lower level protocol such as TCP IP the Transmission Control Protocol Internet Protocol that also uses sequence numbers may be used for responding to packet loss at a per network connection level e.g. by retransmitting lost packets. However such low level protocols would not be aware of stream records or stream semantics and would therefore typically not be particularly useful in reducing the space requirements associated with local de duplication in a manner analogous to the SSSN based technique or in providing feedback to data producers about which specific recent submission requests are missing as described above

If the submission time lies within the de duplication window as indicated by the Yes outcome of the test indicated by element the ingestion node may proceed to perform further tests on SRn. If the local de duplication table at the ingestion node does not contain an entry with a de duplication signature matching that of SRn the No outcome of element SRn may be deemed a new request i.e. not a duplicate . Accordingly a de duplication table entry with SRn s de duplication signature and a write confirmation pending flag set to True may be added to the local de duplication table. A write request or multiple requests depending on the persistence replication policies in effect for Sj Pk may be submitted to the SMS storage subsystem by the ingestion node element . In some cases the write request may be buffered instead of being sent immediately e.g. to achieve greater efficiencies in transmitting data to the storage subsystem and or in writing the data at the storage subsystem using sequential write operations.

If an entry with SRn s de duplication signature is found in the local de duplication table in operations corresponding to element the write confirmation pending flag for the entry may be examined element . If the flag value indicates that the write is confirmed e.g. if the flag is set to False SRn may be rejected as a duplicate element . If the flag value indicates that the write is not yet confirmed e.g. if it is set to True the ingestion node may queue SRn and wait for the asynchronous result of the write request before deciding whether to reject or accept SRn element . If the write eventually is confirmed as detected in operations corresponding to element SRn may be rejected. If the write fails as also detected in element SRn may be accepted as the equivalent of a new non duplicate submission and operations corresponding to element may be performed. There may be no need to add an entry to the de duplication table in this scenario instead the existing entry corresponding to the earlier request whose write did not succeed may be re used in at least some implementations. 

The ingestion node may wait for the result of the write request to the storage subsystem corresponding to the non duplicate submission request element . If the write succeeds as detected in element an acknowledgement may be sent to the data producer element and the write confirmation pending flag may be reset to False . If the write fails in at least some embodiments an indication of the failure may be provided to the data producer element and the de duplication table entry may be deleted.

When an ingestion node fails or becomes inaccessible a replacement ingestion node may be designated in accordance with a failover protocol. In some embodiments each ingestion node may be configured as a member of a replication group as indicated in with one of the members designated as a primary at any given time. is a flow diagram illustrating aspects of a failover mechanism for ingestion nodes that implement local de duplication tables according to at least some embodiments. As shown in element the current primary ingestion node IN configured for a partition Sj Pk may write de duplication signatures from its local de duplication table which may be instantiated in volatile memory in at least some implementations to a persistent storage location PS e.g. in batches to a storage subsystem node or a database. A control node of the SMS may determine that IN has reached an undesirable state element . The control node may then initiate failover to a replacement currently non primary ingestion node IN element .

IN may instantiate and populate its own local de duplication table e.g. in volatile memory element . In some embodiments to populate the table IN may read de duplication signatures from the persistent storage PS for those data records whose submission times lie within a de duplication time window of the failure time of IN. In other embodiments in which the session specific sequence numbers described above are used for pruning the local de duplication tables SSSN metadata pertaining to various client sessions that were active at the time of the failure may be used to select the subset of de duplication signatures that are to be read from the persistent storage. After it has populated the local de duplication table IN may start handling submission requests targeting Sj Pk. In some embodiments Sj Pk submission requests that are received during the time taken to populate IN s local de duplication table may be queued until the table is fully populated. It is noted that at least in some embodiments the de duplication signatures may be stored at different storage locations than are used for the stream data records e.g. a chain of replication nodes using one set of storage servers may be used for the data records while a database may be used for the de duplication signatures. In at least one embodiment de duplication signatures themselves may not be stored in persistent storage. Instead some indication of how to reconstruct the signatures e.g. information on the de duplication keys to use may be stored and the de duplication signatures may be recomputed during recovery by the replacement ingestion node from the data portion of the stream s records.

As described earlier a number of different techniques may be used for storing stream data records in various embodiments. In some embodiments for example a database service implemented at a provider network may be used. In at least one embodiment an approach employing sequential or chained replication at a plurality of storage servers may be used in which for example relatively inexpensive commodity disks of the storage servers may be used to efficiently attain a high degree of data durability. illustrates examples of replication chains that may be used for sequential replication of data records at a storage subsystem of a stream management system according to at least some embodiments. A chain manager may be configured in such embodiments to determine for a given stream partition such as Sj Pk a mapping of the stream s data to a selected set of storage destinations at which copies of the partition s data records are to be created in sequential order. In at least some implementations the chain manager may be implemented as a component of an SMS control subsystem . Reflecting the sequential or chained nature of the replication the mappings may be referred to herein as chain mappings . Each partition may be assigned a replication chain comprising some number of replication nodes that are responsible for generating the replicas. A replication node may for example comprise a process or thread of execution at a storage server and may be granted write permission to one or more storage devices employing any of various types of non volatile storage technologies and accessible from the storage server . Different replication chains may comprise different numbers of replication nodes in at least some embodiments e.g. based on the data durability requirements of the corresponding partitions. A given replication chain may include respective replication nodes instantiated at a plurality of data centers and or at a plurality of availability containers in some embodiments. A replication chain may be assigned to more than one partition potentially of more than one stream in some implementations. The chain mappings generated by chain manager may comprise information on a number of different types of potentially dynamically modifiable relationships the replication chain currently assigned to a given partition the storage servers assigned to a given replication chain the roles e.g. head node intermediate node or tail node described below in further detail assigned to replication nodes of a given chain and or the storage device s at which a given replication node is to write data records.

In the example scenario depicted in three replication chains A B and C are shown in an SMS storage subsystem . Replication chain A configured for partition Sj Pk the kth partition of stream Sj comprises three replication nodes replication node A on storage server A replication node K on storage server B and replication node P on storage server C. Node A is currently designated the head of the replication chain A while node B is currently designated the tail of the replication chain A. The head of a given replication chain may be configured to receive write requests as indicated by the arrow labeled WReq in the case of node A for a given partition s data records from an SMS ingestion subsystem node. For example in one embodiment an ingestion subsystem node may receive a data submission request of partition Sj Pk from a data producer optionally perform de duplication checking as described earlier determine if it is not known already the identity or address of a head node A or replication chain A from chain manager and then submit a corresponding write request WReq to the head node A. After receiving the write request the head node may store a local copy of the data to a storage device accessible from the head node s storage server e.g. to one or more of local storage devices A or B in the case of head node A at storage server A. After storing the local replica the head node A may transmit or forward a write request for the data record to the next replication node in the replication chain such as replication node K. The sequential order in which the data records of the partition are to be replicated starting from a head node passing through zero or more intermediate nodes and ending at a tail node may be defined by the chain manager as part of the chain mapping . For some partitions that may not require very high data durability a single node replication chain may be defined in some implementations in which separate head and tail nodes are not defined. Each node in the chain may receive a write request and store a local replica of the corresponding data records. All the nodes except for the tail node may transmit or forward a write request to the next node in the chain in at least some implementations such write requests may serve as acknowledgements that the nodes have completed their local writes successfully. The tail node after storing its replica may transmit a write acknowledgement e.g. WAck from tail node P of replication chain A to the SMS ingestion subsystem indicating that the data record has been successfully stored in accordance with the applicable policies for the partition. As a result of replicating the data record in sequential order as described above at least some level of workload balance may be achieved automatically among the different replication nodes of a chain e.g. for a given data record submitted to the ingestion subsystem by a data producer each node in the chain may receive one incoming message perform one storage operation and transmit one outbound message either a write request or in the case of the tail node a write acknowledgement . Upon receiving the write acknowledgement from the tail replication node in some embodiments the ingestion subsystem may provide a response to the data producer that submitted the data record indicating that the data has been added or ingested to the stream.

Replication chains A and C each comprise three replication nodes in while replication chain B comprises two replication nodes. In each of the illustrated replicas chains different nodes are designated as head nodes and tail nodes. For replication chain B configured for partition Sp Pq node Q is designated as the head node configured to receive write requests WReq from the SMS ingestion subsystem and node B is designated as the tail node configured to transmit write acknowledgements WAck to the ingestion subsystem. Replication chain C is configured to store data records for two partitions of different streams partition Sj Pq and Sa Pb. For replication chain C node L on storage server B is the head node configured to receive write requests WReq of partitions Sj Pq and Sa Pb from the ingestion subsystem while node C at storage server A is the tail node responsible for sending write acknowledgements WAck to the SMS ingestion subsystem. Replication nodes that are currently designated neither as head nodes nor as tail nodes such as replication node K or R may be referred to as intermediate nodes of their replication chains. In some embodiments a given replication node may serve a plurality of roles e.g. it may be a head node for one partition a tail node for another partition and or an intermediate node for a different partition. As mentioned above for some partitions a replication chain comprising only a single node may be configured combining the head node functionality receiving the initial write request for a data record from the SMS ingestion subsystem and the tail node functionality transmitting a write acknowledgment to the ingestion subsystem after the required number of replicas are generated .

In the embodiment depicted in a number of multi tenant resources may be used e.g. resources may be shared by several partitions either of the same stream or of different streams. For example a given storage server may comprise a computer host or other computing device whose processors memory and or storage devices may be shared by several replication nodes . Similarly a given storage device such as any of devices A B C D E and F may be used to store data records of more than one partition. Furthermore as indicated above a given replication node e.g. a process or thread may be configured to store replicas of data records of more than one stream. In at least some embodiments the chain manager may be responsible for deciding e.g. at stream initialization time and or in response to dynamic repartitioning decisions how best to share a limited set of resources storage server hosts storage devices and replacement nodes among the various partitions of one or more data streams. In some environments the resources available for the replication chains may vary in their capabilities further increasing the complexity of the chain manager s mapping responsibilities e.g. some storage servers such as C may have more local storage devices than others such as A and B . The available storage devices may differ in performance size or even storage technology e.g. SSDs may be available at some storage servers while only rotating disk based devices may be available at others .

In addition to generating the chain mappings the chain manager may also be responsible for monitoring the health status e.g. responsiveness of the various replication nodes in at least some embodiments and or to configure replacement replication nodes when certain types of triggering conditions or failures are detected. In one embodiment a respective node manager may be instantiated at each storage server e.g. node manager A at storage server A node manager B at storage server B and node manager C at storage server C. The node manager may act as a local agent of the chain manager e.g. to monitor the health of replication nodes using a heartbeat mechanism and notify the chain manager regarding health status changes to start stop replace replication nodes as needed and so on. The use of node managers may help to reduce the workload that has to be handled by the chain manager in such embodiments. In other embodiments node managers may not be implemented and the chain manager may perform the necessary configuration and health monitoring functions without the help of such intermediaries. The chain manager itself may comprise a plurality of software and or hardware components in some embodiments.

In at least some embodiments in which the storage devices include rotating disks the replication nodes may attempt to optimize write performance using various techniques. For example in one such embodiment the number of disk seeks may be reduced by buffering data records e.g. in volatile or main memory and flushing the buffers to disk using large sequential write operations instead of smaller more random write operations. In other embodiments non volatile write caches may be used. In at least some embodiments a given replication node may be configured to ensure that the local replica has been saved to persistent storage before transmitting a write request to the next node in the replication chain or in the case of the tail node before transmitting the write acknowledgement to the ingestion subsystem .

As described earlier retrieval subsystem nodes may receive read requests directed at a given partition from a number of data consumers. A retrieval subsystem node may in turn determine the replication chain configured for the requested records e.g. by communicating with the chain manager or some other SMS control subsystem component and submit an internal read request to a selected replication node of the chain. The replication node may be selected based on any of various factors in different embodiments e.g. based on a retrieval workload distribution policy random selection affinity e.g. a retrieval subsystem node may continue to send read requests to a selected replication node as long as the node remains responsive measured latencies e.g. the retrieval node may record read latencies for various replication nodes of the chain and preferentially use the nodes that have the lowest read latencies and so on. In one embodiment retrieval nodes e.g. processes or threads responsible for responding to retrieval requests from data consumers may be implemented at the storage servers themselves e.g. the storage subsystem and the retrieval subsystem may be combined. In such an embodiment a data consumer may obtain network addresses of the combined retrieval storage nodes e.g. from the SMS control subsystem and may submit read requests to the combination nodes.

As indicated above a number of policies metrics and other factors may have to be taken into account by a chain manager to generate the chain mappings . illustrates examples of factors that may influence the replication chain mappings generated by a chain manager of a stream management system according to at least some embodiments. The chain manager may determine an initial chain mapping in some embodiments at the time that a stream is created or initialized and may modify the chain mapping as needed over time e.g. in response to dynamic repartitioning events . To determine the initial chain mapping in some embodiments the chain manager may determine various applicable stream level policies such as the overall partitioning policy replication or durability policies and availability policies. The stream level policies may determine for example the number of partitions into which the stream is to be divided and the physical geographical distribution of the stream s data which in turn may lead to the configuration of a corresponding number of replication chains at selected data centers or availability containers. The expected temporal distribution of writes record submissions and or the expected temporal distribution of reads record retrievals may also be considered when deciding various aspects of chain mappings such as the kinds of storage devices to be used for the replication chains. For example in an embodiment in which both rotating disk based storage and solid state storage devices are available the chain manager may assign rotating disk storage to partitions for which high submission and retrieval rates are expected so that large sequential writes and reads can be used thus reducing the performance overhead associated with disk head seek operations while SSDs may be used for streams with lower expected write read rates.

Metrics collected from the various storage servers and or from the storage devices being used including for example throughput latency error rates health state metrics and the like may also play a role in determining exactly which storage servers and devices should be assigned to a replication chain in some embodiments. The chain manager may also consider the performance specifications of storage devices accessible from various storage servers when determining chain mappings e.g. when deciding how many replication nodes should be configured to store data records at the same shared storage device. In some embodiments the chain manager may also have to consider client budget constraints e.g. it may be advisable to use cheaper commodity disks than more expensive SSDs for a given replication chain in accordance with a client s storage budget. The chain manager may have to weigh conflicting factors when making its mapping decisions e.g. from the budget perspective a disk based replication chain may be preferred for a given partition but from a write performance perspective it may be preferable to use SSDs. In some embodiments a number of resource usage balancing policies may be employed for storage devices or storage servers and such policies may also influence the mappings generated by chain manager . For example power consumption balancing policy may be applied in some storage systems in an attempt to ensure that the variation in the amount of power consumed by different storage servers or devices is kept reasonably small. Similarly for certain types of storage device such as SSDs or other kinds of disks a wear and tear balancing policy may be implemented in some embodiments to distribute workloads relatively uniformly among devices with the goal of achieving similar time to failure or time to replacement metrics for the various storage devices. In addition to the factors mentioned earlier such power usage balancing policies and or wear balancing policies may also be taken into consideration by chain manager when selecting the specific resources to be used for various replication nodes.

In at least some embodiments as discussed earlier dynamic repartitioning may be initiated in response to client requests or in response to various triggering conditions. The triggering conditions may include overload conditions detected at a replication chain or at one or more replication nodes. In some such scenarios in which the chain manager monitors the health status of the various replication nodes the chain manager itself may initiate a dynamic repartitioning that in turn leads to a change in the chain mapping. As described above the chain mappings may include mappings between streams partitions replication chains storage servers and or storage devices in various embodiments. In some embodiments some of the mapping decisions may be made locally at the storage servers e.g. node managers may determine the specific storage devices file systems etc. that are to be used by a given replication node while the storage servers themselves may be selected by the chain manager . In response to a repartitioning changes may be made to any of the different mappings e.g. a different replication chain may be assigned to a partition a chain that was previously configured for one partition may be assigned a different set of one or more partitions or the storage servers or devices being used for a given partition may be changed.

The selected replication nodes may be configured or activated element e.g. to start receiving write requests for data records saving respective replicas to selected storage locations and either forwarding the write request on or in the case of a tail node sending an acknowledgement to the ingestion node from which the initial write request was received at the chain. In some embodiments pools of processes or threads may be set up at the storage nodes and members of such pools may be configured for replication chains utilized until they are no longer required and then returned to the pools. Each node in a given replication chain may be notified regarding the next node in the chain or that it is the tail node e.g. by the chain manager or a node manager at the storage server in some embodiments.

After the replication nodes have been configured the chain manager may monitor the health status of the nodes element . In some embodiments a heartbeat mechanism may be used and or log messages generated by the replication nodes may be monitored. In some embodiments a node manager at the storage server may be configured to monitor the health of replication nodes at the storage server and notify the chain manager when an unexpected undesired health state is discovered. In at least some embodiments the chain manager and or the node manager may configure a replacement replication node if when an undesired state of an existing replication node is identified element .

If the recipient node is the tail node of the replication chain as detected in element a write acknowledgement may be transmitted to the ingestion subsystem node from which the data was initially received at the storage subsystem element . The write acknowledgement may signal to the ingestion subsystem that the replication of the data producer s data has been successfully completed and a corresponding acknowledgement to that effect may be sent to the data producer in at least some embodiments. If the recipient node is not the tail node as also detected in element the write request may be sent on to the next node in the chain element e.g. with the next node being selected in accordance with the sequential replication order defined for the chain by the chain manager. The operations corresponding to element onwards may be repeated at the same set of replication chain nodes for data records submitted subsequently for the same partition.

It is noted that in various embodiments operations other than those illustrated in the flow diagrams of and may be used to implement the stream management service and or the stream processing functionality described above. Some of the operations shown may not be implemented in some embodiments or may be implemented in a different order or in parallel rather than sequentially. It is also noted that with respect to each of the SMS and SPS functions for which programmatic interfaces are supported in various embodiments any combination of one or more techniques may be used for implementing the interfaces including the use of web pages web sites web services APIs other APIs command line tools graphical user interfaces mobile applications apps tablet apps and the like.

The techniques described above of establishing scalable partitioning based dynamically configurable managed multi tenant services for collection storage retrieval and staged processing of stream data records may be useful in a number of scenarios. For example large provider networks may comprise thousands of instance hosts implementing service instances of a number of different multi tenant or single tenant services for tens of thousands of clients simultaneously. Monitoring and or billing agents installed on the various instances and hosts may rapidly generate thousands of metric records which may need to be stored and analyzed to produce accurate billing records to determine effective provisioning plans for the data centers of the provider network to detect network attacks and the like. The monitoring records may form an input stream to an SMS for scalable ingestion and storage and SPS techniques described may be implemented for the analysis of the collected metrics. Similarly applications to collect and analyze large numbers of log records from numerous log sources e.g. application logs from the nodes of a distributed application or system logs from the hosts or compute instances at a data center may also be able to utilize SMS and SPS functionality. In at least some environments the SPS processing operations may comprise a real time ETL Extract Transform Load processing operation i.e. an operation that transforms received data records in real time for loading into a destination instead of doing the transformation offline or a transformation of data records for insertion into a data warehouse. Using an SMS SPS combination for loading data into a data warehouse in real time may avoid the delays that are typically required to clean and curate data from one or more data sources before the data can be inserted into a warehouse for analysis.

A number of different big data applications may also be built using the SMS and SPS techniques. For example the analysis of trends in various forms of social media interactions may be performed efficiently using streams. Data collected from mobile phones or tablet computers such as location information of the users may be managed as stream records. Audio or video information collected for example from a fleet of monitoring cameras may represent another category of streaming data set that could be collected and processed in a scalable manner potentially helping prevent attacks of various kinds. Scientific applications that require analysis of ever growing data sets collected for example from weather satellites ocean based sensors forest based sensors astronomical telescopes may also benefit from the stream management and processing capabilities described herein. The flexible policy based configuration options and pricing options may help different types of users customize the streaming functionality to suit their specific budgets and data durability availability requirements.

In at least some embodiments a server that implements a portion or all of one or more of the technologies described herein including the techniques to implement the components of the SMS subsystems e.g. the ingestion storage retrieval and control subsystems including chain managers as well as the SPS worker and control nodes may include a general purpose computer system that includes or is configured to access one or more computer accessible media. illustrates such a general purpose computing device . In the illustrated embodiment computing device includes one or more processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA. In some implementations graphics processing units GPUs may be used instead of or in addition to conventional processors.

System memory may be configured to store instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces such as various types of persistent and or volatile storage devices used to store physical replicas of data object partitions. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other devices attached to a network or networks such as other computer systems or devices as illustrated in through for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer accessible medium configured to store program instructions and data as described above for through for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible media. Generally speaking a computer accessible medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer accessible storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc. that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer accessible medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface . Portions or all of multiple computing devices such as that illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer accessible medium. Generally speaking a computer accessible medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc. as well as transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. The order of method may be changed and various elements may be added reordered combined omitted modified etc.

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description to be regarded in an illustrative rather than a restrictive sense.

