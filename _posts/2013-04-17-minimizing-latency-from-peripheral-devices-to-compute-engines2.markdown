---

title: Minimizing latency from peripheral devices to compute engines
abstract: Methods, systems, and computer program products are provided for minimizing latency in a implementation where a peripheral device is used as a capture device and a compute device such as a GPU processes the captured data in a computing environment. In embodiments, a peripheral device and GPU are tightly integrated and communicate at a hardware/firmware level. Peripheral device firmware can determine and store compute instructions specifically for the GPU, in a command queue. The compute instructions in the command queue are understood and consumed by firmware of the GPU. The compute instructions include but are not limited to generating low latency visual feedback for presentation to a display screen, and detecting the presence of gestures to be converted to OS messages that can be utilized by any application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09558133&OS=09558133&RS=09558133
owner: Advanced Micro Devices, Inc.
number: 09558133
owner_city: Sunnyvale
owner_country: US
publication_date: 20130417
---
The disclosure is generally directed to computing operations performed in a computing system and more particularly to reducing latency from peripheral devices to compute engines in a processing unit.

A computing device generally includes a processing unit e.g. a central processing unit CPU a graphics processing unit GPU accelerated processing units APU or the like system memory controlled by an operating system OS and a display device. Users of the computing device demand high quality graphics and real time i.e. ideally zero latency interactions to be rendered on a display and increasingly faster performance of application programs executed on the computing device. The computing device may be embodied in a traditional personal computer desktop or notebook mobile device tablet smart phone e reader or embedded in a larger system e.g. a kiosk vehicle etc. 

A peripheral device e.g. a camera module connected to the computing device relies on the CPU and system memory to interact with the rest of the computing environment. A peripheral device driver is a software application program running on the CPU that is specific to each peripheral device and allows the peripheral device to communicate with the rest of the computing device.

In one implementation a peripheral device is used as a capture device and a compute device processes the captured data in an APU environment. An application program executed on the computing device in the implementation incurs significant latency or time delay e.g. in rendering an image on the display. In some usage scenarios the latency experienced by users may not meet users expectations for a real time low latency performance. The excessive latency is not acceptable to users and needs to be reduced.

One existing solution of a peripheral device with reduced latency is a mouse device. Mouse device data i.e. user movement as input is input to the computing device and the response in the form of a cursor is output to a display. To meet user expectations specialized motion input device support is added to display hardware which can be used within an OS to reduce the latency perceived by a user on the display. Nonetheless the actual processing of motion input activities by software applications occurs with higher latencies.

Therefore what is needed is a system method and computer program product that substantially reduces latency in the implementation with a peripheral device used as a capture device and a compute device that processes the captured data in a computing environment. The reduced latency opens opportunities for real time low latency applications such as touch free human computer interface HCI applications in an APU environment with minimal latency. Embodiments result in low latency feedback to a display screen as well as detection and recognition of gestures in captured data to be converted to OS messages that can be utilized by any application.

Existing implementations involve many interactions at the application level among OS components device drivers and the application that run on the CPU. The application plays a significant role in configuring devices processing data captured by the peripheral device providing instructions to a compute device to offload processing and then updating the application s windows on a display screen. When the OS is busy with background tasks the CPU response time and hence the application response time to user inputs varies.

For example when video data is captured by a camera there is a noticeable time delay before the captured video is processed by the application and visual feedback is displayed on a screen of a computing device to the user. The excessive latency degrades performance forces users to slow down to try to preserve manipulative stability and the outcome becomes unpredictable. The variable CPU response time is a significant source of latency in application performance that is not acceptable to users.

To reduce the significant latency some embodiments minimize application level interactions i.e. reduce device driver and OS overhead by tightly integrating the devices at the hardware level. The integration causes intelligence to be added to the firmware of embedded processors in the devices. Firmware can be a combination of a programmable and or persistent memory stored on a memory chip for example. The intelligence includes pre packaged precompiled compute code that is added to the peripheral device firmware and the compute device firmware. In addition the devices are connected via a common memory pool. The peripheral device can capture data as before in the typical arrangement. However the peripheral device due to the augmented abilities in the firmware now has the ability to provide instructions and data to the compute device via the common memory pool.

Some embodiments include a method processing unit and computer readable storage device that include a processing unit accessing compute instructions and data from a command queue the compute instructions and data being presented by firmware in a peripheral device and the processing unit based on the compute instructions performing tasks on data captured by the peripheral device and stored in common data buffers where the accessing and performing occur in an environment including a CPU and a GPU. In an embodiment the compute instructions specific to the processing unit are determined by the firmware in the peripheral device. In some embodiments the compute instructions include a human computer interface HCI compute function that includes at least one of face tracking eye tracking hand tracking and finger tracking.

In other embodiments the compute instructions further include generating visual feedback of results of a HCI compute function on a display. The visual feedback can be an overlay on top of regular screen content and the visual feedback can be presented with per pixel alpha blending. In other embodiments the compute instructions further include detecting and recognizing a presence of a gesture.

Further features and advantages as well as the structure and operation of various embodiments are described in detail below with reference to the accompanying drawings. It is noted that the disclosure is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

The embodiments will now be described with reference to the accompanying drawings. In the drawings generally like reference numbers indicate identical or functionally similar elements. Additionally generally the left most digit s of a reference number identifies the drawing in which the reference number first appears.

The following detailed description refers to the accompanying drawings that illustrate exemplary embodiments. Other embodiments are possible and modifications can be made to the embodiments within the spirit and scope of the disclosure. Therefore the detailed description is not meant to limit the scope. Rather the scope is defined by the appended claims.

It would be apparent to one of skill in the art that the embodiments as described below can be implemented in many different embodiments of software hardware firmware and or the entities illustrated in the figures. Any actual software code with the specialized control of hardware is not limiting. Thus the operational behavior will be described with the understanding that modifications and variations of the embodiments are possible and within the scope and spirit of the disclosure.

Computing devices process data and provide many applications to users. Example computing devices include but are not limited to mobile phones personal computers workstations and game consoles. Computing devices use a central processing unit CPU to process data. A CPU is a processor which carries out instructions of computer programs or applications. For example a CPU carries out instructions by performing arithmetical logical and input output operations. In an embodiment a CPU performs control instructions that include decision making code of a computer program or an application and delegates processing to other processors in the computing device such as a graphics processing unit GPU .

A GPU is a processor that is a specialized electronic circuit designed to rapidly process mathematically intensive applications on electronic devices. The GPU has a highly parallel structure that is efficient for parallel processing of large blocks of data such as mathematically intensive data common to computer graphics applications images and videos. The GPU may receive data for processing from a CPU or generate data for processing from previously processed data and operations. In an embodiment the GPU is a hardware based processor that uses hardware to process data in parallel.

Due to advances in technology a GPU also performs general purpose computing also referred to as GPGPU computing . In the GPGPU computing a GPU performs computations that traditionally were handled by a CPU. An APU includes functions of a CPU and a GPU. An APU environment provides a unified view of fundamental computing elements. An APU environment allows a programmer to write applications that seamlessly integrate CPUs with GPUs while benefiting from the best attributes of each. GPUs have transitioned in recent years from pure graphics accelerators to more general purpose parallel processors supported by standard application programming interfaces APIs and tools such as OpenCL . In an APU environment a programmer can take advantage of the parallel processor in the GPU as a peer or co processor to the traditional multithreaded CPU. In addition an APU environment allows CPUs and GPUs to access memory through the same virtual address translation.

In an embodiment a GPU includes one or more compute units that process data. A compute unit includes arithmetic logic units ALU s and other resources that process data on the GPU. Data can be processed in parallel within and across compute units.

In an embodiment a control processor on a GPU schedules task processing on compute units. Tasks include computation instructions. Those computation instructions may access data stored in the memory system of a computing device and manipulate the accessed data. In an embodiment the data may be stored in volatile or non volatile memory. An example of volatile memory includes random access memory RAM . Examples of RAM include dynamic random access memory DRAM and static random access memory SRAM . Volatile memory typically stores data as long as the computing device receives power. Examples of non volatile memory include read only memory flash memory ferroelectric RAM F RAM hard disks floppy disks magnetic tape optical discs etc. Non volatile memory retains its memory state when the computing device loses power or is turned off.

Users demand high quality graphics high speed rendering of graphics and increasingly faster performance from their computing devices including mobile computing devices. When a peripheral device connects to a computing device such as a computer system compute processing may not be necessary. For example if the peripheral device is a camera and the computing device is a computer system with a CPU and a GPU for example the camera can capture and store data in a file format such as JPEG on the computer. The captured data is not processed immediately.

There are also scenarios where a peripheral device is used as a capture device and immediate processing is required to process the captured data in the computer system that includes a CPU and a GPU. One example of that is using camera gestures as a human computer interface. In that scenario the application plays a major role in configuration and processing to provide visual feedback and interpret the results of the computation to messages understood by the operating system. Applications running in the implementation experience high latency that precludes real time low latency applications that meet user expectations.

Because the implementation typically involves many interactions at the application level among the application OS and device drivers a significant time delay occurs that is noticeable to users of the application. The time the CPU takes to respond or perform varies especially if the OS is busy running background processes. The variable CPU response time due to OS processing is the reason that applications in the implementation can experience high latency between the time the peripheral device captures data and the time the processed captured data results appear on a display device. The high latency in application processing is experienced for example as visual feedback latency on the display device.

For ease of discussion and without limitation examples using a touch free human computer interface HCI application as the real time low latency application a camera module as the peripheral device and a GPU as the compute device is included.

For example in the implementation with a touch free HCI application with gesture recognition an unacceptable visual feedback latency occurs between image capture of a hand or facial gesture by a camera and processing by a processing unit to generate a visual feedback on a screen. The excessive latency degrades performance e.g. users may experience a noticeable lag in the feedback on the display forces users to slow down to try to preserve manipulative stability and the process becomes unnatural. The excessive latency is not acceptable to users and thus needs to be reduced.

Touch screen displays on many mobile computing devices run HCI applications that also experience high latencies. The latencies are due to OS and software driver interactions running on a CPU but because there is only one peripheral device that is used for both input and output the touch screen the latency is not as noticeable to users. Thus low latency HCI is not essential to touch screen displays.

System includes CPU GPU peripheral device bus and the following that reside in system memory application operating system OS common data buffers GPU command queue GPU driver and peripheral device driver .

Peripheral device can be any device that can capture data. Examples include but are not limited to a camera that captures data such as images and video and a microphone that captures audio data.

Common data buffers such as a ring buffer and GPU command queue are located in user address space. Common data buffers are configured to be shared between and accessible by different devices such as GPU and peripheral device . GPU command queue is polled or sampled by GPU to obtain compute instructions for processing data captured in common data buffers . GPU can also be notified by a job submitter to pick up compute instructions in GPU command queue .

Although computing system is shown comprising two processing units it is to be appreciated that this is for illustrative purposes only and not limitation. In general a system in accordance with an embodiment may include one or more processing units including different types of processing units such as a CPU GPU APU application specific integrated circuit ASIC controller other similar types of processing units or a combination thereof. In addition each processing unit may comprise one or more compute units. In an embodiment two processing units are a GPU and a CPU.

In the example CPU application OS common data buffers GPU command queue GPU GPU driver peripheral device and peripheral device driver are connected via bus . Bus may be any type of communication infrastructure used in computer systems including a peripheral component interface PCI bus a memory bus a PCI Express PCIE bus front side bus FSB hypertransport HT or another type of communication structure or communications channel whether presently available or developed in the future.

In the example peripheral device and GPU do not have tight integration so peripheral device cannot communicate with GPU via GPU command queue . Instead application determines if GPU computation is needed as well as determines and stores the compute instructions for GPU in GPU command queue . In addition application with assistance from drivers and as well as OS configures buffers and updates application s windows on a display screen. These activities occur with variable latencies due to the variable CPU response times.

It is to be appreciated that operations in method may be performed in a different order than shown and method may not include all operations shown. For ease of discussion and without limitation method will be described in terms of elements shown in . In addition an example of OS being a Windows OS with an AVStream multimedia class driver that streamlines video data capture from a camera module as peripheral device into user mode applications such as touch free HCI application with gesture recognition as application is also described. AVStream multimedia class driver provides two interfaces a pin interface that connects to hardware and a filter interface that connects to software.

In step peripheral device connects to computing system . OS detects peripheral device and establishes communications with Peripheral device driver .

In an example a camera module connects to a USB port of computing system . Windows OS detects a camera module and camera driver connects to the AVStream pin interface in Windows OS . A Pin in Windows topology refers to an access point to a source or sink device or resource . In the example the camera module is a data source.

In step application communicates with OS peripheral device driver and GPU driver to establish common data buffers and GPU command queue . For substantially improved performance peripheral device can be configured to capture and store data directly into the common data buffers which can be page mapped to allow direct access from GPU without any additional buffer copying operations. Peripheral device is now using common data buffers for storing captured data while GPU can process captured video data directly from the same set of common data buffers .

Application communicates with OS to register a callback function. The callback function is executed by components in OS to notify application when data captured by peripheral device is available for processing. For compute offload application will establish GPU command queue for the submission of compute jobs. Configuration is now complete.

In the example touch free HCI application with gesture recognition communicates with Windows OS camera driver and GPU driver to establish common data buffers and GPU command queue . Camera module is configured to write to common data buffers . In the example touch free HCI application with gesture recognition connects to an AVStream interface in Windows OS to register the callback function. GPU can access common data buffers and is aware of GPU command queue . GPU may begin sampling or polling GPU command queue for instructions.

In step application touch free HCI application with gesture recognition in the example begins i.e. begins to utilize hardware and software capabilities.

At step peripheral device captures and stores data in common data buffers . In the example camera module captures and saves gestures of a user as video data in common data buffers . An example of a gesture can be a vertical finger movement.

At step peripheral device issues an interrupt to OS and OS initiates the callback function to application indicating that data is ready for processing. In the example camera module notifies Windows OS that video data is ready for processing. Windows OS informs the AVStream filter component that initiates the callback function to alert touch free HCI application with gesture recognition that data is ready for processing.

At step application processes the data stored in common data buffers . In the example touch free HCI application with gesture recognition processes data to detect the presence of recognizable gestures such as the vertical finger movements.

At step a determination is made whether the workload can be offloaded to another processing unit such as GPU .

If the workload cannot be meaningfully offloaded to another processing unit application completes processing the stored video data and method proceeds to step .

If the workload can be offloaded to another processing unit such as GPU at step application submits compute functions that are typically written in a high level compute language like DirectCompute and OpenCL. GPU driver may compile and store the compiled compute instructions in GPU command queue .

In the example if touch free HCI application with gesture recognition chooses to offload parallel workload to GPU during the gesture recognition process touch free HCI application compute functions are compiled and stored in GPU command queue .

At step GPU accesses instructions from GPU command queue and processes the data stored in common data buffers accordingly. The processing result is sent to application .

At step when a gesture is detected application performs the corresponding action. In the example when a gesture is detected touch free HCI application with gesture recognition converts the detected vertical finger movement into operations associated with the intended command. An example intended command may be a mouse click or a keyboard action. Touch free HCI application with gesture recognition updates a corresponding application window s to provide visual feedback to inform the end user that the intended command has been carried out.

At step a determination is made whether application ends. Application can end as the result for example of inaction over a given period. If application does not end method returns to step and the process repeats as long as peripheral device captures new data. If application ends application de registers the callback with OS and the process terminates at step .

As would be known by one skilled in the art application OS GPU driver and peripheral device driver run on CPU . Thus method involves CPU processing during the configuration steps through steps through and step involving capturing and processing data. In addition OS processing takes place during configuration in steps when data is captured in step and in step to convert the detected gesture to an action. As discussed earlier the variable CPU response time and hence the latency in completing the steps cannot be guaranteed. For example when the kernel the main component of OS is busy with other background tasks the CPU processing times for steps to will vary.

The latency between the time the gesture is presented to and captured by the camera module at step and the time the corresponding application window is updated thereby providing visual feedback on a display at step is typically in the order of 100 ms too long to allow for an acceptable HCI mechanism for many end users.

Some embodiments take advantage of embedded processors in peripheral devices and compute devices to achieve low latency. In particular intelligence is added to the firmware of a peripheral device and the firmware in a GPU to achieve a tight integration to avoid excessive or unpredictable latency. Thus the peripheral device and the GPU will share corresponding precompiled compute code at the hardware firmware level so they essentially speak the same language and will be able to communicate via common memory buffers. The interactions at the hardware firmware level are substantially improved as they do not involve application level interactions among the OS device drivers and application after data capture through captured data processing. In contrast to the typical implementation described in method of the latency in the implementation with tight integration between the peripheral device and the GPU is shorter and more predictable. The embodiments open opportunities for real time low latency applications such as new touch free HCI applications to meet or exceed user expectations and requirements. For example captured video data can be processed to enable low latency visual feedback on a display screen as well as low latency interpretation of the captured data converted to OS messages that can be utilized by any application even though the messages are generated by a camera.

In embodiments peripheral device and GPU are tightly integrated and communicate at a hardware firmware level. With the added intelligence peripheral device firmware can determine compute instructions specific to GPU to be stored in GPU command queue that are understood and consumed by GPU firmware . The compute instructions include but are not limited to generating visual feedback for presentation to a display screen and detecting the presence of gestures.

In some embodiments gesture recognition is a system level service that is independent of a specific application i.e. the tight integration combined with a virtual device driver results in gesture recognition and conversion of the detected gestures to OS messages that can be utilized by any application. This is in contrast to method which is specific to application i.e. the results of the gesture recognition is used only by application that orchestrates the gesture recognition process.

Virtual device driver is a software application that becomes available due to the tight integration of the underlying devices namely peripheral device driver and GPU . When GPU driver detects the presence of peripheral device that supports the implementation with tight integration e.g. supports gesture capture a virtual device driver is identified to OS as a child device of the GPU driver and can appear as a device to OS including but not limited to a computer mouse or keyboard.

In the gesture recognition example the combination of GPU driver and peripheral device driver initialize virtual HCI driver . Once loaded and initialized virtual HCI driver can translate detected gestures into OS messages that are understood by OS . Thus any application can use the OS messages even though they originated as a gesture captured by a camera i.e. the implementation using a peripheral device as camera capture and compute device is transparent to the application using the resulting OS messages.

All other elements shown in can operate similarly to related elements found in computing system as discussed above.

It is to be appreciated that operations in method may be performed in a different order than shown and method may not include all operations shown. For ease of discussion and without limitation method will be described in terms of elements shown in . For illustrative purposes and not limitation an example with OS being a Windows OS with an AVStream multimedia class driver that streamlines video data capture from a camera module as peripheral device to be available for gesture recognition processing is also described.

At step OS detects peripheral device and establishes communications with peripheral device driver . In an example a camera module connects to a USB port or a camera interface of computing system Windows OS detects camera module and camera driver connects to the AVStream pin interface in Windows OS .

At step OS components of GPU driver and peripheral device driver establish required common data buffers for data capture and storage by peripheral device and GPU command queue for submitting commands to GPU device . GPU samples GPU command queue for instructions to consume captured data in common data buffers and detect events.

For substantially improved performance peripheral device is configured to capture and store data directly into the common data buffers without any additional buffer copying operations. Peripheral device firmware is now aware of common data buffers including location type of buffer and size for storing captured data for GPU to process. GPU firmware will sample the command queue to obtain outstanding compute jobs.

At step components in GPU driver interact with peripheral device driver to enable virtual device driver to OS . In the example GPU driver can interact with camera driver to enable a virtual mouse device not shown to OS .

In one example configuration is complete and further interactions among peripheral device driver OS and GPU driver are unnecessary.

At step gesture recognition begins. Note that gesture recognition is a system level service that is not tied to a specific application in contrast to method which is specific to application .

At step peripheral device captures and stores video data in common data buffers . In the example a camera module captures and stores video data in common data buffers .

At step peripheral device firmware determines and stores compute instructions and data specific to GPU in GPU command queue . Because of the tight integration the compute instructions from peripheral device firmware are specifically tailored to GPU firmware at the hardware firmware level. This is in contrast to step of where application provides intermediary processing and communications at the application level between peripheral device and GPU of .

For example the compute instructions can include the set of HCI compute programs compiled at runtime by application at step in . Peripheral device firmware can be packaged with several pre compiled HCI compute programs including but not limited to compute codes for face tracking eye tracking hand tracking and finger tracking Depending on the nature of the HCI application needed at runtime peripheral device firmware can decide at runtime which subset of the pre compiled HCI compute programs or compute codes is presented to compute device GPU . For example an implementation can choose to default to finger tracking but can be configured by application to track for other features on demand. In another implementation a small control utility is provided to allow the user to enable and disable the gesture recognition to switch the gesture recognition to operate in a desired mode and to tune the sensitivity to suit personal preferences. For instance a user can switch the gesture recognition service to operate in hand tracking mode. In addition the user can configure the gesture recognition service to look for small hands such that a young child can interact with the computing device through hand tracking.

Peripheral device does not execute or consume any of the pre compiled HCI compute programs or compute codes. Thus peripheral device treats the pre compiled HCI compute programs or compute codes as data and stores an applicable subset in GPU command queue for GPU to consume.

In the example camera firmware provides compute instructions and associated data in GPU command queue for GPU to consume. Associated data may include for example data such as pointers and addresses for locating capture data in common data buffers and the location of compute results.

At step GPU accesses the compute instructions and associated data that are specific to GPU from GPU command queue and processes the captured data such as video data in common data buffers based on the compute instructions and associated data. For instance the compute instructions may track finger motions in the captured video data.

In an embodiment the compute instructions include tasks as well as embedded priority and dependency information. There may be several levels of priority such that higher level priority tasks are scheduled to be completed first. For example GPU schedules tasks based on the priority information so that the highest priority tasks such as real time tasks are completed before tasks with lower priority that are not time sensitive. An embodiment further includes scheduling by the processing unit such as GPU the tasks based on priority information in the compute instructions. In another embodiment real time tasks have a highest priority.

At step when motion tracking is successful the compute instructions can further render low latency visual feedback and overlay that on the display. Additionally a hardware interrupt can be issued to the OS that causes analysis of motion tracking results and virtual device driver to convert a recognized supported gesture into corresponding messages that OS natively supports. Thus many application on OS platform can utilize the messages. This is in contrast to the typical implementation at step of method of . At step application processes the detected gestures and converts them to respective actions. The processing and visual feedback latency in method is so high that application will not meet users expectations. In addition the detected gestures are utilized by application rather than being converted to standard OS messages for use by other applications.

At step a determination is made whether the need for gesture input ends or not. Gesture recognition can be terminated by the user through a control utility or by the gesture recognition service itself when no tracked object s is detected for a settable period of time. If gesture recognition does not end method returns to step and the process repeats as long as peripheral device captures new data. If gesture recognition ends the virtual device driver becomes inactive at step . Gesture recognition can resume due to user actions either through a control utility or through application for example.

System and method allow application or any application that utilizes OS platform i.e. recognizes OS messages to continue to interact with peripheral device driver and OS in the same manner as described in i.e. the tight integration between peripheral device and GPU is transparent to the rest of system .

The tight integration of the firmware in peripheral device and GPU obviates the need for application to orchestrate the gesture processing pipeline. In particular application is not involved in configuration steps nor in processing captured data or providing instructions in steps which is in contrast to method . Further after configuration steps OS is not involved until a gesture is recognized and converted to an OS supported message at step .

The time lapse or latency between the time peripheral device generates and stores data in common data buffers at step and the time GPU processes the data in step in computing system and presents visual feedback on the screen is substantially less than the latency between steps and steps of computing system . The latency is shorter and more predictable.

Additionally or alternatively a similar method may be applied to other applications including but not limited to other types of HCI applications such as facial recognition eye detection and limb detection as well as stereo image processing and audio processing.

It is to be appreciated that operations in method may be performed in a different order than shown and method may not include all operations shown. For ease of discussion and without limitation method will be described in terms of elements shown in . For illustrative purposes and not limitation an example with a real time low latency touch free HCI application with gesture recognition as application and a camera module as peripheral device is also described.

At step a determination is made whether compute instructions executed on a portion of data or a frame of data has detected motion of a tracked object e.g. tracking a finger motion. If motion has not been detected method continues to step of .

If execution of compute instructions has detected tracked motion method branches to step to generate low latency visual feedback and step to notify virtual device driver to examine the compute results.

At step based on compute instructions GPU will proceed to provide low latency visual feedback to a display by rendering frames of potential gesture trajectories being traced. Low latency visual feedback can be a rendered animation showing tracked moving object s in progress such as a vertical finger movement and assures the user that a potential gesture is being tracked by system . When the rendering of each animation frame is done method continues to step .

At step according to compute instructions GPU firmware presents the rendered result as an animation on a display screen potentially as an overlay on top of regular screen content with proper per pixel alpha blending. Per pixel alpha blending would for example allow the visual feedback to appear as a transparent overlay e.g. a visual image or video of the traced gesture on top of the regular screen content on the display screen. Method continues to step of .

At step based on compute instructions GPU generates a hardware interrupt to OS . OS recognizes the interrupt as coming from GPU and will forward the interrupt to GPU driver .

At step based on the data structure e.g. an identifier that signifies an HCI compute function associated with the interrupt GPU driver will call its child virtual device driver to process the compute results. For example virtual device driver may include functions to combine the motion tracking results produced by compute in step over a time period to determine that several frames of the tracked motion of a specific finger form a mouse click gesture.

At step a determination is made whether virtual device driver detects the presence of a supported gesture. If a supported gesture is not detected which is the case for most of the time method continues to step of .

If a supported gesture is detected at step the supported gesture is presented to OS as a message native to OS . For example the mouse click gesture is translated by virtual HCI device driver to the associated native OS message such as a mouse click message. Thus application designed as a real time low latency touch free HCI application or any application can readily utilize the mouse click message as if the message was from a physical mouse device even though the message originated as a gesture captured from a camera.

Various aspects of the disclosure can be implemented by software firmware hardware or a combination thereof. illustrates an example computer system in which some embodiments or portions thereof can be implemented as computer readable code. For example the methods and of can be implemented in system . Various embodiments are described in terms of example computer system . After reading the description it will become apparent to a person skilled in the relevant art how to implement the embodiments using other computer systems and or computer architectures.

Computer system includes one or more processors such as processor . Processor can be a special purpose or a general purpose processor. Examples of processor are CPU and GPU of or an APU that includes a CPU and one or more processors such as a GPU or a GPGPU. Processor is connected to a communication infrastructure for example a bus or network such as bus of .

Computer system also includes a main memory such as random access memory RAM and may also include a secondary memory . Secondary memory may include for example a hard disk drive a removable storage drive and or a memory stick. Removable storage drive may comprise a floppy disk drive a magnetic tape drive an optical disk drive a flash memory or the like. The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit may comprise a floppy disk magnetic tape optical disk etc. that is read by and written to by removable storage drive . As will be appreciated by persons skilled in the relevant art s removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

In alternative implementations secondary memory may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means may include for example a removable storage unit and an interface . Examples of such means may include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces that allow software and data to be transferred from the removable storage unit to computer system .

Computer system may also include a communications interface . Communications interface allows software and data to be transferred between computer system and external devices. Communications interface may include a modem a network interface such as an Ethernet card a communications port a PCMCIA slot and card or the like. Software and data transferred via communications interface are in the form of signals that may be electronic electromagnetic optical or other signals capable of being received by communications interface . These signals are provided to communications interface via a communications path . Communications path carries signals and may be implemented using wire or cable fiber optics a phone line a cellular phone link an RF link or other communications channels.

In this document the terms computer program medium and computer usable medium are used to generally refer to media such as removable storage unit removable storage unit and a hard disk installed in hard disk drive . Signals carried over communications path can also embody the logic described herein. Computer program medium and computer usable medium can also refer to memories such as main memory and secondary memory which can be memory semiconductors e.g. DRAMs etc. . These computer program products are means for providing software to computer system .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs may also be received via communications interface . Such computer programs when executed enable computer system to implement the embodiments as discussed herein. In particular the computer programs when executed enable processor to implement the disclosed processes such as the steps in the methods of of as discussed above. Accordingly such computer programs represent controllers of the computer system . Where the embodiments are implemented using software the software may be stored in a computer program product and loaded into computer system using removable storage drive interface hard drive or communications interface . This can be accomplished for example through the use of general programming languages such as C or C hardware description languages HDL including Verilog HDL VHDL Altera HDL AHDL and so on or other available programming and or schematic capture tools such as circuit capture tools . The computer program code can be disposed in any known computer readable medium including semiconductor magnetic disk or optical disk such as CD ROM DVD ROM . As such the code can be transmitted over communication networks including the Internet and internets. It is understood that the functions accomplished and or structure provided by the systems and techniques described above can be represented in a core such as a processing unit core that is embodied in program code and may be transformed to hardware as part of the production of integrated circuits.

Embodiments are also directed to computer program products comprising software stored on any computer useable medium. Such software when executed in one or more data processing device causes a data processing device s to operate as described herein. Embodiments employ any computer useable or readable medium known now or in the future. Examples of computer useable mediums include but are not limited to primary storage devices e.g. any type of random access memory secondary storage devices e.g. hard drives floppy disks CD ROMS ZIP disks tapes magnetic storage devices optical storage devices MEMS nanotechnological storage device etc. and communication mediums e.g. wired and wireless communications networks local area networks wide area networks intranets etc. .

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments as contemplated by the inventor s and thus are not intended to limit the disclosure and the appended claims in any way.

The disclosure has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.

The foregoing description of the specific embodiments will so fully reveal the general nature of the embodiments that others can by applying knowledge within the skill of the art readily modify and or adapt for various applications such specific embodiments without undue experimentation without departing from the general concept of the present disclosure. Therefore such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.

The breadth and scope of the present disclosure should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

