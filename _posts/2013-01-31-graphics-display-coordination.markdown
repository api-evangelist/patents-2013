---

title: Graphics display coordination
abstract: The subject matter of this specification can be embodied in, among other things, a method that includes computer-implemented graphics frame buffer process that establishes on a computing device a graphics frame buffer accessible to be written by an application process and to be read by a graphics server process. The method further comprises generating a plurality of control bits whose value or values control access to the frame buffer by the application process and the graphics server process and reading frames from the frame buffer using the value or values in the plurality of control bits.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08717375&OS=08717375&RS=08717375
owner: Google Inc.
number: 08717375
owner_city: Mountain View
owner_country: US
publication_date: 20130131
---
This application is a continuation of U.S. application Ser. No. 12 268 192 filed on Nov. 10 2008 which claims priority from U.S. Provisional Application Ser. No. 60 987 381 filed Nov. 12 2007 and entitled Graphics Display Coordination the contents of which are incorporated herein by reference.

As computers become more powerful users demand better visual performance from their computers. A black screen with green text will not suffice anymore for most people. Rather color graphics with animation and video is now the norm on desktop computers. Such impressive graphics displays are often rendered by dedicated graphics cards with high speed graphics processing units GPUs or other powerful processors programmed to crunch the data needed to produce beautiful fast changing displays.

As people use their cellular telephones and other mobile devices for more activities such as web surfing local search and watching of videos those smaller devices need to provide better graphics capability. Yet graphics processing traditionally require space and electrical power both of which are anathema to mobile battery operated devices. One part of graphics processing that can require processing power is communications and coordination between applications seeking to place content on a device s display and a graphics processor or server that is responsible for generating the display.

This document describes systems and techniques that may be used to manage the rendering of graphical content on a computing device such as a mobile smartphone or personal digital assistant. In general and in certain implementations inter process communications may be largely avoided by using a token or small area of memory holding state variables to coordinate actions between a computer application wishing to draw to a device display and a graphics processor or server tasked with managing such drawing to the display.

The application process and a graphics process may both look to the token for cues regarding the status of a frame buffer and may also write to the token to change its statuses. For example the token may contain a bit that is written by the application process to indicate that a frame is ready and that can be cleared by the graphics process when the frame is read. Also the token may contain a bit that indicates which buffer an application should write to i.e. where the frame buffer has multiple buffers and the graphics process may flip that bit after it has read from a particular buffer. Various other mechanisms may also be used to minimize the need for high overhead processes such as inter process communication used for frame coordination in the frame passing process.

In certain implementations such systems and technique may provide one or more advantages. For example using a token rather than inter process communications or other similar mechanisms to coordinate frame passing may lower the overhead required for such activities. As a result additional graphics processing power may be freed up for other actions which may improve the speed of a processor improve the resolution or color depth of the displayed graphics lower the speed required of the graphics processor lower the power required for generating graphics and lower the heat generated by such processing.

In one implementation a computer implemented graphics frame buffer process is disclosed. The process comprises a computer implemented graphics frame buffer process that establishes on a computing device a graphics frame buffer accessible to be written by an application process and to be read by a graphics server process. The process further comprises generating a token whose value or values control access to the frame buffer by the application process and the graphics server process and reading frames from the frame buffer using the value or values in the token.

In a second general aspect a tangible recordable media has recorded and stored thereon instructions that when executed perform establishes on a computing device a graphics frame buffer accessible to be written by an application process and to be read by a graphics server process. The tangible recordable media having recorded and stored instructions further comprises generating a token whose value or values control access to the frame buffer by the application process and the graphics server process read frames from the frame buffer using the value or values in the token.

In a third general aspect a computer graphics processing system comprises a graphics processor to operate a graphics display process and a graphics frame buffer accessible by an application process and the graphics display process. The system further comprises a token associated with the graphics frame buffer presenting a state of the graphics frame buffer to the graphics processor and one or more application processes.

The details of one or more embodiments of the graphics management features are set forth in the accompanying drawings and the description below. Other features and advantages of the graphics management features will be apparent from the description and drawings and from the claims.

This document describes systems and techniques for coordinating the display of graphics data on a computing device. In an illustrative implementation graphics applications may share access to a frame buffer with a graphics server by setting and clearing bits in an area of shared memory. For example a graphics application may generate image data that represents a three dimensional image and store the data in a frame buffer associated with the application. When notified that such data has been stored or periodically without notification a graphics server may read the data from the buffer and display the image on the screen of a computing device.

Access to the buffer may be controlled by setting and clearing bits of memory in a segment of shared memory. Each bit may represent status information related to buffer e.g. whether an application may access the buffer which part of the buffer is available for processing etc. By setting and clearing bits in shared memory in an appropriate manner the graphics applications and the graphics server may share access to a frame buffer without engaging in direct communication and active synchronization.

The graphics applications generally include application programs running on the system such as business applications mapping applications or other programs that need to communicate with a user through a graphical user interface GUI . The display of such information in the GUI is not performed directly by the graphics applications but is instead performed by the graphics server which may include one or more processes running on a microprocessor or graphical processing unit GPU . In general display of information associated with applications that a device is running occurs by the applications passing images to the graphics server through the frame buffers and through cooperation of the applications and the graphics server as is explained more fully here.

The graphics applications can generate a series of three dimensional images or other graphics information for storage in the frame buffers . For example applications may determine the viewpoint from which a imaginary camera may observe the image frame being created. After determining the viewpoint applications may generate geometric primitives such as triangles and polygons or more advanced objects such as surfaces to represent three dimensional objects in the frame.

Each application may have a frame buffer associated with it. Frame buffers can be areas of memory reserved for writing image data for a frame created by applications . The memory may be shared as between a particular application and the graphics server but each application s frame buffer may be protected from access by any other application.

The image data provided by the applications can be read from the buffers by the server which may display the data on the computing device s screen. In certain implementations the frame buffers are divided into two sections or buffers a front buffer and a back buffer. Each section of the buffer may be accessed in a mutually exclusive fashion by the server and the application associated with the frame buffer . Access to the frame buffer may be controlled by setting bits in shared memory also referred to as a token as explained in more detail below.

In addition to frame buffers applications may also have access to one or more tokens which are simply indicators that can be read and or written by the server and the respective application to coordinate access to the frame buffers .

As data is written to and read from a frame buffer bits in tokens may be set and cleared by the applications and server to indicate which sections of the buffers can and or should be written to or read from. For example one or more bits may indicate whether the particular frame buffer or is currently being processed by the server which buffer within the frame buffer or is available for use by the associated application and whether the relevant buffer or needs to be serviced by the server among other information related to the status of the buffers.

Generally tokens and frame buffers are implemented in partially shared memory memory that is shared between the server and a particular application or perhaps a group of applications but that is not shared with other applications. In some implementations tokens may be implemented in a frame buffer . For instance one or more bits of the buffer may be set aside to control access to the buffer . In an illustrative example tokens may be implemented as either two or four bits of the frame buffer however other implementations may involve additional or in some cases fewer bits.

Work list is used by server to control which frame buffer is next accessed. Work list may include a list of applications whose associated frame buffers are awaiting processing by the server . In some circumstances an application may send a signal to the work list indicating that the application s frame buffer has data ready for processing by the server in response to the signal work list may add the address of the application s frame buffer to the list for future processing by the server. The server may periodically check the work list and in response may process data contained in the applications frame buffers in the order the buffers are presented in the list .

In other implementations the server may process the buffers designated in the work list according to a criteria other than when the buffer was added to the list e.g. certain buffers may be flagged in the list for expedited processing the list may be sorted based on the amount of data stored in the buffers etc. Also even when applications report availability of frames to the list the report may be more of a soft report than a command in that the list may show all currently registered and operating applications and server may use the list simply as a mechanism to cycle through the buffers each time it wakes up e.g. 30 or 60 times each second .

Server can manipulate the geometric primitives and surfaces created by the applications to create a cohesive scene and display the resulting frame on the screen of a computing device such as a personal digital assistant cellular telephone personal computer or other appropriate computing device. In some situations server is implemented as a surface manager see and the accompanying description for a detailed discussion of the surface manager and its functions.

In an illustrative implementation the server may read the image data created and stored in the frame buffers by the applications when an appropriate bit in shared memory is set or in response to information contained in the work list .

The server may subsequently convert the objects stored in the buffers from their own coordinate system i.e. model space to a coordinate system suitable for additional processing. For example the server may first transform the objects from model space to world space i.e. the scene s coordinate system. In addition to or often in lieu of the transformation from model to world space the server can transform the objects into view space the coordinate system of the camera. Once the objects have been transformed into view space further manipulations may occur.

In some circumstances the server may determine which objects are visible in the scene by for example calculating which objects if any are within the viewing frustum of the camera objects outside the frustum are excluded from further processing. In addition the server may remove objects in the scene that are blocked i.e. occluded by objects in the foreground of the scene. Further object exclusion may occur when the objects are converted from view space into clipping space i.e. where the coordinates of the three dimensional objects are normalized into a specified range e.g. x and y coordinates between 1 and 1 and z coordinates between 0 and 1. Sections of scene objects that reside partially outside the clip space are removed from the scene. When the server has determined which objects are part of the scene the server may perform additional processing lighting texture mapping etc. before displaying the objects on the screen of the device.

Other operations may also be performed by the server in combining information from multiple applications for presentation on a computer display. For example where different applications are competing for screen real estate the server may determine which data from each application to display and may combine the provided data into one composite presentation.

After the server has processed a frame buffer the server may indicate that the frame buffer is available for use by the application by for example setting and clearing the appropriate bits in token or . In some implementations each application may have a server responsible for drawing the images saved in the frame buffer to the display screen. For example each application may have portions of one or more objects or surfaces to be displayed on the computing device. After the application has written its portion of the image data to the application s frame buffer the server assigned to the application may draw the data stored in the buffer to the appropriate area of the display.

In an illustrative example the system may prepare to draw an image by instantiating one or more applications and servers . Upon receiving a request from an application the server may allocate an area in memory for each application to store the image data it creates i.e. the server may create a frame buffer or for each application .

Before an application attempts to store image data in its frame buffer the application may check the state of control bits in token . For example one or more of the control bits may indicate that both sections of or buffers in the frame buffer are free and that the application may write to the frame buffer . If this is the case the application may in some implementations write its image data to the front section of the buffer subsequently the application may set one or more bits indicating that the front section of the buffer is no longer free and requesting that the server process that section of the buffer .

If the application attempts to write to the frame buffer before the server has serviced the front segment of the buffer the state of the control bits will indicate that the application should write data to the back of the buffer. After writing to the back portion of the buffer the application may in some implementations set a control bit indicating that buffers are full. If this bit is set the application will be forced to wait for the server to process the stored data before the application can write additional data to a segment of the buffer 

Once server is aware that a buffer is ready to be processed the server can access the appropriate section of the buffer and draw its contents on the display screen of an output device such as cellular telephone. In some implementations the server periodically checks the work list to determine whether any buffers have data that should be displayed. Alternatively the server may use the control list to cycle through the frame buffers regardless of whether data is ready for display and may check the appropriate control bits for each application to determine if data for that particular application is ready for display. The control bits may also be integrated with the control list .

For example in addition to or instead of setting a control bit in shared memory an application may submit a processing request to the work list . In some cases the request may contain the frame buffer s handle in other implementations the request may contain additional information such as which buffer section contains data the priority of the request or other pertinent information. The server may process the requests in the list in either ascending or descending order or may process the requests according to other criteria such as the amount of data contained in the buffer whether the image data contained in the buffer is in the foreground of the display whether the image data is dynamic i.e. moving etc.

In some situations the server may read a control bit in token to determine whether any data needs processing. For example one or more of the bits may indicate a processing request by an application . When the bit is set it indicates to the server that data is awaiting processing and the server may respond by displaying the data on an output device such as a screen. The server may also check another bit that may indicate which section of the buffer is to be processed next i.e. a bit that may be flipped by the server each time it finishes reading from the particular frame buffer .

While the server is processing a buffer segment the server may set one or more control bits to indicate that the server is processing data contained in the buffer. If these bits are set an application may not be allowed to write data to the section being processed by the server. Once the server has finished processing the server may clear i.e. zero the aforementioned control bit or bits indicating that an application may write data to the buffer. In addition and as noted the server may flip one or more bits that indicates which segment of the buffer is available for write operations by the server. After the control bits are reset the process can be repeated. Further descriptions of processing by servers such as server are provided below with respect to .

The device may communicate with a remote computing device via a network such as the Internet. Such communication may occur for example wirelessly via a cellular network WiFi WiMAX or similar mechanism.

In operation application code may be stored in a persistent area of memory e.g. disk drive or Flash memory and accessed by CPU when an application is launched or while the application is running. As the user interacts with an application additional data may be formed by the application and stored in persistent or non persistent e.g. RAM areas of memory in various well known manners. Also the CPU may cause communication to occur over an interface to the network such as through HTTP requests and responses or other similar mechanisms.

As the applications generate information to be viewed by the user they may provide such information to the GPU for final processing before it is provided to a display on the device using the techniques described here.

The GPU can run one or more graphics applications that can produce image data . Alternatively the applications may run on CPU . In addition the GPU may also run one more graphics servers to perform various operations on the image data created by the applications such as lighting culling texture mapping etc. In an illustrative example once a program requiring three dimensional graphics is executed on the device one or more graphics applications and graphics servers may be created in response. After the servers and applications have been created the servers may provide each application with access to a section of the frame buffer storage . Each application may store image data created by the application in its associated area of the frame buffer storage . Subsequently one or more graphics servers may process the image data by for example performing lighting culling texture mapping or MIP mapping shading or other operations on the image data. Once the image data has been processed the image data may be displayed on the device s display screen.

Referring to the process begins at step when applications are launched and server may have been previously launched . Applications and server may be launched when a device attempts to generate a three dimensional or other graphical display. For example a cellular telephone user may select a three dimensional video game by selecting an icon that represents the program in the device s graphical user interface. In response the device s operating system may launch one or more applications and server or servers to generate the three dimensional objects required by the game.

After the applications and server have been launched the method proceeds to step where a request is received to establish a frame buffer . In some instances once an application has been created it may send a request to a server to create a frame buffer for the application . For example the application may contact the server via a communication channel e.g. using inter process communications or IPC and ask the server to generate a frame buffer containing a specific number of bits. In response the server may reserve memory for the frame buffer including control bits in a token at step . For example the server may reserve the amount of memory specified by the application and also reserve a segment of memory to act as a token for coordination purposes. In an alternative implementation the server may dynamically determine the size of the buffer or the buffer size may be predetermined. In some situations the token may be implemented in the frame buffer .

After the memory has been reserved the server may return a handle to the application at step . For instance the server may return the address i.e. the handle of the memory it allocated for the application s buffer to the application by means of the communication channel.

At step before the server attempts to read data from a frame buffer the server checks the status of control bits in the token associated with the frame buffer to determine whether the data is ready for processing and if so which section of the buffer needs processing. In an illustrative implementation two control bits may reside in shared memory. One bit may alert the server that there is information in a section of the buffer or waiting to be processed the work bit the other bit may indicate which section or segment of the buffer is free to accept image data from an application the buffer bit . When the work bit is one there is data in the buffer for the server to process and the application may not write to the buffer if the bit is zero the buffer is empty and free for use by the application. Similarly if the buffer bit is zero the front segment of the buffer is available for processing if the buffer bit is one the back segment of the buffer may be used by the application to store image data. However unlike the work bit only the server may change the value of the buffer bit in this example.

Before the server attempts to read data from the buffer the server checks the status of both the work bit and the buffer bit at steps and to determine which buffer contains data ready for processing. As noted above if the work bit is one the buffer contains data that can be processed by the server . At step the server checks the work bit if it is set the method may proceed to step . Assuming that the work bit is set i.e. the bit is one the server will check the status of the buffer bit to determine which buffer to read from as will be explained in reference to step next.

At step the server reads from either the front or back segment of the frame buffer depending on the state of the buffer bit. If the buffer bit is set i.e. the bit is one the server reads data from the back section of the frame buffer if not the server reads data from the front segment. As the server reads data from the appropriate part of the buffer it displays the data on the screen of the computing device. After the server has finished reading data from the buffer it may flip the work bit at step and clear the buffer bit at step subsequently the method returns to step where the server polls the work bit to determine if any data is ready for display.

This method may occur repeatedly while a server is active. The repetition may occur as applications write to the frame buffer or as the server periodically wakes up to determine if there is work for it to do.

In response at step the server may create a frame buffer for the application by reserving a section of memory for the application and in some implementations a separate section of shared memory to control access to the buffer e.g. a token . In some implementations the server may reserve one or more bits of the frame buffer to control access to the buffer. In this example the server may create a piece of shared memory that consists of two bits. Subsequently the server may clear both the shared memory and the frame buffer and return the addresses of the memory locations to the application. Other forms of tokens which may use more or fewer bits may also be implemented and frame buffers that operate by mechanisms other than bits may also be employed.

Once the application has received the frame buffer s handle the application may write data into the frame buffer at step . In an illustrative example as discussed above the application may check one of the control bits e.g. bit one known as the work bit to determine if the application can write data into the buffer. If the bit is one there is data in the buffer waiting to be displayed and the application cannot write to the buffer if the bit is zero the application may write data into the buffer. Because the server cleared shared memory when it was allocated the work bit is initially zero thus the application may write image data into the buffer.

To determine which segment of the frame buffer the application may write to the application checks the second bit e.g. bit zero known as the buffer bit. When the buffer bit contains a zero the front segment of the buffer is available to store image data when the buffer bit contains a one the back segment of the buffer may be used to store image data. But as noted above only the server may alter the status of the buffer bit in this example. Like the work bit the buffer bit is initially set to zero so the application can write to the front buffer. Once the application has written data into the buffer the application may set the work bit to one.

After the application has written data to the buffer the application cannot write to the buffer unless the server has processed the data placed in the buffer. Thus the method proceeds to the step where the application waits for the server to process the buffer. The server may be alerted to the presence of data in the buffer by as noted above checking either the task list or the work bit.

In the illustrative example once the server detects that the work bit has been set to one at step the server may access the buffer and display its contents on the screen of the computing device. After the buffer has finished processing the buffer at step the server may flip the buffer bit here setting the buffer bit to one and clear the work bit. Once the server has displayed the contents of the buffer the application may again write data to the buffer after the application has finished writing data to the buffer the application may again set the work bit at step

The process described above may be repeated with the same server and another application and such process may be interleaved with subsequent such processes with the initial application. As shown in the figure at step a second application is launched as described above afterwards the second application may connect to the server and request a frame buffer at step . In response the server may again allocate memory for a frame buffer and shared memory and return the handle of the memory to the second application at step . As described above in steps the second application and server may write and read data from the buffer in a similar fashion using the control bits in shared memory in steps .

The token is represented by a four bit segment of memory in which each bit that relates to the status of a frame buffer associated with the token. The buffer number bit indicates which segment of the buffer to use. The request pending bit acts as a flag to indicate that there is work available for the server if the bit is on i.e. set to one a buffer section contains image data that the server can process. The next buffer pending indicates whether both buffers have been used while the busy buffer bit indicates that the buffer is being processed by the server. Only the server may alter the state of the buffer number bit in this example to prevent conflicts in the process. In an illustrative example at state the token is initially clear i.e. all the bits in shared memory are set to zero. The token may have been initially established in this state or multiple writes to and reads from the frame buffer may have left the token in such a state.

When an application attempts to write to the buffer the application checks the state of the request pending bit to see whether there is any work available for the server. Because in the illustrative example the request pending buffer is set to zero the application may write to a segment of the buffer subsequently the application checks the buffer number bit to determine which buffer segment is available. Like the request pending buffer the buffer number is also initially zeroed indicating that the application may write to the front buffer which in this example the application does. After writing the image frame to the front buffer the application sets the request pending bit to one leaving the token in the state shown at state .

The application may attempt to write another image frame to the frame buffer while the server does not yet act on the buffer . As before the application checks the status of the request pending buffer. Here at state the request pending bit is set to one thus the application checks the busy bit here the busy bit is still zero because the server is not currently accessing the buffer. The status of the bits at state request pending set to one while buffer number is zero indicates that data has been stored in the front buffer thus the application will write data into the back buffer. Once the application has finished writing data the application sets the next buffer pending bit to one as illustrated at state .

Optionally the application may send a message to the server process either directly or indirectly. For example the application process may send a message to an activity list that is monitored by the server process when the server process is active. Alternatively the application may send a message that wakes the server process up so that it checks the token and reads the data out of the buffer.

The process described above is repeated if the application attempts to write a third image to the buffer. The application first checks the state of the request pending bit and because the request pending bit is set to one the application subsequently checks the state of the next buffer pending bit which shows that both buffers have been filled.

About the same time the server wakes up and becomes directed to the token. In the illustrative example the server may begin to process buffer data as it periodically polls either a work list or various tokens or in some implementations both associated with currently active applications the server may become aware that data in a buffer is waiting to be processed. For example the server may scan tokens for a set request pending bit. Once a set request pending bit is located the server checks both the buffer number and request pending bits of the associated token to determine which buffer section contains the most recent data. In the illustrative example the buffer number and request pending are zero and one respectively as indicated by state .

Because the buffer number bit is zero while the request pending bit is one the server is aware that the back buffer contains the most recently stored image data as only the server can change the state of the buffer number bit. In other words because the buffer number is still zero and a buffer segment contains data as indicated by the request pending bit being set to one the back buffer must contain the most recent image data because in the illustrative example the application writes to the front buffer first when the buffer number is set to zero.

As illustrated in state while the server reads data from the back buffer it sets the busy bit to one to prevent an application from accessing the buffer while the servers is reading data from the buffer. After the server has completed reading data from the buffer it sets the next buffer pending bit to zero flips the state of the buffer number bit here the buffer number would now be set to one and clears the busy bit and request pending bit as illustrated in state .

Once the busy bit is reset to the zero the application can once again write image data to the buffer. In the illustrative example the application once again begins the process of writing image data to the frame buffer by examining the state of the request pending bit. As illustrated by state the request pending bit is zero so the application proceeds to look at the buffer number bit. Because the buffer number bit has been set to one the application begins writing data into the back buffer. After writing the image to the back buffer the application sets the request pending bit to one to produce the bit configuration shown in state .

The application may repeat the process described above to write another frame to the front buffer. Again the application first checks the state of the request pending bit as the bit has been set to one the application proceeds to look at the busy bit which in the illustrative example has been cleared. After checking both the request pending and busy bits the application proceeds to check the buffer number bit. Here the buffer number bit like the request pending bit has been set to one thus the front buffer is not available for data storage. The application sets the next buffer pending bit to one as illustrated in state .

As noted above once the next buffer pending bit is set the application may be barred from writing data to the frame buffer until the server processes the buffer. When the server begins to process the buffer the server sets the busy bit to one. The server than considers the state of buffer number and request pending bits to determine which segment of the buffer contains the most recently stored image data. In the illustrative example the front buffer contains the most recent data because both the buffer number and request pending bits are one the application would have written to the back buffer first so the server begins to read data from the front buffer. While the server is processing the data it sets the busy bit to one as illustrated in state .

Once the server has processed the image data the server resets the busy bit and next buffer pending bits to zero. In addition the server also flips the buffer number bit which in this example sets the buffer number to zero and zeros the request pending bit.

Referring now to the exterior appearance of an exemplary device that implements the graphics management system is illustrated. Briefly and among other things the device includes a processor configured to generate graphics on a display of a mobile device upon request of a user operating an application on the device.

In more detail the hardware environment of the device includes a display for displaying text images and video to a user a keyboard for entering text data and user commands into the device a pointing device for pointing selecting and adjusting objects displayed on the display an antenna a network connection a camera a microphone and a speaker . Although the device shows an external antenna the device can include an internal antenna which is not visible to the user.

The display can display video graphics images and text that make up the user interface for the software applications used by the device and the operating system programs used to operate the device . Among the possible elements that may be displayed on the display are a new mail indicator that alerts a user to the presence of a new message an active call indicator that indicates that a telephone call is being received placed or is occurring a data standard indicator that indicates the data standard currently being used by the device to transmit and receive data a signal strength indicator that indicates a measurement of the strength of a signal received by via the antenna such as by using signal strength bars a battery life indicator that indicates a measurement of the remaining battery life or a clock that outputs the current time.

The display may also show application icons representing various applications available to the user such as a web browser application icon a phone application icon a search application icon a contacts application icon a mapping application icon an email application icon or other application icons. In one example implementation the display is a quarter video graphics array QVGA thin film transistor TFT liquid crystal display LCD capable of 16 bit or better color.

A user uses the keyboard or keypad to enter commands and data to operate and control the operating system and applications that provide for graphics management. The keyboard includes standard keyboard buttons or keys associated with alphanumeric characters such as keys and that are associated with the alphanumeric characters Q and W when selected alone or are associated with the characters and 1 when pressed in combination with key . A single key may also be associated with special characters or functions including unlabeled functions based upon the state of the operating system or applications invoked by the operating system. For example when an application calls for the input of a numeric character a selection of the key alone may cause a 1 to be input.

In addition to keys traditionally associated with an alphanumeric keypad the keyboard also includes other special function keys such as an establish call key that causes a received call to be answered or a new call to be originated a terminate call key that causes the termination of an active call a drop down menu key that causes a menu to appear within the display a backward navigation key that causes a previously accessed network address to be accessed again a favorites key that causes an active web page to be placed in a bookmarks folder of favorite sites or causes a bookmarks folder to appear a home page key that causes an application invoked on the device to navigate to a predetermined network address or other keys that provide for multiple way navigation application selection and power and volume control.

The user uses the pointing device to select and adjust graphics and text objects displayed on the display as part of the interaction with and control of the device and the applications invoked on the device . The pointing device is any appropriate type of pointing device and may be a joystick a trackball a touch pad a camera a voice input device a touch screen device implemented in combination with the display or any other input device.

The antenna which can be an external antenna or an internal antenna is a directional or omni directional antenna used for the transmission and reception of radiofrequency RF signals that implement point to point radio communication wireless local area network LAN communication or location determination. The antenna may facilitate point to point radio communication using the Specialized Mobile Radio SMR cellular or Personal Communication Service PCS frequency bands and may implement the transmission of data using any number or data standards. For example the antenna may allow data to be transmitted between the device and a base station using technologies such as Wireless Broadband WiBro Worldwide Interoperability for Microwave ACCess WiMAX 3GPP Long Term Evolution LTE Ultra Mobile Broadband UMB High Performance Radio Metropolitan Network HIPERMAN iBurst or High Capacity Spatial Division Multiple Access HC SDMA High Speed OFDM Packet Access HSOPA High Speed Packet Access HSPA HSPA Evolution HSPA High Speed Upload Packet Access HSUPA High Speed Downlink Packet Access HSDPA Generic Access Network GAN Time Division Synchronous Code Division Multiple Access TD SCDMA Evolution Data Optimized or Evolution Data Only EVDO Time Division Code Division Multiple Access TD CDMA Freedom Of Mobile Multimedia Access FOMA Universal Mobile Telecommunications System UMTS Wideband Code Division Multiple Access W CDMA Enhanced Data rates for GSM Evolution EDGE Enhanced GPRS EGPRS Code Division Multiple Access 2000 CDMA2000 Wideband Integrated Dispatch Enhanced Network WiDEN High Speed Circuit Switched Data HSCSD General Packet Radio Service GPRS Personal Handy Phone System PHS Circuit Switched Data CSD Personal Digital Cellular PDC CDMAone Digital Advanced Mobile Phone System D AMPS Integrated Digital Enhanced Network IDEN Global System for Mobile communications GSM DataTAC Mobitex Cellular Digital Packet Data CDPD Hicap Advanced Mobile Phone System AMPS Nordic Mobile Phone NMP Autoradiopuhelin ARP Autotel or Public Automated Land Mobile PALM Mobiltelefonisystem D MTD Offentlig Landmobil Telefoni OLT Advanced Mobile Telephone System AMTS Improved Mobile Telephone Service IMTS Mobile Telephone System MTS Push To Talk PTT or other technologies. Communication via W CDMA HSUPA GSM GPRS and EDGE networks may occur for example using a QUALCOMM MSM7200A chipset with an QUALCOMM RTR6285 transceiver and PM7540 power management circuit.

The wireless or wired computer network connection may be a modem connection a local area network LAN connection including the Ethernet or a broadband wide area network WAN connection such as a digital subscriber line DSL cable high speed internet connection dial up connection T 1 line T 3 line fiber optic connection or satellite connection. The network connection may connect to a LAN network a corporate or government WAN network the Internet a telephone network or other network. The network connection uses a wired or wireless connector. Example wireless connectors include for example an INFRARED DATA ASSOCIATION IrDA wireless connector a Wi Fi wireless connector an optical wireless connector an INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS IEEE Standard 802.11 wireless connector a BLUETOOTH wireless connector such as a BLUETOOTH version 1.2 or 3.0 connector a near field communications NFC connector an orthogonal frequency division multiplexing OFDM ultra wide band UWB wireless connector a time modulated ultra wide band TM UWB wireless connector or other wireless connector. Example wired connectors include for example a IEEE 1394 FIREWIRE connector a Universal Serial Bus USB connector including a mini B USB interface connector a serial port connector a parallel port connector or other wired connector. In another implementation the functions of the network connection and the antenna are integrated into a single component.

The camera allows the device to capture digital images and may be a scanner a digital still camera a digital video camera other digital input device. In one example implementation the camera is a 6 mega pixel MP camera that utilizes a complementary metal oxide semiconductor CMOS .

The microphone allows the device to capture sound and may be an omni directional microphone a unidirectional microphone a bi directional microphone a shotgun microphone or other type of apparatus that converts sound to an electrical signal. The microphone may be used to capture sound generated by a user for example when the user is speaking to another user during a telephone call via the device . Conversely the speaker allows the device to convert an electrical signal into sound such as a voice from another user generated by a telephone application program or a ring tone generated from a ring tone application program. Furthermore although the device is illustrated in as a handheld device in further implementations the device may be a laptop a workstation a midrange computer a mainframe an embedded system telephone desktop PC a tablet computer a PDA or other type of computing device.

The display interface in particular may include a graphics processor that can run a number of processes including one or more graphics servers. The display interface may include one or more particular physical processors such as a GPU and or chip set components or may operate with or on the CPU .

The CPU can be one of a number of computer processors. In one arrangement the computer CPU is more than one processing unit. The RAM interfaces with the computer bus so as to provide quick RAM storage to the CPU during the execution of software programs such as the operating system application programs and device drivers. More specifically the CPU loads computer executable process steps from the storage medium or other media into a field of the RAM in order to execute software programs. Data is stored in the RAM where the data is accessed by the computer CPU during execution. In one example configuration the device includes at least 128 MB of RAM and 256 MB of flash memory.

The storage medium itself may include a number of physical drive units such as a redundant array of independent disks RAID a floppy disk drive a flash memory a USB flash drive an external hard disk drive thumb drive pen drive key drive a High Density Digital Versatile Disc HD DVD optical disc drive an internal hard disk drive a Blu Ray optical disc drive or a Holographic Digital Data Storage HDDS optical disc drive an external mini dual in line memory module DIMM synchronous dynamic random access memory SDRAM or an external micro DIMM SDRAM. Such computer readable storage media allow the device to access computer executable process steps application programs and the like stored on removable and non removable memory media to off load data from the device or to upload data onto the device .

A computer program product is tangibly embodied in storage medium a machine readable storage medium. The computer program product includes instructions that when read by a machine operate to cause a data processing apparatus to store image data in the mobile device. In some embodiments the computer program product includes instructions that manage the display of graphical information in a graphical user interface GUI .

The operating system may be a LINUX based operating system such as the ANDROID mobile device platform APPLE MAC OS X MICROSOFT WINDOWS NT WINDOWS 2000 WINDOWS XP WINDOWS MOBILE a variety of UNIX flavored operating systems or a proprietary operating system for computers or embedded systems. The application development platform or framework for the operating system may be BINARY RUNTIME ENVIRONMENT FOR WIRELESS BREW JAVA Platform Micro Edition JAVA ME or JAVA 2 Platform Micro Edition J2ME using the SUN MICROSYSTEMS JAVASCRIPT programming language PYTHON FLASH LITE or MICROSOFT .NET Compact or another appropriate environment.

The device stores computer executable code for the operating system and the application programs such as an email instant messaging a video service application a mapping application word processing spreadsheet presentation gaming mapping web browsing JAVASCRIPT engine or other applications. For example one implementation may allow a user to access the GOOGLE GMAIL email application the GOOGLE TALK instant messaging application a YOUTUBE video service application a GOOGLE MAPS or GOOGLE EARTH mapping application or a GOOGLE PICASA imaging editing and presentation application. The application programs may also include a widget or gadget engine such as a TAFRI widget engine a MICROSOFT gadget engine such as the WINDOWS SIDEBAR gadget engine or the KAPSULES gadget engine a YAHOO widget engine such as the KONFABULTOR widget engine the APPLE DASHBOARD widget engine the GOOGLE gadget engine the KLIPFOLIO widget engine an OPERA widget engine the WIDSETS widget engine a proprietary widget or gadget engine or other widget or gadget engine the provides host system software for a physically inspired applet on a desktop.

Although it is possible to provide for various features using the above described implementations it is also possible to implement the functions according to the present disclosure as a dynamic link library DLL or as a plug in to other application programs such as an Internet web browser such as the FOXFIRE web browser the APPLE SAFARI web browser or the MICROSOFT INTERNET EXPLORER web browser.

The navigation module may determine an absolute or relative position of the device such as by using the Global Positioning System GPS signals the GLObal NAvigation Satellite System GLONASS the Galileo positioning system the Beidou Satellite Navigation and Positioning System an inertial navigation system a dead reckoning system or by accessing address internet protocol IP address or location information in a database. The navigation module may also be used to measure angular displacement orientation or velocity of the device such as by using one or more accelerometers.

The operating system can generally be organized into six components a kernel libraries an operating system runtime application libraries system services and applications . The kernel includes a display driver that allows software such as the operating system and the application programs to interact with the display via the display interface . The display driver may include features for coordinating data transfer with various applications including applications that are part of the operating system and application programs that run on the operating system .

The kernel also includes a camera driver that allows the software to interact with the camera a BLUETOOTH driver a M Systems driver a binder IPC driver a USB driver a keypad driver that allows the software to interact with the keyboard via the keyboard interface a WiFi driver audio drivers that allow the software to interact with the microphone and the speaker via the sound interface and a power management component that allows the software to interact with and manage the power source .

The BLUETOOTH driver which in one implementation is based on the BlueZ BLUETOOTH stack for LINUX based operating systems provides profile support for headsets and hands free devices dial up networking personal area networking PAN or audio streaming such as by Advance Audio Distribution Profile A2DP or Audio Video Remote Control Profile AVRCP . The BLUETOOTH driver provides JAVA bindings for scanning pairing and unpairing and service queries.

The libraries include a media framework that supports standard video audio and still frame formats such as Moving Picture Experts Group MPEG H.264 MPEG 1 Audio Layer 3 MP3 Advanced Audio Coding AAC Adaptive Multi Rate AMR Joint Photographic Experts Group JPEG and others using an efficient JAVA Application Programming Interface API layer a surface manager a simple graphics library SGL for two dimensional application drawing an Open Graphics Library for Embedded Systems OpenGL ES for gaming and three dimensional rendering a C standard library LIBC a LIBWEBCORE library a FreeType library an SSL and an SQLite library .

The operating system runtime includes core JAVA libraries and a Dalvik virtual machine . The Dalvik virtual machine is a custom virtual machine that runs a customized file format .DEX .

The operating system can also include Mobile Information Device Profile MIDP components such as the MIDP JAVA Specification Requests JSRs components MIDP runtime and MIDP applications as shown in . The MIDP components can support MIDP applications running on the device .

With regard to graphics rendering a system wide composer manages surfaces and a frame buffer and handles window transitions using the OpenGL ES and two dimensional hardware accelerators for its compositions.

The Dalvik virtual machine may be used with an embedded environment since it uses runtime memory very efficiently implements a CPU optimized bytecode interpreter and supports multiple virtual machine processes per device. The custom file format .DEX is designed for runtime efficiency using a shared constant pool to reduce memory read only structures to improve cross process sharing concise and fixed width instructions to reduce parse time thereby allowing installed applications to be translated into the custom file formal at build time. The associated bytecodes are designed for quick interpretation since register based instead of stack based instructions reduce memory and dispatch overhead since using fixed width instructions simplifies parsing and since the 16 bit code units minimize reads.

The application libraries include a view system a resource manager and content providers . The system services includes a status bar an application launcher a package manager that maintains information for all installed applications a telephony manager that provides an application level JAVA interface to the telephony subsystem a notification manager that allows all applications access to the status bar and on screen notifications a window manager that allows multiple applications with multiple windows to share the display and an activity manager that runs each application in a separate process manages an application life cycle and maintains a cross application history.

The applications include a home application a dialer application a contacts application a browser application and graphics generating application .

The telephony manager provides event notifications such as phone state network state Subscriber Identity Module SIM status or voicemail status allows access to state information such as network information SIM information or voicemail presence initiates calls and queries and controls the call state. The browser application renders web pages in a full desktop like manager including navigation functions. Furthermore the browser application allows single column small screen rendering and provides for the embedding of HTML views into other applications.

Some processes can be persistent. For example processes associated with core system components such as the surface manager the window manager or the activity manager can be continuously executed while the device is powered. Additionally some application specific process can also be persistent. For example processes associated with the dialer application may also be persistent.

The processes implemented by the operating system kernel may generally be categorized as system services processes dialer processes browser processes and maps processes . The system services processes include status bar processes associated with the status bar application launcher processes associated with the application launcher package manager processes associated with the package manager activity manager processes associated with the activity manager resource manager processes associated with the resource manager that provides access to graphics localized strings and XML layout descriptions notification manger processes associated with the notification manager window manager processes associated with the window manager core JAVA libraries processes associated with the core JAVA libraries surface manager processes associated with the surface manager Dalvik virtual machine processes associated with the Dalvik virtual machine LIBC processes associated with the LIBC library and graphics handling processes associated with the graphics generating applications .

The dialer processes include dialer application processes associated with the dialer application telephony manager processes associated with the telephony manager core JAVA libraries processes associated with the core JAVA libraries Dalvik virtual machine processes associated with the Dalvik Virtual machine and LIBC processes associated with the LIBC library . The browser processes include browser application processes associated with the browser application core JAVA libraries processes associated with the core JAVA libraries Dalvik virtual machine processes associated with the Dalvik virtual machine LIBWEBCORE processes associated with the LIBWEBCORE library and LIBC processes associated with the LIBC library .

The maps processes include maps application processes core JAVA libraries processes Dalvik virtual machine processes and LIBC processes . Notably some processes such as the Dalvik virtual machine processes may exist within one or more of the systems services processes the dialer processes the browser processes and the maps processes .

Computing device includes a processor memory a storage device a high speed interface connecting to memory and high speed expansion ports and a low speed interface connecting to low speed bus and storage device . Each of the components and are interconnected using various busses and may be mounted on a common motherboard or in other manners as appropriate. The processor can process instructions for execution within the computing device including instructions stored in the memory or on the storage device to display graphical information for a GUI on an external input output device such as display coupled to high speed interface . In other implementations multiple processors and or multiple buses may be used as appropriate along with multiple memories and types of memory. Also multiple computing devices may be connected with each device providing portions of the necessary operations e.g. as a server bank a group of blade servers or a multi processor system .

The memory stores information within the computing device . In one implementation the memory is a volatile memory unit or units. In another implementation the memory is a non volatile memory unit or units. The memory may also be another form of computer readable medium such as a magnetic or optical disk.

The storage device is capable of providing mass storage for the computing device . In one implementation the storage device may be or contain a computer readable medium such as a floppy disk device a hard disk device an optical disk device or a tape device a flash memory or other similar solid state memory device or an array of devices including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that when executed perform one or more methods such as those described above. The information carrier is a computer or machine readable medium such as the memory the storage device memory on processor or a propagated signal.

The high speed controller manages bandwidth intensive operations for the computing device while the low speed controller manages lower bandwidth intensive operations. Such allocation of functions is exemplary only. In one implementation the high speed controller is coupled to memory display e.g. through a graphics processor or accelerator and to high speed expansion ports which may accept various expansion cards not shown . In the implementation low speed controller is coupled to storage device and low speed expansion port . The low speed expansion port which may include various communication ports e.g. USB Bluetooth Ethernet wireless Ethernet may be coupled to one or more input output devices such as a keyboard a pointing device a scanner or a networking device such as a switch or router e.g. through a network adapter.

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a standard server or multiple times in a group of such servers. It may also be implemented as part of a rack server system . In addition it may be implemented in a personal computer such as a laptop computer . Alternatively components from computing device may be combined with other components in a mobile device not shown such as device . Each of such devices may contain one or more of computing device and an entire system may be made up of multiple computing devices communicating with each other.

Computing device includes a processor memory an input output device such as a display a communication interface and a transceiver among other components. The device may also be provided with a storage device such as a microdrive or other device to provide additional storage. Each of the components and are interconnected using various buses and several of the components may be mounted on a common motherboard or in other manners as appropriate.

The processor can execute instructions within the computing device including instructions stored in the memory . The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide for example for coordination of the other components of the device such as control of user interfaces applications run by device and wireless communication by device .

Processor may communicate with a user through control interface and display interface coupled to a display . The display may be for example a TFT LCD Thin Film Transistor Liquid Crystal Display or an OLED Organic Light Emitting Diode display or other appropriate display technology. The display interface may comprise appropriate circuitry for driving the display to present graphical and other information to a user. The control interface may receive commands from a user and convert them for submission to the processor . In addition an external interface may be provide in communication with processor so as to enable near area communication of device with other devices. External interface may provide for example for wired communication in some implementations or for wireless communication in other implementations and multiple interfaces may also be used.

The memory stores information within the computing device . The memory can be implemented as one or more of a computer readable medium or media a volatile memory unit or units or a non volatile memory unit or units. Expansion memory may also be provided and connected to device through expansion interface which may include for example a SIMM Single In Line Memory Module card interface. Such expansion memory may provide extra storage space for device or may also store applications or other information for device . Specifically expansion memory may include instructions to carry out or supplement the processes described above and may include secure information also. Thus for example expansion memory may be provide as a security module for device and may be programmed with instructions that permit secure use of device . In addition secure applications may be provided via the SIMM cards along with additional information such as placing identifying information on the SIMM card in a non hackable manner.

The memory may include for example flash memory and or NVRAM memory as discussed below. In one implementation a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that when executed perform one or more methods such as those described above. The information carrier is a computer or machine readable medium such as the memory expansion memory memory on processor or a propagated signal that may be received for example over transceiver or external interface .

Device may communicate wirelessly through communication interface which may include digital signal processing circuitry where necessary. Communication interface may provide for communications under various modes or protocols such as GSM voice calls SMS EMS or MMS messaging CDMA TDMA PDC WCDMA CDMA2000 or GPRS among others. Such communication may occur for example through radio frequency transceiver . In addition short range communication may occur such as using a Bluetooth WiFi or other such transceiver not shown . In addition GPS Global Positioning System receiver module may provide additional navigation and location related wireless data to device which may be used as appropriate by applications running on device .

Device may also communicate audibly using audio codec which may receive spoken information from a user and convert it to usable digital information. Audio codec may likewise generate audible sound for a user such as through a speaker e.g. in a handset of device . Such sound may include sound from voice telephone calls may include recorded sound e.g. voice messages music files etc. and may also include sound generated by applications operating on device .

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a cellular telephone . It may also be implemented as part of a smartphone personal digital assistant or other similar mobile device.

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium computer readable medium refers to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

To provide for interaction with a user the systems and techniques described here can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

The systems and techniques described here can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here or any combination of such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network . Examples of communication networks include a local area network LAN a wide area network WAN and the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

A number of embodiments have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the invention. For example various mechanisms may be used for making buffer status known to an server and an application providing frames to the server.

In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other embodiments are within the scope of the following claims.

