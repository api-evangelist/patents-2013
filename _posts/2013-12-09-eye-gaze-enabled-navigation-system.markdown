---

title: Eye gaze enabled navigation system
abstract: A navigation system is configured to generate a sequence of driving instructions for directing a driver of a vehicle from a current location to a final destination. The navigation system is configured to capture sensor data that reflects the field of view of the driver and to identify objects in that field of view. The navigation system then customizes the driving instructions to reference specific objects, thereby generating context-specific driving instructions. The navigation system is also configured to identify particular objects upon which the driver is focused, and to generate context-specific driving instructions relative to such objects of focus. The navigation system may also provide correction information to the driver upon determining that the driver has incorrectly focused on a different object than an object referenced in a context-specific driving instruction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09354073&OS=09354073&RS=09354073
owner: HARMAN INTERNATIONAL INDUSTRIES, INC.
number: 09354073
owner_city: Stamford
owner_country: US
publication_date: 20131209
---
Embodiments of the present invention relate generally to navigation systems and more specifically to an eye gaze enabled navigation system.

A conventional navigation system is capable of generating a sequence of driving instructions for directing the driver of a vehicle from a current location to a final destination. The driver follows each driving direction in the sequence by causing the vehicle to perform a specific navigation action as dictated by the navigation system. For example a given driving direction may specify that a left turn is required 500 feet ahead. In response the driver would cause the vehicle to turn left after travelling 500 feet. Once a given driving direction has been successfully followed the navigation system proceeds to the next driving direction in the sequence. This pattern of operation continues until the vehicle arrives at the final destination.

The basic functionality described above can be effective provided that the driver interprets each direction correctly. However various factors often contribute to the driver misinterpreting the driving directions. For example driving directions that rely on measures of distance such as in the above example sometimes cannot easily be interpreted because drivers are not usually aware of the exact distances that vehicles travel in a given period of time. Furthermore drivers are usually preoccupied with the physical act of driving and may not be able to spare the attention required for interpreting complex driving directions. Due to these factors drivers that rely on conventional navigation systems sometimes become confused and consequently become lost.

One embodiment of the present invention sets forth a system configured to generate context specific driving instructions for a driver of a vehicle including at least one sensor configured to capture sensor data that reflects a field of view of the driver a computing device configured to process the sensor data to identify a first object within the field of view of the driver and generate a context specific driving instruction that references the first object and at least one output device configured to output the context specific driving instruction to the driver.

One advantage of the disclosed technique is that it enables context specific driving instructions that are consistent with the visual context of the driver. Consequently the driver may intuitively follow those instructions without distraction.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details.

As shown driver resides within vehicle that includes various components of navigation system . In particular navigation system includes eye gaze sensors outward facing cameras and speakers and and a computing device . Eye gaze sensors are configured to determine a direction of focus along which driver may be looking. Eye gaze sensors are further configured to determine a point of focus that represents a particular depth at which driver may be looking along direction of focus . Field of view represents a panorama within which driver may visually perceive objects at any given time. As such point of focus generally resides within field of view . Eye gaze sensors may determine point of focus via eyeball tracking sensors as well as head tracking sensors. Computing device is configured to process data from those sensors to determine direction of focus and point of focus within field of view . Persons skilled in the art will generally be familiar with a wide variety of techniques for determining direction of focus and point of focus . As such those techniques will not be exhaustively listed herein.

Outward facing cameras are configured to capture video data that reflects a visual panorama surrounding a portion of vehicle including field of view associated with driver . Computing device is configured to process the video data captured by outward facing cameras and to apply computer vision techniques to identify a set of objects within field of view of driver . In doing so computing device may also analyze a parallax between video data captured by outward facing cameras and in order to determine a depth value associated with each identified object. In further embodiments of the present invention outward facing cameras may include other types of sensors beyond cameras including but not limited to infrared sensors ultraviolet sensors ultrasound based sensors laser based sensors SONAR and or LIDAR devices range sensors and devices capable of generating a depth map such as e.g. a depth sensor or a time of flight camera among others. As a general matter outward facing cameras may include any type of sensor capable of identifying a set of objects and corresponding depth values within field of view of driver and outward facing cameras represent just one example of such a sensor.

Speakers are configured to output audio that dictates context specific driving instructions and correction information to driver . Speakers may be stereo speakers typically found in conventional automobiles dedicated speakers associated with navigation system or other types of audio output devices. In further embodiments of the invention speakers may also include other types of output devices beyond audio output devices including visual textual and or tactile output devices among others. Computing device is configured to generate driving instructions and correction information and to then synthesize audio reflecting that information using computer vocalization techniques.

Computing device may be any technically feasible device capable of processing data including a laptop computer a cell phone device a dedicated navigation unit a tablet computer and so forth. As a general matter computing device is responsible for managing all functionality of navigation system described herein. In operation computing device is configured to interact with driver in order to determine a final destination to which driver wishes to navigate. Computing device then determines the current location of vehicle based on global positioning service GPS data or other location services. Computing device is configured to generate a sequence of driving instructions to direct driver from the current location to the final destination. In doing so computing device may rely on a database of roadway information that could be e.g. cloud based and remotely accessible or alternatively stored within computing device . Computing device may then modify each such driving instruction to specifically reference real world objects in field of view of driver thereby generating context specific driving instructions. Computing device may also provide correction information to driver based on direction of focus and point of focus as determined by eye gaze sensors . An exemplary computing device is described in greater detail below in conjunction with .

Navigation system may generally operate according to different embodiments. In a first embodiment of navigation system navigation system provides a driving instruction to driver that references a real world object in field of view of driver . Should the driver fail to look directly at the real world object navigation system then provides correction information to driver in order to cause driver to look at the appropriate real world object. The first embodiment of navigation system is described in greater detail below in conjunction with . In a second embodiment of navigation system navigation system identifies a real world object towards which driver is already looking and then generates a driving instruction that specifically references that real world object. The second embodiment is described in greater detail below in conjunction with . Persons skilled in the art will recognize that the first and second embodiments described herein may also be combined with one another in any technically feasible fashion. In either embodiment navigation system generally operates according to various data and processing stages that are described in greater detail below in conjunction with .

Navigation system is configured to generate eye gaze information via eye gaze sensors . Eye gaze information may include data that specifies direction of focus as well as point of focus . Navigation system is also configured to generate outward facing camera information via outward facing cameras . Outward facing camera information may include multiple streams of video data captured by outward facing cameras and and may thus represent a stereoscopic representation of field of view of driver .

Navigation system is configured to implement one or more object recognition algorithms in order to process eye gaze information and outward facing camera information . In doing so navigation system may implement computer vision techniques in order to designate particular regions of the stereoscopic representation mentioned above as being associated with a particular type of real world object. For example and without limitation by implementing object recognition algorithms navigation system could determine that a particular portion of the stereoscopic representation is associated with a car. Navigation system may further implement object recognition algorithms to determine a depth value for each identified object. Returning to the above example navigation system could determine that the identified car resides approximately 30 feet from outward facing cameras . Navigation system may also apply object recognition algorithms to identify specific real world objects residing at point of focus i.e. real world objects onto which driver is currently focused. In doing so navigation system may correlate point of focus with a specific region of the stereoscopic representation of field of view of driver where that specific region includes one or more real world objects identified via object recognition algorithms . With the aforementioned techniques navigation system generates visual context data .

Visual context data generally represents a set of objects within field of view of driver that have been identified via object recognition algorithms in the fashion described above. Visual context data could include for example and without limitation an enhanced version of the stereoscopic representation captured by outward facing cameras that indicates particular object types for different regions of that representation. The enhanced version could also include data specifying direction of focus and point of focus within the stereoscopic representation along with an indication of a specific real world object associated with point of focus . Navigation system is configured to process visual context data with enhanced directions composer in order to generate context specific driving directions.

In operation enhanced directions composer is configured to access GPS navigation and traffic information and to generate a set of driving instructions for directing driver from a current location to a final destination. Driver could select the final destination for example and without limitation by interacting with a graphical user interface GUI provided by navigation system. The set of driving instructions may be generated by conventional techniques and may rely on existing application programming interfaces APIs for querying public cloud based engines that generate driving instructions. Enhanced directions composer then modifies a current instruction in the set of driving instructions to include references to real world objects indicated by visual context data thereby generating a context specific driving instruction. The real world object could be any object in field of view of driver or an object of focus towards which driver is already looking. Enhanced driving directions composer then outputs the context specific driving direction to driver via speakers .

In a specific example of the functionality of enhanced directions composer and without limitation the current instruction in the set of instructions could indicate that a left turn should be performed 500 feet ahead. Enhanced directions composer typically acquires the particular instruction to turn and the distance at which the turn should be performed from GPS navigation and traffic information . Enhanced directions composer could then identify from within visual context data that a blue car is parked on the left side of the street approximately 500 feet ahead. Enhanced directions composer would then modify the current instruction to indicate that a left turn should be performed after the blue car. Enhanced directions composer would then dictate the context specific driving instruction to driver .

In addition enhanced directions composer may also provide correction information to driver in situations where driver fails to look at the real world object referenced in the context specific driving instruction or looks at an incorrect object. Returning to the above example should driver fail to look at the blue car referenced in the context specific instruction and instead looks at a red car enhanced directions composer could generate correction information instructing driver that the red car is in fact the wrong car. Enhanced directions composer could also generate another context specific driving instruction that includes a more detailed reference to real world objects in field of view of driver . For example and without limitation enhanced directions composer could instruct driver to turn left at the blue car next to the green house.

Enhanced directions composer may also provide driving instructions to driver that specifically reference objects of focus towards which driver is already looking. For enhanced directions composer could determine based on visual context data that driver is looking ahead to an intersection. Enhanced directions composer could then instruct driver that a left turn is needed at the intersection where driver is currently looking. The different techniques described thus far may also be combined with one another in any technically feasible fashion. For example and without limitation enhanced directions composer could provide context specific driving instructions based on either real world objects or objects of focus towards which driver is looking. Enhanced directions composer could also provide correction information based on either real world objects or objects of focus towards which driver is looking.

As a general matter navigation system is configured to rely on the various data and processing stages described above in conjunction with in order to generate different types of context specific driving instructions for driver . The particular types of context specific driving instructions may vary across different use cases. Each of below illustrates a different use case that may occur as navigation engine directs driver to a final destination. One skilled in the art will recognize that the different use cases described herein are exemplary in nature only and are in no way intended to limit the scope of the present invention.

Navigation system is configured to generate a set of driving instructions that reflects a particular sequence of driving actions for guiding vehicle to a final destination. A current driving instruction could indicate that the right hand fork should be followed. Navigation system generates visual context data that indicates the presence of both cars and . Navigation system then generates a context specific driving instruction indicating that the car on the right should be followed in accordance with the original driving instruction. The context specific driving instruction thus provides additional contextual clues that assist driver in correctly performing the driving action associated with the original driving instruction. However driver could still misinterpret the context specific driving instruction and may not immediately look at car as described below in conjunction with .

As shown in a direction of focus of driver is aligned with car the left hand car and not car the right hand car that was referred to by navigation system in the context specific direction. In other words driver is looking at the wrong car. Navigation system is configured to determine direction of focus via eye gaze sensors and to then identify that driver is looking at car instead of car . Navigation system then generates correction information to cause driver to look at the correct car as described below in conjunction with .

As shown in navigation system indicates to driver that the car at which driver is looking car is in fact the wrong car and that the correct car car is on the right hand side. Driver may then look towards car along direction of focus as shown in . As also shown in navigation system may generate a confirmation message indicating that driver is looking at the correct car. With this approach navigation system provides driver with context specific driving instructions that include more relevant contextual information compared to traditional driving instructions. In addition when navigation system determines that driver may have misinterpreted a given driving instruction navigation system attempts to correct that interpretation by providing additional information to driver .

Navigation system may also generate context specific instructions relative to real world objects that may have a fixed location. Those objects may be identifiable within visual context data generated by navigation system or identifiable via GPS or external mapping databases and may include structures businesses and so forth as described in greater detail below in conjunction with .

Navigation system is configured to proceed to a subsequent driving instruction in the set of driving instructions discussed above in conjunction with . A current driving instruction could indicate that a right turn should be performed just after intersection . Navigation system generates visual context data that indicates the presence of both gas stations and . Navigation system then generates a context specific driving instruction indicating that a right hand turn should be performed after the second gas station . However driver may not immediately look at the correct gas station as described below in conjunction with .

As shown in a direction of focus of driver is aligned with gas station the first gas station and not gas station the second gas station that was referred to by navigation system in the context specific driving instruction. In other words driver is looking at the wrong gas station. Navigation system is configured to determine direction of focus via eye gaze sensors and to then identify that driver is looking at gas station instead of gas station . Navigation system then generates correction information to cause driver to look at the correct gas station as is shown. Driver may then look towards gas station along direction of focus and as shown in navigation system may provide a confirmation message indicating that driver is looking at the correct gas station.

Navigation system may also generate context specific driving instructions that refer to real world objects upon which driver is already focused as described in greater detail below in conjunction with .

Similar to above navigation system is configured to proceed to a subsequent driving instruction in the set of driving instructions. A current driving instruction could indicate that a right turn should be performed 100 feet ahead of vehicle . Navigation system generates visual context data that indicates the presence of car . Navigation system is configured to determine that the right turn should be performed at the current location of car which happens to be 100 feet ahead of vehicle . Navigation system then generates a context specific driving instruction indicating that a right hand turn should be performed at the current location of car as shown in . With the approach described in conjunction with navigation system may proactively provide context specific driving instructions that reference real world objects upon which driver is already focused.

Navigation system is also configured to interact with driver in order to confirm that driver has interpreted a context specific driving instruction correctly as described in greater detail below in conjunction with .

Similar to above navigation system is configured to proceed to a subsequent driving instruction in the set of driving instructions. A current driving instruction could indicate that a right turn should be performed just after intersection . Navigation system generates visual context data that indicates the presence of both churches and . Navigation system then generates a context specific driving instruction indicating that a right hand turn should be performed after the smaller of the two churches . Driver may not immediately understand which of churches and is the smaller of the two. However navigation system is configured to interact with driver in order to confirm that driver sees the correct church as described below in conjunction with .

As shown in a direction of focus of driver is aligned with church . Driver may query navigation system in order to confirm that driver is in fact looking at the smaller of the two churches and . Navigation system determines that driver is actually looking at the wrong church and in response provides correction information to driver as described below in conjunction with .

As shown in navigation system provides correction information that distinguishes church from and clarifies that the right turn should be performed after church instead of church . Navigation system is generally configured to provide additional correction information to driver until driver focuses on a particular real world object associated with a current context specific driving instruction.

Navigation system may be implemented to assist driver with performing a driving action associated with a current driving instruction and may also be implemented to guide driver to a final destination as described below in conjunction with .

Similar to above navigation system is configured to proceed to a subsequent driving instruction in the set of driving instructions. The subsequent driving instruction could be a final driving direction that indicates the address of the final destination. Navigation system generates visual context data that indicates the presence of buildings and . Navigation system then generates a context specific driving instruction indicating that the final destination is on the right hand side of vehicle . However driver may misinterpret the context specific driving instruction and look towards the wrong building as described below in conjunction with .

As shown in a direction of focus of driver is aligned with building which is not the final destination. Navigation system is configured to determine that driver is looking at the wrong building and to then generate correction information that informs driver of the correct building relative to direction of focus and building . In particular navigation system indicates to driver that the final destination is two buildings past the building at which driver is currently looking. Driver may then shift focus to direction of focus and view the final destination as shown in .

Referring generally to persons skilled in the art will understand that the exemplary use case scenarios described in conjunction with those figures is not meant to be exhaustive and only intended to illustrate possible situations within which navigation system may provide navigation assistance. In addition those skilled in the art will recognize that the different techniques described thus far may be broadly categorized into two separate embodiments as also mentioned above in conjunction with .

Again in the first embodiment navigation system may provide a context specific driving instruction relative to a real world object and then provide correction information relative to an object of focus at which driver is looking as described in stepwise fashion below in conjunction with . In the second embodiment navigation system may provide a context specific driving instruction relative to an object of focus at which driver is already looking as described in stepwise fashion below in conjunction with .

As shown a method begins at step where navigation system generates a sequence of driving instructions for directing driver of vehicle from a current location to a final destination. Navigation system may query driver for an address associated with the final destination and rely on position services such as GPS to determine the current instructions of vehicle . In addition navigation system may acquire the sequence of driving directions from an external source such as e.g. a cloud based navigation service.

At step navigation system identifies a set of real world objects in field of view of driver . Navigation system may receive video data captured by outward facing cameras and then process that video data to identify the set of real world objects. Navigation system could for example and without limitation rely on computer vision techniques along with a database of identifiable objects to associate different regions of each frame of video data with a particular category of object. In embodiments where outward facing cameras include other types of sensors as described above in conjunction with navigation system is configured to process other types of data. For example when outward facing cameras includes a LIDAR based sensor navigation system could receive and process laser data using e.g. computer vision or equivalent techniques to identify the set of real world objects. At step navigation system generates a context specific driving instruction that references a real world object in field of view of driver based on the current driving instruction in the sequence. In other words navigation system modifies the current driving instruction to specifically reference a contextually relevant real world object that driver may perceive.

At step navigation system causes speakers to dictate the context specific driving instruction to driver . At step navigation system determines a direction of focus associated with driver . Navigation system is configured to track the position of each eye associated with driver via eye gaze sensors and to determine the direction driver is looking and a depth along that direction upon which driver is focused.

At step navigation system determines whether driver is looking at the real world object referenced in the context specific driving instruction. If driver is in fact looking at the real world object then driver may have interpreted the context specific driving instruction correctly. However if driver is not looking at the real world object then driver may not have understood the context specific driving instruction. In the context of this disclosure driver is considered to be looking at a real world object when for example driver makes eye contact with the real world object for a certain amount of time and or repeatedly makes eye contact with the same area object for a certain amount of time. Persons skilled in the art will understand that many techniques are possible for identifying a real world object that driver is looking at and any such technique may be applied when navigation system performs step .

If navigation system determines at step that driver is in fact looking at the real world object referenced by navigation system then navigation system proceeds to step . Step is described in greater detail below. However at step if navigation system determines that driver is not looking at the real world object then navigation system proceeds to step . At step navigation system generates correction information based on the direction of focus of driver . At step navigation system causes speakers to dictate the correction information to driver . The correction information generally distinguishes the real world object associated with the context specific driving instruction from any other object at which driver may be looking.

At step navigation system determines if driver has arrived at the final destination. If driver has arrived then the method ends. Otherwise if navigation system determines that driver has not yet arrived then at step navigation system proceeds to a subsequent driving instruction in the sequence of driving instructions and then returns to step . Accordingly navigation system is configured to repeat some or all of the method until the final destination is reached. At any given time when implementing the method navigation system may also interact with driver to provide confirmation messages indicating whether driver has interpreted a context specific instruction correctly in the fashion described above in conjunction with .

Navigation system may also be configured to generate context specific driving instructions that specifically reference a real world object at which driver is already looking as described in greater detail below in conjunction with .

As shown a method beings at step where navigation system generates a sequence of driving instructions for directing driver of vehicle from a current location to a final destination. Step is generally similar to step of the method . At step navigation system identifies a set of real world objects in field of view of driver similar to step of the method .

At step navigation system identifies an object of focus at which driver is currently looking. Similar to step of the method navigation system relies on eye gaze sensors to determine a direction and depth associated with the gaze of driver . At step navigation system generates a context specific driving instruction that references the object of focus determined at step based on the current driving instruction. In other words navigation system modifies the current driving instruction to specifically reference a contextually relevant real world object. At step navigation system causes speakers to dictate the context specific driving instruction to driver .

At step navigation system determines if driver has arrived at the final destination. If driver has arrived then the method ends. Otherwise if navigation system determines that driver has not yet arrived then at step navigation system proceeds to a subsequent instruction in the sequence of driving instructions and then returns to step . Accordingly navigation system is configured to repeat some or all of the method until the final destination is reached. Similar to the method at any given time when implementing the method navigation system may also interact with driver to provide confirmation messages indicating whether driver has interpreted a context specific instruction correctly in the fashion described above in conjunction with .

Persons skilled in the art will understand that the methods and represent different embodiments of navigation system that may be implemented in conjunction with one another. For example and without limitation navigation system could implement the method during one step in the sequence of driving instructions and then implement the method during another step in the sequence of driving instructions. Further navigation system may select between the two methods and based on a wide variety of criteria including but not limited to the degree to which driver has successfully followed previous context specific driving instructions.

Processing unit may be a central processing unit CPU an application specific integrated circuit ASIC a field programmable gate array FPGA or any other type of hardware unit configured to process data and execute applications. I O devices may includes devices capable of receiving input including a touchscreen keyboard microphone and so forth as well a devices capable of providing output such as speakers display devices and so forth. I O devices may also include devices capable of both receiving input and providing output such as a universal serial bus USB port Ethernet port WiFi transceiver etc. I O devices generally provide computing device with GPS cellular and or Internet connectivity.

Memory unit may be hard disk flash memory unit random access memory RAM module or any other type of storage medium. Software application may be executed by processing unit to implement any functionality of navigation system described thus far. Software application may store data to and retrieve data from database . Database may include among other things various collections of navigation data such as maps driving instructions and so forth as well as data related to driver including saved routes configuration preferences etc.

Persons skilled in the art will understand that portions of computing device may be implemented remotely in a cloud based environment and that generally computing device could be any type of distributed system. For example and without limitation database may reside in a remote location and software application may be configured to access that location to retrieve route information etc. Additionally software application itself may be downloaded from a remote location and or updated periodically from a remote server machine. Persons skilled in the art will understand that computing device represents just one exemplary computing device configured to implement the functionality of navigation system and that other devices may also perform that functionality.

In sum a navigation system is configured to generate a sequence of driving instructions for directing a driver of a vehicle from a current location to a final destination. The navigation system is configured to capture sensor data that reflects the field of view of the driver and to identify objects in that field of view. The navigation system then customizes the driving instructions to reference specific objects thereby generating context specific driving instructions. The navigation system is also configured to identify particular objects upon which the driver is focused and to generate context specific driving instructions relative to such objects of focus. The navigation system may also provide correction information to the driver upon determining that the driver has incorrectly focused on a different object than an object referenced in a context specific driving instruction.

One advantage of the disclosed technique is that it enables context specific driving instructions that are consistent with the visual context of the driver. Consequently the driver may intuitively follow those instructions without distraction. Since the navigation system accounts for the field of view of the driver and specific objects upon which the driver is already focused the navigation system can provide directions that are immediately relevant to the driver. Thus the driver need not shift contexts in order to perform driving actions. Another advantage of the disclosed techniques is that context specific driving instructions may closely match driving instructions that a human navigator would provide and so the driver may naturally follow those instructions with relative ease. Since the context specific driving instructions may be more easily interpreted and understood compared to conventional driving instructions the driver may be far less likely to become confused and or lost. The personal safety of the driver may thus be protected.

One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as compact disc read only memory CD ROM disks readable by a CD ROM drive flash memory read only memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored.

The invention has been described above with reference to specific embodiments. Persons of ordinary skill in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

