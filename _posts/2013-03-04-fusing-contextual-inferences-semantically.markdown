---

title: Fusing contextual inferences semantically
abstract: System and methods for performing context inference in a computing device are disclosed. In one embodiment, a method of performing context inference includes: determining, at a computing device, a first context class using context-related data from at least one data source associated with a mobile device; and determining, at the mobile device, a fusion class based on the first context class, the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09336295&OS=09336295&RS=09336295
owner: QUALCOMM Incorporated
number: 09336295
owner_city: San Diego
owner_country: US
publication_date: 20130304
---
This application claims the benefit of U.S. Provisional Application No. 61 732 778 entitled FUSING CONTEXTUAL INFERENCES SEMANTICALLY filed Dec. 3 2012 assigned to the assignee hereof and hereby expressly incorporated by reference herein in its entirety.

Advancements in wireless communication technology have greatly increased the versatility of today s wireless communication devices. These advancements have enabled wireless communication devices to evolve from simple mobile telephones and pagers into sophisticated computing devices capable of a wide variety of functionality such as multimedia recording and playback event scheduling word processing e commerce etc. As a result users of today s wireless communication devices are able to perform a wide range of tasks from a single portable device that conventionally required either multiple devices or larger non portable equipment.

An example method for performing context inference in a computing device includes determining at a computing device a first context class using context related data from at least one data source associated with a mobile device and determining at the mobile device a fusion class based on the first context class the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class.

Implementations of such a method may include one or more of the following features. The fusion class has an associated label that semantically encapsulates a label of the first context class and a label of the second context class. The method further includes obtaining information associated with an initial classification used to determine the first context class. Obtaining the information associated with the initial classification comprises obtaining a confidence value associated with the initial classification. Determining the fusion class is performed in response to the confidence value having an undesirable value. Obtaining the information associated with the initial classification comprises identifying an operational property of the initial classification. Determining the fusion class is based on the operational property of the initial classification. The context related data are first context related data associated with a first time the method further including determining the second context class using second context related data associated with a second time that is after the first time where determining the fusion class is based on the first context class and the second context class. Determining the first context class comprises selecting the first context class from a plurality of predetermined available context classes. Determining the fusion class comprises selecting the fusion class from a plurality of predetermined available fusion classes.

An example apparatus includes first determining means for determining a first context class using context related data from at least one data source associated with a mobile device and second determining means communicatively coupled to the first determining means for determining a fusion class based on the first context class the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class.

Implementations of such an apparatus may include one or more of the following features. The fusion class has an associated label that semantically encapsulates a label of the first context class and a label of the second context class. The first determining means comprise obtaining means for obtaining information associated with an initial classification used to determine the first context class. The obtaining means are configured to obtain a confidence value associated with the initial classification. The second determining means are configured to determine the fusion class in response to the confidence value having an undesirable value. The obtaining means are configured to identify an operational property of the initial classification. The second determining means are configured to determine the fusion class based on the operational property of the initial classification. The context related data are first context related data associated with a first time the second determining means being further for determining the second context class using second context related data associated with a second time that is after the first time where the second determining means are configured to determine the fusion class based on the first context class and the second context class. The first determining means are configured to determine the first context class by selecting the first context class from predetermined available context classes. The second determining means are configured to determine the fusion class by selecting the fusion class from predetermined available fusion classes.

An example mobile device includes at least one data source a target state classifier communicatively coupled to the at least one data source and configured to determine a first context class using context related data from the at least one data source and a fusion classifier communicatively coupled to the target state classifier configured to determine a fusion class based on the first context class the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class.

Implementations of such a mobile device may include one or more of the following features. The fusion class has an associated label that semantically encapsulates a label of the first context class and a label of the second context class. The target state classifier is configured to obtain information associated with an initial classification used to determine the first context class. The target state classifier is configured to obtain a confidence value associated with the initial classification. The fusion classifier is configured to determine the fusion class in response to the confidence value having an undesirable value. The target state classifier is configured to identify an operational property of the initial classification. The fusion classifier is configured to determine the fusion class based on the operational property of the initial classification. The context related data are first context related data associated with a first time the fusion classifier is configured to determine the second context class using second context related data associated with a second time that is after the first time and the fusion classifier is configured to determine the fusion class based on the first context class and the second context class. The target state classifier is configured to determine the first context class by selecting the first context class from predetermined available context classes. The fusion classifier is configured to determine the fusion class by selecting the fusion class from predetermined available fusion classes.

An example processor readable storage medium includes processor readable instructions configured to cause a processor to determine a first context class using context related data from at least one data source associated with a mobile device and determine a fusion class based on the first context class the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class.

Implementations of such a storage medium may include one or more of the following features. The fusion class has an associated label that semantically encapsulates a label of the first context class and a label of the second context class. The storage medium further includes instructions configured to cause the processor to obtain information associated with an initial classification used to determine the first context class. The instructions configured to cause the processor to obtain the information associated with the initial classification comprise instructions configured to cause the processor to obtain a confidence value associated with the initial classification. The instructions configured to cause the processor to determine the fusion class are configured to cause the processor to determine the fusion class in response to the confidence value having an undesirable value. The instructions configured to cause the processor to obtain the information associated with the initial classification comprise instructions configured to cause the processor to identify an operational property of the initial classification. The instructions configured to cause the processor to determine the fusion class are configured to cause the processor to determine the fusion class based on the operational property of the initial classification. The context related data are first context related data associated with a first time the storage medium further including instructions configured to cause the processor to determine the second context class using second context related data associated with a second time that is after the first time where the instructions configured to cause the processor to determine the fusion class are configured to cause the processor to determine the fusion class based on the first context class and the second context class. The instructions configured to cause the processor to determine the first context class are configured to cause the processor to select the first context class from predetermined available context classes. The instructions configured to cause the processor to determine the fusion class are configured to cause the processor to select the fusion class from predetermined available fusion classes.

Items and or techniques described herein may provide one or more of the following capabilities and or possibly one or more other capabilities not mentioned. Data collected from mobile device data sensors can indicate a target context state. A target state classifier can be trained to detect a target context state. Target context states can be associated with a low confidence value due to ambiguities between particular target context states. A fusion classifier can semantically fuse a set of target classifiers. As a result context inference with fusion classification can be more accurate than context inference from the detected target context states. Other capabilities may be provided and not every implementation according to the disclosure must provide any let alone all of the capabilities discussed. Further it may be possible for an effect noted above to be achieved by means other than that noted and a noted item technique may not necessarily yield the noted effect.

Described herein are techniques for fusing contextual inferences associated with a computing device. The techniques described herein can be used to aid in context determination for devices such as smartphones laptop or tablet computers personal digital assistants PDAs etc. as well as any other computing device presently existing or existing in the future. Other uses may also be possible. While various examples given in the description below relate to mobile computing devices the techniques described herein can be applied to any device for which context inference is desirable.

Advancements in mobile device technology have given mobile devices the ability to detect and use device and user context information such as the location of a device events occurring in the area of the device etc. in performing and customizing functions of the device. One way in which a mobile device can be made aware of its user s context is the identification of dialogue in the ambient audio stream. For instance a device can monitor the ambient audio environment in the vicinity of the device and its user and determine when conversation is taking place. This information can then be used to trigger more detailed inferences such as speaker and or user recognition age and or gender estimation estimation of the number of conversation participants etc. Alternatively the act of identifying conversation can itself be utilized as an aid in context determination. For instance detected conversation can be utilized to determine whether a user located in his office is working alone or meeting with others which may affect the interruptibility of the user.

Further an objective of mobile context awareness is to have a device infer what its user is doing. This can be evaluated along multiple dimensions such as by the type of place the user is located e.g. office conference room lecture hall home gym restaurant coffee shop bar etc. or the type of situation the user is in e.g. meeting working alone driving having lunch working out sleeping etc. . Each such dimension is referred to herein as a context. By inferring user contexts a range of applications are facilitated such as but not limited to the following 

1 Automating device functionality such as diverting calls to voicemail or responding to text messages when the user is uninterruptible adjusting the ringer volume based on the environment notifying meeting participants when the user is running late etc.

2 Automating social networking interaction such as check ins notifying friends when the user is nearby etc.

3 Providing health care information such as calories burned miles walked hours spent at work vs. play etc.

4 Facilitating accurate and timely recommendations such as for restaurants shops consumer products gasoline etc.

Applications utilizing context awareness services fall into two categories those that utilize deterministic inference and those that utilize only statistical inference. An example of an application that uses deterministic inference is a detector that brings up a driving based user interface UI e.g. having large buttons speedometer alerts etc. when a context awareness service detects the user is driving. An example of an application using only statistical inference is a user profiler that attempts to estimate the average number of hours the user spends driving by utilizing a similar or same context awareness service that detects when the user is driving. Applications using deterministic inference may not be able to tolerate false alarms or missed detections i.e. classifier errors . For example an incorrect classification could result in a user s mobile device instantiating a driving UI while the user is on a bus or vice versa.

To reduce classifier errors that would result in incorrect operation such as that exampled above context inferences are semantically fused as described below. In general given a set of independent supervised classifiers that have each been trained to detect a target class a new classifier is created and used to output one class from a new set of classes when the original classifiers detect multiple target classes. To each new class an associated label is attached that semantically encapsulates labels of classes in the set of detected target classes that triggers its output.

The techniques described herein can be utilized for a mobile device such as the example mobile device illustrated in . The mobile device includes a wireless transceiver that sends and receives wireless signals via a wireless antenna over a wireless network. The transceiver is connected to a bus by a wireless transceiver bus interface . While shown as distinct components in the wireless transceiver bus interface may also be a part of the wireless transceiver . Here the mobile device is illustrated as having a single wireless transceiver . However a mobile device can alternatively have multiple wireless transceivers and wireless antennas to support multiple communication standards such as Wi Fi Code Division Multiple Access CDMA Wideband CDMA WCDMA Long Term Evolution LTE Bluetooth etc.

A general purpose processor memory digital signal processor DSP and or specialized processor s not shown may also be utilized to process the wireless signals in whole or in part. Storage of information from the wireless signals is performed using a memory or registers not shown . While only one general purpose processor DSP and memory are shown in more than one of any of these components could be used by the mobile device . The general purpose processor and DSP are connected to the bus either directly or by a bus interface . Additionally the memory is connected to the bus either directly or by a bus interface not shown . The bus interfaces when implemented can be integrated with or independent of the general purpose processor DSP and or memory with which they are associated.

The memory includes a non transitory processor readable storage medium or media that stores functions as one or more instructions or code. Media that can make up the memory include but are not limited to RAM ROM FLASH disc drives etc. Functions stored by the memory are executed by the general purpose processor specialized processor s or DSP . Thus the memory is a processor readable memory that stores software code processor readable programming code processor readable instructions etc. configured to cause the processor and or DSP to perform the functions described. Alternatively one or more functions of the mobile device may be performed in whole or in part in hardware.

The mobile device further includes one or more sensors that capture data associated with the mobile device and or its surroundings. The sensors may include but are not limited to microphones or audio sensors cameras light sensors pressure sensors inertial sensors e.g. accelerometers and or gyroscopes magnetometers etc. The sensors may be used individually or in combinations such as sensor arrays or any other combinations. Multiple sensors if implemented by the mobile device can operate interdependently or independently of one another. The sensors are connected to the bus either independently or through a bus interface not shown . For instance the sensors can communicate with the DSP through the bus in order to process data captured by the sensors . The sensors can additionally communicate with the general purpose processor and or memory to generate or otherwise obtain metadata associated with captured data. In some embodiments the antenna and or transceiver may also be utilized as sensors for example to sense or detect wireless signals such as Wi Fi signals.

Data collected from the device data sources can take any form usable by the target state classifiers and or the fusion classifier . For instance such data can include audio samples from the audio sensors GPS readings from the location sensors network strength and or other network related readings from the network sensors motion acceleration or orientation data from the motion sensors entries associated with a calendar etc. In addition to the data labels applied to the data can also be collected and or utilized. For instance calendar entries may be labeled with a location or title e.g. user s office or doctor appointment. Any other data types data labels or other aspects of information usable by the target state classifiers and or the fusion classifier could also be used.

The target state classifiers as described above are independently supervised classifiers that are each trained to detect a target context state. Given the target state classifiers the fusion classifier is used as a new classifier to output one of a new set of fusion classes under various conditions e.g. the target state classifiers detect multiple classes no target state is detected with an adequate level of confidence etc. Each fusion class is assigned a label that semantically encompasses and encapsulates a set of detected target states the fusion class is a joint state for a set of merged target states detected by respective target classifiers. The fusion classes each share and the fusion class labels are indicative of a characteristic common to multiple classes e.g. multiple target context states . The fusion classifier outputs the particular fusion class triggered by an encompassed target state. In this way the fusion classifier represents a merged set of target state classifiers .

For example for three supervised motion classifiers trained to detect states walk sit and stand respectively the fusion classifier can output a state labeled stationary when both sit and stand are detected. As another example for supervised motion classifiers trained to detect states walk run drive bus and subway the fusion classifier can output pedestrian motion when walk or run is detected and vehicular motion when drive bus or subway is detected. An illustrative view of these groupings is given by system in . However the concepts described herein are not limited to motion classification any suitable classification types could be utilized such as location classification e.g. indoor vs. outdoor work vs. home etc. event classification e.g. meeting detection etc. environment classification e.g. based on network availability or signal strength etc. etc.

If the target state classifiers output probabilities or confidence values associated with their detection decision then the fusion classifier can utilize these in determining its output. For example for two supervised classifiers trained to detect in office and in meeting and each outputting confidence values for their decisions the fusion classifier can be configured to output at work when either in office or in meeting is detected with low confidence or in office and in meeting are detected both with low confidence . In either of these cases the confidence in either or both of the particular context states here in office and in meeting is low but the confidence of the fusion class here at work is high. The fusion classifier may output the original classification output e.g. in office or in meeting when one is detected with high confidence or to output the classification with the higher confidence value if both are detected with high confidence. The level of confidence indicates the degree of ambiguity associated with the target state classification decision based on the input data.

The fusion classifier may output a fused class based on one or more classes output by a multi class supervised classifier that outputs one or more classes from a set of trained classes. The fusion classifier is configured to output one class from a set of classes with a label that semantically encapsulates all classes outputted by the original classifier. For example given a supervised audio classifier trained to detect the number of speakers present i.e. trained with classes 0 speakers 1 speaker 2 speakers 3 speakers etc. the fusion classifier may output either no speakers 1 speaker or many speakers. Alternatively the classifier may be configured to output no speakers few speakers or many speakers. As another example for a classifier trained for classes not in meeting 2 in meeting with person A and 3 in meeting with person B the fusion classifier is configured to output either 1 not in meeting or 2 in meeting. Still other configurations may be used.

If a target state classifier assigns a probability distribution or a similar set of weightings to the set of classes it has been trained to classify based on received input data the fusion classifier can select its output based on this information. For example if a three state classifier trained to discriminate between walk sit and stand provides an output walk sit stand with respective probabilities 0.0 0.4 0.6 the fusion classifier can output stationary e.g. as the original classifier is ambivalent between sit and stand .

If a target state classifier assigns a confidence value to its output decision based on the input data the fusion classifier can select its output based on one or more of the following 1 the original classifier s output 2 the confidence value associated with the output and or 3 known behavior of the original classifier. This may be used e.g. if the original classifier is known to commonly confuse a subset of states and the confidence value is known to indicate a possible confusion or ambiguity. In some implementations the fusion classifier may be more robust due to less associated ambiguity than the original target state classifier . For the previous example if the original classifier performs and initial classification based on the input data and outputs sit with a low confidence value and this classifier is known to commonly confuse sit and stand the fusion classifier outputs stationary. In some cases the fusion classifier may disregard the confidence value. For example multiple applications may wish to utilize the same trained classifier outputs but some may have lower accuracy tolerance than others. The applications with lower tolerance may decide to output a broader semantic class in some or all cases in which the original classifier outputs any class known to be commonly confused with others.

The fusion classifier may operate by semantically merging contextual inferences over a temporal dimension. For example if the original classifier outputs a sequence of 7 decisions sit stand sit sit sit stand stand over consecutive periods of 3 seconds each the fusion classifier outputs a single decision stationary which encapsulates and merges the previous 21 seconds of decisions. Alternatively the fusion classifier may operate on the same time scale as the original classifier semantically filtering context inferences. Continuing the previous example the fusion classifier may output filtered decisions at the same rate of the original classifier i.e. once every 3 seconds e.g. sit stand stationary stationary stationary stationary stationary .

1 For a classifier trained to discriminate between driving and on bus states the fusion classifier outputs in transit when either of the original classes is outputted with low confidence.

2 For a classifier that detects in office the fusion classifier outputs at work when the confidence of the detection is low.

3 For a situation classifier that selects from two classes named hanging out with friends and having lunch the fusion classifier outputs having lunch with friends when the outputted probabilities for the two original classes are within 0.2 of each other e.g. 0.6 and 0.4 .

The above examples are not an exhaustive list of implementations of the fusion classifier and other use cases are possible.

To restate the above the target state classifiers receive data from the device data sources and classify the data into respective states. The fusion classifier is communicatively coupled to the target state classifiers and configured to receive classifier decisions from the target state classifiers and optionally other information e.g. confidence values etc. . Based on information received from the target state classifiers the fusion classifier determines whether to output the original state provided by the target state classifiers or a new merged state that semantically encompasses the state that was provided by the target state classifiers as well as one or more similar states e.g. states for which the output state may have been provided as erroneous output. Additionally the fusion classifier may receive data directly from the device data sources . This data may include duplicate data to those data provided to the target state classifiers and or other data.

As an example the target state classifiers may be built into one or more integrated circuits ICs chipsets or other hardware modules and accessed via an application programming interface API . The API is configured to provide outputs of the target state classifiers and their associated confidence values or probabilities. The fusion classifier is built by a device manufacturer operating system developer or application developer and implements semantic fusing for the target state classifiers with respect to one or more particular applications. While illustrates a system with a single fusion classifier multiple fusion classifiers could be used. For instance multiple fusion classifiers may be associated with respective applications or sets of applications such that a given application utilizes the target state classifiers in combination with the fusion classifier that corresponds to the application. A fusion classifier or respective ones of a set of fusion classifiers may also be adjusted or customized based on user preferences application properties or any other criteria that could potentially have an effect on the classification of data from the device data sources into respective context states. Other implementations are also possible.

As an alternative to system in which the target state classifiers and fusion classifier are shown as separate entities the target state classifiers and fusion classifier could be implemented as a single multi stage classifier. For instance first states could be identified at a first classifier stage as described above with respect to the target state classifiers and subsequently second states could be identified at a second classifier stage in a similar manner to that described with respect to the fusion classifier .

Additionally or alternatively the fusion classifier as shown in can perform temporal analysis of outputs from the target state classifiers to enhance the stability of the target state classifiers and or obtain implied confidence values probability distributions or other soft decision metrics when no explicit confidence outputs are available from the target state classifiers . Here the fusion classifier identifies outputs from a particular target state classifier over time e.g. by buffering or otherwise storing classifier outputs over a period of time. Based on the history of initial classifier decisions and any changes to those decisions the fusion classifier can elect to either output the initial state decision or a new state decision. As an example if a target state classifier alternates perhaps quickly between two related states e.g. in adjacent or near adjacent decisions the fusion classifier can output a fusion class to avoid ping pong effects between indicating the individual different states. To illustrate if an initial classifier alternates rapidly between sit and stand the fusion classifier may infer a low confidence level substitute a new decision e.g. stationary for the initial decisions or take other suitable actions.

As another example if an initial classifier outputs the same state for a predetermined number of decisions and subsequently switches to a new state the fusion classifier can detect the change and output a broader or intermediate state for one or more state decisions following the change. To illustrate if a target state classifier outputs walk for several decisions and then switches to run the fusion classifier may output pedestrian motion for one or more decisions when the switch to run is identified.

As a further example the fusion classifier can leverage one or more operational properties of the target state classifiers in combination with historical data from the target state classifiers to increase classification accuracy. For instance in an example where an initial classification is known to have difficulty distinguishing between in car and on train states in some cases the fusion classifier can substitute an initial context inference with a broader inference such as vehicular motion if the initial classifier output is found to alternate between in car and on train.

As noted above the target state classifiers and fusion classifier infer a user and or device context based at least in part on information received from device data sources . While some examples given above relate to motion classification any suitable low level features may be utilized and any suitable low level inferences e.g. context inferences or other inferences can be performed. By way of example and not limitation a list of possible low level features that can be computed from data obtained from device data sources include the following 

Similarly a list of possible low level inferences that can be computed by the target state classifiers and or fusion classifier includes but is not limited to the following 

Referring to with further reference to a first process of performing contextual inference with respect to a computing device includes the stages shown. The process is however an example only and not limiting. The process can be altered e.g. by having stages added removed rearranged combined and or performed concurrently. Still other alterations to the process as shown and described are possible.

At stage the process includes determining at a computing device a first context class using context related data from at least one data source e.g. at least one of the data sources associated with the mobile device . The first context class may be e.g. a context class from a set of context classes assigned to the context related data by the set of target state classifiers and or other mechanisms. In general however the first context class may be determined at stage in any suitable manner. Classifiers classification algorithms or other means for determining the first context class may be a part of and or otherwise controlled by a device performing the process and or by other devices. The first context class may be determined synchronously e.g. according to a period schedule or other timeframe or asynchronously e.g. in response to triggering events for measurement classification or reporting . The first context class may be determined by selecting the first context class from multiple predetermined available context classes. The first context class may represent hard decisions e.g. discrete state values or other indicators which may or may not include supplemental information such as probability and or confidence information. Alternatively the first context class may result in soft decisions e.g. as a vector of probabilities for each of a set of context classes or other forms. Other formats and or techniques for the first context class at stage are possible.

At stage the process includes determining at the computing device a fusion class based on the first context class the fusion class being associated with at least one characteristic that is common to the first context class and a second context class that is different from the first context class. The fusion class may be determined e.g. in response to the first context class having an associated confidence that is low and or in response to the first class and the second class both being determined and or the first class being amenable to grouping without loss of relevant information e.g. few speakers vs. 2 speakers etc. The fusion classifier determines the fusion class e.g. by analysis of relationships between context classes and fusion classes. The fusion class may be determined by selecting the first context class from multiple predetermined available fusion classes. The fusion classifier may determine more than one fusion class associated with the first context class e.g. at work and in meeting . Each of the fusion classes i.e. the fusion class labels semantically encapsulates a given set of context classes as described above e.g. stationary to encapsulate sit and stand many speakers to encapsulate all context classes associated with more than a given number of speakers etc. . Fusion classification can merge or combine multiple context classes into a fusion class. As generally described above with respect to the fusion classifier shown in system selection of the fusion class is performed by one or more techniques including but not limited to 1 identifying multiple context classes e.g. both with low confidence and selecting a fusion class that encapsulates the context classes 2 identifying a context class having a low confidence e.g. a confidence value that is an undesirable value e.g. below a threshold value or at or below the threshold value or low probability and selecting a fusion class that represents a broader case or context encompassing the context class 3 identifying trends or changes in context classes over time and selecting a fusion class that represents a broader case or context encompassing corresponding context classes in response to qualifying changes in the context class 4 identifying an operational property or operational properties of an initial classification that resulted in the context class es such as a context class that is commonly confused in connection with the first classification and substituting a context class with a fusion class when deemed appropriate based on these properties etc.

More than one fusion class may be determined. For example the mobile device may be determined to have a context class of sit with an undesirable confidence value and may also be determined to be alternating between context classes of in office and in meeting. The fusion classifier may determine fusion classes of both stationary and at work for the mobile device in this example.

Referring to with further reference to a second process of performing contextual inference with respect to a computing device includes the stages shown. The process is however an example only and not limiting. The process can be altered e.g. by having stages added removed rearranged combined and or performed concurrently. Still other alterations to the process as shown and described are possible.

At stage context related data is obtained from one or more device data sources e.g. the device data sources shown in system . The data may be obtained synchronously e.g. according to a period schedule or other timeframe or asynchronously e.g. in response to triggering events for measurement or reporting at the device data sources .

At stage first classification of the context related data is performed e.g. by target state classifiers as shown in system by associating the data with multiple context classes from a set of context classes. The first classification may result in hard decisions or soft decisions as described above with respect to process in . In either case classification is performed for multiple context classes either through a multi state classifier or a set of classifiers configured to each detect corresponding state s .

At stage in response to the first classification performed at stage associating the context related data with the multiple context classes a second classification of the context related data is performed e.g. by a fusion classifier as shown in system by associating the data with one or more of a set of fusion classes based on the context classes. Here the second classification performed at stage is similar to the fusion classification performed at stage of process although different classification techniques are possible.

A computer system as illustrated in may be utilized to at least partially implement the functionality of the previously described computerized devices. For example the computer system can be utilized to at least partially implement the processes shown in in software. The computer system may also be implemented via one or more of the components of the mobile device shown in such as the general purpose processor and or memory . The computer system may additionally or alternatively be used to provide at least a partial software implementation the system shown in and or one or more of its components such as modules . Other implementations of the computer system are possible. For example the input devices may comprise and or be used to implement any of the device data sources as shown in . Further the processor and or portions of the working memory such as either the operating system or the application in combination with the processor or operating independently may comprise and or be used to implement any of the modules shown in . In some embodiments the processor may comprise and or be used to implement the processor and or the DSP as shown in and one or both of the working memory and the storage device may comprise and or be used to implement the memory also shown in .

The computer system is shown comprising hardware elements that can be electrically coupled via a bus or may otherwise be in communication as appropriate . The hardware elements may include one or more processors including without limitation one or more general purpose processors and or one or more special purpose processors such as digital signal processing chips graphics acceleration processors and or the like one or more input devices which can include without limitation a mouse a keyboard and or the like and one or more output devices which can include without limitation a display device a printer and or the like. The processor s can include for example intelligent hardware devices e.g. a central processing unit CPU such as those made by Intel Corporation or AMD a microcontroller an ASIC etc. Other processor types could also be utilized.

The computer system may further include and or be in communication with one or more non transitory storage devices which can comprise without limitation local and or network accessible storage and or can include without limitation a disk drive a drive array an optical storage device solid state storage device such as a random access memory RAM and or a read only memory ROM which can be programmable flash updateable and or the like. Such storage devices may be configured to implement any appropriate data stores including without limitation various file systems database structures and or the like.

The computer system might also include a communications subsystem which can include without limitation a modem a network card wireless or wired an infrared communication device a wireless communication device and or chipset such as a Bluetooth device an 802.11 device a WiFi device a WiMax device cellular communication facilities etc. and or the like. The communications subsystem may permit data to be exchanged with a network such as the network described below to name one example other computer systems and or any other devices described herein. In many embodiments the computer system will further comprise a working memory which can include a RAM or ROM device as described above.

The computer system also can comprise software elements shown as being currently located within the working memory including an operating system device drivers executable libraries and or other code such as one or more application programs which may comprise computer programs provided by various embodiments and or may be designed to implement methods and or configure systems provided by other embodiments as described herein. Merely by way of example one or more procedures described with respect to the method s discussed above might be implemented as code and or instructions executable by a computer and or a processor within a computer and such code and or instructions can be used to configure and or adapt a general purpose computer or other device to perform one or more operations in accordance with the described methods.

A set of these instructions and or code might be stored on a computer readable storage medium such as the storage device s described above. In some cases the storage medium might be incorporated within a computer system such as the system . In other embodiments the storage medium might be separate from a computer system e.g. a removable medium such as a compact disc and or provided in an installation package such that the storage medium can be used to program configure and or adapt a general purpose computer with the instructions code stored thereon. These instructions might take the form of executable code which is executable by the computer system and or might take the form of source and or installable code which upon compilation and or installation on the computer system e.g. using any of a variety of generally available compilers installation programs compression decompression utilities etc. then takes the form of executable code.

Substantial variations may be made in accordance with specific desires. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets etc. or both. Further connection to other computing devices such as network input output devices may be employed.

A computer system such as the computer system may be used to perform methods in accordance with the disclosure. Some or all of the procedures of such methods may be performed by the computer system in response to processor executing one or more sequences of one or more instructions which might be incorporated into the operating system and or other code such as an application program contained in the working memory . Such instructions may be read into the working memory from another computer readable medium such as one or more of the storage device s . Merely by way of example execution of the sequences of instructions contained in the working memory might cause the processor s to perform one or more procedures of the methods described herein.

The terms machine readable medium and computer readable medium as used herein refers to any non transitory computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs that participates in providing machine instructions and or data that causes a machine to operate in a specific fashion. In an embodiment implemented using the computer system various computer readable media might be involved in providing instructions code to processor s for execution and or might be used to store and or carry such instructions code e.g. as signals . In many implementations a computer readable medium is a physical and or tangible storage medium. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media include for example optical and or magnetic disks such as the storage device s . Volatile media include without limitation dynamic memory such as the working memory . Transmission media include without limitation coaxial cables copper wire and fiber optics including the wires that comprise the bus as well as the various components of the communication subsystem and or the media by which the communications subsystem provides communication with other devices . Hence transmission media can also take the form of waves including without limitation radio acoustic and or light waves such as those generated during radio wave and infrared data communications .

Common forms of physical and or tangible computer readable media include for example a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium a CD ROM a Blu Ray disc any other optical medium punch cards paper tape any other physical medium with patterns of holes a RAM a PROM EPROM a FLASH EPROM any other memory chip or cartridge a carrier wave as described hereinafter or any other medium from which a computer can read instructions and or code.

Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to the processor s for execution. Merely by way of example the instructions may initially be carried on a magnetic disk and or optical disc of a remote computer. A remote computer might load the instructions into its dynamic memory and send the instructions as signals over a transmission medium to be received and or executed by the computer system . These signals which might be in the form of electromagnetic signals acoustic signals optical signals and or the like are all examples of carrier waves on which instructions can be encoded in accordance with various embodiments of the invention.

The communications subsystem and or components thereof generally will receive the signals and the bus then might carry the signals and or the data instructions etc. carried by the signals to the working memory from which the processor s retrieves and executes the instructions. The instructions received by the working memory may optionally be stored on a storage device either before or after execution by the processor s .

The methods systems and devices discussed above are examples. Various alternative configurations may omit substitute or add various procedures or components as appropriate. For instance in alternative methods stages may be performed in orders different from the discussion above and various stages may be added omitted or combined. Also features described with respect to certain configurations may be combined in various other configurations. Different aspects and elements of the configurations may be combined in a similar manner. Also technology evolves and thus many of the elements are examples and do not limit the scope of the disclosure or claims.

Specific details are given in the description to provide a thorough understanding of example configurations including implementations . However configurations may be practiced without these specific details. For example well known circuits processes algorithms structures and techniques have been shown without unnecessary detail in order to avoid obscuring the configurations. This description provides example configurations only and does not limit the scope applicability or configurations of the claims. Rather the preceding description of the configurations will provide those skilled in the art with an enabling description for implementing described techniques. Various changes may be made in the function and arrangement of elements without departing from the spirit or scope of the disclosure.

Configurations may be described as a process which is depicted as a flow diagram or block diagram. Although each may describe the operations as a sequential process many of the operations can be performed in parallel or concurrently. In addition the order of the operations may be rearranged. A process may have additional steps not included in the figure. Furthermore examples of the methods may be implemented by hardware software firmware middleware microcode hardware description languages or any combination thereof. When implemented in software firmware middleware or microcode the program code or code segments to perform the necessary tasks may be stored in a non transitory computer readable medium such as a storage medium. Processors may perform the described tasks.

As used herein including in the claims or as used in a list of items prefaced by at least one of indicates a disjunctive list such that for example a list of at least one of A B or C means A or B or C or AB or AC or BC or ABC i.e. A and B and C or combinations with more than one feature e.g. AA AAB ABBC etc. .

As used herein including in the claims unless otherwise stated a statement that a function operation or feature is based on an item and or condition means that the function operation function is based on the stated item and or condition and may be based on one or more items and or conditions in addition to the stated item and or condition.

Having described several example configurations various modifications alternative constructions and equivalents may be used without departing from the spirit of the disclosure. For example the above elements may be components of a larger system wherein other rules may take precedence over or otherwise modify the application of the invention. Also a number of steps may be undertaken before during or after the above elements are considered. Accordingly the above description does not bound the scope of the claims.

