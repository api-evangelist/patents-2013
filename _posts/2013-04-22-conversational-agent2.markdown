---

title: Conversational agent
abstract: A method, system, and computer program product provide a conversation agent to process natural language queries expressed by a user and perform commands according to the derived intention of the user. A natural language processing (NLP) engine derives intent using conditional random fields to identify a domain and at least one task embodied in the query. The NLP may further identify one or more subdomains, and one or more entities related to the identified command. A template system creates a data structure for information relevant to the derived intent and passes a template to a services manager for interfacing with one or more services capable of accomplishing the task. A dialog manager may elicit more entities from the user if required by the services manager and otherwise engage in conversation with the user. In one embodiment, the conversational agent allows a user to engage in multiple conversations simultaneously.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09575963&OS=09575963&RS=09575963
owner: MALUUBA INC.
number: 09575963
owner_city: Waterloo
owner_country: CA
publication_date: 20130422
---
This application claims the benefit of or priority to U.S. provisional application No. 61 636 444 filed Apr. 20 2012 the disclosure of which is incorporated herein by reference.

The present disclosure relates to user interfaces for a computing device and more particularly to a user interface that conversationally interacts with a user of a computing device such as a smartphone.

User interfaces for electronic and other devices are evolving to include speech based inputs in a natural language such as English. A user may voice a command to control the operation of a device such as a smartphone tablet computer personal computer appliance television robot and the like. Natural language processing a type of machine learning using statistics may be used to interpret and act upon speech inputs. Speech recognition may convert the input to text. The text may be analyzed for meaning to determine the command to be performed.

Processing speech inputs in a natural language may be difficult because speech commands may be ambiguous and require clarification. More than one speech input may be used or even required to complete a specific command. Thus sequential speech inputs may be related to one specific command or to different commands.

When speaking to conventional speech recognition systems users often feel the need to modify their natural way of speaking so that a machine may understand the user s intention. This can be cumbersome and annoying which may cause users to abandon such a system.

A method system device and computer program product provide a conversation agent to process natural language queries expressed by a user and perform commands according to the derived intention of the user. A natural language processing NLP engine derives intent using conditional random fields to identify a domain and at least one task embodied in the query. The NLP may further identify one or more subdomains and one or more entities related to the identified command. A template system creates a data structure for information relevant to the derived intent and passes a template to a services manager for interfacing with one or more services capable of accomplishing the task. A dialogue manager may elicit more entities from the user if required by the services manager and otherwise engage in conversation with the user. In one embodiment the conversational agent allows a user to engage in multiple conversations simultaneously. In one aspect there is described a computing device comprising one or more processors and one or more non transitory storage devices storing instructions that when executed by the one or more processors configure the computing device to provide a natural language processing NLP engine for deriving a user intent from at least one user query the NLP engine configured to identify at least one domain and at least one command associated with the user intent derived and wherein the NLP engine includes at least one conditional random field for performing entity extraction on the at least one user query to identify at least one entity associated with the at least one command and wherein the command is for performing by a service associated with the domain. The NLP engine may select the at least one conditional random field in response to the at least one domain identified. The computing device may store at least one optimized feature set associated with the at least one domain identified and the at least one conditional random field may be configured to access the at least one feature set. The at least one user query may be received as an audio input comprising speech received from a user communication device. The computing device may provide a speech recognition engine for generating a text representation of the at least one query the text representation comprising a digital format and said audio input comprising a sound wave. The at least one command and at least one entity may be provided to a services component for identifying at least one service capable of performing the at least one command and for instructing at least one service to perform the at least one command the at least one service configured to return a service result to the services component in response to performing. The computing device may provide a dialogue manager for identifying at least one dialogue response to the at least one query. The computing device may provide a display manager for formatting an output comprising the at least one dialogue response. The at least one dialogue response may be at least partly based on said service result. The at least one dialogue response may include a confirmation question. The at least one dialogue response may include a clarification question. The at least one dialogue response may include an invitation to one or more services. The dialogue manager may be configured to define the at least one dialogue response in a conversational manner. The NLP engine may be configured to create a list of candidate interpretations of the user query and the dialogue manager may be configured to define the at least one dialogue response to present the list for selection. The dialogue manager may be configured to identify at least one unfilled entity relating to said at least one command and generate at least one dialogue response comprising a prompt to present to a user to obtain the at least one unfilled entity. A respective prompt may be generated for each of the at least one unfilled entity.

In one aspect there is described a computing device comprising one or more processors and one or more non transitory storage devices storing instructions that when executed by the one or more processors configure the computing device to provide a natural language processing NLP engine for deriving a user intent from at least one user query the NLP engine configured to identify at least one domain and at least one command associated with the user intent derived and wherein the NLP engine includes at least one conditional random field for performing entity extraction on the at least one user query to identify at least one entity associated with the at least one command and wherein the command is for performing by a service associated with the domain. The NLP engine may select the at least one conditional random field in response to the at least one domain identified. The computing device may store at least one optimized feature set associated with the at least one domain identified and the at least one conditional random field may be configured to access the at least one feature set. The at least one conditional random field may comprise a base labeled conditional random field configured to extract the at least one entity. The at least one conditional random field may comprise an expanded conditional random field configured to identify a subset of entities for selection by a user. The at least one user query may be received as an audio input comprising speech received from a user communication device. The computing device may provide a speech recognition engine for generating a text representation of the at least one query the text representation comprising a digital format and said audio input comprising a sound wave. The at least one command and at least one entity may be provided to a services component for identifying at least one service capable of performing the at least one command and for instructing at least one service to perform the at least one command the at least one service configured to return a service result to the services component in response to performing. The computing device may provide a dialogue manager for identifying at least one dialogue response to the at least one query. The computing device may provide a display manager for formatting an output comprising the at least one dialogue response. The at least one dialogue response may be at least partly based on said service result. The at least one dialogue response may include a confirmation question. The at least one dialogue response may include a clarification question. The at least one dialogue response may include an invitation to one or more services. The dialogue manager may be configured to define the at least one dialogue response in a conversational manner. The NLP engine may be configured to create a list of candidate interpretations of the user query and the dialogue manager may be configured to define the at least one dialogue response to present the list for selection. The dialogue manager may be configured to identify at least one unfilled entity relating to said at least one command and generate at least one dialogue response comprising a prompt to present to a user to obtain the at least one unfilled entity. A respective prompt may be generated for each of the at least one unfilled entity. Related method and computer program product aspects will also be apparent to those of ordinary skill in the art.

For convenience like reference numerals and designations indicate like parts components modules process steps etc. in the various drawings.

Headings of sections provided in this patent application and the title of this patent application are for convenience only and are not to be taken as limiting the disclosure in any way.

A user may interact with the Conversational Agent via App to perform one or more commands. A command may comprise an action and generally at least one associated parameter or other data. For example a user query such as I want to book a meeting indicates a calendar related action i.e. command but does not include associate parameters such as date time location invitees etc. A user query I want to fly to San Francisco next Tuesday indicates a travel related command and provides some associated parameters such as destination and travel date. A user query such as How are you today is a chat related command and does not have any associated parameter. Such user queries may be expressed by the user to carry on a conversation with the App which is adapted to recognize the intention of the user and to respond accordingly.

Services in the context of this specification may include internal services or external services . Internal services relate to one or more functions of the user s device e.g. smartphone such as voice and data communication services personal information management PIM by way of example telephone email instant messaging IM text of short message service SM calendar contacts notes music alarm and the like. Internal services may incorporate any application already installed on the device as well as system information such as user information current time hardware and software information and the like. External services relate to those provided by another party typically via a web connection such as a travel booking service weather information services taxi service shopping service information retrieval service social networking service news service online marketplace service and the like. The term interfaces and services may be used interchangeably in this specification to refer to services .

In some contexts the user input may be a speech input query but responses output from the services for presentation to the user by user interface manager on smartphone may be any one or combination of speech e.g. synthesized automated voice text graphical audio animation responses and the like. Output may include text or other types of responses such as image sounds and the like. In addition to speech input queries a user may interact with the intelligent user interface using a keyboard touch screen mouse and the like and any combination thereof. For example a speech input Send an email to Bob defining a command to email a particular contact may initiate a draft email on smartphone . The user may manually edit the email using a keyboard not shown a touchscreen keyboard or other input means of smartphone . Furthermore some input commands may be inputted using a combination of two or more input modes for example by combining a voice command with a touchscreen input. For example a user may increase the zoom level of the display screen on smartphone by placing one finger on the screen and expressing a command such as zoom 4 times . In a further example a user may touch in the vicinity of a certain input field such as the field for entering recipients of an email message and say names such as Bob Sam Neal etc. The Conversational Agent may interface with several services such as microphone service speech recognition service touchscreen service etc. to receive and process multi modal user inputs to perform the desired command according to derived intent of the user.

Techniques and mechanisms described or reference herein will sometimes be described in singular form for clarity. However it should be noted that particular embodiments include multiple iterations of a technique or multiple instantiations of a mechanism unless noted otherwise.

With reference to components of cloud based service infrastructure include cloudfront server Delegate Service event notification service speech service natural language processing NLP engine service dialogue service domain manager backup manager authentication service Display Manager service Services Manager learning manager external dependent service interfaces providing access to one or more external services such as flight provider service A taxi service B and weather service C. It is apparent that there may be a plurality of each of these respective service components within the infrastructure which is scalably reliably and dynamically able to handle service requests from a plurality of communication devices of which only one smartphone is illustrated. Though shown as a client smartphone and server model certain functions and features may be performed on the client.

Cloudfront server may provide connection load balancing and other communication related services to a plurality of communication devices such as smartphone . Delegate Service may be chiefly responsible for handling and or coordinating processing of the speech input natural language processing of the speech input the resulting commands for the applicable services and any responses. It will be appreciated that each of the services shown in may also have a load balancer that allocates instantiates and destroys its respective services dynamically depending on the demand for a particular service by plurality of smartphones . Load balancing of any service or group of services of the Conversational Agent may be accomplished though a server administration account and may incorporate performance metrics such as queries per second number of user accessing the Conversational Agent and or a particular module etc. processing resources being consumed etc.

As will be appreciated by one of skilled in the art examples herein described may be embodied as a method system apparatus or computer program product. Accordingly the examples may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects all generally referred to herein as a circuit module library and the like. Furthermore the present invention may take the form of a computer program product on a computer usable storage medium having computer usable program code embodied in the medium.

Devices that are in communication with each other need not be in continuous communication with each other unless expressly specified otherwise. In addition devices that are in communication with each other may communicate directly or indirectly through one or more intermediaries.

Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. The computer usable or computer readable medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus device or propagation medium. By way of example and not limitation computer readable media may comprise computer storage media and communication media.

Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

When the subject matter is embodied in the general context of computer executable instructions the embodiment may comprise program modules executed by one or more systems computers or other devices. Generally program modules include routines programs objects components managers engines resources data structures etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

A description of an embodiment with several components in communication with each other does not imply that all such components are required. To the contrary a variety of optional components are described to illustrate the wide variety of possible embodiments of one or more of the invention s .

Further although process steps method steps algorithms or the like may be described in a sequential order such processes methods and algorithms may be configured to work in alternate orders. In other words any sequence or order of steps that may be described in this patent application does not in and of itself indicate a requirement that the steps be performed in that order. The steps of described processes may be performed in any order practical. Further some steps may be performed simultaneously despite being described or implied as occurring non simultaneously e.g. because one step is described after the other step . Moreover the illustration of a process by its depiction in a drawing does not imply that the illustrated process is exclusive of other variations and modifications thereto does not imply that the illustrated process or any of its steps are necessary to one or more of the invention s and does not imply that the illustrated process is preferred.

When a single device or article is described it will be readily apparent that more than one device module component service article collectively referred to as components whether or not they cooperate may be used in place of a single component. Similarly where more than one component is described whether or not they cooperate it will be readily apparent that a single component may be used in place of the more than one component.

The functionality and or the features of a device may be alternatively embodied by one or more other devices that are not explicitly described as having such functionality features. Thus other embodiments of one or more of the invention s need not include the device itself.

Although described within the context of conversational technology for a computing device such as a smartphone it may be understood that the various aspects and techniques described herein such as those associated with natural language processing for example may also be deployed and or applied in other fields of technology involving human and or computerized interaction with software. For example the Conversational Agent of the invention may be used with web enabled televisions set top boxes voice enabled appliances in a smart home interactive voice response systems voice enabled automobile interfaces as well as with other technologies where voice interaction and or natural language understanding of a user s intent is useful.

Event notification service provides event related messages to smartphone for example data communications such as calendar reminders recommendations previously used external services daily deals and daily updates social media events such as status updates follow ups survey requests and the like. In another embodiment smartphone also includes a device event service for processing device specific events such as battery low on power automatic processing of images taken by the camera of the smartphone location reminder based on real time GPS coordinates of the device as well as any or all of the calendar alarm reminders that may also be handled by event notification service . Cloud based event notification service may provide information on events related to a user of a smartphone from external services such as a social media service email service new service and the like. In one embodiment cloud based event notification service uses push technology to notify the Conversational Agent when certain events occur that may be of interest to a user. For example a user may want to know when a friend has changed their status on a social media website. Cloud based event notification service may periodically scan for events and when such an event occurs such as a friend changing their status notify the Conversational Agent using push and or pull technology so that the change of status may be communicated to the user.

Speech service performs speech to text conversion receiving speech input for defining a command such as in the form of a digital audio file from smartphone and provides text output in the form of a user query . In an embodiment the speech service may reside wholly or in part on the client device . Speech service may take as an input the raw audio file in lossy or lossless format examples of which include PCM ASR mp3 and the like . Speech service may interact with one or more language grammars which may correspond with specific domains languages subtopics etc. In one embodiment the Conversational Agent interacts with user specific grammars which may include audio and or grammar models that correspond to the user s accent intonation patterns as well as user specific terms such as the names from the user s address book geographic terms commonly expressed by the user and the like. Speech service is described in more detail with respect to . In this description the term user query may refer either to spoken input queries or the text translation of a given spoken input. Natural language processing of an input query is generally performed with a text input string representation of a user query . User queries voiced by the user are made up of sound waves. Sound is a mechanical wave that is an oscillation of pressure transmitted through a solid liquid or gas composed of frequencies within the range of hearing. The speech recognition module may employ one or many techniques for converting the inputted audio signals from the user into a digital format for further processing. The digital format may be an audio file a text file or any other digital format or combination of digital formats. The speech recognition service transforms the substance of the input from an audio query wherein the user intent is embodied in a sound wave to a digital format such as text string wherein the user intent is embodied in an electronic digital medium which can then be processed by an electronic device such as a computer or smartphone .

NLP Engine analyzes the user query to derive the user s intention and specific commands with which to provide the services desired by the user and may create a representation of the desired user intent. Dialogue service assists with the user interface between the user and the services for example by engaging in natural language dialogue with the user. The dialogue may include questions clarifying one or more aspects of a specific command as discussed further herein below. The dialogue service s responses to speech inputs from smartphone need not be in spoken audio format but may be in a text based visual audio or other format as previously mentioned. Dialogue service may also receive general conversational queries and engage in a continuous conversation i.e. CHAT with the user. General chat queries do not necessarily relate to a particular command and NLP Engine may determine that the intention of the user is to converse with the Conversational Agent .

Domain manager may dynamically manage update and make available domain corpora to NLP Engine and other services. In one embodiment domain manager may dynamically switch domain corpora to maximize the accuracy of NLP Engine recognition of the user s intent for example to increase the precision and recall of the Conversational Agent . In one embodiment domain manager manages the incorporation of new domain functionality into the Conversational Agent see . For example as discussed herein the range of knowledge available to the Conversational Agent may be expanded by adding new domains including domain models and corpora to the Conversational Agent dynamically to provide a broader user experience.

Interfaces are interfaces to particular web based services e.g. Web Services or other external services. External services typically utilize well defined interfaces e.g. application programming interfaces APIs for receiving requests and returning responses. Cloud based service infrastructure provides a manner for receiving natural language commands for such services determining the applicable external service request based on the derived user intent and any associated data parameters to make the request and invoking the request. Cloud based service infrastructure is also configured to receive the applicable response and provide same to smartphone on user interface . Similar operations may be performed to invoke internal services and provide the response s to smartphone .

Internal and external services such as via interfaces may be invoked in any one of several ways. Any service call mechanism can be used. Examples include REST SOAP COBRA and the like. Non service call passive mechanisms can also be used. In this case data is placed at a digital location that is accessible by the invoked service. The invoked service checks this digital location. The passive mechanism is also effective as an invocation mechanism.

Software components further include template service to assist with the dialogue service persistence memcache service relational database management service RDBMS for storing and managing data and application server and business code components such as components of an object oriented Jboss Server and Enterprise Java Beans EJB contain service in accordance with an example implementation

Smartphone is configured such as via one more applications to send language information to cloud based service infrastructure and receive a response based on language understanding and the derived intent of the user. In an embodiment an automatic speech recognition service ASR Service available to smartphone receives an audio user query from the user and converts the audio user query into a text format which is then communicated to cloud based service infrastructure . ASR service may reside entirely or in part in cloud based service infrastructure and or smartphone . One or more applications on smartphone may be configured to accept and process one or more user interface commands into an execution command which is then communicated to cloud based service infrastructure . By way of example a user may voice a command such as Tell Bob I will be late for the meeting while pressing an icon on a touch screen that corresponds to a text message. Application may receive the input query and the input touch command and process these two commands into a single command which is passed on to cloud based service infrastructure for further processing by modules of Conversational Agent such as Services Manager to perform according to the derived intent of the user as determined by NLP Engine .

Smartphone is also configured to receive notifications from event notification service . In some embodiments smartphone may be configured to perform natural language understanding without the use of cloud based service infrastructure for example when understanding requires sensitive information that a user prefers is not sent off the smartphone or if cloud based service infrastructure is unavailable for any reasons. In an embodiment the natural language processing of user query may be partially performed on smartphone and by cloud based service infrastructure . In some embodiments user devices need not be limited to smartphones only. Other communication devices can be supported such as dumb phones via any communication protocol including TTY and SMS. Non phone clients such as laptops tablet computers personal computers set top boxes televisions kiosks etc. can also be supported as well.

In one embodiment the Conversational Agent employs an encryption manager not shown to encrypt and decrypt information sent between smartphone and cloud based service infrastructure . Any encryption method or combination of encryption techniques may be used such as public key encryption. Certain information relating to users of the Conversational Agent may also be anonymized for example financial information and addresses and contact information of contacts.

A user interacts with App on their smartphone to perform commands and or to engage in a conversational dialogue with their smartphone . App is a component of the Conversational Agent and provides a user interface for allowing the user to interface with the functionality provided by Conversational Agent . A user query is a text representation of a voiced or typed user query provided by the user. In general a user query relates to a domain of functionality. A domain in the context of this specification refers generally to a field of action thought topic conversation etc. Example domains include CHAT TRAVEL WEATHER SPORTS CALENDAR SOCIAL MEDIA and the like. Domains are general categories of classifying dialogue interaction and intended functionality and may be as specific or as general as makes sense for a given implementation of the Conversational Agent .

In one embodiment NLP Engine receives a user query as described below and derives the intention of the user. NLP Engine may identify a domain a subgroup also referred to as a subdomain one or more tasks also referred to as actions and or commands according to the derived intention of the user and one or more entities also referred to as parameters that may be useful to accomplish the one or more tasks. As an example interaction a user expresses the query Find me a flight from Toronto to New York leaving in a week . The above query may be classified by NLP Engine as relating to the domain TRAVEL the subgroup of flights. NLP Engine may further relate the user query to tasks to be performed such as find flights and may be book flights and may further identify the entities Toronto New York as well as the departure date. The process of identifying the domain subgroup one or more task and entities associated with a user query is generally referred to herein as deriving the user intent. NLP Engine may create a representation of the derived user intent by creating a software object such as a template and or by saving the intent to temporary and or permanent memory. As described further in this specification the Conversational Agent may attempt to elicit additional entity information from the user such as in this example interaction a particular airline the return date the class of the ticket number of tickets number of stops allowed time of the departure and return flights and the like.

Dialogue driver i.e. Delegate Service which may be a component of Dialogue Manager receives user query for processing and provides user query to question type classifier . User query is also provided to keyword expansion unit . The user query and expanded keywords not shown are provided to previous query score determiner which references prior queries not shown stored in query database . Previous query score determiner performs statistical analysis and provides candidate answers i.e. commands for ranking by answer ranking unit .

Query database may store such as in a machine learning manner a history of user queries and the associated commands and additional data such as keywords determined by cloud based service infrastructure . The query database may store a complete history or subset of a particular user s query and associated commands to build user centric preferences. For example a particular user s query Tell Bob I want a meeting may result in a command to telephone Bob send a text message to Bob or email Bob. In an embodiment the Conversational Agent may ask the user to clarify the command by offering a series of choices for communicating the message to the recipient in this case Bob . For example the Conversational Agent may provide a list on the user interface that includes send email send text and phone the user may simply select the option desired and the Conversational Agent will automatically perform the desired command see for example . In an embodiment the Conversational Agent may simply express a clarification question such as Would you like to phone email or text Bob The user may simply say phone Bob or phone or phone him and other related command to initiate a phone command. The Conversational Agent may also provide a clarification list together with an audio clarification question to provide a range of options to the user for selecting the desired command.

In an embodiment the Conversational Agent may map a specific command to one or more words contained in a user query. In the above example the Conversational Agent may map the word tell or the phrase tell Bob with one or more commands such as an internal phone service. The Conversational Agent may learn over time the behavior patterns and or preferences of the user in relation to many commands. The Conversational Agent may also learn the preferences and or behavior patterns of a user in relation to performing a command for a specific parameter or class of parameters. For example the Conversational Agent may associate the word Tell with the parameter Bob to the command phone . However in the case of another parameter for example the contact Ann the Conversational Agent may associate the word Tell with email. For a class of parameters such as work contacts the Conversational Agent may associate the word Tell also with email. It will be appreciated that the learning ability of the Conversational Agent of the invention may be leveraged in a variety of other ways. The Conversational Agent may recognize that the word Tell is associated with email most often during the week and with phone during the weekend. In an embodiment the Conversational Agent may present a list of command choices where one command is presented as a default command based on the learned behavior and or user preferences and other commands are presented as an ordered list of commands where the order is also learned.

In addition to providing a source of user centric preferences and learned user behavior query database may also be useful to store and provide access to user queries associated commands and the like from all users such as via an aggregated subset of queries and associated commands. The aggregated data may define a broader corpus from which statistics and other data may be gleaned and be useful when determining expanded keywords classification of user queries mapping words to certain commands determining classes of users based on recognized user types and or the like.

Question type classifier evaluates user query to determine whether the user query is a function type query an entity type query or a clarification type query. A function type query establishes a new command also referred to herein as a topic . An example of a functional type query is Book a meeting for next Friday at 2 00 pm or Send a message to Bob .

An entity type query is in relation to a current command topic and adds or changes an entity in such a command. For example Actually move that to 3 00 pm or Add James to the message or Make that a return ticket .

A clarification type query is in relation to a current command and is responsive to one or more clarification questions posed by the Conversational Agent to elicit more information such as entities and or parameters or to determine which domain the user is referring to with a specific query. Clarification type queries may occur when the Dialogue Manager asks the user a clarification style question. For example for the user query Tell Bob I want to book a meeting Conversational Agent may formulate an output comprising a clarification questions from Dialogue Manager such as Did you want to text or email Bob . These clarification questions are formulated to elicit more information regarding the communication method the user wishes to employ to communicate the message to Bob. In the above example a user query such as Text him in response to the clarification question would be classified as a clarification query .

In response to some queries the Conversational Agent may formulate a clarification question to determine which domain the user is referring to. For example for the user query Get me tickets to Rome the Conversational Agent may recognize that Rome is a city there are several restaurants with the word Rome in the name and that Rome is also the name of a movie. Conversational Agent may formulate and present as output a clarification question such as Did you want a flight to Rome tickets to the movie Rome reservations for a restaurant or something else . The Conversational Agent may learn over time that the user prefers a certain mapping for queries with the word Rome and may take corresponding action i.e. perform a command based on the user behavior and or user preferences. For example the Conversational Agent may default to the option of finding flights for queries that contain city names where user behavior indicates that a particular user is a frequent traveler. As another example the Conversational Agent may default to movies when a particular user query may relate to movies or restaurants or other domains because a particular user of Conversational Agent frequently searches for movies.

Function type queries may be directed by question type classifier to answer ranking unit for determining the new command if possible. Question type classifier may direct entity type queries and clarification type queries to Template System for additional processing to obtain further meaning from the user query with a view to also initiating appropriate output for example by formulating a clarification question. Template System may also receive function type queries from answer ranking unit . Template System may access template memory store to define or refine a command and to define applicable output .

Some user queries may be more than one type of query and or may be compound queries that specify several commands. For example a user may express a user query such as Change my return date to September 16 and give me the weather while I am there . Such a user query may be processed in several ways. For example user query may be divided into separate queries by NLP Engine i.e. Change my return date to September 16 and Give me the weather for destination between departure date and return date . Furthermore NLP Engine may also assign the destination location to the word there so that the weather may be obtained. NLP Engine may include a query preprocessor not shown that is adapted to separate compound queries into individual queries and also to assign specific entities to anaphora terms in a given query .

Extraction Pipeline may receive user query and conversation features and extract entities from the user query to build up the command and its associated data as described further herein below with reference to . The entities extracted from a given user query may be populated into template object which is passed to services manager to accomplish the derived user intent. Dialogue Manager and Display Manager provide output for smartphone also as described below. Smartphone may have a queue manager that receives output from cloud based service infrastructure .

At step in one embodiment user query may be subjected to binary classification such as via a support vector machine SVM for analysis. Other known types of binary classification may also be used alone or in combination such as decision trees Bayesian networks support vector machines and neural networks. A support vector machine SVM is a concept in statistics and computer science for a set of related supervised learning methods that analyze data and recognize patterns used for classification and regression analysis. The standard SVM takes a set of input data and predicts for each given input which of two possible classes forms the input making the SVM a non probabilistic binary linear classifier. Given a set of training examples each marked as belonging to one of two categories an SVM training algorithm builds a model that assigns new examples into one category or the other. In one embodiment of the Conversational Agent the two categories are functional type query and entity type query. The classifier i.e. the SVM may be trained by providing a set of queries identified as belonging to the category of entity type queries and another set of queries belonging to the category of functional type queries.

User query is applied to the SVM at step and SVM may perform analysis of the user query to determine whether the query is an entity type query related to current command topic or not i.e. the user query is a function type query . Functional type queries are passed at step to answer ranking module . Entity type queries may be passed at step to Template System .

As described above a training algorithm may build a model for the SVM for assigning new queries to either the functional type query category or the entity type query category. An SVM is a representation of the examples as points in space hyperplane mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New queries are then mapped into that same space and predicted to belong to a category based on the side of the gap on which reach respective query falls. When preparing the SVM and when passing in new queries for classification it may be useful to selectively provide certain words terms and metadata and or other features related to the query . Using all words from a query may be problematic because common words may skew results incorrectly. Services application programming interfaces or other means such as Extraction Pipeline illustrated in which perform entity extraction may be useful to extract entities parameters such as people places dates specific things contacts times etc. For example the following is an example of features which may be determined and provided by a query preprocessor not shown and passed to the SVM 

Presence of keywords TF IDF term frequency inverse document frequency scores for each domain may be calculated for each word in the entire corpus. The words are then sorted and a selection of the words with the top 50 scores as an example is made.

Question type keywords This represents the words that often begin or identify questions such as how where when why who what followed by obvious keywords that related to the domains e.g. commands related to functions provided by a user interface such as call text message book and the like.

Presence of key entities Examples include places addresses person names restaurant types and names food dish names date etc. As new domains may be added to the Conversational Agent key entities may also be added. These key entities may be retrieved using named entity recognition and extraction as described herein.

Potential features For example the current action that the user is performing on the device the previous domain the user requested etc.

Presence of regular expressions whether the query matches a pattern known to be found in data for each domain. Patterns may have be handcrafted and or partly learned from data for each domain. For example a query beginning with the phrase Find me . . . may commonly indicate a functional type query related to flights internet search music and the like.

When a clarification query has been posed and is pending i.e. the clarification question has not been answered at a determination may be made whether the user query contains keywords related to the clarification question posed i.e. whether the query is responsive to a clarification query . For example in the case where a clarification question offers a list of options such as Would you like to phone text or email Bob Conversational Agent may look for the words phone text and email in the response user query . As another example where the clarification question asks for the specific name of an entity such as What city would you like to depart from the Conversational Agent may look for the name of a specific city in the response query. If it is determined that the query contains keywords related to the clarification question posed then the query is a clarification type query and the classification of the user query and its association with the current command may be passed to Template System for further processing. If such keywords are not present the user query may comprise a new functional type query or an entity type query such as where the entity entities were not the focus of the clarification question posed . The user query may be then forwarded to step via the no branch from .

In one embodiment NLP Engine uses a clarification question SVM to determine if a particular query is responsive to a pending clarification question. In an embodiment keyword identification may be performed in the context of operations enable the determination of whether the user query is an answer to the clarification question posed. Statistics may be defined for particular terms to identify their relative frequency of appearance in user queries associated with a particular category e.g. each respective category may represent a specific command .

In an embodiment the relative frequency of a term in a category is comparatively determined in relation to the terms infrequency in the other categories as well. In step TF IDF word scoring is used to determine keywords for each category. A document is defined as the set of queries that belong to the same category e.g. . Specifically a separate corpus may be maintained and utilized for each domain such as TRAVEL MUSIC SOCIAL MEDIA CALENDAR TIME and the like. The corpus related to the TRAVEL domain for example may include queries with relevant travel related keywords such as flight trip vacation hotel attractions city names airline names airport names airport codes rental rental car companies and the like. The corpus related to the SOCIAL MEDIA domain may include queries with relevant social related keywords such as for example friends wall news fee message the name of common social media sties the names of friends and business associates the name of application integrated with social media websites and the like.

The corpus within query database is the set of queries etc. that are not the category where we are finding the keywords. In this specification the term category ies may be used synonymously with the term domain s . A term keyword which is relatively unique to category D is also less frequently occurring in the corpus of category A B and C queries. This database of queries related commands and associated statistics may be maintained e.g. pre calculated so that the statistics are available for use in real time when processing the user query . These statistics may be updated by a learning manager module as described further in the specification. A word ranking for words in the current user query may be determined at to identify unique words indicative of keyword status for determining the domain to which the user query relates.

The user query may be analyzed for keywords from the category or categories associated to the user query . Given that a clarification type question may have elicited the current user query one or more categories may have been previously associated with the current user query as determined from processing the prior user query which occasioned the clarification. These one or more categories related to the current command. It is understood that because individual user queries may be vague and or ambiguous more than one category command may be associated with the use query e.g. as respective commands . As the dialogue develops a specific command can be determined.

The classification of the query type is useful to perform a new command via answer ranking unit and Template System or to further process a current command by eliciting more information from the user via Dialogue Manager and Template System .

With reference to there is illustrated a flow chart of a method of an answer ranking module that may be used according to a Conversational Agent of the invention. Answer ranking may be performed to assist with the identification of the specific command to which the user query relates. In the context of answer ranking module is configured to identify an appropriate command that relates to the derived intent of the user. For example a user may voice a query such as I want to buy a ticket to San Francisco . Speech service may process the audio input and incorrectly produce the user query of I want to tickets in San Francisco which is provided to answer ranking module . Answer ranking module evaluates the user query with operations methods shown in and may correctly determine that the correct command i.e. according to the user intent is related to finding a flight to San Francisco.

As described above answer ranking may be performed when the question type classifier determines that a user query is likely a function type query. In the present example embodiment answer ranking method performs four types of analyses and on user query and combines the results via a two layer neural network to drive a rank of answers . A neural network is a mathematical model or computational model that is inspired by the structure and or functional aspects of biological neural networks. A neural network consists of an interconnected group of artificial neurons and it processes information using a connectionist approach to computation. In most cases an artificial neural network ANN is an adaptive system that changes its structure based on external or internal information that flows through the network during the learning phase. Modern neural networks are non linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs or to find patterns in data.

Though a plurality of four natural language processing techniques are used in the example embodiment few or additional techniques may be used and the respective results of same combined to drive a rank of answers. In some embodiments a means other than two layer neural network may be used to combine such results.

In one of the analyses user history is examined to define a previous score . Previous query score may be used for example as an indication that the current query is related to the same or a similar command to that used in relation to a previous user query. For example for a given user query such as Find me the weather outside now there may be a strong likelihood that similar queries for example query What is the weather like right now relate to the same or similar commands as was previously associated with query . In this way an association between a given command and the same or similar user queries may be reinforced by the previous query score according to one embodiment.

Keywords may be extracted from user query such as by TF IDF techniques as described herein. Previous user queries and their respective associated commands form a corpus for comparative purposes. Keywords may be expanded with related words e.g. synonyms and or words with similar meanings such as via WordNet expansion WordNet is a registered trademark of Princeton University or using other keyword generation methods.

The extracted and expanded keywords may form the basis of a comparison or search applied against the query corpus and a relevance score calculated e.g. retrieval and ranking functions to rate search results. The search results i.e. each respective candidate command and its associated ranking score are made available to operations of two layer neural network . The ranking function applied at may comprise a BM25 of similar ranking function e.g. BM25 F taking into account document format length etc. . BM25 relies upon IDF statistics to determine relevance of keywords in a document set.

In one of the analyses random forest in this embodiment the user query is applied to a set of decision trees where each decision tree assigns i.e. determines a command to which the user query relates. A rank or mode may be calculated to determine which command or commands results most frequently by the decision trees. Let N c represent the number of decision trees that classify the user query as command c . R c is the score for class c calculated as N c divided by the sum of N c for all c s derived by the decision trees. The scores and associated candidate commands are made available to operations of two layer neural network . A two layer neural network see discussed below may be trained in order to determine the probability that the query was relevant to a given command. From this a rank for each of the classes can be determined according to this probability.

In one set of analyses e.g. multiclass Support Vector Machines the query is applied to a set of SVMs to determine a command. In one embodiment each SVM is a binary classifier configured to determine whether the user query is associated with a particular command or any of the other commands i.e. a oneversus all determination . An example one versus one determination is email vs. telephone. In another embodiment an SVM is configured for each pair of commands to determine whether the user query is associated with one of the two particular commands e.g. email vs. telephone i.e. a one versus one determination . It is noted that in a one versus one embodiment SVMs may be configured for a pairing of particular commands to a null class.

In a one versus all determination if the SVM approach is the sole classifier a winner takes all approach is often adopted selecting the highest score from the SVMs. The SVMs require calibration to produce comparable scores. In the one versus one approach a command selected most frequently by the set of SVMs is the candidate command if the SVM approach is the sole classifier. In this example environment where the SVM approach is one of four inputs scores for each candidate command are provided for operations of two layer neural network .

In one of the analyses na ve Bayes classifier the user query is provided to a Bayes theorem based classifier with strong independence assumptions to perform document classification. The na ve Bayes classifier determines a probability that a particular user query set of features belongs i.e. is associated with a particular class i.e. command . The classifier na ve Bayes classifier may be trained using a training set of known queries and associated commands. It may be assumed that words of a user query are independent. Frequency of appearance count of a word in a given class command may be used to determine a probability that a particular word is in a particular class. The score for a particular class is a multiplier of the score probability for each word in the query relative to the particular class. Care must be taken when a word never appears in a particular class to avoid multiplying by zero. A smoothing technique can be used to eliminate the effects of zero probabilities in the data.

The Conversational Agent may employ one or more aggregation modules for combining classifiers and and for providing generating a result therefrom. In one embodiment a two layer neural network is used to combine scores from classifiers and and to define a single score for each command. More particularly the scores from the classifiers are used as input nodes to a two layer neural network which represents a rank function. The set of classifier scores for a single candidate command represents a single input vector. This vector is scored via the neural network according to its relevance to the user query. Here a score of 1 is considered highly relevant to the user query and a score of 0 is considered irrelevant. Each of the vectors for each command are scored via the rank function and sorted according to their score. Finally the scores are normalized by dividing each of the scores by the maximum number of scores.

Other aggregation modules may be employed in place of or in conjunction with two layer neural network . In one embodiment answer ranking module uses a logistic regression analysis to combine classifier scores and generate a combined ranking result for each candidate command. Logistic regression is a type of regression analysis used for predicting the outcome of a binary dependent variable a variable which can take only two possible outcomes e.g. yes vs. no or success vs. failure based on one or more predictor variables. For example in one embodiment logistic regression analysis takes classifier scores and determines whether candidate command is likely to be correct or not.

In another embodiment answer ranking module uses a reciprocal rank fusion analysis to combine classifier scores and to generate a combined ranking result i.e. score for each candidate command.

According to one embodiment the Conversational Agent of the invention may employ one or more Conditional Random Fields CRF s such as for example template filler CRF and entity extraction CRF as shown in . CRFs are a type of discriminative undirected probabilistic graphical model. They are used to encode known relationships between observations and construct consistent interpretations.

In one embodiment each word in a given user query is evaluated according to at least one CRF to determine whether each word is likely to represent a particular feature. A feature in this context is a property that a given word either has or doesn t have. Examples of features are Is this word a noun Is this word a city Is this word a song Is this word a preposition and the like. A CRF decides upon whether a given word has a particular feature according to the following formula Entity Feature 

Where Alpha is the normalization constant and W is the weight vector for the specific entity. Each weight will be associated with a feature.

A CRF for a specific domain requires specific features and entities that are relevant to be identified. As an example take a scenario of buying a flight ticket. A user may express the query Find me a ticket from Toronto to New York leaving on Monday coming back on Friday . The Conversational Agent processes this user query to identify entities that may be necessary for the Services manager to call an external flight service to process the request. In this particular example Services Manager may require DEPARTURE CITY Toronto DESTINATION CITY New York DEPARTURE DATE coming Monday AND RETURN DATE Friday after the coming Monday . Services Manager may also use TIME LUXURY CLASS COST CARRIER STOPOVERS NUMBER OF TICKETS PRICE SPECIFIC GROUP HOTEL as well as other entities.

Within the Conversational Agent recognized features may be passed along to a Template Tagger i.e. Template System which further breaks down the recognized entities into more precise entities. In one embodiment the first CRF recognizes general features such as this word is a city and the second CRF recognizes specifics of the features such as this city is San Francisco .

Once a set of features has been decided for a particular domain it is necessary to acquire training data and then have the data labeled with correct entities. The labeled data and general features set are passed along to a genetic algorithm and both conditional random fields . One a set of training data has been labeled with the correct entities training of the one or more CRFs is a matter of maximum likelihood learning for P Ei Fi W .

Once training has been complete any new sentence i.e. user query can be processed by first extracting out features and then feeding that sentence and the feature set though the one or more CRFs. The process used by the NLP Engine for processing queries according to one embodiment is illustrated in and .

Feature selection and hence optimizing the operation of conditional random fields are done via . Any combination of features can be used to perform the task of Named Entity Recognition using a CRF. However the use of a particular feature set may have a dramatic effect on the accuracy of the results. The Conversational Agent may use a genetic algorithm to determine the optimal feature set for a given domain. The challenge of finding the optimal feature set may be thought of as searching the entire space of feature sets for the optimal answer. In order to apply the genetic algorithm the following mapping from the feature set space to a binary vector space is applied 

An example of a potential fitness function is made of the f measure log n where n is the number of features in the feature set. The f measure is a common accuracy measure for named entity recognition and the log n term is added so that the system favors smaller models.

With reference to a genetic algorithm working on a general feature set determined from a labeled corpus generates e.g. off line in advance of its use in a particular classification instance optimized feature sets for respective specific domains. Each domain may have its own Extraction Pipeline for extracting entities for the specific domain. For example the Extraction Pipeline for the RESTAURANT domain is adapted to identify entities related to restaurants such as name location cuisine price atmosphere rankings and the like. Each pipeline instance receives the user query and its conversation features . Examples of conversational features include question ID results of pronoun resolution and or anaphora resolution with previous sentences and other related information.

A feature extraction module expands the features associated with the user query and conversation features . Examples include date lists number lists city lists time lists name lists among others.

The expanded user query and its specific conversation features are fed through the filter created by the genetic algorithm and provided to a previously defined conditional random field CRF . CRF is a statistical modeling method applied for pattern recognition. Optimized feature sets are used to define the filter and to train the CRF. The CRF is trained with specific features decided by the genetic algorithm. After it is trained with specific features the CRF is configured i.e. biased to expect those features in the future. The system ensures that the CRF only gets the features it is expecting.

In the illustrated embodiment two layers of CRF are employed. A first layer determines general entities e.g. an entity extraction CRF . For example in a travel booking user interface general entities may include date place time etc. A second layer determines more specific template entities e.g. a template filler extraction CRF such as destination departure location departure date to fill templates of the Template System . In some embodiment a single layer CRF may be employed. Template System may store e.g. to template memory store the filled or partially filled template for a particular command as user queries are processed.

A Services Manager may be provided for executing and or performing a command according to the derived user intent. Services Manager may interface with one or several internal and or external services via an application programming interface a predefined protocol and or the like. In an embodiment Services Manager performs a requested command or groups of commands based on a filled or partially filled template provided by NLP Engine . In one embodiment template is filled with entity information by the NLP Engine as described above with respect to named entity recognition and entity extraction which then passes template to the Services Manager . The derived user intent may be combined with some or all of the rich information described herein to further complete template . Services Manager in one embodiment evaluates the content of template to determine if the command requested according to derived user intent can be performed. In one embodiment Services Manager may select a service from a collection of services that are able to perform substantially the same command i.e. offer substantially similar functionality .

By way of example a user may express the query Show me the weather for Singapore for the next two weeks . Natural language processing engine may receive the query from the delegate and fill out a template with the entities that can be extracted from the query as well as from rich information described further below . NLP Engine may pass the template back to the Delegate Service for routing to the Services Manager and or directly route the template to the Services Manager . In an embodiment Services Manager evaluates template to determine several pieces of information. First Services Manager obtains the domain that the query relates to in this example WEATHER as well as any subdomains if applicable. A subdomain of the domain WEATHER may be for example weather forecast weather history weather maps etc. In this case Services Manager may identify the query as relating to the subdomain weather forecast . Services Manager may then refer to a list of applicable services that related to the domain subdomain to determine which of the services are operable to perform the desired command and or similar commands. Services Manager and or another module of Conversational Agent may maintain the list of applicable services and their related domains subdomain as well as interfacing instructions for each applicable service . The list of services categorized by domain and or subdomain may be stored in memory by Services Manager and updated accordingly. In an embodiment Services Manager dynamically creates updates stores optimizes etc. the list of services as new domains are added to the functionality of Conversational Agent and or as new third party functionality is integrated into the Conversational Agent by interfaces .

Once the Services Manager has identified the service s that are available to perform the command according to the derived user intent Services Manager may select an appropriate service to execute the command. Services Manager may select the appropriate service based on one or more criteria such as user satisfaction with a particular service traffic load on services amount of information contained i.e. the entities available in the template etc. As an example a user may express a query Get me a flight to San Francisco leaving on Friday . NLP Engine identifies the user query as a query relating to the TRAVEL domain and flight booking subdomain extracts the relevant entities from the user query and fills out template with the extracted entities. As an example template filled in with relevant entities may be illustrated as follows 

In the example template NLP Engine is able to extract the entities directly out of the user query for example the destination city of San Francisco and the departure date of Mar. 16 2012 . In an embodiment NLP Engine may apply user settings and or preferences such as Look for one way tickets if return date not entered and Use current GPS location for departure city in this case Toronto. NLP Engine may pass this partially completed template to Services Manager for handling as described herein. When Services Manager receives template Services Manager selects appropriate services from a services list for the TRAVEL domain flight subdomain and may apply additional logic to select the appropriate service. For example Services Manager may determine that four external services are available for booking flights. In this example these services are labeled S1 S2 S3 and S4 for convenience. Services Manager may then apply logic to determine which of S1 S2 S3 and S4 are most appropriate to call according to the derived user intent as well as to provide a high level of user satisfaction. Continuing this example Services Manager may determine that service S1 does not list flights for San Francisco and is therefore not an appropriate service to call Services Manager may also determine that service S2 is currently down i.e. not available and therefore is not an appropriate service to call. Because only service S3 and service S4 are appropriate for executing a command according to the derived user intent Services Manager may analyze user satisfaction ratings for S3 and S4. In finding that S3 has a higher user satisfaction rating and or that S3 is preferred to S4 by the current user Services Manager then calls S3 which returns a result to the Services Manager. In one embodiment Services Manager analyses other user preferences such as Default to dates are flexible to determine the appropriate service. For example if Dates are flexible is set or defaulted to be TRUE Services Manager evaluates the appropriate services to determine if they are capable of executing a command according to the derived user intent and user preferences. Continuing with the above example Services Manager has already determined that only services S3 and S4 are available and or capable of executing the desired user command. Services Manager then determines that service S3 is not capable of searching for flights with flexible dates and therefore after applying logic Services Manager calls service S4 which returns a result. If for example both S3 and S4 are incapable of searching for flights by flexible dates Services Manager may still select one or both services S3 and S4 to call by providing default dates.

Clarification type questions may be generated by Dialogue Manager . Each class i.e. command may have a predefined clarification dialogue or multiple dialogues that are assembled using natural language generation. Dialogue Manager generates questions providing specific alternatives among the classes e.g. Did you want to Continuing the example for the user query Tell Bob I want a meeting on Thursday a possible clarification response question generated by dialogue driver may be Did you want to text email or book a meeting Dialogue Manager passes the desired command and extracted entities to the Delegate Service for example to invoke a particular function via Services Manager .

Dialogue Manager is operable to provide a variety of functions such as but not including domain modularization disambiguation mixed initiative Personalization recommendation intent recognition subtask resumption confirmation each of which is described in more detail below see too .

Dialogue Manager maintains conversation system state and generates responses output based on the state of the conversation the current domain being discussed by the user entities that may need to be filled by eliciting clarification questions response from services and the like. Dialogue Manager may be configured as a finite state machine. Markov decision process MDP or partially observable MDP POMDP techniques may be used for determining actions of the Dialogue Manager . States may comprise entity clarification speech error NLP error unknown request informative response and the like. The operation of Dialogue Manager will be described in more detail below.

As mentioned above Delegate Service may receive user query and may communicate user query relevant metadata and or a modified user query to other modules managers services of the present invention. In one embodiment Delegate Service directs user query to NLP Engine to extract a representation of the intent of user an associated command and one or more parameters. NLP Engine may return the derived information representing the user intent back to the Delegate Service for further processing and or store the information in the Topic Board . In one embodiment NLP Engine uses a Template Tagger i.e. Extraction Pipeline to create and populate template object and then communicates directly or via Delegate Service the template to Services Manager for accomplishing the command according to the derived user intent.

Topic Board may be a database a data structure instantiated objects a log file and the like. Topic Board may be used by the Delegate Service to store rich information about a user conversation user session and or user history. In an embodiment Topic Board may store the following information user query entire conversation transcript NLP domain classification identified task filled entities etc. Topic Board may be adapted to act as a parallel agenda in that Topic Board may keep track of monitor detect events etc related. to any number of simultaneous conversations that the user is engaging in with the smartphone .

Dialogue Manager may be operable to periodically scan Topic Board to determine an appropriate presentation order of results received from services and the associated conversational and or output dialogue to be presented on the App of smartphone . For example Dialogue Manager may scan Topic Board and see a single entry which is an incomplete template . The template is incomplete in the sense that template did not have the required entities filled in so that Services Manager could not perform a command via internal and or external services according to a derived intention of the user. Continuing the example Dialogue Manager accesses Topic Board and determines that more information i.e. entities are needed from the user so that Services Manager can perform a command according to derived user intent. Dialogue Manager may have access via a dialogue database to a predetermined collection of dialogue statements i.e. clarification questions designed to elicit entities from a user so that a given template may be populated. In one embodiment Dialogue Manager may generate dialogue using natural language generation technology to elicit additional entities from the user.

In an example interaction a user expresses a user query such as Get me a flight from Toronto to New York leaving on April 9th coming back on April 15th . NLP Engine receives the user query via the Delegate Service and processes the user query as described herein. NLP Engine recognizes the user intention relates to a domain such as TRAVEL subgroup flights and recognizes certain entities such as Toronto N.Y. April 9th and April 15th. A Template Tagger may be employed to create a template object with the relevant information of the derived user intention. A possible template for this example interaction may look as follows 

As shown above example template is in the form of an XML file however other formats can be used to store and communicate domains subgroups entities etc. between modules of the Conversational Agent . The tag value with an associated string in quotations indicates that a particular entity has been filled. In this example TO FROM DEPARTUREDAY and RETURNDAY have their respective value field filled. It will of course be appreciated that the above tag names and entity types are merely exemplary and that embodiments of the invention may employ a variety of template formats tag names specific entities for a particular domain and across several domains.

Dialogue Manager may access template from Topic Board as described above and generate dialogue to elicit additional entities from the user. Continuing the example Dialogue Manager may employ logic to determine which entities must be filled so that Services Manager may correctly interface with a service . Say for example that in one embodiment the entities LUXURY and NUMBERATICKETS must be filled for Services Manager to interface with services . Dialogue Manager may access a dialogue collection to generate dialogue configured to elicit entity information from the user. The dialogue questions identified may related to each entity a collection of entities and or may be created by concatenating several dialogue statements together using natural language generation. Dialogue Manager may produce an output question such as How many tickets would you like to purchase for this flight Display Manager may format the dialogue question together with any flight results already found by Services Manager and format the presentation of the output in an appropriate format. Ux Manager displays the flight results together with the output question How many tickets would you like to purchase for the flight . A user may respond to the questions by expressing a query such as two tickets two two please please give me two tickets and the like and or by inputting the number of tickets in another input mode such as via the touchscreen

In one embodiment Dialogue Manager is operable to generate compound entity eliciting questions. In the above example Dialogue Manager may generate a question such as Please tell me the luxury level and the number of tickets you would like In one embodiment Dialogue Manager may randomly select an appropriate entity eliciting question from a corpus of suitable questions i.e. questions designed to elicit one or more particular entities so that the interaction between a user and the Conversational Agent is unpredictable and refreshing to a user as different dialogue questions may be outputted to the user for a single entity.

Referring to a process and system are illustrated for extending the entities supported by a particular domain using minimal tagged data i.e. using a training data set of a relatively small size . A Base labeled CRF is trained using the training data in which entities are already tagged. When a user asks a query the NLP Engine communicates with the Base labeled CRF and requests the Base labeled CRF to extract any entities from the query. The Base labeled CRF extracts the entities embodied in the query and directs such entities to the NLP Engine 1 . The NLP Engine provides the extracted entities to the user by displaying or otherwise communicating the entities to the user 2 . The user proceeds with their interaction by accepting the entities provided at 2 or communicating that the entities are incorrect 3 and or not acceptable to the user s intention in asking the query.

The NLP Engine may interface with a second CRF Expanded CRF that is configured to provide additional entities that may better match the entities embodied with the query 4 . In various embodiments the Expanded CRF may be a CRF such as the Base labeled CRF together with one or more data sources of similar entities supported by the Base labeled CRF. For example the Expanded CRF may include one or more data sources having synonyms geographic data restaurant data contact information etc. that may be used in conjunction with the Base labeled CRF to extend the breadth of entities that are supported by the Base labeled CRF. The Expanded CRF returns an N best list of possible entities to the NLP Engine 5 which are then displayed or otherwise communicated to the user 6 . N is a whole number such as 5 that may be set by an administrator of the system and or the user. The user may choose one of the entities provided as best matching the user s intention or the user may reject all of the entities provided by the Expanded CRF.

Input pipeline output pipeline and Topic Board provide an architecture that allows a user of smartphone to engage in multiple conversations with the Conversational Agent simultaneously and across domains. For example a user can simultaneously carry on an interactive voice session with the Conversational Agent about diverse domains such as FLIGHTS WEATHER RESTAURANTS NEWS SOCIAL SEARCH KNOWLEDGE MOVIES STOCKS TIME AND ALARM CALENDAR etc. the given domains and domain tags i.e. SEARCH being purely exemplary.

By way of example a user may engage in the following conversation with the Conversational Agent by using application on his her smartphone 

In the above interaction the letter U denotes a user query and CA denotes a response generated by the Conversational Agent and presented on user interface by Ux Manager . The user queries above have initiated processing by the Conversational Agent in several domains for example TRAVEL SPORTS WEATHER and STOCKS.

With query How did the Leafs do last night NLP Engine creates a template object with the domain subgroup and entities and directs the template to the Services Manager . Services Manager then interfaces with an external sports service which returns the score of the game. Services Manager adds entry to Topic Board including the result from the external sports service and the memory associated with Services Manager is released. In one embodiment Services Manager creates a separate entry for each domain to accomplish the command desired by the user according to the derived intent. For example Services Manager may create a Sports Service that interfaces with external sports service to process sports related commands.

Dialogue Manager periodically scans Topic Board and identifies entry . Dialogue Manager removes entry and Display Manager formats the output for communication to smartphone . Ux Manager presents the results to the user with a response such as Toronto beat Buffalo 4 1 .

Referring next to the user has expressed two additional queries one relating to the weather in Singapore and the second relating to the user s stock portfolio. In each case NLP Engine has formulated templates and Services Manager has called an appropriate service . Given that the queries are not expressed exactly simultaneously but sequentially by the user the Conversational Agent may employ two separate Services Managers i.e. one for each query each of which is created by the Delegate Service when a new user query is received. The Services Managers add entries and indicated that the action is pending before the appropriate external services are called.

Dialogue Manager identifies the entries on Topic Board and this case decides not to present dialogue to the user interface on the smartphone .

In the Services Manager related to the flight to Singapore receives a response from the external flight service and Services Manager modifies entry on Topic Board by changing the status of entry from pending to complete . Dialogue Manager picks up the modified entry recognizes that the travel related action is complete and formats the result data with Display Manager . Dialogue Manager then removes entry from Topic Board . Ux Manager presents the flight results to the smartphone with a message such as I have your flight. Here are the details . . . and also presents a list of flights results. In this example the user may select and purchase a ticket and the confirmation information will also be presented to the user by the Ux Manager .

Referring to Topic Board shows that entries related to the weather in Singapore and related to the user s stock portfolio have been updated by changing the result from pending to complete and the results for each have been stored on Topic Board . As described herein one services manager performed a command via interface according to the user s weather query and another services manager performed a command via interface according to the user s stock query. Each of the Services Managers creates a respective entry in the Topic Board and includes the result provided by interfaces . Dialogue Manager which periodically scans Topic Board identifies entry and formats output to send to smartphone using Display Manager the output being presented on the device by Ux Manager . Dialogue Manager then removes entry from Topic Board . Continuing with its scanning of the Topic Board Dialogue Manager identifies entry and determines that its status is complete and that results are available in the Topic Board . Dialogue Manager may then remove entry from the Topic Board which now becomes clear of all entries and formats output to communicate to the smartphone using Display Manager . Ux Manager receives the formatted output and presents the result to the user on the user interface of App .

In one embodiment entries on Topic Board are given an initial priority level by NLP Engine and or Services Manager . A given entry in Topic Board may be reassigned a priority level by Dialogue Manager NLP Engine and or services manager as additional information is elicited from the user. For example a pending command may receive a priority level of 3 a command that cannot be performed without additional information may receive a priority of 1 and a command that can be performed i.e. there is sufficient entity information available however the user should be given a chance to add entities may receive a priority of 2.

Topic Board may set a priority for each query using a variety of techniques. In one embodiment Topic Board may establish a first in has highest priority rule in which each new query receives a highest priority rank as soon as it is passed to Topic Board by Delegate Service . Entries that are already in the Topic Board may all have their priority decreased using this technique. Topic Board may also use intelligent logic to determine the priority of each query. For example Topic Board may determine that the query What s the cheapest flight to Singapore leaving Friday coming back in two weeks is a high priority query because the query relates to finding a flight and possible booking tickets for a flight. A user may establish preferences using the Conversational Agent to set which types of queries will automatically have the highest priorities on the Topic Board .

When Dialogue Manager is asked for dialogue from the DelegateService Dialogue Manager takes the highest priority topic and generates dialogue from it. This topic may then be updated with a new priority and put back into the Topic Board . Many different services may put topics into the Topic Board directly or via another service such as Delegate Service .

Delegate Service may ask for dialogue from the Dialogue Manager periodically in response to returns from service calls and or at a predefined rate for example a certain number of times per second.

In one embodiment dialogue manager is configured to elicit entities that may be required for a pre determined template as required by a specific service . By way of example Services Manager may expect flight template to contain the following entities before template is provided to flight service TO DEPARTUREDAY RETURNDAY FROM LUXURY RETURNTIME DEPARTURETIME PRIVE SPECIFICGROUP CARRIER NUMBERATICKETS

In an embodiment the dialog manager may be operable to elicit the entity information required to call a service and or entity information may be intelligently filled in depending on user information user history GPS coordinates rules and the like.

For example in an embodiment the Conversational Agent may only require the TO entity i.e. the destination city to be obtained from the user via an input command such as a voice command. The Conversational Agent may then apply a variety of rules to determine the remaining entities that are required to call flight service API. In such an embodiment Conversational Agent may assume the following 

 FROM entity i.e. departure city is the city where the user is current located. This can be determined by obtaining the GPS coordinates of the smartphone 

 RETURNDAY entity is not applicable since the Conversational Agent may assume that the flight is one way.

A conversation thread may include an input pipeline and an output pipeline . A query on a client device is passed to the Delegate Service which is actually a web service. Delegate Service may direct query to NLP which determines a representation of user intent. NLP may communicate the represented user intent feature manager service. Topic Board and emotion board are data storage that may comprise any or all of Internal Processor registers and cache Main the system RAM and controller cards On line mass storage Secondary storage or Off line bulk storage Tertiary and Off line storage . A conversation thread may be created for every query expressed by the user that is processed by the delegate. Conversation thread is routed by delegate to the appropriate service to derive a representation of the user intent and to extract the features of the query. NLP Engine derives user intent and passes back to Delegate Service.

According to one embodiment the conversational agent of the invention may include and or interface with a dynamic domain knowledge set to intelligently converse with the user provide information and perform tasks requested by the user etc. The domain knowledge set may include one or more domain models that are associated with a specific domain. For example the domain TRAVEL may be associated with a travel model the domain SPORTS may be associated with a sports model etc. In one embodiment each domain model includes one or more statistical models such as but not limited to SVMs CRFs optimized feature sets na ve Bayes random forests neural networks etc. that are trained in advance by the Learning Manager as described below another component of the Conversational Agent and or are provided by another service. Each domain model may interface and or contain data from internal and or external knowledge sets such as gazetteers. The term Gazetteer in the context of this specification may refer to geographic directory as well as domain specific lists such as professional jargon for example Medical legal etc. regional and or cultural terms names of people song artist and album list movie titles famous personalities etc.

The domain knowledge set is dynamic in that new domain models may be added to the domain knowledge set in real time and existing domains models are constantly being updated with user queries common phrases sentences synonyms technical terms etc. to make the system more accurate. The domains models available to a particular user may be circumscribed depending on the user s account status preferences commonly accesses subject matter etc.

The domain manager may add new domains to the system of the invention without necessarily changing the underlying code and architecture of the conversational agent significantly and or at all. New domain models may be added to the conversational agent in a plug and play manner allowing a user to converse about a new topic related to the newly added domain models and obtain new functions related to the new domain models.

In one embodiment domain manager communicates with learning manager to ensure that new domain models are pretrained prior to the domain manager incorporating a new domain model into the functionality of the conversational agent . In one embodiment the dialogue manager may inform the user of new functionality by presenting and or voicing a new domain added message and display manager may also add examples of new example interactions that that the user may now engage in.

The Conversational Agent of the invention may provide an alarm and reminder service for a user of a smartphone . A user interacts with the alarm reminder service by entering input into the smartphone for example by expressing a user query using the touchscreen keyboard and the like and any combination thereof. For example a user may set an alarm by expressing a user query such as Set an alarm for 6 am tomorrow . As described above one or more microphones on the smartphone convert the sound waves of the expressed query into a digital audio format such as a pulse code modulation format PCM . A speech recognition engine receives the PCM audio file and may convert the audio file to text. The speech recognition engine may reside on the device and or in the cloud based infrastructure . The text string generated by the speech recognition module from the PCM audio file is the user query . The user query may be passed to the Delegate Service for processing which may direct the user query to the NLP Engine which is adapted to derive a representation of the desired user intent including identifying a domain and or subdomain at least one command and at least one parameter and or entity relating to the command.

In the example given above the NLP Engine determines that the user query relates to a command in the ALARM REMINDER domain. NLP Engine may further determine that the user query relates to a command such as set an alarm which may use parameters such as 6 a.m. and a date for example Apr. 8 2012 . NLP Engine may create an object such as template object that is then passed to the Services Manager for processing.

The Conversational Agent of the invention may provide a reminder service for a user of a smartphone . A user may express a user query such as Remind me to go to the gym at 3 pm to accomplish a desired command such as setting a reminder. The NLP Engine processes this user query and determines that it relates to a command such as set a reminder which may use parameters such as 3 p.m. as well as a string for example Go the gym . After determining the user intent NLP Engine may pass a template object with this information to the Services Manager for performing the reminder command. Alarms reminders timers and the like may use an internal service on smartphone which may be accessible an API . The internal service may then process the reminder and or alarm command according to the functionality of the particular service available on the smartphone

In one embodiment conversational agent may transfer control to the internal service called so that a result may be displayed to a user on the smartphone . In one embodiment conversational agent instructs service to perform a command however conversational agent displays a confirmation message that the command has been performed and or embeds the service into the user interface so that the service becomes an interactive control on the conversational agent .

In another embodiment the Conversational Agent may provide its own alarm reminder service to use in combination with and or in place of the internal alarm reminder service. The alarm reminder service may reside in cloud based infrastructure and or on a client device .

In one embodiment the Conversational Agent is configured to implement an event notification service for monitoring events including events generated by services that may be desirable to communicate to a user via the user interface . For example a user may set a reminder by conversationally interacting with the conversational agent such as Remind me at 6 pm to pick up groceries . In this example Conversational Agent calls an internal service and the internal service executes the desired command i.e. service sets the reminder and includes the reminder message . The internal service may process the reminder and notify the user at 6 pm. Event notification service may monitor smartphone events such as reminders that go off and process the reminder through the user interface to communicate the reminder to the user.

In one embodiment the Conversational Agent may provide an alarm reminder service that is able to provide functionality based on location and or another class of parameters. For example a user may express the user query remind to pick up milk when I am near a grocery store . Such a user query contains ambiguous terms such as near and undefined location such as a grocery store . The Conversational Agent of the invention is able to process and make semantic sense of such a query as well as provide useful functionality to the user according to the derived user intent. For example the NLP Engine may determine that the user query relates to the ALARM REMINDER domain and perhaps the set reminder subdomain. NLP Engine may further determine the a grocery store is a general class of locations the applicability of any given grocery store being undetermined. In addition NLP Engine may attach meaning to the word near such as within a 1 km radius or 100 m radius etc. The applicable radius for this user query may be based on a user preference intelligent information derived from user mobility patterns default settings and the like.

In this example after receiving template with a representation of the derived user intent Services Manager may build a list of all grocery stores within a certain distance from the user s current location as provided by GPS service . Services manager may periodically obtain the user s current GPS coordinates and compare the GPS coordinates to the location of grocery stores in the list. Once the user s position is within a predefined distance from any given grocery store the conversational agent may notify the user that he she is near a grocery store and may also provide directions to the grocery store.

In one embodiment the Conversational Agent optimizes its use of an internal GPS service because scanning the GPS coordinates of a device uses the smartphone s battery power. Calling a GPS service too often may result in the battery of the device draining faster than is acceptable to a user. In this embodiment Conversational Agent varies its rate of interfacing with GPS service depending on the distance between the smartphone and the grocery stores that are in the list of grocery stores previously created and or updated by the conversational agent . For further clarity say that the closest grocery store to the user s current location is located 15 kilometers away from the user s current location as provided by GPS service . Conversational Agent may determine that a user cannot get to the closest grocery store in less than fifteen minutes for example and therefore may not access GPS service for another fifteen minutes. After each call to the GPS service Conversational Agent may compute the length of time to wait before calling GPS service again based at least partly on the user s current location relative to the closest location in the list.

The Conversational Agent according to an embodiment of the invention may provide music functionality to a user of a smartphone . In an embodiment the music functionality includes playing a song by title artist album genre ratings playing albums by artist year genre rating length dynamically creating and playing playlists locating playing downloading etc. songs and albums from third party services and well as additional functionality.

A user may interface with the music service by expressing a query and or in combination with other modes of input such as the touchscreen.

For example a user may interact with their smartphone by voicing the query Play me some Madonna . The Delegate Service receives the query in a text string format and directs the query to NLP Engine for processing. By applying the query to one or more CRFs for example NLP Engine derives that the user intent relates to the domain MUSIC with a entity Madonna . NLP Engine may create and or fill a template with the information according to the derived user intent and pass the template to Services Manager . Services Manager receives the template and may apply logic to further fill the template entities. For example Services Manager may assume and or use logic to determine that the user wants to hear a song by Madonna an album by Madonna a playlist contain Madonna songs search the internet for Madonna music for download and or search and play internet radio playing Madonna music.

In an embodiment music service searches music data that the user already has access to on their device in cloud based service infrastructure and or available on third party web services of which the user may or may not have an account. Music service may find Madonna music data songs playlists albums etc. that the user has access to and begin playing Madonna music randomly and or based on previous listening habits of the user. For example music service may access the user s ratings of must and play Madonna music in order of highest rated to lowest rated. While music is playing a user may continue to interact with the Conversational Agent by expressing other queries .

To optimize the operation of the user interaction with the music service available via conversational agent music service may periodically search a user s device and or user accounts on the Internet to index songs playlists albums and the like. Music service may index such music data every time a user launches the Conversational Agent each time a user turns on their smartphone each time a user accesses the music service and or at regular intervals.

Music service may transfer some or all indexed music data to cloud based service infrastructure so that NLP Engine music service and other services can easily access and process music data as a user inputs further user queries .

According to one embodiment of the invention the Conversational Agent provides internet search functionality for a user of a smartphone . In one embodiment the user may express a query that relates to internet search knowledge search database searching such as library catalogues academic databases mathematical calculations and the like.

To obtain search results from the Conversational Agent a user inputs a command for example a voice command to the App of the Conversational Agent running on smartphone . For example a user may say the following to the Conversational Agent via the App running on the smartphone What are the tallest mountains in the World An automatic speech recognition service receives the voice file in an appropriate format for example PCM mp3 and the like and performs speech to text operations. The ASR engine may communicate the text user query to the NLP Engine via the Delegate Service in some embodiments do derive the intent of the user.

NLP Engine processes the user query to identify a domain subgroup subdomain desired command s to perform and any entities if applicable. In the current example NLP Engine may derive the intention of the user as relating to the SEARCH domain with the entity tallest mountains in the World as a search string. NLP Engine may further identify the query as relating to the subdomain geography. NLP Engine may formulate a template and or object containing the domain subdomain and entity for processing by the Services Manager . Services Manager receives the template from the NLP Engine the Delegate Service and or another module and performs logic to identify the appropriate service to call. In one embodiment Services Manager uses one service for queries relating to mathematical calculations mathematical and scientific facts and the like and another service for queries relating to general knowledge. In yet another embodiment Services Manager interfaces with one or many internet search engines to obtain a result for the query . In an embodiment the Conversational Agent may classify certain queries as relating to a SEARCH domain which may result in service calls to internet search engines and other queries as relating to a KNOWLEDGE domain which may results in service calls to knowledge databases such as TrueKnowledge Wolfram Alpha academic and professional databases and the like .

Continuing with the example Services Manager may determine that query What are the tallest mountains in the world is a science question which NLP Engine has identified as relating to subgroup geography and may therefore call an external API that relates to science and or geography and the external service may return a result. Services Manager takes the result which may be in an XML format JSON format and the like and may add it to the template as a result tag. The final template with all its content may be added to the Topic Board as a database record for example where it can be further processed by the Dialogue Manager and produced on the smartphone by the Ux Manager .

In one example NLP Engine looks for keywords such as search find and the like within the query to perform general internet searches with search engines such as Google Bing True Knowledge Yahoo and the like. For example a user may express the query Search the Internet for the best clubs in Toronto . NLP Engine receives the text version of the audio query and identifies that the user intends to perform an internet search with the string best clubs in Toronto . NLP Engine creates a template identifying the domain as relating to SEARCH with the string query best clubs in Toronto i.e. search entity and passes the template to the Services Manager . The Services Manager receives the template and may call a default search engine with the entity string a search engine generally preferred by the user a search engine that the user prefers for entertainment type queries etc. When services manager receives the result from search engine services manager may place the information from the template together with the result on topic board where there result and any associated dialogue and or display content such as images may be presented to the user on the app .

The Conversational Agent according to one embodiment of the invention may provide general chat capabilities so that a user of a smartphone may converse with the Conversational Agent on an informal basis similar to how a group of people may converse.

For example a user may input a voice command such as I m feeling pretty excited about the presentation today to the Conversational Agent . In this exemplary case the user may not intend for their smartphone to perform any action but instead the user may desire to engage in conversation with their device . The Conversational Agent may process this query in a manner similar to other domains. For example the above query is converted to text by the ASR engine and the text query may be directed to the NLP Engine for processing. NLP Engine derives the user intent of the query by at least partly employing the methods illustrated in relating to domain CHAT. Services Manager receives a template object created by the NLP Engine which may be stored in the Topic Board and applies logic to call an appropriate service . Services Manager may use an internal chat service external chat service s or a combination thereof. In one embodiment the Chat Service called by the Services Manager receives the text query and may perform one or several algorithms to identify candidate responses.

In one embodiment the Chat Service may include a comprehensive database of queries mapped to candidate responses. The queries may be organized by letter such that the Chat Service compares the query string to the database by letter I the first letter of I m feeling . . . and looks for the longest best match. Say for example that the longest best match found in the chat database is I m feeling pretty excited about the p the character indicating a wildcard. The Chat service may then look at the candidate responses for the match and select randomly if there are multiple candidate responses available. For example the Chat service may determine that three candidate responses are available for the query match I m feeling pretty excited about the p and output one of the three randomly for display on the user interface of the app running on smartphone . In another embodiment Chat service remembers the most recent output for a particular query so that a different response is generated the next time a user inputs the same or similar query . The response received from the Chat service may be added to the Topic Board for processing dialogue manager which may extract the result from the topic board and together with display manager format an output for display on the user interface of App .

In another embodiment the Chat Service of the Conversational Agent may include additional responses with the candidate response found in the chat database. For example the candidate response chosen by the Chat service for the above query may be That s great to hear . The Chat Service may also add information related to the holidays the user s personal schedule user interests such as sport television etc and other customized information. The Chat Service may add this information to the candidate response to generate a longer response such as That s great to hear by the way your favorite team also won the game last night . Another example related to holidays would be That s great to hear what a fine St. Patrick s day it is . Another example related to the user s schedule could be That s great to hear your afternoon is free by the way . The Chat service may append several different responses to the candidate response include more information within the candidate response and or precede the candidate response with a customized message.

In one embodiment the Chat service of the Conversational Agent employs natural language generation NLG to respond to chat inputs or inputs relating to other domains from the user. NLG is the natural language processing task of generating natural language from a machine representation system such as a knowledge base or a logical form.

In one embodiment the conversational chat dialogue may continue indefinitely. The Conversational Agent may interrupt the chat when appropriate to ask random questions not contained in the chat database and or to perform commands previously requested by the user. For example a user may have set an alarm for 5 p.m. which occurs within a chat session. The Chat service may generate the dialogue That s great to hear by the way you asked me to reminder you at 5 p.m. to pick up milk after work .

According to one embodiment the Conversational Agent of the invention may provide a Transit Service so that a user of a smartphone may access transit information in real time. Information that a user may access via the Conversational Agent includes bus streetcar and subway routes nearest transit stops transit options from point A to point B next arrival times and the like.

Example queries that a user may input include What s the nearest transit stop how do I get from downtown to the Roxbury neighborhood How do I get to Fenway via transit When is the next bus coming and the like.

The Conversational Agent of the invention may maintain a database of transit information from transit authorities. The database may be updated by the learning update manager as described herein. In one embodiment the database is populated by a comma delimited file from each transit authority. The files may be organized according to the General Transit Feed Specification GTFS .

An example transit interaction is as follows. A user expresses the voice query What s the nearest station that will take me to Fenway Park . The Conversational Agent receives the query performs speech to text operation and routes the query string to the NLP Engine . NLP Engine processes the query and derives a representation of the user intent. In this case NLP Engine may recognize that the user query relates to the domain TRANSIT and perhaps subgroup stops and subgroup directions . NLP Engine populates a template object with the derived entities for example current location destination which may also include the current GPS coordinates of the smartphone . Services Manager receives the template object and applies logic to determine the appropriate service to call in this case Services Manager may call an internal or external Transit Service . The Transit Service may provide a result to the Services Manager which then adds the information extracted from NLP engine and the result to the Topic Board for presentation on the smartphone by the Ux Manager .

According to one embodiment the Conversational Agent may provide a social networking and social sharing service so that a user of a smartphone may access social media sites personal relationships and share information and search results with friends and contacts in real time.

At certain time while interacting with the Conversational Agent a user may choose to share relevant results with a contact by expressing an appropriate query for example Share this result with Peter or may add a result to a social media website by saying something like Add this to Facebook . Facebook is a trademark of Facebook Inc. NLP Engine receives the user query from the Delegate Service and processes the query as described above. NLP Engine derives the intention of the user as relating to social media and creates a representation of the user intent in the form of a template object . NLP Engine may identify the user query as being related to the domain SOCIAL and perhaps a subgroup such as share and contact such as Peter .

NLP Engine may communicate the template to Services Manager which identifies an appropriate service to accomplish the intention of the user. In an embodiment Services Manager may interface with one or several external services that may accomplish a variety of social media commands such as for example update status on various social media websites write on own wall or contact s wall upload pictures including profile pictures share with contacts via email or instant messaging make new connections with contacts tag photos interact with social media applications such as Places I ve visited and the like.

Services Manager may employ internal logic to determine which service is appropriate for a given user intent and calls the service with the appropriate data including entities . Service provides a result to Services Manager which directs the output to Display Manager which creates a presentation layer for display on the user interlace of smartphone .

In an example interaction a user may receive a call from a person for example named Peter Smith regarding a potential business relationship. The user finishes the call and hangs up. If the Conversational Agent is not already running the user may launch the Conversational Agent on the smartphone . Once the Conversational Agent is running the user may simply express a query such as Add Peter to my LinkedIn account . The Conversational Agent may recognize that the user is referring to the most recent caller however if there are already contacts with the name Peter in the address book the Conversational Agent may ask a clarification question to the user with or without a list of options.

Continuing with the example the Conversational Agent may respond to the user Would you like to add Peter Lee Peter Hall or Peter Smith to your LinkedIn account A none of the above option may also be presented. This response may be presented as an organized list in an example so that the user may simply select the option that applies to their intent. The user may also select the option by voicing an audio input such as Peter Smith Smith the last guy and or the like.

Once a selection is made NLP Engine may add information to template such as the name of the contact that the user would like to connect with on LinkedIn. NLP Engine may not have to reprocess the user query to derive an intention of the user if the user s response was an answer to the clarification question.

Referring to the processing of clarification questions with respect to an intention of the user related to social media is shown. The general logic of may also be employed with other domains as well. Referring to step NLP Engine has identified potential ambiguity in the user query . NLP Engine may have identified the user intent as relating to SOCIAL and the subgroup ADD FRIEND. NLP Engine may also have identified the SOCIAL SITE as being LinkedIn and the CONTACT as having a first name of Peter . NLP Engine may create a template object with the identified entities and may direct the template object to Services Manager for processing. Services Manager receives template object and determines that a clarification question should be presented to resolve the ambiguity. At step a clarification question is presented to the user which may include an ordered list of possible responses. At step the user input is received which may be in the form of a selection from the ordered list and or a voice input from the user. At step the Conversational Agent determines whether the user input was responsive to the clarification question posed. If the input from the user was responsive then NLP Engine or template service further fills out the template object . Several methods may be used to determine if the user input was responsive to the clarification question. For example the Conversational Agent may look for keywords such as first last second last etc. in the user s response. Such logic would catch a scenario where the user expressed something like the last option . Continuing the example of adding a new contact to LinkedIn the Conversational Agent may look for a response that included a person s name such as Lee Hall or Smith . It will be appreciate that the logic employed to determine if the user s input was responsive to a clarification question may be unique for each domain. Once the template object has a minimum amount of information required to call a particular service.

In one embodiment Conversational Agent allows a user of a smartphone to get social media updates by interacting with the Conversational Agent . In an example interaction a user may express a query along the lines of Give me a Facebook update . NLP Engine may identify the intention of the user as relating to a command that reads the update section of user s profile page. Conversational agent may associate certain queries or words in a query with a desired command and store this association in a user preferences database. For example the conversational agent may intelligently determine that the user prefers to get updates for a few close friends instead of all contacts on a social media site.

In one embodiment the user of a smartphone may quickly share results such as webpages media photos and the like to friends by dragging the results obtained by services and displayed on the user interface to a predetermined share area of the touchscreen. This feature is described in more detail with respect to .

The Conversational Agent of the invention according to one embodiment may provide restaurant functionality so that a user of a smartphone may locate restaurants by location price cuisine atmosphere handicap accessibility size of a dinner party and other search criteria. A user may also book a restaurant using the Conversational Agent which in some cases necessitates entering financial information such as a credit card number.

In an example interaction a user may look for a restaurant by expressing a query such as Find me a Mexican restaurant in Chicago. As described herein user query is processed by NLP Engine to derive the intention of the user. In this example NLP Engine may identify that the user query relates to the domain of RESTAURANT and a subgroup of find restaurants the domain and subgroup tags being purely exemplary. NLP Engine may further identify the entities Mexican and Chicago which are relevant to the derived intention of the user.

NLP Engine may create a template with the relevant information i.e. domain subgroup and entities for processing by services manager . Services Manager may have a variety of external services which are available to perform various commands related to restaurants. Services Manager selects an appropriate service perhaps by accessing user preferred restaurant providers and calls the external restaurant service . External service returns a result which is then formatted by Display Manager and rendered to the device screen by Ux Manager .

In an embodiment Conversational Agent is able to book a restaurant by accessing financial payment information associated with a user. Continuing the above example interaction Conversational Agent provides a list of restaurants servicing Mexican food in Chicago. A list of restaurants that satisfy the user query is presented on the user interface of the smartphone . User interface may include an interactive application showing the restaurant results within the application of Conversational Agent . Interactive results application within app may allow a variety of user interaction including for example linking to a restaurant website reviewing restaurant rankings map restaurant booking a restaurant etc.

Continuing with the example say that on the results screen the user clicks via touchscreen on a book link and or voices a command with an intention of booking a particular restaurant. Ux Manager receives the input and in the case of a voice input may direct the user query to NLP Engine . NLP engine then derives the intention of the user as relating to booking a particular restaurant. In the case of clicking on a book link the Ux Manager is already aware that the likely intention of the user is to book a particular restaurant.

The Conversational Agent according to one embodiment of the invention may provide a calendar service so that a user of a smartphone may add find edit and delete meetings events and the like. A user may access their calendar using the Conversational Agent by expressing a relevant query such as Show me my calendar for today . NLP Engine of Conversational Agent identifies the intention of the user as relating to the CALENDAR domain and perhaps the subgroup show calendar and a identifies a relevant entity such as today . In this example interaction NLP Engine communicates a template with the relevant domain subgroup and entity information to the Services Manager to accomplish the identified intention of the user.

Services Manager may interface with one or more services to accomplish the user s intention. In this example Services Manager may identify an internal calendar service as a suitable service and will call the calendar service according to a predetermined interface. Ux Manager may display the results from calendar service as an interactive application within the application of Conversational Agent . Application may allow user interaction commonly found in calendar applications such as adding modifying and deleting meetings viewing holidays viewing the user s calendar by month week year and other common functions.

In an embodiment Ux Manager may also present the calendar results with audio output. In the above example Ux Manager may read out the calendar events that the user has booked for the day. In one embodiment the Ux Manager may read out a confirmation message such as your meeting has been booked for 10 am . If a scheduling conflict occurs Conversational Agent may read a message such as You are already busy at 10 am would you like to book the meeting for another time . Conversational Agent may have access to a dialogue database as described herein and the Dialogue Manager is configured to select an appropriate dialogue to present to the user depending on the state of the command intended by the user. For example Dialogue Manager may access different dialogue messages that are associated with certain command states such as pending results available confirmation that command has been performed clarification necessary scheduling conflict found etc.

In another example interaction a user may create a new calendar event using the Conversational Agent by expressing a suitable query such as Book me a meeting for Friday at 10 am for the Matrix Boardroom include Peter and James . NLP Engine processes the user query as described herein and identifies the user s intention as relating to the CALENDAR domain the add meeting subgroup and possibly identifies the entities of Friday 10 am Matrix Boardroom as well as contacts Peter and James . Using Template Tagger NLP Engine creates and populates a template which may be directed to Services Manager . Services Manager processes the intended command according to the flowchart shown in . As shown in at Services Manager may determine if the event requested by the user to be scheduled conflicts with any of the requested participant s schedule. If the requested event has no other invitees or all the invitees are free at the requested time then the services manager schedules the event using internal calendar service or external service and informs the user via the app . If however one of the requested invitees is not available at the requested time then at step the services manager informs the user of the conflict and gives the user an opportunity to pick another time. The user may pick another time at which point services manager begins processing at step or the user may keep the original time despite the conflict and services manager may go ahead and book the event as requested.

In one embodiment the Conversational Agent is configured to add events to a user s calendar automatically i.e. even if the user does not explicitly ask the Conversational Agent to add an event to his her calendar . For example a user may book a flight as described herein by expressing a query related to booking flights. Service manager processes the request and may determine that the command i.e. book a flight has blocked off a period of the user s calendar. Services manager may then add an event corresponding to the flight booking to the calendar with the relevant time of the event. In one embodiment services manager adds an alarm to remind the user of certain events in advance of the event occurring. In one embodiment Services manager may keep a list of commands that correspond to calendar events i.e. commands that are to be added to a user s calendar as well as predefined alarm settings such as the length of time before an event starting that a user should be reminded about the event. In the flight example services manager may add the booked flight to the user s calendar as well as an alarm set for the day before 3 hours before 1 hour before and 30 minutes before the scheduled flight. These alarm settings may be predefined and may also be modified by a user for a particular event i.e. a particular flight or a for a class of events i.e. all flights .

Reference is made to to illustrate the e commerce functionality of the Conversational Agent according to one embodiment. Conversational Agent may interface via the Services Manager with one or more internal payment systems and or external payment systems . Access to external payment system may be provided by an application programming interface and likewise internal payment wallet may be accessed via an API not shown . In one embodiment Services Manager is notified of a user s desire to make an electronic purchase via NLP Engine Ux Manager and or other components of Conversational Agent . Services Manager may maintain a list of payment systems that are acceptable to a particular external service . When a user accesses an external service such as a travel booking service and expresses or chooses via touchscreen an intention to book a flight Services Manager references the payment systems acceptable to the particular travel booking service and the payment systems preferred by the user.

If a user has access to a payment system that is acceptable to the external service Services Manager will coordinate the payment via payment system . In another embodiment if the user does not have access to a payment system required by the external service Conversational Agent may provide an interface and or instructions so that a user can sign up for the payment system.

In another embodiment Conversational Agent may interface with one or more internal payment systems also referred to as wallet applications that are available on smartphone . Internal wallet applications may comprise a pre loaded debit and or credit card and or may interface directly with the user s bank accounts at a financial institutions.

Reference is next made to to describe an embodiment of the speech service in accordance with one embodiment of the Conversational Agent of the invention. Speech service may be cloud based so that speech language processing is performed by computing resources in the cloud and therefore offloaded from smartphone . Such an architecture allows the offloading of speech processing from smartphones so smartphone processor resources may be applied to providing other functionality to the users. In one embodiment smartphones include a speech processing engine partly or entirely resident on smartphones

In one embodiment speech service may include general language models and user specific language models . General language models may be applicable to all users of the Conversational Agent and each language model may correspond to domain specific language. For example language model may contain common terms and phrases relating to the TRAVEL domain language model may contain common terms and phrases related to the RESTAURANT domain and language model C may contain common terms and phrases related to the SOCIAL MEDIA domain. Learning manager described further below may add modify substitute delete etc. language models as appropriate to increase the accuracy of speech service and or to add new domain functionality to the Conversational Agent .

In one embodiment Conversational Agent maintains user specific language models . User specific language models may contain user specific information from smartphones such as but not limited to address book contacts aliases commonly used words and phrases uttered by a particular user and the like. In one embodiment App is adapted to periodically upload information from smartphone to cloud based service infrastructure to create user specific language model . As will be described further learning manager may be employed to create language models dynamically as they are uploaded to the cloud by App .

The Conversational Agent may include a Learning Manager for updating training and or reinstating any of the modules used by the Conversational Agent . Modules that may be modified by the Learning Manager include support vector machines conditional random fields na ve Bayesian classifiers random forest classifiers neural networks previous query score classifiers and the like.

Learning Manager may update some or all of the intelligent modules of the invention periodically according to a set schedule and or when initiated by an administrator. The Conversational Agent may gather feedback from users based on their interaction with the Conversational Agent for training purposes. Examples of how the Conversational Agent uses feedback from user interaction are shown in . For example the Conversational Agent may determine whether each outputted response was useful to the user. In one embodiment the Learning Manager of Conversational Agent classifies each response as either correct incorrect and or neutral . Learning manager may also assign a weight to each of the above categories such that a response is determined to be a certain percentage correct or incorrect . In an example interaction the user may express a query of Find me some French cuisine in St. Louis . ASR service processes the voice query and provides a text representation of the query to NLP Engine . NLP Engine provides a template object to Services Manager the template object including the DOMAIN in this example RESTAURANTS and several entities St. Louis and French . Services Manager determines an appropriate service to perform the derived intention of the user calls that service external service in this example . External service provides a response to Services Manager which is presented to the user by the Ux Manager .

Continuing with the example say that NLP Engine misinterprets the user query and instead of identifying French restaurants in St. Louis instead identifies the user intention as relating to kitchen supplies in St. Louis . A user may react to this incorrect interpretation in a number of ways. A user may say for example No actually I would like French restaurants in St. Louis or What I really want is restaurants serving French food in St. Louis etc. The Conversational Agent may be configured to identify certain words phrases intonations etc. in the user s response to a given output to classify the response as correct incorrect and or neutral and to possible assign a weighing in relation thereto. Continuing with the example the Conversational Agent may realize with the user s response No actually I would like . . . as feedback that the output from speech service of kitchen supplies in St. Louis was incorrect according to the user s intention. Learning manager may store this information in a database for retraining purposes. The database may include for example the user query the output generated by speech service and or a classification of the correctness of the output as well as perhaps additional information. It will be appreciated that information about the correctness of the Conversational Agent s response may be collected and stored for a significant percentage of responses for each particular user. Therefore over a period of time Learning Manager will collect store and may use a large corpus of correctness data gathered in real time for real interaction that may be used to train any or all of the intelligent modules of the invention.

In another example let s say that NLP Engine determines that the user intention relates to French restaurants in St. Louis Mich. however the user was looking for French restaurants in St. Louis Mo.

The user may respond in any number of ways for example by saying Actually I m talking about St. Louis Mo. . The Learning Manager may determine that NLP Engine incorrectly derived the intention of the user however Learning Manager may instead determine that the correction initiated by the user relates to a user preference. Learning Manager may store the user preference in a user preferences database so that Conversational Agent in future interactions will add location specific information to some queries in particular to queries relating to locations.

The Conversational Agent of the invention may include an Authentication Manager as shown in . Authentication Manager may provide functionality for authenticating users and devices as well as providing backup services when existing users switch over to new devices and or if their smartphone becomes damaged.

The authentication of users may be accomplished by having a user input one or more of the following userid password keyword phrases and the like. Authentication Manager receives the authentication information provided by the user and compares the received input to the authentication information for the particular user in user database. Authentication information received from the user and data in the user database may be encrypted.

In an embodiment authentication of a user is tied to a particular smartphone so that any user of a particular smartphone may have access to some or all features of the Conversational Agent . In one embodiment authentication of a user may be accomplished entirely or in part by voice recognition. The Conversational Agent may store a representative voice pattern of each user on the smartphone and or on cloudfront server . When a particular user wants to use the Conversational Agent the user is prompted to say a particular name and or predefined phrase. Conversational Agent receives the phrase expressed by the user from the smartphone microphone s and compares the received voice pattern to voice patterns stored in user database. If there is a match between the received voice pattern and user voice patterns stored in user database Conversational Agent may welcome the user and provide the user with functionality provided via App .

In one embodiment the functionality available to a particular user may be limited depending on the subscription purchased by the user via carrier for example the type of smartphone and or other factors. For example a user may buy smartphone version 1 which includes access to Conversational Agent with limited functionality. Say for example that the user uses the Conversational Agent for 2 years. In that time Conversational Agent will intelligently gather and store a variety of information that is used to provide an efficient user experience. Each time that a user accesses Conversational Agent authentication manager may authenticate the user and determine the set of functionality available to the user. Authentication manager may communicate with user experience manager and user experience manager controls the functionality which is available to the user. The user may upgrade to smartphone version 2 at which time authentication manager changes the user s status to include more functionality and communicates to Ux Manager to make additional functionality available to the user.

In one embodiment authentication manager may backup device data and user data to cloudfront server or may interface with backup manager which is configured to backup sensitive device data and cloud based data. Backups may be performed periodically and or when a user initiates a backup. The backups ensure that a user does not lose information that is used and or generated by the Conversational Agent should the smartphone become damaged. In an embodiment authentication manager backups information such as user preferences address books calendar songs movies images files user defined aliases for contacts and files and learned information such as speaking style accents etc.

When a user switches smartphone authentication manager receives user authentication information as described above such as a password userid telephone number inputted voice phrase etc. and determines whether the user has access to the Conversational Agent and the status of the user s account. For example authentication manager may authenticate the user of a new smartphone based on the fact that the new smartphone has the same phone number as the old smartphone . Authentication manager may communicate with Ux Manager to make certain functionality available to the user. Authentication manager may also ask the user via a prompt and or a voice output whether the user wishes the Conversational Agent to download certain data onto the new smartphone . The data may substantially correspond to the user data that resided on smartphone . In this way Conversational Agent allows a user to seamlessly switch between smartphones at any time without losing any data that is gathered by and or used by Conversational Agent .

User Experience Manager is for managing the interaction layer of the Conversational Agent for example by providing a user interface on the display of the smartphone via App . User Experience Manager may provide a multi modal input output environment so that the Conversational Agent may communicate and provide output to a user with one or more output modes for example by sound video images text vibration and the like. Likewise the user may interact with the Conversational Agent by providing input in one or more supported modes.

User Experience Manager provides a user interface for visually as well as perhaps using other modes presenting responses to queries including for example formatted output from services and clarification questions.

Example user interfaces are illustrated in . shows a user interface on smartphone . The user interface shows an example dialogue interaction between a user and the App of Conversational Agent . Dialogue bubble shows the user query expressed by the user for example show me some Mexican restaurants in Portland . Dialogue bubble shows a response generated by Dialogue Manager for example Okay give me a moment to find what you asked for . . . Result window shows the results of the Conversational Agent s search the results having been found by Services Manager interfacing with an external service in an embodiment.

Buttons and in the example user interface may provide quick access to common features of the Conversational Agent . For example button may provide Bookmark functionality button may provide Share functionality i.e. social media button may provide Email sms phone functionality and button may provide Map functionality. The number of buttons and the assigned functionality may be changed by a user and or dynamically changed by the Conversational Agent depending on several factors such as the capabilities of the smartphone the domain to which the user query relates etc.

A user may access the functionality of buttons by dragging an entry from the result screen to the button desired and or by pressing the area of touchscreen corresponding with buttons . Example arrow illustrates the general interaction. For example a user may desire to Email and or SMS a particular restaurant to a friend. A may drag the entry to button which may launch another screen or a window that appears from the side of the display that asks the user to confirm the desire to email and or sms a restaurant listing to a contact.

While the invention has been described with respect to a limited number of embodiments those skilled in the art having benefit of the above description will appreciate that other embodiments may be devised which do not depart from the scope of the present invention as described herein. In addition it should be noted that the language used in the specification has been principally selected for readability and instructional purposes and may not have been selected to delineate or circumscribe the inventive subject matter. Accordingly the disclosure of the present invention is intended to be illustrative but not limiting of the scope of the invention which is set forth in the claims.

