---

title: System and method for managing energy
abstract: A method of managing energy consumption in an enclosed spaced includes the step of providing temperature and foot traffic data to a plan generator. The method further includes the steps of generating an energy plan based on the temperature and foot traffic data and controlling one or more energy consuming devices based on the energy plan.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09217994&OS=09217994&RS=09217994
owner: SHOPPERTRAK RCT CORPORATION
number: 09217994
owner_city: Chicago
owner_country: US
publication_date: 20130110
---
This application claims the benefit of U.S. Provisional Patent Application No. 61 586 543 filed on Jan. 13 2012 which is incorporated herein in its entirety.

The present invention generally relates to the field of object detection tracking and counting. In specific the present invention is a computer implemented detection and tracking system and process for detecting and tracking human objects of interest that appear in camera images taken for example at an entrance or entrances to a facility as well as counting the number of human objects of interest entering or exiting the facility for a given time period.

Traditionally various methods for detecting and counting the passing of an object have been proposed. U.S. Pat. No. 7 161 482 describes an integrated electronic article surveillance EAS and people counting system. The EAS component establishes an interrogatory zone by an antenna positioned adjacent to the interrogation zone at an exit point of a protected area. The people counting component includes one people detection device to detect the passage of people through an associated passageway and provide a people detection signal and another people detection device placed at a predefined distance from the first device and configured to detect another people detection signal. The two signals are then processed into an output representative of a direction of travel in response to the signals.

Basically there are two classes of systems employing video images for locating and tracking human objects of interest. One class uses monocular video streams or image sequences to extract recognize and track objects of interest. The other class makes use of two or more video sensors to derive range or height maps from multiple intensity images and uses the range or height maps as a major data source.

In monocular systems objects of interest are detected and tracked by applying background differencing or by adaptive template matching or by contour tracking. The major problem with approaches using background differencing is the presence of background clutters which negatively affect robustness and reliability of the system performance. Another problem is that the background updating rate is hard to adjust in real applications. The problems with approaches using adaptive template matching are 

1 object detections tend to drift from true locations of the objects or get fixed to strong features in the background and

2 the detections are prone to occlusion. Approaches using the contour tracking suffer from difficulty in overcoming degradation by intensity gradients in the background near contours of the objects. In addition all the previously mentioned methods are susceptible to changes in lighting conditions shadows and sunlight.

In stereo or multi sensor systems intensity images taken by sensors are converted to range or height maps and the conversion is not affected by adverse factors such as lighting condition changes strong shadow or sunlight.

Therefore performances of stereo systems are still very robust and reliable in the presence of adverse factors such as hostile lighting conditions. In addition it is easier to use range or height information for segmenting detecting and tracking objects than to use intensity information.

Most state of the art stereo systems use range background differencing to detect objects of interest. Range background differencing suffers from the same problems such as background clutter as the monocular background differencing approaches and presents difficulty in differentiating between multiple closely positioned objects.

U.S. Pat. No. 6 771 818 describes a system and process of identifying and locating people and objects of interest in a scene by selectively clustering blobs to generate candidate blob clusters within the scene and comparing the blob clusters to a model representing the people or objects of interest. The comparison of candidate blob clusters to the model identifies the blob clusters that is the closest match or matches to the model. Sequential live depth images may be captured and analyzed in real time to provide for continuous identification and location of people or objects as a function of time.

U.S. Pat. Nos. 6 952 496 and 7 092 566 are directed to a system and process employing color images color histograms techniques for compensating variations and a sum of match qualities approach to best identify each of a group of people and objects in the image of a scene. An image is segmented to extract regions which likely correspond to people and objects of interest and a histogram is computed for each of the extracted regions. The histogram is compared with pre computed model histograms and is designated as corresponding to a person or object if the degree of similarity exceeds a prescribed threshold. The designated histogram can also be stored as an additional model histogram.

U.S. Pat. No. 7 176 441 describes a counting system for counting the number of persons passing a monitor line set in the width direction of a path. A laser is installed for irradiating the monitor line with a slit ray and an image capturing device is deployed for photographing an area including the monitor line. The number of passing persons is counted on the basis of one dimensional data generated from an image obtained from the photographing when the slit ray is interrupted on the monitor line when a person passes the monitor line.

Despite all the prior art in this field no invention has developed a technology that enables unobtrusive detection and tracking of moving human objects requiring low budget and maintenance while providing precise traffic counting results with the ability to distinguish between incoming and outgoing traffic moving and static objects and between objects of different heights. Thus it is a primary objective of this invention to provide an unobtrusive traffic detection tracking and counting system that involves low cost easy and low maintenance high speed processing and capable of providing time stamped results that can be further analyzed.

In addition people counting systems typically create anonymous traffic counts. In retail traffic monitoring however this may be insufficient. For example some situations may require store employees to accompany customers through access points that are being monitored by an object tracking and counting system such as fitting rooms. In these circumstances existing systems are unable to separately track and count employees and customers. The present invention would solve this deficiency.

In an illustrative embodiment a method of managing energy consumption in an enclosed spaced includes the step of providing temperature and foot traffic data to a plan generator. The method further includes the steps of generating an energy plan based on the temperature and foot traffic data and controlling one or more energy consuming devices based on the energy plan.

In a further illustrative embodiment a method of managing energy utilized in an enclosed space includes the steps of providing forecast and real time temperature data to a plan generator and providing forecast and real time foot traffic data to the plan generator. The method further includes the steps of generating an energy plan based on the forecast and real time temperature and foot traffic data and transmitting the energy plan to the control device. Still further the method includes the step of controlling the air temperature and air flow of one or more heating cooling and air conditioning units based on the energy plan.

In another illustrative embodiment an energy management system includes a plan generator that receives forecast and real time temperature data and forecast and real time foot traffic data and generates an energy plan based on the forecast and real time temperature or foot traffic data. The energy management system further includes at least one energy consuming device and a control device that operates the at least one energy consuming device based on the energy plan.

In accordance with these and other objectives that will become apparent hereafter the present invention will be described with particular references to the accompanying drawings.

This detailed description is presented in terms of programs data structures or procedures executed on a computer or a network of computers. The software programs implemented by the system may be written in languages such as JAVA C C C Assembly language Python PHP or HTML. However one of skill in the art will appreciate that other languages may be used instead or in combination with the foregoing.

Referring to and the present invention is a system comprising at least one image capturing device electronically or wirelessly connected to a counting system . In the illustrated embodiment the at least one image capturing device is mounted above an entrance or entrances to a facility for capturing images from the entrance or entrances . Facilities such as malls or stores with wide entrances often require more than one image capturing device to completely cover the entrances. The area captured by the image capturing device is field of view . Each image along with the time when the image is captured is a frame .

Typically the image capturing device includes at least one stereo camera with two or more video sensors which allows the camera to simulate human binocular vision. A pair of stereo images comprises frames taken by each video sensor of the camera. A height map is then constructed from the pair of stereo images through computations involving finding corresponding pixels in rectified frames of the stereo image pair.

Door zone is an area in the height map marking the start position of an incoming track and end position of an outgoing track. Interior zone is an area marking the end position of the incoming track and the start position of the outgoing track. Dead zone is an area in the field of view that is not processed by the counting system .

Video sensors receive photons through lenses and photons cause electrons in the image capturing device to react and form light images. The image capturing device then converts the light images to digital signals through which the device obtains digital raw frames comprising pixels. A pixel is a single point in a raw frame . The raw frame generally comprises several hundred thousands or millions of pixels arranged in rows and columns.

Examples of video sensors used in the present invention include CMOS Complementary Metal Oxide Semiconductor sensors and or CCD Charge Coupled Device sensors. However the types of video sensors should not be considered limiting and any video sensor compatible with the present system may be adopted.

The counting system comprises three main components 1 boot loader 2 system management and communication component and 3 counting component .

The boot loader is executed when the system is powered up and loads the main application program into memory for execution.

The system management and communication component includes task schedulers database interface recording functions and TCP IP or PPP communication protocols. The database interface includes modules for pushing and storing data generated from the counting component to a database at a remote site. The recording functions provide operations such as writing user defined events to a database sending emails and video recording.

The counting component is a key component of the system and is described in further detail as follows.

In an illustrated embodiment of the present invention at least one image capturing device and the counting system are integrated in a single image capturing and processing device. The single image capturing and processing device can be installed anywhere above the entrance or entrances to the facility . Data output from the single image capturing and processing device can be transmitted through the system management and communication component to the database for storage and further analysis.

Referring to in block the image capturing device obtains raw image frames at a given rate such as for every 1 As second of the field of view from the video sensors . Each pixel in the raw frame records color and light intensity of a position in the field of view . When the image capturing device takes a snapshot each video sensor of the device produces a different raw frame simultaneously. One or more pairs of raw frames taken simultaneously are then used to generate the height maps for the field of view as will be described.

When multiple image capturing devices are used tracks generated by each image capturing device are merged before proceeding to block .

Block uses calibration data of the stereo cameras not shown stored in the image capturing device to rectify raw stereo frames . The rectification operation corrects lens distortion effects on the raw frames . The calibration data include each sensor s optical center lens distortion information focal lengths and the relative pose of one sensor with respect to the other. After the rectification straight lines in the real world that have been distorted to curved lines in the raw stereo frames are corrected and restored to straight lines. The resulting frames from rectification are called rectified frames .

Block creates a disparity map from each pair of rectified frames . A disparity map is an image map where each pixel comprises a disparity value. The term disparity was originally used to describe a 2 D vector between positions of corresponding features seen by the left and right eyes. Rectified frames in a pair are compared to each other for matching features. The disparity is computed as the difference between positions of the same feature in frame and frame .

Block converts the disparity map to the height map . Each pixel of the height map comprises a height value and x y coordinates where the height value is represented by the greatest ground height of all the points in the same location in the field of view . The height map is sometimes referred to as a frame in the rest of the description.

Object detection block is a process of locating candidate objects in the height map . One objective of the present invention is to detect human objects standing or walking in relatively flat areas. Because human objects of interest are much higher than the ground local maxima of the height map often represent heads of human objects or occasionally raised hands or other objects carried on the shoulders of human objects walking in counting zone . Therefore local maxima of the height map are identified as positions of potential human object detects. Each potential human object detect is represented in the height map by a local maximum with a height greater than a predefined threshold and all distances from other local maxima above a predefined range.

Occasionally some human objects of interest do not appear as local maxima for reasons such as that the height map is affected by false detection due to snow blindness effect in the process of generating the disparity map or that human objects of interests are standing close to taller objects such as walls or doors. To overcome this problem the current invention searches in the neighborhood of the most recent local maxima for a suboptimal location as candidate positions for human objects of interest as will be described later.

A run is a contiguous set of pixels on the same row of the height map with the same non zero height values. Each run is represented by a four tuple row start column end column height . In practice height map is often represented by a set of runs in order to boost processing performance and object detection is also performed on the runs instead of the pixels.

Object detection comprises four stages 1 background reconstruction 2 first pass component detection 3 second pass object detection and 4 merging of closely located detects.

Pixel q is an eight neighbor of pixel p if q and p share an edge or a vertex in the height map and both p and q have non zero height values. A pixel can have as many as eight neighbors.

A set of pixels E is an eight connected component if for every pair of pixels Pi and Pi in E there exists a sequence of pixels Pi . . . Pi such that all pixels in the sequence belong to the set E and every pair of two adjacent pixels are eight neighbors to each other. Without further noting an eight connected component is simply referred to as a connected component hereafter.

The connected component is a data structure representing a set of eight connected pixels in the height map . A connected component may represent one or more human objects of interest. Properties of a connected component include height position size etc. Table 1 provides a list of properties associated with a connected component. Each property has an abbreviated name enclosed in a pair of parentheses and a description. Properties will be referenced by their abbreviated names hereafter.

Several predicate operators are applied to a subset of properties of the connected component to check if the subset of properties satisfies a certain condition. Component predicate operators include 

IsNoisy which checks whether a connected component is too small to be considered a valid object detect . A connected component is considered as noise if at least two of the following three conditions hold 1 its det minSize is less than two thirds of a specified minimum human body size which is configurable in the range of 9 36 inches 2 its det area is less than four ninths of the area of a circle with its diameter equal to a specified minimum body size and 3 the product of its det minSize and det area is less than product of the specified minimum human body size and a specified minimum body area.

IsPointAtBoundaries which checks whether a square window centered at the current point with its side equal to a specified local maximum search window size is intersecting boundaries of the height map or whether the connected component has more than a specific number of pixels in the dead zone . If this operation returns true the point being checked is considered as within the boundaries of the height map .

NotSmallSubComponent which checks if a subcomponent in the second pass component detection is not small. It returns true if its detrninxize is greater than a specified minimum human head size or its det area is greater than a specified minimum human head area.

BigSubComponentSeed which checks if a subcomponent seed in the second pass component detection is big enough to stop the grouping operation. It returns true if its detrninxize is greater than the specified maximum human head size or its det area is greater than the specified maximum human head area.

SmallSubComponent which checks if a subcomponent in the second pass component detection is small. It returns true if its detrninxize is less than the specified minimum human head size or its der area is less than the specified minimum human head area.

The background represents static scenery in the field view of the image capturing device and is constructed from the height map . The background building process monitors every pixel of every height map and updates a background height map. A pixel may be considered as part of the static scenery if the pixel has the same non zero height value for a specified percentage of time e.g. 70 .

First pass components are computed by applying a variant of an eight connected image labeling algorithm on the runs of the height map . Properties of first pass components are calculated according to the definitions in Table 1. Predicate operators are also applied to the first pass components. Those first pass components whose IsNoise predicate operator returns true are ignored without being passed on to the second pass component detection phase of the object detection.

In this phase height map local maxima to be considered as candidate human detects are derived from the first pass components in the following steps.

First for each first pass component find all eight connected subcomponents whose pixels have the same height. The deigrouped property of all subcomponents is cleared to prepare for subcomponent grouping and the deCID property of each subcomponent is set to the ID of the corresponding first pass component.

Second try to find the highest ungrouped local maximal subcomponent satisfying the following two conditions 1 the subcomponent has the highest height among all of the ungrouped subcomponents of the given first pass component or the largest area among all of the ungrouped subcomponents of the given first pass component if several ungrouped subcomponents with the same highest height exist and 2 the subcomponent is higher than all of its neighboring subcomponents. If such a subcomponent exists use it as the current seed and proceed to the next step for further subcomponent grouping. Otherwise return to step 1 to process the next first pass component in line.

Third if BigSubComponentSeed test returns true on the current seed the subcomponent is then considered as a potential human object detect. Set the det grouped flag of the subcomponent to mark it as grouped and proceed to step 2 to look for a new seed. If the test returns false proceed to the next step.

Fourth try to find a subcomponent next to the current seed that has the highest height and meets all of the following three conditions 1 it is eight connected to the current seed 2 its height is smaller than that of the current seed and 3 it is not connected to a third subcomponent that is higher and it passes the NotSmallSubComponent test. If more than one subcomponent meets all of above conditions choose the one with the largest area. When no subcomponent meets the criteria set the deigrouped property of the current seed to grouped and go to step 2. Otherwise proceed to the next step.

Fifth calculate the distance between centers of the current seed and the subcomponent found in the previous step. If the distance is less than the specified detection search range or the current seed passes the SmallSubComponent test group the current seed and the subcomponent together and update the properties of the current seed accordingly. Otherwise set the det grouped property of the current seed as grouped . Return to step 2 to continue the grouping process until no further grouping can be done.

Because the image capturing device is mounted on the ceiling of the facility entrance a human object of interest is identified by a local maximum in the height map. Sometimes more than one local maxima detection is generated from the same human object of interest. For example when a human object raises both of his hands at the same time two closely located local maxima may be detected. Therefore it is necessary to merge closely located local maxima.

First search for the closest pair of local maxima detections. If the distance between the two closest detections is greater than the specified detection merging distance stop and exit the process. Otherwise proceed to the next step.

Second check and process the two detections according to the following conditions in the given order. Once one condition is met ignore the remaining conditions and proceed to the next step 

a if either but not all detection is in the background ignore the one in the background since it is most likely a static object the local maximum in the foreground has higher priority over the one in the background 

b if either but not all detection is touching edges of the height map or dead zones delete the one that is touching edges of the height map or dead zones a complete local maximum has higher priority over an incomplete one 

c if the difference between det rnaxlleights of detections is smaller than a specified person height variation threshold delete the detection with significantly less 3 D volume e.g. the product of det maxHeight and det masArea for one connected component is less than two thirds of the product for the other connected component a strong local maximum has higher priority over a weak one 

d if the difference between maximum heights of detections is more than one foot delete the detection with smaller det maxHeight if the detection with greater height among the two is less than the specified maximum person height or delete the detection with greater det maxHeight if the maximum height of that detection is greater than the specified maximum person height a local maxima with a reasonable height has higher priority over a local maximum with an unlikely height 

e delete the detection whose det area is twice as small as the other a small local maximum close to a large local maximum is more likely a pepper noise 

f if the distance between the two detections is smaller than the specified detection search range merge the two detections into one both local maxima are equally good and close to each other 

g keep both detections if the distance between the two detections is larger than or equal to the specified detection search range both local maxima are equally good and not too close to each other . Update the det. closestDet attribute for each detection with the other detection s ID.

The remaining local maxima detections after the above merging process are defined as candidate object detects which are then matched with a set of existing tracks for track extension or new track initiation if no match is found.

Object tracking block in uses objects detected in the object detection process block to extend existing tracks or create new tracks . Some short broken tracks are also analyzed for possible track repair operations.

To count human objects using object tracks zones are delineated in the height map . Door zones represent door areas around the facility to the entrance. Interior zones represent interior areas of the facility. A track traversing from the door zone to the interior zone has a potential in count. A track traversing to the door zone from the interior zone has a potential out count. If a track traverses across zones multiple times there can be only one potential in or out count depending on the direction of the latest zone crossing.

As illustrated in the process of object tracking comprises the following phases 1 analysis and processing of old tracks block 2 first pass matching between tracks and object detects block 3 suboptimal localization of unpaired tracks block 4 second pass matching between tracks and object detects block and 5 track updating or creation block .

An object track can be used to determine whether a human object is entering or leaving the facility or to derive properties such as moving speed and direction for human objects being tracked.

Object tracks can also be used to eliminate false human object detections such as static signs around the entrance area. If an object detect has not moved and its associated track has been static for a relatively long time the object detect will be considered as part of the background and its track will be processed differently than normal tracks e.g. the counts created by the track will be ignored .

Object tracking also makes use of color or gray level intensity information in the frames to search for best match between tracks and object detects . Note that the color or the intensity information is not carried to disparity maps or height maps .

The same technique used in the object tracking can also be used to determine how long a person stands in a checkout line.

Each track is a data structure generated from the same object being tracked in both temporal and spatial domains and contains a list of 4 tuples x y t h in addition to a set of related properties where h x and y present the height and the position of the object in the field of view at time t. x y h is defined in a world coordinate system with the plane formed by x and y parallel to the ground and the h axis vertical to the ground. Each track can only have one position at any time. In addition to the list of 4 tuples track also has a set of properties as defined in Table 2 and the properties will be referred to later by their abbreviated names in the parentheses 

Several predicate operators are defined in order to obtain the current status of the tracks . The predicate operators are applied to a subset of properties of a track to check if the subset of properties satisfies a certain condition. The predicate operators include 

IsNoisyNow which checks if track bouncing back and forth locally at the current time. Specifically a track is considered noisy if the track points with a fixed number of frames in the past specified as noisy track duration satisfies one of the following conditions 

a the range of track trkrange is less than the specified noisy track range and either the negative distance trk negDist is larger than two thirds of the positive distance trk posDist or the negative steps trk negNum are more than two thirds of the positive steps trk posNum 

b the range of track trkrange is less than half of the specified noisy track range and either the negative distance trk negDist is larger than one third of the positive distance trk posDist or the negative steps trk negNum are more than one third of the positive steps trk posNum .

This check is used when the track was created a short time ago and the whole track is considered noisy if one of the following conditions holds 

a the range of track trkrange is less than the specified noisy track range and either the negative distance trk negDist is larger than two thirds of the positive distance trk posDist or the negative steps trk negNum are more than two thirds of the positive steps trk posNum 

b the range of track trkrange is less than half the specified noisy track range and either the negative distance trk negDist is larger than one third of the positive distance trk posDist or the negative steps trk negNum are more than one third of the positive steps trk posNum .

IsSameTrack which check if two tracks are likely caused by the same human object. All of the following three conditions have to be met for this test to return true a the two tracks overlap in time for a minimum number of frames specified as the maximum track timeout b the ranges of both tracks are above a threshold specified as the valid counting track span and c the distance between the two tracks at any moment must be less than the specified minimum person width.

IsCountIgnored when the track crosses the counting zones it may not be created by a human object of interest. The counts of a track are ignored if one of the following conditions is met 

Unreliable Merged Tracks trkrange is less than the specified minimum background counting track length as well as one of the following trk mergedTracks is equal to trk smallSearches or trk backgroundCount is more than 80 of the life time of the track or the track crosses the zone boundaries more than once.

Small Child Test trk lowPtSteps is greater than of trk totalSteps and trk maxTrackHt is less than or equal to the specified minimum person height.

Shopping Cart Test trk voteFollowing is greater than 3 trk minFollowingDist is more than or equal to 80 of trk maxFollowingDist and trk maxTrackHt is less than or equal to the specified shopping cart height.

False Track test trk voteMirrorTrack is more than 60 of the life time of the track and trk maxMirrorTrackDist is less than two thirds of the specified maximum person width or trk totalVoteMirrorTrack is more than 80 of the life time of the track .

Referring to each track is updated with new information on its position time and height when there is a best matching human object detect in the current height map for First set trk state of the track to 1 block .

Second for the current frame obtain the height by using median filter on the most recent three heights of the track and calculate the new position by averaging on the most recent three positions of the track block .

Third for the current frame check the noise status using track predicate operator IsNoisyNow. If true mark a specified number of frames in the past as noisy. In addition update noise related properties of the track block .

a the track is not noisy at the beginning but it has been noisy for longer than the specified stationary track timeout block or

b the track is not in the background at the beginning but it has been in the background for longer than the specified stationary track timeout block .

It helps to use a predicted position of the track when looking for best matching detect . The predicted position is calculated by linear extrapolation on positions of the track in the past three seconds.

This is the first phase of object tracking. Active tracks are tracks that are either created or extended with human object detects in the previous frame. When there is no best matching human object detect for the track the track is considered as inactive.

This phase mainly deals with tracks that are inactive for a certain period of time or are marked for deletion in previous frame . Track analysis is performed on tracks that have been inactive for a long time to decide whether to group them with existing tracks or to mark them for deletion in the next frame . Tracks are deleted if the tracks have been marked for deletion in the previous frame or the tracks are inactive and were created a very short period of time before. If the counts of the soon to be deleted tracks shall not be ignored according to the IsCountIgnored predicate operator collect the counts of the tracks .

After all tracks are analyzed for grouping or deletion this phase searches for optimal matches between the human object detects i.e. the set of local maxima found in the object detection phase and tracks that have not been deleted.

First check every possible pair of track and detect and put the pair into a candidate list if all of the following conditions are met 

1 The track is active or it must be long enough e.g. with more than three points or it just became inactive a short period of time ago e.g. it has less than three frames 

2 The smaller of the distances from center of the detect to the last two points of the track is less than two thirds of the specified detection search range when the track hasn t moved very far e.g. the span of the track is less than the specified minimum human head size and the track has more than 3 points 

3 If the detect is in the background the maximum height of the detect must be greater than or equal to the specified minimum person height 

4 If the detect is neither in the background nor close to dead zones or height map boundaries and the track is neither in the background nor is noisy in the previous frame and a first distance from the detect to the predicted position of the track is less than a second distance from the detect to the end position of the track use the first distance as the matching distance. Otherwise use the second distance as the matching distance. The matching distance has to be less than the specified detection search range 

5 The difference between the maximum height of the detect and the height oblast point of the track must be less than the specified maximum height difference and

6 If either the last point off track or the detect is in the background or the detect is close to dead zones or height map boundaries the distance from the track to the detect must be less than the specified background detection search range which is generally smaller than the threshold used in condition 4 .

Sort the candidate list in terms of the distance from the detect to the track or the height difference between the detect and the track if the distance is the same in ascending order.

The sorted list contains pairs of detects and tracks that are not paired. Run through the whole sorted list from the beginning and check each pair. If either the detect or the track of the pair is marked paired already ignore the pair. Otherwise mark the detect and the track of the pair as paired . 0144 2.2.7 Search of Suboptimal Location For Unpaired Tracks

Due to sparseness nature of the disparity map and the height map some human objects may not generate local maxima in the height map and therefore may be missed in the object detection process . In addition the desired local maxima might get suppressed by a neighboring higher local maximum from a taller object. Thus some human object tracks may not always have a corresponding local maximum in the height map . This phase tries to resolve this issue by searching for a suboptimal location for a track that has no corresponding local maximum in the height map at the current time. Tracks that have already been paired with a detect in the previous phase might go through this phase too to adjust their locations if the distance between from end of those tracks to their paired detects is much larger than their steps in the past. In the following description the track currently undergoing this phase is called Track A. The search is performed in the following steps.

First referring to if Track A is deemed not suitable for the suboptimal location search operation i.e. it is inactive or it s in the background or it s close to the boundary of the height map or dead zones or its height in last frame was less than the minimum person height block stop the search process and exit. Otherwise proceed to the next step.

Second if Track A has moved a few steps block e.g. three steps and is paired with a detection called Detection A block that is not in the background and whose current step is much larger than its maximum moving step within a period of time in the past specified by a track time out parameter block proceed to the next step. Otherwise stop the search process and exit.

Third search around the end point of Track A in a range defined by its maximum moving steps for a location with the largest height sum in a predefined window and call this location Best Spot A block . If there are some detects deleted in the process of merging of closely located detects in the object detection phase and Track A is long in either the spatial domain or the temporal domain e.g. the span of Track A is greater than the specified noisy track span threshold or Track A has more than three frames block find the closest one to the end point of Track too. If its distance to the end point of Track A is less than the specified detection search range block search around the deleted component for the position with the largest height sum and call it Best Spot AI block . If neither Best Spot A nor Best Spot AI exists stop the search process and exit. If both Best Spot A and Best Spot AI exist choose the one with larger height sum. The best spot selected is called suboptimal location for Track A. If the maximum height at the suboptimal location is greater than the predefined maximum person height block stop the search and exit. If there is no current detection around the suboptimal location block create a new detect block at the suboptimal location and stop the search. Otherwise find the closest detect to the suboptimal location and call it Detection B block . If Detection B is the same detection as Detection A in step 2 block update Detection A s position with the suboptimal location block and exit the search. Otherwise proceed to the next step.

Fourth referring to if Detection B is not already paired with a track block proceed to the next step. Otherwise call the paired track of the Detection B as Track B and perform one of the following operations in the given order before exiting the search 

1 When the suboptimal location for Track A and Detection B are from the same parent component e.g. in the support of the same first pass component and the distance between Track A and Detection B is less than half of the specified maximum person width create a new detect at the suboptimal location block if all of the following three conditions are met i the difference between the maximum heights at the suboptimal location and Detection B is less than a specified person height error range ii the difference between the height sums at the two locations is less than half of the greater one iii the distance between them is greater than the specified detection search range and the trk range values of both Track A and Track B are greater than the specified noisy track offset. Otherwise ignore the suboptimal location and exit 

2 If the distance between the suboptimal location and Detection B is greater than the specified detection search range create a new detect at the suboptimal location and exit 

3 If Track A is not sizable in both temporal and spatial domains block ignore the suboptimal location 

4 If Track B is not sizable in both temporal and spatial domain block detach Track B from Detection B and update Detection B s position with the suboptimal location block . Mark Detection B as Track A s closest detection 

5 Look for best spot for Track B around its end position block . If the distance between the best spot for Track B and the suboptimal location is less than the specified detection search range block and the best spot for Track B has a larger height sum replace the suboptimal location with the best spot for Track B block . If the distance between is larger than the specified detection search range create a detect at the best spot for Track B block . Update Detection A s location with the suboptimal location if Detection A exists.

Fifth if the suboptimal location and Detection B are not in the support of the same first pass component proceed to the next step. Otherwise create a new detection at the suboptimal location if their distance is larger than half of the specified maximum person width or ignore the suboptimal location and mark Detection B as Track A s closest detection otherwise.

Finally create a new detect at suboptimal location and mark Detection B as Track A s closest detection block if their distance is larger than the specified detection search range. Otherwise update Track A s end position with the suboptimal location block if the height sum at the suboptimal location is greater than the height sum at Detection B or mark Detection Bas Track A s closest detection otherwise.

After the previous phase a few new detections may be added and some paired detects and tracks become unpaired again. This phase looks for the optimal match between current unpaired detects and tracks as in the following steps.

For every pair of track and detect that remain unpaired put the pair into a candidate list if all of the following five conditions are met 

2 the distance from detect to the end point of the track block is smaller than two thirds of the specified detection search range block when the track doesn t move too far e.g. the span of the track is less than the minimal head size and the track has more than three points block 

3 if the detect is in the background block the maximum height of the detect must be larger than or equal to the specified minimum person height block 

4 the difference between the maximum height and the height of the last point of the track is less than the specified maximum height difference block 

5 the distance from the detect to the track must be smaller than the specified background detection search range if either the last point of the track or the detect is in background block or the detect is close to dead zones or height map boundaries block or if not the distance from the detect to the track must be smaller than the specified detection search range block .

Sort the candidate list in terms of the distance from the detect to the track or the height difference between the two if distance is the same in ascending order block .

The sorted list contains pairs of detects and tracks which are not paired at all at the beginning. Then run through the whole sorted list from the beginning and check each pair. If either the detect or the track of the pair is marked paired already ignore the pair. Otherwise mark the detect and the track of the pair as paired block .

After the second pass of matching the following steps are performed to update old tracks or to create new tracks 

First referring to for each paired set of track and detect the track is updated with the information of the detect block .

Second create a new track for every detect that is not matched to the track if the maximum height of the detect is greater than the specified minimum person height and the distance between the detect and the closest track of the detect is greater than the specified detection search range block . When the distance is less than the specified detection merge range and the detect and the closest track are in the support of the same first pass component i.e. the detect and the track come from the same first pass component set the trk IastCollidingTrack of the closest track to the ID of the newly created track if there is one block .

Third mark each unpaired track as inactive block . If that track has a marked closest detect and the detect has a paired track set the trk IastCollidingTrack property of the current track to the track ID of the paired track block .

Fourth for each active track search for the closest track moving in directions that are at most thirty degrees from the direction of the active track . If the closest track exists the track is considered as closely followed by another track and Shopping Cart Test related properties of the track are updated to prepare for Shopping Cart Test when the track is going to be deleted later block .

Finally for each active track search for the closest track . If the distance between the two is less than the specified maximum person width and either the track has a marked closest detect or its height is less than the specified minimum person height the track is considered as a less reliable false track. Update False Track related properties to prepare for the False Track test later when the track is going to be deleted later block .

As a result all of the existing tracks are either extended or marked as inactive and new tracks are created.

Track analysis is applied whenever the track is going to be deleted. The track will be deleted when it is not paired with any detect for a specified time period. This could happen when a human object moves out of the field view or when the track is disrupted due to poor disparity map reconstruction conditions such as very low contrast between the human object and the background.

The goal of track analysis is to find those tracks that are likely continuations of some soon to be deleted tracks and merge them. Track analysis starts from the oldest track and may be applied recursively on newly merged tracks until no tracks can be further merged. In the following description the track that is going to be deleted is called a seed track while other tracks are referred to as current tracks. The steps of track analysis are as follows 

First if the seed track was noisy when it was active block in or its trkrange is less than a specified merging track span block or its trk IastCollidingTrack does not contain a valid track ID and it was created in less than a specified merging track time period before block stop and exit the track analysis process.

Second examine each active track that was created before the specified merging track time period and merge an active track with the seed track if the Is the Same Track predicate operation on the active track block returns true.

Third if the current track satisfies all of the following three initial testing conditions proceed to the next step. Otherwise if there exists a best fit track definition and search criteria for the best fit track will be described in forthcoming steps merge the best fit track with the seed track block . If there is no best fit track keep the seed track if the seed track has been merged with at least one track in this operation block or delete the seed track block otherwise. Then exit the track analysis.

The initial testing conditions used in this step are 1 the current track is not marked for deletion and is active long enough e.g. more than three frames block 2 the current track is continuous with the seed track e.g. it is created within a specified maximum track timeout of the end point of the seed track block 3 if both tracks are short in space e.g. the trkrange properties of both tracks are less than the noisy track length threshold then both tracks should move in the same direction according to the relative offset of the trk start and trk end properties of each track block .

Fourth merge the seed track and the current track block . Return to the last step if the current track has collided with the seed track i.e. the trk IastCollidingTrack of the current track is the trk ID of the seed track . Otherwise proceed to the next step.

Fifth proceed to the next step if the following two conditions are met at the same time otherwise return to step 3 1 if either track is at the boundaries according to the is at the boundary checking block both tracks should move in the same direction and 2 at least one track is not noisy at the time of merging block . The noisy condition is determined by the is noisy predicate operator.

Sixth one of two thresholds coming up is used in distance checking. A first threshold block is specified for normal and clean tracks and a second threshold is specified for noisy tracks or tracks in the background. The second threshold block is used if either the seed track or the current track is unreliable e.g. at the boundaries or either track is noisy or trkranges of both tracks are less than the specified noisy track length threshold and at least one track is in the background block otherwise the first threshold is used. If the shortest distance between the two tracks during their overlapping time is less than the threshold block mark the current track as the best fit track for the seed track block and if the seed track does not have best fit track yet or the current track is closer to the seed track than the existing best fit track block . Go to step 3.

This operation merges two tracks into one track and assigns the merged track with properties derived from the two tracks. Most properties of the merged track are the sum of the corresponding properties of the two tracks but with the following exceptions 

Referring to trk enters and trk exits properties of the merged track are the sum of the corresponding properties of the tracks plus the counts caused by zone crossing from the end point ozone track to the start point of another track which compensates the missing zone crossing in the time gap between the two tracks block .

The trk start property of the merged track has the same trk start value as the newer track among the two tracks being merged and the trk end property of the merged track has the same trk end value as the older track among the two block .

The buffered raw heights and raw positions of the merged track are the buffered raw heights and raw positions of the older track among the two tracks being merged block .

As shown in an alternative embodiment of the present invention may be employed and may comprise a system having an image capturing device a reader device and a counting system . In the illustrated embodiment the at least one image capturing device may be mounted above an entrance or entrances to a facility for capturing images from the entrance or entrances . The area captured by the image capturing device is field of view . Each image captured by the image capturing device along with the time when the image is captured is a frame . As described above with respect to image capturing device for the previous embodiment of the present invention the image capturing device may be video based. The manner in which object data is captured is not meant to be limiting so long as the image capturing device has the ability to track objects in time across a field of view . The object data may include many different types of information but for purposes of this embodiment of the present invention it includes information indicative of a starting frame an ending frame and direction.

For exemplary purposes the image capturing device may include at least one stereo camera with two or more video sensors similar to the image capturing device shown in which allows the camera to simulate human binocular vision. A pair of stereo images comprises frames taken by each video sensor of the camera. The image capturing device converts light images to digital signals through which the device obtains digital raw frames comprising pixels. The types of image capturing devices and video sensors should not be considered limiting and any image capturing device and video sensor compatible with the present system may be adopted.

For capturing tag data associated with RFID tags such as name tags that may be worn by an employee or product tags that could be attached to pallets of products the reader device may employ active RFID tags that transmit their tag information at a fixed time interval. The time interval for the present invention will typically be between 1 and 10 times per second but it should be obvious that other time intervals may be used as well. In addition the techniques for transmitting and receiving RFID signals are well known by those with skill in the art and various methods may be employed in the present invention without departing from the teachings herein. An active RFID tag is one that is self powered i.e. not powered by the RF energy being transmitted by the reader. To ensure that all RFID tags are captured the reader device may run continuously and independently of the other devices and systems that form the system . It should be evident that the reader device may be replaced by a device that uses other types of RFID tags or similar technology to identify objects such as passive RFID ultrasonic or infrared technology. It is significant however that the reader device has the ability to detect RFID tags or other similar devices in time across a field of view for the reader device . The area captured by the reader device is the field of view and it is preferred that the field of view for the reader device be entirely within the field of view for the image capturing device .

The counting system processes digital raw frames detects and follows objects and generates tracks associated with objects in a similar manner as the counting system described above. The counting system may be electronically or wirelessly connected to at least one image capturing device and at least one reader device via a local area or wide area network. Although the counting system in the present invention is located remotely as part of a central server it should be evident to those with skill in the art that all or part of the counting system may be i formed as part of the image capturing device or the reader device ii stored on a cloud computing network or iii stored remotely from the image capturing device and reader device by employing other distributed processing techniques. In addition the RFID reader the image capturing device and the counting system may all be integrated in a single device. This unitary device may be installed anywhere above the entrance or entrances to a facility . It should be understood however that the hardware and methodology that is used for detecting and tracking objects is not limited with respect to this embodiment of the present invention. Rather it is only important that objects are detected and tracked and the data associated with objects and tracks is used in combination with tag data from the reader device to separately count and track anonymous objects and defined objects which are associated with an RFID tag .

To transmit tag data from the reader device to a counting system the reader device may be connected directly to the counting system or the reader device may be connected remotely via a wireless or wired communications network as are generally known in the industry. It is also possible that the reader device may send tag data to the image capturing device which in turn transmits the tag data to the counting system . The tag data may be comprised of various information but for purposes of the present invention the tag data includes identifier information signal strength information and battery strength information.

To allow the counting system to process traffic data tag data and object data may be pulled from the reader device and the image capturing device and transmitted to the counting system . It is also possible for the reader device and the image capturing device to push the tag data and object data respectively to the counting system . It should be obvious that the traffic data which consists of both tag data and object data may also be transmitted to the counting system via other means without departing from the teachings of this invention. The traffic data may be sent as a combination of both tag data and object data and the traffic data may be organized based on time.

The counting system separates the traffic data into tag data and object data . To further process the traffic data the counting system includes a listener module that converts the tag data into sequence records and the object data into track records . Moreover the counting system creates a sequence array comprised of all of the sequence records and a track array comprised of all of the track records . Each sequence record may consist of 1 a tag ID which may be an unsigned integer associated with a physical RFID tag located within the field of view of a reader device 2 a startTime which may consist of information indicative of a time when the RFID tag was first detected within the field of view 3 an endTime which may consist of information indicative of a time when the RFID tag was last detected within the field of view of the reader device and 4 an array of references to all tracks that overlap a particular sequence record . Each track record may include a a counter which may be a unique ID representative of an image capturing device associated with the respective track b a direction which may consist of information that is representative of the direction of movement for the respective track c startTime which may consist of information indicative of a time when the object of interest was first detected within the field of view of the image capturing device d endTime which may consist of information indicative of a time when the object of interest left the field of view of the image capturing device and e tagID which if non zero may include an unsigned integer identifying a tag associated with this track record .

To separate and track anonymous objects such as shoppers or customers and defined objects such as employees and products the counting system for the system must determine which track records and sequence records match one another and then the counting system may subtract the matching track records from consideration which means that the remaining unmatched track records relate to anonymous objects and the track records that match sequence records relate to defined objects .

To match track records and sequence records the counting system first determines which track records overlap with particular sequence records . Then the counting system creates an array comprised of track records and sequence records that overlap which is known as a match record . In the final step the counting system iterates over the records in the match record and determines which sequence records and track records best match one another. Based on the best match determination the respective matching track record and sequence record may be removed from the match record and the counting system will then iteratively move to the next sequence record to find the best match for that sequence record until all of the sequence records and track records in the match record have matches or it is determined that no match exists.

The steps for determining which sequence records and track records overlap are shown in . To determine which records overlap the counting system iterates over each sequence record in the sequence array to find which track records overlap with a particular sequence records the term overlap generally refers to track records that have startTimes that are within a window defined by the startTime and endTime of a particular sequence records . Therefore for each sequence record the counting system also iterates over each track record in the track array and adds a reference to the respective sequence record indicative of each track record that overlaps that sequence record . Initially the sequence records have null values for overlapping track records and the track records have tagID fields set to zero but these values are updated as overlapping records are found. The iteration over the track array stops when a track record is reached that has a startTime for the track record that exceeds the endTime of the sequence record at issue.

To create an array of overlapped records known as match records the counting system iterates over the sequence array and for each sequence record the counting system compares the track records that overlap with that sequence record to the track records that overlap with the next sequence record in the sequence array . As shown in a match record is then created for each group of sequence records whose track records overlap. Each match record is an array of references to all sequence records whose associated track records overlap with each other and the sequence records are arranged in earliest to latest startTime order.

The final step in matching sequence records and track records includes the step of determining which sequence records and track records are the best match. To optimally match records the counting system must consider direction history on a per tag basis i.e. by mapping between the tagID and the next expected match direction. The initial history at the start of a day or work shift is configurable to either in or out which corresponds to employees initially putting on their badges or name tags outside or inside the monitored area.

To optimally match records a two level map data structure referred to as a scoreboard may be built. The scoreboard has a top level or sequencemap and a bottom level or trackmap . Each level has keys and values . The keys for the top level are references to the sequence array and the values are the maps for the bottom level . The keys for the bottom level are references to the track array and the values are match quality scores . As exemplified in the match quality scores are determined by using the following algorithm.

1 Determine if the expected direction for the sequence record is the same as the expected direction for the track record. If they are the same the MULTIPLIER is set to 10. Otherwise the MULTIPLIER is set to 1.

2 Calculate the percent of overlap between the sequence record and the track record as an integer between 0 and 100 by using the formula OVERLAP earliest endTime latest startTime latest endTime earliest startTime 

The counting system populates the scoreboard by iterating over the sequence records that populate the sequence array referenced by the top level and for each of the sequence records the counting system also iterates over the track records that populate the track array referenced by the bottom level and generates match quality scores for each of the track records . As exemplified in once match quality scores are generated and inserted as values in the bottom level each match quality score for each track record is compared to a bestScore value and if the match quality score is greater than the bestScore value the bestScore value is updated to reflect the higher match quality score . The bestTrack reference is also updated to reflect the track record associated with the higher bestScore value.

As shown in once the bestTrack for the first sequence in the match record is determined the counting system iterates over the keys for the top level to determine the bestSequence which reflects the sequence record that holds the best match for the bestTrack i.e. the sequence record track record combination with the highest match quality score . The bestScore and bestSequence values are updated to reflect this determination. When the bestTrack and bestSequence values have been generated the sequence record associated with the bestSequence is deleted from the scoreboard and the bestTrack value is set to 0 in all remaining keys for the bottom level . The counting system continues to evaluate the remaining sequence records and track records that make up the top and bottom levels of the scoreboard until all sequence records and track records that populate the match record have been matched and removed from the scoreboard or until all remaining sequence records have match quality scores that are less than or equal to 0 i.e. no matches remain to be found. As shown in Table 1 the information related to the matching sequence records and track records may be used to prepare reports that allow employers to track among other things i how many times an employee enters or exits an access point ii how many times an employee enters or exits an access point with a customer or anonymous object iii the length of time that an employee or defined object spends outside and iv how many times a customer enters or exits an access point. This information may also be used to determine conversion rates and other What If metrics that relate to the amount of interaction employees have with customers. For example as shown in Table 2 the system defined herein may allow employers to calculate among other things a fitting room capture rates b entrance conversion rates c employee to fitting room traffic ratios and d the average dollar spent. These metrics may also be extrapolated to forecast percentage sales changes that may result from increases to the fitting room capture rate as shown in Table 3.

In some cases there may be more than one counter which consists of the combination of both the image capturing device and the reader device to cover multiple access points. In this case separate sequence arrays and track arrays will be generated for each of the counters . In addition a match array may be generated and may comprise each of the match records associated with each of the counters . In order to make optimal matches tag history must be shared between all counters . This may be handled by merging in a time sorted order all of the match records in the match array and by using a single history map structure which is generally understood by those with skill in the art. When matches are made within the match array the match is reflected in the track array associated with a specific counter using the sequence array associated with the same counter . This may be achieved in part by using a counter ID field as part of the track records that make up the track array referenced by the bottom level of the scoreboard . For example references to the track arrays may be added to a total track array and indexed by counter ID. The sequence arrays would be handled the same way.

As shown in a further embodiment of the present invention may be employed and may comprise a system having one or more sensors a data capturing device and a counting system . In the illustrated embodiment the sensor s may be image capturing devices and may be mounted above an entrance or entrances to a facility for capturing images from the entrance or entrances and object data . The area captured by the sensor is a field of view . Each image captured by the sensor along with the time when the image is captured is a frame . As described above with respect to image capturing device in connection with a separate embodiment of the present invention the sensor may be video based. The object data may include many different types of information but for purposes of this embodiment of the present invention it includes information indicative of a starting frame an ending frame and direction. It should be understood that the sensor may also employ other technology which is widely known in the industry. Therefore the manner in which object data is captured is not meant to be limiting so long as the sensor has the ability to track objects in time across a field of view .

For exemplary purposes the sensor may include at least one stereo camera with two or more video sensors similar to the sensor shown in which allows the camera to simulate human binocular vision. A pair of stereo images comprises frames taken by each video sensor of the camera. The sensor converts light images to digital signals through which the counting system obtains digital raw frames comprising pixels. Again the types of sensors and video sensors should not be considered limiting and it should be obvious that any sensor including image capturing devices thermal sensors and infrared video devices capable of counting the total foot traffic and generating a starting frame an ending frame and a direction will be compatible with the present system and may be adopted.

For providing more robust tracking and counting information the object data from the sensor may be combined with subset data that is captured by the data capturing device . The subset data may include a unique identifier A an entry time B an exit time C and location data for each object of interest . The subset data may be generated by data capturing devices that utilize various methods that employ doorway counting technologies tracking technologies and data association systems. Doorway counting technologies such as Bluetooth and acoustic based systems are similar to the RFID system described above and generate subset data . To generate the subset data the doorway counting technology may provide a control group with a device capable of emitting a particular signal i.e. Bluetooth or sound frequency . The system may then monitor a coverage area and count the signals emitted by the devices associated with each member of the control group to generate subset data . The subset data from the doorway counting system may be combined with the object data from the sensor to generate counts related to anonymous objects and defined objects. The doorway counting system may also be video based and may recognize faces gender racial backgrounds or other immutable characteristics that are readily apparent.

The data capturing device may also use tracking technology that triangulates on a cellular signals emitted from a mobile handsets to generate location data . The cellular signal may be T IMSI associated with GSM systems CDMA which is owned by the CDMA Development Group or Wi Fi which is owned by the Wi Fi Alliance signals. The data capturing device may also receive location data such as GPS coordinates for objects of interest from a mobile handset . The location data may be provided by a mobile application on the mobile handset or by the carrier for the mobile handset . User authorization may be required before mobile applications or carriers are allowed to provide location data .

For ease of reference we will assume that the subset data discussed below is based on the location data that is provided by a mobile handset . The data capturing device receives subset data associated with a mobile handset which is transmitted at a fixed time interval. The time interval for the present invention will typically be between 1 and 10 times per second but it should be obvious that other time intervals may be used as well. In addition the techniques for transmitting and receiving the signals from mobile handsets are well known by those with skill in the art and various methods may be employed in the present invention without departing from the teachings herein. To ensure that the subset data for all mobile handsets is captured the data capturing device may run continuously and independently of the other devices and systems that form the system . As mentioned above the data capturing device may employ various types of signals without departing from the scope of this application. It is significant however that the data capturing device has the ability to track mobile handsets or other similar devices in time across a coverage area . The area captured by the data capturing device is the coverage area . In some instances the field of view for the sensor may be entirely within the coverage area for the data capturing device and vice versa.

The data capturing device may also use data association systems . Data association systems take data from other independent systems such as point of sale systems loyalty rewards programs point of sale trigger information i.e. displays that attach cables to merchandise and count the number of pulls for the merchandise mechanical turks which utilize manual input of data or other similar means. Data generated by data association systems may not include information related to direction but it may include more detailed information about the physical characteristics of the object of interest.

The counting system may process digital raw frames detect and follow objects of interest objects and may generate tracks associated with objects in a similar manner as the counting system described above. The counting system may be electronically or wirelessly connected to at least one sensor and at least one data capturing device via a local area or wide area network. Although the counting system in the present invention is located remotely as part of a central server it should be evident to those with skill in the art that all or part of the counting system may be i formed as part of the sensor or the data capturing device ii stored on a cloud computing network or iii stored remotely from the sensor and data capturing device by employing other distributed processing techniques. In addition the data capturing device the sensor and the counting system may all be integrated in a single device. This unitary device may be installed anywhere above the entrance or entrances to a facility . It should be understood however that the hardware and methodology that is used for detecting and tracking objects is not limited with respect to this embodiment of the present invention. Rather it is only important that objects are detected and tracked and the data associated with objects and tracks is used in combination with subset data from the data capturing device to separately count and track anonymous objects and defined objects which are associated with the mobile handset .

To transmit subset data from the data capturing device to a counting system the data capturing device may be connected directly to the counting system or the data capturing device may be connected remotely via a wireless or wired communications network as are generally known in the industry. It is also possible that the data capturing device may send subset data to the sensor which in turn transmits the subset data to the counting system . The subset data may be comprised of various information but for purposes of the present invention the subset data includes a unique identifier location based information and one or more timestamps.

To allow the counting system to process traffic data subset data and object data may be pulled from the data capturing device and the sensor respectively and transmitted to the counting system . It is also possible for the data capturing device and the sensor to push the subset data and object data respectively to the counting system . It should be obvious that the traffic data which consists of both subset data and object data may also be transmitted to the counting system via other means without departing from the teachings of this invention. The traffic data may be sent as a combination of both subset data and object data and the traffic data may be organized based on time.

The counting system separates the traffic data into subset data and object data . To further process the traffic data the counting system may include a listener module that converts the subset data into sequence records and the object data into track records . Moreover the counting system may create a sequence array comprised of all of the sequence records and a track array comprised of all of the track records . Each sequence record may consist of 1 a unique ID which may be an unsigned integer associated with a mobile handset the telephone number associated with the mobile handset or any other unique number character or combination thereof associated with the mobile handset 2 a startTime which may consist of information indicative of a time when the mobile handset was first detected within the coverage area 3 an endTime which may consist of information indicative of a time when the mobile handset was last detected within the coverage area of the data capturing device and 4 an array of references to all tracks that overlap a particular sequence record . Each track record may include a a counter which may be a unique ID representative of a sensor associated with the respective track b a direction which may consist of information that is representative of the direction of movement for the respective track c startTime which may consist of information indicative of a time when the object of interest was first detected within the field of view of the sensor d endTime which may consist of information indicative of a time when the object of interest left the field of view of the sensor and e handsetID which if non zero may include an unsigned integer identifying a mobile handset associated with this track record .

To separate and track anonymous objects i.e. shoppers or random customers and defined objects such as shoppers with identified mobile handsets or shoppers with membership cards employee badges rail air tickets rental car or hotel keys store sponsored credit debit cards or loyalty reward cards all of which may include RFID chips the counting system for the system must determine which track records and sequence records match one another and then the counting system may subtract the matching track records from consideration which means that the remaining unmatched track records relate to anonymous objects and the track records that match sequence records relate to defined objects . The methodology described in paragraphs 169 179 above includes steps related to matching track records and sequence records . A similar method for matching track records and sequence records may be employed in connection with the present embodiment of the counting system . The match algorithm or quality score algorithm that is employed should not be viewed as limiting as various methods for matching tracks and sequence records may be used.

In some cases there may be more than one counting system which consists of the combination of both the sensor and the data capturing device to cover multiple access points. In this case separate sequence arrays and track arrays will be generated for each of the counters . In addition a match array may be generated and may comprise each of the match records associated with each of the counting systems . In order to make optimal matches tag history must be shared between all counting systems . This may be handled by merging in a time sorted order all of the match records in the match array and by using a single history map structure which is generally understood by those with skill in the art.

By identifying tracking and counting objects simultaneously with one or more sensors and one or more data capturing devices the system can generate data sets based on time geography demographic characteristics and behavior. For example the system may be capable of determining or calculating the following 

Although there are a multitude of different data types and reports that may be calculated or generated the data generally falls into the following four dimensions time A geographic B demographic C and behavioral D. These various dimensions or categories should not however be viewed as limiting as it should be obvious to those with skill in the art that other dimensions or data types may also exist.

To generate data related to the time dimension A various algorithms may be applied. For example the algorithm in shows a series of steps that may be used to calculate dwell time for one or more shoppers or to count the frequent shopper data or number of visits by one or more shoppers. As shown at step to calculate dwell time or frequent shopper data the system must first upload the traffic data including the object data and the subset data . The traffic data may also include a unique ID A a start time B and an end time C for each shopper included as part of the traffic data . The start times B and end times C may be associated with specific predefined areas . To generate reports for specific time periods the system may also sort the traffic data based on a selected time range. For example at step the system may aggregate the traffic data based on the start time B the end time C or the time period . Aggregating traffic data based on start time B end time C or time period is generally understood in the industry and the order or specific steps that are used for aggregating the traffic data should not be viewed as limiting. Once the traffic data is aggregated or sorted it may be used to calculate dwell times or frequent shopper data . It should be understood that the time periods may be based on user defined periods such as minutes hours days weeks etc.

To allow a user to generate either dwell time or frequent shopper data the system may ask the user to select either dwell time or frequent shopper data see step . This selection and other selections that are discussed throughout this description may be effectuated by allowing a user to select a button a hyperlink or an option listed on a pull down or pop up menu or to type in the desired option in a standard text box. Other means for selecting reporting options may also be employed without departing from the present invention. To calculate the dwell time for a shopper the following equation may be used Dwell time Time at which a shopper leaves a predefined area Time at which a shopper enters a predefined area 

For example assume a shopper enters a predefined area such as a store at 1 00 pm and leaves at 1 43 pm. The dwell time would be calculated as follows Dwell time 1 43 1 00 43 minutes In this instance the dwell time would be the total amount of time 43 minutes that was spent in the predefined area . The predefined area may be defined as a specific department i.e. the men s clothing department the women s clothing department a general area a particular display area a point of purchase a dressing room etc. Thus if a shopper visits multiple predefined areas or departments the system may calculate dwell times for each predefined area or department that is visited.

Predefined areas may be determined by entering a set of boundaries obtained from a diagram of the desired space or store. The set of boundaries may define particular departments display areas within particular departments or other smaller areas as desired. More specifically the predefined areas may be determined by copying the diagram into a Cartesian plane which uses a coordinate system to assign X and Y coordinates to each point that forms a set of boundaries associated with the predefined areas . Track records may be generated for each shopper and may include an enter time and exit time for each predefined area . In order to calculate dwell times the following information may be necessary i unique IDs A for each shopper ii a set of boundaries for each predefined area iii coordinates for set of boundaries within a predefined areas iv enter times and exit times for each predefined area and shopper. In addition to aggregating the traffic data and prior to calculating the dwell times the system may also sort the traffic data by time periods unique IDs A and or the predefined areas visited within the time periods . The process of calculating dwell times is an iterative and ongoing process therefore the system may store dwell times by shopper or predefined area for later use or use in connection with other dimensions . Dwell times may be used to generate reports that list aggregate or average dwell times for selected shoppers geographies time periods or demographic groups and these reports may also be feed into other systems that may use the dwell time to function such as HVAC systems that may raise or lower temperatures based on the average dwell times for various time periods and geographic locations. It should be obvious to those with skill in the art that the dwell times and the dwell time reports A may be used in many different ways. Therefore the prior disclosure should be viewed as describing exemplary uses only and should not limit the scope potential uses or formats for the dwell times or dwell time reports A.

To generate frequent shopper data the system may first upload shopper visit data for a particular time period . Shopper visit data may be generated from the dwell times for a predefined area without regard to the length of the time associated with the dwell times . In other words step may increment a counter for each shopper that enters a predefined area . Then the system may populate the shopper visit data with the data from the counter and store the shopper visit data in a database . The database may sort the shopper visit data based on a unique ID A for a particular shopper a predefined area or a desired time period . To avoid including walk through traffic as part of the shopper visit data the system may require a minimum dwell time in order to register as a visit and thereby increment the counter . The minimum dwell time may be on the order of seconds minutes or even longer periods of time. Similar to dwell times the shopper visit data may be sorted based on time periods unique IDs A and or the predefined areas . For example as shown in step the shopper visit data may be used to generate a shopper frequency report A by geography or based on a predefined area . More specifically the shopper frequency report A may show information such as the percentage of repeat shoppers versus one time shoppers for a given time period or the distribution of repeat shoppers by predefined areas . The shopper frequency report A may also disclose this information based on specified demographic groups. It should be obvious to those with skill in the art that the shopper visit data and the shopper frequency reports A may be used in many different ways. Therefore the prior disclosure should be viewed as describing exemplary uses only and should not limit the scope potential uses or formats for the shopper visit data or shopper frequency reports A.

To generate data related to the geographic dimension B several different methods may be employed. The algorithm shown in shows one example of a series of steps that may be used to analyze foot traffic by geography. After it is determined in step that the geographic analysis should be conducted the system must first upload the traffic data including the object data and the subset data . The subset data includes a unique identifier A an entry time B an exit time C and location data for each object of interest . The location data for object of interests is particularly important for generating data related to the geographic dimension B. As mentioned above the location data may be generated by using information from fixed receivers and a relative position for a shopper to triangulate the exact position of a shopper within a predefined area or by receiving GPS coordinates from a mobile handset. The exact position of a shopper within a predefined area is determined on an iterative basis throughout the shopper s visit. Other methods for calculating exact position of a shopper may also be used without departing from the teachings provided herein.

To determine the position of an object of interest within a predefined area the location data may be associated with the predefined area . As mentioned above the predefined area may be defined by entering a set of boundaries within a diagram of the desired space or store. The diagram of the desired space or store may be generated by the system from an existing map of the desired space or store. Again as referenced above boundaries may be generated by copying the diagram into a Cartesian plane and assigning X and Y coordinates to each point that forms an external point on one or more polygons associated with the predefined area . By iteratively tracking the position of an object of interest over time the system may also generate the direction in which the object of interest is traveling and path data associated with the path traveled by the object of interest . The position of an object of interest within a predefined area may also be generated by 1 using fixed proximity sensors that detect nearby objects of interest 2 triangulation of multiple reference signals to produce the position of an object of interest or 3 using cameras that track video infrared or thermal images produced by an object of interest . Other means for generating the position of an object of interest may also be used without departing from the teachings herein.

To generate path data for an object of interest the system may use subset data including location data associated with an object of interest to iteratively plot X and Y coordinates for an object of interest within a predefined area of a diagram at sequential time periods. Therefore the X and Y coordinates associated with an object of interest are also linked to the time at which the X and Y coordinates were generated. To count and track objects of interest in predefined areas that are comprised of multiple floors subset data and or location data may also include a Z coordinate associated with the floor on which the object of interest is located. A multi floor diagram is shown in .

As shown in step after location data and path data are generated for objects of interest that information should be stored and associated with the respective objects of interest . As shown in step the system allows a user to analyze traffic data based on a predefined area or by path data for objects of interest . The predefined area may be a particular geographic area a mall a store a department within a store or other smaller areas as desired. To analyze the traffic the system may first aggregate the traffic data for the objects of interest within the predefined area see step . As shown in step the system may subsequently load dwell times shopper visit data sales transaction data or demographic data for the objects of interest . Step generates store level traffic data for predefined areas by extrapolating the subset data for particular predefined areas based on the corresponding object data which may include the total number of objects of interest within a predefined area . By using the traffic data which includes object data and subset data and as shown in Step the system may generate reports that show the number of objects of interest for a predefined area the number of objects of interest for a predefined area during a specific time period the number of predefined areas that were visited such as shopper visit data or the dwell times for predefined areas . These reports may include information for specific subsets of objects of interest or shoppers or the reports may include store level traffic data which extrapolates subset data to a store level basis. It should be obvious that the reports may also include other information related to time geography demographics or behavior of the objects of interest and therefore the foregoing list of reports should not be viewed as limiting the scope of system .

At step the user may also choose to analyze traffic data based on path data for objects of interest or the path taken by objects of interest . To analyze the traffic data based on path data or the path taken the system may first load the location data and path data that was generated for objects of interest in step . The system may also load information such as dwell times shopper visit data sales transaction data or demographic data for the objects of interest . Once this information is loaded into system the system may aggregate the most common paths taken by objects of interest and correlate path data information with dwell times see step . After the information is aggregated and correlated various reports may be generated at step including reports that show i the most common paths that objects of interest take in a store by planogram including corresponding dwell times if desired ii changes in shopping patterns by time period or season and iii traffic patterns for use by store security or HVAC systems in increasing or decreasing resources at particular times. These reports may be stored and used in connection with generating data and reports for other dimensions . As shown in reports may also be generated based on the behavioral and demographic dimensions C D.

To generate data related to the demographic dimension C the algorithm shown in may be employed. As shown at step in the system should first load traffic data and demographic data . The demographic data may be received from a retail program including loyalty programs trigger marketing programs or similar marketing programs and may include information related to a shopper including age ethnicity sex physical characteristics size etc. The traffic data may be sorted in accordance with the demographic data and other data such as start time B end time C time period and location data . Once the traffic data and demographic data is loaded and sorted the system may analyze the traffic data including the object data and subset data based on various demographic factors including but not limited to shopper demographics in store behavior and marketing programs.

To analyze the traffic data based on the shopper demographics step the system may sort the traffic data by geography and time period. It should be obvious however that the traffic data may also be sorted according to other constraints. In step the system analyzes the traffic data including object data and subset data based on time periods and predefined areas . The analysis may include counts for objects of interest that enter predefined areas or counts for objects of interest that enter predefined areas during specified time periods . To assist in analyzing the traffic data based on time periods and predefined areas the information that was generated in connection with the time dimension A including dwell times shopper data and shopper visit data and the geographic dimension B i.e. predefined areas boundaries and x and y coordinates may be used. As shown in step the system may generate reports that show traffic by demographic data and store department time of day day of week or season etc.

To analyze traffic data based on in store behavior the system must determine whether to look at in store behavior based on dwell time or path data . If dwell time is selected step the system may load dwell times generated in relation to the time dimension A and sort the dwell times based on the geographic dimension B. After the dwell times and path data are combined with the demographic data the system may generate reports that show the dwell times by profile characteristics or demographic data i.e. age ethnicity sex physical characteristics size etc. For analyzing traffic data based on a combination of demographic data and path data the system may first load path data generated in relation to the geographic dimension B. After the path data is sorted according to selected demographic data the system may then generate reports that show the number of departments visited by objects of interest associated with particular demographic groups the most common paths used by the objects of interest associated with those demographic groups. It should be obvious that other reports associated with demographic groups and path data may also be generated by the system .

To analyze the traffic data based on a particular marketing program the system may first load demographic data associated with a particular marketing program . The marketing program may be aimed at a specific product or it may be a trigger marketing program being offered by a retailer. Examples of such programs are percent off price promotion for items in a specific department e mail blasts sent to customers promoting certain products time based discounted upsell offerings made available to any female entering the store a flash loyalty discount for any customer making a return trip to the store within a 10 day period upon entering the store sending a shopper a message informing her of a trunk show event taking place later that day and provide shoppers with the option to download an unreleased song from a popular band made available as part of national ad campaign. Other types of marketing programs may also be the source of the demographic data without departing from the teaching and tenets of this detailed description. To analyze the traffic data based on the marketing program the system may first sort the traffic data based on the demographic data provided by the marketing programs. As shown in step the system may then generate reports that show retailer loyalty program driven behavior demographics such as the impact of loyalty programs on particular demographic groups the traffic of those demographic groups or shopping habits of those demographic groups. These reports may include information related to how specific demographic groups teens young adults seniors males females etc. shop in specific departments or areas of a store traffic reports with information related to before and after a targeted promotion is offered to loyal customers benchmark information regarding the effects of marketing programs on traffic and sales within the store and comparisons of traffic by department for a targeted demographic promotion.

To generate data related to the behavioral dimension D the system may combine data and reports generated in connection with the other dimensions namely the time dimension A geographic dimension B and demographic dimension C. In addition conversion rate analysis or purchaser non purchaser analysis may also be added to the data and reports generated in connection with the other dimensions . To generate conversion rates purchase data which includes purchaser A and non purchaser data B the algorithm shown in may be employed. As shown at step in the first step is to determine whether to generate conversion rates or purchase data .

For generating conversion rates the system may first load traffic data and transaction data from the geographic dimension B and sort the traffic data by time periods . The transaction data may include information related to the sales amount the number of items that were purchased the specific items that were purchased the date and time of the transaction the register used to complete the transaction the location where the sale was completed department ID and sub department ID and the sales associate that completed the sale. Other information may also be gathered as part of the transaction data without departing from the teaching herein. Next the system may load projected traffic data from the geographic dimension B which is also sorted by time periods . In step the system may calculate conversion rates . The conversion rates may be calculated by dividing the transactions by the traffic counts within a predefined area by a time period . For instance for one hour of a day a department in a store generated twenty sales transactions . During the same hour one hundred people visited the department. The department s conversion rate was twenty percent 20 20 transactions 100 shoppers . The conversion rates may also be associated with a demographic factor . For instance given the type of store males or females gender demographic may convert at different rates. The conversion rates that are calculated may be stored by the system for later use in step . Once the conversion rates are calculated they may be used to generate reports such as the conversion rate for an entire store or a specific department the conversion rate for shoppers with specific profiles or characteristics cross sections of the above referenced conversion rates based on a time period or other reports based on combinations of the conversion rate with information from the time dimension A geographic dimension B or demographic dimension C.

For generating reports based on purchaser behavior the system may first load dwell times and then sort the dwell times by predefined areas see step . The dwell times may be further sorted by time periods . As shown in step the system may then load transaction data such as sales transactions for the same predefined areas and corresponding time periods . The system may then produce reports that show comparisons between purchasers and non purchasers based on dwell times predefined areas and or time periods . These reports may also be sorted based on demographic data as mentioned above.

Referring to the energy management system includes a number of different modules that work together to control energy usage and costs associated with energy usage. The system includes a plan generator that creates and updates an energy plan for the system . The plan generator may be a UNIX based C C or Java software program that runs on a Sun Solaris operating system. One skilled in the art will understand that other software programs and or operating systems may optionally or additionally be utilized. In order to create and update the energy plan the plan generator may receive weather forecast data from a weather forecast module or application programming interface API such as the weather.com API. In particular current and forecast data may be pulled from the weather source for each individual site based on the zip code of that site. The plan generator may also receive foot traffic forecast data from a foot traffic forecast module which in turn pulls data from a database .

The foot traffic forecast module may pull historical traffic data from the database and utilize an algorithm to determine the foot traffic forecast. When referring to foot traffic data with respect to the energy management system it should be understand that foot traffic refers to an occupancy of or a number of people in a particular structure building room or other enclosed space at a particular time or during a particular time period.

Other information may additionally be provided to the plan generator . For example national holiday information days of non operation of a particular site and or any other information useful in determining foot traffic or weather and or managing the use of energy may be provided to the plan generator .

The plan generator the weather forecast module the foot traffic forecast module and the database may be disposed in an offsite location. Regardless the plan generator foot traffic forecast module and the database store and generate data for a number of different sites. The weather forecast module may be an external datasource wherein weather data is pulled based on the particular location of a site.

The plan generator may also receive real time temperature and real time foot traffic data from a communication device . The plan generator may use the forecast and real time temperature and foot traffic data to create validate and update an energy plan. The energy plan is a set of instructions for a period of time e.g. an hour a shift a day a week etc. that is broadcast to other components of the energy management system for controlling energy consuming components within the system . The plan generator regularly updates the energy plan and sends the updated plan to the communication device . The manner in which the plan generator updates the energy plan will be discussed below in relation to .

Still referring to the communication device receives real time foot traffic data from a video counting device which can be a radio frequency identification device a sensor an imaging device any other counting device disclosed herein or known in the art or combinations thereof. While current foot traffic data may be collected by any of the systems disclosed herein in one embodiment the foot traffic data is collected by a camera based sensor located at entry and exit points of the site wherein the sensor has been tuned to record only the movements of persons entering and leaving the site. The camera based sensor includes onboard counting analytics that determine the number of persons in the space at any given time and a two way communication device that transmits the occupancy or foot traffic data to at least the communication device and a central database such as the database . The system of employing this sensor develops an energy management plan at predetermined time intervals that meets the cooling heating fresh air and lighting requirements for the actual number of people within the space. The predetermined time interval can be any amount of time but periods of between 15 60 minutes are likely to be used. In this embodiment the predetermined time interval is 15 minutes. The foot traffic data received from the video counting device as discussed above is transmitted to the plan generator .

The current or real time and forecast foot traffic data and current or real time and forecast weather data are provided on a store by store basis. The forecast traffic data may include a single numerical value that represents the forecast foot traffic data for each 15 minute period throughout the day and the real time traffic data may include a single number that represents the actual foot traffic for each 15 minute period throughout the day. For each predetermined time interval either a numerical value representing the actual foot traffic for that interval or an indicator that no data has been collected will be provided and stored. The weather data as discussed above is provided based on the zip code of each site.

The energy management system further includes an on site control device and a programmable thermostat wherein the counting device the on site control device and the programmable thermostat are located within the site in which energy must be managed and preferably each site to be managed includes these components. The on site control device receives the energy plan from the communication device and sends control signals based on the energy plan to the programmable thermostat and a lighting control unit . The programmable thermostat and the lighting control unit in turn send operating instructions to one or more rooftop Ethernet enabled HVAC units and one or more light fixtures respectively. The instructions sent to the HVAC unit s may include air temperatures air flow rates and or any other instructions for operating HVAC units. Once instructions are received by the HVAC unit the HVAC unit operates in the manner indicated by the instructions. Likewise the instructions sent to the light fixture s may include an instruction to activate or deactivate a light intensity and or any other instructions for operating light fixtures.

The HVAC unit may include a sensor or other device to detect an outside temperature. At the predetermined time intervals the HVAC unit transmits outside temperature information and an actual inside temperature based on a reading of the programmable thermostat to the on site control device which transmits the real time outside temperature data to the communication device . The communication device in turn transmits the real time outside temperature data to the plan generator . The real time outside temperature data is used for example to determine whether the outside air temperature is within a correct temperature range to execute the energy plan and or to modify the energy plan to account for variations in actual shopper traffic based on temperature and weather conditions i.e. rain snow etc. .

As can be seen in the energy management system may also include an online dashboard . The online dashboard extracts or receives data from the on site control device for example the energy plan the status of the system the operational status of each of the components of the system etc. and also extracts or receives data from an energy meter . The data is used to display on a computer tablet cell phone or other online device real time energy usage energy savings the operational status of the components of the system and any other features of the system that a user may desire to monitor and or view. The online dashboard may also allow a user to control the operation of the HVAC unit s and or light fixture s by overriding the energy plan for a period of time. Still optionally the online dashboard may identify malfunctioning equipment or other issues with the system . The online dashboard may be implemented within a computer program stored on a hard drive or other memory or may be accessible through a secure website. Alternatively the online dashboard may be accessible in any other manner known in the art. The online dashboard may be implemented for each individual site and or may be implemented for a number of different sites in a single dashboard e.g. a regional manager may have a single dashboard for viewing data related to all of the stores in his her particular region .

Still referring to once the necessary data has been read retrieved or received the processor generates an energy plan with optimal temperature and air flow profiles for the site s . The energy plan is created on a daily based but may alternatively be created at another interval for example on a weekly or monthly basis. The energy plan may also include at least one week of daily instructions at the predetermined time intervals during operating hours and 1 hour intervals after hours. Energy plans for each site may be created as data files and stored on the database for the particular site so that the file can be accessed and transmitted to the communication device associated with a corresponding site. Any time an energy plan is updated that energy plan is also stored in the database and may overwrite the previous energy plan . The instructions may include for example for an HVAC unit temperature settings with deviations and an amount of air flow allowed to flow through an HVAC damper. A sample set of instructions can be seen in . One skilled in the art will understand that the predetermined time intervals may be varied depending on the particular site or application.

The generation of the plan also includes a computation of occupancy and heating cooling delta values. Once the energy plan has been created the energy plan is transmitted at block to the communication device which then transmits the energy plan to the on site control device as described with respect to . The energy plan is also transmitted by the on site control device to the online dashboard for viewing by users at the site. On a continuous or intermittent e.g. every 15 minutes 1 hour 2 hours etc. basis the processor checks at block to see if foot traffic updates have been received. The interval at which updates are received by the plan generator may be pre defined or programmed. If updates have not been received the processor may loop through block until updates have been received. On the other hand if updates have been received at block the processor returns to block and the energy plan is updated accordingly. The processor then continuously loops through blocks and to update the energy plan when necessary. Although the processor is described as checking for updates at block the processor may alternatively automatically update the energy plan at block any time an update is received.

Various information may be extracted from the energy management system . A sample set of data that may be extracted is depicted in . The set of data may include a ShopperTrakOrg ID which is a site identification number for the data center a customer ID which is an identification number for the site a date a time a total number of people entering the property for that date and time a total number of people exiting the property for the date and time and a data indicator which is a letter code indicating whether the data is actual or inputted. Alternatively any other set of data may be extracted and or a user may select the data to be extracted.

While the energy management system is disclosed for use with one or more HVAC units and or one or more light fixtures the energy management system may optionally or additionally be used to manage other energy consuming devices such as fans appliances alarm systems and the like. The data necessary to obtain an energy plan for such devices may be obtained from one or more databases such as database or from other sources known in the art.

The invention is not limited by the embodiments disclosed herein and it will be appreciated that numerous modifications and embodiments may be devised by those skilled in the art. Therefore it is intended that the following claims cover all such embodiments and modifications that fall within the true spirit and scope of the present invention.

