---

title: Computer system with a cluster load balancer for graphics processing and graphics processing method thereof
abstract: A computer system and a graphics processing method with a cluster load balancer for graphics processing are provided. The computer system includes at least one physical machine (PM) and a graphics processing cluster. The at least one PM includes at least one virtual machine (VM) and a virtual machine manager (VMM). The graphics processing cluster includes graphics processing servers. Each of the graphics processing servers includes graphics processing units (GPUs). A main graphics processing server out of the graphics processing servers receives a graphics processing request provided by the VMM and the VM for assigning the graphics processing request to a minor graphics processing server out of the graphics processing servers. The minor graphics processing server provides a graphics processing result according to the graphics processing request and transmits the graphics processing result to the VM though the VMM.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183024&OS=09183024&RS=09183024
owner: Wistron Corporation
number: 09183024
owner_city: New Taipei
owner_country: TW
publication_date: 20130318
---
This application claims the priority benefit of Taiwan application serial no. 102103011 filed on Jan. 25 2013. The entirety of the above mentioned patent application is hereby incorporated by reference herein and made a part of this specification.

The disclosure relates to a computer network technique and more particularly relates to a computer system having a graphics processing cluster and a graphics processing method thereof.

With the popularity of mobile network and diversified developments of various network applications the server groups used in various cloud networks and data centers inevitably have to enhance their own performances to be able to handle the large demand of users. The service types of network applications may be roughly classified into processing services data access services and other kinds of common services.

In order to avoid wasting costs due to building too much hardware equipment and unnecessary power consumption the hardware equipment manufacturers of the cloud networks intend to dynamically adjust supply of each hardware resource according to the cloud computing amount of the users so that the servers may spread the load of the services by themselves. However since the users demand on the image quality and graphics processing of the cloud services gradually increases and the graphics computing procedure in each physical machine PM is only able to perform access and computing through the graphics processing unit GPU built in the physical machine the load relevant to the graphics processing cannot be transmitted to other servers to achieve load balance.

Therefore to improve the graphics processing function of each physical machine one can only keep buying new machine hardware and use multiple high performance GPUs that perform parallel computing to achieve the improvement. In addition not every kind of services requires high performance GPUs and thus the idle GPUs consume considerable power. Therefore the graphics processing services require a lot of operation costs of the manufacturers.

The disclosure provides a computer system and a graphics processing method thereof. The computer system makes graphics processing services of a virtual machine no longer be limited to hardware equipment of a local physical machine thereby reducing hardware limitation of the physical machine. Program coding of the virtual machine does not have to be revised and the hardware equipment may be expanded according to needs of the graphics processing services of the computer system thereby reducing costs.

The disclosure provides a computer system which includes at least one physical machine PM and a graphics processing cluster. The at least one PM includes at least one virtual machine VM and a virtual machine manager VMM . The graphics processing cluster includes a plurality of graphics processing servers. Each of the graphics processing servers includes a plurality of graphics processing units GPUs . A main graphics processing server out of the graphics processing servers receives a graphics processing request provided by the VMM and the VM for assigning the graphics processing request to a minor graphics processing server out of the graphics processing servers. The minor graphics processing server generates a graphics processing result according to the graphics processing request and transmits the graphics processing result to the VM though the VMM.

In an embodiment of the disclosure the main graphics processing server includes a cluster load balancer. The cluster load balancer keeps updating a load scale table and assigns the graphics processing request to the GPUs in the graphics processing servers according to the load scale table.

In an embodiment of the disclosure each of the graphics processing servers respectively includes a proxy and the proxy receives a graphics processing request from the cluster load balancer and assigns the graphics processing request to a corresponding GPU. When the graphics processing result is generated the proxy transmits the graphics processing result to the VM though the VMM.

In an embodiment of the disclosure the graphics processing servers respectively include a plurality of virtual graphics processing procedures. Each of the virtual graphics processing procedures respectively corresponds to each of the GPUs. Each of the virtual graphics processing procedures receives and records the graphics processing request from the proxy and transmits through a thin hypervisor the graphics processing request to a corresponding GPU to perform computing so as to generate the graphics processing result.

From another perspective the disclosure provides a graphics processing method of a computer system. The computer system includes at least one physical machine PM and a graphics processing cluster wherein the PM includes at least one virtual machine VM and a virtual machine manager VMM . The graphics processing method includes the following steps. A graphics processing request provided by the VMM and the VM is received. The graphics processing request is assigned to one of a plurality of graphics processing servers in a graphics processing cluster. A minor graphics processing server generates a graphics processing result according to the graphics processing request. The graphics processing result is transmitted to the VM though the VMM.

Based on the above the computer system disclosed in the embodiments of the disclosure revises a procedure flow of the VMM in the PM so that the graphics processing request of the VM does not use the GPU in the local PM directly but may selectively be performed through a graphics processing cluster in the network. In this way the graphics processing services of the VM is no longer limited to the hardware equipment of the local PM thereby reducing the hardware limitation of the PM. The program coding of the VM does not have to be revised and the hardware equipment may be expanded according to the needs of the graphics processing services of the computer system thereby reducing costs.

To make the above features and advantages of the invention more comprehensible embodiments accompanied with drawings are described in detail below.

Currently computer systems that provide network user services are all constructed by physical machines PM and virtual machines VM as a unit and software applications of each of the network users are communicated with one of the VMs and perform relevant services. is a schematic view of a physical machine PM . The PM may be embodied by a desktop computer or a server. The PM may also be called a virtual machine server. Each PM may operate at least one virtual machine VM . The PM further includes a virtual machine manager VMM an operating system a graphics driver program and a plurality of graphics processing units GPUs . In some embodiments the VMM may be a software procedure and operated in the operating system . In addition in some embodiments the VMM may be accessed directly from hardware.

Generally speaking when the VM requires hardware resources to perform computing or data access the VM informs the VMM . The VMM may also be called a hypervisor. The VMM appropriately assigns the hardware resources in the local PM to the VM that needs the hardware resources. For example one or more physical GPUs in the local PM are assigned to the VM that requires the GPUs through the operating system or direct access of the hardware and the graphics driver program so that the VM may use the physical GPUs assigned thereto directly to perform graphics processing services. However in this way each PM has to be disposed with sufficient GPUs to operate the VM that requires graphics processing services.

Herein the VM in the embodiments of the disclosure may transmit the graphics processing request to the graphics processing cluster for centralized treatment through the network and the adjusted VMM. The graphics processing cluster may assign a graphics processing server with better performance to perform the graphics processing request and relevant instructions provided by the VM and to transmit the graphics processing result to the corresponding VM to complete graphics processing. Therefore it is not necessary to dispose a plurality of high performance GPUs in each PM . The graphics processing cluster that performs centralized treatment of the graphics computing services may save power through various ways thereby spreading the load on the servers lowering power consumption reducing hardware limitation of the PM in operating the VM and allowing the hardware equipment exclusively for performing graphics processing to achieve the best performance. Embodiments that meet the spirits of the disclosure are described below as proof of the invention.

Generally speaking hardware resources of the VM are provided by the VMM and an application programming interface API in the VMM searches for a GPU in the local PM by default to perform computing. The present embodiment revises the VMM in the PM and adds a para virtualization aware graphics driver in the VM so that the API does not search for the GPU in the local PM directly but transmits a graphics processing request to the VMM and the VMM decides whether to use the GPU in the local PM or to use a graphics processing cluster at a remote end to perform the graphics processing request. In other words the VMM of the present embodiment may communicate with and transmit the graphics processing request to the graphics processing cluster through the network.

The graphics processing cluster includes a plurality of graphics processing servers to . Each of the graphics processing servers to respectively includes a plurality of GPUs to . In the embodiments of the invention each of the graphics processing servers to may have for example 16 GPUs at most. The number of the GPUs to illustrated in simply serves as an example. The graphics processing cluster is a set of the graphics processing servers to . The operating system or direct access of the hardware of the graphics processing servers to of the present embodiment performs a procedure called load balancers. These load balancers may communicate with one another and may select one of the graphics processing servers such as the graphics processing server as the main graphics processing server through various methods of judgment. The load balancer in the main graphics processing server is called a cluster load balancer or the load balancer may be the load balancing procedure performed in the operating system of the main graphics processing server. The other graphics processing servers such as the graphics processing servers and that are not selected serve as minor graphics processing servers wherein the load balancers therein are called minor load balancers. The above method of judgment may determine which one is the main graphics processing server based on information such as a processing performance and a network address of each of the graphics processing servers to . In some embodiments one of the graphics processing servers may be the main graphics processing server by default to perform functions of the cluster load balancer and the other graphics processing servers serve as the minor graphics processing servers and perform functions of the minor load balancers.

An appropriate example is described herein to illustrate the disclosure in detail. When a certain VM has to perform graphics processing the VM transmits a graphics processing request to the VMM of the local PM so as to gain hardware resources. When the VMM receives the graphics processing request of the VM the VMM computes a first load level about graphics processing resources in the local PM and then the VMM obtains an average load level of all the graphics processing servers to in the graphics processing cluster to determine if the graphics processing request is to be directly performed in the local PM or if it is better to perform this graphics processing request with the graphics processing cluster at remote network.

If the local PM has sufficient graphics processing resources or if the average load level of the remote graphics processing cluster is too high to accept other requests the VMM may use the resources of the PM directly to perform the graphics processing request. However if the local PM does not have graphics processing resources the VMM has to use the graphics processing cluster to perform graphics processing through the network. In some embodiments the VMM may directly transmit the graphics processing request to the graphics processing cluster after receiving the graphics processing request and should not be limited to the process disclosed above.

The graphics processing cluster has a uniform network address for external network equipment so that each VM and VMM are able to uniformly transmit the graphics processing requests to the main graphics processing server in the graphics processing cluster . When the VMM determines that the graphics processing request is performed by the graphics processing cluster the VMM transmits the graphics processing request to the uniform network address of the graphics processing cluster through network transmission. The network address is mainly controlled by the main graphics processing server . After receiving the graphics processing request the cluster load balancer of the main graphics processing server assigns this graphics processing request to a graphics processing server that is able to process this request such as a server with a lighter load or a server with a particular specification according to the load level of each of the graphics processing servers to in the graphics processing cluster . The VMM learns the assignment status of the main graphics processing server through the network and record the network address of the graphics processing server that is performing the graphics processing request and the serial number of the graphics processing unit that is actually performing the graphics processing request through ways of redirection settings so that the VM and the VMM may obtain the result after graphics processing through the network and the graphics processing server directly without through the main graphics processing server . In other words a minor graphics processing server that processes the graphics processing request may generate a graphics processing result according to the graphics processing request and transmits the graphics processing result to the VM that has transmitted this request through the VMM .

In the present embodiment the cluster load balancer of the main graphics processing server keeps updating a load scale table built therein thereby keeping learning changes in the load level of each of the graphics processing servers to . For example the cluster load balancer keeps transmitting a heartbeat signal to the load balancer or the load balancing procedure in each of the graphics processing servers to to monitor an operating status of the graphics processing servers to . The GPUs to of each of the graphics processing servers to also the status of acceptance of graphics processing requests or work requests at this time completion of the work requests load levels of the graphics processing servers to and so on so that the cluster load balancer may update the load scale table according to the respondence of the GPUs to . In this way the cluster load balancer assigns the graphics processing request to the plurality of GPUs to in the graphics processing servers to according to the load scale table. In detail the load scale table may include data of the following columns setting data of the graphics processing servers to the number and specification of the GPUs to in each of the graphics processing servers to the state of the graphics processing servers to and the state and or the weighted value of the GPUs to but the data are not limited to the above.

Furthermore the minor load balancers of the minor graphics processing servers to keep monitoring whether the cluster load balancer of the main graphics processing servers is operating. Some of the minor load balancers even backup the load scale table in the cluster load balancer. When the cluster load balancer stops operating the minor load balancers and other minor load balancers communicate with one another and one of the minor load balancers is selected as the cluster load balancer based on the above method of judgment. In this way when the cluster load balancer of the main graphics processing server fails to operate the situation that the entire graphics processing cluster thereby becomes invalid is avoided. In the present embodiment a plurality of GPUs of the same brand and specification may be disposed in certain graphics processing servers to so that when the VM processes the graphics processing request the VM may select the graphics processing servers to that performs the graphics processing request according to the particular brand such as Nvidia Corporation AMD Inc. or Intel Corporation and particular specification of the GPUs. In other words when the graphics processing procedure transmitted by the VM has been set to be performed by a GPU with a particular specification the cluster load balancer assigns a corresponding graphics processing sever and GPUs with the particular brand and particular specification of the GPUs to perform this graphics processing procedure according to the specification of the graphics processing servers to and GPUs to . The GPUs with some specification are able to optimize certain graphics processing procedures like some GPUs designed for 3D image processing engines or application software the VM may ask the particular graphics processing servers to to provide specific graphics processing services for the VM by inputting the brand and type of GPU that the VM intends to use. The method of selecting a certain server for service according to the brand and specification is the so called service level agreement.

The cluster load balancer of the main graphics processing server may perform power management according to actual usage requirements of the VM . When the VM has a lower usage requirement the cluster load balancer may reduce frequency of or directly disable some of the GPUs to not in use in the graphics processing servers to thereby lowering power consumption of each of the graphics processing servers to . In contrast when the VM has an increasing usage requirement and the GPUs to that are operating are all at a high load level the GPUs to that have been disabled or reduced in frequency are enabled or increased in frequency so as to maintain the operation of the graphics processing cluster .

If the actual usage requirement of the VM or the number of connections of the VM is too low or too high and it is necessary to turn on turn off the entire graphics processing servers to in the graphics processing cluster then a class interval method may be used to turn on turn off the graphics processing servers to . That is a class interval value is predetermined in the load scale table of the cluster load balancer and the class interval value is the number of user connections for which the VM may provide graphics processing services. When the number of user connections to the VM that is reduced i.e. the number of the users decreases every time is greater than the class interval value one of the graphics processing servers to may be turned off entirely to save power. In contrast when the number of the user connections to the VM that increases i.e. the number of the users increases every time is greater than the class interval value the one of the graphics processing servers to that have been turned off may be turned on entirely.

The proxy receives a graphics processing request assigned by the cluster load balancer in a main graphics processing unit and assigns the graphics processing request to the VGPUs to which the local GPUs correspond. Each of the VGPU receives and records the graphics processing request from the proxy and transmits through a thin hypervisor operated by an operating system the graphics processing request to a corresponding GPU to perform computing so as to generate the graphics processing result. When the local GPU that is assigned generates the graphics processing result the VGPU transmits the graphics processing result to the proxy and the proxy transmits the graphics processing result to the VM through the remote VMM . Furthermore after the graphics processing result is generated the VGPU may transmit a completion state of the work request to the cluster load balancer of the main graphics processing server and the cluster load balancer proceeds to update the load scale table. In addition it should be noted that even when the physical GPU is turned off and does not operate the VGPU still operates so as to indicate the current state and relevant information of the physical GPU 

The thin hypervisor performs a live task migration of the GPUs. In detail since the VGPU informs the cluster load balancer in the main graphics processing server of reception of the work request and completion of performance of the work request to update the load scale table the cluster load balancer may obtain the state of the graphics processing cluster in real time and computes the average load level of the graphics processing cluster .

The formula 1 for computing the load level such as the first load level of each of the graphics processing servers to is as follows 

Crepresents the number of connections of the VM that is connected in service in the Xgraphics processing server. Urepresents the weighted value of the GPUs in the Xgraphics processing server. VGrepresents the number of the idle VGPUs in the Xgraphics processing server. LBrepresents the load level of the Xgraphics processing server.

N represents the total number of the graphics processing servers to in the graphics processing cluster . Crepresents the total number of connections of the VM that is connected in service in all the graphics processing servers to . Urepresents the average weighted value of the GPUs in all the graphics processing servers to . VGrepresents the total number of the idle VGPUs in all the graphics processing servers to . LBrepresents the average load level in the graphics processing cluster . The smaller the value of is the lower the load level is.

When the average load level is too low lower than 0.4 for example the cluster load balancer examines the load level of each of the graphics processing servers one by one assigns work of the graphics processing server with the lowest load level to other graphics processing servers that may take this load takes a snap shot of the current relevant information such as an operation status calculation parameters and sources of instructions of the VM that is temporarily suspended from operation with the thin hypervisor and transmits the current relevant information to GPUs inside other graphics processing servers through the network according to instructions of the cluster load balancer. When other graphics processing servers finish receiving the current relevant information the graphics processing server with the lowest load level is turned off and transmits information to the cluster load balancer to update the load scale table.

From another perspective the embodiment of the disclosure further provides a graphics processing method of a computer system. is a flowchart of a graphics processing method of a computer system according to an embodiment of the invention. Referring to the computer system includes at least one physical machine PM and a graphics processing cluster wherein the PM includes at least one virtual machine VM and a virtual machine manager VMM . In Step S the cluster load balancer in the main graphics processing server receives the graphics processing request provided by the VMM and the VM . In Step S the graphics processing request is assigned to a minor graphics processing server among a plurality of graphics processing servers in the graphics processing cluster . In Step S the minor graphics processing server generates a graphics processing result according to the graphics processing request. In addition in Step S the graphics processing result is transmitted to the corresponding VM through the minor graphics processing servers and the VMM . For other detailed steps and processes of the graphics processing method of the computer system and a hardware structure of the computer system please refer to the above embodiments and details thereof are omitted herein.

In summary of the above the computer system disclosed in the embodiments of the disclosure revises a procedure flow of the VMM in the PM so that the graphics processing request of the VM does not use the GPU in the local PM directly but may selectively be executed through a graphics processing cluster in the network. In this way the graphics processing services of the VM is no longer limited to the hardware equipment of the local PM thereby reducing the hardware limitation of the PM. Program coding of the VM does not have to be revised and the hardware equipment may be expanded according to the needs of the graphics processing services of the computer system thereby reducing costs.

Although the invention has been described with reference to the above embodiments it will be apparent to one of ordinary skill in the art that variations and modifications to the invention may be made without departing from the spirit and scope of the invention. Accordingly the scope of the invention will be defined by the attached claims.

