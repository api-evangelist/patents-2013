---

title: System and method for providing arbitrary protection topologies in a computing cluster
abstract: Methods and systems for a computing cluster are provided. An application programming interface (API) at a manager application is exposed. The API specifies input identifying nodes and connections between the nodes to implement storage protection policies in the computing cluster. A user input that includes instructions to implement multiple destination nodes and respective connections between a source node and the destination nodes is received. A topology that includes the source node, the destination nodes, and the connections between the source node and the destination nodes is traversed. Based on traversing the topology, commands are sent to a storage system of the cluster to implement a destination volume corresponding to the destination node and multiple protection configurations. Each of the protection configurations corresponds to a respective one of the connections.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09389797&OS=09389797&RS=09389797
owner: NETAPP, INC.
number: 09389797
owner_city: Sunnyvale
owner_country: US
publication_date: 20130726
---
The present disclosure relates generally to computing system clusters and more particularly to providing for arbitrary protection topologies in such clusters.

As computing and storage solutions become more distributed in nature the cluster architectures may offer a variety of protection configuration possibilities. For instance a primary storage volume e.g. a logical volume within a network storage system may be backed up by a mirror or vault implemented by a secondary volume. In fact the primary volume may be backed up by more than one secondary volume in a fan out configuration. Additionally some systems may allow for further backup of any of the secondary volumes by one or more tertiary volumes. Thus as systems get more sophisticated and as cluster architectures get more advanced the possibilities for protection configurations grows.

A particular conventional storage management system provides a user with several different pre set protection configurations from which to choose. For instance one conventional storage management system allows for a user to choose a fan out arrangement where a primary storage volume is mirrored in parallel to two secondary volumes. However such conventional system does not provide for a three way fan out or four way fan out. During a setup process an administrator chooses from the fixed number of options of protection configurations. The administrator inputs the choice and a management application implements the protection configuration by communicating commands with one or more storage controllers. The storage controllers implementing a storage operating system receive the commands and provide low level control of the physical storage drives to provide virtualized storage according to the chosen configuration option.

Accordingly it would be desirable to provide improved methods and systems for managing the protection configuration options at a storage management system.

In the following description specific details are set forth describing some embodiments consistent with the present disclosure. It will be apparent however to one skilled in the art that some embodiments may be practiced without some or all of these specific details. The specific embodiments disclosed herein are meant to be illustrative but not limiting. One skilled in the art may realize other elements that although not specifically described here are within the scope and the spirit of this disclosure. In addition to avoid unnecessary repetition one or more features shown and described in association with one embodiment may be incorporated into other embodiments unless specifically described otherwise or if the one or more features would make an embodiment non functional.

Various embodiments of the present disclosure provide for techniques that allow a user to configure protection topologies arbitrarily for a clustered storage systems. The storage management domain includes a storage management server and at least one storage subsystem. The storage subsystem includes a storage controller and an array of storage drives e.g. hard disk drives or solid state drives . The storage controller implements lower level control over the storage array to provide for virtualized storage. The storage management server communicates with the storage controllers and with one or more clients where the storage server provides for administrative control over the storage subsystem

Administrative control over the storage subsystem is facilitated by a manager program that runs on the storage management server. The manager program includes a utility that receives user input to provision volumes and set up protection configurations within the storage subsystem. In one example the manager program communicates with a backup application where the backup application is used by an administrator to specify a protection configuration for the system. The administrator provides input at a UI of the backup application to define nodes and connections between the nodes where the nodes and connections are a conceptual way to identify a desired topology.

Continuing with the example the nodes represent storage volumes in the storage subsystem. For example a node may include a primary virtual volume a secondary volume a tertiary volume etc. Connections between the nodes indicate relationships of one node to another. For instance a connection may specify whether a node is a mirror or a vault to back up a primary volume. Connections may also include other relationship information such as backup scheduling and the like. Connections and nodes are discussed in more detail below with respect to .

The manager application exposes Application Programming Interfaces APIs that define how information from the backup application is communicated to the manager program. In this example the APIs exposed by the manager program receive input from the backup application at a node by node and connection by connection level. Thus the administrator at a User Interface UI of the backup application can specify protection configurations by adding nodes and connections in an arbitrary manner.

The manager program receives the input from the Backup Application as defined by the APIs. The manager program then traverses the tree formed by the nodes and connections and translates the node and connection input into volume provisioning and storage policy operations for use at the storage controller. The manager program then communicates the volume provisioning and storage policy operations to the storage controller. The storage controller then provides storage subsystem level control to implement the protection configuration at the storage drives.

Various embodiments provide one or more advantages over conventional systems. For instance the ability to construct properties of protection at a level of singular nodes and singular connections allows for the creation of arbitrary protection topologies. Conventional systems by contrast select from a menu of pre set protection topologies. Thus the user is given more flexibility in determining types of protection to use.

Additionally the APIs discussed below which allow for the presentation of topology information on a node by node and connection by connection level of granularity provide for flexibility in design options. Specifically the APIs exposed by the manager program can be used by any given backup application that is designed with those APIs in mind. Thus a suite of storage cluster hardware and software is not limited to any particular backup application but instead may be paired with an appropriate backup application that can communicate topology input according to the APIs.

While the example above is discussed with respect to setup of a storage system it should be noted that the scope of embodiments is not so limited. Various embodiments are applicable to a setup process that includes defining nodes and connections before the system has initiated normal operations. However after an initial setup it may be possible to add further primary volumes and various embodiments are also applicable to set up new primary volumes and associated backup protections. Also various systems may allow for the modification of a previously defined protection configuration and embodiments of the present disclosure may also be used in those instances to modify or replace existing protection configurations.

Each storage device may include storage objects comprising one or more storage volumes where each volume has a file system implemented on the volume. A file system implemented on the storage devices may provide multiple directories in a single volume each directory containing various filenames. A file system provides a logical representation of how data files are organized on a volume where data files are represented as filenames that are organized into one or more directories. Examples of common file systems include New Technology File System NTFS File Allocation Table FAT Hierarchical File System HFS Universal Storage Device Format UDF Unix . file system and the like. For the Data ONTAP storage operating system available from NetApp Inc. of Sunnyvale Calif. which may implement a Write Anywhere File Layout WAFL file system there is typically a WAFL file system within each volume and within a WAFL file system there may be one or more logical units LUs . The scope of embodiments is not limited to any particular storage operating system or file system.

Continuing with the example to facilitate access to the disks the storage operating system implements a write anywhere file system of a virtualization system that virtualizes the storage space provided by storage drives . The file system logically organizes the information as a hierarchical structure of named directory and file objects on the storage drives . Each on disk file may be implemented as set of blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization system allows the file system to further logically organize information as a hierarchical structure of named virtual disks vdisks on the storage drives thereby providing an integrated NAS and SAN storage system approach to storage by enabling file based NAS access to the named files and directories while further enabling block based SAN access to the named vdisks on a file system based storage platform. The file system simplifies the complexity of management of the underlying physical storage in SAN deployments.

Client system includes a computer system that interacts with server system for submitting read write access requests and for receiving or transmitting data from or to the server system over the network . In a virtual server environment a client system may interact over the network with one or more virtual machines VMs executing on a server system for submitting read write access requests and for receiving or transmitting data from or to the storage system over the network .

Server system includes a computer system that executes applications and interacts with the client system for receiving read write access requests and receiving or transmitting data from or to the client system over the network . Server system in this example is connected to the client system over a network such as a local area network LAN an Ethernet subnet a PCI or PCIe subnet a switched PCIe subnet a wide area network WAN a metropolitan area network MAN the Internet or the like.

The server may include any appropriate computer hardware and software. In one example server includes a general purpose computer configured to execute any of a variety of operating systems including the Unix Linux and Microsoft Windows operating systems.

Various embodiments may be implemented in a Network Attached Storage NAS system and in a Storage Area Network SAN system. Server systems generally utilize file based access protocols when accessing information in the form of files and directories over a NAS based network. In such an example server may request the services of the storage cluster by issuing file access protocol messages in the form of packets to the storage cluster over the network . For example a server running the Windows operating system may communicate with the storage cluster using the Common Internet File System CIFS protocol. On the other hand a server running the Unix operating system may communicate with the multi protocol storage system using the Network File System NFS protocol over TCP IP . The scope of embodiments is not limited to any particular operating system for server nor to any particular file access protocols.

Server may utilize block based access protocols such as the Small Computer Systems Interface SCSI protocol when accessing information in the form of blocks storage drives or vdisks over a SAN based network. SCSI is an input output I O interface with a standard device independent protocol that allows different peripheral devices such as disks to attach to the storage subsystems . In SCSI terminology server operating in a SAN environment is an initiator that initiates requests and commands for data. A given storage system is thus a target configured to respond to the requests issued by the initiator in accordance with a request response protocol. The initiator and targets have endpoint addresses that in accordance with the Fibre Channel FC protocol include worldwide names WWN . A WWN includes a unique identifier e.g. a node name or a port name consisting of an 8 byte number.

Server system includes hypervisor which creates and manages one or more Virtual Machines VMs in this case VM . The present example shows only a single VM though in other embodiments the server includes multiple VMs not shown each VM being used by and connected with a client through a computer network. Thus systems with more than one client may include more than one VM each client being supported by at least one VM. VM includes an encapsulation or instance of an operating system and applications running executing on top of that instance. Briefly application provides read write access to the clients to data stored in cluster . Application provides a backup application for creating and managing protection configurations within cluster . Application is a manager application that communicates with application to receive input regarding protection topologies and to implement those topologies in cluster . The applications and are discussed in more detail below with respect to .

In some embodiments different types of VM hypervisors may be used e.g. VMware ESX Microsoft Hyper V etc. . Each different type of VM hypervisor may produce a different type of VM using a different type of virtual storage component. In particular a first VM produced by a first type of VM manager e.g. VMware ESX may have different attributes than a second VM produced by a second type of VM manager e.g. VMware Microsoft Hyper V . As such the attributes of a VM may differ depending on the type of VM hypervisor used to produce the VM. In addition a first set of virtual storage components allocated to the first VM may have different attributes than a second set of virtual storage components allocated to the second VM. As such the organization and mapping of a VM to its virtual storage components on the server to its underlying storage objects on the cluster may differ depending on the type of VM hypervisor used to produce the VM and virtual storage components. The scope of embodiments is not limited to any particular type of hypervisor.

Each storage system is configured to allow server to access its data for example to read or write data to the storage system. The server executes application that connects to storage systems over computer network to send an access request read or write request to storage system for accessing particular data stored on the storage system . The VM application executing on the server services the connected client by receiving the client access requests and submitting the access requests to the storage system for execution.

The scope of embodiments is not limited to the particular architecture of system . For instance other systems may include additional servers each server being similar to server . While the example of shows only one client it is understood that any appropriate number of clients may be supported by the system . Moreover while cluster shows two storage subsystems and it is understood that any appropriate number of controllers and storage drive arrays may be used with various embodiments. For instance some embodiments may include only a single storage subsystem whereas other embodiments may include three or more storage subsystems. In other words the scope of embodiments is not limited to a single storage cluster. A topology may span multiple clusters and define relationships both within a cluster and between clusters. In one example a topology defines a mirror within the same cluster for fast restore and a fan out mirror to a remote cluster for disaster recovery.

It is noted that UI may include a command line interface a graphical user interface GUI or other appropriate interface. It is further noted that the feature of the application to receive information from the application at a node by node and connection by connection level of granularity provides for UI to also receive input from a user at a similar level of granularity in some embodiments. Application exposes APIs to application where the APIs specify how application should present protection topology information to application . In one example an administrator desires to create a storage system with one primary source node four secondary destination nodes and one tertiary destination node as shown in . The input received by the application from application to implement such topology may include e.g. 

A collection of nodes and connections can be conceptually referred to as a tree as the branching structure of is reminiscent of a tree. However various embodiments are not limited to topologies that fan out as any appropriate protection topology may be used. The scope of embodiments is not limited to any particular API though example APIs for some embodiments include the following. The storage service create API takes as input a storage service topology information element consisting of a set of storage service node information and storage service connection information elements each specifying the properties specific to the nodes and connections of the topology. Internal to the storage management server this information is represented and persisted as a storage service object consisting of node and connection objects. Other APIs provide for managing the storage services such as listing their attributes modification and deletion. Still other APIs provide the client application the ability to subscribe volumes to the service for protection. Once subscribed the storage service conform API causes the storage management application to traverse the tree defined in the storage service and configure the storage subsystem to conform to the properties specified in the nodes and connections e.g. to provision secondary and tertiary volumes and the mirror and backup vault relationships.

Returning to application also uses a different set of APIs to communicate with cluster . Upon receiving the input from the application where the input specifies nodes and connections therebetween application traverses the tree and translates the node and connection information into volume provisioning and mirror create commands to send to the clustered storage operating system of cluster . Specifically the node information that is received from application indicates storage volumes to be created and the connection information indicates the protection configuration particulars of the relationships between the nodes. As application traverses the tree it translates the generic nodes into particular source and destination volumes to be implemented within the physical storage drives of cluster . Similarly the application translates the connections into the particular policies and operations that specify how a particular destination volume backs up a particular source volume. Different rules or business logic gets invoked depending on the node connection properties. Intelligence within application chooses particular operations from a library of storage operating system commands to implement the protection topology in cluster .

Volume provisioning commands include commands to create source and destination volumes size specifications of the volumes selection of storage drive arrays on which to implement the volumes and the like. Mirror create commands include specifications of relationship type with respect to the primary volume e.g. mirror or vault backup scheduling bandwidth use throttling various use policies and the like. According to one embodiment when traversing the tree application selects appropriate volume provisioning and mirror create commands from a library. Application then sends the commands to storage subsystems to cause storage subsystems to create the volumes and implement the protection procedures. Table 1 below provides some example commands in the Data ONTAP storage operating system that may be included in a library of commands for use by application . However as noted above the scope of embodiments is not limited to any particular storage operating system.

Block includes exposing an API at a manager application. The API specifies input of nodes and connections between the nodes to implement storage protection policies in the computing cluster. The manager application runs on a server in a computing system having a management domain. An example of the application includes application and an example of a computing system includes system of which has server and multiple storage subsystems acting together to provide storage for clients .

Block includes receiving user input to the manager application according to the API. The user input includes instructions to implement multiple destination nodes and respective connections between a source node and the multiple destination nodes. As explained above the nodes are an abstraction that represent volumes that are created or will be created in one or more storage subsystems. Also as explained above the connections include protection relationships with respect to the storage volumes represented by the nodes. Further in this example the protection topology is a more complex topology that includes multiple destination nodes.

The user input of block is received at the manager application at a level of specificity that includes the source node the multiple destination nodes and the connections between the source node and the destination nodes. The input received at the manager application may also include additional nodes and connections but the input itself is received at a node by node and connection by connection level of specificity. Thus a protection configuration of multiple nodes and at least one connection is described with reference to the individual nodes and individual connections. Furthermore the input regarding the individual nodes includes information regarding properties e.g. types of the nodes and the input regarding connections includes properties of those connections e.g. specific backup properties so that the manager application itself makes few if any assumptions about the topology Such feature may allow the input from the interface application to the manager application to specify any of a variety of configurations that can be described by an arbitrary number of nodes and the connections therebetween. Of course various applications may place a limit on the number of nodes and connections that are supported as a function of e.g. computing power and available size and type of storage subsystems.

An example of configuration information that may be passed from the UI to the manager application includes the information described above with respect to . Furthermore existing protection configurations can be scaled up or scaled down on a node by node basis in some examples. The action of block is provided in contrast to conventional systems that allow a user to select from a variety of pre set protection configurations where the input from the UI to the manager application is not amenable to a node by node or connection by connection breakdown.

Block includes traversing a topology that includes the source node the multiple destination nodes and the connections between the source node and the multiple destination nodes. As noted above the topology may be referred to as a tree whether or not the tree has many branches. Block includes programmatically examining the nodes and connections. The manager application then determines storage volumes to be created based upon the nodes and protection procedures and policies with respect to those volumes based upon the connections.

Block may also include examining a library of storage operating system commands and selecting ones from the library that are appropriate to implement the storage volumes and protection procedures within the storage subsystems.

Block includes sending commands to a storage system of the cluster to implement the multiple destination volumes corresponding to the destination nodes and a protection configuration corresponding to the connection. Block may also include sending a command to implement the source volume in systems in which the source volume has not yet been created. This is in contrast to some systems in which the source volume is created first and protection configurations are created later.

The scope of embodiments is not limited to the actions shown in . Other embodiments may add omit rearrange or modify one or more actions as appropriate. For instance some embodiments may include storing protection configuration metadata in the manager application for later retrieval or modification.

It should be noted that the examples above are given in the context of a network storage system through the scope of embodiments is not so limited. Rather the concepts described above may be implemented in any type of computing cluster wherein policies may be set with reference to different nodes in the cluster. One example embodiment includes a cluster of servers where the servers have different responsibilities e.g. primary and backup . In such embodiment block may include nodes that represent the different servers in the cluster and connections that represent the responsibility relationships among the servers. Method would then use the nodes and connections in the input to implement the server responsibilities within the cluster.

At block the backup application receives user input specifying a protection configuration. The user input may be received via a GUI a command line or other type of interface.

Block includes transmitting user input to the manager application according to an API exposed by the manager application where the user input includes instructions to implement multiple destination nodes and respective connections between a source node and the destination nodes. For instance block may include transmitting the user input as the user input is described above with respect to block of .

Block or block may include translating the user input into another format consistent with that specified by the API if appropriate. For instance in one example the UI is a GUI that allows a user to build a tree by arranging nodes and connections graphically and block may include translating the layout of nodes into a format compatible with the API.

It should also be noted that the actions of may be applied to any computing cluster not just clusters that provide storage. Thus in one example the user input specifies relationships among servers in a computing cluster.

When implemented via computer executable instructions various elements of embodiments of the present disclosure are in essence the software code defining the operations of such various elements. The executable instructions or software code may be obtained from a non transient tangible readable medium e.g. a hard drive media optical media RAM EPROM EEPROM tape media cartridge media flash memory ROM memory stick network storage device and or the like . In fact readable media can include any medium that can store information.

In the embodiments described above example clients server and storage controllers include processor based devices and may include general purpose processors or specially adapted processors e.g. an Application Specific Integrated Circuit . Such processor based devices may include or otherwise access the non transient tangible machine readable media to read and execute the code. By executing the code the one or more processors perform the actions of methods and or as described above.

Although illustrative embodiments have been shown and described a wide range of modification change and substitution is contemplated in the foregoing disclosure and in some instances some features of the embodiments may be employed without a corresponding use of other features. One of ordinary skill in the art would recognize many variations alternatives and modifications. Thus the scope of the invention should be limited only by the following claims and it is appropriate that the claims be construed broadly and in a manner consistent with the scope of the embodiments disclosed herein.

