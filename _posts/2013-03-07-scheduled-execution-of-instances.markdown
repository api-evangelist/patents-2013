---

title: Scheduled execution of instances
abstract: Techniques are disclosed for a client-and-server architecture where the client makes scheduled execution of instances to the server. The server may then launch occurrences as indicated by one of these API calls at each of the scheduled times. The server may also implement operations to selectively execute particular occurrences, such as executing a new occurrence only when no other occurrences are still running. In other embodiments, the server may implement pricing information in a determination of whether to execute a particular occurrence.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09521188&OS=09521188&RS=09521188
owner: Amazon Technologies, Inc.
number: 09521188
owner_city: Seattle
owner_country: US
publication_date: 20130307
---
An application programming interface API is a specification that sets forth routines that may be invoked and how those routines may be invoked. Calls to a particular API may then be used to effectuate the performance of certain actions. For instance a client computer and a server computer may be communicatively coupled via a network and the client may send the server calls in an API that the server implements. In turn the server may receive these calls and perform the associated processing.

This document describes techniques for scheduling execution of an instance as well as other actions among various embodiments. For example the instance may be a virtual machine instance or an instance that runs on bare hardware without use of a hypervisor. In an example embodiment a computing service may receive a request from a user that specifies an action e.g. to run an instance and a schedule to execute that action e.g. at 12 30 am each day . In response to this request the computing service may determine that a time at which the instance is scheduled to run has been reached e.g. it is 12 30 am on some day and then determine whether other requirements are met. For instance a requirement may be that only one of these instances may run at a time that no more than a threshold number of these instances may run at a time that no more than a threshold number of instances have run within a recent period of time or that a current cost of running the instance is below a maximum allowed cost.

In other embodiments history information about how previous instances have run may be used to determine the requirements for running the present instance. For example it may be that these instances function as black boxes that it may be determined that they are running but it may not be determined whether they are still progressing towards successful completion. In such cases history information about for how long instances run may be used to determine how long it normally takes for an instance to successfully complete. Then where the present instance runs for significantly longer than what is normal it may be considered to have failed and be terminated.

Embodiments of the present disclosure are directed to techniques for allowing interaction with a web service such as a data storage service or a computing service. For example a computing service that offers processing through the use of instances and data storage services is accessible through one or more application programming interfaces APIs that is usable by requestors of the computing service to access various capabilities of the computing service. Requestors may for instance use the one or more APIs to store data retrieve stored data or run instances such as to process data or to perform other operations.

In an embodiment one or more APIs of a computing service allow users to upload or select virtual machine volumes from a catalog start and execute instances of these virtual machine volumes and take snapshots of these virtual machine volumes. An API call may for example include a location where the virtual machine volume is to be uploaded from along with parameters for its storage.

A customer may request the performance of any of the above operations by sending API requests to the computing service. Similarly the computing service may provide responses to customer requests. Such requests and responses may be submitted over any suitable communications protocol such as Hypertext Transfer Protocol HTTP File Transfer Protocol FTP and the like in any suitable format such as Representational State Transfer REST Simple Object Access Protocol SOAP and the like. The requests and responses may be encoded for example using Base 64 encoding encrypted with a cryptographic key or the like.

The following is an example API call and response to determine the status of two virtual machine instances i 43a4412a and i 23a3397d. An API call may be made via a HTTPS hypertext transfer protocol secure protocol using a URL uniform resource locator as follows 

https example website .com Action MonitorInstances InstanceId.1 i 43a4412a InstanceId.2 i 23a3397d AUTHPARAMS

This request enables the monitoring of the status of a running virtual machine instance. The request may identify an endpoint of the service to which the API call is directed example website .com the type of API call that is requested Monitorinstances and an identifier of the two instances for which monitoring is requested i 43a4412a and 23a3397d . The type of API call that is requested as well as the identifier of the two instances for which monitoring is requested are contained within a query string in the URL the portion to the right of the in the URL. A server that receives such a URL may run a program and pass the query string to the program for processing.

After performing processing in accordance with the query string the server may return a result to the requestor. The following is an example result that the server may return to the requestor 

As depicted the result is formatted in XML extensible markup language a markup language that defines a set of rules for encoding documents in a format that is both human readable and machine readable. The first line of the response identifies the type of response MonitorInstancesResponse and defines the namespace for the XML file xmlns http example website .com doc 2012 08 15 . A namespace is generally an identifier that allows for the disambiguation of homonym identifiers. A tag and associated value identifies the request being responded to 59dbff89 35bd 4eac 99ed be587EXAMPLE . This may enable the requestor to distinguish between responses where the requestor makes multiple Monitorinstances requests. Then there is a section that identifies each instance e.g. i 43a4412a along with an associated state of that instance pending .

Given this architecture when client issues requests to external facing server to start a virtual machine instance external facing server may issue instructions to instance manager and instance manager may select host to host the virtual machine. For instance external facing server may receive a request to launch an instance and route the request to instance manager to start a virtual machine instance. After instance manager selects a host to host the virtual machine instance e.g. host instance manager may issue a request to host to launch the virtual machine instance.

In this manner client may send external facing server an API call specifying an action such as a launch instance command along with a schedule and instance manager and the instance manager may perform the action at the times indicated by the API call without additional input from client .

That is embodiments may include using separate services to carry out functions like launching instances and generating snapshots within a service provider environment. More generally as well as the other figures depicts simplified embodiments to illustrate concepts and specific implementations may vary.

In embodiments the procedures for scheduled execution of instances may be implemented on external facing server instance manager host or a combination of those computers. For instance external facing server may receive an API call to schedule an action from client and store an indication of the call such as an action to perform and the schedule at which to perform it in database . Then external facing server may send an indication to instance manager to check database for this indication of the call and instance manager performs the operations to perform instances of the call. In other embodiments instance manager may periodically check database for indications of calls that have been stored there by external facing server and instance manager may then discover new calls to perform without being directly informed of these new calls by external facing server .

As used herein identifying particular instances of an object or thing as being first or second is not intended to limit the number of those instances or to imply that the one marked as being the first one is the first instance that has occurred. Rather these terms are used to distinguish instances from each other. Additionally it is written that occurrences of actions are performed. Where the same action is being performed multiple times e.g. start an instance every hour an occurrence of an action is used to refer to one time that this action is performed.

Another example of scheduled execution of instances would be to start up and tear down entire cloud computing systems. For example a business may not just use one instance or even multiple instances operating independently. A business may use multiple instances operating in concert. In such a situation a business s instances may be started just before the start of the business day and the business s instances may be shut down at the close of the business day. This may be more broadly extended to forming cloud computing resources at a scheduled time where the resources work with each other e.g. one instance performs a federation services role one instance performs a login role and one instance performs a mail server role and accessing the mail server involves coordinated action from all three instances. Such embodiments are described in more detail with reference to below.

The operating procedures of begin with operation which depicts receiving a request. In embodiments an API call may be received from a client computer such as client of . In a conventional manner the client would send an API call each time the client desires that the API call be implemented. In contrast in the client may send one API call that identifies multiple times at which an associated action is to be processed.

In embodiments an API call comprises a hypertext transfer protocol HTTP or hypertext transfer protocol secure HTTPS uniform resource locator URL e.g. https example website .com Action RunInstances ImageId i 43a4412a MaxCount 1 MinCount 1 AUTHPARAMS. In embodiments a parameter of such an asynchronous API call is found within the query string of that URL the portion of that URL to the right of the . In addition in embodiments of the disclosure information such as the schedule to perform the action may also be contained within the query string of the URL.

After operation the process flow moves to operation which depicts determining whether a first time indicated in the schedule has been reached. Determining whether the first time has been reached may involve for example executing a process that keeps track of both the current time when the first time is and compares the two to determine if the current time has exceeded the first time. For example when the API call indicates that the associated action should be processed once per hour this first time may be one hour after that API call is received. In an embodiment after the external facing server receives the request a record can be created in database that includes the information that the computing service uses to launch the instance according to the schedule for example the record could identify the action e.g. run instance the schedule the customer ID that submitted the request instance identifiers for the request the authorization parameters for the request etc. The instance manager can periodically access the database and read the record. If this first time of the period time has not yet been reached then the process flow waits at operation until this first time has been reached. If this first time of the period of time has been reached then the process flow moves to operation .

Operation depicts starting a first occurrence of the action. This may comprise performing the action as indicated in the API call. For instance the API call may identify the action as starting an instance which once started will perform some operations before terminating. Where this is the case operation may comprise starting an instance as indicated by the API call. For example the instance manager can read the record and determine the parameters for launching the virtual machine. The instance manager can select a server to host the virtual machine and send a RunInstance command to the selected host. In response to the command the host can launch the instance.

After a first occurrence of the action has been started in operation the process flow moves to operation which depicts determining whether a second time specified by the schedule has been reached. Operation may be implemented in a manner similar to how operation is implemented. Continuing with the example of the action being scheduled to be processed every hour the first time may be one hour after the API call is received and the second time may be one hour after the first time or two hours after the API call is received. If this second time has not yet been reached then the process flow waits at operation until this second time has been reached. If this second time of the period of time has been reached then the process flow moves to operation .

Turning now to operation while there are generally embodiments that implement fewer operations than are depicted in in particular operation as well as operations and may be considered optional operations and are indicated as such within by being represented via dashed lines. Operation depicts determining whether the first occurrence of the action is still running. For instance where performing the first occurrence of the action comprises executing a process such as an instance operation may comprise determining whether this process is still executing. Operation may be implemented in embodiments where there is to be a limit of how many occurrences of a given action are allowed to be performed concurrently. It may be that there is a desire by the client to limit the number of occurrences of an action running concurrently because multiple occurrences may read to and write from the same data and their concurrent execution may cause inconsistent state problems. It may also be that there is a desire by the client to limit the number of occurrences of an action running because running each action costs money and the client is operating on a budget. If the first occurrence of the action is still running then the process flow moves to operation where the process flow ends. If the first occurrence of the action is no longer running then the process flow moves to operation .

Operation depicts determining whether the number of occurrences currently running is below a maximum number of occurrences allowed to run concurrently. For instance for budget reasons similar to those stated for operation the client may specify the maximum number of concurrently running occurrences at 3. Where there are only two concurrently running instances when the second time is reached then another occurrence of the action may be begun. Where there are three or more concurrently running instances when the second time is reached then another occurrence of the action may not be begun even though the second time has been reached. If the number of occurrences currently running is not below a maximum number of occurrences allowed to run concurrently then the process flow moves to operation where the process flow ends. If the number of occurrences currently running is not below a maximum number of occurrences allowed to run concurrently then the process flow moves to operation .

Operation may be more generally expressed as consulting a policy to determine whether to start the second occurrence of the action beyond merely determining that the time to start the second occurrence of the action has been reached. In this sense then determining whether the number of occurrences currently running is below a maximum number of occurrences allowed to run concurrently is a case where the policy specifies the maximum number of occurrences that are allowed to run concurrently. Other policies may include whether any other occurrence of the action is still running e.g. where the maximum number of occurrences that are allowed to run concurrently is one whether the most recently started occurrence is still running though previously started occurrences may still be running whether a budget has been exceeded where there is a charge associated with performing occurrences of the action whether it is likely that a budget will be exceeded in performing this occurrence of the action and whether it is likely that this occurrence of the action will be completed within a given amount of time.

Another example of a policy incorporates pricing information as described in more detail with respect to . There may be a spot market where customers can bid on computing resources and be able to use those resources as long as their bid exceeds the current spot price. The spot price may vary over time such as based on supply of and or demand for those computing resources. There may also be the option to execute occurrences of an action on demand where computing capacity is guaranteed at a set time without regard to the spot market. In embodiments the on demand price may be generally higher than the spot market price since the on demand price guarantees access to computing resources while the spot market price does not because the customer s bid may not be sufficient to secure those resources . In this case the policy may be to attempt to secure computing resources to perform an occurrence of the action on the spot market and if that fails fall back on using on demand resources.

Operation depicts starting a second occurrence of the action. Operation may be implemented in a similar manner as operation starting the first occurrence of the action is implemented.

After operation the process flow moves to operation where it is determined if a maximum time for the second occurrence of the action to run has been reached. It may be that it is difficult to determine directly whether an occurrence of an action has been successfully completed. For instance where the action involves starting an instance that performs various operations it may be possible to determine whether the instance is functioning but not whether those various operations performed within the instance have been successfully performed. In the absence of this direct information about whether the occurrence has been successfully completed an amount of time that the occurrence has run for may be used as indirect information about the success of the occurrence. For instance a client may indicate that no action should run for more than 30 minutes because the action almost always completes successfully before 30 minutes of running. Here the maximum time for the second occurrence of the action and other occurrences of the action to run may be set at 30 minutes and when 30 minutes passes since the starting of the second occurrence of the action that occurrence may be determined to have failed and the occurrence should be terminated.

In other embodiments the user that sent the API call may specify a time to live TTL value in the call which indicates how long an occurrence of an instance may run before it is to be terminated. Determining whether the maximum time has been reached in operation may comprise determining whether this TTL value has been exceeded by the amount of time the occurrence of the instance has run.

If the maximum time for the second occurrence of the action to run has not been reached then the process flow moves to operation where the process flow ends. If the maximum time for the second occurrence of the action to run has been reached then the process flow moves to operation .

Operation depicts ending the second occurrence of the action. In other embodiments rather than ending the second occurrence of the action a computer that implements these operations may send a notification to the client that the second occurrence is still running after the expiration of the TTL described with respect to operation . After operation completes the process flow moves to operation where the process flow ends.

In other embodiments there may be fees associated with performing actions indicated by API calls. Different customer accounts may pay different fees or one customer account may pay different fees for different actions. For instance there may be a higher fee for a guarantee that a call will be processed at a given time and a lower fee for a guarantee only that a call will be processed only if possible after processing all high priority calls. Then when a scenario occurs where too much processing requested at a given time a server may perform a triage on the requested calls. Given the two status embodiment above higher fee and lower fee it may be initially determined that the lower fee calls will not be processed in favor of the higher fee calls until the projected processing is below a maximum amount. In embodiments there may be a bidding system for resources at a given time so that a requestor that is sufficiently motivated and funded may ensure that its request will be executed at that time.

The operating procedures of begin with operation which depicts receiving a request to invoke an action at scheduled times. Operation may be implemented in a manner similar to operation of . In operation the query string may additionally include pricing information such as a maximum price at which to start an occurrence of the action as is used in for example operation . Pricing information may identify a price per amount of processing resources used e.g. data storage or central processing unit CPU runtime .

The operating procedures of may be integrated with the operating procedures of . When a computing service attempts to run a scheduled action the computing service may check the spot price and use spot resources instead of possibly more expensive on demand instances or reserved instances when the spot price is low and the computing service has confidence that the action will complete before the spot price goes up. This confidence that the action will complete in time may be based on a history of how long the action takes to complete and a history of the spot price e.g. it is Monday morning and the spot price is generally low on Monday mornings .

After operation the instance manager can read the schedule and determine to launch an instance and the process flow moves to operation which depicts determining whether the price identified in the request of operation is below the current spot price. The current spot price is the prevailing price at which an action may use processing resources. When the identified price is above the spot price it means that the prevailing price is less than the client is willing to spend and that the action should be started. When the identified price is below the spot price it means that the prevailing price is more than the client is willing to spend and that the action should not be started. Where the identified price is above the spot price then the process flow moves to operation where the process flow ends. In this case the instance manager may check the spot price at a later time any try to launch the instance again. Alternatively the instance manager may launch the instance from a pool of on demand instances i.e. from a pool of fixed priced instances . For example the instance manager could execute the process described with respect to . Where the identified price is below the spot price then the process flow moves to operation .

Operation depicts determining whether starting another instance of the action would cause the frequency of the action to be performed above an allowable frequency at which the action may be performed. There may be a maximum rate at which occurrences of the action are performed and this may be less than the rate indicated by the period in the request. For example the period indicated in the request may be to check every 30 minutes whether the spot market is below the identified price and if that is the case and if no more than two occurrences have been started in the past 3 hours then start another occurrence. Where starting another instance of the action would cause the frequency of the action to be performed above an allowable frequency at which the action may be performed the process flow moves to operation where the process flow ends. Where starting another instance of the action would cause the frequency of the action to be performed below an allowable frequency at which the action may be performed the process flow moves to operation .

Operation depicts starting an occurrence of the action. Operation may be implemented in a manner similar to operation of .

After operation the process flow moves to operation which depicts determining whether the spot price is now above a maximum allowable price for the action. There may be two prices indicated in a request a price at which an occurrence of an action may be started and a price that if reached during execution of the action the action should be immediately stopped regardless of how close the action is to completion other embodiments may factor in how close the action is to completion in determining the maximum price . Where the spot price is above a maximum allowable price for the action the process flow moves to operation where the occurrence of the action that was started in operation is ended and then to operation where the entire process flow ends. When the spot price remains below a maximum allowable price for the action the process flow moves to operation .

Operation depicts determining whether the occurrence of the action has been completed. For instance where the action involves starting an instance that will terminate itself upon completion of the rest of the action operation may comprise determining if that instance is still running. Where the occurrence of the action has been completed the process flow moves to operation where the process flow ends. Where the occurrence of the action has not been completed then the process flow moves back to operation which continues to monitor whether the spot price exceeds the maximum allowable price for the action. In this manner operations and form a decision loop which terminates when either the occurrence of the action is complete or the spot price exceeds the maximum allowable price for the action.

Operation depicts determining whether a first occurrence of the action has been completed. When the first occurrence of the action has not been completed the process flow loops on operation until the first occurrence of the action has been completed. Where the first occurrence of the action has been completed then the process flow moves to operation .

Operation depicts recording information regarding execution of the first occurrence of the action. This information may indicate how long the first occurrence of the action lasted in total time and or processor time how much bandwidth was used in executing the first occurrence of the action or whether the first occurrence of the action completed successfully or failed or likely completed successfully or failed . In embodiments the client that originally sent the API call can send an API call to the instance manager indicating whether the occurrence of the action completed successfully. Alternatively after the instance completes the action it can be configured to send the API call to the computing service. This may be implemented via a callback API call that the client sends to the computing service in a similar manner as how the client sent the server the original API call. In an embodiment the computing service may be informed of whether the occurrence completed successfully because the computing service may not have an agent running within the virtual machine that can determine whether the code running within the instance competed the action. This information may be stored by the server and either combined with information about executing additional occurrences such as in operation or used as the history information on its own.

Upon completion of operation the process flow moves to operation which depicts determining whether a second occurrence of the action has been completed. Operation may be implemented in a similar manner as operation . Where the second occurrence of the action has not been completed the process flow loops on operation until the second occurrence of the action has been completed. Where the second occurrence of the action has been completed then the process flow moves to operation .

Operation depicts recording information regarding execution of the second occurrence of the action. Operation may be implemented in a similar manner as operation .

Upon completion of operation the process flow moves to operation which depicts compiling the information regarding the execution of the first and second occurrences of the action that was recorded in operations and . For instance compiling the information may include determining an average execution time a standard deviation of the execution time or a rate at which occurrences of the action successfully completed.

Upon completion of operation the process flow moves to operation which depicts using the compiled information to determine whether the client is tolerant of the action failing. For instance where the action is to launch an instance the launched instance may then perform some operation that may complete successfully or fail. Here the action may be considered to have failed even though the act of launching the instance itself completed successfully because the operation that is part of the action failed to complete. An action may be determined to be fault tolerant where the client has configured the action via the request in the API call such that the action completes successfully relatively rarely. That the action rarely completes successfully may be taken as an indication that it is fault tolerant that the client does not believe that the action must complete successfully a high amount of the time. Likewise where an action usually completes successfully that may be taken as an indication that the action is not fault tolerant that the client does believe that the action must complete successfully a high amount of the time. Where it is determined that the action is fault tolerant the process flow moves to operation . Where it is determined that the action is not fault tolerant the process flow moves to operation .

Operation depicts placing future occurrences of the action on hardware in response to determining that the action is fault tolerant. The hardware that a fault tolerant action may be placed on may be hardware that is relatively likely to be the cause of a fault such as by failing during execution of the action . This may be older or less reliable hardware that is more likely to fail during execution of an occurrence of the action than other hardware that is available for execution of the action. Placing the action on hardware based on fault tolerance may allow for the use of hardware that is otherwise unusable due to the risk that a highly fault tolerant action would be placed on it were it to be in service.

Operation depicts placing future occurrences of the action on hardware in response to determining that the action is not fault tolerant. The hardware that not a fault tolerant action may be placed on may be hardware that is highly reliable and is relatively unlikely to be the cause of a fault.

Web services platform comprises front end and hosts and . This is a simplified embodiment to illustrate these aspects of web services platform and it may be appreciated that there are embodiments of a web services platform that include more or fewer components . In turn within web services platform each host comprises a host manager and one or more instances. That is host comprises host manager and instances and . Likewise host comprises host manager and instances and . In other embodiments hosts and may be implemented in a similar manner as host of and carry out similar functions as host .

Host managers and may execute within the host partition of their respective host. Host managers and may configure launch and terminate instances. Where instance images are stored somewhere other than on the host host managers and may retrieve and configure these instance images in the process of configuring and launching instances. Host managers and may also create and remove firewalls for use in processing the network communications of instances.

Instances and may comprise a virtualized hardware configuration and an operating system that runs on that virtualized hardware configuration. This virtualized hardware configuration may include an amount of virtual memory a number and type of virtual processors e.g. 32 bit or 64 bit processors and an associated architecture an amount of virtual storage and a level of I O performance.

Front end may execute within an instance or may execute in the host partition of a host. Front end may host APIs used as an interface between web services platform and client . Front end may receive API calls from client and based on those calls determine whether there is sufficient capacity of a specific kind e.g. a specific hardware class with which to execute a particular instance type to fulfill the action indicated by those calls. Front end may also be in communication with hosts and and determine which host will carry out the action specified in a call. Where these actions are scheduled for some time after the calls are received front end may store an indication of these actions and monitor when the scheduled time to carry out these actions occurs. When the scheduled time does occur front end may determine which host among hosts and will carry out the action and indicate to that host to carry out that action. In other embodiments front end may be implemented in a similar manner as external facing server of and carry out similar functions as external facing server .

Front end may receive API calls from client that indicate an action such as performing a scheduled API call of an instance. These actions may be interrelated. For instance the action may involve launching instances and where these instances are configured to communicate with each other. That is the action may involve launching each instance and configuring each instance both with its own network address and an indication of the other instance s network address. Where an instance is typically assigned a network address while it is being launched it may be that neither instance can be fully launched and configured before the other instance has been configured since fully configuring one instance requires knowledge of the other instance s network address . In such a scenario front end or host manager or may reserve a network address for each instance. Then each instance may be configured and launched using these reserved network addresses.

In other embodiments one instance may be configured until it is assigned a network address. Then the other instance may be configured with both its own network address and the network address of the first instance which has already been assigned . Finally the configuring the first instance may resume and it may be configured with the network address of the other instance which has already been assigned.

In other embodiments launching the two instances so that they may communicate with each other may include configuring a firewall on each of host manager and . When launching the two instances front end or another component of web services platform may have an indication that each instance is to be able to communicate with the other instance. Then front end may instruct host manager to configure its firewall to allow instance on host to communicate with instance and instruct host manager to configure its firewall to allow instance on host to communicate with instance

The operating procedures of begin with operation which depicts receiving a request. In embodiments an API call may be received from a client computer such as client of . In a conventional manner the client would send an API call each time the client desires that the associated action be implemented. In contrast in the client may send one API call that identifies multiple times at which the associated action is to be processed.

After operation the process flow moves to operation which depicts determining whether a first time of the period time has been reached. Determining whether the first time has been reached may involve for example executing a process that keeps track of both the current time when the first time is and compares the two to determine if the current time has exceeded the first time. For example when the API call indicates that the associated action should be processed once per hour this first time may be one hour after that API call is received. If this first time of the period time has not yet been reached then the process flow waits at operation until this first time has been reached. If this first time of the period of time has been reached then the process flow moves to operation .

Operation depicts starting a first occurrence of the action. This may comprise performing the action as indicated in the API call. For instance the API call may identify the action as starting an instance which once started will perform some operations before terminating. Where this is the case operation may comprise starting an instance as indicated by the API call.

After a first occurrence of the action has been started in operation the process flow moves to operation which depicts determining whether a second time of the period time has been reached. Operation may be implemented in a manner similar to how operation is implemented. Continuing with the example of the action being scheduled to be processed every hour the first time may be one hour after the API call is received and the second time may be one hour after the first time or two hours after the API call is received. If this second time of the period time has not yet been reached then the process flow waits at operation until this second time has been reached. If this second time of the period of time has been reached then the process flow moves to operation .

Operation depicts estimating a cost of running a second occurrence of the action. This estimate may be based on the actual cost of running the first occurrence of the action and of running other occurrences of the action. For instance occurrences of the action run at night may use more processing resources than occurrences of the action running during the day. It may be that the action incorporates conditional logic such that it performs additional operations at night e.g. during the day the action checks several websites and gathers information from them and at night the action both checks those websites and gathers information from them and performs analysis of the data gathered over the course of the day .

In other embodiments running previous occurrences of the action including the first occurrence may be done on different types of hardware e.g. the different sizes of computing resources discussed with respect to and data may be gathered on how much time and cost is involved with running the action on these different hardware configurations. In such embodiments estimating a cost of running a second occurrence of an action may then comprise estimating a cost of running a second occurrence of the action based on available hardware configurations.

Where occurrences of the action are run using virtual machine instances these virtual machine instances may vary such as in number of virtual CPU cores virtual memory virtual disk space or CPU architecture e.g. x32 or x64 . In embodiments running previous occurrences of the action including the first occurrence may be done on different types of virtual machines and data may be gathered on how much time and cost is involved with running the action on these different virtual machine configurations. In such embodiments estimating a cost of running a second occurrence of an action may then comprise estimating a cost of running a second occurrence of the action based on available virtual machine configurations.

There may also be a maximum amount of time for which an occurrence of the action may run as indicated by the customer or otherwise determined. In these embodiments estimating the cost of running a second occurrence comprises estimating the cost of running the second occurrence on those hardware configurations where it is estimated that the action will complete within the maximum amount of time. In some embodiments a customer may indicate a preference for running the action as quickly as possible as long as the cost does not exceed a threshold amount. In other embodiments a customer may indicate a preference for running the action as cheaply as possible as long as the time does not exceed the maximum allowable amount. In all of these embodiments it is the history of how the action has run in previous occurrences based on e.g. the type of hardware it was run on the time of day week month etc. it was run the cost it incurred while running and the amount of time it took to run that is used in determining whether and how to run the current instance of the action.

This history information based on how previous occurrences of the action may be used to determine placement of the current occurrence of the action among multiple physical hosts such as the server computers A N of . These physical hosts may be heterogeneous they may be made of different hardware or they may currently be experiencing different loads. Given that these physical hosts are different an estimate of how much the current occurrence of the action will cost on these different physical hosts may be used in placing the current occurrence of the action on the host on which the action may be run the most cheaply. Similar determinations may be made for placing the current occurrence of the action on a host such that the action completes as quickly as possible without exceeding a cost limit or completes as cheaply as possible without exceeding a time limit.

Operation depicts determining whether it is likely that the cost of running a second occurrence of the action will be below a threshold amount. If the cost is estimated to be above the threshold amount the process flow moves to operation where the process flow ends. If the cost is estimated to be below the threshold amount the process flow moves to operation .

Operation depicts starting a second occurrence of the action. Operation may be implemented in a similar manner as operation starting the first occurrence of the action is implemented.

The PES platform can provide computing resources for executing applications on a permanent or an as needed basis. The computing resources provided by the PES platform may include various types of resources such as data processing resources data storage resources data communication resources and the like. Each type of computing resource may be general purpose or may be available in a number of specific configurations. For example data processing resources may be available as virtual machine instances. The instances may be configured to execute applications including Web servers application servers media servers database servers and the like. Data storage resources may include file storage devices block storage devices and the like.

Each type or configuration of computing resource may be available in different sizes such as large resources consisting of many processors large amounts of memory and or large storage capacity and small resources consisting of fewer processors smaller amounts of memory and or smaller storage capacity. Customers may choose to allocate a number of small processing resources as Web servers and or one large processing resource as a database server for example.

The computing resources provided by the PES platform are enabled by one or more data centers A N which may be referred herein singularly as a data center or in the plural as the data centers . The data centers are facilities utilized to house and operate computer systems and associated components. The data centers typically include redundant and backup power communications cooling and security systems. The data centers might also be located in geographically disparate locations. One illustrative configuration for a data center that implements the concepts and technologies disclosed herein for launching virtual machine instances will be described below with regard to .

The customers and other consumers of the PES platform may access the computing resources provided by the data centers over a wide area network WAN . Although a WAN is illustrated in it should be appreciated that a local area network LAN the Internet or any other networking topology known in the art that connects the data centers to remote customers and other users may be utilized. It should also be appreciated that combinations of such networks might also be utilized.

The customer computing system is a computer utilized by a customer or other consumer of the PES platform . For instance the customer computing system may be a server computer a desktop or laptop personal computer a tablet computer a wireless telephone a PDA an e reader a game console a set top box or any other computing device capable of accessing the PES platform .

As will be described in greater detail below the customer computing system may be utilized to configure aspects of the computing resources provided by the PES platform . In this regard the PES platform might provide a Web interface through which aspects of its operation may be configured through the use of a Web browser application program executing on the customer computing system . Alternatively a stand alone application program executing on the customer computing system might access an application programming interface API exposed by the PES platform for performing the configuration operations. Other mechanisms for configuring the operation of the PES platform including launching new virtual machine instances on the PES platform might also be utilized.

According to embodiments disclosed herein the capacity of purchased computing resources provided by the PES platform can be scaled in response to demand. In this regard scaling refers to the process of instantiating which may also be referred to herein as launching or creating or terminating which may also be referred to herein as de scaling instances of computing resources in response to demand. In this manner the capacity of resources purchased by a customer of the PES platform can be scaled on demand.

Auto scaling is one mechanism for scaling computing resources in response to increases or lulls in demand for the resources. Auto scaling allows customers of the PES platform to configure the platform to scale their purchased computing resources according to conditions defined by the customer. For instance rules may be defined for scaling up capacity in a particular manner in response to the occurrence of specified conditions such as a spike in demand. Similarly rules might also be defined to scale down capacity in a particular manner in response to the occurrence of other conditions such as a lull in demand. The mechanisms disclosed herein for launching virtual machine instances might be utilized when instances are manually launched by a customer or when instances are launched by an auto scaling component in the PES platform .

The PES platform may also be configured with a deployment component to assist customers in the deployment of new instances of computing resources. The deployment component may receive a configuration from a customer that includes data describing how new instances should be configured. For example the configuration might specify one or more applications or software components that should be installed in new instances provide scripts and or other types of code to be executed in new instances provide cache warming logic specifying how an application cache should be prepared and other types of information. The deployment component utilizes the customer provided configuration and cache warming logic to launch configure and prime new instances of computing resources.

In one embodiment the instances A N which may be referred herein singularly as an instance or in the plural as the instances are virtual machine instances. As known in the art a virtual machine instance is an instance of a software implementation of a machine i.e. a computer that executes programs like a physical machine. In the example of virtual machine instances each of the servers may be configured to execute an instance manager capable of executing the instances. The instance manager might be a hypervisor or another type of program configured to enable the execution of multiple instances on a single server for example. As discussed above each of the instances may be configured to execute all or a portion of an application.

It should be appreciated that although the embodiments disclosed herein are described primarily in the context of virtual machine instances other types of instances can be utilized with the concepts and technologies disclosed herein. For instance the technologies disclosed herein might be utilized with instances of storage resources instances of data communications resources and with other types of resources. The embodiments disclosed herein might also execute all or a portion of an application directly on a computer system without utilizing virtual machine instances.

The data center shown in also includes a server computer reserved for executing software components for managing the operation of the data center the server computers and the instances . In particular the server computer might execute a management component . As discussed above a customer of the PES platform might utilize the customer computing system to access the management component to configure various aspects of the operation of PES platform and the instances purchased by the customer. For example the customer may purchase instances and make changes to the configuration of the instances. The customer might also specify settings regarding how the purchased instances are to be scaled in response to demand. The customer might also provide requests to launch instances to the management component .

As also described briefly above an auto scaling component scales the instances based upon rules defined by a customer of the PES platform . In one embodiment for instance the auto scaling component allows a customer to specify scale up rules for use in determining when new instances should be instantiated and scale down rules for use in determining when existing instances should be terminated.

The auto scaling component may execute on a single server computer or in parallel across multiple server computers in the PES platform . In addition the auto scaling component may consist of a number of subcomponents executing on different server computers or other computing devices in the PES platform . The auto scaling component may be implemented as software hardware or any combination of the two. The auto scaling component may monitor available computing resources in the PES platform over an internal management network for example.

As discussed briefly above the data center may also be configured with a deployment component to assist customers in the deployment of new instances of computing resources. The deployment component may receive a configuration from a customer that includes data describing how new instances should be configured. For example the configuration might specify one or more applications that should be installed in new instances provide scripts and or other types of code to be executed for configuring new instances provide cache warming logic specifying how an application cache should be prepared and other types of information.

The deployment component utilizes the customer provided configuration and cache warming logic to configure prime and launch new instances . The configuration cache warming logic and other information may be specified by a customer using the management component or by providing this information directly to the deployment component . Other mechanisms might also be utilized to configure the operation of the deployment component .

In the example data center shown in an appropriate LAN is utilized to interconnect the server computers A N and the server computer . The LAN is also connected to the WAN illustrated in . It should be appreciated that the network topology illustrated in has been greatly simplified and that many more networks and networking devices may be utilized to interconnect the various computing systems disclosed herein. Appropriate load balancing devices or software modules might also be utilized for balancing a load between each of the data centers A N between each of the server computers A N in each data center and between instances purchased by each customer of the PES platform . These network topologies and devices should be apparent to those skilled in the art.

It should be appreciated that the data center described in is merely illustrative and that other implementations might be utilized. In particular functionality described herein as being performed by the management component the auto scaling component and the deployment component might be performed by one another might be performed by other components or might be performed by a combination of these or other components. Additionally it should be appreciated that this functionality might be implemented in software hardware or a combination of software and hardware. Other implementations should be apparent to those skilled in the art.

The various embodiments further can be implemented in a wide variety of operating environments which in some cases can include one or more user computers computing devices or processing devices which can be used to operate any of a number of applications. User or client devices can include any of a number of general purpose personal computers such as desktop or laptop computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also can include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also can include other electronic devices such as dumb terminals thin clients gaming systems and other devices capable of communicating via a network. These devices may be considered to be computing nodes along with each virtual machine of one or more virtual machines that executes on such devices.

Most embodiments utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of protocols such as TCP IP OSI FTP UPnP NFS CIFS and AppleTalk. The network can be for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network and any combination thereof.

In embodiments utilizing a Web server the Web server can run any of a variety of server or mid tier applications including HTTP servers FTP servers CGI servers data servers JAVA servers and business application servers. The server s also may be capable of executing programs or scripts in response requests from user devices such as by executing one or more Web applications that may be implemented as one or more scripts or programs written in any programming language such as JAVA C C or C or any scripting language such as Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM .

The environment can include a variety of data stores and other memory and storage media as discussed above. These can reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers or remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device can include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU at least one input device e.g. a mouse keyboard controller touch screen or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also can include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader can be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or Web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that can be used to store the desired information and that can be accessed by the a system device. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

Other variations are within the spirit of the present disclosure. Thus while the disclosed techniques are susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the invention to the specific form or forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention as defined in the appended claims.

The use of the terms a and an and the and similar referents in the context of describing the disclosed embodiments especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. The term connected is to be construed as partly or wholly contained within attached to or joined together even if there is something intervening. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate embodiments of the invention and does not pose a limitation on the scope of the invention unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention.

Preferred embodiments of this disclosure are described herein including the best mode known to the inventors for carrying out the invention. Variations of those preferred embodiments may become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventors expect skilled artisans to employ such variations as appropriate and the inventors intend for the invention to be practiced otherwise than as specifically described herein. Accordingly this invention includes all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is encompassed by the invention unless otherwise indicated herein or otherwise clearly contradicted by context.

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

While the present disclosure has been made in connection with preferred embodiments as illustrated in the various figures it is understood that other similar aspects may be used or modifications and additions may be made to the described aspects for performing the same function of the present disclosure without deviating there from. Therefore the present disclosure should not be limited to any single aspect but rather construed in breadth and scope in accordance with the appended claims. For example the various procedures described herein may be implemented with hardware or software or a combination of both. Aspects of the disclosure may be implemented with computer readable storage media which do not include signals and or computer readable communication media. Thus the invention or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible or non transitory media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium. Likewise certain aspects or portions of the disclosure may be embodied in propagated signals or any other machine readable communications medium. Where the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus configured for practicing the disclosed embodiments. In addition to the specific implementations explicitly set forth herein other aspects and implementations will be apparent to those skilled in the art from consideration of the specification disclosed herein. It is intended that the specification and illustrated implementations be considered as examples only and not considered as encompassing all aspects of the disclosure.

