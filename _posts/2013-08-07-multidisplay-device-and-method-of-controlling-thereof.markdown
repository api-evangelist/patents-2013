---

title: Multi-display device and method of controlling thereof
abstract: A multi-display apparatus includes a first body mounted with a first display, a second body mounted with a second display, a hinge connecting the first body and the second body, a first frame buffer corresponding to a first display, a second frame buffer corresponding to a second display, and a controller which manages the first and second frame buffers with a separate storing method which separately manages the first and second frame buffers and stores data or a united storing method which manages the first and second frame buffers as one virtual united frame buffer and stores data. The controller stores data on the first and second frame buffers by converting the managing method according to data features displayed on the first and second displays, and the first and second displays display the data stored in the first and second frame buffers respectively.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09406281&OS=09406281&RS=09406281
owner: SAMSUNG ELECTRONICS CO., LTD.
number: 09406281
owner_city: Suwon-Si
owner_country: KR
publication_date: 20130807
---
This application claims the benefit of priority under 35 U.S.C. 119 from Korean Patent Application No. 10 2012 0155190 filed on Dec. 27 2012 in the Korean Intellectual Property Office the disclosure of which is incorporated herein by reference in its entirety.

Devices and methods consistent with what is disclosed herein relate to a multi display apparatus and a controlling method thereof and more specifically to a multi display apparatus which controls display screens of a display and a controlling method thereof.

Various types of display apparatuses have been used recently. Some display apparatuses may have more than two displays and the trends are towards bigger sized screens. Therefore a user can watch a plurality of screens implementing a plurality of applications in these display apparatuses.

However conventional dual display apparatuses display a whole screen by partition outputting screens in which one window is physically divided. Therefore even when displaying separate application screens on respective displays a problem arises in that it is not possible to control each screen separately.

Thus there is need for a technology that can control screens separately in a multi display apparatus providing multi tasking environment so that a user can use with more convenience.

Exemplary embodiments of the present inventive concept overcome the above disadvantages as well as other disadvantages not described above. Also the present inventive concept is not required to overcome the disadvantages described above and an exemplary embodiment of the present inventive concept may not overcome any of the problems described above.

Additional features and utilities of the present general inventive concept will be set forth in part in the description which follows and in part will be obvious from the description or may be learned by practice of the general inventive concept.

The foregoing and or other features and utilities of the present general inventive concept may be achieved by providing a multi display apparatus which controls a plurality of screens according to allocating addresses of frame buffers and a controlling method thereof.

The foregoing and or other features and utilities of the present general inventive concept may also be achieved by providing a multi display apparatus which mounts a first body which includes a first display a second body which includes a second display a hinge which connects the first body and the second body a first frame buffer which corresponds to the first display a second frame buffer which corresponds to the second display and a controller which manages the first frame buffer and the second frame buffer according to a managing method of either a separate storing method which separately manages the first and second frame buffers and stores data or a united storing method which manages the first and second frame buffers as one virtual united frame buffer and stores data. The controller stores data in the first and second frame buffers by converting the managing method according to data features displayed on the first and second displays. Further the first and second displays display the data stored in the first and second frame buffers respectively.

The controller may allocate separate addresses on the first and second frame buffers when managing with the separate storing method divide whole addresses of the virtual united frame buffer into a first group and a second group and allocate addresses of the first group on the first frame buffer and addresses of the second group on the second frame buffer when in the management with the united storing method and dynamically allocate the addresses.

The multi display apparatus may additionally include a rotation recognizing sensor which senses rotation of the multi display apparatus. The controller may adjust a first screen data to be displayed on the first display and a second screen data to be displayed on the second display respectively according to the rotation store the adjusted first and second screen data on the first and second frame buffers and separately convert screens of the first and second displays according to the rotation.

The multi display apparatus may additionally include a user recognizing sensor which recognizes user position. The controller may adjust a first screen data to be displayed on the first display and a second screen data to be displayed on the second display respectively according to the user position store the adjusted first and second screen data on the first and second frame buffers and separately convert screens of the first and second displays according to the recognized user position.

The multi display apparatus may additionally include a photographer. The controller may adjust a first screen data to be displayed on the first display and a second screen data to be displayed on the second display respectively when user gestures for converting a screen are recognized based on an image captured by the photographer store the adjusted first and second screen data on the first and second frame buffers and separately convert screens of the first and second displays according to the user gestures.

The multi display apparatus may additionally include a touch sensor. The controller may adjust a first screen data to be displayed on the first display and a second screen data to be displayed on the second display respectively when touch gestures for converting a screen are sensed by the touch sensor store the adjusted first and second screen data on the first and second frame buffers and separately convert screens of the first and second displays according to the touch gestures.

When data stored in the first frame buffer and data stored in the second frame buffer are the same and when data stored in the first frame buffer is adjusted the controller may adjust data stored in the second frame buffer to be uniform with data stored in the first frame buffer and store the adjusted data on the second frame buffer so that screens of the first and second displays can be simultaneously converted.

Screens of the first display and the second display may be home screens or implement screens of selected applications.

The foregoing and or other features and utilities of the present general inventive concept may also be achieved by providing a controlling method of a multi display apparatus which includes a first body mounted with a first display a second body mounted with a second display and a hinge connecting the first body and the second body including the steps of managing the first and second frame buffers according to a managing method of either a separate storing method which separately manages the first and second frame buffers and stores data or a united storing method which manages the first and second frame buffers as one virtual united frame buffer and stores data storing data on the first and second frame buffers by converting the managing method according to data features displayed on the first and second displays and displaying data stored in the first and second frame buffers respectively.

A non transitory computer readable medium may contain computer readable codes as a program to execute the above mentioned steps.

The managing the first and second frame buffers may further comprise allocating separate addresses on the first and second frame buffers when in the management with the separate storing method dividing whole addresses of the virtual united frame buffer into a first group and a second group and allocating addresses of the first group on the first frame buffer and addresses of the second group on the second frame buffer when in the management with the united storing method and dynamically allocating the addresses.

The controlling method of the multi display apparatus may additionally include sensing rotation of the multi display apparatus. The storing data on the first and second frame buffers may further comprise separately adjusting at least one of a first screen data to be displayed on the first display and a second screen data to be displayed on the second display in a converting format according to the rotation and storing the adjusted first and second screen data on the first and second frame buffers.

The controlling method of the multi display apparatus may additionally include recognizing user position. The storing data on the first and second frame buffers may further comprise separately adjusting at least one of a first screen data to be displayed on the first display and a second screen data to be displayed on the second display so as to be converted according to the user position and storing the adjusted first and second screen data on the first and second frame buffers.

The controlling method of the multi display apparatus may additionally include photographing user gestures and recognizing user gestures by using the photographed image. The storing data on the first and second frame buffers may further comprise separately adjusting at least one of a first screen data to be displayed on the first display and a second screen data to be displayed on the second display so as to be converted according to the user gestures and storing the adjusted first and second screen data on the first and second frame buffers.

The controlling method of the multi display apparatus may additionally include receiving touch gestures. The storing data on the first and second frame buffers may further comprise separately adjusting at least one of a first screen data to be displayed on the first display and a second screen data to be displayed on the second display so as to be converted according to the touch gestures and storing the adjusted first and second screen data on the first and second frame buffers.

When data stored in the first frame data and data stored in the second frame data are the same and when data stored in the first frame buffer is adjusted the storing data may on the first and second frame buffers may further comprise adjusting data stored in the second frame buffer to be uniform with the data stored in the first frame buffer so that screens of the first and second displays can be simultaneously converted and storing the adjusted data on the second frame buffer.

A screen of the first display and a screen of the second display may be home screens or screens corresponding to areas of selected applications.

The foregoing and or other features and utilities of the present general inventive concept may also be achieved by providing a multi display apparatus that manages data with one method of the separate storing method and the united storing method by dynamically allocating addresses of the frame buffers and can variously control screens displayed on the first and second displays separately or unitedly. Further when screens displayed on the first and second displays are the same they may be interoperated and converted by manipulating one display.

The foregoing and or other features and utilities of the present general inventive concept may also be achieved by providing a multi display device comprising a plurality of display screens a plurality of frame buffers to buffer images to be displayed on the plurality of display screens each frame buffer being associated with a respective display screen and a controller to control operation of the plurality of display screens by allocating addresses among the plurality of frame buffers independently when the display screens are individually operated and allocating addresses among the plurality of frame buffers collectively as a unified virtual buffer when the display screens are cooperatively operated.

The multi display device may further comprise a rotation sensor to sense a rotational change in the multi display device wherein the controller adjusts data stored in the plurality of buffers to affect a change in orientation of information displayed on the plurality of display screens based on signals from the rotation sensor.

The multi display device may further comprise a near field sensor to sense a user gesture in a space near at least one of the plurality of display screens.

The controller may adjust data stored in the plurality of buffers to affect a change in orientation of information displayed on the plurality of display screens based on signals from the near field sensor.

The foregoing and or other features and utilities of the present general inventive concept may also be achieved by providing a multi display device comprising a first body a second body pivotably connected to the first body a first and second display mounted on the first and second body respectively a first and second frame buffer associated with the first and second display respectively to buffer images to be displayed on the first and second display a sensor to sense a relative angle between the first body and the second body a controller to control operation of the first and second display screens by allocating addresses among the first and second frame buffers independently when the display screens are individually operated and allocating addresses among the first and second frame buffers collectively when the display screens are cooperatively operated wherein the controller adjusts data stored in the plurality of buffers to affect a change in orientation of information displayed on at least one of the first and second display screens based on signals from the sensor.

The first and second display may further comprise a plurality of touch sensors and the controller may adjust data stored in the plurality of buffers to affect a change in orientation of information displayed on the plurality of display screens based on signals from the plurality of touch sensors.

Certain exemplary embodiments of the present inventive concept will now be described in greater detail with reference to the accompanying drawings.

In the following description same drawing reference numerals are used for the same elements even in different drawings. The matters defined in the description such as detailed construction and elements are provided to assist in a comprehensive understanding of the present inventive concept. Accordingly it is apparent that the exemplary embodiments of the present inventive concept can be carried out without those specifically defined matters. Also well known functions or constructions are not described in detail since they would obscure the exemplary embodiments with unnecessary detail.

Referring to the attached drawings the general inventive concept will be described in detail below. Additionally note that when specific explanations regarding relevant well known technologies or constitutions are considered to affect the essence of the general inventive concept unnecessarily the explanations will not be included. Terms described below are terms defined by considering functions of the general inventive concept and may be different according to intentions or customs of users and providers. Therefore definition of the terms should be determined based on overall explanations of the specification.

In this specification a multi display apparatus includes a plurality of displays and is defined as displaying sorts of screens through the displays. Specifically the multi display apparatus may be implemented as for example any of a tablet personal computer portable multimedia player PMP personal digital assistant PDA smart phone cellular phone digital frame and or game machine.

Referring to the multi display apparatus includes a first body a second body and a hinge . The first body includes a controller a first frame buffer and a first display and the second body includes a second frame buffer and a second display

The first body and the second body are connected by the hinge . The first body and the second body may rotate based on the hinge . Accordingly the first and second displays may be closed to fold and face each other or the first and second displays may be widely opened to face a contrary direction to each other in which back sides of the first and second displays fold and face each other or the first and second displays may be open to any position there between. Further according to constitutions of the hinge they may be opened straight by 180 . Opening the first body and the second body based on the hinge will be specifically explained in various embodiments described above.

The first frame buffer performs buffering for the image frame displayed on the first display and the second frame buffer performs buffering for the image frame displayed on the second display

For example an image frame processed in digital signals by a graphics processing unit GPU see is stored in a bitmap format in the first and second frame buffers . In this case a buffering area in each of the frame buffers is allocated to be suitable for a maximum pixel size that each of the displays can support. The first display driver analyzes the image frame stored in the first frame buffer and converts the information to first image source signals. The first display driver provides the first image source signals to the first display and operates the first display to display the image frame.

Likewise the second display driver analyzes and converts an image frame stored in the second frame buffer to second image source signals and provides the second image source signals on the second display to display the image frame.

The first and second frame buffers may be positioned on a predetermined area within the GPU or may be positioned by allocating a predetermined area of a storage not illustrated in the multi display apparatus . Thus all of the first and second frame buffers may be included in the first body or the second body . The multi display apparatus may establish a virtual united frame buffer not illustrated . The established virtual united frame buffer manages data to be displayed on the first and second displays as one data.

The controller divides whole addresses of the united frame buffer into a first group and a second group. Addresses of the first group are allocated on the first frame buffer and addresses of the second group are allocated on the second frame buffer . Screens of the first and second displays may be converted by using addresses allocated to the first and second frame buffers and and adjusting data stored in the first and second frame buffers and . The controller may be included in the second body or may be arranged in a plurality of units and included in both of the first and second bodies .

The controller may optionally include a GPU see . When the multi display apparatus is constituted with the controller including a GPU as one unit there is an advantage in efficiency of transmitting data. In this case because the first and second frame buffers may be positioned within the GPU the first and second frame buffers may be positioned and mounted within the controller . The united frame buffer not illustrated may be implemented with a method of allocating addresses on the first and second frame buffers or may be implemented separately by using another storing space. Further when the united frame buffer is implemented by using another storing space it may be positioned on the same place of the first frame buffer or the second frame buffer

Since illustrates an apparatus constitution including two display units such as the first and second displays it may be referred to as a dual display apparatus. However the number of display units may be three or more units as well as two units. Thus the specification refers to the apparatus as a multi display apparatus.

Referring to the first body may include a first photographer and a first sensor and the second body may include a second photographer and a second sensor . The multi display apparatus may include photographers and or sensors 

The first and second photographers may photograph or digitally capture an image of a user to facilitate a screen orientation conversion process. The controller recognizes a user s position by analyzing a user image photographed by the first and second photographers . The controller adjusts first and second screen data of the first and second frame buffers according to the recognized user position and stores each of the adjusted screen data in the first and second buffers . Thus screen orientations of the first and second displays may be converted by the recognized user position. In this case because the first and second photographers are used to recognize user position they may be considered as one type of user recognizing sensors.

Further the first and second photographers may be used to track user space gestures in order to convert screen orientations. Space gestures may also be used to operate the multi display apparatus by using specific movements of a user e.g. user hands on space without physically contacting a touch screen or pushing a button of the multi display apparatus .

The controller may recognize user gestures by analyzing images regarding movements of a user photographed using the first and second photographers . When the recognized gestures correspond to a preset command for example to convert screen orientation the controller executes the command. In this case the controller adjusts first and second screen data of the first and second frame buffers to change screen orientation and stores each adjusted screen data in the first and second frame buffers . Thus screen orientations of the first and second displays may be converted by the recognized user gestures.

The first and second sensors may each include a respective rotation recognizing sensor or user recognizing sensor. The rotation recognizing sensor senses rotation of the multi display apparatus and the user recognizing sensor recognizes user position.

If the first and second sensors sense a rotation of the multi display apparatus the controller adjusts first and second screen data of the first and second frame buffers to change the display orientation according to the rotation of the controller and stores each adjusted screen data in the first and second frame buffers . Thus screen orientations of the first and second displays may be converted by rotation of the multi display apparatus .

Screen orientations may thus be converted according to the above methods using the first and second sensors when a user position is recognized.

A rotation recognizing sensor to sense rotation of the multi display apparatus may be for example a geomagnetic sensor an acceleration sensor a gravity sensor or a gyro sensor. A user recognizing sensor to recognize user position may be for example an infrared light sensor or an ultrasonic wave sensor. One type of sensor may be used to sense rotation or user position or a combination of different types of sensors may be used.

According to another exemplary embodiment a user can convert screen orientation by touching a touch screen or by inputting gestures corresponding to a screen converting command into the multi display apparatus with a near field sensor.

The multi display apparatus may furthermore convert screen orientation displayed on a first display or a second display by using sensed external information.

The following will describe software layer structure of the multi display apparatus and a specific method of displaying a screen on the first or second display 

The hardware may include various units such as the controller the photographers and the sensors of the multi display apparatus .

OS controls general implementation of the hardware and manages the hardware . In other words the OS performs basic functions such as hardware managing memory and security. OS controls implementation of the multi display apparatus by operating modules such as for example a display driver which operates a multi display communicating driver which transmits receives data camera driver which operates a photographer and audio driver which operates an audio and power manager.

The framework layer is installed on top of the OS . The framework layer connects an application layer with the OS . In other words the framework layer may include for example a location manager notification manager and a frame buffer which displays images on a display.

The application layer is installed on top of the framework layer . Various application programs such as for example the call application the multimedia application the camera application the browser application and the gesture recognizing application may be included in the application layer .

Based on the software layer structure a method of displaying screens of the multi display apparatus will be explained below.

Referring to a first frame buffer and a second frame buffer are mounted physically. The first frame buffer and the second frame buffer are allocated with separate addresses respectively. In other words the multi display apparatus may manage screen display data with a separate storing method which manages the first and second frame buffers separately. Therefore data stored in the first frame buffer is displayed on a first display and data stored in the second frame buffer is displayed on a second display

For example assume that a user implements a first application on the first display and a second application on the second display . The first and second applications can be marked separately. The controller allocates separate addresses on the first frame buffer and the second frame buffer . If for example 0 99 addresses are available on each of the first and second frame buffers the controller allocates 0 99 on the first frame buffer and 0 99 on the second frame buffer . The first and second frame buffers utilize separate addresses and are recognized as separate frame buffers from each other. The controller stores first application screen data in the first frame buffer and second application screen data in the second frame buffer . The stored first application screen data is displayed on the first display and the stored second application screen data is displayed on the second display . Therefore when separate addresses are allocated on the first and second frame buffers screens displayed on the first and second displays may be controlled separately.

Referring to the first and second frame buffers are managed as one virtual united frame buffer . The controller divides whole addresses of the virtual united frame buffer into a first group and a second group. Addresses of the first group are allocated on the first frame buffer and addresses of the second group are allocated on the second frame buffer . Thus the display apparatus may manage screen display data with a united storing method which manages the first and second frame buffers as one united frame buffer . Accordingly the united frame buffer may be mounted in another storing space.

For example assume that a user implements one application on the combined whole area of the first and second displays . The controller allocates addresses by managing the first and second frame buffers as one virtual united frame buffer . If for example addresses of 0 99 are available on the first and second frame buffers respectively the controller establishes the addresses of the virtual united frame buffer as 0 199. Thus a single application screen data is stored in the first and second frame buffers by allocating addresses of 0 99 on the first frame buffer and addresses of 100 199 on the second frame buffer . Therefore one application screen data may be displayed on the combined whole area of the first and second displays 

The allocation of addresses either separately or unitedly may be performed dynamically by the controller . Dynamic performance indicates allocating proper addresses according to the situation displayed on the display rather than determining an address allocation method according to a specific application.

Thus while addresses are separately allocated when a user expands an application displayed on the first display to display on both the first and second displays the controller dynamically allocates addresses by converting an address allocating method from the separate address allocating to the united address allocating method. Addresses can be allocated by converting an address allocating method from united to separate as well.

Referring to application layer is a layer in which applied programs called applications are installed. For example home application or customer home application may be installed. Regarding home application the multi display apparatus may display the application on the first display . Regarding extended application the multi display apparatus may display the application on the first and second displays . Regarding custom home application the multi display apparatus may display the application on the second display

Libraries layer is a layer which third parties access. In the libraries layer a surface flinger may be installed. The surface flinger plays a role for managing access regarding a display subsystem and controlling 2D and 3D graphic layers of applications. For example an application may allow a picture to be drawn on a screen surface similar to a canvas through a graphic device interface GDI thread. The surface flinger transmits the input received via the surface to display subsystem .

The hardware abstraction layer HAL comprises the OS and application programming interface API . The kernel may have additional different API or operation according to specific device designs. Thus the HAL inserted between the kernel and applications ensure that applications are uniformly used even when hardware changes. The display subsystem is mounted in the HAL . Further a frame buffer which stores data displayed on the first and second displays is installed in the kernel . The frame buffer includes the first and second frame buffers . A null frame buffer indicates a virtual united frame buffer which unites and manages the first and second frame buffers . The drawing only illustrates that the null frame buffer is separately mounted however the first and second frame buffers may be used with a method of allocating addresses. In this case a whole unit of the first and second frame buffers is one virtual united frame buffer.

As described by referring to the controller may separately control display units through allocating addresses separately on the first and second frame buffers . The first and second frame buffers may alternatively be managed as the virtual united frame buffer through unitedly allocating addresses and both display units may be managed as one display.

If a rotating event occurs the controller examines rotating information regarding which direction and how much angle a screen displayed on the display should rotate. Screen data is adjusted by using the examined rotating information at operation S. For example as one exemplary embodiment of a method of adjusting screen data a start coordinate is converted only while fixing addresses. Referring to adjusted screen data is stored in the first frame buffer or the second frame buffer by using addresses.

Data stored in the first frame buffer is outputted to the first display and data stored in the second frame buffer is outputted to the second display . Because the data stored in the first frame buffer or the second frame buffer is adjusted by the controller with the examined rotating information the screen displayed on the first display or the second display becomes a rotated screen at operation S. When a rotating event occurs regarding a home screen the rotated home screen is displayed on the display. When a rotating event occurs regarding a selected application the rotated application is displayed on the display.

Referring to a rotating event occurs by rotation of a hardware device at operation S. The controller shields the rotating event at operation S. Thus even when a hardware device rotates the data stored in the first and second frame buffers are maintained unchanged. Thus the screen displayed on the display is kept at operation S.

If a rotating event occurs by using software the screen displayed on the display may likewise be kept in place with the above method. However when a shielded rotating event occurs in terms of software it is more convenient for the related input itself to be disregarded so that a rotating event is not triggered.

If rotating event occurs as described in the screen orientation displayed on the display may be converted or kept. Therefore the whole screen orientation displayed on the first display or the second display can be converted or kept. Further it can be converted or kept on an application by application basis among a plurality of applications displayed on the screen.

The controller adjusts first screen data and second screen data according to the rotation of the multi display apparatus and stores the adjusted screen data on the first frame buffer and the second frame buffer respectively at operation S. Rotation of the multi display apparatus may include rotation of the entire multi display apparatus or changes of angle made by the first body with respect to the second body . For example in a standing mode in which the first body and the second body are almost folded outside to face almost opposite directions the first and second screen data may be adjusted so that edge areas of the first body and the second body that are not near the hinge can be directed to the lower area of the screen.

The controller separately converts screens of the first and second displays according to the rotation of the multi display apparatus at operation S. For example in the standing mode the screen of the first display displays so that an edge area of the first body that is not near to the hinge can be directed to the lower area of the screen. Separately converting the screens of the first and second displays indicates that the screen of the first display and the screen of the second display can be separately controlled without affecting each other and does not indicate that the screens should be controlled separately. According to the situation the screens displayed on the first and second displays may be interoperated and converted.

Referring to the first display and the second display display different screens from each other while operating based on the orthogonal to the hinge . The screens displayed on the first and second displays may be for example a home screen as an initial screen or an implement screen which several separate applications implement.

The multi display apparatus rotates by 90 clockwise. The rotation recognizing sensor senses rotation of the multi display apparatus and generates a rotating event. The controller adjusts the first and second screen data of the first and second frame buffers by using the sensed rotation and rotating information. The adjusted first and second screen data are outputted by the first and second displays 

Referring to the multi display apparatus in which the adjusted first and screen data are outputted is illustrated. The multi display apparatus rotates by 90 clockwise the first display is now positioned above the hinge and the second display is positioned beneath the hinge . Accordingly the first and second displays display screen rotated by 90 counterclockwise.

Referring to the sensors recognize a user position at operation S. The sensors may include user recognizing sensors which recognize user position. For example the user recognizing sensor may be an ultrasonic wave sensor or an infrared sensor. Further although the photographers may normally not be considered as sensors however within a range that a user position is recognized by using the photographed image of a user they may be defined as one unit of the user recognizing sensor.

The controller adjusts the first and second screen data according to the recognized user position and stores the adjusted screens in the first and second frame buffers respectively at operation S. In other words the first and second screen data are adjusted so that forward directed screens can be viewed from the recognized user position. For example regarding general English texts the forward directed screen arranges characters left to right and connects one line with a lower line at the end of the line while characters are not turned over or sideways from a view point of a user. Regarding images a forward directed screen indicates that upper image areas are positioned on the upper part of the screen and lower image areas are positioned on the lower part of the screen from a view point of a user.

The controller separately converts screens of the first and second displays according to the recognized user position at operation S. As described above separately converting the screens of the first and second displays indicates that the screen of the first display and the screen of the second display can be separately controlled without affecting each other and does not indicate that the screens should necessarily be separately controlled. According to the situation the screens displayed on the first and second displays may be interoperated and converted.

Referring to the multi display apparatus includes the first body and the second body . The first body and the second body are connected by the hinge . The first sensor may be mounted on the side of the first body opposite the hinge and the second sensor may be mounted on the side of the second body opposite the hinge . Positions of the first and second sensors are not limited to those illustrated in and may be arranged any place where user position can be recognized.

The first and second sensors may include user recognizing sensors which can recognize user position. For example the user recognizing sensor may be an infrared sensor or an ultrasonic wave sensor. As described above within a range that a user position can be recognized by using the photographed image of a user the photographer of can be considered as one unit of the user recognizing sensor. The photographer will be further described below.

The infrared sensor may sense a user using any of various methods. Examples of the infrared sensors include a pyroelectric infrared ray sensor PIR sensor and a reflecting infrared sensor. The PIR sensor may recognize a user by sensing infrared rays emitted from a human body. The reflecting infrared sensor includes a light emitter and a light receiver and may recognize a user by sensing reflecting infrared rays in the light receiver when infrared rays outputted from the light emitter reflect from a user.

An ultrasonic wave sensor may recognize a user position by outputting ultrasonic waves and sensing sound waves reflecting from a user.

In a first user is positioned on the end of the first body and a second user is positioned on the end of the second body . The first and second sensors including the user recognizing sensor may sense the first and second users respectively. When users are sensed the controller triggers a rotating event and adjusts screen data of the first and second frame buffers so that a forward directed screen can be viewed from the respective recognized users. The adjusted screen data are outputted to the first and second displays . Thus the multi display apparatus may convert screen orientation on the displays by recognizing user position.

Referring to structure of the first and second bodies and the hinge in the multi display apparatus are the same as described in . The first and second users place on the end of the first and second bodies respectively.

The photographers to photograph the users may be arranged on the same side of the displays . Because the photographers may be used in various ways including a case which confirms user position they may be arranged by considering this point. Embodiments related with arranging the photographers will be described below.

As illustrated in the first photographer photographs a user standing near the first body and the second photographer photographs a user standing near the second body . The controller may recognize user position by using the photographed image by the photographers . For example information regarding recognizing objects such as human shapes face contours eyes noses or mouths may be previously stored and a user position may be recognized by matching the photographed image with the prestored recognizing objects. Rotating information to convert a screen displayed on the display may be obtained by establishing a direction which the recognized user places to be the lower direction of the screen. Details of the screen conversion method have already been described above and will not be further explained.

Therefore the multi display apparatus may recognize user position by using the photographers and convert screens of the first and second displays according to the recognized user position.

Referring to the first user stands near an edge area of the first display opposite to the hinge . The second user stands near an edge area of the second display opposite to the hinge facing the first user . Therefore as in the illustration of the screen of the first display is converted on a forward direction from a view point of the first user and the screen of the second display is converted on a forward direction from a view point of the second user .

Referring to the first user stands near an edge area of the first display adjacent to the hinge . The second user stands near an edge area of the second display opposite the hinge . Therefore the screen of the first display is converted to a forward direction from a view point of the first user and the screen of the second display is converted to a forward direction from a view point of the second user .

Referring to the hinge is mounted on an orthogonal direction in the multi display apparatus . The first user stands near an edge area of the first display adjacent to the hinge . The second user stands near an edge area of the second display adjacent to the hinge in a direction facing the first user . Thus the screen of the first display is converted to a forward direction from a view point of the first user and the screen of the second display is converted to a forward direction from a view point of the second user .

Referring to the hinge is mounted on an orthogonal direction in the multi display apparatus . The first user stands near an edge area of the first display adjacent to the hinge . The second user stands near an edge area of the second display adjacent to the hinge facing the same direction as the first user . Thus the screen of the first display is converted on a forward direction from a view point of the first user and the screen of the second display is converted on a forward direction from a view point of the second user .

User position may therefore be recognized by using the user recognizing sensor. As described above the infrared sensor and the ultrasonic wave sensor may operate as user recognizing sensor. Further within range that user position may be recognized by photographing a user the photographers can be considered as one unit of the user recognizing sensor. However the method of converting a screen by using the photographed image is not limited to the method of recognizing user position and converting screen. A method of converting screen by photographing movements of a user on a space and recognizing space gestures can be used. Before further explaining various embodiments regarding the photographer arrangement will be described.

Because these are provided to explain the arrangement of the photographers other units are excluded from the following description.

First referring to the multi display apparatus comprises the first body and the second body . The first body includes the first display and the second body includes the second display . The first body and the second body are connected via hinge so that they can move relatively. The first photographer may be mounted on a center of the edge area counter to the hinge among the edge area of the first body . The second photographer may be mounted on a center of the edge area counter to the hinge among the edge area of the second body .

Referring to a direction from which a user views the multi display apparatus is considered to be a relative basis for describing an arrangement in another exemplary embodiment. A first photographer may be mounted on a center face of the left edge area in the first body and a second photographer may be mounted on a center face of the left edge area in the second body . According to another exemplary embodiment the first and second photographers may be mounted on a center face of the right edge area in the first and second bodies respectively. Further the first and second photographers may be mounted on the corner area in the first and second bodies respectively. The multi display apparatus may be used vertically as well as horizontally.

If the first and second photographers are arranged on the left or the right edge area in the first and second bodies a user has convenience in inputting a command to the multi display apparatus by using space gestures with a left or right hand and touching a touch screen with another hand.

Referring to the first photographer is arranged on the same side upon which the first display of the first body is arranged and the second photographer is arranged on the same side upon which the second display of the second body is arranged. A third photographer is arranged on the side opposite to the side upon which the second display of the second body is arranged. Although illustrates the multi display apparatus having the first and second photographers arranged on a center of the edge area facing the hinge it need not be limited as such. For example the first and second photographers may be respectively arranged on a center of the edge area on any one side among the edge areas of the first and second bodies or on the corner area which does not contact to the hinge . The third photographer is not limited to be arranged on the corner of one side opposite to the side which the second display of the second body is placed. For example it may be arranged on the opposite corner area or on the center area.

If more than three photographers are arranged two photographers mounted on the same side upon which the displays are mounted may be used for recognizing user position or space gestures and other photographers may be used for another operation such as image photographing and video photographing.

Referring to the first photographer is formed on a center of the edge area of the first body opposite to the hinge and a rotating photographer is formed on a center of the edge area of the second body opposite to the hinge . The rotating photographer may connect to a hinge that can rotate relative to the second body . Thus the rotating photographer may rotate within an angle of 82.

A method of rotating the rotating photographer may be passive in which a user directly rotates the device or automatic in which the device rotates by predetermined value on predetermined conditions. Otherwise both methods i.e. the passive and automatic methods can be operated. The rotating photographer may rotate to the contrary side of the second display automatically or passively so as to photograph external image or may rotate to the same side of the second display automatically or passively so as to recognize user position or space gestures.

The above described photographers may photograph or video user gestures i.e. user movements within a space. The controller recognizes user gestures by using the photographed images or video at operation S. In order for the controller to examine movements of a user at least three image frames are preferable. However when a fast moving object is photographed at least 5 6 image frames are preferable because blurring which shows the object shape vaguely may happen.

For example one user moves left to right. The photographers capture movements of a user in several image frames. The controller of the multi display apparatus examines shapes or movements of a user and recognizes gestures by using for example at least three images. When a gesture is recognized operation corresponding to the recognized gesture is performed.

If the recognized gesture corresponds to a predetermined command to convert the screen the controller adjusts the first and second screen data and stores the adjusted screen data on the first and second frame buffers respectively at operation S. According to the predetermined command to convert the screen the controller separately converts screens of the first and second displays at operation S. Specific related processes are already described and will not be further explained.

Referring to a user moves within photographing range of the first photographer . The first photographer captures movements of a user to recognize gestures however the first display may display general contents such as home menu and icons. Therefore because a user may have difficulty in perceiving his position on the first display corresponding to his movements a pointer corresponding to user movements is displayed. The pointer may be displayed in cross shape as illustrated or other various shapes such as arrow or hand. Otherwise a user can establish customized shape. When a user moves left to right the corresponding pointer moves left to right. Thus a user can intuitively perceive gestures.

Although illustrates that object is one user object may be more than two users. When there are two or more users the pointer may include two or more icons corresponding to the number of users.

The above may be applied uniformly to a process capturing user movements in the second photographer so as to recognize gestures near the second display

Further so that a user can perceive the gesture recognizing mode the multi display apparatus may mark an icon on the screen of the first or second displays . The icon may be another icon that helps a user to perceive the gesture recognizing mode or characters such as gesture or G . Outside of the displays of the first and second bodies a notification of gesture recognizing mode may be displayed by using another indicator such as for example a light emitting diode LED .

Further when the multi display apparatus including a touch screen operates in the space gesture recognizing mode a user can input a command by touching the touch screen or making a gesture or mark on the touch screen as well as using space gestures.

Referring to methods of inputting gestures into the multi display apparatus may include means other than user hands such as the use of a stylus . A stylus may have a simple structure which does not include other functions or structure which includes coils for near field sensing or a more complex structure which includes other additional functions.

The multi display apparatus may recognize user hands and a stylus as one inputting means without separating a user s hand from the stylus . Further as described above it may separately recognize a stylus from a user s hand by recognizing the stylus shape with the photographers .

A user may operate the multi display apparatus to recognize gestures while using hands and after using a stylus . The contrary process can also be operated. In this case in which inputting means changes the multi display apparatus may display notification saying that the currently recognized inputting means have changed and a new inputting means is recognized. Further without displaying notification it may display changes of inputting means by converting shape or color of a user interface UI object such as a pointer displayed on the display . Alternatively without displaying any notification or converting the multi display apparatus may recognize inputting means changes internally.

The method of recognizing gestures and operating in the multi display apparatus may be the same as those described in .

Referring to the multi display apparatus may recognize both hands of a user as objects and movements of both hands as space gestures. Referring to two user objects move within photographing range of the second photographer . The multi display apparatus recognizes gestures by examining movements of the captured two user objects and performs operations corresponding to the gestures.

For example when a plurality of applications operate on the second display applications may be classified into two groups. Users can optionally convert an orientation of only one group among the classified two groups. Users may perform hold gestures by using one hand regarding a group which they intend to maintain the present orientation and perform screen convert gestures by using another hand regarding a group for which they intend to convert orientation. The controller may perform the corresponding command by recognizing gestures of the plural user objects. In this scenario an orientation of only one group will be converted. An embodiment of a UI screen which converts per group will be described below.

Referring to one object is a hand of the user and the other object is the stylus . A plurality of objects may be used concurrently for example both hands of the user the stylus and a hand of the user or two styluses.

A method of inputting a command into the multi display apparatus by using user space gestures has been described. A method of converting a display screen of the display by using space gestures will be described in greater detail below.

Referring to the multi display apparatus is laid down by spreading the first display and the second display based on the hinge . The first photographer is formed on a center of the edge area on one side which does not contact to the hinge among the edge area of the first body . The second photographer is formed on a center of the edge area on one side which does not contact to the hinge among the edge area of the second body . Assume that a first user stands near the side upon which the first photographer is mounted and a second user stands near a side upon which the second photographer is mounted.

The first and second displays display forward directed screen from a view point of the first user. Screens displayed on the first and second displays may be uniform or different. Further they may be home screen as initial screen of the multi display apparatus or implement screen which specific applications implement.

The first user moves a first user object i.e. his in a direction parallel to the X axis. The second user moves a second user object i.e. his hand in a direction parallel to the Y axis. The first photographer photographs movements of the first user object and the second photographer photographs movements of the second user object . The controller recognizes user gestures by using images of the first and second user objects . In assume that directing a palm toward the display and moving the hand to a specific direction are gestures corresponding to a screen conversion command. Accordingly the controller recognizes that movements of the first user object are a command to convert screen orientation to X axis. Further the controller recognizes that movements of the second user object are a command to convert screen orientation to Y axis.

Referring to the first display is converted to an X axis orientation and the second display is converted to a Y axis orientation opposite to its original orientation. In other words the controller adjusts the first and second screen data responding to the recognized command. The adjusted screen data are stored in the first and second frame buffers and the stored first and second screen data are outputted to the first and second displays respectively.

Space gestures corresponding to a command to convert screen orientation may be established with various movements of user objects. For example the command may correspond to movements of spreading a hand directing a palm toward the display and moving the hand toward a specific direction. Alternatively the command may correspond to movements of using one finger and moving the finger in a straight direction. Further it may correspond to movements of using one finger and rotating the finger toward a specific direction. It may also correspond to movements of using two fingers and rotating the two fingers toward the same direction. The above movements are only examples of space gestures that could correspond to a command to convert a screen orientation other movements may correspond to the command.

When space gestures corresponding to a command to convert a screen orientation is established uniformly with touch gestures a user can make adjustments with convenience. Furthermore so that a user can establish and use unique gestures corresponding to a command to convert screen the multi display apparatus may include a gesture setting menu.

Space gestures may be recognized by using a near field sensor as well as by using the photographed image.

A user may input a command into the multi display apparatus with a near field touch method of using a near field sensor. Near field touches indicate recognizing gestures within a determined effective recognizing range of a space without directly touching a screen.

Referring to display includes a display panel an infrared source and an infrared sensor . The infrared source radiates in a surface direction of the display . Specifically the infrared source may be formed beneath the display panel which displays video or image and can radiate infrared rays toward a surface direction of the display . Above the display surface a determined area that can recognize the approach of a user object is formed. This area is effective recognizing area within which the multi display apparatus can recognize near field touch.

User objects indicate means to input a command to the multi display apparatus for example a part of a body such as a hand or finger may serve as a user object.

If user object approaches within range of the effective recognizing area the infrared sensor generates an infrared scan image by sensing infrared rays reflected from approaching of the user object . Specifically the infrared sensor may generate an infrared scan image corresponding to infrared rays reflected from the approaching user object by using a plurality of infrared sensing components arranged in an array format. The multi display apparatus may sense a near field touch input by using the generated infrared scan image.

Referring to a display panel a near field source and a sensor described in are included. The stylus may include coils so as to recognize near field touches by using a specific stylus. The display includes an electrostatic sensor . The electrostatic sensor may include a plurality of coils.

If the stylus including coils approaches within a certain distance coils of the electrostatic sensor induces electrical currents by electrostatic induction. Electrical currents are most greatly induced in coils near to the stylus and decreasingly induced in coils away from the stylus . Therefore the controller recognizes a point at which the biggest electrical currents are induced as a position where the stylus is positioned.

Because the display illustrated as includes the infrared sensor both of the infrared sensor and the electrostatic sensor recognize approaching of the stylus when the stylus approaches within a certain distance. Therefore a problem of double recognition may be solved for example by prioritizing approaching recognition of the electrostatic sensor first.

Referring to touch sensor of the touch screen receives touch gestures at operation S. Touch gestures corresponding to a command to convert a screen orientation may be established uniformly with space gestures. In other words the command may correspond to for example movements of spreading a hand directing a palm to the screen and moving the hand toward a specific direction. Otherwise the command may correspond to movements of using one finger and moving the finger toward a straight direction. Further it may correspond to movements of using one finger and rotating the finger toward a specific direction. It may also correspond to movements of using two fingers and rotating the two fingers toward the same direction. The above movements are only examples of gestures corresponding to a command to convert screen other movements may correspond to the command.

The controller determines whether the inputted touch gestures correspond to a preset command to convert the screen orientation. When inputted gestures correspond to a screen converting command the first and second screen data are adjusted and the adjusted screen data are stored in the first and second frame buffers respectively at operation S. According to the preset command to convert screen the controller separately converts screens of the first and second displays at operation S.

A user performs screen converting gestures in which a user moves a user object straightly left to right so as to convert the screen displayed on the second display . As described above screen converting gestures are not limited to the movements illustrated in the drawing various movements may be established as screen converting gestures.

Referring to because the first display did not receive any command its screen orientation is maintained. The second display displays a screen rotated toward a right direction corresponding to the screen converting gestures . Likewise even when the screens displayed on the first and second displays are home screens the screen of the second display can be separately controlled from the first display . A user may reconvert the screen displayed on the second display and separately convert the screen displayed on the first display in the display screens illustrated in .

Referring to applications of A B C and D are displayed on one screen. The applications of A B C and D may be implemented in windows or in an icon state before being implemented. The plurality of applications displayed on one screen can be controlled separately. In a user performs movements of a screen converting gesture which rotates application B clockwise.

Referring to the applications of A C and D which do not receive a command are kept in previous situation. However application B which received a screen converting command is rotated by 90 clockwise and displayed on screen.

In this situation a user may proceed to separately convert application orientations again. As shown in a user performs movements of screen converting gesture which rotates C application counterclockwise.

Referring to the applications of A and D which do not receive any command so far are still kept in their original orientations. Application B for which a screen converting gestures was inputted for one time is displayed on screen still rotated by 90 clockwise. Application C for which the screen converting gesture rotating counterclockwise was inputted is now displayed rotated by 90 counterclockwise.

Referring to applications of A B C and D may be displayed on one screen. The multi display apparatus may classify the plurality of applications displayed on one screen into groups and separately control each group.

A user performs a holding gesture by using one user object. The holding gesture may be established for example by pressing and holding the screen with a finger. The holding gesture inputs a command to grip a selected area. When a user performs the holding gesture regarding an area not specific to any particular application the controller determines that whole area and all applications located therein are selected.

For example the controller divides one whole screen into parts such as two parts or four parts. When a holding gesture is not determined to select a specific application every application represented within the selected area may be controlled so as to be selected and held. Further areas may be established by referring to the layout arrangement of applications or relative sizes of applications. Alternatively a user may establish each area voluntarily by selection.

If each area is established applications represented within the same area may be classified as comprising a group. When applications classified as a group are selected notification which a user can perceive regarding the group may be outputted. For example methods by which a user can perceive a group include a method of displaying a boundary around all corresponding applications a method of converting corresponding applications into the same color or a method of displaying boundaries of corresponding applications with the same color or the same depth.

Referring to in response to the holding gesture of a user the applications of B C and D form one group. The controller may display one boundary around the applications of B C and D to express the group. While maintaining holding gesture the user may perform a screen converting gesture regarding application A

Referring to the held applications of B C and D remain in their previous orientation. Application A to which a screen converting command was inputted is displayed on screen in a format converted by 180 .

Referring to the first display displays the applications of A B C and D. The second display displays the same screen as that displayed on the first display . A B C and D may be separate applications to each other or a plurality of objects included and displayed in one application.

A user performs movements of screen converting gestures only to C application displayed on the first display

If the screen of the first display is the same as the screen of the second display the controller may store the second screen data to be displayed on the second display in the second frame buffer as the same data with the first screen data. Therefore when the first screen data is adjusted in response to the screen converting command of a user the screens of the first and second displays may be interoperated and outputted by storing and outputting the adjusted data in the first and second frame buffers respectively.

The multi display apparatus may include a display apparatus consisting of a first display and second display that can be physically or graphically separated and support various screen modes illustrated in by using the two displays 

Various modes may be used according to a relative angle between the first body and the second body of the multi display apparatus . Relative angle is the rotating angle of the second body which rotates on a specific direction e.g. counterclockwise toward the first body . Specifically relative angle may be examined by a hinge sensor not illustrated formed within the hinge . The hinge sensor may be constituted to be any one of for example a hall sensor a pressure sensor an induction examining sensor an electricity contacting sensor and an optical sensor and recognize relative angle by examining movements of the hinge and relative position. Further relative angle may be recognized by examining each position of the first and second bodies with a geomagnetic sensor or an acceleration sensor beside the hinge sensor.

Referring to the first body and the second body contact each other while the first and second displays of the first and second bodies are counter to each other. In other words the second display is positioned on the contrary side of the first display . When a user watches the first display the user cannot directly view the second display because the second display is positioned on the contrary. Thus the user may view only one display. Relative angle is defined as 0 in this situation. In the fully folded configuration may be referred to as single mode. For example when relative angle between the first and second bodies is 0 to 60 the multi display apparatus recognizes the single mode. The single mode may be used helpfully in various situations for example when the multi display apparatus is not used or in a call application. In the single mode the first display facing the user displays a job screen with at least one application and the second display to the rear may be turned off. Some applications may optionally turn on the second display to the rear.

Referring to the first display displays a plurality of thumbnail images . The second display shows one image selected from the plurality of thumbnail images displayed on the first display as whole screen. Generally photographs may be horizontally or vertically oriented according to focus objects or photographing angles. An image photographed horizontally may be displayed lengthwise as a forward directed image in the multi display apparatus . However an image photographed vertically may appear as an image rotated left or right in the multi display apparatus therefore a user may be inconvenienced when attempting to confirm or edit the photographed image.

In a user selects vertically photographed image among the plurality of thumbnail images displayed on the first display and operates the selected image as whole image on the second display . Because the image displayed on the second display appears rotated by 90 counterclockwise a user performs movements of the screen converting gestures which convert the image by 90 clockwise.

Referring to the controller rotates image displayed on the second display by 90 clockwise in response to a screen converting command of the user.

Referring to the first user and the second user are facing each other with the multi display apparatus positioned between them. The first and second displays display forward directed screens from a view point of the first user . The second user performs movements of screen converting gestures on the second display . illustrates performing the screen converting gestures so that a command is issued to display the screen on the second display in a forward directed screen from a view point of the second user . However this is only exemplary as a screen may be converted in a direction of any one side among the four sides of the second display . The controller may display a moderated screen to be suitable for resolution when the screen is rotated by 90 and displayed.

Referring to the screen of the second display is rotated by 180 and displayed in response to a screen converting command of the second user . The screens displayed on the first and second displays may be the same screen or screens including different instances of the same application or otherwise related with each other.

For example when the multi display apparatus is used in a learning environment the first user may be a teacher and the second user may be a student. Therefore the same learning contents may be displayed on the first and second displays . Further when contents for teachers and contents for students regarding the same topic are displayed the first display may display contents for teachers and the second display may display contents for students. When it is used in a presentation the first user may be a service provider and the second user may be a client. In this case the first and second displays may display contracts presentation materials and examination materials and the first user may explain relevant facts to the second user .

In the relative angle between the first body and the second body is less than 180 i.e. the two displays are almost folded outside to face almost contrary directions. In this specification this configuration is referred to as standing mode. For example when relative angle between the first and second bodies is 30 to 90 the multi display apparatus recognizes the standing mode. In standing mode the two displays are folded so as to face outside and the multi display apparatus can stand in a triangular shape. In this configuration the multi display apparatus may be used for example as a digital clock or picture frame or used valuably to view personal broadcasting movie or video.

As another example the standing mode may be applied to applications which need collaboration or interworking of more than two users e.g. video conference or collaborative game. Some applications may display a job screen only on the first display at the front in the standing mode and turn off the second display to the rear. Other applications may turn on the second display to the rear by using option menu.

Specific embodiments of the standing mode may otherwise be implemented similarly to those of the expanding mode.

In the multi display apparatus stands on the floor so that a part of the hinge contacts to the floor. This configuration is referred to as vertical viewing mode. The vertical viewing mode is recognized when relative angle between the first and second bodies is 30 to 60 and the acceleration sensor not illustrated recognizes that the multi display apparatus stands vertically.

Specifically the acceleration sensor recognizes rotating of the multi display apparatus . The acceleration sensor senses converting between the vertical viewing mode in which the first and second displays of the multi display apparatus are arranged left and right and standing mode in which the first and second displays are arranged up and down.

The vertical viewing mode may be applied for example to applications which need to provide different images to more than two users respectively e.g. video conference or multi video player.

As described above the multi display apparatus may support various screen modes according to a relative angle of the hinge . In the following exemplary constitutions to implement various embodiments will be described.

Referring to multi display apparatus may connect to external devices not illustrated by using for example at least one of cellular communicating module wireless LAN module near field communicating module and connector in a communicator unit .

External devices may include at least one of the other devices such as cellular phone smart phone tablet PC computer server and digital TV.

The multi display apparatus includes the two displays . Although illustrates two displays it may be expanded with three or more displays and implemented moderately.

The multi display apparatus includes a communicator unit a multimedia unit a controller a photographer unit a sensor unit an inputter outputter unit a storage an electrical source a first display and a second display

The communicator unit includes the cellular communicating module the wireless LAN module the near field communicating module the connector global positioning system GPS module and broadcasting communicating module .

The cellular communicating module may operate the multi display apparatus to connect to external devices e.g. station of the cellular system through at least one or a plurality of antennas not illustrated by using wireless access technology according to a cellular communication protocol.

Further the cellular communicating module may trans receive wireless signals for use including a voice call video call short message service SMS messages or multimedia messaging service MMS message communication with other devices such as a cellular phone smart phone tablet PC or others.

Further the communicator may include at least one of the wireless LAN module and the near field communicating module . For example it may include the wireless LAN module only the near field communicating module only or both of the wireless LAN module and the near field communicating module .

The wireless LAN module may connect to the Internet in a place where a wireless AP not illustrated is available according to controlling of the controller . The wireless LAN module may support for example wireless LAN standard IEEE802.11x by the Institute of Electrical and Electronics Engineers.

The near field communicating module may perform near field communication wirelessly between the multi display apparatus and external devices according to controlling of the controller . Near field communication methods may include Bluetooth and infrared data association IrDA .

The connector may provide interface with various devices under communication standards such as for example USB 2.0 USB 3.0 HDMI and IEEE 1394.

The connector may be used as interface to connect the multi display apparatus with external devices or electrical sources. Through wire cables connected to the connector data stored in the storage of the multi display apparatus may be transmitted to external devices or data may be received from external devices according to controlling of the controller . Through wire cables connected to the connector electrical power may be provided from an electrical source or a battery e.g. electrical source powering the multi display apparatus may be charged.

The GPS module may receive electrical waves from a plurality of GPS satellites not illustrated operating on the orbits of the Earth and calculate time of arrival from the GPS satellites not illustrated to the multi display apparatus and position of the multi display apparatus by using GPS parameters.

The broadcasting communicating module may receive broadcasting signals e.g. TV broadcasting signals radio broadcasting signals or data broadcasting signals and broadcasting additional information e.g. electric program guide EPS or electric service guide ESG which are transmitted from broadcasting stations through broadcasting antennas not illustrated according to controlling of the controller .

The audio playing module may play digital audio files e.g. files whose filename extension is mp3 wma ogg or wav or other file types which are stored or received according to controlling of the controller . The video playing module may support various formats of codec so as to play digital video files. In other words a video file may be played using a prestored codec suitable for a format of the video file to be played. Further the audio playing module or the video playing module of the multimedia unit may be included in the controller .

The controller includes read only memory ROM which stores control programs to control the multi display apparatus and random access memory RAM which recalls signals or data inputted from outside of the multi display apparatus or is used as recall area for jobs performing in the multi display apparatus . CPU may include for example at least one of single core processor dual core processor triple core processor and quad core processor. CPU ROM and RAM may be connected to each other through an internal bus.

The controller controls the communicator unit the GSP module the multimedia unit the photographer unit the sensor unit the inputter outputter unit the storage the electrical source and the first and second displays 

The photographer unit includes at least one of the first photographer and the second photographer . Although illustrates the first photographer and the second photographer additional photographers may be included according to embodiments.

The first photographer and the second photographer may be mounted on the body of the multi display apparatus or connected to the multi display apparatus by using other connecting methods. At least one the first photographer and the second photographer may include a supportive light source e.g. flash not illustrated which provides lights to aid in photographing.

According to an embodiment the first photographer may be formed on the front of the multi display apparatus and the second photographer may be formed at the rear of the multi display apparatus . According to another embodiment the first photographer and the second photographer may be arranged adjacently e.g. interval between the first photographer and the second photographer is more than 1 cm and less than 8 cm and they may photograph 3D still image or 3D video. Further the first photographer may be arranged on the first body and the second photographer may be arranged on the second body.

The photographer includes a lens and an image sensor. The types of lenses that can be used in the photographer may include a normal widely used lens a pantoscope lens and or a zoom lens. The first and second photographers may include identical lens types however the photographers may include different respective lens types in alternate embodiments.

The image sensors may be complementary metal oxide semiconductor CMOS and charge coupled device CCD . The first and second photographers are generally constructed with one type of the image sensors however they may be constructed by combining different types of the image sensors. For example both of the first and second photographers may use CMOS or CCD or the first photographer may use CMOS while the second photographer may use CCD.

The photographer unit may deliver a photographed image to the controller through at least one of the first photographer and the second photographer . The controller may detect user movements or user shapes by analyzing the image and may perform commands corresponding to the detected movements. For example movements of user hands may be detected through the first photographer or the second photographer . User shapes may indicate user face shapes detected through the first photographer or the second photographer .

For another example the multi display apparatus may detect user movements by using other methods such as an infrared detector and implement or control applications in response to the movements.

The sensor unit includes the touch sensor the geomagnetic sensor the acceleration sensor the hinge sensor and the near field sensor .

The touch sensor may sense user touches regarding the display. The touch sensor may be classified into any of an electrostatic method or a piezoelectric method according to methods used to sense user touches. The touch sensor according to an embodiment may be implemented in each of the two methods. The touch sensor may be constituted with the display panel in the display. Further explanations will be described below.

The touch sensor may detect user input on the display screen via a user pushing the displays with a part of human body such as a finger or other inputting means that can be sensed. The touch sensor may detect user input via for example changes in charging capacity resistance quantity or light quantity.

The geomagnetic sensor may sense an azimuth by examining geomagnetics. Thus a direction of the multi display apparatus may be recognized. The acceleration sensor may calculate dynamic measurements such as acceleration vibration or pulse of objects by processing output signals and sensing velocity changes or power intensity. The hinge sensor may sense angle changes or movements of the hinge. The near field sensor may sense whether an object approaches the multi display apparatus .

Although not illustrated in the sensor unit of the multi display apparatus may include at least one of a gravity sensor which senses a direction influenced by gravity a gyro sensor which senses six axes by putting rotating to the previous acceleration sensor respectively an orientation sensor which automatically rotates or arranges contents by automatically sensing horizontal and vertical frames of the contents such as image an illuminating sensor which senses light quantity around the multi display apparatus a height measuring sensor which measures air pressure an RGB sensor which examines object colors a distance measuring sensor which measures distance by using ultrasonic waves or infrared lights and a hall sensor which uses changes in pressure according to intensity of a magnetic field.

Each sensor of the sensor unit may sense a situation generate signals corresponding to the sensed situation and transmit data regarding the sensed situation to the controller . The sensors of the sensor unit may be added or deleted according to functions of the multi display apparatus .

At least one button may be formed in push type or touch type on the front side or back of the body of the multi display apparatus and include at least one of for example a power lock button a volume button a menu button a home button a back button and a search button.

The microphone generates electrical signals by receiving voices or sounds according to controlling of the controller .

The speaker may output sounds corresponding to various signals of the cellular communicating module the wireless LAN module the near field communicating module the multimedia unit or the photographer unit e.g. wireless signals broadcasting signals digital audio files digital video files or files from the photographer unit to the outside of the multi display apparatus .

The speaker may also output sounds corresponding to functions which the multi display apparatus performs e.g. button sounds corresponding to calling or connecting sounds. The speaker may be formed on a proper position or proper positions of the multi display apparatus singularly or plurally. For example the speaker may be constituted by including an internal speaker module which is arranged on a proper position to approach to an ear of a user while calling and an external speaker module which has higher output to be proper for playing audio video files or watching broadcastings and which is arranged on a proper position of the body in the multi display apparatus .

The vibrating motor may convert electrical signals into mechanical vibrations according to controlling of the controller . For example when a voice call is received from another device not illustrated the multi display apparatus in vibrating mode operates the vibrating motor . The vibrating motor may be formed within the body of the multi display apparatus singularly or plurally. The vibrating motor may operate in response to touch gestures of a user sensed on the first and second displays and consecutive movements of touches sensed on the first and second displays 

The storage stores various types of multimedia data processed by the controller contents data and received data from external sources.

The storage may store data regarding inputting outputting signals e.g. information or data in response to operations of the cellular communicating module the wireless LAN module the near field communicating module the connector the GPS module the multimedia unit the photographer unit the sensor unit the inputter outputter unit the first display and the second display

The storage may store controlling programs and applications to control the multi display apparatus or the controller . The term storage as used herein may include ROM RAM or memory card that can attach detach to the multi display apparatus e.g. SD card or memory stick . Further the storage may include non volatile memory volatile memory hard disc drive HDD or solid state drive SSD .

The electrical source provides electrical power used in the multi display apparatus . The electrical source may be batteries that can be charged and may further include a voltage converter which converts and provides power from an external electrical source to the batteries that can be charged.

The electrical source may operate in various modes such as maximum mode normal mode saving mode and standby mode according to controlling electrical source management of the controller .

The first and second displays may be connected to each other by the hinge not illustrated . The first and second displays display applications multimedia contents image video and text and other screens by controlling of the controller .

The first display and the second display are physically separated. Display screens displayed on the first display and the second display may be controlled independently. For example resolution of the first display and resolution of the second display may be established separately. Further expansion rotation movement and division of the screens displayed on the first display and the second display may be performed separately.

Further the first display and the second display may display a united display screen by using a virtual united frame buffer.

The first and second displays may be implemented in any of various technologies such as for example liquid crystal display panel LCD panel plasma display panel PDP organic light emitting diode OLED vacuum fluorescent display VFD field emission display FED and electro luminescence display ELD .

The first and second displays may be implemented as display panels without having a touch inputting capacity or as touch display panels which can recognize user manipulation by using the near field sensor or the touch sensor . When implemented as touch display panels at least one of touch gestures may be inputted through a part of a user body e.g. fingers including a thumb or sensible inputting means e.g. a stylus .

Such user interface may include designated touch areas a soft key and a soft menu. The first and second displays may transmit electrical signals corresponding to at least one of touch gestures inputted through the user interface to the first and second displays through a LCD controller not illustrated . Further the first and second displays may sense consecutive movements of touches and transmit electrical signals corresponding to linear or nonlinear movements to the LCD controller.

For example the first and second displays may be implemented with a resistive method a capacitive method an infrared method or an acoustic wave method.

The first and second displays convert the sensed signals of user movements by the touch sensor to digital signals e.g. X and Y coordinates and transmit the digital signals to the controller . The controller may perform commands and various controlling operations corresponding to the inputted user movements through the first and second displays by using the received digital signals. For example responding to the user movements the controller may operate so that the soft key displayed on the first and second displays can be selected or applications corresponding to the soft key can be executed.

The above user gestures also include non contact means and are not limited to direct contacting with the first and second displays by a user or to inputting means that can be touched. A degree of user movements that can be examined by the first and second displays may be moderated according to performance or structure of the multi display apparatus .

The above embodiments illustrate and describe bodies of the multi display apparatus as connected by a hinge however they may be connected by a connector comprising flexible material instead of a hinge.

Referring to the multi display apparatus includes the communicator unit the multimedia unit the controller ROM the photographer unit the sensor unit the inputter outputter unit the storage the electrical source and a multi display . The same units described in will not be further described and a display process will be explained below.

CPU reads data stored in the storage to RAM and delivers data that needs to be graphic processed among the data stored in RAM . CPU receives the graphic processed data by GPU transmits the data to the LCD controller not illustrated connected with system bus and displays an image on the multi display .

CPU temporarily stores image data processed by GPU in a virtual frame buffer area allocated on a predetermined area of RAM . CPU allocates virtual frame buffer area so that a maximum resolution e.g. can be supported. When two displays are mounted the virtual frame buffer area is allocated with maximum size.

CPU inputs temporarily stored data on the virtual frame buffer to GPU and performs digital signal processing.

GPU performs graphic processing regarding the inputted data under the control of CPU . Specifically GPU may generate screens including various objects such as icons images or text by using a calculator not illustrated and a renderer not illustrated . The calculator calculates feature values such as coordinates to display each object shape size or color according to screen layout. The renderer generates screens in various layouts including objects based on the calculated feature values. The screens generated in the renderer may be delivered to the first and second displays through the bus and displayed or stored in the storage .

CPU may control displaying the graphic processed data by GPU on at least one of the first and second displays or control storing the data in the storage or input the processed data into a display controller not illustrated .

GPU may include a decoder a renderer and a scaler. Accordingly stored contents are decoded frames are constituted by rendering the decoded contents and a size of the constituted frame is scaled according to display size by controlling of the display controller not illustrated . When a screen is displayed on any one of the first and second displays the screen may be scaled according to the screen size. When a screen is displayed on both of the two displays the screen may be scaled according to combined size of the two displays. GPU provides and displays the processed frame on the display.

Because the multi display apparatus includes a plurality of displays it may provide various screens by using the displays. In the following basic detailed constitution and operations of the multi display apparatus will be described.

For convenient explanation illustrates the first display however the second third or any other display may be implemented in the same constitution.

Referring to the first display may include a timing controller a gate driver a data driver a voltage driver and a display panel .

The timing controller generates gate controlling signals passing controlling signals and data controlling signals data signals by externally receiving clock signals DCLK horizontal synchronizing signals Hsync and vertical synchronizing signals Vsync that are appropriate for resolution of the touch screen rearranges inputted RGB data and provides data to the data driver .

The timing controller may generate gate shift clock GSC gate output enable GOE and gate start pulse GSP signals regarding the gate controlling signals. GSC signals are signals which determine on off time of a thin film transistor TFT connected to a light emitting diode such as an R G B organic light emitting diode OLED . GOE signals are signals which control output of the gate driver . GSP are signals which inform a first driving line of the screen from one Vsync.

Further the timing controller may generate source sampling clock SSC source output enable SOE and source start pulse SSP signals regarding the data controlling signals. SSC signals are used as a sampling clock to latch data in the data driver and determine driving frequency of a data drive IC. SOE signals deliver the latched data by the SSC to the display panel . SSP signals are signals which inform a starting of latching or sampling data during a period of horizontal synchronizing.

The gate driver is a unit which generates passing signals and is connected to the display panel through passing lines S S S . . . Sn. The gate driver approves gate on off voltage Vgh Vgl provided from the voltage driver to the display panel according to the gate controlling signals generated by the timing controller . Gate on voltage Vgh is consecutively provided from gate line not illustrated to gate line N not illustrated to implement a basic frame image on the display panel .

The data driver generates data signals and is connected to the display panel through data lines D D D . . . Dn. The data driver completes scaling according to the data controlling signals generated in the timing controller and inputs RGB data of the image frame to the display panel . The data driver converts the RGB image data provided in serial from the timing controller to be in parallel converts digital data to analogue voltage and provides image data corresponding to one horizontal line to the display panel . This process is implemented consecutively in each horizontal line.

The voltage driver generates and delivers driving voltage to the gate driver the data driver and the display panel respectively. In other words the voltage driver generates and provides electrical power voltage VDD necessary for the display panel or provides grounded voltage VSS by receiving commonly used external electrical power i.e. alternate voltage of 110 V or 220 V. Further it may generate and provide gate on voltage Vgh to the gate driver . The voltage driver may include a plurality of voltage driving modules not illustrated which operate separately for the above process. The plurality of voltage driving modules not illustrated may operate to provide different voltages according to controlling of the controller . The controller may control the voltage driver so that the plurality of voltage driving modules provide different driving voltages according to preset information. For example each of the plural voltage driving modules may provide different first voltage and defaulted second voltage by controlling of the controller according to preset information.

According to an embodiment the voltage driver may include the plurality of voltage driving module corresponding to each area of the display panel which is divided into a plurality of areas. In this case the controller may control the plurality of voltage driving module to provide the different first voltage i.e. ELVDD voltage according to screen information or inputted image information in each of the plural areas. Thus the controller may control amount of ELVDD voltage by using image information inputted to the data driver . The screen information may be at least one of brightness information and grey scale information regarding the inputted image.

The display panel forms the plurality of gate lines GL GLn not illustrated and data lines D Dn to be crossed with each other and define pixel areas and RGB emitting diode such as OLED may be formed on crossed pixel area . A switching diode i.e. a TFT may be formed on one area of the pixel area for example on the corner. While the TFT is turned on grey scale voltage from the data driver is provided to R G B emitting diodes respectively. At this step R G B emitting diodes provide light in response to the amount of the provided electrical current based on the grey scale voltage. As more electrical current is provided the R G B emitting diodes provide more light.

Referring to the display panel from includes R G B pixel areas . The R G B pixel area may include scan signals S switching diodes M M M which operate by gate on voltage Vgh switching diodes M M M which output electrical current based on pixel values including moderated grey scale values provided through the data lines D Dn and switching diodes M M M which adjust electrical current provided to the R G B emitting diode from the switching diodes M M M according to controlling signals provided from the timing controller . Further the switching diodes M M M provide electrical current to OLED by connecting the OLED to electrical current from switching diodes M M M . The OLED indicates a display which emits lights in itself by the light emitting principle of the electromagnetic field when electrical current flows to fluorescent or phosphorescent organic thin films.

Anode electrodes of the OLED connect to pixel circuits and cathode electrodes connect to VSS. Each OLED generates light having a certain brightness in response to electrical currents provided from the respective pixel circuits. Gate electrodes of the switching diodes M M M connect to a passing line S and any one of source electrodes and drain electrodes connects to a data line D D D . A capacitor C C C may be connected between voltage VDD VDD VDD and the source drain of the switching diodes M M M connected to the gate of switching diode M M M . The display panel may be implemented as active matrix OLED panel AMOLED panel .

The above embodiment is one of the exemplary embodiments and the general inventive concept does not exclude for example passive matrix OLED PMOLED in which one line simultaneously emits and operates.

Referring to the multi display apparatus manages the first and second frame buffers with a separate storing method or a united storing method at operation S. The separate storing method indicates a method which controls display screens by recognizing the first frame buffer and the second frame buffer as separate frame buffers. The united storing method indicates a method which controls display screens by recognizing the first frame buffer and the second frame buffer as a united frame buffer.

The multi display apparatus stores data in the first and second frame buffers by converting a managing method according to data features displayed on the first and second displays at operation S. The multi display apparatus uses the separate storing method when the first and second displays are determined to display separate screens and uses the united storing method when the first and second displays are determined to display one screen.

The first and second displays display the data stored in the first and second frame buffers at operation S.

According to the above various embodiments the multi display apparatus examines rotation information when a screen rotating event occurs. The multi display apparatus stores the screen data converted by using the examined rotation information on corresponding frame buffer and outputs the data to the display.

The present general inventive concept can also be embodied as computer readable codes on a computer readable medium. The computer readable medium can include a computer readable recording medium and a computer readable transmission medium. The computer readable recording medium is any data storage device that can store data as a program which can be thereafter read by a computer system. Examples of the computer readable recording medium include a semiconductor memory device a read only memory ROM a random access memory RAM CD ROMs magnetic tapes floppy disks and optical data storage devices. The computer readable recording medium can also be distributed over network coupled computer systems so that the computer readable code is stored and executed in a distributed fashion. The computer readable transmission medium can transmit carrier waves or signals e.g. wired or wireless data transmission through the Internet . Also functional programs codes and code segments to accomplish the present general inventive concept can be easily construed by programmers skilled in the art to which the present general inventive concept pertains

For example a non transitory computer readable medium may store programs which implement the following steps managing the first and second frame buffers with one of the separate storing methods that manages the first and second frame buffers separately to store data and the united storing method that manages the first and second frame buffers as one virtual united frame buffer to store data storing data in the first and second frame buffers by converting a managing method according to data features displayed on the first and second displays and displaying the stored data in the first and second frame buffers.

Although a few embodiments of the present general inventive concept have been shown and described it will be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the general inventive concept the scope of which is defined in the appended claims and their equivalents.

