---

title: Systems and methods for spoken dialog service arbitration
abstract: Systems and methods for arbitrating spoken dialog services include determining a capability catalog associated with a plurality of devices accessible within an environment. The capability catalog includes a list of the plurality of devices mapped to a list of spoken dialog services provided by each of the plurality of devices. The system arbitrates between the plurality of devices and the spoken dialog services in the capability catalog to determine a selected device and a selected dialog service.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09396727&OS=09396727&RS=09396727
owner: GM GLOBAL TECHNOLOGY OPERATIONS LLC
number: 09396727
owner_city: Detroit
owner_country: US
publication_date: 20131202
---
This application claims priority to U.S. Prov. Pat. App. No. 61 844 646 filed Jul. 10 2013 the entire contents of which are incorporated by reference herein.

The technical field generally relates to speech systems and more particularly relates to methods and systems for selecting between available spoken dialog services.

Vehicle spoken dialog systems or speech systems perform among other things speech recognition based on speech uttered by occupants of a vehicle. The speech utterances typically include commands that communicate with or control one or more features of the vehicle as well as other systems that are accessible by the vehicle. A speech system generates spoken commands in response to the speech utterances and in some instances the spoken commands are generated in response to the speech system needing further information in order to perform the speech recognition.

Increasingly such spoken dialog services may be provided by multiple devices and or applications within the user s environment. In the context of a vehicle spoken dialog system for example it is not unusual for such services to be available simultaneously from the user s mobile device via one or more applications resident on the mobile device the vehicle s onboard speech system and external third party servers which are coupled via a network to an onboard communication network .

In such cases two or more of the spoken dialog services might be candidates for processing a given speech utterance and or for performing the requested task while perhaps only one of the services is optimal or even suitable for the user s particular requirements. For example a request for navigation information might be processed by either the onboard navigation system or a navigation application resident on the user s smartphone with both systems having respective strengths and weaknesses in a particular context. In known systems this issue is addressed via the use of multiple buttons or other user interface techniques e.g. based on which application is in focus on a touch screen each corresponding to a particular spoken dialog service. Such methods can lead to user distraction and or other unsatisfactory results.

Accordingly it is desirable to provide improved methods and systems for selecting spoken dialog services in a speech system. Furthermore other desirable features and characteristics of the present invention will become apparent from the subsequent detailed description and the appended claims taken in conjunction with the accompanying drawings and the foregoing technical field and background.

Methods and systems are provided for arbitrating spoken dialog services. In accordance with various embodiments a capability catalog associated with a plurality of devices accessible within an environment e.g. a vehicle is determined. The capability catalog includes a list of the devices mapped to a list of spoken dialog services provided by each of the plurality of devices. The system arbitrates between the plurality of devices and the spoken dialog services in the capability catalog to determined a selected device and a selected dialog service. The system then forwards the spoken utterance to the selected spoken dialog service on the selected device.

In one embodiment the system receives a spoken utterance from a user within the environment classifies the spoken utterance to determine a set of candidate devices and a set of spoken dialog services based on the capability catalog and determines a selected device from the set of candidate devices and a selected spoken dialog service from the set of candidate spoken dialog services based on a verification criterion.

The following detailed description is merely exemplary in nature and is not intended to limit the application and uses. Furthermore there is no intention to be bound by any expressed or implied theory presented in the preceding technical field background brief summary or the following detailed description. As used herein the term module refers to an application specific integrated circuit ASIC an electronic circuit a processor shared dedicated or group and memory that executes one or more software or firmware programs a combinational logic circuit and or other suitable components that provide the described functionality.

Referring now to in accordance with exemplary embodiments of the subject matter described herein a spoken dialog system or simply speech system is provided within a vehicle . In general speech system provides speech recognition dialog management and speech generation for one or more vehicle systems through a human machine interface module HMI module configured to be operated by or otherwise interface with one or more users e.g. a driver passenger etc. . Such vehicle systems may include for example a phone system a navigation system a media system a telematics system a network system and any other vehicle system that may include a speech dependent application. In some embodiments one or more of the vehicle systems are communicatively coupled to a network e.g. a proprietary network a 4G network or the like providing data communication with one or more back end servers .

One or more mobile devices might also be present within vehicle including one or more smart phones tablet computers feature phones etc. Mobile device may also be communicatively coupled to HMI through a suitable wireless connection e.g. Bluetooth or WiFi such that one or more applications resident on mobile device are accessible to user via HMI . Thus a user will typically have access to applications running on at three different platforms applications executed within the vehicle systems themselves applications deployed on mobile device and applications residing on back end server . Furthermore one or more of these applications may operate in accordance with their own respective spoken dialog systems and thus multiple devices might be capable to varying extents to respond to a request spoken by user .

Speech system communicates with the vehicle systems and through a communication bus and or other data communication network e.g. wired short range wireless or long range wireless . The communication bus may be for example a controller area network CAN bus local interconnect network LIN bus or the like. It will be appreciated that speech system may be used in connection with both vehicle based environments and non vehicle based environments that include one or more speech dependent applications and the vehicle based examples provided herein are set forth without loss of generality.

As illustrated speech system includes a speech understanding module a dialog manager module and a speech generation module . These functional modules may be implemented as separate systems or as a combined integrated system. In general HMI module receives an acoustic signal or speech utterance from user which is provided to speech understanding module .

Speech understanding module includes any combination of hardware and or software configured to processes the speech utterance from HMI module received via one or more microphones using suitable speech recognition techniques including for example automatic speech recognition and semantic decoding or spoken language understanding SLU . Using such techniques speech understanding module generates a list or lists of possible results from the speech utterance. In one embodiment list comprises one or more sentence hypothesis representing a probability distribution over the set of utterances that might have been spoken by user i.e. utterance . List might for example take the form of an N best list. In various embodiments speech understanding module generates list using predefined possibilities stored in a datastore. For example the predefined possibilities might be names or numbers stored in a phone book names or addresses stored in an address book song names albums or artists stored in a music directory etc. In one embodiment speech understanding module employs front end feature extraction followed by a Hidden Markov Model HMM and scoring mechanism.

Dialog manager module includes any combination of hardware and or software configured to manage an interaction sequence and a selection of speech prompts to be spoken to the user based on list . When a list contains more than one possible result dialog manager module uses disambiguation strategies to manage a dialog of prompts with the user such that a recognized result can be determined. In accordance with exemplary embodiments dialog manager module is capable of managing dialog contexts as described in further detail below.

Speech generation module includes any combination of hardware and or software configured to generate spoken prompts to a user based on the dialog determined by the dialog manager module . In this regard speech generation module will generally provide natural language generation NLG and speech synthesis or text to speech TTS .

List includes one or more elements that represent a possible result. In various embodiments each element of the list includes one or more slots that are each associated with a slot type depending on the application. For example if the application supports making phone calls to phonebook contacts e.g. Call John Doe then each element may include slots with slot types of a first name a middle name and or a last name. In another example if the application supports navigation e.g. Go to 1111 Sunshine Boulevard then each element may include slots with slot types of a house number and a street name etc. In various embodiments the slots and the slot types may be stored in a datastore and accessed by any of the illustrated systems. Each element or slot of the list is associated with a confidence score.

In addition to spoken dialog users might also interact with HMI through various buttons switches touch screen user interface elements gestures e.g. hand gestures recognized by one or more cameras provided within vehicle and the like. In one embodiment a button e.g. a push to talk button or simply talk button is provided within easy reach of one or more users . For example button may be embedded within a steering wheel .

Referring now to in accordance with various exemplary embodiments HMI module includes an arbitration module that is communicatively coupled through suitable communication channels either wired or wireless to one or more devices . In the illustrated embodiment for example three devices are communicatively coupled to arbitration module device device and device . Devices might correspond to various components or combinations of components illustrated in . For example device might correspond to mobile device in device might correspond to backend server in and device might correspond to HMI module working in conjunction with one or more of vehicle devices etc.

Each device may include one or more applications configured to perform a spoken dialog service or services as described above. For example as illustrated device includes an application device includes applications and and device includes applications and . Furthermore an individual application etc. might be capable of performing more than one spoken dialog service. For example a single application might be configured to recognize spoken dialog and based on that spoken dialog provide both navigation services as well as media services. In the exemplary spoken dialog services are denoted by square regions within each application e.g. services and of application .

A variety of applications are known to be capable of performing spoken dialog services and more are likely to be developed in the future. Current examples of such applications include but are not limited to Pandora Internet Radio iGo Navigation Google Maps Google Now Stitcher as well as various vehicle navigation system applications known in the art.

Referring now to an arbitration module in accordance with one embodiment will now be described in conjunction with an exemplary arbitration method depicted in . As illustrated in arbitration module includes a device classification module a service classification module a verification module a device gate module and a capability catalog also sometimes referred to as a capability map .

Initially the capability catalog is determined at in . With reference to capability catalog includes any suitable data structure or structures for storing data associated with the capabilities e.g. application functionality hardware limitations etc. of devices . In one embodiment capability catalog includes a list of the available devices e.g. mapped to a list of spoken dialog services provided by each of the plurality of devices. So for example capability catalog might reflect that with respect to applications having spoken dialog services device is capable of performing navigation services and media services device is capable of performing only navigation services which may the same or different from those performed by device and device is capable of performing only streaming radio services.

Capability catalog may be populated in accordance with a variety of known techniques. For example a registration procedure may be performed when each of the devices are powered up or otherwise communicatively coupled to arbitration module . Bluetooth and or WiFi association techniques may be employed to interrogate each device to determine the respective spoken dialog services provided by each device .

Upon receiving a spoken utterance device classification module classifies that utterance to determine a set of candidate devices based on the capability catalog at in . That is with reference back to using the list of devices and services stored by capability catalog device classification module determines a set e.g. an N best list of devices configured to perform the requested function. This set may include all devices a proper subset of devices or none of the devices . In accordance with one embodiment device classification module is configured to produce a confidence level associated with each devices listed in the set. For example device classification module may determine that devices and are both capable of performing navigation functions but that its confidence level is higher for device than based on one or more factors e.g. hardware capabilities historical training data and the like . Historical training data includes any information related to devices and or services employed previously by the system for particular spoken utterances or any other non spoken interaction that indicates a user preference system performance or the like. Device classification module may then apply one or more learning algorithms to the historical training data to classify a spoken utterance.

Similarly upon receiving spoken utterance service classification module classifies the spoken utterance to determine a set of candidate services based on the capability catalog at in . With regard back to as with device classification module this module uses the list of devices and services stored by capability catalog to determine a set e.g. an N best list of services configured to perform the requested task. In accordance with one embodiment service classification module is configured to produce a confidence level associated with each service listed in the set. For example device classification module may determine that services within devices and are both capable of performing navigation functions but that its confidence level is higher for device than device based on one or more factors e.g. software limitations and or historical training data .

Verification module which is communicatively coupled to both modules and reconciles the possibly conflicting candidates provided by device classification module and service classification module at in . That is verification module is configured to select a device or devices from the set of candidate devices and corresponding spoken dialog services from the set of candidate spoken dialog services to produce an ordered list of one or more device service pairs. In one embodiment this selection is based on a verification criterion as described in more detail below. The verification criterion may be based on at least one of the hardware capabilities of each of the candidate devices the monetary cost of each of the candidate spoken dialog services the functionality of each of the candidate spoken dialog services.

With reference to verification module is configured to communicate one way with dialog manager . This allows additional dialog with the user to be performed in order to clarify possible ambiguities in the desired task . For example the user may be asked to explicitly choose via spoken dialog or otherwise which device and or which service should be used for the task.

After determining the selected device and the selected service that information is provided by dialog manager to device gate module which thereupon processes the spoken utterance with the selected spoken dialog service on the selected device. That is the result or results from that service are used to accomplish the task requested by the user. For example device gate module might process the spoken utterance with the navigation service residing on device .

Since arbitration module effectively treats each device as a black box and operates in an open loop to forward the speech utterance to the selected device the embodiment illustrated in may be referred to as a router mode arbitration module.

Referring now to an arbitration module in accordance with another embodiment will now be described in conjunction with an exemplary arbitration method depicted in . As illustrated arbitration module includes a device classification module a service classification module a verification module a device application programming interface API module and a capability catalog . Thus the embodiment depicted in is similar to that shown in with the exception that it includes a device API module capable of interfacing more closely with the internal spoken dialog functionality of each device . Furthermore as noted by the arrows interconnecting the various modules the communication from module to dialog manager is two way as is the communication from device API module to devices and from verification module to device API module . During normal operation the embodiment illustrated in may perform in a manner consistent with that of and i.e. in a router mode . However if it is determined that verification and or classification of the spoken utterance fails or is indeterminate then the procedure shown in may be performed. More particularly the spoken utterance is sent to two or more of devices via device API and those devices then send back confidence scores associated with recognition of the spoken utterance at in . The devices will typically also send back a response e.g. a prompt. 

Verification is then performed via verification module at based on the confidence scores received from devices . The system determines whether ambiguity remains at . If not the system utilizes the selected device and selected spoken dialog service at and responds to the user with the received prompt if any . If ambiguity remains then arbitration module may through dialog manager request additional information from the user and then continue at until the ambiguity is sufficiently resolved. Since arbitration module uses dialog manager and API to operate interactively and directly with devices the embodiment illustrated in may be referred to as an integrated mode arbitration module.

In one embodiment default settings for selection of spoken dialog services and associated devices are provided. Those default preference settings are then modified i.e. the user s preferences for certain tasks based upon user behavior. For example the system might modify the preferences based on the user performing a certain task using a particular spoken dialog service. The user then may be prompted to preserve that preference e.g. Would you like to always send address requests to Google Maps .

By way of example the following dialog illustrates various use cases. In each case the arbitrator module determines which device and which dialog service to employ e.g. a built in device or a smart phone device in response to the user s spoken utterance.

In general the methods described above may be implemented using any level of desired automation. That is for example arbitration may be accomplished a automatically with no user input b automatically but giving the user an opportunity to change or c automatically but allowing the user to confirm.

While at least one exemplary embodiment has been presented in the foregoing detailed description it should be appreciated that a vast number of variations exist. It should also be appreciated that the exemplary embodiment or exemplary embodiments are only examples and are not intended to limit the scope applicability or configuration of the disclosure in any way. Rather the foregoing detailed description will provide those skilled in the art with a convenient road map for implementing the exemplary embodiment or exemplary embodiments. It should be understood that various changes can be made in the function and arrangement of elements without departing from the scope of the disclosure as set forth in the appended claims and the legal equivalents thereof.

