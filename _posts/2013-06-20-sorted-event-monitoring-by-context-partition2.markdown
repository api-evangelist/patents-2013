---

title: Sorted event monitoring by context partition
abstract: An event monitoring system that includes two stages, an event sorting stage and an event processing stage. The event sorting stage receives events provided by at least one application, and includes multiple event sorting systems. The event processing stage includes at least one event processing system that processes events forwarded by the event sorting stage. The event processing system(s) is/are capable of processing events that fall within a particular set of one or more context partitions that correspond to the respective event processing system. As the event sorting system receives an event, the event sorting system identifies which context partition the event falls within. The event sorting system then identifies the event processing system that corresponds to the identified context partition of the event, and then forwards the event to the identified event processing system. The event processing system then applies the set of one or more monitoring rules.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09584379&OS=09584379&RS=09584379
owner: Microsoft Technology Licensing, LLC
number: 09584379
owner_city: Redmond
owner_country: US
publication_date: 20130620
---
Operations monitoring systems often applies monitoring rules against streams of events generated in the course of operations. The stream of events is used to evaluate or characterize operations such as whether operations are proceeding normally or whether one or more problems are occurring. One of the key metrics to measure efficiency of such monitoring systems is the shortness of the Mean Time to Mitigate MTTM . MTTM refers to the mean time measured from the moment a problem appeared the first time to the time the problem is mitigated. MTTM relies on a metric called Time to Detect TTD which is the time from when the problem first appeared until the time that the problem was detected. After all a course of action for mitigating a problem cannot be initiated until the problem itself is identified.

Accordingly low latency problem detection solutions have been developed in such monitoring systems. One way to provide low latency is by offloading local event processing on agent machines while leaving cross component aggregation and other higher level processing to central management servers. This solution works fine with applications deployed on a single machine when a local agent can cover the monitoring needs for a given application.

At least some embodiments described herein relate to an event monitoring system that includes two stages an event sorting stage and an event processing stage. The event sorting stage receives events provided by at least one application and includes multiple event sorting systems. The event processing stage includes at least one event processing system that processes events forwarded by the event sorting stage. The event processing system s is are capable of processing events that fall within a particular set of one or more context partitions that correspond to the respective event processing system.

As the event sorting system receives an event the event sorting system identified which context partition the event falls within. A context partition refers to a set of one or more characteristics in which all events possessing that set of characteristics will be monitored under the same set of one or more monitoring rules. The event sorting system then identifies the event processing system that corresponds to the identified context partition of the event. The event is then forwarded to the identified event processing system. The event processing system then applies the set of one or more monitoring rules.

As all of the events corresponding to a particular context partition are processed on a single event processing system event processing may occur efficiently allowing streams of events to also be efficiently processed even if the stream of events are generated by a distributed application and provide different streams to different event sorting systems.

This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

At least some embodiments described herein relate to an event monitoring system that includes two stages an event sorting stage and an event processing stage. The event sorting stage receives events provided by at least one application and includes multiple event sorting systems. The event processing stage includes at least one event processing system that processes events forwarded by the event sorting stage. The event processing system s is are capable of processing events that fall within a particular set of one or more context partitions that correspond to the respective event processing system.

As the event sorting system receives an event the event sorting system identifies which context partition the event falls within. A context partition refers to a set of one or more characteristics in which all events possessing that set of characteristics will be monitored under the same set of one or more monitoring rules. The event sorting system then identifies the event processing system that corresponds to the identified context partition of the event. The event is then forwarded to the identified event processing system. The event processing system then applies the set of one or more monitoring rules.

As all of the events corresponding to a particular context partition are processed on a single event processing system event processing may occur efficiently allowing streams of events to also be efficiently processed even if the stream of events are generated by a distributed application and provide different streams to different event sorting systems.

Some introductory discussion of a computing system will be described with respect to . Then embodiments of an event monitoring system and its operation will be described with respect to subsequent figures.

Computing systems are now increasingly taking a wide variety of forms. Computing systems may for example be handheld devices appliances laptop computers desktop computers mainframes distributed computing systems or even devices that have not conventionally been considered a computing system. In this description and in the claims the term computing system is defined broadly as including any device or system or combination thereof that includes at least one physical and tangible processor and a physical and tangible memory capable of having thereon computer executable instructions that may be executed by the processor. The memory may take any form and may depend on the nature and form of the computing system. A computing system may be distributed over a network environment and may include multiple constituent computing systems.

As illustrated in in its most basic configuration a computing system typically includes at least one processing unit and memory . The memory may be physical system memory which may be volatile non volatile or some combination of the two. The term memory may also be used herein to refer to non volatile mass storage such as physical storage media. If the computing system is distributed the processing memory and or storage capability may be distributed as well. As used herein the term executable module or executable component can refer to software objects routings or methods that may be executed on the computing system. The different components modules engines and services described herein may be implemented as objects or processes that execute on the computing system e.g. as separate threads .

In the description that follows embodiments are described with reference to acts that are performed by one or more computing systems. If such acts are implemented in software one or more processors of the associated computing system that performs the act direct the operation of the computing system in response to having executed computer executable instructions. For example such computer executable instructions may be embodied on one or more computer readable media that form a computer program product. An example of such an operation involves the manipulation of data. The computer executable instructions and the manipulated data may be stored in the memory of the computing system . Computing system may also contain communication channels that allow the computing system to communicate with other message processors over for example network .

Embodiments described herein may comprise or utilize a special purpose or general purpose computer including computer hardware such as for example one or more processors and system memory as discussed in greater detail below. Embodiments described herein also include physical and other computer readable media for carrying or storing computer executable instructions and or data structures. Such computer readable media can be any available media that can be accessed by a general purpose or special purpose computer system. Computer readable media that store computer executable instructions are physical storage media. Computer readable media that carry computer executable instructions are transmission media. Thus by way of example and not limitation embodiments of the invention can comprise at least two distinctly different kinds of computer readable media computer storage media and transmission media.

Computer storage media includes RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other tangible medium which can be used to store desired program code means in the form of computer executable instructions or data structures and which can be accessed by a general purpose or special purpose computer.

A network is defined as one or more data links that enable the transport of electronic data between computer systems and or modules and or other electronic devices. When information is transferred or provided over a network or another communications connection either hardwired wireless or a combination of hardwired or wireless to a computer the computer properly views the connection as a transmission medium. Transmissions media can include a network and or data links which can be used to carry or desired program code means in the form of computer executable instructions or data structures and which can be accessed by a general purpose or special purpose computer. Combinations of the above should also be included within the scope of computer readable media.

Further upon reaching various computer system components program code means in the form of computer executable instructions or data structures can be transferred automatically from transmission media to computer storage media or vice versa . For example computer executable instructions or data structures received over a network or data link can be buffered in RAM within a network interface module e.g. a NIC and then eventually transferred to computer system RAM and or to less volatile computer storage media at a computer system. Thus it should be understood that computer storage media can be included in computer system components that also or even primarily utilize transmission media.

Computer executable instructions comprise for example instructions and data which when executed at a processor cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions. The computer executable instructions may be for example binaries intermediate format instructions such as assembly language or even source code. Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the described features or acts described above. Rather the described features and acts are disclosed as example forms of implementing the claims.

Those skilled in the art will appreciate that the invention may be practiced in network computing environments with many types of computer system configurations including personal computers desktop computers laptop computers message processors hand held devices multi processor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers mobile telephones PDAs pagers routers switches and the like. The invention may also be practiced in distributed system environments where local and remote computer systems which are linked either by hardwired data links wireless data links or by a combination of hardwired and wireless data links through a network both perform tasks. In a distributed system environment program modules may be located in both local and remote memory storage devices.

The event monitoring system receives events from the applications . For instance the event monitoring system receives events through from the applications although the ellipses represents that the principles described herein may be used to monitor a large number of events from the applications .

One or more of the applications may each be located on a single computing system such as the computing system of . One or more of the applications might alternatively be distributed applications with components running on different computing systems that are perhaps remotely located and perhaps may be located in different parts of the globe. In fact a particular advantage of at least some embodiments described herein is that the event monitoring system may efficiently and quickly process events from multiple applications even where one or more or even all of those applications are distributed. As an example the application is illustrated as including two components A and B although the distributed application may have many more components . The two components A and B may be operated on different computing systems.

The event monitoring system includes two stages including an event sorting stage and an event processing stage . The event sorting stage includes multiple event sorting systems through although the ellipses represent that the event sorting stage may include any number of event sorting systems. The event processing stage includes multiple event processing systems through although the ellipses represent that the event processing stage may include any number of event processing systems. Each event sorting system through and each event processing system through may be structured as described above for the computing system of . The event sorting stage and the event processing stage may each be distributed.

The event sorting stage receives events such as events through from various applications such as applications of . For instance each of the event sorting systems through receives a subset of the total flow of events that are received by the event sorting stage . For events that are received by a given event sorting system through the event sorting system through determines a context partition associated with each event and then forwards the event to whichever of multiple event processing systems is dedicated to processing events of that context partition.

A context partition is defined as a set of one or more characteristics of an event in which at least some of the events that share that common set of one or more characteristics are to be monitored collectively in a correlated way so as to give rise to monitoring state. Because of this events may be more efficiently monitored if the events of a common context partition are monitored on the same machine. Examples of the set of one or more characteristics include any one or more of the following a customer identifier an application identifier a hosted service name a role identifier a namespace a network site identifier a time identifier and so forth. That said the identity of what parameters may be used to define a partition is quite flexible. For instance as described further below a partition segment identifier may be used to implement loopback to allow even large partitions to be efficiently processed in multiple stages.

As an example only the event processing system is illustrated as dedicated to processing two context partitions A and B the event processing system is illustrated as dedicated to processing a single context partition the event processing system is illustrated as dedicated to processing two context partitions A and B and the event processing system is illustrated as dedicated to processing two context partitions A and B.

This means that no matter which event sorting system through actually receives an event having a particular context partition that event will be forwarded to the correct event processing system through that monitors events of a particular context partition. Thus events of a common context partition are monitored on the same event processing system thereby being monitored more efficiently even for events generated by distributed applications.

The monitoring rules to be applied when monitoring a particular partition are on the corresponding event processing system for that partition. Such localization of the monitoring rules to the same event processing system as the partition to which the monitoring rules are to be applied allows for faster application of the monitoring rules.

Such monitoring rules may include standard monitoring rules and custom monitoring rules. For instance standard monitoring rules may be encompassed in a different object class than the custom monitoring rules. The standard monitoring rules object might include more general input parameters such as perhaps a type of monitoring to be performed e.g. safety . The custom monitoring rules on the other had may be populated with more detailed configuration that defines custom monitoring.

The monitoring rules may also be applied to streaming events causing state to be maintained at the event processing system associated with the partition whose streaming events are to be monitored. Such state may be maintained in a processor addressable data vessel of the corresponding event processing system. In this description a processor addressable data vessel is defined as non volatile and or volatile locations where data may be placed and which may be addressable using a processor. An example of a processor addressable data vessel is computer memory which can be directly addressed by a processor and which conventionally is volatile but in modern systems can also be partially or even fully non volatile across its range of valid address locations.

This example is kept relatively simply in terms of the number of context partitions being processed by each of the event processing systems. However the number of context partitions managed by a single event processing system may vary from as few as a single context partition to enumerable context partitions. Factors that may limit the number of context partitions processed by a single event processing system include the rate of incoming events anticipated for a particular context partition and the amount of the processor addressable data vessel usable by code that keeps track of state used to performing monitoring rules on the context partition.

Higher event rates will place a higher demand on the processing resources of the event processing system. Furthermore larger requirements for tracking state will place a higher demand on the memory resources of the event processing system. It is advantageous to keep all state in memory so that processing may occur more quickly and thus the time required to apply the monitoring rules on incoming event streams for a given context partition are reduced. This is enabled by consolidating all events of a common context partition on the same computing system and the same processor addressable data vessel.

Again illustrates a flowchart of a method for an event sorting system to sort incoming events. The method is initiated upon a particular event sorting system receiving an event act . For instance referring to the example of the event sorting system receives the event the event sorting system receives the event and the event and the event sorting system receives the event and the event .

The event sorting system that received the event then identifies which context partition the event falls within act identifies the event processing system act that corresponds to the identified context partition of the event and forwards the event towards the identified event processing system act . Optionally the event sorting system also modifies the event act so that the event processing system can use the event itself to identify which context partition the event belongs to.

For instance in in response to receiving the event act the event sorting system identifies the context partition as corresponding to the event act identifies the event processing system as corresponding to the context partition act and forwards the event to the event processing system as represented by the arrow act . When sorting the event the event sorting system might modify act the event to add an identification of the context partition so that the event processing system may quickly identify that the event belongs to the context partition . Alternatively or in addition perhaps the event is not modified to identify the context partition of the associated event but the event sorting system provides information such as the partition identifier in some other manner such as in a separate communication to the associated event processing system .

Further in response to receiving the event act the event sorting system identifies the context partition as corresponding to the event act identifies the event processing system as corresponding to the context partition act and forwards the event to the event processing system as represented by the arrow act . When sorting the event the event sorting system might modify act the event and or communicate the partition identifier to the corresponding event processing system to add an identification of the context partition so that the event processing system may quickly identify that the event belongs to the context partition .

Continuing the example in response to receiving the event act the event sorting system identifies the context partition A as corresponding to the event act identifies the event processing system as corresponding to the context partition A act and forwards the event to the event processing system as represented by the arrow act . When sorting the event the event sorting system might modify act the event to add an identification of the context partition A and or communicate the partition identifier to the corresponding event processing system so that the event processing system may quickly identify that the event belongs to the context partition A.

Continuing in response to receiving the event act the event sorting system identifies the context partition B as corresponding to the event act identifies the event processing system as corresponding to the context partition B act and forwards the event to the event processing system as represented by the arrow act . When sorting the event the event sorting system might modify act the event to add an identification of the context partition B and or communicate the partition identifier to the corresponding event processing system so that the event processing system may quickly identify that the event belongs to the context partition B.

Completing the example in response to receiving the event act the event sorting system identifies the context partition A as corresponding to the event act identifies the event processing system as corresponding to the context partition A act and forwards the event to the event processing system as represented by the arrow act . When sorting the event the event sorting system might modify act the event to add an identification of the context partition A and or communicate the partition identifier to the corresponding event processing system so that the event processing system may quickly identify that the event belongs to the context partition A.

The event sorting stage may also be distributed perhaps even throughout the globe. This might explain why in this example event generated by component A of the distributed application was received by the event sorting system whereas the events and generated by the component B of the same distributed application were received by the event sorting system . In this case the event sorting system may be more proximate from a network routing perspective hereinafter referred to simply as network proximate to the first component A whereas the event sorting system may be more network proximate to the second component B.

The method is initiated by an event processing system upon receiving and event from the event sorting stage act . The event processing system then identifies the context partition to which the event belongs act . For instance if the context partition is identified in the event itself due to the optional performance of act the content partition of the event might be identified by simply reading the context partition identifier. The monitoring rules to be applied to that partition are accessed and applied to the event act according to the event s context partition. illustrates a flowchart of a method for applying monitoring rules to events received from the event sorting stage and represents an example of the act of .

In accordance with method the input event might possibly be used to generate an output event that may be acted upon. First the input event is optionally logged act . The event processing system then verifies whether one or more conditions upon which generation of the output event is predicated have been satisfied decision block . If the condition s is are not satisfied No in decision block processing of the input event ends act .

If the condition s is are satisfied Yes in decision block the input event is used to generate an output event act . The output event may be of a different event type than the input event. Examples of event types include for example 1 a performance metric sample which describes a performance metric provided by the application 2 an alter change event which opens and closes an alert in the monitoring system 3 an availability state event which indicates whether or not particular services are available and 4 other events such as custom events.

Note that the decision on whether the condition is met decision block might be based on state associated with the partition. For instance suppose the monitoring rule is to generate a warning event if all events received in a rolling window of the most recent 3 hours indicate processor usage in excess of a certain percentage of capacity. In that case perhaps there are tens of thousands of events received in the last 3 hours. Suppose now that the most recent event causes the 3 hour rolling average to increase above the threshold. The decision on whether or not the condition is met decision block would then actually involve much more than an analysis of the most recent invent but would also involve an analysis of the partition state in which the information regarding the prior 9 999 events is represented.

Action is then taken upon the output event act . The content of act illustrates three potential example actions and that might be taken on the output event. As an example the event processing system might save the output event act such as to an identified store. Alternatively or in addition the event processing system might transmit the output event outside of the system act . Alternatively or in addition the event processing system might loop back the event act which will now be described in further detail with respect to .

Looping back of the output event essentially allows the output event to be an input event that is assigned to the same or a different partition for further processing. In the loop back process the event processing system that generated the output event may perform the method and thus act as an event sorting system and treat the output event as a received input to the sorting process.

For instance once the event processing system processes the input event as an event of the context partition B the output event from such processing is looped back as represented by arrow to the same context partition B to be further processed as an input event and thus the output event is subject again to the method .

The loop back arrows and illustrate a different form of looping back in which the output event from one partition is provided as an input event to another partition. For instance the event processing system processes one or both of events and as being part of context partition to generate an output event that is looped back as represented by arrow . The output event is then processed as an input event with a new context partition B. Likewise the event processing system processes one or both of events and as being part of context partition A to generate an output event that is looped back as represented by arrow . The output event is then processed as an input event with the context partition B.

In the case of each of loop back arrows and loop back is used to allow the event processing stage to perform tasks on chains of events. Furthermore as loop back arrows and come from different context partitions to the same context partitions the event processing stage may serve to hierarchically process events.

This may be particularly helpful when context partitions may normally be quite large in the absence of hierarchical processing. For instance perhaps the input stream to that context partition comes at a high rate of speed and or tracking of the state for the context partition would require large amounts of memory. In some cases such a large context partition may simply be too large to process by a single context partition. In that case the task might be divided into several smaller context partitions by further defining a partition by a partition segment identifier each smaller context partition doing the same work and producing an intermediate result. For instance partitions and A might represent examples of such partitions. The output event from each may represent intermediate results allowing the intermediate result events to then be processed by the context partition B. For really large partitions the partition may be perhaps even divided into hundreds or thousands of segments. Such looping back might be accomplished even two or more times in a single workflow to allow three of more stages of processing.

In real time the events received for any particular context partition may indeed be considered to be an input event stream. The processing of the input event stream results in an output event steam albeit perhaps with fewer output events since the processing of some input events will not result in the generation of an output event following the No path in decision block . The number of output events may even be one or more or even many orders of magnitude fewer than the number of input events.

Examples of the implementation of monitoring rules will now be described. That said the broadest principles described herein are not limited at all to the code used to implement the monitoring rules nor whether even software itself is used to apply the monitoring rules. Accordingly these code examples should be viewed as illustrative only.

In one embodiment the input event stream of typed events can be accessed in monitoring rules from special selectors modeled with properties of the IObservable interface. This .Net interface is used by both StreamInsight and Rx as the model of incoming and outgoing data streams for temporal queries. Such temporal queries are accessible from a specific interface called IPartitionData. For example consider the following code example 

This rule is written in C class and uses a temporal query defined in Rx syntax against a selector referenced as IPartitionData data and data.PerfMetricSamples . This selector provides a stream of events of the type Performance Metric Sample within some partition. Thus in this case the input event stream is composed of portions from each of the input events for that partition that was received from the event sorting stage. The rule implementation is hosted inside a method Initialize of a class marked with the interface INamespaceRule which is used to initialize the rule instance.

The data access object with IPartitionData interface contains partition id and namespace id properties as well as represented by the following declaration for the interface 

The resulting stream of the type IObservable is used to keep the reference to the query instance to listen on the query state in case it asynchronously throws the exception or stops. The resulting events themselves may be ignored. That is why the stub structure called Empty is used instead of real values.

The name of the interface suggests that this rule will be applied to the streams of every partition of some specific namespace. That allows creating rules which should work for every data item in the overall stream of events like the detection scenario from this example a perhaps a rule like aggregate and store all submitted performance metrics for this particular customer inside a performance data storage system .

One choice for the rule implementation would be StreamInsight query as well. One could switch between the Rx and StreamInsight contexts according to the following. Rx is a good match for processing sequence of events observed in time when time itself is flowing naturally and is not controlled and the order of events is not defined. This allows only fuzzy time event correlation logic within local timespans unless specialized Schedulers are used . On the other hand StreamInsight technology allows expressing strict time based queries like one event time is equal to another with absolute precision not within some epsilon like it is usual for Rx.

The natural time flow is the case for many monitoring scenarios actually. In fact examples below will be expressed in Rx since they do not need to drive most precise time correlations extensively and local timespans manipulations within some epsilon are sufficient. Nevertheless the basic example with the query implemented in StreamInsight syntax shows how another temporal engine can be naturally used in this monitoring rules model.

To define some action for the stream of given event types the following built in operators might be used SaveAlert SavePerfSample Send Loopback. SaveAlert can be applied to the stream of alert change alerts or the operator may be provided with the selector to convert given stream of events to alert change events. This operator saves the stream of monitor states to an alert store which in turn opens or closes alerts. SavePerfSample has the same logic as SaveAlert but sends the data to the performance data storage system and is be applied to a stream of performance counters events or availability states alerts or provided with corresponding selector . Send can push the data outside of the system to notify partner monitoring system for example . Loopback shares the resulting events for the secondary queries for the same or another partition for example first query aggregates counters across the source and second query defines detection for aggregated counters as explained above.

So to register the alert in monitoring system for the query above one might add a SaveAlert operator for the stream of MonitorState events as follows 

Another form allows the definition of the same semantics with one less operator and with operator ToEmpty which wraps the query chained together as follows 

This query will generate alert for the system for any counter submitted for the partner who defined this query with the value higher than 90. That is not particularly useful from monitoring perspective since it is applied for any counter submitted by given customer. To make this query more specific one need to add stream filtering operators as in the following example 

This is much more meaningful rule which might be extremely useful in some real life scenarios. One of the big advantages of this approach is that the generated alert will be registered in the system with extremely low latency. All the computations defined by this query will be done in memory in real time. So the only delays would be with delivering requests between services which can be done in terms of seconds at most.

The close look at the previous query will reveal that the query is now extremely scenario specific for the very specific source. So when partner wants to setup similar monitoring rule for the same or another source one could define exactly the same rule but with another values hardcoded in the query. That does not look like an efficient way to manage monitoring rules. Besides the last rule would execute over each data item in all streams submitted by partner which might become a problem and a scaling issue. The scale would be limited by the amount of the memory consumed by every partition to host the configuration objects and the query state.

To solve the problem of defining and maintaining almost identical rules and the scaling issues at the same time it is possible to define a rule specific for some context partition defined by a namespace id and partition id in the following example alongside with the rule configuration type. For instance the partner could define the following classes for configuration objects 

The system might provide the REST API for partners to manage configuration object per rule type and the partition. Since the configuration object is submitted for specific partition the scope of data for such rule instance is stream data items pushed into given partition.

The system may host instances of the rule for each configuration object submitted for a specific partition. In case when no matching configuration was provided but the rule was defined with a configuration perhaps no instance of this rule will be hosted in the service.

The lifetime of usual rules that have no configuration are inherited from IRule. Such rules are instantiated automatically for every partition in given namespace hence the name and they do not wait on the configuration to be provided. There is a generic version of IRule as well. Rules of this type perhaps are not instantiated until single instance of configuration is provided for the whole namespace.

For the monitoring rules may be partition specific application specific customer specific Role specific etc. the rule may implement an IRule interface and will be instantiated by configuration objects.

The last query is an example of a monitoring rule for on premise one machine application. In the cloud however application logic is distributed across multiple machines. That means that monitoring rules should be ready to calculate state across multiple machines to detect given condition. And that is to be done with low latency and low cost.

That can be easily with the help of in memory computations expressed as temporal queries. The last query could be extended further for scenarios when real time aggregation of counters across sources is required first definition of configuration class is skipped 

This query is almost the same as the previous version. It has three additional standard Rx operators which are underlined. The semantics for this query is as follows buffer all incoming filtered performance counters for a given period of time and then produce the stream of aggregated counters over different sources which can be used for alerting.

It is worth to point out that highlighted sub query is going could be used across different monitoring rules and can be hidden behind C subroutine 

The underlined operator SelectAverage is a custom made extension which customers can re use out of the box.

That said the above is just a specific example of how the rules might be implemented inside a particular event processing system. Accordingly the more general principles described herein provide an effective system for processing events provided by distributed applications.

The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

