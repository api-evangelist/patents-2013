---

title: Network virtualization-aware data storage system
abstract: A data storage system includes at least one network virtualization-aware switch. The data storage system also includes at least one storage array operatively coupled to the network virtualization-aware switch, wherein the storage array is operatively coupled to at least one host computing device, and wherein the host computing device instantiates at least one virtual machine in at least one virtual network. Further, the data storage system includes at least one controller operatively coupled to the network virtualization-aware switch, wherein the controller is configured to link the storage array with the virtual machine of the virtual network through the network virtualization-aware switch.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09128622&OS=09128622&RS=09128622
owner: EMC Corporation
number: 09128622
owner_city: Hopkinton
owner_country: US
publication_date: 20131216
---
The field relates to computing systems implemented via a distributed virtual infrastructure and more particularly to techniques for enabling network virtualization awareness in a data storage system so as to provide tenant aware storage services in such a distributed virtual infrastructure.

In existing software defined data center SDDC implementations there are multi tenancy supports for software defined storage SDS and a software defined network SDN respectively. Multi tenancy refers to a software architecture paradigm whereby a single instance of an application functional software program executes on a server which serves multiple tenants multiple clients customers . With a multi tenant architecture an application virtually partitions its data and configuration and each tenant operates with a customized virtual application instance.

Traditionally there are two typical usage cases to provision storage to applications i directly exporting a block or file interface to applications and ii delegating storage management to intermediate nodes.

In the first usage case direct export storage arrays servers export storage via Internet Small Computer System Interface iSCSI Network File System NFS Common Internet File System CIFS to end users. The requirement of such usage is that the storage arrays servers be connected to the application s network.

In the second usage case intermediate node storage sometimes the storage arrays servers are designed to be hidden from applications for security issues. Moreover the application s network may be dynamic and invisible to the storage e.g. applications running on mobile devices . Thus applications need not be aware of the storage arrays servers. In a practical system a hypervisor is a suitable candidate to serve as an intermediate node. When storage is provisioned to a hypervisor applications e.g. virtual machines VMs request the storage e.g. virtual disk from the hypervisor. Thus the storage arrays servers do not need to be aware of the virtual network where the VMs reside. Unfortunately file storage NFS CIFS may not be available to the application VMs under such an approach.

Of course storage arrays servers can still serve applications in a virtual network with the assistance of a hypervisor as described above in the second usage case. But under such a situation it is the hypervisor vendor that dictates the storage requirements to storage vendors.

Embodiments of the invention provide techniques for enabling network virtualization awareness in a data storage system so as to provide tenant aware storage services in a distributed virtual infrastructure.

In one embodiment a data storage system comprises at least one network virtualization aware switch. The data storage system also comprises at least one storage array operatively coupled to the network virtualization aware switch wherein the storage array is operatively coupled to at least one host computing device and wherein the host computing device instantiates at least one virtual machine in at least one virtual network. Further the data storage system comprises at least one controller operatively coupled to the network virtualization aware switch wherein the controller is configured to link the storage array with the virtual machine of the virtual network through the network virtualization aware switch.

In another embodiment an article of manufacture comprises a processor readable storage medium having encoded therein executable code of one or more software programs. The one or more software programs when executed by the at least one processing device implement operations of the above described data storage system.

Advantageously illustrative embodiments described herein provide techniques for integration of SDS and SDN NV network virtualization i.e. attaching an allocated storage e.g. a virtual iSCSI volume to a tenant s private virtual network.

These and other features and advantages of the present invention will become more readily apparent from the accompanying drawings and the following detailed description.

Illustrative embodiments of the invention will be described herein with reference to exemplary computing systems and data storage systems as well as associated servers computers storage units computing devices and other processing devices. It is to be appreciated however that embodiments of the invention are not restricted to use with the particular illustrative system and device configurations shown. Moreover the phrases computing system and data storage system as used herein are intended to be broadly construed so as to encompass for example private or public cloud computing or storage systems as well as other types of systems comprising distributed virtual infrastructure. However a given embodiment may more generally comprise any arrangement of one or more processing devices.

As used herein the term cloud refers to a collective computing infrastructure that implements a cloud computing paradigm. For example as per the National Institute of Standards and Technology NIST Special Publication No. 800 145 cloud computing is a model for enabling ubiquitous convenient on demand network access to a shared pool of configurable computing resources e.g. networks servers storage applications and services that can be rapidly provisioned and released with minimal management effort or service provider interaction.

Embodiments of the invention realize that in order change the situation whereby the hypervisor vendor dictates the storage requirements to storage vendors storage products delivered by storage vendors have to meet new network challenges to deliver a high quality of storage services in a virtual network. In a traditional network hosts and servers are deployed in the same network environment Layer2 or Layer3 thus storage input output I O commands e.g. commands of iSCSI contained in network packets issued by the hosts can be naturally understood by the backend storage servers arrays. But in a virtual network the network packets originated by the VMs are encapsulated before transferring and de capsulated upon receiving which is performed by additional switches.

Accordingly an illustrative embodiment of the invention provides an embedded switch in the data storage system to make the data storage system aware of the virtual network. Thus the system provides a high quality of storage service based on the tenant and virtual machine VM information in different virtual networks.

The host computing devices are connected to a data storage system via a physical network represented as switch fabric . The data storage system comprises a plurality of storage arrays by way of example only and . Each storage array has associated therewith an S4NV switch by way of example only and . The S4NV switches are operatively coupled to an SDN NV storage controller . Note that while SDN NV storage controller is shown as wholly a part of the data storage system and separate from SDN NV controller it is to be appreciated that in alternative embodiments some functions of each controller can be shared and otherwise distributed there between.

Since the host computing devices and the storage arrays are connected to the physical network they can naturally communicate with each other without access control. However with a network virtualization overlay technique different tenants are isolated from one another in different virtual networks. For instance VM and VM are in one virtual network and VM and VM are in another virtual network. To achieve this each hypervisor in each host computing device is configured with an NVE the responsibility of which is to encapsulate de capsulate the packets for the VMs . Moreover all NVEs are controlled by the dedicated SDN NV controller such SDN NV controller can be either distributed or centralized.

Conventional storage products cannot be linked into a virtual network created in one or more host computing devices since the storage products have no knowledge of the virtual network. To resolve such an issue embodiments of the invention provide an S4NV switch to make the storage array aware of the virtual networks e.g. virtual network with VM and VM and virtual network with VM and VM . Moreover SDN NV storage controller controls the S4NV switches and interacts with the SDN NV controller to link the virtual storage resources of the storage array into one or more virtual networks of one or more tenants and provide customized storage services.

Advantageously with the embedded S4NV switch approach a data storage system is naturally aware of a created virtual network without a need for external NV aware switches thus making the data storage system more flexible and autonomous in terms of functionality. Also with the embedded S4NV switch approach the data storage system is able to collect more information of the tenants in the different virtual networks and thereby provide customized and high quality storage service.

Thus as will be explained below methodology depicts a detailed procedure to provision storage e.g. iSCSI NFS to tenant VMs in a virtual storage network. When a tenant requests a storage service e.g. file block service in a virtual network the following steps operations occur 

1. The request is intercepted by the SDN NV storage controller which invokes an application programming interface API exported by the storage to NV configurator to proceed with the virtual storage allocation process.

2. Upon receiving the request the storage to NV configurator utilizes the storage VIF configurator to interact with the S4NV switch on the corresponding storage array for configuring a virtual interface VIF to the allocated storage entity the virtual storage resource .

3. When the VIF is successfully created then the storage to NV configurator invokes the attachment configurator to interact with the SDN NV controller . The SDN NV controller attaches the VIF to the tenant virtual network and configures the Internet Protocol IP address via Dynamic Host Configuration Protocol DHCP in one illustrative embodiment.

4. After the connection is constructed the SDN NV storage controller forwards the virtual IP address and the relevant storage service information to the tenant. Then the tenant can advantageously access the exported storage service e.g. Network Attached Storage NAS or iSCSI target in the tenant s own virtual network.

5. Since I O requests in different virtual networks can be uniquely identified by a VNI the data storage system can distinguish tenant VMs by identifier address pairs i.e. . Advantageously different tenants can physically share the same virtual storage resource and or access their own dedicated virtual storage resources . It is to be understood that a virtual storage resource can comprise by way of example only one or more logical storage units LUNs that are instantiated on the plurality of storage arrays of the data storage system.

With such an S4NV switch approach more information of the tenant can be captured and thus different tenants can be identified and data traffic can be accurately measured to the VM level. Thus more customized storage services can be delivered by the data storage system. Advantageously embodiments of the invention can be utilized to meet the I O SLA requirements i.e. quality of service or QoS committed to tenants provide end to end storage I O QoS to each VM in a tenant network and prioritize the storage I O traffic with the specific requirements of different tenants.

In this example the data storage system is composed of a DART Data Access in Real Time operating system EMC Corporation hosted on data movers by way of example only and control station and storage processors or SP by way of example only and . Each data mover as shown comprise a plurality of virtual data movers or VDM by way of example only and in data mover and and in data mover a plurality of virtual network interface cards or vNIC by way of example only and in data mover and and in data mover an S4NV switch by way of example only in data mover and in data mover and a network interface card or NIC by way of example only in data mover and in data mover . As further shown CIFS is operatively coupled to vNIC and NFS is operatively coupled to vNIC .

To provide a file service to a tenant in a designated virtual network e.g. 10.32.105.X the administrators use Unisphere EMC Corporation to control the control station and create a VDM or . Then the administrator can interact with the SDN NV storage controller in to generate a vNIC or and interact with the SDN NV controller in e.g. NVP to generate a virtual IP address in the user s virtual network e.g. 10.32.105.128 . Then a CIFS or NFS service can be built on the created VDM with the allocated IP address. In fact the CIFS NFS service is provisioned by the DART which means the DART operates on the VDM. So if we want to make the VNX system be aware of the NV network via an embedded switch but not relying on a gateway approach the S4NV switch e.g. open vSwitch is added in the DART operating system.

Although only a single hypervisor is shown in the example of a given embodiment of host infrastructure configured in accordance with an embodiment of the invention may include multiple hypervisors each running on its own physical infrastructure. Portions of that physical infrastructure might be virtualized.

As is known virtual machines are logical processing elements that may be instantiated on one or more physical processing elements e.g. servers computers processing devices . That is a virtual machine generally refers to a software implementation of a machine i.e. a computer that executes programs in a manner similar to that of a physical machine. Thus different virtual machines can run different operating systems and multiple applications on the same physical computer. Virtualization is implemented by the hypervisor which as shown in is directly inserted on top of the computer hardware in order to allocate hardware resources of the physical computer physical infrastructure dynamically and transparently. The hypervisor affords the ability for multiple operating systems to run concurrently on a single physical computer and share hardware resources with each other.

An example of a commercially available hypervisor platform that may be used to implement portions of the host infrastructure in one or more embodiments of the invention is the VMware vSphere which may have an associated virtual infrastructure management system such as the VMware vCenter .

The processing device in the processing platform comprises a processor coupled to a memory . The processor may comprise a microprocessor a microcontroller an application specific integrated circuit ASIC a field programmable gate array FPGA or other type of processing circuitry as well as portions or combinations of such circuitry elements.

Components of a computing system as disclosed herein can be implemented at least in part in the form of one or more software programs stored in memory and executed by a processor of a processing device such as processor . Memory or other storage device having such program code embodied therein is an example of what is more generally referred to herein as a processor readable storage medium. Articles of manufacture comprising such processor readable storage media are considered embodiments of the invention. A given such article of manufacture may comprise for example a storage device such as a storage disk a storage array or an integrated circuit containing memory. The term article of manufacture as used herein should be understood to exclude transitory propagating signals.

Furthermore memory may comprise electronic memory such as random access memory RAM read only memory ROM or other types of memory in any combination. The one or more software programs when executed by a processing device such as the processing device causes the device to perform functions associated with one or more of the components steps of system methodology . One skilled in the art would be readily able to implement such software given the teachings provided herein. Other examples of processor readable storage media embodying embodiments of the invention may include for example optical or magnetic disks.

Also included in the processing device is network interface circuitry which is used to interface the processing device with the network and other system components. Such circuitry may comprise conventional transceivers of a type well known in the art.

The other processing devices of the processing platform are assumed to be configured in a manner similar to that shown for processing device in the figure.

The processing platform shown in may comprise additional known components such as batch processing systems parallel processing systems physical machines virtual machines virtual switches storage volumes logical units etc. Again the particular processing platform shown in is presented by way of example only and system of may include additional or alternative processing platforms as well as numerous distinct processing platforms in any combination.

Note also that the components of may also be implemented in a processing platform such as the one depicted in .

Also numerous other arrangements of servers computers storage devices or other components are possible. Such components can communicate with other elements of the system over any type of network such as a wide area network WAN a local area network LAN a satellite network a telephone or cable network a storage network e.g. FC a converged network e.g. FCoE or Infiniband or various portions or combinations of these and other types of networks.

Advantageously in accordance with embodiments described herein virtual storage resources can be directly provisioned to the applications executed by one or more VMs on a host computing device in a virtual network focusing on the management work related to attaching detaching one or more virtual storage resources to SDN NV. Smart data service can be delivered. With the embedded switch inside the storage array more information of the tenants can be captured e.g. VNI virtual IP address thus the value added services e.g. backup archive high availability caching to the tenants inside the virtual network can be provisioned. Also the S4NV switch approach can help the tenants to seamlessly migrate an entire production system into a virtualized environment without changing the configurations of both the application and storage network since there is no change of the logical data path for storage I O.

It should again be emphasized that the above described embodiments of the invention are presented for purposes of illustration only. Many variations may be made in the particular arrangements shown. For example although described in the context of particular system and device configurations the techniques are applicable to a wide variety of other types of information processing systems computing systems data storage systems processing devices and distributed virtual infrastructure arrangements. In addition any simplifying assumptions made above in the course of describing the illustrative embodiments should also be viewed as exemplary rather than as requirements or limitations of the invention. Numerous other alternative embodiments within the scope of the appended claims will be readily apparent to those skilled in the art.

