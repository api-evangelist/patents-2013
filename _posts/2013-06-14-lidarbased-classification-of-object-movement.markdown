---

title: Lidar-based classification of object movement
abstract: Within machine vision, object movement is often estimated by applying image evaluation techniques to visible light images, utilizing techniques such as perspective and parallax. However, the precision of such techniques may be limited due to visual distortions in the images, such as glare and shadows. Instead, lidar data may be available (e.g., for object avoidance in automated navigation), and may serve as a high-precision data source for such determinations. Respective lidar points of a lidar point cloud may be mapped to voxels of a three-dimensional voxel space, and voxel clusters may be identified as objects. The movement of the lidar points may be classified over time, and the respective objects may be classified as moving or stationary based on the classification of the lidar points associated with the object. This classification may yield precise results, because voxels in three-dimensional voxel space present clearly differentiable statuses when evaluated over time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09110163&OS=09110163&RS=09110163
owner: Microsoft Technology Licensing, LLC
number: 09110163
owner_city: Redmond
owner_country: US
publication_date: 20130614
---
Within the field of machine vision many scenarios involve the detection of movement of various objects such as object motion tracking and speed estimation techniques and devices. For example a sequence of images of a scene captured over a brief period of time may be evaluated to identify a particular object that is visible in several sequential images and based on various geometric properties of the scene the movement of the object through the scene over the captured time period may be estimated. Some such scenarios may involve a realtime or near realtime evaluation of such objects while other scenarios may involve a retrospective evaluation of previously captured images e.g. a vehicle moving down a street may capture a sequence of images of the scene to be stitched together to form a panoramic or dynamic view of the scene and the images may later be post processed to remove obstructions of the view by transient objects present during the capturing.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

While objects may be identified estimated as moving or stationary and removed from a sequence of natural light images the precision of such estimation that is achievable through only analysis of visual image may be limited. However the analysis may be supplemented with ranging information about such objects gathered by lidar which is often included in vehicles for object detection avoidance and navigation. The availability and use of lidar may provide a high precision source of data that may be particularly revealing in an evaluation of whether such objects are moving or stationary as each type of object may present a distinctly different signature of lidar data.

In view of these observations presented herein are techniques for detecting movement of objects depicted in a lidar point cloud. These techniques involve mapping respective lidar points in the lidar point cloud to a voxel in a three dimensional voxel space and identifying at least one object represented by a voxel cluster of voxels sharing an adjacency within the three dimensional voxel space. These techniques also involve for the respective lidar points in the lidar point cloud associating the lidar point with a selected object and classifying the movement of the lidar point according to the selected object. Finally these techniques involve for the respective objects classifying the movement of the object according to the movement of the respective lidar points associated with the object. By achieving the detection of movement of respective objects depicted in the lidar point cloud in this manner the techniques presented herein may enable a high precision classification of moving vs. stationary objects in the visual space where such classification may be usable for a variety of further processing techniques e.g. focusing one or more images on the object estimating a position orientation velocity and or acceleration of the object and removing the object from images depicting the area represented by the lidar point cloud in accordance with the techniques presented herein.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Within the field of machine vision many scenarios involve an automated evaluation of images of an environment to detect the objects present in the environment and depicted in the images and more particularly to identify the position size orientation velocity and or acceleration of the objects. As a first example the evaluation may involve vehicles in a transit environment including automobiles bicycles and pedestrians in a roadway as well as signs trees and buildings in order to facilitate obstacle avoidance. As a second example a physical object tracking system may evaluate the motion of an object within an environment in order to interact with it e.g. to catch a ball or other thrown object . As a third example a human actor present in a motion capture environment may be recorded while performing various actions in order to render animated personalities with human like movement. In various scenarios the analysis may be performed in realtime or near realtime e.g. to facilitate a device or individual in interacting with the other present objects while in other scenarios the analysis may be performed retrospectively e.g. to identify the movement of objects that were present at the time of the capturing . These and other scenarios often involve the capturing and evaluation of a set of visible light images e.g. with a still or motion camera and the application of visual processing techniques to human viewable images. For example machine vision techniques may attempt to evaluate from the contents of the image the type color size shape orientation position speed and acceleration of an object based on visual cues such as shadowing from light sources perspective relative sizes and parallax effects.

However in these scenarios the achievable precision in the identification of the movement of the objects from an inspection of visual images may be limited. For example techniques such as perspective and parallax may provide only general estimates particularly for objects that are distant from the camera lens and or may be distorted by visual artifacts such as glare and shadows. As a result such evaluative techniques may produce estimates with low precision and or a high degree of error and may be inadequate for particular uses.

Many scenarios involving the evaluation of object movement may be achieved through devices such as vehicles that also have access to data from a laser imaging lidar capturing device which may emit a set of focused low power beams of light of a specified wavelength and may detect and record the reflection of such wavelengths of light from various objects. The detected lidar data may be used to generate a lidar point cloud representing the lidar points of light reflected from the object and returning to the detector thus indicating specific points of the objects present in the environment . By capturing and evaluating lidar data over time such a device may build up a representation of the relative positions of objects around the lidar detector e.g. the locations of other vehicles with respect to the vehicle operating the camera .

In order to classify respective objects such as vehicles as moving or stationary and optionally in order to identify other properties such as position and velocity techniques may be utilized to translate the lidar points of the respective lidar point clouds to three dimensional space. presents an illustration of an exemplary scenario featuring a translation of a set of lidar point clouds to classify the objects depicted therein. In this exemplary scenario for respective lidar point clouds the lidar points are mapped to a voxel in a three dimensional voxel space . Next the voxels of the three dimensional voxel space may be evaluated to detect one or more voxel clusters of voxels e.g. voxels that are occupied by one or more lidar points in the lidar point cloud and that share an adjacency with other occupied voxels of the three dimensional voxel space such as within a specified number of voxels of another occupied voxel resulting in the identification of one or more objects within an object space corresponding to the three dimensional voxel space . Next for the respective lidar points in the lidar point cloud the lidar point may be associated with a selected object . The movement of the lidar points may then be classified according to the selected object e.g. the objects may be identified as moving or stationary with the object in the three dimensional voxel space . According to the classified movements of the lidar points associated with the object e.g. added for the object spaces at respective time points a projection of the lidar points and an evaluation of the movements of the lidar points associated with respective objects the movement of the respective objects may be classified. For example and as depicted in the projection of the lidar points associated with the first object after projection in view of the three dimensional voxel space appear to be moving with respect to the lidar detector and may result in a classification of the object as a moving object while the lidar points associated with the second object after projection in view of the three dimensional voxel space appear to be stationary after adjusting for the movement of the lidar detector and may result in a classification of the object as a stationary object. In this manner the techniques illustrated in the exemplary scenario of enable the classification of the objects identified within the environment depicted by the lidar point clouds into stationary objects and moving objects in accordance with the techniques presented herein.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. Such computer readable media may include e.g. computer readable storage media involving a tangible device such as a memory semiconductor e.g. a semiconductor utilizing static random access memory SRAM dynamic random access memory DRAM and or synchronous dynamic random access memory SDRAM technologies a platter of a hard disk drive a flash memory device or a magnetic or optical disc such as a CD R DVD R or floppy disc encoding a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein. Such computer readable media may also include as a class of technologies that are distinct from computer readable storage media various types of communications media such as a signal that may be propagated through various physical phenomena e.g. an electromagnetic signal a sound wave signal or an optical signal and in various wired scenarios e.g. via an Ethernet or fiber optic cable and or wireless scenarios e.g. a wireless local area network WLAN such as WiFi a personal area network PAN such as Bluetooth or a cellular or radio network and which encodes a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein.

An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method of classifying the movement of objects according to a lidar point cloud such as the exemplary method of . In another such embodiment the processor executable instructions may be configured to implement a system for classifying the movement of objects according to a lidar point cloud such as the exemplary system of . Some embodiments of this computer readable medium may comprise a computer readable storage medium e.g. a hard disk drive an optical disc or a flash memory device that is configured to store processor executable instructions configured in this manner. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary method of and the exemplary system of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized.

As a first variation of this first aspect the techniques presented herein may be utilized to evaluate many types of objects including vehicles traveling in an environment such as automobiles and bicycles traveling on a roadway or airplanes traveling in an airspace individuals moving in an area such as a motion capture environment and projectiles moving in a space such as ballistics.

As a second variation of this first aspect the techniques presented herein may be utilized with many types of lidar signals including visible near infrared or infrared near ultraviolet or ultraviolet light. Various wavelengths of lidar signals may present various properties that may be advantageous in different scenarios such as passage through various media e.g. water or air of varying humidity sensitivity to various forms of interference and achievable resolution.

As a third variation of this first aspect the techniques presented herein may be utilized with various types of lidar emitters and or lidar detectors such as various types of lasers and photometric detectors. Additionally such equipment may be utilized in the performance of other techniques e.g. lidar equipment provided for range detection in vehicle navigation systems may also be suitable for the classification of moving and stationary objects and may be applied to both sets of techniques concurrently or in sequence.

As a fourth variation of this first aspect the classification of the objects according to the techniques presented herein may be usable in many ways. As a first example the classification of objects as moving or stationary may be usable to identify the regions of corresponding images where the objects are present. Object based image evaluation techniques may therefore be focused on the specific areas of the images e.g. in order to perform an automated evaluation and or identification of the objects in order to identify the portions of the images to be redacted e.g. in furtherance of the privacy of individuals associated with the objects in images to be made available to the public and or in order to compensate for the presence of the objects in the images e.g. removing objects classified as moving objects in order to avoid obscured areas of the images while reconstructing a three dimensional model of the environment . As a second example the classification of objects may facilitate object recognition e.g. classifying the respective objects as an object type according to the movement of the object . For example the device may comprise an object type classifier that is trained to select object type classifications of objects and the device may invoke the object type classifier to classify an object into an object type in view of the classification of the movement of the object . Those of ordinary skill in the art may devise a broad variety of such scenarios and or uses for the classification of objects according to the techniques presented herein.

A second aspect that may vary among embodiments of the techniques presented herein relates to the mapping of lidar points of a lidar point cloud to the voxels of a three dimensional voxel space .

As a first variation of this first aspect the mapping may involve a three dimensional voxel space of various sizes. For example the voxels may be uniformly spaced across the three dimensional voxel space or may vary in size and or density. In an embodiment in order to compensate for potential dispersal of the laser over distance the voxels further from the lidar detector in the three dimensional voxel space may have a larger size than voxels that are closer to the lidar detector .

As a second variation of this second aspect the mapping may involve a comparison of an adjacency threshold between a selected voxel and other voxels of the three dimensional voxel space . For example it may be determined that if a first voxel that is mapped to at least one lidar point is within an adjacency threshold of three voxels of a second voxel that is mapped to at least one lidar point then the voxels are determined to share an adjacency and therefore are part of the same voxel cluster. As a further variation the axes within the three dimensional voxel space may have different adjacency thresholds e.g. a first axis within the three dimensional voxel space may have a first adjacency threshold while a second axis within the three dimensional voxel space may have a second adjacency threshold that is different from the first adjacency threshold. In one such variation the axis parallel to the view of the lidar detector within the three dimensional voxel space may be selected as having a significantly larger adjacency threshold since voxels that are connected along this axis may be difficult to detect with a surface based lidar reflection e.g. a first voxel that is close to the lidar detector may be connected to a second voxel that is distant from the lidar detector through a connecting piece of the object oriented parallel to the axis of view and thus not detected by reflective lidar .

As a third variation of this second aspect the mapping may determine that two or more voxel clusters are connected. For example nearby voxel clusters may be connected by a portion of the object that is not highly reflective thus resulting in few lidar points . The lidar detector may conclude that if the voxel clusters are nearby and appear to move together then the voxel clusters are likely connected and thus represent the same object . Determining connectedness may be achieved e.g. by selecting a first voxel cluster performing a nearest neighbor search e.g. a breadth first search of the three dimensional voxel space and finding a second voxel cluster that appears to be connected to the first voxel cluster. These and other variations may facilitate the mapping of lidar points to voxels in the three dimensional voxel space in accordance with the techniques presented herein.

A third aspect that may vary among embodiments of the techniques presented herein relates to the classification of the movement of the lidar points .

As a first variation of this third aspect the classification may be performed by classifying the movement of the respective voxels within the three dimensional voxel space . For example for respective voxels a measurement may be performed of an occupancy duration of the voxel over time by at least one lidar point of the lidar point cloud . If the occupancy duration of the voxel is determined to be within an occupancy time variance threshold e.g. if the voxel is occupied by at least one lidar point for more than a threshold duration then the voxel may be classified as stationary as well as the lidar points mapped to the voxel . Conversely lidar points that are not mapped to a voxel that is classified as stationary may be classified as moving. As one such variation the occupancy duration may be measured and compared as a standard deviation of the occupancy duration of respective voxels of the three dimensional space and voxels presenting an occupied status for more than one standard deviation may be classified as stationary. This variation may be advantageous e.g. for reducing the effects of small variations in the positions of the lidar points over time such as rotation shape changes or detector jitter that do not translate to motion.

As a second variation of this third aspect rather than performing the classification of movement of lidar points and or objects according to predefined calculations the classification may be performed by a movement classifier that has been trained to select a classification of movement of the lidar points and or objects such as an artificial neural network or genetic algorithm. Many such variations may be devised for classifying the movement of lidar points and or objects in accordance with the techniques presented herein.

A fourth aspect that may vary among embodiments of the techniques presented herein relates to additional processing that may be applied during the classification of the movement of the objects .

As a first variation of this fourth aspect after classifying the movement of respective objects the device may map the lidar points of the lidar point cloud to the respective objects . That is after achieving the classification of the objects based on the aggregated collective classification of the lidar points the individual lidar points may then be remapped to the objects in order to verify that substantially all of the lidar points of the lidar point cloud have been accounted in the classification. A small number of lidar points that are not mapped to any of the objects may be dismissed as artifacts but a significant number of lidar points that are not mapped to any of the objects may provoke a recomputation perhaps with adjusted parameters e.g. different voxel sizes .

As a second variation of this fourth aspect the device may for respective objects estimate a position and an orientation of the object according to the lidar points of the lidar point cloud that are associated with the object . Alternatively or additionally the device may for respective objects estimate at least one vector of the object over a time axis of the lidar point cloud e.g. estimating the speed or acceleration of the object over a period of time . These types of may provide data that may inform e.g. a prediction of imminent changes in the movement of the object and or may facilitate the consolidation of lidar points of the lidar point cloud to respective objects . Additionally in some variations the device may subtract the vector of the object from at least one lidar point that is associated with the object thereby providing information as to the relative movement of the lidar points with respect to the object e.g. a change of orientation and or shape of the object during movement .

As a third variation of this fourth aspect the lidar point cloud may be detected by a lidar detector that is mounted on a vehicle having a vehicle vector e.g. a direction speed and or orientation . The vehicle vector of the vehicle may be subtracted from the vectors of the objects detected in the environment e.g. in order to discount the movement of the lidar detector from the estimation of movement of the object thereby translating a mapping of movement relative to the lidar detector to a mapping of movement relative to the environment .

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB Firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

