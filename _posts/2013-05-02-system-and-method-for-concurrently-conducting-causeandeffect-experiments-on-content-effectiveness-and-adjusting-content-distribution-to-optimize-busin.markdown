---

title: System and method for concurrently conducting cause-and-effect experiments on content effectiveness and adjusting content distribution to optimize business objectives
abstract: The present invention is directed to systems, articles, and computer-implemented methods for assessing effectiveness of communication content and optimizing content distribution to enhance business objectives. Embodiments of the present invention are directed to computer-implemented methods for a computer-implemented method, comprising conducting an experiment using experimental content to determine effectiveness of communication content and executing, while conducting the experiment, a machine learning routine (MLR) using MLR content to enhance an effectiveness metric.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519916&OS=09519916&RS=09519916
owner: 3M INNOVATIVE PROPERTIES COMPANY
number: 09519916
owner_city: St. Paul
owner_country: US
publication_date: 20130502
---
This application is a continuation of U.S. application Ser. No. 12 651 650 filed Jan. 4 2010 now allowed which claims the benefit of U.S. Provisional Patent Application No. 61 143 060 filed Jan. 7 2009 the disclosure of which is incorporated by reference herein in its entirety.

This application is related to commonly owned U.S. patent application Ser. Nos. 12 166 969 12 167 002 and 12 166 984 filed on Jul. 2 2008 which are hereby incorporated herein by reference. This application is also related to U.S. patent application Ser. Nos. 12 159 107 and 12 159 106 filed Dec. 29 2006 which are hereby incorporated herein by reference.

The present invention relates to determining effectiveness of communication content and to optimizing content distribution to enhance business objectives and more particularly to concurrently performing these operations.

Visual information in a retail environment often takes the form of advertising content. Such content is inherently persuasive and is typically designed to influence a viewer s attitudes perceptions and behaviors in order to create a positive business impact such as increasing sales strengthening brand awareness or engendering consumer loyalty.

In 2002 for example total spending on advertising content used in retail environments commonly referred to as Point of Purchase POP was estimated at 17 billion in the United States and exceeded 43 billion per year globally. This level of spending has garnered increasing scrutiny among brand owner executives who are demanding greater accountability for their marketing investments.

The need for measurable performance is increasingly urgent as well because the average tenure of a Chief Marketing Officer has decreased to an estimated 22.9 months according to industry sources. Marketing leaders thus have precious little time to measurably demonstrate results from their marketing efforts. Marketing research a sub set of the research industry has historically used correlational or matched control studies to evaluate advertising content performance against objectives. However these best practice marketing research methodologies do not reliably reveal causation between the marketing message and the business result as has been widely commented on by marketing analysis experts e.g. Don E. Schultz Marketing News Feb. 15 2005 . Even so marketing research spending is currently estimated at 8 billion annually in the United States alone which includes these types of studies.

The present invention is directed to systems articles and computer implemented methods for assessing effectiveness of communication content and optimizing content distribution to enhance business objectives. Embodiments of the present invention are directed to computer implemented methods for a computer implemented method comprising conducting an experiment using experimental content to determine effectiveness of communication content and executing while conducting the experiment a machine learning routine MLR using MLR content to enhance an effectiveness metric.

Another embodiment is directed to a computer implemented method comprising generating a plurality of schedules each unrelated to one another and each comprising a plurality of time periods for presenting content and collecting data indicative of content effectiveness. The method also includes using a digital signage network comprising a plurality of geographically disparate displays and the plurality of schedules for concurrently conducting at least two cause and effect experiments on effectiveness of communication content that ensures that experimental content of the communication content are not confounded using at least two of the plurality of schedules concurrently executing at least two machine learning routines MLR using MLR content to enhance a predetermined business goal using at least two of the plurality of schedules or conducting at least one of the cause and effect experiments while executing at least one of the machine learning routines using at least two of the plurality of schedules.

Another embodiment is directed to a computer implemented method comprising receiving a viewer visit duration VVD for viewers at a location where content is to be presented generating a schedule comprising a plurality of time periods for implementing a machine learning routine MLR based in part on the VVD and an effectiveness metric. Then the MLR is executed using a digital signage network comprising a plurality of geographically disparate displays in accordance with the schedule to determine effectiveness of the MLR content.

Another embodiment is directed to a computer implemented method comprising performing an evaluation to determine for any given time period if using experimental content has more value than using MLR content for the time period. Content is then assigned to the time period based on the result of the evaluation.

Another embodiment is directed to a computer implemented method comprising receiving data gathered in accordance with a schedule comprising a plurality of time slot samples and executing a machine learning routine MLR using content collected from within time slot samples to enhance an effectiveness metric.

The above summary of the present invention is not intended to describe each embodiment or every implementation of the present invention. Advantages and attainments together with a more complete understanding of the invention will become apparent and appreciated by referring to the following detailed description and claims taken in conjunction with the accompanying drawings.

While the invention is amenable to various modifications and alternative forms specifics thereof have been shown by way of example in the drawings and will be described in detail. It is to be understood however that the intention is not to limit the invention to the particular embodiments described. On the contrary the intention is to cover all modifications equivalents and alternatives falling within the scope of the invention as defined by the appended claims.

In the following description of the illustrated embodiments reference is made to the accompanying drawings that form a part hereof and in which is shown by way of illustration various embodiments in which the invention may be practiced. It is to be understood that the embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

Embodiments of the present invention are generally directed to computer implemented systems and methods for assessing effectiveness of communication content and optimizing content distribution to enhance business objectives. Particular embodiments are directed to concurrently executing communication content effectiveness assessments preferably using cause and effect experiments and optimizing content distribution patterns that maximize one or more effectiveness metrics point of purchase sales upgrades customer loyalty etc. that maintains the validity of the cause and effect experiments. In general terms cause and effect experiments are controlled experiments in which appropriate balancing counterbalancing blocking randomization and meeting necessary sample size requirements are used to ensure confound free results. Effectiveness metrics refer to measured results of consumer behavior. Representative effectiveness metrics include sales customer loyalty upgrades brand perception and other measurable elements of a particular business goal.

Business goals refer to a general category of a viewer behavior that specifies a relationship between experiencing a piece of content and responding to the content. Representative examples of business goals include Bar Sales Room Upgrades and Package Food Sales. Other business goals include influencing attitudes and beliefs about brands and products and or influencing foot traffic patterns within an establishment. A business goal is associated with at least one effectiveness metric e.g. number of room upgrades but there may be a collection of effectiveness metrics for a particular business goal e.g. preferred customer upgrades new customer upgrades complimentary upgrades . A business objective often relates to multiple business goals and may change over time. For example this week a user may have the objective of maximizing both room upgrades and bar sales. Next week the objective may change to maximizing room upgrades while controlling bar sales.

Various embodiments of the invention are directed to scheduling content distribution and determining for each time period of the schedule whether to utilize each time period for conducting a cause and effect experiment or optimizing content distribution patterns that maximize one or more effectiveness metrics in a manner that maintains the validity of the cause and effect experiment. For purposes of the present disclosure a schedule may be a static plan or a continuously and dynamically updated plan. Scheduling methodologies consistent with embodiments of the invention typically involve making such determinations on a display by display basis for each time period of the schedule. In certain embodiments of the invention time periods of a schedule correspond to time slot samples as described herein and in commonly owned U.S. patent application Ser. No. 12 166 984. Scheduling methodologies consistent with these embodiments may further involve dynamically adjusting the schedule on a per time period basis to achieve user specified requirements e.g. desired balance of experimentation vs. content distribution optimization . According to some embodiments systems and methods may be implemented that constantly analyze whether for a given time period a display should be under the control of a cause and effect experiment system or under the control of a machine learning system given the cost of using a particular time period on each display for experiments relative to a lost opportunity of using the same time period on each display for enhancing a predetermined business goal by execution of the machine learning routine.

Systems and methods of the present invention can be implemented to execute various types of machine learning routines to enhance or optimize one or more effectiveness metrics. In general terms a machine learning routine refers to a computer implemented methodology for learning the relationships between actions e.g. content states e.g. sign location time of day etc. and rewards e.g. sales upgrades etc. . Representative examples of useful machine learning routines include a reinforcement learning routine logistic regression routine unsupervised learning routine semi supervised routine or use of one or more neural networks. Other machine learning routines that may be used include transduction genetic algorithms support vector routines and learning to learn routines among others.

One particular machine learning methodology reinforcement learning has been found to be particularly useful in the context of various embodiments of the present invention. Reinforcement learning allows systems machines and software agents to automatically maximize performance for a particular problem space. Many different algorithms can be developed to implement a reinforcement learning routine. Reinforcement learning can be applied to problems in which there are states actions and rewards. The states refer to identifiable properties that are not under the control of the algorithm in which the problem can exist e.g. time of day display location weather etc. . Actions refer to the elements that are under the control of the algorithm e.g. content to display . Rewards are the measurable responses e.g. point of purchase sales to the actions generated by the algorithm given the state when those actions were executed.

Reinforcement algorithms are designed to learn the relationship between actions states and rewards. More generally the reinforcement learning algorithms and machine learning in general learns an expected outcome reward that will be generated when the system is in a particular state and a particular action is generated. Under many real world conditions the relationship between rewards states and actions is probabilistic and thus the resulting reward given a particular action and state will vary from trial to trial.

For a given problem the reinforcement algorithm is programmed to learn the relationship between the states actions and rewards by testing different actions in the different states and recording and analyzing the resulting rewards. The result is a prediction of the expected reward for executing each action for each state. Because the system is constantly evaluating the expected reward for an action for a given state the model can learn to maximize the expected reward for a static state problem i.e. a system in which the reward for an actions state pair remains constant and it can also adapt to a dynamic state problem i.e. one in which the reward for a particular action state pair changes over time . Under some conditions a reinforcement learning algorithm will converge to a global optimum.

In accordance with embodiments of the invention that employ reinforcement routines the state may be defined by the time of day the type of store and the geographical location of the business or any other state dependent variables. For example a particular state may be defined by the time of day of the display period e.g. 9 00 9 30 AM the type of store e.g. urban and the geographical location e.g. Midwest . The actions relate to distributing specific pieces of content available to the algorithm. The rewards are the effectiveness metrics individual or combinations of specific effectiveness metrics and may include point of purchase sales loyalty data upgrades etc.

A reinforcement learning routine of the present invention typically involves an explore routine and an exploit routine. It is noted that some implementations may use only one of these two routines or may select between these two routines. Exploit generally relates to showing the content that the machine learning algorithm predicts will produce the largest reward given the current state. Explore generally relates to showing content that is not predicted to produce the largest reward with the goal of learning updating and or verifying the expected reward of that content for the current state. The goal of the reinforcement routines is to provide an understanding of the relationship between the states actions and rewards.

Embodiments of the present invention are directed to systems and methods that facilitate user input of data associated with one or more hypotheses for a cause and effect experiment and data associated with one or more business goals. After entry of these and any other necessary data processes of the present invention are executed to ensure that for each time period of a playlist schedule and for each display of a network of displays that the system will work to maximize the utility of the network to achieve the user s requirements indicated by the user s input data. The user need not be further involved in these processes unless involvement is desired. The user may for example query the system to determine the status of the network display with high resolution e.g. the state of the network displays can be resolved to a single time period of the schedule and if desired implement changes to these processes such as by terminating an experiment or increasing the amount to time periods allocated to explore and or exploit routines.

Some embodiments of the invention are directed to systems and methods for implementing optimization of content distribution to maximize business objectives exclusive of conducting communication content effectiveness assessments. Other embodiments involve optimization of content distribution to maximize business objectives and optionally invoking cause and effect experimentation if factors indicate the desirability of such experimentation.

Various embodiments of the present invention are directed to systems and methods for executing machine learning routines via a digital signage network. Some embodiments involve generating a playlist schedule comprising machine learning routine MLR content assigned to time slot samples and executing machine learning routines using the time slot samples. Particular embodiments involve use of reinforcement learning routines and generating a playlist schedule comprising reinforcement learning content assigned to time portions e.g. time slot samples of the playlist schedule. Playlist schedules according to these embodiments are preferably executed via a digital signage network to optimize content distribution patterns that maximize one or more effectiveness metrics such as point of purchase sales upgrades and customer loyalty and the like.

These and other embodiments of the invention may be implemented via a computer controllable multiple location content presentation infrastructure such as a digital signage network. It is understood that embodiments of the invention are not limited to visual media but may involve aural tactile or other sensory media alone or in combination with visual media.

Turning now to there is shown a flow chart that illustrates processes for concurrently conducting cause and effect experiments on content effectiveness and automatically adjusting content distribution patterns to enhance effectiveness metrics in accordance with embodiments of the present invention. Embodiments according to involve conducting a cause and effect experiment on effectiveness of communication content that ensures that experimental content of the communication content are not confounded. Embodiments according to further involve executing while conducting the experiment a machine learning routine that distributes content to maximize a predetermined set of rewards i.e. effectiveness metrics .

For example and as also shown in at least some of the time periods of the schedule that are unused for conducting one or more experiments may be used for executing one or more machine learning routines. According to another approach an experiment s may be conducted using a first set of time periods of the schedule while a second set of time periods of the schedule interspersed with the first set of time periods may be used for executing a machine learning routine s . It is understood that more than two sets of time periods may be allocated for concurrently conducting one or a multiplicity of experiments and one or a multiplicity of machine learning routines. According to a further approach for experimental content and MLR content that are unrelated at least a portion of each of an experiment s and a machine learning routine s may be implemented using the same time period or periods.

The approaches shown in and other alternative approaches can be implemented individually or in various combinations. Also multiple schedules may be provided and used to implement the approaches shown in and in other Figures in a manner that ensures the integrity of cause and effect experimentation while concurrently using machine learning routines to maximize effectiveness metrics.

Traditional approaches known in the art have heretofore been unable to conduct a confound free cause and effect experiment while concurrently executing a machine learning routine as depicted in . Conducting a cause and effect experiment in the context of digital signage networks DSNs for example generally involves implementing carefully designed controlled and conducted performance evaluations experiments that measure the impact of digitally delivered messages on specific dependent variables i.e. consumer behavior . These results generate insights about specific independent variables of interest e.g. message type message form for particular dependent variables e.g. metrics such as upgrades product sales etc. that are of interest to the user. These insights are generated by carefully scheduling content on the user s network that provide confound free results to the user. Conventional approaches have been unable to facilitate cause and effect experimentation while at the same time facilitate execution of optimization routines to automatically maximize pre specified effectiveness metrics.

In some embodiments methods of the invention are performed using an experiment such as a cause and effect experiment as described herein. In other embodiments methods of the invention are performed using other types of experiments such as quasi experiments or correlational designs.

Previously users have had to choose between these alternatives when using prior art approaches is because cause and effect experiments requires content to be distributed very precisely such that confounds are minimized or eliminated within the experiment. By contrast optimization routines continuously adjust content distribution to maximize a function e.g. total revenue and do so without any mechanism to ensure that confounds are not being inserted in the content distribution schedule. As such conventional implementations require end users to choose between either using a system that distributes content for cause and effect results or a system that automatically maximizes specific effectiveness metrics.

Embodiments of the present invention are directed to systems and methodologies that simultaneously across a network of displays provide the integrity of a cause and effect experimentation while facilitating use of optimization routines that maximize effectiveness metrics. Embodiments such as that illustrated in are directed to concurrently executing cause and effect experiments on content effectiveness in addition to automating content distribution patterns to maximize consumer metrics. Embodiments of the invention may further involve balancing the distribution of return on investment ROI maximization with the distribution of cause and effect content that takes into account the value and the urgency of both of these components. The balancing of these components takes into account the predicted opportunity cost for distributing cause and effect experimental content during a time period instead of MLR content that will maximize specific effectiveness metrics. The system will select time periods that will maintain the integrity of the experiment e.g. appropriate counterbalancing and statistical assumptions necessary for the inferential statistics that minimizes the opportunity costs associated with the experiment.

Opportunity cost reductions may come in many forms including but not limited to designing an experiment with unequal number of samples in different conditions based upon the value priority of questions that the experimenter is interested in answering the cost of using specific samples and providing on going cost analysis to determine the expected cost versus benefit for finding a reliable effect given the current results i.e. means and variances of the different conditions and specifying a stopping rule based upon statistical properties such as power and effect size. Embodiments of the invention include optimizing the allocation of samples to the cause and effect experiments and the MLR routines that minimize the cost associated with the cause and effect experiments and maximize the expected reward from the MLR routines.

Because the MLR routines are learning the relationship between the states actions and rewards ultimately a very rich historical database will exist. In addition to using this database for predicting the best action i.e. content to assign to a particular time period on a particular digital display this historical database can be used to provide the user with alerts to particular relationships in the data that the user may be interested in knowing and or testing. Because these relationships are not generated using experimental design under most conditions they will be simple correlations between independent and dependent variables. These correlation results do not provide the user with cause and effect results but simply a relationship between the independent and dependent variables.

Because the system is learning relationships between the states and the content there will be a very large set of relationships that will be available. One method for rapidly filtering through these possible relationships is to query the user about the relationships that they find interesting and or valuable. By querying the user about relationships that are valuable the system can constantly be analyzing the historical data for valuable relationships. The user can be alerted about specific relationships in the data and given the option to run a cause and effect experiment testing the causal effects of the independent variables on the dependent variables and or the user can indicate that the system should automatically design and run an experiment that is valuable and meets specific criteria e.g. predicted cost .

Those skilled in the art will readily understand that the terms optimize optimization maximize and similar superlatives in the context of the present invention are not absolute terms. Rather such terms describe the process of either minimizing or maximizing a value based upon the current constraints of the problem. For example when optimizing the content distribution pattern the system constantly monitors the performance of the actions that are available to it i.e. the content that can be assigned to a schedule and assigns the content that given its current knowledge will maximize a particular value. But because the optimization or maximization routines are working in a problem space that is highly dynamic and the specific underlying function is unknown the system is constantly in a state of uncertainty with respect to which action will actually minimize or maximize the objective function. These terms are used commonly in the technical literature relating to machine learning. Therefore in the context of the presently claimed subject matter terms such as optimize or maximize are synonymous with terms indicative of enhancement betterment improvement increase advancement and the like.

An example of complementary products is shampoo and conditioner. That is if the customer is driven to purchase shampoo they are also more likely to buy conditioner. An example of competing products is pre packaged food versus in store prepared food. If the customer is driven to buy in store prepared food they will be less likely to buy pre packaged food. By using multiple effectiveness metrics e.g. shampoo sales conditioner sales prepared food sales and packaged food sales and specifying the relative value of these effectiveness metrics the MLR learns maximize an objective function that takes into account these competing and complementary consumer behaviours.

Use of optimization routines to increase or maximize the objective function across multiple effectiveness metrics typically involves optimizing the amount of time that each display of a digital display network dedicates to different content messages and showing 55 versions of content that are predicted to maximize the effectiveness metrics or objective function for a particular screen location and time. An objective function refers to a set of relative values for each of the different consumer metrics. This is used by the MLR to predict which piece of content will be the most effective for a particular state display location time of day etc. . It is also used by the cause and effect experiment distribution system to determine the opportunity costs associated with an experiment to optimize the experimental design and select the set of samples time periods that will minimize the overall cost of the experiment.

Embodiments according to also involve analyzing historical data collected from the optimization routines and alerting the user of correlations that the user might find valuable. An example of such a correlation is showing content with people is correlated with increased sales in the morning but showing content without people is correlated with increased sales in the evening.

A content distribution and data processing module or processor is configured to distribute content across the network and process effectiveness metrics in the form of data streams e.g. point of sale data . The content distribution and data processing module is configured to continuously adjust content distribution patterns in order to learn the relationship between the content e.g. actions and the states e.g. display properties and maximize the objective function that is specified by the relative values on the different effectiveness metrics.

The following scenario represents one of many possible implementations in accordance with embodiments of the invention. The following representative processes are implemented by a system of the present invention that is capable of measuring the effects of content on effectiveness metrics. The system is preferably configured to generate the necessary conditions for distributing the content to run a controlled cause and effect experiment preferably in a manner described hereinbelow. The following components of the experiment would be entered into the system by the user as is shown in 

These dependent and independent variables i.e. environmental and content factors are used by the system to design a specific experiment in a manner as described hereinbelow. The system algorithm s receive the data that is defined above and assign content to different TSSs such that certain factors are precisely controlled and other factors are randomized e.g. that which version of content is shown is randomized across occupancy levels . For many experiments only a certain amount of display time is necessary for the experiment thus leaving certain time periods e.g. TSSs open. For purposes of clarity the term open as used in the preceding sentence refers to the present availability of a given time period e.g. TSS to be used for a purpose other than for the experiment e.g. a machine learning routine . However for a given time period a particular business goal may be open. In this context for example if a time period e.g. TSS is being used to evaluate a particular business goal such as Upgrades another business goal such as Bar Sales is open. 

Once the experiment has been defined the following representative processes are preferably used to fill the open time periods i.e. those not dedicated to the experiment using a machine learning algorithm to generate content distribution patterns that increase the user s objective function i.e. the values placed on different consumer metrics . Below is a description of the representative method steps shown in for inputting data into the machine learning routines and how the routine uses this information to generate a schedule. This is followed by presentations of illustrative deployment scenarios that involve these representative processes.

The following deployment scenario illustrates how the processes described above can be implemented in accordance with embodiments of the invention.

Manticore is a hotel chain that owns five hotels that have a digital signage network. Manticore has classified their five hotels by location type Urban vs. Suburban and their size in terms of the number of rooms Small Medium Large .

Manticore wants to understand whether adding a human model in an advertisement increases the likelihood that a customer will choose to upgrade their room Step 1 in Example 2 above . Because it costs Manticore royalty fees to use a model in their advertisements they are interested in determining the benefit of using a model over not using a model. They have reasons to believe that the effect of adding a model might be different for their Urban hotels versus their Suburban hotels Step 2 in Example 2 above .

Manticore designed two pieces of content that are identical in all ways with the exception of one One piece of content has a model RoomUpgrade Model while the other does not RoomUpgrade NoModel Step 3 in Example 2 above . Manticore also knows that 99.9 of all customers check in and make their upgrade decision within 1 hour of entering their hotels VVD 1 hour TSS 2 hours Step 4 in Example 2 above .

Using the procedures described below for designing a cause and effect experiment the system generates a schedule and assigns Experimental Content to the schedule. shows the distribution of content for the five Manticore hotel properties for this study. Furthermore Manticore wants to know the answer by the end of the next day Step 5 in Example 2 above . It is noted that by extending the urgency date one can evaluate demonstrate how the system would modulate the allocation of display time to MLR versus cause and effect experimentation. Using this data the algorithm schedules the content to the five Manticore properties as shown in .

Manticore is also interested in using the open periods shown a screened squares in to increase their ROI.

In the squares with the broken diagonal pattern indicate the times that have been dedicated to the Room Upgrade and Bar content respectively. The stippled squares represent explore time periods in which the algorithm randomly selected one of the lower performing pieces of content to present during that period.

As can be see in data is collected during the time period that the content was presented. The numbers in the patterned and white squares indicate the number of upgrades during that TSS. The bar performance for TSSs associated with Bar Sales are listed on the far right. The Hotel U S does not have a bar therefore it does not have any bar sales.

The following illustrative deployment scenario exemplifies the value of implementing an ROI maximization approach of the present invention. The data shown in demonstrates that optimization routines of the present invention can generate a significant improvement in ROI by optimizing over content daypart and location. In this representative example there are four types of stores Urban Suburban Exurban and Rural . The system is maximizing the ROI for Morning Afternoon and Evening periods using three pieces of content A B and C .

In this case simply presenting the best overall content produces a 2.53 increase in ROI over simply presenting each piece of content randomly i.e. equally often . Choosing the best content for a particular daypart produces a 5.11 increase over distributing the content equally often over the network. Choosing the content that is best for a specific location produces a 3.53 increase in ROI over distributing the content randomly. However choosing the content that is the best for all of these context variables daypart content location generates a 12.94 increase over the randomly distributed approach.

The following representative deployment scenario illustrates additional complexity that is involved when generating a playlist schedule that accounts for multiple VVDs and multiple business goals in which a machine learning routine is running concurrently with a cause and effect experiment. This example illustrates how a user can use a machine learning routine such as a reinforcement learning routine that employs explore and or exploit algorithms to schedule content during certain time periods of the schedule.

In this illustrative scenario it is assumed that a digital signage network is deployed in a department store and that the network is configured to perform ROI measurements. It is also assumed that time slot samples will be used as the time periods of the playlist schedule.

One display is near the in store bistro where VVD has been determined to be 45 minutes. The bistro display is running ongoing experiments relating to suggestions of getting a glass of wine appetizer desert etc. with your meal. Additionally experiments are run having content relating to merchandising for various retail departments of the department store. The experimental content is interspersed with the food related content.

Another display is located in the book music department of the department store where VVD has been determined to be 20 minutes. This display runs experiments relating only to items sold in the book music department. Another display is located near the escalators on the first floor not far from and visible from the department store entrance. This display runs experiments relating to a variety of content including the bistro retail departments and the book music department. The overall VVD for the department store has been determined to be 70 minutes. Each display has open time slot samples of a length determined by the algorithms described hereinbelow.

The user decides to incorporate a machine learning enhancement for department store s digital signage network. For the next quarter the user s business goals are defined as 

A schedule can then be generated in a manner described herein that accounts for the requirements and constraints described above. This scenario illustrates additional complexity that can be accounted for using a playlist schedule constructed for concurrently running cause and effect experiments and optimization routines in accordance with embodiments of the invention.

For purposes of simplicity and to emphasize the role of multiple business goals and multiple VVDs in the playlist schedule generation scenario described in Example 5 above consider the display that is located in the book music department. An initial step involves defining the experiment to answer the following question. Which will perform better advertisements describing book purchasing as an investment versus an earned luxury for evening versus morning shoppers In this illustrative example it has been determined that VVD is 30 minutes and TSS is 60 minutes. It is assumed that a reinforcement learning routine will be used that includes an explore exploit algorithm.

According to another approach an explore exploit routine may use data from a single time slot sample understanding that confidence in cause and effect is substantially lower. Importantly however the described use of the relationship between VVD TSS and data collection periods does eliminate same location carryover effects. To preserve the integrity of true experimentation constraints all explore exploit routine content shown during an experimental TSSs must be unrelated. 

By way of example a one hour TSS may be sequentially showing 15 second content clips of experimental content exploit content business goal A exploit content business goal B and weather report content. In this case data collection may be simultaneously taking place at three independent point of sale systems one measuring the effect of experimental one measuring the effect of business goal A exploiting and one measuring the effect of business goal B exploiting. All data collected is thus clean due to the unrelatedness of the communication content.

According to other embodiments two distinct and unrelated schedules may be implemented to run concurrently on the same display. Content switching may occur every 30 seconds or other time interval as dictated by the two unrelated schedules. The two schedules may have very different time features. For example at least one of VVD TSS and data collection periods can differ as between the two schedules. By way of further example each of VVD TSS and data collection periods can differ as between the two schedules.

For example both schedules can be generated to conduct cause and effect experiments e.g. true experiments . By way of further example both schedules can be generated to perform machine learning routines such as explore exploit routines. In accordance with another example one schedule can be generated to conduct cause and effect experiments and the other schedule can be generated to perform machine learning routines. It is understood that more than two schedules can be constructed to implement a multiplicity of cause and effect experiments machine learning routines or a combination of cause and effect experiments and machine learning routines.

Whenever a study is being conducted it comes at a cost to the customer. The time periods dedicated to the study are being used to gather data or knowledge instead of being focused on generating return on investment e.g. using an explore exploit algorithm . The cost of the study can be calculated as the difference in revenue generated by using an optimization algorithm versus the amount of money generated during the actual study. Because there is a measurable cost associated with running an experiment i.e. the opportunity cost associated with not employing a machine learning routine embodiments of the present invention provide the user with the ability to automatically terminate at an appropriate or predetermined stage.

For example the user may specify automatic termination of a study when 1 the data has demonstrated a significant result or 2 when given the current effect size and the estimated variance the cost associated with the study exceeds the value that the customer places on the study. Although there are known methods describing how one can determine whether or not to continue collecting data none of these methods heretofore have been applied to or contemplate evaluating experiments with digital content distribution systems.

The following is an illustrative example of evaluating the cost of conducting a study in accordance with embodiments of the invention. As is shown in representative processes for conducting a cost evaluation of a study of the present invention include the following 

The method steps of Example 7 above describe one approach for deciding whether and when to terminate a study. Those skilled in the art will understand that there are other algorithms for computing when to terminate a study and that these algorithms may be used in accordance with embodiments of the invention.

An advantage of using a digital signage network in the context of the present invention is that multiple messages can be presented on a single display. This provides both an opportunity and a challenge. Both marketing and basic memory research clearly show that humans typically require multiple presentations of a message to both remember the message and to act upon a message. On the one hand a digital signage network provides an opportunity to provide different messages over time to a viewer. However given that it typically takes multiple presentations for a customer to act upon a message if one is not careful messages can become ineffective when customers do not experience a message a sufficient number of times to actually modify their behavior.

The challenge is that there is no prescriptive number of experiences that will ensure maximum benefit. The number of experiences required will depend on multiple factors including but not limited to 

Embodiments of the invention involve identifying the frequency rate for presenting content on a digital sign that automatically optimizes the presentation frequency of content to maximize a customer s ROI. With reference to the following example illustrates processes of frequency rate optimization in accordance with embodiments of the invention 

One of the benefits of the explore exploit algorithm is that it is designed to automatically explore the space of content presentation patterns to find the best or optimal content mix to return ROI value for the customer. During this exploration phase there is a great deal of knowledge that the algorithm begins to uncover. This knowledge comes in the form of particular correlations between content and the content attributes such as color tactics etc. locations customer types time of day etc. Many of these correlations are spurious correlations that occur due to random chance. Other correlations may have a causal component to them. In order to differentiate between spurious correlations and causal effects a controlled study is needed.

The challenge is in determining which correlations to actually pursue. The explore exploit algorithm will uncover many correlations in the data. Some may be of significant value to the user while others will not be of much value. Embodiments of the present invention are directed to identifying and uncovering the valuable correlations using an automatic hypothesis generation methodology referred to herein as auto hypothesis generation a representative example of which is described below with reference to .

In accordance with various embodiments systems and methods of the present invention may be implemented that continuously analyze all displays of a digital signage network to determine whether each display should present content for purposes of conducting a cause and effect experiment or for executing a machine learning routine. Embodiments of the invention may be implemented to continuously analyze all DSN displays to effectively decide whether each display is to be under the control of a cause and effect experiment system or under the control of a machine learning system. This decision is preferably made by the DSN system based on the cost of using a particular time period on each display for experiments relative to a lost opportunity of using the same time period on each display for optimizing a predetermined business goal by execution of the machine learning routine.

As is shown in a DSN system processor or module is configured i.e. programmed to execute program instructions stored in memory to determine for each time period e.g. TSS of each playlist schedule and associated display if the time period is to be used by or under the control of a machine learning routine or a cause and effect experiment. If the module determines that the time period is to be used for a machine learning routine appropriate content is assigned to the time period as determined by the machine learning routine. For example the machine learning routine may be programmed to present explore content or exploit content during this time period. If the module determines that the time period is to be used for a cause and effect experiment appropriate content e.g. experimental content or placebo content is assigned to the time period as determined by the cause and effect experiment. The content assigned to the time portion is distributed and displayed . The processes shown in are repeated for each time period for each display of the digital display network.

Content distribution is managed in the embodiment shown in by a server . The server is communicatively coupled to a multiplicity of displays six of which are shown in for purposes of illustration. The state of each display is known at all times and for all time periods shown as time slot samples in this embodiment. For each display the current TSS and mode experiment or MLR mode is shown for each time t of the schedule that is used by the server preferably by a DSN system processor or module to control content distribution. In some embodiments the time between time t and time t 1 is the duration of a time slot sample. In another embodiments the time between time t and time t 1 is a duration defined by the Time Interval TI as described herein.

Looking vertically along the time axis the state of each display is shown for each time increment of the schedule control i.e. time t t 1 t 2 etc. . For example the DSN system has determined that TSS is to be used for executing a machine learning routine for Display at time t. For time t 1 the DSN system has determined that TSS is to be used for conducting a cause and effect experiment for Display . Continuing with this example it can be seen that for time t 2 the DSN system has determined that TSS is to be used for conducting a cause and effect experiment for Display . The state of all displays of the DSN system is similarly known and controlled for each time t through t n of the schedule control in accordance with this embodiment of the invention.

Advantageously systems and methods of the present invention make this optimal allocation decision automatically by optimization algorithms in a top level decision tool. That is the top level decision tool ensures that the value derived independently from the two subcomponents the cause and effect experiment system and the MLR system is maximized across the entire content distribution network given that each subcomponent needs control of time periods e.g. time slot samples in order to achieve its goals.

One way in which the decision tool may reallocate control is based on information that accrues during and related to a cause and effect experiment. The following examples are provided which refer to time periods in terms of time slot samples for illustrative purposes.

Because there are methods for adjusting the execution of cause and effect experiments while the experiments are underway the top level decision tool can continuously re evaluate the cost benefit equation for which sub system should have control over the various time slot samples as time progresses. That is the value of insights gained from a cause and effect experiment may be overcome by the cost of conducting finishing an experiment during the time course in which the experiment actually being conducted.

Based on early dependent variable data the decision tool or experiment system can determine that the projected effect size of the factor under investigation is likely to be much smaller than initially expected and as such the experiment would take longer to conduct to reach the desired statistical power and therefore the cost of conducting the experiment might exceed the expected benefit of the insight in light of benefit the network owner could otherwise derive by giving control over to the MLR system.

The value of dedicating a particular time slot sample on a particular display at a particular location to the control of the experiment system may change as a result of the MLR system s ability to control that time slot sample display and gain more value. For example whereas a particular time slot sample might have been slotted to run condition x of an experiment if the MLR system could gain greater value by controlling the time slot sample at that display at that location the decision tool could move the implementation of condition x for the experiment to another display on the system. That is condition x might have been slotted to play on a display in Dubuque at 10 00 am but now the decision tool decides to move that condition to a different time slot sample such that it plays on a display in San Diego at 10 00 am instead.

As such there are ways in which the decision tool may speed up or slow down an experiment by shifting control of time slot sample and there are ways in which the decision tool may keep the experiment on the same pace but re arrange the physical location of where the experimental conditions play in the physical world across the network. Likewise the decision tool might reallocate control due to information that accrues from the machine learning routines.

Referring again to and with reference to decision process the experiment vs. MLR system decision tool is a set of algorithms that continuously monitors the network and decides how to allocate control of each TSS for each display to the subcomponent systems a experiment system b MLR system . The decision tool uses inputs from the user regarding the value of experimental insights the experiment system regarding the required sample size duration to meet the desired statistical power the incoming dependent variable data as the experiment progresses and the estimated or known value of allowing the MLR to control the TSSs in order to maximize current business goals.

The experiment system is the subcomponent configured to receive inputs such as dependent measures of interest and their characteristics environmental factors of interest content factors of interest viewer visit duration for the dependent measure of interest and experiment urgency value. The experiment system then generates an experiment to be conducted on the content distribution network. The experiment system can estimate the expected duration sample size required to reach a desired level of statistical power.

The MLR system is a set of processor implemented machine learning algorithms that continuously manages content distribution in order to maximize outcomes in the data streams of interest. The MLR system takes inputs such as business goals and their value the value of each effectiveness metric content available to show on the network any location or time constraints and viewer visit duration associated with content. Content distribution across the content distribution network occurs under the direction of both the experiment system and the MLR system and or the top level decision tool itself via computer hardware and software e.g. server .

The mix of up to 60 unique pieces content that fills each 30 minute TSS is preferably controlled either by the algorithms associated with the experiment system or the MLR system . However as shown in the diagram any particular TSS across the network may be under the control of either the experiment or the MLR algorithms where control means choosing the content that fills the TSS and it s play order within the TSS . And each TSS at any point in time may be under the control of either the experiment system or the MLR system .

At the next TSS the next 30 minute section of time a display may show content in a TSS that is under the control of the same subcomponent as the previous TSS or the other subcomponent as shown by looking down the vertical axis of as time moves forward . For example the decision tool may decide that at TSS Display will show content defined by the MLR system to optimize business goals . Yet when Display shows content in TSS the decision tool may calculate that for maximum value to the user that TSS should be under the control of the experiment system . Thus at any point in time displays at different locations may be under the control of the same or different subcomponents experiment system or MLR system by virtue of showing content in time slot samples defined by or under the control of either the experiment system or the MLR system .

Manticore is interested in evaluating whether a human Model in upgrade content is more effective than No Model on the number of upgrades. Manticore is also interested in evaluating whether having a model interacts with the time daypart. More specifically Manticore is interested in evaluating morning check in versus evening check in. The primary question of interest is whether the Model improves performance over No Model regardless of the time of day that it is shown. The secondary question is whether the use of a Model interacts with the Time of Day.

To optimize the design of the study the user inputs the value of the two questions. In this illustrative example the user specifies that the Model vs. No Model has a value of 10 000 while the interaction has a value of 3 000. An urgency date is set to complete the study within 30 days. The user is also queried about the minimum effect size that they would consider to be of value. The user specifies an effect size of at least 10 would be needed to be of interest.

The system first evaluates whether the opportunity costs associated with two different designs are below the threshold of the value set by the user for the answers to the two questions being asked i.e. Model vs. No Model and the interaction of Model with Daypart .

The first analysis is to determine the predicted opportunity cost for running an experiment evaluating the effectiveness of using a Model vs. No Model. First the system identifies the collection of time periods that can be used to complete the study. Using the properties of the time slot samples the system uses the historical data to determine the variance of the upgrade data and completes a power analysis to determine the number of samples to find a significant main effect of the size specified by the user 10 . The power analysis predicts that 150 samples are necessary 75 Model and 75 No Model to find a reliable effect.

Given this collection of time slot samples the system uses its historical database to generate a prediction about the expected rewards for these different time slot samples using a machine learning routine Expected Reward for the Machine Learning Routine denoted ER MLR in this illustrative example . Also using the historical database the system makes a prediction about the expected reward for presenting the Upgrade content Expected Reward for the True Experiment denoted as ER TE in this illustrative example . The predicted ER MLR in this example is 20 000 and the ER TE is predicted to be 15 000. The opportunity cost is calculated as the difference between these two predictions  Model  Model In this case the opportunity cost 5 000420 000 15 00 is below the value of the answer to the hypothesis related to the use of Models within content 10 000 .

The system then considers the opportunity cost for answering the question related to the interaction Model vs. No Model with Morning vs. Evening . A second set of time periods are considered that only include Morning and Evening time periods. According to the user input described above the value of the interaction is 3 000. Thus if adding the constraint of daypart increases the cost of the experiment by more than 3 000 then the user will be alerted to this fact. The opportunity cost of generating an experiment with the interaction is calculated by  Interaction  Interaction  Model The ER MLR is calculated by making predictions about the MRL expected value for only the Morning and Evening dayparts other dayparts are not considered. In this case the ER MLR is calculated to be 23 000.

Using the historical database the predicted expected reward for presenting the upgrade content material during these same periods is 16 000. Thus the predicted opportunity cost for running the experiment with the interaction is 2 000 23 000 16 000 5 000 . The initial analysis shows that the opportunity cost of running the experiment with an interaction 2 000 is below the value specified by the user of the answer 3 000 .

Given that the opportunity costs for both questions are lower than the value to the answers the system generates an initial schedule that satisfies the requirements of the study with appropriate counterbalancing and randomization that will be completed by the 30 day urgency period specified by the user.

As data is being collected the system is continuously re evaluating the power analysis and the number of samples that are necessary to complete the study. Furthermore the opportunity costs are also continuously evaluated to determine whether the predicted opportunity costs associated with answering each question remains below the value of the answer specified by the user.

In this example after day of the study a power analysis of the interaction shows that because there is a small interaction effect a significant number of samples would be needed to generate a significant and meaningful difference from an initial estimation of 200 samples to 1000 samples . This increase in necessary sample size produces an opportunity cost for the interaction that exceeds the value of the interaction specified by the user 3000 value and a predicted opportunity cost of 12 000 . That is the effect size of the interaction is very small. By contrast the effect size of the Main Effect of Model vs. No Model is very large and the predicted opportunity cost for finishing the experiment with only the Main Effect is still below the value of the answer 10 000 value and a predicted opportunity cost of 5 000 . The user is alerted to the fact that the opportunity cost associated for finding a significant interaction now exceeds the value of the study and queried as to whether the user would like to continue the study with the interaction or simply run the study to generate an answer to the interaction.

With either response the system will need to generate a new schedule. If the user decides to continue with the study the schedule will have to include a significantly larger set of samples. If the user decides to continue with the study but only run it with the interaction the system will re schedule the content to include content during all dayparts not just morning and evening dayparts .

The system will continue to generate a power analysis to ensure that there are enough samples to complete the study with statistical reliability and that the opportunity costs for finding an answer do not exceed the value associated with the question.

Other embodiments of this system include those in which no urgency date is provided by the user. In this case the system will cue up the experiment and will constantly evaluate whether particular time periods should be used for this experiment or not. One method for the system to automatically decide whether a particular time period should be allocated to the experiment is to derive a value of the time period for the experiment versus for the MLR. The method for calculating the predicted expected reward for the MLR is the same as that described above. The method for calculating the value of the time period for the experiment is derived by taking the value of the experiment or hypothesis being investigated and dividing that value by the estimated number of time periods needed to conduct the study using a power analysis . When a time period that is necessary for conducting the experiment is being considered the system will conduct this calculation time periods not necessary for the experiment have zero value . If the value of the time period is greater than the expected reward for the MLR then the system will allocate that time period to the experiment otherwise the time period is allocated to the MLR. The user can monitor the progress of the experiment and if the value of the hypothesis begins to increase the user can modify the value to increase the speed at which the system will complete the study. In another embodiment the user may only specify the urgency date and no value of the hypothesis. Under this condition the system will specify a schedule and continuously update the schedule that minimizes the cost for conducting the experiment before the end of the urgency date.

Embodiments of the present invention are directed to systems and methods that facilitate user input of data associated with one or more hypotheses for a cause and effect experiment and data associated with one or more business goals. After entry of these and other necessary data processes of the present invention such as those described above with reference to for example are executed to ensure that for each time period of a playlist schedule and for each display of a network of displays that the system will work to maximize the utility of the network to achieve the user s requirements indicated by the user s input data. The user need not be further involved in these processes unless involvement is desired. The user may at any time query the system to determine the state of the network displays and may do so at various levels of resolution with granularity down to a time period by time period basis e.g. TSS by TSS basis if desired. The user may implement changes to these processes such as by terminating an experiment or increasing the amount to time periods allocated to explore and or exploit routines for example.

As was discussed previously a machine learning system may be implemented in accordance with embodiments of the present invention exclusive of a cause and effect experiment system. According to embodiments of the invention a machine learning system is preferably implemented using a digital signage network of a type described herein. Time periods of a playlist schedule are allocated for presenting various content on each display of the DSN network in accordance with a particular machine learning routine. Content is distributed and data is collected in accordance with MLR algorithms for optimizing content distribution patterns that maximize one or more effectiveness metrics e.g. point of purchase sales upgrades customer loyalty etc. . Various type of MLR systems may be implemented including those configured to execute reinforcement learning routines logistic regression routines unsupervised learning routines semi supervised routines transduction routines genetic algorithms support vector routines and learning to learn routines among others and those that use one or more neural networks.

According to various embodiments an MLR can be conducted without any cause and effect experimentation. Under these conditions the constraints that a cause and effect experiment require can now be removed. More particularly when considering content to present during a particular time period the DSN system does not have to consider whether the content has the potential of confounding the cause and effect experiment. Thus when the MLR is being run without cause and effect experiments the MLR can consider all of the content that it has at its disposal e.g. explore content exploit content etc. . Representative processes for implementing content optimization routines exclusive of cause and effect experiments according to embodiments of the invention include those shown in blocks of for example.

Other representative embodiments of systems and methods that employ MLR routines without a cause and effect experiment are those that use time slot samples. According to these embodiments the system assigns content to TSS s that are defined by the Viewer Visit Durations VVDs associated with the time that a customer can potentially see a display sign and ultimately act upon the content presented by the display. Methods for defining a TSS are described herein. For a particular TSS the MLR selects the content without considering whether the content would confound a cause and effect experiment. The MRL then executes the necessary algorithms as shown in blocks of for example.

The following discussion is primarily directed to details for implementing a cause and effect experiment in accordance with embodiments of the invention. Although primarily describing cause and effect experiments many aspects of the following discussion are applicable or adaptable to implementation of machine learning systems such as the embodiments described hereinabove. By way of introduction there are two major classes of research experimental and non experimental. Embodiments of the invention that involve cause and effect experiments are generally directed to systems and methods for conducting true experimental research and to sub systems and sub processes of such systems and methods that have stand alone utility and usefulness. However while systems and processes of the present invention described herein find particular usefulness when used as part of a true experiment many of the systems processes and methodologies described herein find usefulness and value outside the context of a true experiment.

For example various aspects e.g. sub systems and sub processes of the systems and processes described as part of a true experiment may be implemented in quasi experiments correlational studies or other forms of non experimental research. Implementing various system aspects and methodologies described herein can significantly improve the efficiency and accuracy of non true experimental systems and methodologies. It is therefore to be understood that the processes methodologies systems and devices described herein are not limited to use only within the context of true experimental research but may be used advantageously in other forms of research such as non or quasi experimental research and correlational studies.

Experiments are typically conducted to determine empirically if there are relationships between two or more variables and typically begin with the formation of one or more hypotheses positing that there is a relationship between one or more independent variables and one or more dependent variables. For example a researcher at a pharmaceutical company might formulate a hypothesis that the amount of a new drug that patients take will be related to the blood pressure of patients. Various types of experiments may be distinguished by the manner and degree to which they are able to reduce or eliminate the effects of confounding variables. Confounding variables are factors that could vary systematically with the levels of the independent variable. Only true experiments however can empirically determine causation which is why the Food and Drug Administration requires that true experiments be used to provide data regarding the effectiveness of new drugs for example.

Independent variables are the variables defined or manipulated by the experimenter during an experiment the amount and or frequency of a drug administered to patients for example. Dependent variables are the variables posited to be predicted by the value of the independent variable such as the blood pressure of patients. The experimenter then conducts an experiment to determine if there is indeed a relationship between the independent and dependent variables such as if the amount of a drug patients receive is related to the blood pressure of patients in a pharmaceutical experiment.

Confounding variables may also influence the dependent variable. These confounding variables are not of primary interest in the experiment yet can influence the dependent variables and therefore obscure an accurate cause and effect relationship between the independent and dependant variables. The experimenter is trying to understand the causal relationships between the independent and dependent variables however these confounding variables can render the results of an experiment uninterpretable. Some examples of confounding variables include Hawthorne effects order effects carryover effects such as between location confounds and within location confounds demand characteristics and or any other factor that could vary systematically with the levels of the independent variables e.g. such as the body mass of a test subjects in the pharmaceutical experiment discussed above.

Confounding variables make it difficult or impossible to know which factor variable caused any observed change in the dependent variable s . The existence of confounding variables that are not properly controlled during the experiment renders it difficult or impossible to make statistical inferences about causal relationships between the independent and dependent variables.

Various types of experiments may be distinguished by the manner and degree to which they are able to reduce or eliminate the effects of confounding variables. The only research methodology that reliably reveals causality is true experiments. The term true experiment denotes an experiment in which the following three characteristics must exist 

2. Samples are randomly assigned to levels of the independent variable. That is each sample in the experiment is equally likely to be assigned to levels of the independent variable.

Experiments that lack any of the above three characteristics are not true experiments and are often referred to as quasi experiments or correlational designs. Only true experiments allow statistical inferences to be drawn regarding the causal relationships between independent and dependent variables. Quasi experiments and correlational designs may allow relationships between independent and dependent variables to be established but it is not possible to determine whether those relationships are causal. Various types of experimental designs including true experiments have been described for example in Campbell D. T. Stanley J. C. Rand McNally 1963 .

Delivering content on displays of a digital signage network within physical environments is rife with potential for confounds that do not exist within the Internet domain. In a physical environment although people are generating dependent variable data e.g. point of sale or POS logs satisfaction survey responses sensor events it is difficult to connect the dependent variable data to the levels of the independent variables e.g. content on displays to which they might have been exposed. Consumers wander through stores and may or may not notice the displays or the content playing on them. Moreover the content played may change while the consumer is within viewing range thus exposing them to multiple levels of the independent variable. Furthermore many other variables might influence dependent variable data ranging from more or less predictable variables such as changing hotel occupancy rates or seasonal temperature variances to the unpredictable such as competitive marketing promotions and road construction.

Two types of confounds within the physical environment present extremely difficult measurement related challenges Between location confounds and within location confounds also referred to as between location and within location carryover effects. It is possible to have both within and between location carryover effects. Within location carryover effects occur when viewers who were present during one experimental condition e.g. while control content is displayed are still present during a different experimental condition e.g. when experimental content is displayed . Between location carryover effects occur when viewers at one location act on the content at a different location.

Embodiments of the invention relate to methods and systems that provide for determining the existence of and measuring the strength of cause and effect relationships between content being communicated and its effectiveness on recipients. Methods and systems implemented in accordance with embodiments of the invention facilitate distribution of communication content and assessment of the effectiveness of distributed communication content and as discussed above facilitate automatic optimization of content distribution patterns to maximize return on investment or other pre established business objective. Embodiments of the present invention provide for distribution of communication content in a manner such that the distribution pattern enables measuring of content effectiveness. Embodiments of the present invention provide for systematic control of the pattern i.e. timing and location at which communication content is distributed in order to control for and or eliminate confounds.

Communication content may take many forms including visual or aural or any form that can impact or be detected by the human sensory system e.g. the five senses of the human sensory system including tactile or touch taste and smell in addition to vision and hearing . Communication content may be static dynamic or a combination thereof.

Distributing communication content may be effected in many ways including electronically optically audio broadcasting or graphically or pictorially via static or dynamic images for example. Communication content may be distributed to and within a variety of physical environments including retail stores banks hotels airports roadways railways and other public or private spaces. Communication content may be presented via stationary or mobile structures devices and systems.

According to embodiments of the present invention a computer implemented system and method provide for generating time slot samples each of which is assigned a clock time. Each time slot sample has a specified time duration referred to as a time slot sample duration to which content may be assigned and a data collection period for measuring effects of the assigned content. The data collection period of a time slot sample is a period of time during which dependent variable data is collected. According to other embodiments a computer implemented system and method provide for assigning pieces of content to time slot samples for displaying on displays for measuring effects of the assigned content pieces.

Embodiments of the present invention provide for the distribution of communication content and to assessing effectiveness of such content consistent with constraints of a true experiment. Embodiments of the present invention are directed to providing for use in a computer implemented process rules for displaying communication content consistent with constraints of a true experiment. The rules which may be time based or event driven preferably control or eliminate confounds such as carryover effects. The communication content is displayed according to the rules. Data relating to effectiveness of the communication content is collected and the effectiveness of the communication content is evaluated based on the collected data.

Embodiments of the present invention are directed to algorithmically distributing content across one or more displays such that the distribution pattern meets the constraints of a true experiment for measuring the effects of the content. Conducting true experiments on communication content distribution networks such as digital signage networks or the Internet provides for determining the existence of and measuring the strength of cause and effect relationships between communication content and measures of business success e.g. sales sensor events survey data etc. .

Embodiments of the present invention employ algorithms to automatically schedule and present signage content such that the content presentation pattern precisely corresponds to the experimental design. The output of the algorithms may be used as the basis for parsing the dependent variable data to correspond to the experimental conditions.

While digital signage networks for example present many challenges such networks also offer ideal conditions for experiments than other media such as broadcast or cable television radio and print. With regard to television and radio for example advertisers cannot control which televisions play their commercials i.e. manipulate independent variables and they cannot measure the direct effect of the commercial on product sales i.e. measure effects of the independent variable on the dependent variable . Since most marketing research methodologies have evolved from these media models market researchers appear to have overlooked the possibility of conducting true experiments.

Digital signage networks by way of further example allow for precise scheduling of advertising content i.e. the ability to precisely manipulate independent variables . And because displays are typically near the product or otherwise in an environment in which changes in behavior can be measured it is possible to measure behavioral changes that arise from the content i.e. it is possible to measure effects of the independent variable on the dependent variable . Also data used to evaluate success against objectives are typically already collected in a form that can be readily used within the experiment.

According to methodologies of the present invention the independent variable is preferably digital signage content and the dependent variable may be any measure with business implications e.g. sales data sensor data survey data . Using systems and methods of the present invention it is possible to systematically control the pattern i.e. timing and location at which digital signage content is distributed across the digital signage network in order to control for and eliminate confounds.

In the context of various embodiments of the present invention the independent variables correspond to the properties of the content such as a strategic message or even an executional element like a dominant color or use of a photographic image. There are always at least two levels of the independent variable either both are experimental content or one level is experimental and one is control content. Experimental content is the content that is hypothesized to have an impact on the dependent variable analogues to the drug or drugs being tested in a clinical drug trial experiment . Control content is any content that would not be expected to impact the dependent variable analogous to a placebo pill in a clinical drug trial experiment . Manipulating the independent variables involves assigning either experimental or control content to be presented on signs at different times and different locations. The different levels of the independent variables are randomly assigned with constraints as described below to the different signs and different locations. The dependent variables can be any variable that would be posited to be impacted by the content e.g. sales data sensor data measuring pre purchase behavior .

Confounding variables as discussed above may influence the dependent variable and therefore obscure an accurate cause and effect relationship between the independent and dependant variables. If the experiment is double blind for example and given proper randomization there are only two categories of possible confounds carryover effects e.g. between and within location confounds which are described above and content confounds.

Content confounds occur when more than one version of experimental content for the same dependent variable is played during the same time slot during which measurement of the dependent variable is being measured. Such instances render it impossible to know which content underlies any observed change in the dependent variable. These types of confounds may be eliminated by ensuring that within a given time slot only experimental and or only control content is presented.

As previously discussed carryover effects occur when it is possible for a viewer to observe content during one time slot corresponding to an experimental condition and act on the content during a time slot associated with a different experimental condition. Again such instances render it impossible to know which content underlies any observed change in the dependent variable. Within location carryover effects occur when viewers who were present during one experimental condition e.g. while control content is displayed are still present during a different experimental condition e.g. when experimental content is displayed . Within location confounds may be controlled by ensuring that the time slot samples to which content can be assigned are sufficiently long to ensure that during some of the time slot samples e.g. half of the time slot sample the vast majority of the viewers e.g. 95 present at the viewing location were not present during the previous time slot sample. In this case data are preferably only recorded during the portion of the time slot sample in which the vast majority of viewers who would have been present during the previous time slot sample would have left the location.

An alternative approach involves using most or all of the data recorded during the time slot sample but weighting the data more heavily toward the end portion of the time slot sample as compared to the beginning portion of the time slot sample. Furthermore any still existing within location carryover effects e.g. those that would arise from the 5 or fewer consumers that would have been exposed to both versions of test content may be eliminated by counterbalancing the order at which content is presented e.g. ensuring that content B follows content A as often across the experiment as content A follows content B .

Between location carryover effects occur when viewers at one location act on the content at a different location. Between location carryover effects may be eliminated by ensuring that locations within plausible traveling distance of each other are constrained in the content they play such that it is not possible to leave one location while one experimental condition is in force and go to a nearby location and act in ways that affect the dependent variable s while other experimental content is in force.

Two types of blocking may be employed for different reasons blocking by optimization factors and blocking by noise variables. Optimization factors are those factors at the signage location that might have implications for the effectiveness of the content. Such factors include signage location ambient lighting socioeconomic status of viewers dayparts and the like. Blocking by these factors allows for factorial analyses to measure interactions between content and optimization factors e.g. measuring whether content A is more effective in the morning whereas content B is more effective in the evening . Blocking by noise variables can be used to increase statistical power by eliminating variability associated with factors that impact the dependent variable that are predictable but that are of no interest with respect to the experiment.

Provided hereinbelow are representative examples directed to distribution of communication content and assessing the effectiveness of such content in a manner consistent with constraints of a true experiment. These examples are provided for illustrative purposes only and do not limit the scope or application of the disclosed principles. Rather a wide variety of media and communication distribution architectures and methodologies are contemplated including those involving print media cellular or wireless communication devices Internet accessed content and devices including fixed and portable e.g. hand held devices in store and outdoor e.g. electronic billboard display systems. A wide variety of content that can be communicated over such architectures and devices is also contemplated including advertising content teaching content and way finding content for example.

Although the automated experimental design methodologies described herein are generally focused on digital signage applications it is understood that such methodologies may be applied to numerous marketing communication tactics including webpage design Internet advertising point of purchase printed marketing and direct marketing among others. For example Internet analytics methods or web based automated experimentation systems such as the systems disclosed in U.S. Pat. Nos. 6 934 748 and 7 130 808 which are incorporated herein by reference may be modified in accordance with the present invention to provide for implementing true experimental design or sub processes that have constraints of a true experiment.

Aspects of the present invention may be incorporated in automated content distribution systems and methods that are not directed to experimentally measuring the effects of the distributed content but involve distributing content based on other constraints such as fulfilling contract obligations. An example of such a system and method is disclosed in U.S. Patent Publication No. 2006 0287913 which is incorporated herein by reference. In such systems and methods content distribution may be performed while simultaneously measuring the effectiveness of the distributed content in accordance with the present invention.

The following non limiting examples of systems and methodologies illustrate various embodiments of the present invention. Some of the examples are directed to systems and algorithms that facilitate measuring the effectiveness of communication content consistent with constraints of a true experiment. Some of the examples are directed to systems and algorithms that facilitate control of the pattern at which communication content is distributed in order to control for and eliminate or significantly reduce confounds. Some of the examples are directed to systems and algorithms that may be implemented to facilitate non experimental analyses of content effectiveness such as in quasi experimental analyses and correlational studies.

Various embodiments of the present invention provide for automatic parsing of the dependent variable data to correspond to the experimental conditions. illustrates embodiments that involve the provision of rules for displaying communication content consistent with constraints of a true experiment. In some embodiments provision of these rules involves creation of such rules consistent with constraints of a true experiment. In other embodiments previously created rules are provided to a system that provides for displaying communication content consistent with constraints of a true experiment. As is further shown in the communication content is displayed according to the rules. Data relating to the effectiveness of the communication content is collected and the effectiveness of the communication content is evaluated based on the collected data.

In some embodiments provision of the playlist and schedule involves creation of the playlist and schedule consistent with constraints of a true experiment. In other embodiments a previously created playlist and schedule are provided to a system that provides for displaying communication content consistent with constraints of a true experiment. The communication content is distributed across a digital signage system. The communication content is displayed on displays of the digital signage system according to the playlist and schedule. Data relating to the effectiveness of the communication content is collected and the effectiveness of the communication content is evaluated based on the collected data.

It is to be understood that one or multiple processing devices e.g. PCs mini computers network processors network servers etc. may be used to perform one some or all of the processes shown in and in other Figures of this disclosure. For example a first processor or set of processors may be used in the creation of playlists and schedules. A second processor or set of processors may be used to distribute content at one location or across a digital signage system. A third processor s may be used to display content according to the playlists and schedule while a fourth processor s may be used to collect data relating to content effectiveness. A fifth processor s may be used to evaluate the effectiveness of content based on the collected data. In some embodiments these processes and other processes discussed herein e.g. those associated with machine learning systems can be implemented by one or more processors that may be networked so as to effect communication between some or all of these processors.

In other embodiments some or each of such processes may be implemented by processor s that are not networked or otherwise linked to effect communication therebetween. For example a first processor s may be configured to execute a set of program instructions to implement playlist and schedule creation while a second processor s may be configured to execute a set of program instructions for distributing content to one or a number of display devices. Unless otherwise indicated the terms processor computer or module and their variations as used herein and in the claims contemplate a single processor multiple processors of which some or all may be communicatively coupled disparate processors single of sub networks that are not communicatively coupled together and other configurations of processing resources.

According to the illustrative example shown in setting up the digital signage network setup involves determining display locations that facilitate control reduction or elimination of confounds such as carryover effects. For example setting up the network may involve determining locations in which at least a predetermined percentage e.g. 95 of customers would not have visited another location displaying experimental or control content. It is not critical that a value of 95 is chosen. However it is understood that the greater the value chosen the less likely it is that the result could underestimate the precise amount of the return on investment from the content. The value of 95 is simply large enough that with proper counterbalancing the impact of carryover effects would be almost nonexistent.

It is important to ensure that the vast majority of viewers will not have an opportunity to see the message at one site and act upon it at another site that is playing different control or experimental content. Instances of this happening would be instances of carryover effects which can confound the results of the experiment. For example if one were conducting experiments on displays in automobile dealerships one would need to know which dealerships are close enough in proximity to each other such that a viewer could see content in one dealership and purchase vehicle in another dealership partaking in the experiment. This can be accomplished as part of the digital signage network setup. For example the software could prompt the installer to select all of the locations across the network at which viewers could plausibly visit after leaving their dealership e.g. other dealerships in the same geographic region .

Network attributes and optimization factors present at sign locations are preferably identified at part of the digital signage network setup. Such factors may include characteristics of each site that predictably impact the value of the dependent variables at the locations e.g. store size socioeconomic class other advertising efforts daypart differences in the typical number of viewers at the location . These factors then become blocking factors in the experiment.

There are two categories of blocking factors. One category includes those factors in which the experiment would test for interactions and that would have implications for strategic decisions about what content to display e.g. content A might be more effective at low Socio Economic Status SES dealerships whereas content B might be more effective at high SES dealership . The other category of blocking factors are those that do not have obvious implications for which content to show but that should nonetheless be blocked against in order to increase the statistical power of the experiment. Again these factors can be specified during the software installation process and updated thereafter.

Network setup also includes estimating sample size requirements for the experiment . Ideally a statistical power analysis is preferably used to calculate how much data is needed to find statistically significant results of at least some minimum magnitude that is of business interest.

Control and experimental content are defined as part of the network setup. Control content i.e. the placebo can be any message that is neither intended nor likely to influence the desired behavior such as local weather or news or messages about a product or service that is unrelated to the dependent variable. Experimental content is the content that is hypothesized to cause a change in the dependent variable. It is noted that under some circumstances experimental content for one hypothesis can serve as control content for a different hypothesis.

Data regarding the maximum duration that the vast majority of viewers spend at the site conducting their business is acquired and used to control for carryover effects. Examples of processes for eliminating or controlling for location carryover effects are described in commonly owned U.S. patent application Ser. No. 12 166 984 filed on Jul. 2 2008 which is incorporated herein by reference.

Data recording does not begin until 95 of the customers who were present during the previous time slot sample would have left the signage location. In this example data are only recorded during the last 30 minute portion of the time slot sample . It is noted that the time interval for each location is preferably represented by the smallest unit of time across which dependent variable data can be measured. For example sales data collected in some point of sale systems is provided in units of seconds whereas other systems report sales only across units of hours. illustrates processes for controlling location carryover effects in connection with distributing communication content and assessing effectiveness of such content in accordance with other embodiments of the present invention.

Many of the processes shown in and figures associated with various machine learning embodiments discussed above have inputs that are typically received from other processes systems e.g. POS systems sensors e.g. presence sensors or from a user among others. These inputs include the following duration data for each piece of content that is being tested for effectiveness CD duration of interest DI after which the content is viewed not to be of interest if the content caused a change in the behavioral or transactional data being measured pair wise content relatedness data CR i.e. is content A expected to differentially impact the same behavioral or transactional data as content B pair wise location relatedness LR i.e. the likelihood that viewers can be exposed to content at location A and behave at location B within the above stated duration of interest optimization factors present at sign location OF estimated sample size requirements which may be optional for how many time slot samples are required for each piece of content by optimization factors SS maximum duration that a certain percentage of target viewers e.g. 95 spend at the sites where displays are located viewer visit duration or VVD time intervals TI for data collection aggregation for data streams of interest that target viewers can affect during visit to the site TI blocking factors i.e. the most powerful factors that are predictive of dependent variable data but that are not per se of interest for optimizing content absolute placebo content and experimental content.

Viewer visit duration is an important parameter that represents the maximum time that a specified percentage of viewers spend at a location. VVD is typically calculated from individual VVDs for many viewers understanding that there will be a distribution of individual VVDs depending on a large number of factors that influence the time an individual spends at a location. Precision of VVD depends on the size of the location. A small location e.g. a small store would have well defined opportunities for seeing the content and then acting on the content within a few minutes.

Viewer visit duration may be determined in a variety of ways such as by estimating the VVD based on an expected VVD. Determining the VVD may be based on one or more factors including for example transactional data prior sales data sensor data e.g. proximity or presence sensor data and observational data. Other approaches for determining the VVD are discussed in illustrative examples provided hereinbelow.

It is understood that some viewers will never see or comprehend displayed content but may nonetheless purchase an advertised item generalized to the behavior being measured . Other viewers will see the content and not buy and other viewers will both see and buy an advertised item. In this regard methods of the invention are directed to revealing the difference between measured behavior as a function of content experimental vs. control being displayed. It is noted that this behavior difference being measured will also be a function of display location e.g. in an obscure corner where few will see it vs. a very conspicuous position where all will see it . If the display is seen by few none then the most compelling content FREE Flat Screen TVs Today will result in virtually no difference for measured behavior picking up the free TVs .

Location is an important term that refers to the physical space within which the viewer can be both exposed to levels of independent variables e.g. in the form of digital signage content and cause a change in dependent variable data often dependent variable data will consist of point of sale or sensor data corresponding to the independent variables. Often the location in a retail environment is the physical space owned by the retailer. However there are some circumstances when the location will be a subset of the space owned by the retailer. For example consider the case of a hotel lobby having a display nearby the check in desk where an experiment is testing the relative effectiveness of two pieces of digital signage content designed to increase the probability that guests will upgrade to a nonstandard room. In this case the location would be the hotel lobby area and not the entire hotel because viewers could only be exposed to the content within the hotel lobby and it is very unlikely that viewers would upgrade to a nonstandard room other than during their first visit to the hotel lobby. As such this is a controlled physical space allowing for precise VVDs.

In the case of a city having a single outdoor display and multiple retail establishments where consumer behavior is measured e.g. by purchasing an advertised product presented on the city s single outdoor display for example VVD becomes much less precise. Shopping mall environments typically fall somewhere between a controlled location allowing for precise VVDs and the exemplary city scenario discussed above. By way of contrast it is noted that the most controlled situation is a location represented by a person sitting at a computer display responding to i.e. behaviorally acting on content by way of mouse clicks and or keystrokes.

As was discussed previously carryover effects occur when the effects of one level of an independent variable persist when attempting to measure the effects of another level of the same independent variable. The solution to controlling for or eliminating carryover effects provided by embodiments of the present invention is to ensure that sufficient time has passed between 1 changing levels of independent variables and 2 collecting data after changing levels of an independent variable.

One way to ensure that carryover effects are eliminated in the context of digital signage content is to wait very long periods between changes of levels of independent variables and or wait very long periods between changing levels of an independent variable and collecting dependent variable data. For example one could only show one level of an independent for a week or more at a time. Then by collecting data during the entire week it would be unlikely that many of the data points collected during the week would be impacted by a different level of the independent variable e.g. save money in this example . However such an approach severely limits the number of instances across time that levels of independent variables can be changed.

Those skilled in the art will appreciate that the speed with which conclusions can be generated from experiments is directly related to the number of instances across time that independent variables can be manipulated. Embodiments of the present invention advantageously provide for use of VVD and TI as inputs to determine how often changes in the levels of an independent variable occur thus allowing one to control for or eliminate carryover effects while changing independent variable levels as frequently as possible.

Referring again to a schedule is parsed into time slot samples. Parsing the schedule is essential for eliminating carryover effects. Parsing typically involves algorithmically parsing the schedule such that time slot samples can be assigned to the schedule or schedules which dictate playback of the content.

Creation of a playlist involves algorithmically assigning content to time slot samples such that the content distribution pattern i.e. timing and location at which content is played meets the constraints of the experiment. This may be accomplished for example by ensuring experimental and control content is not confounded randomly assigning content to time slot samples with specific constraints that ensure blocking by network optimization factors i.e. factors that are being studied blocked by other factors that can be controlled and predicted but that are otherwise not of interest in the study i.e. noise factors counterbalancing for order effects randomizing across uncontrolled factors ensuring that the design is balanced such that there is roughly an equal number of time slot samples across blocks and meeting established sample size requirements.

The content is distributed according to the playlist schedule. Ideally this process and associated algorithms are embedded within content management software so that the content can be automatically distributed according to the created playlist schedule. A report of the algorithmic processes discussed above is preferably generated . The report preferably identifies what content was presented and when and where the content was presented. The report may also indicate what dependent variable data to code and any optimization noise and blocking factors were present or used. Other data pertinent to processes or performance impacting the algorithms may also be included on the generated report. It is understood that these and other data information is recorded so that a report of the algorithmic processes may be generated. The report preferably specifies which dependent variable to code within each time slot sample and which dependent variable data to use or discard due to possible contamination by carryover effects or other confounds.

Dependent variable measures are parsed by experimental condition which may use data of the generated report. For example dependent variable data e.g. POS sales data is preferably time and location stamped such that this data can be automatically parsed according to the experimental conditions for analysis and or for use by a machine learning system such as those described hereinabove .

Embodiments of the present invention as exemplified by the processes shown in generate samples referred to herein as time slot samples to which content can be assigned for measuring the effects of the assigned content. These samples and the methodologies that generate such samples have significant value and represent an end product that can be utilized by a purchaser of these samples to test the effectiveness of content.

The processes shown in in one sense describe a technique or tool e.g. software that can be used to increase the speed and accuracy of conducting experiments on the effectiveness of content. A technique or tool implemented in accordance with represent a valuable end product that provides utility to one that wishes to conduct experiments on the effectiveness of content. By way of analogy and in the context of the biological research domain tools are developed and used to increase the speed and accuracy of conducting experiments on for example cancer cells and for decreasing the cost of conducting such experiments. For example genetic sequencing tools have been developed to automatically control the steps of genetic sequencing. In a similar fashion tools and techniques implemented in accordance with may be used to increase the speed and accuracy of conducting experiments on the effectiveness of content and to decrease the cost of conducting such experiments.

Time slot sample duration TSSD is determined for each display location. Time slot sample duration is a specific duration of time that a time slot sample lasts. During a TSSD different experimental and control content is played preferably in a manner such that there is no overlap that would produce confounds. According to one approach and as indicated at blocks and of time slot sample duration may be computed as follows Is If No then 2 If Yes then 1 

It is noted that if the TI is not equal to nor greater than the VVD e.g. TI is 1 second in Formula 1 above then half of the duration of the time slot sample duration will include viewers that were not present for content from the previous time slot sample. Importantly only data collected during this second half i.e. the data collection period of the TSSD in this example is included in the analysis and in conjunction with counterbalancing this eliminates carryover effects.

A randomization process ensues by which time intervals are subject to random selection . The algorithm randomly selects any open time interval that begins at least one of a particular location s TSSDs after that location s opening time. The term open time interval in this context refers to a time interval that does not already have a time slot sample associated with it.

A time slot sample is assigned to begin one TSSD of that location prior to the beginning of the randomly selected TI. This process continues until no legal TIs remain to assign a TSS. It is noted that time slot samples are selected with the following constraint time slot samples subsumed by previously selected time slot samples are excluded e.g. if content is already being played from 9 01 9 20 the system does not choose 9 01 9 20 for candidate slots .

According to the sequential time slot sample generation methodology of creating time slot samples for each location involves selecting a location at which content is to be presented. The beginning of the first TI that is TSSD from the location s opening time is found . A TSS is assigned to begin one TSSD before the beginning of the TI. This process is repeated for the closest TI which is TSSD away from the end of the previous TSSD until the closing time is reached . This TSS creation process is repeated for each selected location . Generating time slot samples in a sequential manner as shown in generally results in achieving greater efficiency of TI utilization.

Another means of quickly generating results needed to evaluate content effectiveness is the ability to use multiple locations on a network each having a display capable of showing content. Each location can be producing time slot samples needed to fulfill the quantity of data to validate a hypothesis. In general the rate of data generation scales with the number of locations e.g. ten locations working in concert can generate about ten times the samples as a single location. This arrangement leads to the added possibility of learning about interactions between content effectiveness and display locations.

The methodology disclosed in this application also allows the ability to simultaneously test multiple independent variables during the same time slot samples providing that the content associated with the different independent variables is unrelated. This is because experimental content for one independent variable can be control content for another independent variable. Using this technique further increases the speed of experimentation as it is possible to simultaneously conduct experiments addressing multiple business objectives thus liberating display time to achieve business goals.

The process of random assignment is repeated with the constraint that only control content is assigned to the same time slot sample as any piece of experimental content. This ensures that there are no location confounds. It is noted that it is valid to assign experimental content for one hypothesis to a time slot sample that already contains experimental content for another hypothesis provided that the content can serve as a control for the experimental content for the other hypothesis. That is one can run two experiments at once provided that the hypotheses are orthogonal and can additionally run one or more machine learning routines as described hereinabove .

The algorithm of may further involve blocking by optimization factors . This allows for factorial analyses to measure interactions between content and optimization factors. The algorithm shown in may also involve blocking by noise factors in order to increase statistical power. These processes preferably continue to assign content to time slot samples until main effect and interaction effect sample size requirements are satisfied and the design is balanced. The algorithm may further provide for counterbalancing for order effects. Within each time slot sample the order in which individual pieces of content are displayed is counterbalanced using known techniques e.g. Latin Squaring .

The processes shown in blocks and are repeated until all time slot samples under the control of the Experiment System are filled with experimental content. A report of the algorithm s output may be generated . The report may contain various information such as that previously described with reference to . It is noted that if the time slot samples are tagged with attributes this will allow for hypotheses to be generated based on any interactions that are found between the content assigned to time slot samples and the attributes of the time slot samples and enable exploratory data analysis.

Under many experimental circumstances it is desirable to have each level of the independent variable or variables assigned to the same number of samples. illustrates processes of an algorithm that assigns content to time slot samples using a constrained randomization process in accordance with embodiments of the present invention such that each piece of experimental content is assigned to the same number of time slot samples. The algorithm shown in involves selecting any time slot sample between the experiment s staring and ending points that has not already been assigned experimental content. The algorithm further involves randomly selecting any piece of experimental content and assigning the selected experimental content to the selected TSS.

The processes shown in blocks and are repeated with the constraint that each piece of experimental content is assigned to the same number of time share samples. A report of the algorithm s output may be generated as discussed previously.

Under some experimental circumstances the experiment might have been designed manually or using off the shelf statistical software or using for example an expert system as described hereinbelow in which case the sample size requirements for various experimental and control content would have been specified. illustrates processes of an algorithm that takes as input such sample size requirements and assigns content to time slot samples using a constrained randomization process in accordance with embodiments of the present invention to ensure sample size requirements are met. The algorithm shown in involves randomly selecting the number of time slot samples required for all content samples. The algorithm further involves randomly assigning experimental content to the selected content samples. It is noted that the remaining time slot samples that were not required because sample size requirements have been met may be filled with content that is optimized for business results rather than for testing any hypothesis.

The algorithm shown in involves randomly selecting any first piece of experimental content and randomly selecting any first time slot sample between experiment starting and ending points. The randomly selected first piece of experimental content is assigned to the selected first time slot sample.

The algorithm of involves randomly selecting another second time slot sample with the constraint that it has a different level of optimization factor than a previously selected first time slot sample. The selected first piece of experimental content is assigned to this second selected time slot sample. The above described TSS selection processes are repeated until the selected first piece of content has been assigned to one TSS in all levels of the optimization factor.

The algorithm of further involves randomly selecting any second piece of experimental content and repeating processes for this next second piece of experimental content. The processes of blocks are repeated until the maximum number of time slot samples have been filled without resulting in an unbalanced design i.e. until there are fewer time slot samples than the number of optimization factors multiplied by the number of pieces of experimental content.

The algorithm shown in involves randomly selecting any first piece of experimental content and randomly selecting any first time slot sample between experiment starting and ending points. The randomly selected first piece of experimental content is assigned to the selected first time slot sample.

The algorithm of involves randomly selecting another second time slot sample with the constraint that it has a different level of blocking factor than a previously selected first time slot sample. The selected first piece of experimental content is assigned to this second selected time slot sample. The above described TSS selection processes are repeated until the selected first piece of content has been assigned to one TSS in all levels of the blocking factor.

The algorithm of further involves randomly selecting any second piece of experimental content and repeating processes for this next second piece of experimental content. The processes of blocks are repeated until the maximum number of time slot samples have been filled without resulting in an unbalanced design i.e. until there are fewer time slot samples than the number of blocking factors multiplied by the number of pieces of experimental content .

The algorithm shown in involves randomly selecting any open time slot sample between experiment starting and ending points. A piece of experimental content is randomly selected and the selected piece of experimental content is assigned to the selected TSS. The algorithm of further involves randomly selecting a piece of experimental content with the constrain that it is unrelated to content already assigned to the TSS. The selected piece of experimental content is assigned to the selected TSS. The processes of blocks and are repeated until it is not possible to add a piece of experimental content without having the sum of the durations of all of the selected experimental content exceed the duration of the TSS or until there are no unrelated experimental content pieces remaining whichever comes first.

If any open time remains in the selected TSS the remaining open time of the TSS is filled with absolute placebo content. The algorithm of also involves randomly ordering the content within the TSS. If the TSS contains any absolute placebo content randomization ensues such that equal durations of the placebo content separate the experimental content pieces.

Another open TSS is randomly selected between the experiment starting and ending points. A piece of experimental content that has not been assigned to a previously filled TSS is randomly selected . If all pieces of content have been assigned absolute placebo content is selected. If absolute placebo content was selected in block the selected TSS is filled with absolute placebo content otherwise the selected piece of experimental content is assigned to the selected TSS and this TSS is filled in accordance with the processes of blocks . Open TSSs continue to be filled according to the processes of blocks until all pieces of experimental content have been assigned to a TSS.

A potential drawback of using all experimental locations in such a way as to eliminate all location confounds is that any location that is used in this fashion is not able to be exposed to multiple levels of the same independent variable. As such it would be difficult to measure how combinations of different levels of an independent variable would interact with one another within the same location. It may be desirable under some circumstances to first select a pre determined number of locations to be assigned experimental content for complete within location testing effects and then run this algorithm to use the remaining locations for testing without between location confounds. That is for example one could use to meet a pre determined sample size for within location factors and then use to measure the effects of content across locations.

The algorithm shown in involves randomly selecting any experimental location and selecting all locations related to the selected location. Content is randomly assigned to the locations selected in the preceding two blocks with the constraint that only unrelated content pieces are assigned to the locations. Another experimental location is randomly selected with the constraint that it is unrelated to any locations already selected. All locations related to the location selected in the previous block and unrelated to selected locations for blocks and are selected . Content is randomly assigned to the locations selected in the preceding two blocks with the constraint that only unrelated content pieces are assigned to these locations. The processes of blocks are repeated until there are no unrelated locations remaining.

System according to embodiments of the present invention may include one or more of the features structures methods or combinations thereof described herein. For example systems may be implemented to include one or more of the advantageous features and or processes illustrated in . It is intended that such systems need not include all of the features described herein but may be implemented to include selected features that provide for useful structures and or functionality.

A digital signage system DSS according to embodiments of the present invention is shown in . The DSS illustrated in is a computerized system configured to present informational content via audio visual and or other media formats. The DSS may include functionality to automatically or semi automatically generate playlists which provide a list of the information content to be presented and schedules which define an order for the presentation of the content. In a semi automatic mode a user may access a DSS control processor via an interactive user interface . Assisted by the DSS control processor the user may identify content to be presented and generate playlists and schedules that control the timing and order of presentations on one or more DSS players . Each player presents content to recipients according to a playlist and schedule developed for the player. The informational content may comprise graphics text video clips still images audio clips web pages and or any combination of video and or audio content for example.

In some implementations after a playlist and schedule are developed the DSS control processor determines the content required for the playlist downloads the content from a content server and transfers the content along with the playlist and schedule to a player controller that distributes content to the players . Although shows only one player controller multiple player controllers may be coupled to a single DSS control processor . Each player controller may control a single player or multiple players . The content and or the playlists and schedules may be transferred from the DSS control processor to the one or more player controllers in a compressed format with appropriate addressing providing information identifying the player for which the content playlist schedule is intended. In some applications the players may be distributed in stores or malls and the content presented on the players may be advertisements.

In other implementations the DSS control processor may transfer only the playlists and schedules to the player controller . If the content is not resident on the player controller the player controller may access content storage to acquire the content to be presented. In some scenarios one or more of the various components of the DSS system including the content storage may be accessible via a network connection such as an intranet or Internet connection wired or wireless . The player controller may assemble the desired content or otherwise facilitate display of the desired content on the players according to the playlist and schedule. The playlists schedules and or content presented on the players can be modified periodically or as desired by the user or automatically algorithmically through the player controller or through the DSS control processor for example.

In some implementations the DSS control processor facilitates the development and or formatting of a program of content to be played on a player. For example the DSS control processor may facilitate formatting of an audiovisual program through the use of a template. The template includes formatting constraints and or rules that are applied in the development of an audiovisual program to be presented. For example the template may include rules associated with the portions of the screen used for certain types of content what type of content can be played in each segment and in what sequence font size and or other constraints or rules applicable to the display of the program. A separate set of rules and or constraints may be desirable for each display configuration. In some embodiments formatting a program for different displays may be performed automatically by the DSS control processor .

In some embodiments the DSS may create templates generate content select content assemble programs and or format programs to be displayed based on information acquired through research and experimentation in the area of cognitive sciences. Cognitive science seeks to understand the mechanisms of human perception. The disciplines of cognitive and vision sciences have generated a vast knowledge base regarding how human perceptual systems process information the mechanisms that underlie attention how the human brain stores and represents information in memory and the cognitive basis of language and problem solving.

Application of the cognitive sciences to content design layout formatting and or content presentation yields information that is easily processed by human perceptual systems is easy to understand and is easily stored in human memory. Knowledge acquired from the cognitive sciences and stored in a cognitive sciences database may be used automatically or semi automatically to inform one or more processes of the DSS including creation of templates content design selection of content distribution of content assembly of programs and or formatting of programs for display. The cognitive sciences database used in conjunction with the programming of the DSS yields advertisements or other digital signage programs that are enhanced by the teachings of cognitive science while relieving the system user from needing specific training in the field.

For example cognitive sciences database may store cognitive and vision science information that is utilized during the content design distribution and or adjustment processes in order to provide content that is easily processed by human perceptual systems easily comprehended and easily stored in memory. Cognitive sciences database may include design rules and templates that may be implemented by a computer to develop and modify content in conformance with principles of cognitive and vision sciences. Cognitive sciences database may also include computer implementable models of principles of cognitive and vision sciences such as models of visual attention text readability and memory principles.

In development of a digital signage program e.g. ad campaign or the like the DSS control processor may guide a user through various processes that are enhanced using knowledge acquired through the cognitive sciences. For example information stored in the cognitive sciences database may be applied to the choice of templates to produce an optimal program layout and or to the selection of content such as whether content elements should be graphical text involve movement color size and or to the implementation of other aspects of program development

Computer assisted methods and systems of the present invention may be implemented to allow content designers who typically do not have the training required to apply principles from cognitive science and vision science to increase the effectiveness of content design and distribution. Systems and methods of the present invention may incorporate features and functionality involving cognitive sciences database in manners more fully described in co pending U.S. patent application Ser. No. 12 159 106 filed on Dec. 29 2006 as International Application US2006 049662 designating the United States entitled Content Development and Distribution Using Cognitive Sciences Database which is incorporated herein by reference.

The DSS may include the capability for designing alternative versions of a digital signage program to accommodate diverse display types and viewing conditions. Display technology is diverse and there are large differences in the types of displays used to present content on a digital signage network. For example the size shape brightness and viewing conditions will vary greatly across a digital signage network e.g. some displays may be small flexible and non rectilinear whereas others may be standard large format Liquid Crystal Display LCD and plasma displays . The variation in display types and viewing conditions means that any single version of a piece of content may not be optimal for all the displays across a network.

In order to overcome this problem it may be necessary to generate versions of each piece of content for each display type and viewing environment and to selectively distribute these versions of content to their corresponding screens in the network. However it is not realistic to expect content designers to have such detailed knowledge of the display types and viewing conditions across a large DSS network. Furthermore even if such content designers had such detailed knowledge it would be time consuming to manually create versions of content for each display and to manually schedule the content to play on each corresponding display at the appropriate time.

The DSS may include a data acquisition unit for collecting data used to improve the effectiveness of deployed content. The data acquisition unit allows distribution factors that underlie the effectiveness of digital signage networks to be continuously gathered in real time during deployment of content. The information acquired can facilitate continuous improvement in content effectiveness of the DSS as well as improvement of individual versions of content pieces. Previously acquired data may be used to learn what sensor or sales events should trigger the display of specific types of content for example.

Individual pieces of content in any content program each have a specific goal e.g. to sell a specific product . It is usually the case that there is variability in the value of each goal to the user of the digital signage network. For example there may be variability in the profit margin and inventory level for each product which factor into the value of the goal for the product. The value of achieving each goal continuously changes during the time a digital signage program is deployed. For example the inventory level of a product may change thus affecting the goal for sales of the product.

Enhancing the effectiveness of a DSS as a whole involves 1 accurate prediction of the impact of deploying a digital signage program on the goal associated with the digital signage program and 2 continuously changing the distribution patterns timing frequency and location of individual pieces of content as the value of each individual goal corresponding to the pieces of content change. In many cases it is unfeasible for users of the DSS to predict the impact of deploying content and to manually change content distribution patterns based on continuously changing values of goals associated with each piece of content. The DSS provides the functionality to predict the impact of digital signage programs and to alter the distribution of content based on the predictions.

As previously stated content is displayed on the players with the goal of affecting human behavior e.g. to impact purchasing behavior . However prior digital signage systems are unable to demonstrate a cause and effect relationship between signage content and human behavior or to measure the strength of the cause and effect relationship. This difficulty arises because the methods by which content is delivered across current digital signage networks does not support the determination of whether any measured change in human behavior was caused by signage content or the result of some confounding factors e.g. change in weather change in general demand for the product change in price of the product .

The only way to decisively determine cause and effect relationships between signage content and human behavior is to conduct a true experiment during which signage content is systematically manipulated using complex experimental designs and the effects of those manipulations on human behavior are carefully measured. Manually conducting such experiments is time consuming and requires significant knowledge and training in the scientific method of how to design true experiments. The users of digital signage systems may not have sufficient training to understand how to design a true experiment to acquire confound free results.

The DSS illustrated in includes a experiment design processor and user interface that provide the capability to design true experiments and also includes a machine learning design processor and the user interface that provides the capability to design machine learning routines. Also included in the DSS shown in is an experiment deployment unit configured to control execution of cause and effect experiments and a machine learning deployment unit configured to control execution of machine learning routines.

The system may further include an experiment deployment unit . The experiment deployment unit is configured to facilitate deployment of the experiment. In the context of a representative DSS system the experiment deployment unit formats the experimental content and the control group content for various player configurations and facilitates the transfer of the experimental content and the control content to the player controller for presentation on players as specified by the playlists and schedules. A machine learning deployment unit of the DSS system coordinates execution of one or more machine learning routines such as those discussed above and formats content to be used by the MLRs. The machine learning deployment unit facilitates the transfer of MLR content to the player controller for presentation on players as specified by MLR playlists and schedules.

The data acquisition unit may be configured to collect experimental data from the control and treatment groups and optimization data for the machine learning routine. The data acquisition unit may perform or facilitate acquisition of data associated with the experiment and the machine learning routine via any means. For example in the context of the exemplary DSS the data acquisition unit may be coupled to various sensor or data acquisition devices that gather information including product movement product sales customer actions or reactions and or other information. Sensors may be used to detect for example if a customer picks up the product or if a customer is in the vicinity of the display when the content is displayed. Sales may be determined based on information acquired by a point of sales POS system . One or more devices that validate the display of content may also be used. Changes in inventory levels of a product may be available via an inventory control system. Customer reactions may be acquired via questionnaires. If the conducted experiment is a true experiment the data acquired by the data acquisition unit is substantially confound free.

The data acquisition unit may be coupled to a data analysis unit that is configured to analyze the experimental data collected by the data acquisition unit . The data analysis unit may determine and or quantify cause and effect relationships between the independent and dependent variables of the experiment. For the illustrated DSS the results of the analysis may be used to determine if the content is effective at influencing product sales. The data analysis unit may analyze acquired data for purposes of optimizing content distribution patterns that maximize one or more effectiveness metrics such as point of purchase sales upgrades and customer loyalty and the like.

Because the analysis unit will have received information regarding the independent and independent variables e.g. whether the IVs and DVs are continuous or discrete the analysis unit would have much of the necessary information to choose the appropriate statistical test to apply to the data from the experiment. For example if there is one IV with two discrete levels and one continuous DV then a T Test would be used for the inferential statistical test whereas if there is one IV with two discrete levels and one DV with two discrete levels then a Chi Squared test would be used for the inferential statistical test. Likewise because analysis unit will access to information from the design processor regarding which experimental conditions are diagnostic of particular hypotheses the analysis unit would have most or all of the information needed to determine which experimental and control conditions should be statistically compared.

The results of these analyses may be additionally or alternatively used to implement or modify various processes. For example if the content was effective at influencing product sales an advertisement campaign may be developed incorporating the content. A value may be assigned to the content by a content valuation process based on the effectiveness of increasing sales. An advertiser using the content may be invoiced by a billing unit according the value of the content. The data analysis unit may also provide information to inventory control . Additionally the data analysis unit may provide information to a sales prediction unit that generates a prediction of sales when the advertising campaign is deployed. The sales prediction unit may additionally or alternatively predict the product inventory needed to support the sales generated by the advertisement campaign.

Implementation of a digital signage system including capabilities for generating digital signage content deploying experiments designed by the expert system and collecting experimental data are further described in co pending U.S. patent application Ser. No. 11 321 340 filed Dec. 29 2005 and in U.S. patent application Ser. No. 12 159 107 filed on Dec. 29 2006 as International Application US2006 049657 and entitled Expert System for Designing Experiments which are incorporated herein by reference.

The systems and methods described herein may form the basis of a consulting business according to embodiments of the present invention. Services offered could include but not be limited to working with customers to characterize their time slot samples as appropriate for certain communication objective and certain consumer audiences determining which variables a study would address determining levels of independent variables for testing determining factors that could be used for blocking and randomizing and conducting a power analysis among others. A measurement algorithm as previously described may be used to specify time slot allocation requirements for cross optimization and blocking factors.

Another application in accordance with the present invention is directed to systems and method for maximizing overall profitability. A system of the present invention may be used to optimize allocation of all available time slot samples for two objectives 1 content effectiveness testing as described in detail hereinabove and 2 content that is not being tested but meant to address any number of business goals such as increasing sales promoting consumer satisfaction informing employees etc.

A system implemented according to the present invention as described herein may provide the data to balance the total inventory of time slot samples allowing the user to determine optimal levels of testing versus non testing time slot samples and allocations within those groups to more efficiently test content using the minimal number of time slot samples freeing more time slot samples for non testing content. Results data could inform users as they seek to continuously monitor and adjust content distribution to maximize profitability satisfaction etc. and could aid users in determining when content is worn out defined as the point in time when previously effective content ceases to be sufficiently effective due to over exposure to the consumer or employee audience.

The DSN system module is configured to distribute content across the network depicted as DSN infrastructure in and collect and process various data. The DSN system module cooperates with the experiment system to conduct cause and effect experiments and with the machine learning system to execute machine learning routines. The DSN system shown in may exclude the experiment system for those embodiments that execute machine learning routines exclusive of running experiments.

The DSN system module may comprise a top level decision tool such as that described hereinabove in the context of various embodiments e.g. see . For example the DSN system module may be configured to implement algorithms that continuously monitor the network and decide how to allocate control of each time period e.g. TSS for each display to the subcomponent systems a the experiment system and b the MLR system . As previously discussed the decision tool uses inputs from the user regarding the value of experimental insights the experiment system regarding the required sample size duration to meet the desired statistical power the incoming dependent variable data as the experiment progresses and the estimated or known value of allowing the MLR to control the TSSs in order to maximize current business goals. It is understood that the decision tool may be implemented in components of the DSN system other than the DSN system module e.g. the experiment system MLR system and may be distributed among various components.

The DSN system module communicates with a multiplicity of displays via the DSN infrastructure which may include one or both of wired and wireless networks. The DSN infrastructure shown in incorporates one or more mobile networks and one or more data networks . The mobile network s may represent any one or more known or future wireless networking technologies such as the Global System for Mobile Communications GSM Universal Mobile Telecommunications System UMTS Personal Communications Service PCS Time Division Multiple Access TDMA Code Division Multiple Access CDMA Wideband CDMA WCDMA or other mobile network transmission technologies. One or more data networks may cooperatively operate with the mobile network s or operate exclusive of mobile network s to facilitate data transfers to and from the DSN system module . For example the illustrated data network may represent the Internet which interfaces to the illustrated mobile network to provide landline connectivity with the DSN system module .

In some embodiments sets of displays are coupled to one or more player controls which communicate with the DSN system module via the DSN infrastructure . The connections between a player control and the displays and DSN infrastructure respectively may be wired wireless or a combination of wired and wireless connections. In other embodiments a player control need not be used to serve as an interface between the displays and the DSN infrastructure . Content distribution and data acquisition may be managed using a streaming technology that allows the DSN system module to coordinate and execute playlist schedules for a multiplicity of displays without the player control . Suitable transport approaches include automatic retry query ARQ TCP and UDP streaming among others.

Using the description provided herein embodiments of the invention may be implemented as a machine process or article of manufacture by using standard programming and or engineering techniques to produce programming software firmware hardware or any combination thereof.

Any resulting program s having computer readable program code may be embodied on one or more computer usable media such as resident memory devices smart cards DVDs CD or other removable memory devices or transmitting devices thereby making a computer program product or article of manufacture according to the invention. As such the terms article of manufacture and computer program product as used herein are intended to encompass a computer program that exists permanently or temporarily on any computer usable medium or in any transmitting medium which transmits such a program.

The foregoing description of the various embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. For example embodiments of the present invention may be implemented in a wide variety of applications. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

