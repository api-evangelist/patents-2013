---

title: System for fast, probabilistic skeletal tracking
abstract: A system and method are disclosed for recognizing and tracking a user's skeletal joints with a NUI system. The system includes one or more experts for proposing one or more skeletal hypotheses each representing a user pose within a given frame. Each expert is generally computationally inexpensive. The system further includes an arbiter for resolving the skeletal hypotheses from the experts into a best state estimate for a given frame. The arbiter may score the various skeletal hypotheses based on different methodologies. The one or more skeletal hypotheses resulting in the highest score may be returned as the state estimate for a given frame. It may happen that the experts and arbiter are unable to resolve a single state estimate with a high degree of confidence for a given frame. It is a further goal of the present system to capture any such uncertainty as a factor in how a state estimate is to be used.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08953844&OS=08953844&RS=08953844
owner: Microsoft Technology Licensing, LLC
number: 08953844
owner_city: Redmond
owner_country: US
publication_date: 20130506
---
This application is a continuation of U.S. patent application Ser. No. 12 876 418 filed on Sep. 7 2010 entitled SYSTEM FOR FAST PROBABILISTIC SKELETAL TRACKING to be issued as U.S. Pat. No. 8 437 506 on May 7 2013 which application is incorporated herein by reference in its entirety.

In the past computing applications such as computer games and multimedia applications used controllers remotes keyboards mice or the like to allow users to manipulate game characters or other aspects of an application. More recently computer games and multimedia applications have begun employing cameras and software gesture recognition engines to provide a natural user interface NUI . With NUI raw joint data and user gestures are detected interpreted and used to control game characters or other aspects of an application.

One of the challenges of a NUI system is distinguishing a person in the field of view of an image sensor and correctly identifying the positions of his or her body parts within the field of view. Body tracking routines are known for this purpose. However these routines are either computationally expensive requiring more processing time than is available within the frame rates of NUI systems or they are computationally inexpensive but arrive at the correct representation of the target user only a portion of the time.

Disclosed herein are systems and methods for recognizing and tracking a user s skeletal joints with a NUI system. A system to solve such a problem can be broken down into two sub problems identifying multiple candidate hypotheses for a given frame of image data and then resolving them to select one or more hypotheses as a state estimate which best represents a user position for that frame. Hypotheses are generated by one or more experts. The experts propose possible skeletal hypotheses by various methods using various sources of information including depth data body part proposals deduced from the depth data and past state estimates. Each expert is generally computationally inexpensive and effective but may not produce accurate results for a given body pose. In state estimation uncertainty is inherent in the system. However one or more of the experts will typically result in a skeletal hypothesis closely mapping the user position. The system further includes an arbiter for resolving the skeletal hypotheses from the experts into a best state estimate for a given frame. The arbiter may score the various skeletal hypotheses based on different methodologies. The one or more skeletal hypotheses resulting in the highest score or combinations thereof may be returned as the state estimate for a given frame. It may happen that the experts and arbiter are unable to resolve a single state estimate with a high degree of confidence for a given frame. It is a further goal of the present system to capture any such uncertainty as a factor in how a state estimate is to be used.

In an embodiment the present technology relates to a method of estimating state information including a receiving image data from the field of view or a scene comprised of fields of view from multiple capture devices used together b producing one or more computer models estimating state information by one or more experts and c analyzing the one or more computer models produced in said step b by one or more methodologies of an arbiter to choose one or more computer models estimated to be the best representation of the state information.

In a further embodiment the present technology relates to a software pipeline for generating a state estimate for a given frame of captured image data the state estimate representing an estimate of a position of a user within a field of view captured within the image data. The pipeline includes a preprocessing routine for receiving the image data optionally removing a background from the image data and processing a foreground into one or more body part proposals one or more experts for receiving information including the one or more body part proposals and generating a plurality of computer models each computer model representing an estimation of the position of the user in the given frame of captured image data and an arbiter for receiving the plurality of computer models scoring the computer models by one or more methodologies which compare the plurality of computer models against depth data from the given frame and or state estimate data from a prior frame and outputting at least one computer model estimated by the arbiter to best approximate the position of the user in the frame.

In a further embodiment the present technology relates to a computer readable storage medium capable of programming a processor to perform a method tracking body parts of a user captured with a capture device as a user moves within a field of view of the capture device to determine a state estimate of the user s position in a current frame of image data captured by the capture device. The method includes a receiving image data from the capture device b processing the image data received in said step a to remove a background and generate body part proposals for images in a foreground c generating a plurality of skeletal hypotheses using at least one of the body part proposals generated in said step b and image data from an earlier time the plurality of skeletal hypotheses defining a probability distribution d selecting one or more skeletal hypotheses as being the most probable state estimates based on the probability distribution where the probability distribution indicates one or more skeletal hypotheses as the probable state estimate and e indicating that no state estimate is determined for the frame of image data where the probability distribution does not indicate one or more skeletal hypotheses as being probable state estimates.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

Embodiments of the present technology will now be described with reference to which in general relate to a pipeline for generating a computer model of a target user captured by an image sensor in a NUI system. The computer model also referred to as a state estimate may be generated once per frame of captured image data and represents a best estimate of the position including pose of a user during the captured frame. The generated state estimate for each frame may be used by a gaming or other application to determine such things as user gestures and control actions. The state estimate may also be fed back into the pipeline to aid in future state estimates.

The state estimate may be generated each frame or other time period based on raw image data image data processed into body part proposals and or historical state estimates. The system includes a model fitting routine for generating a plurality of candidate models or hypotheses and a model resolution routing for selecting one or more hypotheses estimated to be the best fit to the user position.

The model fitting routine runs a plurality of computationally inexpensive tracking routines referred to as experts which receive the raw image data body part proposals and historical state data from which the experts generate one or more hypotheses. In embodiments the hypotheses are skeletal hypotheses each representing positions of a plurality of the target user s joints which together form an estimated skeleton of the user position. Depending on a variety of factors including the user pose in a given frame the experts are able to derive skeletal hypotheses including joint position data representing the true user pose with varying degrees of success. Each expert may generate one or more skeletal hypotheses as well as an indication of how good the hypotheses are believed to be represented by a probability distribution of the different hypotheses.

If the probability distribution indicates that the various skeletal hypotheses are related and close to each other this is a good indication that the skeletal hypotheses have come close to correctly modeling the true user pose for that time frame. If there are two or more clusters of hypotheses within the probability distribution then there may be uncertainty between two or more distinct solutions. Similarly if there is no coherence between the skeletal hypotheses in the probability distribution then again there may be uncertainty as to a solution.

The skeletal hypotheses and the indication of how good the skeletal hypotheses are believed to be are fed to the resolution routine referred to herein as the arbiter. The arbiter may include various scoring methodologies which evaluate the various skeletal hypotheses across the probability distribution. In general the arbiter may test how well the skeletal hypotheses match the depth data and or historical state estimates. These tests may measure whether points in a given skeletal hypothesis exist in the actual depth data. These tests may also measure how completely a skeletal hypothesis explains the available data i.e. whether there are additional points in the depth data that are not explained by a skeletal hypothesis. The arbiter may also include scoring subroutines that score skeletal hypotheses based on kinematics static configuration of joints and motion state evolution over time . These subroutines penalize unlikely configurations of joints in a skeletal hypothesis e.g. illegal joint angles or bone lengths and unlikely transitions e.g. unrealistically rapid acceleration .

Based on its scoring of the skeletal hypotheses from the experts the arbiter outputs a best estimate of the correct skeletal configuration represented by the captured image of the user in the field of view FOV . While the following description works with image capture of a field of view by a capture device it is understood that the present technology may also be applied to capturing a scene comprised of fields of view from multiple capture devices. The experts and arbiter perform these functions for each frame of captured image data or some other predefined repeating time period . In embodiments the arbiter is inclusive of the skeletal hypotheses maintaining all hypotheses as possible best outputs until it is required to output a single best hypothesis. In this way skeletal hypotheses are eliminated from the solution set after analysis by all methodologies in the arbiter. The output of the arbiter may be used by a NUI system in a variety of ways including animating an on screen avatar of the user and or determining whether a user has performed a specific known gesture. The output of the arbiter is also fed back into the pipeline as data for use in generating skeletal hypotheses for subsequent frames.

Referring initially to the hardware for implementing the present technology includes a target recognition analysis and tracking system which may be used to recognize analyze and or track a human target such as the user . Embodiments of the target recognition analysis and tracking system include a computing environment for executing a gaming or other application. The computing environment may include hardware components and or software components such that computing environment may be used to execute applications such as gaming and non gaming applications. In one embodiment computing environment may include a processor such as a standardized processor a specialized processor a microprocessor or the like that may execute instructions stored on a processor readable storage device for performing processes described herein.

The system further includes a capture device for capturing image and audio data relating to one or more users and or objects sensed by the capture device. In embodiments the capture device may be used to capture information relating to partial or full body movements gestures and speech of one or more users which information is received by the computing environment and used to render interact with and or control aspects of a gaming or other application. Examples of the computing environment and capture device are explained in greater detail below.

Embodiments of the target recognition analysis and tracking system may be connected to an audio visual A V device having a display . The device may for example be a television a monitor a high definition television HDTV or the like that may provide game or application visuals and or audio to a user. For example the computing environment may include a video adapter such as a graphics card and or an audio adapter such as a sound card that may provide audio visual signals associated with the game or other application. The A V device may receive the audio visual signals from the computing environment and may then output the game or application visuals and or audio associated with the audio visual signals to the user . According to one embodiment the audio visual device may be connected to the computing environment via for example an S Video cable a coaxial cable an HDMI cable a DVI cable a VGA cable a component video cable or the like.

In embodiments the computing environment the A V device and the capture device may cooperate to render an avatar or on screen character on display . For example shows where a user playing a soccer gaming application. The user s movements are tracked and used to animate the movements of the avatar . In embodiments the avatar mimics the movements of the user in real world space so that the user may perform movements and gestures which control the movements and actions of the avatar on the display . In the capture device is used in a NUI system where for example a user is scrolling through and controlling a user interface with a variety of menu options presented on the display . In the computing environment and the capture device may be used to recognize and analyze movements and gestures of a user s body and such movements and gestures may be interpreted as controls for the user interface.

The embodiments of are two of many different applications which may be run on computing environment and the application running on computing environment may be a variety of other gaming and non gaming applications.

Suitable examples of a system and components thereof are found in the following co pending patent applications all of which are hereby specifically incorporated by reference U.S. patent application Ser. No. 12 475 094 entitled Environment and or Target Segmentation filed May 29 2009 U.S. patent application Ser. No. 12 511 850 entitled Auto Generating a Visual Representation filed Jul. 29 2009 U.S. patent application Ser. No. 12 474 655 entitled Gesture Tool filed May 29 2009 U.S. patent application Ser. No. 12 603 437 entitled Pose Tracking Pipeline filed Oct. 21 2009 U.S. patent application Ser. No. 12 475 308 entitled Device for Identifying and Tracking Multiple Humans Over Time filed May 29 2009 U.S. patent application Ser. No. 12 575 388 entitled Human Tracking System filed Oct. 7 2009 U.S. patent application Ser. No. 12 422 661 entitled Gesture Recognizer System Architecture filed Apr. 13 2009 U.S. patent application Ser. No. 12 391 150 entitled Standard Gestures filed Feb. 23 2009 and U.S. patent application Ser. No. 12 474 655 entitled Gesture Tool filed May 29 2009.

As shown in the capture device may include an image camera component . According to an example embodiment the image camera component may be a depth camera that may capture the depth image of a scene. The depth image may include a two dimensional 2 D pixel area of the captured scene where each pixel in the 2 D pixel area may represent a depth value such as a length or distance in for example centimeters millimeters or the like of an object in the captured scene from the camera.

As shown in according to an example embodiment the image camera component may include an IR light component a three dimensional 3 D camera and an RGB camera that may be used to capture the depth image of a scene. For example in time of flight analysis the IR light component of the capture device may emit an infrared light onto the scene and may then use sensors not shown to detect the backscattered light from the surface of one or more targets and objects in the scene using for example the 3 D camera and or the RGB camera .

In some embodiments pulsed infrared light may be used such that the time between an outgoing light pulse and a corresponding incoming light pulse may be measured and used to determine a physical distance from the capture device to a particular location on the targets or objects in the scene. Additionally in other example embodiments the phase of the outgoing light wave may be compared to the phase of the incoming light wave to determine a phase shift. The phase shift may then be used to determine a physical distance from the capture device to a particular location on the targets or objects.

According to another example embodiment time of flight analysis may be used to indirectly determine a physical distance from the capture device to a particular location on the targets or objects by analyzing the intensity of the reflected beam of light over time via various techniques including for example shuttered light pulse imaging.

In another example embodiment the capture device may use a structured light to capture depth information. In such an analysis patterned light i.e. light displayed as a known pattern such as a grid pattern or a stripe pattern may be projected onto the scene via for example the IR light component . Upon striking the surface of one or more targets or objects in the scene the pattern may become deformed in response. Such a deformation of the pattern may be captured by for example the 3 D camera and or the RGB camera and may then be analyzed to determine a physical distance from the capture device to a particular location on the targets or objects.

According to another embodiment the capture device may include two or more physically separated cameras that may view a scene from different angles to obtain visual stereo data that may be resolved to generate depth information. In another example embodiment the capture device may use point cloud data and target digitization techniques to detect features of the user.

The capture device may further include a microphone . The microphone may include a transducer or sensor that may receive and convert sound into an electrical signal. According to one embodiment the microphone may be used to reduce feedback between the capture device and the computing environment in the target recognition analysis and tracking system . Additionally the microphone may be used to receive audio signals that may also be provided by the user to control applications such as game applications non game applications or the like that may be executed by the computing environment .

In an example embodiment the capture device may further include a processor that may be in operative communication with the image camera component . The processor may include a standardized processor a specialized processor a microprocessor or the like that may execute instructions that may include instructions for receiving the depth image determining whether a suitable target may be included in the depth image converting the suitable target into a skeletal representation or model of the target or any other suitable instruction.

The capture device may further include a memory component that may store the instructions that may be executed by the processor images or frames of images captured by the 3 D camera or RGB camera or any other suitable information images or the like. According to an example embodiment the memory component may include random access memory RAM read only memory ROM cache Flash memory a hard disk or any other suitable storage component. As shown in in one embodiment the memory component may be a separate component in communication with the image camera component and the processor . According to another embodiment the memory component may be integrated into the processor and or the image camera component .

As shown in the capture device may be in communication with the computing environment via a communication link . The communication link may be a wired connection including for example a USB connection a Firewire connection an Ethernet cable connection or the like and or a wireless connection such as a wireless 802.11b g a or n connection. According to one embodiment the computing environment may provide a clock to the capture device that may be used to determine when to capture for example a scene via the communication link .

Additionally the capture device may provide the depth information and images captured by for example the 3 D camera and or the RGB camera . With the aid of these devices a partial skeletal model may be developed in accordance with the present technology with the resulting data provided to the computing environment via the communication link .

The computing environment may further include a gesture recognition engine for recognizing gestures as explained below. In accordance with the present system the computing environment may further include one or more experts and an arbiter . The experts are one or more software routines for generating skeletal hypotheses. The arbiter is a software routine for analyzing the skeletal hypotheses and selecting a skeletal hypothesis estimated to be the best representation of a true skeletal configuration of the user captured by capture device . Portions of the experts and arbiter may be implemented in hardware or a combination of a hardware and software. The experts and arbiter are explained in greater detail below.

A model of a target can be variously configured without departing from the scope of this disclosure. In some examples a model may include one or more data structures that represent a target as a three dimensional model including rigid and or deformable shapes or body parts. Each body part may be characterized as a mathematical primitive examples of which include but are not limited to spheres anisotropically scaled spheres cylinders anisotropic cylinders smooth cylinders boxes beveled boxes prisms and the like.

For example body model of includes body parts bp through bp each of which represents a different portion of the modeled target. Each body part is a three dimensional shape. For example bp is a rectangular prism that represents the left hand of a modeled target and bp is an octagonal prism that represents the left upper arm of the modeled target. Body model is exemplary in that a body model may contain any number of body parts each of which may be any machine understandable representation of the corresponding part of the modeled target.

A model including two or more body parts may also include one or more joints. Each joint may allow one or more body parts to move relative to one or more other body parts. For example a model representing a human target may include a plurality of rigid and or deformable body parts wherein some body parts may represent a corresponding anatomical body part of the human target. Further each body part of the model may include one or more structural members i.e. bones or skeletal parts with joints located at the intersection of adjacent bones. It is to be understood that some bones may correspond to anatomical bones in a human target and or some bones may not have corresponding anatomical bones in the human target.

The bones and joints may collectively make up a skeletal model which may be a constituent element of the body model. In some embodiments a skeletal model may be used instead of another type of model such as model of . The skeletal model may include one or more skeletal members for each body part and a joint between adjacent skeletal members. Exemplary skeletal model and exemplary skeletal model are shown in respectively. shows a skeletal model as viewed from the front with joints j through j. shows a skeletal model as viewed from a skewed view also with joints j through j.

Skeletal model further includes roll joints j through j where each roll joint may be utilized to track axial roll angles. For example an axial roll angle may be used to define a rotational orientation of a limb relative to its parent limb and or the torso. For example if a skeletal model is illustrating an axial rotation of an arm roll joint j may be used to indicate the direction the associated wrist is pointing e.g. palm facing up . By examining an orientation of a limb relative to its parent limb and or the torso an axial roll angle may be determined. For example if examining a lower leg the orientation of the lower leg relative to the associated upper leg and hips may be examined in order to determine an axial roll angle.

A skeletal model may include more or fewer joints without departing from the spirit of this disclosure. Further embodiments of the present system explained hereinafter operate using a skeletal model having 31 joints.

As described above some models may include a skeleton and or other body parts that serve as a machine representation of a modeled target. In some embodiments a model may alternatively or additionally include a wireframe mesh which may include hierarchies of rigid polygonal meshes one or more deformable meshes or any combination of the two.

The above described body part models and skeletal models are non limiting examples of types of models that may be used as machine representations of a modeled target. Other models are also within the scope of this disclosure. For example some models may include polygonal meshes patches non uniform rational B splines subdivision surfaces or other high order surfaces. A model may also include surface textures and or other information to more accurately represent clothing hair and or other aspects of a modeled target. A model may optionally include information pertaining to a current pose one or more past poses and or model physics. It is to be understood that a variety of different models that can be posed are compatible with the herein described target recognition analysis and tracking.

As mentioned above a model serves as a representation of a target such as game player in . As the target moves in physical space information from a capture device such as depth camera in can be used to adjust a pose and or the fundamental size shape of the model in each frame so that it accurately represents the target.

The pipeline can be used to accurately and efficiently track one or more humans that are present in the FOV of a depth camera or several depth cameras . The pipeline can model and track one or more humans in real time thus providing a responsive immersive and realistic experience for a human being tracked. Furthermore the pipeline is believed to be efficient so as to limit the computing resources used to execute the pipeline.

Pipeline includes six conceptual phases depth image acquisition background removal foreground pixel assignment model fitting using the one or more experts model resolution using the arbiter and reporting an output . Depth image acquisition background removal and foreground pixel assignment may all be considered as part of the preprocessing of the image data also referred to herein as rasterization.

Depth image acquisition may include receiving an observed depth image of a target within a FOV from depth camera of capture device . The observed depth image may include a plurality of observed pixels where each observed pixel has an observed depth value. The observed depth value includes depth information of the target as viewed from the source. The depth image may optionally be represented as a pixel matrix that includes for each pixel address a depth value indicating a world space depth from the plane of the depth camera or another suitable reference plane to a surface at that pixel address.

As shown at of depth image acquisition may optionally include downsampling the observed depth image to a lower processing resolution. Downsampling to a lower processing resolution may allow the observed depth image to be more easily utilized and or more quickly processed with less computing overhead. One example of downsampling is to group the pixels into patches in a technique occasionally referred to as oversegmentation. Patches may be chosen to have approximately constant depth and roughly equal world space area. This means that patches further from the camera appear smaller in the image. All subsequent reasoning about the depth image may be expressed in terms of patches rather than pixels. As indicated the downsampling step of grouping pixels into patches may be skipped so that the pipeline works with depth data from individual pixels.

As shown at of depth image acquisition may optionally include removing and or smoothing one or more high variance and or noisy depth values from the observed depth image. Such high variance and or noisy depth values in the observed depth image may result from a number of different sources such as random and or systematic errors occurring during the image capturing process defects and or aberrations resulting from the capture device etc. Since such high variance and or noisy depth values may be artifacts of the image capturing process including these values in any future analysis of the image may skew results and or slow calculations. Thus removal of such values may provide better data integrity and or speed for future calculations.

Background removal may include distinguishing human targets that are to be tracked from non target background elements in the observed depth image. As used herein the term background is used to describe anything in the scene that is not part of the target s to be tracked. The background may for example include the floor chair and plant in but may in general include elements that are in front of i.e. closer to the depth camera or behind the target s to be tracked. Distinguishing foreground elements that are to be tracked from background elements that may be ignored can increase tracking efficiency and or simplify downstream processing.

Background removal may include assigning each data point e.g. pixel of the processed depth image a value which may be referred to as a player index that identifies that data point as belonging to a particular target or to a non target background element. When such an approach is used pixels or other data points assigned a background index can be removed from consideration in one or more subsequent phases of pipeline . As an example pixels corresponding to a first player can be assigned a player index equal to one pixels corresponding to a second player can be assigned a player index equal to two and pixels that do not correspond to a target player can be assigned a player index equal to zero. Such player indices can be saved in any suitable manner. In some embodiments a pixel matrix may include at each pixel address a player index indicating if a surface at that pixel address belongs to a background element a first player a second player etc. The player index may be a discrete index or a fuzzy index indicating a probability that a pixel belongs to a particular target and or the background.

A pixel may be classified as belonging to a target or background by a variety of methods. Some background removal techniques may use information from one or more previous frames to assist and improve the quality of background removal. For example a depth history image can be derived from two or more frames of depth information where the depth value for each pixel is set to the deepest depth value that pixel experiences during the sample frames. A depth history image may be used to identify moving objects in the foreground of a scene e.g. a human game player from the nonmoving background elements. In a given frame the moving foreground pixels are likely to have depth values that are different than the corresponding depth values at the same pixel addresses in the depth history image. In a given frame the nonmoving background pixels are likely to have depth values that match the corresponding depth values in the depth history image.

As one non limiting example a connected island background removal may be used. Such a technique is described for example in U.S. patent application Ser. No. 12 575 363 filed Oct. 7 2009 the entirety of which is hereby incorporated herein by reference. Additional or alternative background removal techniques can be used to assign each data point a player index or a background index or otherwise distinguish foreground targets from background elements. In some embodiments particular portions of a background may be identified. For example at of a floor in a scene may be identified as part of the background. In addition to being removed from consideration when processing foreground targets a found floor can be used as a reference surface that can be used to accurately position virtual objects in game space stop a flood fill that is part of generating a connected island and or reject an island if its center is too close to the floor plane. A technique for detecting a floor in a FOV is described for example in U.S. patent application Ser. No. 12 563 456 filed Sep. 21 2009 the entirety of which is hereby incorporated herein by reference. Other floor finding techniques may be used.

Additional or alternative background removal techniques can be used to assign each data point a player index or a background index or otherwise distinguish foreground targets from background elements. For example in pipeline includes bad body rejection . In some embodiments objects that are initially identified as foreground objects can be rejected because they do not resemble any known target. For example an object that is initially identified as a foreground object can be tested for basic criteria that are to be present in any objects to be tracked e.g. head and or torso identifiable bone lengths within predetermined tolerances etc. . If an object that is initially identified as being a candidate foreground object fails such testing it may be reclassified as a background element and or subjected to further testing. In this way moving objects that are not to be tracked such as a chair pushed into the scene can be classified as background elements because such elements do not resemble a human target. Where for example the pipeline is tracking a target user and a second user enters the FOV the pipeline may take several frames to confirm that the new user is in fact human. At that point the new user may either be tracked instead of or in addition to the target user.

After foreground pixels are distinguished from background pixels pipeline further classifies the pixels that are considered to correspond to the foreground objects that are to be tracked. In particular at foreground pixel assignment of each foreground pixel is analyzed to determine what part of a target user s body that foreground pixel is likely to belong. In embodiments the background removal step may be omitted and foreground object determined other ways for example by movement relative to past frames.

A variety of different foreground pixel assignment techniques can be used to assess which part of a player target s body or a machine representation of the body a particular pixel is likely to belong. In one of several possible embodiments the body part proposal system runs Exemplar which is a known technique for receiving a two dimensional depth texture image and generating body part proposals as probabilities as to the proper identification of specific body parts within the image. In particular each foreground pixel may be assigned a body part index and or body part probability distribution. Exemplar analyzes a foreground object using information learned from a prior trained collection of known poses. This approach can be used to assign each foreground pixel a body part index or distribution without any prior state information i.e. knowledge of the prior frame is not needed . A variety of other stateless machine learning techniques may be employed for assigning pixels to different body parts with a given confidence.

Returning to once depth image acquisition background removal and foreground pixel assignment have been completed the pipeline performs model fitting to identify skeletal hypotheses that serve as machine representations of a player target and model resolution to select from among these skeletal hypotheses the one or more hypotheses that are estimated to be the best machine representation of the player target . The model fitting step is performed by the one or more experts and the model resolution step is performed by the arbiter . Further details of the one or more experts and the arbiter are now explained in greater detail with reference to the diagram of .

In general the present system sets forth methods for tracking i.e. estimating over time the configuration of an articulated skeletal model by inferring at time t a state estimate vector xwhich contains the three dimensional position of every tracked point. In embodiments the present system may track the location of 31 three dimensional points corresponding to locations on the human body though it is understood that the present system may track greater or fewer points than that in further embodiments. Each point has three degrees of freedom in Cartesian space. Thus in an embodiment tracking 31 points the skeleton is fully specified by 93 values which may be represented at time step t as state estimate vector x.

In embodiments the state estimate vector xmay be derived from different sources including the depth data denoted z. . . z obtained as described above at every discrete time step. The state estimate vector xmay also come from historical knowledge of dynamic state data denoted D. Specifically D contains state estimate vector information about position and motion from prior frames including for example likely configurations of joints and likely trajectories of joint locations over time.

The output of any tracker is only an estimate sometimes more accurate sometimes less but always with a degree of uncertainty. In light of this a proposed state may be considered according to a belief of how good it is represented by a probability distribution skelton now all depth data and dynamics 

The function x referred to herein as the belief function assigns a probability score to a proposed state indicating how good it is i.e. how closely it is believed to match the true state estimate vector x. The belief function x captures not only information about the likely state at a given time but also about uncertainty. It may not be practical to consider the complete distribution x for all possible values of x. Instead state estimation is approximated by a set of sampled skeletal hypotheses X x. . . x where each hypothesis represents a machine representation of a skeleton that is plausible given the data. The accuracy of this approximation will improve as the number n of skeletal hypotheses increases. However as n increases so does the computational cost increase.

Thus where a conventional tracking system may employ thousands of samples or more the present system operates by selecting a small number of skeletal hypotheses for example between 10 and 100 skeletal samples for X. There may be more or less samples in further embodiments. Given that embodiments of the system track a space which is 93 dimensional this is a small number of samples. However instead of selecting random samples the system may employ experts explained below which make use of information including depth data z. . . z and historical skeletal motion data D to improve the intelligence of the search for a set of proposed skeletal hypotheses.

In step the present system proposes m skeletal hypotheses generated by experts using some or all the available information. As indicated these experts are selected based on their ability to provide good state estimates at least some of the time. Next in step for each skeletal hypothesis the arbiter computes a score using the belief function x .

In step the set of n sampled skeletal hypotheses Xis filled from the m proposals of step . The probability that a given skeletal hypothesis may be selected into the sampled set Xis proportional to the score assigned by the arbiter in step . Thus once steps have been executed expert proposals that were assigned a high probability by the arbiter are more likely to appear in the output set Xthan proposals that were assigned a low probability. In this way Xwill gravitate towards a good state estimate. One or more sample skeletal hypotheses from the sampled set X or a combination thereof may then be chosen in step as output for that frame of captured data or other time period.

If the distribution in the sampled set Xdoes not indicate one or more estimates believed to closely match the state estimate vector X this information may be returned instead of or in addition to one or more sample skeletal hypotheses from the set X. In particular in embodiments when the data given by the belief function x are unambiguous the members of Xare similar to each other this is a strong indicator that one or more of the sampled skeletal hypotheses are good indicators of the true state estimate vector x. However there may also be situations in which there are numerous possibilities for at least part of the skeleton. For example there may be two or more clusters within X in which case it can be concluded that there is uncertainty between several distinct solutions. It may also happen that there is no coherence amongst the members of X. This is an indication that there is little certainty of the state and the system can act accordingly knowing that the system was unable to produce any single estimate with confidence.

Referring now to preprocessing layer receives depth data optionally removes a background of the FOV and pixels are assigned to candidate body parts using for example Exemplar. Each of these processes has been described above with respect to . The data from preprocessing layer may be provided to the one or more experts . The experts may also receive historical state estimates and or motion prediction based on historical state estimates. In particular in one embodiment the previous frame output of the arbiter in identifying a best estimate of a machine representation of a skeletal configuration of a user is fed back to preprocessing layer and used by one or more of the experts in generating skeletal hypotheses for the current frame. In further embodiments the output of two or more previous frames may be fed back to the preprocessing layer . In such embodiments the experts may also interpolate or predict motion of one or more body parts of a user based on a pattern of movement of the one or more body parts.

As noted above the one or more experts receive data from the preprocessing layer and from that data the one or more experts generate a plurality of skeletal hypotheses that serve as machine representations of the player target. As noted above the experts may generate a relatively small number of skeletal hypotheses. However using the preprocessed data to arrive at estimates the experts are able to provide one or more skeletal hypotheses generally providing a good approximation of user position. Some experts may be better at approximating a first position of a user while other experts may be better at approximating a second different position of the user. In addition to providing the skeletal hypotheses themselves the group of skeletal hypotheses Xresult in a probability distribution indicating a degree of confidence that one or more of the skeletal hypotheses represent the true position of body parts of the user.

The following describes some sample experts which may be used in embodiments of the present system. In further embodiments some of the following described sample experts may be omitted and or other experts may be used instead of or in addition to the sample experts described below. While embodiments may use a plurality of experts it is contemplated that a single expert be used in further embodiments. Furthermore experts may be used in combination with each other. That is the experts may be used in different layers with the output from one or more experts used as the input for one or more further experts. In such embodiments a given expert may be used in both a first layer providing skeletal hypotheses or other data to a second layer or in a second layer receiving skeletal hypotheses or other data from a first layer.

A first sample expert is referred to as centroid based joint fusion skeleton generator expert . As indicated in the flowchart of this expert generates skeletal hypotheses by first looking at body part proposals from the preprocessed data step and then combining the body part proposals into complete skeletons step . In step Exemplar s pixel wise probability distributions are converted into centroid proposals for full 93 dimensional skeletons. Exemplar which uses only local information in labeling a pixel may be an unreliable source of global information about a single body part. For example Exemplar may have difficulty distinguishing between the left and right hands. Centroid generation is a known technique for receiving Exemplar data of a two dimensional depth texture image and generating numerous joint positions with attached probabilities from this data. For each body part these joint positions identify multiple candidate locations for the specific body part within the image.

In embodiments centroids are generated for each of the 31 points tracked though again there may be more or less than 31 tracked points in further embodiments. The various skeletal points may correspond to actual joints of a human target terminal ends of a human target s extremities and or points without a direct anatomical link to the human target. Exemplar and centroid generation are just one example for identifying body parts in an image and it is understood that any of a wide variety of other stateless i.e. not based on past state estimates methods may be used for producing body part location proposals. One or more centroid candidates may be calculated for each body part. That is for each body part b 1 31 the process generates m 0 candidate locations for that part u . . . u.

It may happen that a good candidate joint was not proposed as input either due to occlusion failure in another subsystem or some other problem. To handle this situation the set of candidates for each joint is augmented with the null candidate u corresponding to an unknown response. In the centroid based joint fusion skeleton generator expert a null candidate is assigned a small but non zero unary potential function value explained below . This means there is a penalty for assigning a joint to null but this may be selected if it releases the other joints in the model to form a better configuration.

Step of the centroid based joint fusion skeleton generator expert involves forming a complete skeleton from the centroid data by selecting one candidate for each body part. To search over all possible combinations of candidates for good skeletons is prohibitively expensive. However the centroid based joint fusion skeleton generator expert may use a function in which the joints of the skeleton are arranged as a tree structure with the torso being the main trunk and the joints of the head arms and legs extending therefrom in a loopless fashion. In this way it is possible to find one or more optimal skeletons or a likely sample with fast polynomial time dynamic programming. One example of dynamic programming uses the Viterbi algorithm described for example in AJ Viterbi Error Bounds For Convolutional Codes And An Asymptotically Optimum Decoding Algorithm 13 2 260 269 April 1967 which paper is incorporated by reference herein in its entirety. In general given the constraint that candidates for good skeletons may be arranged as a loopless tree structure the Viterbi algorithm describes a solution for finding an optimal lowest cost connection of neighbor candidate centroids.

In particular for each combination of 31 candidates a probability may be assigned according to the following model 

The unary potential u is a weight for each candidate location for a part derived from the Exemplar data used to generate it. N is the set of all pairs of body parts that are neighbors e.g. the hand is connected to the wrist the shoulder is connected to the chest and the upper arm etc. Each pair of neighbors has a binary potential u u weighting their relative position. This may be based on the distance between the points and how closely the distance matches an expected bone length. By choosing the members of the set N such that the connectivity of connected body parts graph has no loops it is possible to efficiently obtain either the configuration that has the maximum probability or to generate a sample from the probability distribution.

It is understood that algorithms other than the Viterbi algorithm may be used in the centroid based joint fusion skeleton generator expert . In one further example a probability based belief propagation model may be used where random samples are taken from the probability distribution given by x . Where the Viterbi algorithm provides an optimal solution the probability based belief propagation model will find solutions at and near the optimal solution.

The above described expert made use of stateless Exemplar data. Further embodiments of experts may make use of stateful data such as historical state estimate data. One such expert is the prior state expert . As explained above a goal of the present system is to arrive at a given state estimate vector x for example each frame or other time period. Thus at a given time t the state estimate vector from one or more prior frames x x etc. may be available. From a random or complete sampling of the points identified at prior times it is possible to infer skeletal hypotheses for the current time frame.

As shown in the flowchart of one or more points from a prior time may be examined in step . It may happen that a joint tracked at a prior time is located at the same location x y and depth z as a current point as indicated by either the current depth map or new centroid. From this the prior state expert may infer that the points are the same and in step the identity of the joint at that location from the past is assigned to the point at that location in the present.

Moreover as shown in the flowchart of it may happen that the position of a point at the current time period may be interpolated given the motion of a joint tracked over two or more prior time periods steps and . If a point is found in the current time at that interpolated position in step indicated by either the current depth map or new centroid the prior state expert may infer the point at the interpolated position is the same joint identified in the prior time periods. Using the processes of the prior state expert may be able to determine one or more skeletal hypotheses.

Examples of two skeletal hypotheses determined by the prior state expert are shown in . The hypotheses of are generated from the same user modeled in the hypotheses in respectively. Based on motion alone it has not used any information from the Exemplar or depth image one can see how it correctly predicts the location of some body parts but incorrectly predicts others. Again multiple such skeletal hypotheses are generated and other samples from the model will connect the points differently in the prior frame. The skeletal hypotheses of are by way of example only and any of a wide variety of other skeletal hypotheses may be generated by the prior state expert for different user positions.

A slight variation on prior state expert is magnetism expert . It may happen that an identified point at time t is near to a point with the same identification found at t 1. In this case the magnetism expert may snap the point identified at the prior time to the current position. Magnetism involves the concept of snapping the location of a skeletal feature such as a hand from a previous frame or frames onto a new depth map. For example if a left hand was identified for a user in a previous frame and that hand is isolated not touching anything magnetism can accurately update that hand s location in the current frame using the new depth map. Additionally where a hand is moving tracking the movement of that hand over two or more previous frames may provide a good estimation of its position in the new frame.

This predicted position can be used outright as a hand proposal as provided by the prior state expert . Additionally or alternatively this predicted position can be snapped onto the current depth map using the magnetism expert to produce another hand proposal that better matches the current frame. This snapping of a prior joint location to an updated location may be performed on a plurality of joints and the magnetism expert and prior state expert may generate a plurality of skeletal hypotheses either singly or working in combination with each other. The snapping to an updated location may also be based on a point just beyond an extremity such as a hand. This feature is explained in U.S. patent application Ser. No. 12 825 657 entitled Skeletal Joint Recognition And Tracking System filed Jun. 29 2010 which application is incorporated by reference herein in its entirety.

A corollary to the magnetism expert is the drag or relax expert . Where a previous frame used magnetism to snap a joint to a new location there may be another joint or joints attached upstream of the snapped joint for which there may not be fresh data. In such an event the attached upstream joint or joints without good data may be dragged along with the snapped joint to a new position. This new position will vary depending on where the snapped joint moved to and the position of a joint upstream of the joint to be dragged. The drag expert may also be used with other experts. In particular where another expert repositioned a joint relative to a prior frame and there is an upstream joint without good data attached to the repositioned joint the drag expert may be used to reposition the upstream joint. Apart from dragging upstream joints the drag expert may provide one or more skeletal hypotheses for example in the same manner as the centroid based joint fusion skeleton generator expert or prior state expert described above. It is understood that other methods may be provided to determine updated data for joints that are upstream of a repositioned joint.

As noted above it may happen that a given joint was not identified either due to occlusion failure in another subsystem or some other problem. The centroid based joint fusion skeletal generator handled this situation with a null candidate. Volumetric model based tracking expert is a further example of an expert where missing joints and other body parts may be grown. That is where there is no good Exemplar and or historical data for an intermediate joint or an extremity the neighboring joints and depth data may be examined to interpolate the data for the missing body part to in effect grow the body part.

A system for generating one or more skeletons including growing body parts that can be used in the volumetric model based tracking expert is disclosed in U.S. patent application Ser. No. 12 363 604 entitled Visual Target Tracking filed on 30 Jan. 2009 which application is incorporated by reference herein in its entirety. However in general in one embodiment missing joint data may be grown using the body part player index stored for each pixel described above with respect to . The growth expert may begin by searching for pixels having neighboring pixels with a different body part player index. These may be considered edge pixels i.e. frontiers along which values may optionally be propagated. Growing the pixel values may include growing into either unknown or known pixels. For unknown pixels the body part player index value for example may have been zero before but may now have a non zero neighboring pixel. In such a case the four direct neighboring pixels may be examined and the neighboring pixel having an observed depth value more closely resembling that of the pixel of interest may be selected and assigned to the pixel of interest.

In the case of known pixels it may be possible that a pixel with a known nonzero body part player index value may be overtaken if one of its neighboring pixels has a depth value written during rasterization that more closely matches the observed depth value of the pixel of interest than that of the synthesized depth value for that pixel.

Additionally for efficiency updating a body part player index value of a synthesized pixel may include adding its neighboring four pixels to a queue of pixels to be revisited on a subsequent pass. As such values may continue to be propagated along the frontiers without doing an entire pass over all the pixels. As another optimization different N N blocks of pixels e.g. 16 16 blocks of pixels occupied by a target of interest can be tracked so that other blocks that are not occupied by a target of interest can be ignored. Such an optimization may be applied at any point during the target analysis after rasterization in various forms. The concept of grouping together pixels into an N N block of pixels may also be used in the other experts described herein.

The volumetric model based tracking expert as well as the other tracking features described in U.S. patent application Ser. No. 12 363 604 incorporated above can be used as another expert in this system producing whole skeletons. Alternatively or additionally the volumetric model based tracking expert as well as the other tracking features described in U.S. patent application Ser. No. 12 363 604 incorporated above can also be used to shore up the output of other experts. The pixel body part growing technology features described in U.S. patent application Ser. No. 12 363 604 incorporated above may also be used to find new body parts that would be useful to other experts.

The above is one example of how joint data for missing joints may be grown. Apart from growing data for missing joints the body part growth expert may provide one or more skeletal hypotheses for example in the same manner as the centroid based joint fusion skeleton generator expert described above. It is understood that other methods may be provided to grow interpolate fix or otherwise provide data for missing joints.

A further expert is referred to herein as the scored centroid expert . Details of the scored centroid expert are set forth in the above referenced U.S. patent application Ser. No. 12 603 437 entitled Pose Tracking Pipeline. However in general the scored centroid expert operates by generating scored centroids for body parts. The scores applied to centroids may be adjusted based on one or more constraints including prior state data and the depth map. It may happen using scored centroid expert or other centroid based experts that one or more of the new centroids may belong to body parts of a second user within the FOV. This may result in a skeletal hypothesis for a target user that includes body parts from other users. Again multiple such skeletal hypotheses are generated using the various experts and other samples from the model will connect the points differently.

The centroid based joint fusion skeleton generator expert makes use of a generalized tree structure of a human body in generating skeletal hypotheses. Further experts may make use of other known human body configurations in generating further skeletal hypotheses. One such expert is referred to herein as head triangle expert . An example of a system which generates skeletal hypotheses using head triangles is described in U.S. patent application Ser. No. 12 825 657 previously incorporated by reference. In general head triangle expert forms candidate head triangles from one head centroid connected to two shoulder centroids from the group of head and shoulder centroids identified by Exemplar from the image data. In general Exemplar provides strong head and shoulder signals for users and this signal becomes stronger when patterns of one head and two shoulder centroids may be found together. Head and or shoulder centroids may come from any number of sources other than Exemplar centroids including for example head magnetism and simple pattern matching.

In some instances one joint may be occluded. For example the left shoulder may be occluded but the head and right shoulder are visible although again it is not yet known that it is the left shoulder which is occluded . The head and right shoulder may also have moved for example to the right by an average of 3 mm relative to a previous frame. In this case an extra candidate triangle would be constructed with the left shoulder also moving to the right by 3 mm rather than dragging where it was or mistakenly jumping to a new place so that the triangle shape is preserved especially over time even though one of the joints is not visible for some time.

Once a head triangle for a target is constructed skeletal hypotheses may then be generated for the rest of the body. In embodiments skeletal hypotheses may be generated for less than the entire body. For example a target user s upper body may be modeled a target user s lower body may be modeled a target user s left side may be modeled and or a target user s right side may be modeled.

Where entire body skeletal hypotheses are generated the head triangle expert may use the one or more identified head triangles and additional centroid and or magnetism data to construct the remainder of each skeletal hypothesis. For example the head triangle expert may next identify left and right hands from the centroid data and a number of possible elbow positions that fit each shoulder hand pair. The head triangle expert may also select torso centroids hip centroids and feet centroids. The system may then select a number of possible knee positions that fit each hip foot pair. In this way the head triangle expert may generate a number of skeletal hypotheses that may be evaluated by the arbiter as explained below.

Another expert making use of the generally known structure of a human body is light weight tracking expert . Further details of a skeletal model generator which may be used as light weight tracking expert are disclosed in U.S. application Ser. No. 12 575 388 entitled Light Weight Human Tracker filed Oct. 7 2009 which application is incorporated herein by reference in its entirety. However in general the light weight tracking expert may operate effectively for front facing targets by identifying a reference position within the torso of a model and then constructing a box around the torso referred to as a torso volume. The torso volume may in general be constructed by searching the depth data right left up down and diagonally from the reference position until a pixel is identified at a different depth than the torso. The torso volume around the torso may be identified by other methods.

The light weight tracking expert may then identify the positions of the head arms and legs for one or more skeletal hypotheses. This may be accomplished by a variety of methods used alone or in combination with each other. In one example centroids for the head arms and legs having appropriate relation to the torso volume may be used to form skeletal hypotheses. In a further example prior state data identifying the positions of the head arms and legs from a prior frame may be used. The prior state data may be the position of the head and or limbs in a depth image received in a previous frame a projected body part location or position based on a previous movement. The prior state data may further be any other suitable previous location or position of a representation of a human target such as a fully articulated skeleton or volumetric model of the human target. For example the light weight tracking expert may compare the position or location including the X value Y value and depth value of points outside of the torso volume with the previous positions including the X values Y values and depth values of the previously identified head and or limbs such as the previously identified left arm right arm left leg right leg or the like. The light weight tracking expert may then associate each of the points outside the torso volume with the previously identified limb that may have the closest position based on the comparison.

The above description of experts through is by way of example only. It is understood that embodiments of the present system may operate without one or more of the experts through . Moreover it is understood that a variety of other computationally inexpensive tracking algorithms may be used as experts in addition to or instead of experts through to form one or more skeletal hypotheses in further embodiments.

Moreover one or more of the experts through may be combined with each other or other experts in various combinations. In one such example any of the centroid based experts described above or other stateless techniques may be combined with any of the magnetism based or motion based experts described above or other stateful techniques to provide an expert which forms one or more skeletal hypotheses based on both stateless and stateful techniques. An example of a system which generates skeletal hypotheses in such a way is described in U.S. application Ser. No. 12 825 657 incorporated above. Other stateless and stateful experts may be used in combination with each other in further embodiments.

In embodiments one or more neural networks may also be used as experts. While a variety of such neural networks are contemplated an example may include one or more multilayer perceptrons . A multilayer perceptron is an example of a known neural network and it may be used as a standalone expert or it may be used in conjunction with one or more of the above described experts to derive further or alternative experts.

In general the multilayer perceptron is computationally inexpensive to run and a number of them can be run within the available timeframe. Multilayer perceptrons in general have a relatively small input set such as for example centroids previous state data and or the output of other experts from the same frame in which case the neural network expert would be considered a downstream expert . These inputs are processed through matrix multiplication using a relatively small number of layers to arrive at one or more output skeletal hypotheses. While possibly burdensome to train once trained the one or more multilayer perceptrons are inexpensive to run. A benefit of this is that a number of multilayer perceptrons can be used each trained to excel at a specific task for example detecting specific joint positions and body poses.

One example of a multilayer perceptron which may be implemented to generate skeletal hypotheses is a kinematic projection neural network. In particular as noted above the present system may track body parts or some other number n each theoretically having 3 degrees of freedom. However in reality given constraints on how body parts may move relative to each other there would in fact be fewer than 3n degrees of freedom. A kinematic neural network takes the n body parts that are tracked and using the trained kinematic constraints on the degrees of freedom and how a body can move it maps the n body parts into one or more skeletal hypotheses which fit the constraints of the kinematic neural network. As described above several different kinematic projection neural networks may be provided each specialized to detect a specific pose or poses of the user.

In embodiments a multilayer perceptron may be used by itself or it may be combined with one or more filter banks to form a so called deep neural network or convolutional neural network. As is known the filter bank may include weighted kernels for receiving large input sets of data for example each pixel in an image depth map. The weighted kernels of the filter bank process the input data into a condensed and rich format which may then be passed as input to the multilayer perceptron . The filter banks may be trained together with the multilayer perceptron for example by back propagation in a known manner to generate one or more skeletal hypotheses either by themselves or in combination with one or more other experts .

There may be a separate multilayer perceptron by itself or receiving output from a filter bank for any of a variety of poses. Thus for example one multilayer perceptron may be specifically directed to recognizing a body pose where the user is in profile i.e. the user is turned 90 from the capture device . This particular neural network may not generate accurate skeletal hypotheses for user poses where the user is facing the capture device but will generate skeletal hypotheses with a high degree of confidence when a user is in profile. Other multilayer perceptrons may be provided which accurately identify a user pose where the user is facing the capture device .

As indicated above the multilayer perceptron by itself with the filter bank may be combined with one or more of the above described experts or other neural networks . In further embodiments it is contemplated that any of the above described experts may be combined with any other above described expert so that the output of one expert an upstream expert may be fed as input to another expert a downstream expert . A given expert may be both an upstream expert in one embodiment and a downstream expert in another embodiment. Moreover the present system may further comprise the concept of a mixer expert which lives downstream of the other experts and consumes all of their output mixing and matching from various skeletal hypotheses. The output of the mixer expert may be skeletal hypotheses having head torso and limbs possibly resulting from different experts. For example a skeletal hypothesis from the mixer expert may have a left arm from centroid based joint fusion skeleton generator and a right leg from magnetism expert . In embodiments the mixer expert may work through different experts one limb at a time or it may work through different experts for complete skeletal hypotheses and then mix and match different limbs making a best guess as to which expert has the best guess as to each limb or other division of body parts.

In general the experts including for example the various experts described above generate one or more skeletal hypotheses in a computationally inexpensive manner. These skeletal hypotheses are then evaluated by the arbiter to identify the one or more skeletal hypotheses believed to best represent the user position for a given frame or other time period. As noted the skeletal hypotheses may be distributed in such a manner that the arbiter is unable to pick out one or more best skeletal hypotheses. This information is also passed on to the pipeline . The arbiter is explained below in greater detail.

In general the arbiter evaluates the one or more skeletal hypotheses using different methodologies. The first two methodologies test how well a skeletal hypothesis matches the depth data firstly by measuring whether points in the proposal exist in the data depth score and secondly by testing how completely the skeletal hypothesis explains the available data explained space . The arbiter also includes methodologies that score skeletal hypotheses based on kinematics static joint configuration score and motion motion score . Each of these methodologies is explained below. In embodiments the arbiter may further use data from a game or other application running on the computing environment as to what action user pose is expected. These methodologies are by way of example only and arbiter may evaluate skeletal hypotheses to arrive at a best guess of the state estimate by other methodologies in further embodiments.

Using the depth score the arbiter evaluates whether the position of each joint described by a skeletal hypothesis is supported by the measured depth data. A disparity between a skeletal hypothesis joint and the measured depth data does not remove that skeletal hypothesis from consideration. Rather it negatively impacts a score associated with the tested skeletal hypothesis. The comparison of all joints against the depth data will result in a cumulative score for the depth score

Referring to the flowchart of the depth score may be characterized by two tests referred to as the trace and saliency steps and . Trace step involves taking trace samples along lines known to be within the body for a large variety of users and which evenly occupy the interior space. In embodiments the samples may fill in a minimum silhouette of a person.

For trace samples good Z matches where the depth value and the measured joint of the skeletal hypothesis are similar result in rewards and bad Z matches result in penalties. The closeness of the match severity of the mismatch can affect the amount of penalty reward and positive vs. negative mismatches may be scored differently. For matches a close match will score higher than a weak match. Drastic mismatches are treated differently based on the sign of the difference if the depth map sample is further than expected this is a salient sample and incurs a harsh penalty. If the depth map sample is closer than expected this is an occlusion sample and incurs a mild penalty. In some embodiments the expected Z values are simply interpolated between the depths of the candidate body part locations. In other embodiments the expected Z values are adjusted to compensate for common non linear body shapes such as the protrusion of the chin and face relative to the neck and shoulders. In other embodiments which begin with other parts of the skeleton similar interpolation and adjustment of the expected Z values can be made.

The saliency test in step operates by defining a number of saliency samples in . The FOV may be referenced by a Cartesian coordinate system where the Z axis is straight out from the depth camera and the X Y plane is perpendicular to the Z axis. The saliency samples may be defined in circles semicircles or partial circles in the X Y plane at the joints of the arms and other joints in a given skeletal hypotheses. The saliency samples can also lie in rails as visible around the upper arm in . The rails are parallel lines on each side of a limb segment connecting adjacent joints when these limb segments are not Z aligned the saliency samples around the lower arm are omitted in for clarity . All of these samples both on circles and rails are set out at some distance in the X Y plane away from the actual joints or lines connecting the joints. The radius of a given sample must be large enough so that if the hypothesis is correct the samples will all lie just outside of the silhouette of the player s arm even for a very bulky player. However the radius should be no larger in order to achieve optimum results.

Once the sample locations are laid out in X Y the actual and hypothetical depth values can be compared at each sample location. Then if any of the saliency samples indicate a depth that is similar to the depth of the hypothesis those samples are penalized. For example in saliency samples A shown as filled squares in the figure would be penalized around the upper arm and hand. If the depth map value is further than the hypothetical this is a salient sample and incurs a reward. And if the depth map value is closer than expected this is an occlusion sample and incurs a mild penalty. As noted the trace and saliency scores for all samples may be tallied step to arrive at a score for the depth score methodology . It is understood that tests other than the trace and saliency tests described above may be used to evaluate and score a given skeletal hypothesis against the depth data.

The depth score looks to how well a skeletal hypothesis was explained in the depth data. However the depth data may define other foreground objects which are not explained by a given skeletal hypothesis. It may be that a given skeletal hypothesis has incorrectly identified a body part and that these other foreground objects are in fact part of the target user s body. Therefore using the explained space methodology the arbiter examines whether a skeletal hypothesis has explained all of the foreground depth data. Referring to the flowchart of the explained space methodology checks in step whether there are foreground objects which are not explained by the skeletal hypothesis then under consideration. If not there is no penalty for the explained space score in step . However if there is an unexplained object in the foreground in step the explained space methodology may penalize the explained space score. The penalty may be based on a proximity of the unexplained object to a joint in the skeletal hypothesis. The closer the object to the skeletal hypothesis the greater the penalty. The penalty may additionally or alternatively be based on a likelihood that the unexplained object could be the same type of body part as the proximate joint in the skeletal hypothesis. If Exemplar indicates that the unexplained object could also be the same body part as a proximate joint in the skeletal hypothesis the explained space score is penalized higher than if it is unlikely that the unexplained and proximate skeletal joint could be the same body part.

The depth score and explained space methodologies can both be expensive if implemented naively pixel wise due to the large number of random accesses required. To circumvent this expense an alternative embodiment of the present system processes the depth map from pixels into patches a technique sometimes referred to as oversegmentation. Patches are chosen to have approximately constant depth and equal world space area. This means that patches further from the capture device appear smaller in the image. In this embodiment all subsequent reasoning about the depth image will be expressed in terms of patches. For a modest loss of fidelity the memory bandwidth requirements are reduced dramatically from millions of pixel accesses to hundreds or thousands of patch accesses.

Once patches have been formed in this embodiment the depth score and explained space methodologies may be performed by first assigning ownership of each patch to particular joints in a skeletal hypothesis. This assignment involves reasoning about occlusion. A wireframe skeleton may from time to time have joints and bones between them that are occluded by other parts of the model. It is important that patches are assigned appropriately so that whether a particular point in the model is either in error or just invisible can be judged. If it is invisible it incurs less cost than when in error. However some other part of the model should account for that region of space hence the importance of this occlusion reasoning.

Ownership is determined by first assigning patches that intersect bones between joints to their closest joint. Following this the patches are grown from these seed points assigning each patch to the seed patch to which it is most likely connected. At each step including the initial bone patch intersection pass a cost is assigned to each patch along with the joint that owns the patch. The initial cost is based on the depth discrepancy between the depth of the patch and the depth of the bone. Then as the known patches patches that have been assigned to a joint grow out over the unknown patches in some embodiments only across connected patches both the owner joint and the cost propagate and are assigned to the new patches. In addition sometimes the cost is increased by a small amount when a patch grows onto another patch. When there are two known patches that could grow onto an unknown patch the known patch with the lower cost will generally win. Known patches also have the opportunity to grow over other already assigned known patches if their cost is significantly lower and if the joints do not neighbor each other in the skeletal topology. In this way errors in the initial intersection are generally corrected. A part of this process is that one joint may steal a patch away from another if it leads to smoother connectivity and it is this process which approximately accounts for occlusion. The depth score cost is computed from the discrepancy between patches which intersect bones and the depth predicted by the model at these points i.e. the initial costs and might also be adjusted to reflect incorrect initial bone patch intersections where the patch ownership changed between the initial intersection and the final state . The explained space cost is based on the number of growth steps required to assign ownership to all of the patches.

Another methodology used by arbiter is static joint configuration score . The static joint configuration score evaluates the lengths between adjacent joints in a skeletal hypothesis and the angles formed by various joints in a skeletal hypothesis. To the extent the skeletal hypothesis defines distances between joints that are not possible too long or too short or are in disagreement the ratios of lengths between various bones are too extreme or angles formed by joints that are not possible joints bending in ways that a human cannot bend the static joint configuration score penalizes that skeletal hypothesis.

Referring to the flowchart of the arbiter checks the lengths between adjacent joints in step . Step may include for example checking whether the distance between the shoulders in the skeletal hypothesis is outside a minimum or maximum distance whether the head is separated from the shoulders by a distance outside a minimum or maximum distance whether the length of the upper and or lower arms in the skeletal hypothesis are outside a minimum or maximum distance and whether the length of the upper and or lower legs in the skeletal hypothesis are outside a minimum or maximum distance. The maximum and minimum take into account the potential variance across the population of users. In further embodiments the system may make deductions regarding the size of a particular target user and tailor the maximum and minimum values for that particular user.

In step the arbiter may measure the length of the upper arm and lower arm and upper leg and lower leg for the skeletal hypothesis under consideration. Where the combined length of the upper and lower arms legs is either too large or too small the score for that skeletal hypothesis is penalized.

In step instead of checking the total length the arbiter may run a subroutine checking the ratio of the upper arm length to the sum of the upper and lower arm lengths and or the ratio of the upper leg length to the sum of the upper and lower leg lengths for the skeletal hypothesis under consideration. For example the ratio of the upper arm length to the sum of the upper and lower arm lengths will commonly be between 0.45 and 0.52 in human bodies. Any arm leg ratio outside of the given range for arms and legs may be penalized. The penalty may be proportional but not necessarily linear to the trespass outside of the expected range. Other ratios might be checked for example the ratio of the total average arm length to the shoulder span the ratio of the average arm length to the average leg length the ratio of one arm s length to the other arm s length and so on. In general these scoring functions as well as the other scoring functions described herein may be continuous and differentiable.

In step of the static joint configuration score methodology the arbiter may run a scoring subroutine which tests whether a given body part in a skeletal hypothesis is kinematically valid. That is given a known range of motions of a human s body parts including the head upper and lower arms upper and lower legs and the possible orientations of these body parts to the torso can a person validly have joint positions in a given skeletal hypothesis. If not the skeletal hypothesis may be penalized or removed. In embodiments the kinematically valid scoring subroutine may begin by translating and rotating a person s position in 3 D real world space to a frame of reference of the person s torso independent of real world space . While operation of this subroutine may be done using a person s position orientation in real world space in further embodiments it is computationally easier to first translate the user to a frame of reference of the person s torso.

In this frame of reference the ortho normal basis vectors for torso space can be visualized as X is from the left shoulder to the right shoulder Y is up the torso spine and Z is out through the player s chest i.e. generally the opposite of Z in world space . Again this frame of reference is by way of example only and may vary in further embodiments.

Thereafter for a given body part position the arbiter checks whether the body part is kinematically valid with respect to the rest of the body. For example in step the arbiter may check whether a lower arm lies within a cone defining the possible positions direction and angle of the lower arm for the given upper arm position. Using the above described ortho normal basis vectors the upper arm might lie along or in between six ortho normal vector positions upper arm forward upper arm back upper arm left upper arm right up and upper arm down . For each of these orthonormal directions of the upper arm a corresponding cone that defines the possible directions of the lower arm is simple to specify and is generally known. Because the direction of the upper arm in the hypothesis is rarely aligned exactly to one of these six orthonormal directions and instead often lies in between several of them the cone definitions associated with the nearest orthonormal upper arm directions are blended together to produce a new cone that is tailored for the specific direction in which the upper arm lies. In this blending the cones of the axes along which the upper arm most closely aligns will receive more weight and the cones of the axes that lie in the opposite direction of the upper arm will have zero weight. Once the blended cone is known the lower arm is then tested to see if it lies within the cone. A skeletal hypothesis in which the lower arm s direction does not fall into the blended cone of valid lower arm directions may then be penalized or if egregious may be discarded. The penalty may be linear or non linear. The same process may be used to test and score other body parts in a skeletal hypothesis under consideration.

It is understood that there are other methods of testing kinematically valid arm positions. Such methods include pose dictionary lookups neural networks or any number of other classification techniques. Further the same tests may be applied to other limbs such as legs the neck and head and even the upper vs. lower body. The static joint configuration score is tallied in step .

Although not shown in there may be another scoring methodology which checks for self penetration or self collision and penalizes it. Details relating to such a scoring methodology are described for example in the above referenced U.S. patent application Ser. No. 12 363 604. However in general in such a methodology the different parts of the body can be represented by simple volumetric primitives rounded cylinders polygonal meshes . Such volumetric primitives may be inexpensively checked to see if these intersect each other using well known techniques. If so a penalty is applied.

The arbiter further includes the motion score methodology . In determining the motion score the arbiter compares joint positions in the current frame against the positions of the same joints identified for a previous frame in step for example the immediately preceding frame. Larger jumps would tend to indicate that the current candidate is not the same joint and the score would be penalized accordingly. For example if the final hand from the previous frame was at certain coordinates and this hypothesis s hand is at new coordinates this methodology looks at the distance between the two coordinates. If the distance is small then there is no penalty incurred but if the distance is large a penalty is incurred. This means that other evidence must be present to counteract the penalty and justify the sudden move. This methodology may compare to the previous frame joint position as well as the projected new joint position or even compute both distances and base the score on the shorter distance. If the prior final output had a poor score i.e. low confidence these penalties may be scaled down or not applied at all. A penalty here may be linear or non linear. The motion score may be tallied in step .

Using the above methodologies the arbiter may select one or possibly more than one skeletal hypothesis having the highest score as the best state estimate xmost closely approximating the player pose in that frame or other time period t. The highest scoring skeletal hypothesis or hypotheses may then be output as explained below. Alternatively a re sampling operation may be performed on the skeletal hypotheses as is also explained below. While the above describes a clear division between experts and the arbiter it is understood that there may be some flexibility as to whether one of the above described experts or some other model fitting algorithm is incorporated as an expert or whether it is incorporated as a methodology in the arbiter for resolving skeletal hypotheses or other computer models of a user.

In embodiments the highest scored skeletal hypothesis may need to exceed some predetermined threshold value in order to be considered accurate. In the event the highest scored skeletal hypothesis is below the threshold the pipeline may not return a state estimate for that time frame or it may return a state estimate with an indication of low reliability. This reliability indication may be used by a gaming or other application receiving the state estimate which may then elect to use or not use the state estimate for that time frame. The reliability indication may also be fed back into the pipeline so that future determinations of state estimates using historical data can factor in that the state estimate for the current time frame may not be a reliable source of information by which to make state determinations in future time frames.

The above sets forth four methodologies by which the arbiter may evaluate and score the various skeletal hypotheses. It is appreciated that a variety of other methodologies may be used in addition to or instead of those discussed above in further embodiments. One feature of the present system is the modularity of the experts and arbiter methodologies. The portfolio of experts can be interchanged independently of each other and the arbiter and the same is true of the methodologies employed by the arbiter. Such a system is highly flexible and adaptable to changing circumstances. Another feature of the present system in maintaining a plurality of skeletal hypotheses and evaluating each is that this results in a system of least commitment. Many possible skeletal hypotheses are considered throughout the model fitting phase of the pipeline without making hard decisions until such decisions can no longer be avoided. This may occur for example just prior to the capture of a new frame of image data where it is time for the system to output its best guess as to one or more skeletal hypotheses that best represent the player position in that time frame.

In embodiments of the present system the final stage of the tracking pipeline may involve re sampling the skeletal hypotheses according to their weight score or a function thereof. That is a new set of skeletal hypotheses may be selected from the original set of skeletal hypotheses for that frame with those skeletal hypotheses scoring higher having a greater chance of being selected into the re sampled set. The effect of this is to make it more likely that bad skeletal hypotheses are culled from the set which otherwise might make it through to the final output.

As indicated in a final step in the pipeline involves outputting the selected best state estimate of the most accurate skeletal hypothesis or hypotheses. The output may be used for at least two purposes. First the output may be used by the gaming or other application to affect some action in the application. For example the state estimate may be used to recognize a user gesture interact with an object within the application or control some other in game function. Other uses of the state estimate by the application are contemplated. Second the output from a given time frame may then be fed back into the pipeline as state history and used as historical skeletal data in future time frames. As noted above it may happen that no single skeletal hypothesis exceeds a threshold confidence value. In this event the state estimate for the current frame may be omitted or may be given little weight as a state estimate in later use by the pipeline or gaming application.

The output can be performed in any suitable manner. As a non limiting example an application programming interface API may be used to report the selected skeletal hypothesis. Such an API may be configured to communicate the joint positions joint velocities joint accelerations confidences in positions velocities and or accelerations and or other information related to the selected skeleton for one or more targets. A content receiver e.g. a gaming application may then use the reported information as desired.

A graphics processing unit GPU and a video encoder video codec coder decoder form a video processing pipeline for high speed and high resolution graphics processing. Data is carried from the GPU to the video encoder video codec via a bus. The video processing pipeline outputs data to an A V audio video port for transmission to a television or other display. A memory controller is connected to the GPU to facilitate processor access to various types of memory such as but not limited to a RAM.

The multimedia console includes an I O controller a system management controller an audio processing unit a network interface controller a first USB host controller a second USB host controller and a front panel I O subassembly that are preferably implemented on a module . The USB controllers and serve as hosts for peripheral controllers a wireless adapter and an external memory device e.g. flash memory external CD DVD ROM drive removable media etc. . The network interface and or wireless adapter provide access to a network e.g. the Internet home network etc. and may be any of a wide variety of various wired or wireless adapter components including an Ethernet card a modem a Bluetooth module a cable modem and the like.

System memory is provided to store application data that is loaded during the boot process. A media drive is provided and may comprise a DVD CD drive hard drive or other removable media drive etc. The media drive may be internal or external to the multimedia console . Application data may be accessed via the media drive for execution playback etc. by the multimedia console . The media drive is connected to the I O controller via a bus such as a Serial ATA bus or other high speed connection e.g. IEEE 1394 .

The system management controller provides a variety of service functions related to assuring availability of the multimedia console . The audio processing unit and an audio codec form a corresponding audio processing pipeline with high fidelity and stereo processing. Audio data is carried between the audio processing unit and the audio codec via a communication link. The audio processing pipeline outputs data to the A V port for reproduction by an external audio player or device having audio capabilities.

The front panel I O subassembly supports the functionality of the power button and the eject button as well as any LEDs light emitting diodes or other indicators exposed on the outer surface of the multimedia console . A system power supply module provides power to the components of the multimedia console . A fan cools the circuitry within the multimedia console .

The CPU GPU memory controller and various other components within the multimedia console are interconnected via one or more buses including serial and parallel buses a memory bus a peripheral bus and a processor or local bus using any of a variety of bus architectures. By way of example such architectures can include a Peripheral Component Interconnects PCI bus PCI Express bus etc.

When the multimedia console is powered ON application data may be loaded from the system memory into memory and or caches and executed on the CPU . The application may present a graphical user interface that provides a consistent user experience when navigating to different media types available on the multimedia console . In operation applications and or other media contained within the media drive may be launched or played from the media drive to provide additional functionalities to the multimedia console .

The multimedia console may be operated as a standalone system by simply connecting the system to a television or other display. In this standalone mode the multimedia console allows one or more users to interact with the system watch movies or listen to music. However with the integration of broadband connectivity made available through the network interface or the wireless adapter the multimedia console may further be operated as a participant in a larger network community.

When the multimedia console is powered ON a set amount of hardware resources are reserved for system use by the multimedia console operating system. These resources may include a reservation of memory e.g. 16 MB CPU and GPU cycles e.g. 5 networking bandwidth e.g. 8 kbs etc. Because these resources are reserved at system boot time the reserved resources do not exist from the application s view.

In particular the memory reservation preferably is large enough to contain the launch kernel concurrent system applications and drivers. The CPU reservation is preferably constant such that if the reserved CPU usage is not used by the system applications an idle thread will consume any unused cycles.

With regard to the GPU reservation lightweight messages generated by the system applications e.g. popups are displayed by using a GPU interrupt to schedule code to render popup into an overlay. The amount of memory required for an overlay depends on the overlay area size and the overlay preferably scales with screen resolution. Where a full user interface is used by the concurrent system application it is preferable to use a resolution independent of the application resolution. A scaler may be used to set this resolution such that the need to change frequency and cause a TV resynch is eliminated.

After the multimedia console boots and system resources are reserved concurrent system applications execute to provide system functionalities. The system functionalities are encapsulated in a set of system applications that execute within the reserved system resources described above. The operating system kernel identifies threads that are system application threads versus gaming application threads. The system applications are preferably scheduled to run on the CPU at predetermined times and intervals in order to provide a consistent system resource view to the application. The scheduling is to minimize cache disruption for the gaming application running on the console.

When a concurrent system application requires audio audio processing is scheduled asynchronously to the gaming application due to time sensitivity. A multimedia console application manager described below controls the gaming application audio level e.g. mute attenuate when system applications are active.

Input devices e.g. controllers and are shared by gaming applications and system applications. The input devices are not reserved resources but are to be switched between system applications and the gaming application such that each will have a focus of the device. The application manager preferably controls the switching of input stream without knowledge of the gaming application s knowledge and a driver maintains state information regarding focus switches. The cameras and capture device may define additional input devices for the console .

In the computing environment comprises a computer which typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as ROM and RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data . further includes a graphics processor unit GPU having an associated video memory for high speed and high resolution graphics processing and storage. The GPU may be connected to the system bus through a graphics interface .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the Exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a keyboard and a pointing device commonly referred to as a mouse trackball or touch pad. Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . The cameras and capture device may define additional input devices for the console . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It will be appreciated that the network connections shown are Exemplary and other means of establishing a communications link between the computers may be used.

The foregoing detailed description of the inventive system has been presented for purposes of illustration and description. It is not intended to be exhaustive or to limit the inventive system to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. The described embodiments were chosen in order to best explain the principles of the inventive system and its practical application to thereby enable others skilled in the art to best utilize the inventive system in various embodiments and with various modifications as are suited to the particular use contemplated. It is intended that the scope of the inventive system be defined by the claims appended hereto.

