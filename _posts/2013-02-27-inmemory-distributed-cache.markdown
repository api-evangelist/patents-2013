---

title: In-memory distributed cache
abstract: Improved caching mechanisms are presented herein for use with an in-memory distributed cache and, potentially, other types of caches. One mechanism permits cache clients to wait on a cache key being fetched by one or more other cache clients. When the cache key arrives at the cache, the waiting cache clients may be called back with the cache key. Another mechanism allows a service to push changed values directly into a distributed cache. Yet another mechanism allows the storage of information in a cache that defines dependencies between cached values. The dependency information can be utilized to invalidate cache values that are dependent upon other cached values that have been invalidated.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09369332&OS=09369332&RS=09369332
owner: Amazon Technologies, Inc.
number: 09369332
owner_city: Seattle
owner_country: US
publication_date: 20130227
---
Large scale dynamic World Wide Web Web sites commonly implement an in memory distributed cache to improve application performance. An in memory distributed cache utilizes a collection of distributed cache nodes that store data in memory for fast retrieval. For example a Web application might utilize an in memory distributed cache to cache the results of a call to a Web service. If another instance of the Web application needs the results of the same call the second instance of the Web application can retrieve the results from the in memory distributed cache rather than performing a second call to the Web service.

Because the in memory distributed cache stores the results of the call to the Web service in main memory the cache will be able to return the results to the Web application much more quickly than the Web service. Moreover because a second call to the Web service is avoided the processing load on the Web service is reduced. However although an in memory distributed cache can improve application performance in many implementations there are still scenarios where the operation of an in memory distributed cache may be improved for even greater application performance.

The following detailed description is directed to technologies for improving the operational performance of an in memory distributed cache. Through an implementation of the technologies disclosed herein cache clients can retrieve values from an in memory distributed cache more quickly in certain common scenarios than in previous cache implementations.

According to one embodiment disclosed herein an in memory distributed cache is provided that includes multiple cache nodes. Each of the cache nodes is configured to execute a cache server component that implements the functionality of the distributed cache. The cache server component is configured to expose various application programming interface API methods to cache clients that utilize the distributed cache. In one embodiment for example the methods exposed by the cache server include a cache get method a claim fetching method a cache add method and a cache wait method. The cache server might also expose other methods for use by the cache clients.

The cache get method allows a cache client to request a value from the in memory distributed cache. In order to request the value the requesting cache client provides a key to the cache server as a part of the call to the cache get method. If the specified key has an associated value in the cache the cache server returns the value stored in the cache to the cache client in response to the request. If the specified key does not have an associated value stored in the cache the cache server determines whether a predefined and possibly user configurable number of cache clients have previously indicated that they are fetching the requested value. As will be described in greater detail below the cache server might expose a claim fetching method through which a cache client can provide such an indication.

If the cache server determines that the required number of cache clients have not indicated that they are fetching the requested value then the cache server returns a null value in response to the request thereby indicating to the calling cache client that the requested value is not stored in the distributed cache. If however the cache server determines that the required number of cache clients have indicated that they are fetching the requested value the cache server provides an indication in response to the request that the cache client can wait for the requested value to become available in the distributed cache.

If the cache client decides to wait for the requested value the cache client might then call the cache wait method exposed by the cache server. When the cache server receives a call to the cache wait method the cache server adds the identity of the cache client to a list or other type of data structure utilized to store data identifying each of the cache clients that are waiting for the requested value. As will be described in detail below the cache server may call the cache client back with the requested value when another cache client adds the value to the distributed cache.

If the cache client decides to fetch the requested value rather than to wait for the value to appear in the distributed cache the cache client may call the claim fetching method exposed by the cache server. In response to receiving such a call the cache server increments a variable utilized to keep track of the number of cache clients that have indicated that they are fetching the value. As discussed above until this variable reaches a predefined value a null value will be returned to cache clients requesting the same value. After the variable has reached the predefined value cache clients will be permitted to wait on the requested value. By requiring a certain number of cache clients to indicate that they are fetching the cache value prior to permitting other cache clients to wait the cache server can increase the likelihood that at least one of the fetching clients will in fact add the value to the distributed cache.

When a cache client calls the cache add method the cache server adds a specified key and value to the distributed cache. The cache server also examines the list of waiting clients to determine whether any cache clients are waiting on the value just added to the cache. If so the cache server provides the value to each of the waiting clients. For example the cache server might call back each of the waiting clients with the newly added value. Additionally the cache server clears the list of cache clients waiting on the value and resets the variable utilized to keep track of the number of cache clients that are fetching the value.

According to another embodiment disclosed herein a service is configured to expose a push to cache method through which a caller can request that a value for a specified key be updated in a cache if the value changes. For example an application might request and receive a value from a Web service. The application might then cause the received value to be stored in a cache such as an in memory distributed cache utilizing an appropriate mechanism such as the cache add method described above.

The application might also request that the service directly update the value stored in the cache if the value changes. In order to perform this functionality the application calls the push to cache method exposed by the service with the value and its associated cache key. The request might also include a node ID that identifies the node in the cache storing the key and a time to live TTL value specifying a lifetime for the request.

When the service receives the call to the push to cache method it stores the cache key the value the node ID and the TTL value if provided. The service then periodically determines whether the value has changed. For example the service might periodically recompute the value retrieve the value from another service or system or perform other types of processing in order to determine whether the value originally supplied in the request has changed. The service might also register for and receive an event indicating that the value has changed.

If the service determines that the value has changed the service then causes the value previously stored in the cache to be updated with the changed value. For example the service might call an update key method on the cache to submit the changed value. This process may continue until the specified TTL for the request has expired. In this way the application can avoid having to retrieve the updated value from the service and re store the value in the cache in the event of a cache miss.

According to another embodiment disclosed herein a mechanism is provided for relational caching. In this embodiment cache keys are stored along with information describing any dependencies between the cache keys. When a cache key is invalidated such as based upon an associated TTL value the stored dependency information may be utilized to invalidate other cache keys that are dependent upon the invalidated cache key. Storing and invalidating cache keys in this way may avoid unnecessary service calls in certain implementations. Additional details regarding these and other aspects of the embodiments disclosed herein will be provided below with regard to .

It should be appreciated that the embodiments disclosed herein might be utilized with any type of computer computing system device application program operating system or other type of system or component. In particular while the embodiments disclosed herein are discussed primarily in the context of an in memory distributed cache various aspects of the embodiments disclosed herein might also be utilized with other types of distributed and non distributed caching mechanisms. It should also be appreciated that the various caching mechanisms described above and in more detail below may be utilized independently or in combination with one another. Further it should also be appreciated that the subject matter presented herein may be implemented as a computer process a computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. These and various other features will become apparent from a reading of the following disclosure and a review of the associated drawings.

While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types.

Those skilled in the art will appreciate that various aspects of the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described below including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants tablet computers electronic book readers wireless telephone devices special purposed hardware devices network appliances or the like. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

In the following detailed description references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific embodiments or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures.

In order to provide this functionality each of the cache nodes is configured to execute a cache server module that controls the operation of the cache node . The cache server module might expose various methods that can be called by cache clients to store data in the cache update data previously stored in the cache retrieve data from the cache and to perform other functions. Details regarding various aspects of the operation of the cache server module will be provided below.

As also illustrated in the distributed cache might be utilized in conjunction with an implementation of a large scale dynamic Web site. In particular aspects of the operation of such a Web site might be implemented by instances of a Web application executing on a multitude of application servers A N. A number of proxies A and B load balancers not shown and other types of networking devices might be utilized to connect the application servers A N to a network such as the Internet. Clients might submit requests to the application servers A N by way of the network .

In order to obtain dynamically generated data the various instances of the application might utilize one or more backend services such as the service . For example the instances of the application might utilize database services and other types of services in order to generate various types of objects. A number of service hosts A N might be utilized to implement each service. The service hosts might be hardware devices and or virtual machine instances. Although only a single service has been illustrated in it should be appreciated that many services might be utilized in other implementations.

Each of the application servers might also be configured with a cache client component for managing data stored in the distributed cache by each of the instances of the application . The cache client is configured for communication with the cache server component executing on the cache nodes . In one implementation the cache client is implemented as a set of libraries that enable communication with the cache nodes of the distributed cache . The instances of the application can call the libraries to perform cache related functions. For example and as will be described in greater detail below the cache client can be utilized to store objects in the distributed cache retrieve objects from the distributed cache and to perform other functions.

In order to enable communication with the distributed cache each of the cache clients is configured with the identity of each of the cache nodes . The cache nodes however do not typically communicate with one other. If a cache client wishes to set or read a value corresponding to a certain key the cache client first computes a hash of the key to identify the particular cache node that will be used to store the value. The cache client then communicates with the cache server on the identified cache node to read or store the desired value. Because all of the cache clients use the same hashing algorithm to identify cache nodes each cache client can read data stored in the distributed cache by the other cache clients .

As mentioned briefly above the cache nodes keep stored values in random access memory RAM . If a cache node runs out of RAM it will typically discard the oldest values. Therefore the cache clients should typically treat the in memory distributed cache as a transitory cache. The cache clients should not assume that data stored in distributed cache will still be in the distributed cache at the time the data is needed.

One specific example of a component for implementing an in memory distributed cache is the MEMCACHED open source distributed in memory object caching system originally developed by DANGA INTERACTIVE. In this regard it should be appreciated that the embodiments disclosed herein might be implemented in conjunction with a distributed cache implemented utilizing MEMCACHED. It should also be appreciated that the concepts presented herein might be implemented with other types of in memory object caching systems from other developers.

It should be appreciated that the operating environment shown in has been simplified for discussion purposes and that many more computing networking and power components might be utilized than shown in . Moreover it should also be appreciated that the operating environment shown in is merely illustrative and that the various caching improvements disclosed herein might be utilized in many different environments and configurations. Additional details regarding the various components shown in will be provided below.

In response to receiving the call the cache server determines whether the requested key is in the distributed cache . If the requested key is in the distributed cache the cache server retrieves the value associated with the key from the distributed cache and returns the value in response to the call. In the example shown in for instance the cache server might return a response A indicating that the key FOO FOOBAR if the value FOOBAR is stored in the distributed cache for the key FOO. If the cache server determines that the requested value is not in the distributed cache the cache server will return a response B with a null value or another type of value indicating that the requested value is not in the distributed cache .

According to embodiments presented herein the cache server might also be configured to return a wait available response C indicating that the cache client may wait for the requested value to become available in the distributed cache in certain circumstances. In particular the cache server might instruct cache clients that they can wait for a value to become available in the distributed cache when a requested key is not in the cache and when one or more other cache clients have indicated that they are fetching the requested value. The number of cache clients that must indicate that they are fetching the requested value before the cache server will provide the wait available response C may be user configurable. For example an administrator of the distributed cache might specify that 20 cache clients must indicate that they are fetching the requested value before another cache client will be permitted to wait on the requested value.

As shown in the cache server might also be configured to expose a claim fetching method. The claim fetching method allows a cache client to indicate to the cache server that the cache client is going to fetch a requested key. For instance in the example shown in the cache client has transmitted a call to the claim fetching method exposed by the cache server indicating that the cache client is fetching the key FOO. In response to receiving such a call the cache server might increment a variable utilized to keep track of the number of cache clients that are fetching a particular key. As discussed above with regard to this variable might be utilized to determine whether a wait available response C may be provided to cache clients when a requested value is not in the distributed cache .

If a cache client desires to wait on a requested key to appear in the distributed cache rather than fetching the key the cache client may transmit a call to a wait cache method exposed by the cache server in one embodiment. For instance in the example shown in the cache client has transmitted a call to the wait cache method exposed by the cache server . In response thereto the cache server adds the calling cache client to a list or other type of data structure that identifies each of the cache clients that are waiting on the particular key. In the example shown in for instance the cache server may add the cache client to a list identifying the clients that are waiting for the key FOO. 

The cache server is also configured to expose a cache add method through which cache clients can add key value pairs to the distributed cache . For example as shown in a cache client might submit a call to the cache add method in order to add a key and its associated value to the distributed cache . When a cache client adds a key to the distributed cache the cache server examines the list or other type of data structure associated with the submitted key to determine if any other cache clients are awaiting the newly submitted value.

If other cache clients are awaiting the new value the cache server provides the value to the waiting cache clients . For example the cache server might provide a callback to the waiting cache clients with the newly added value. In the example shown in for instance the cache server has provided a callback to the cache client with the value FOOBAR. It should be appreciated that mechanisms other than a callback might be utilized in order to provide values to the waiting cache clients . Additional details regarding the various methods exposed by the cache server will be described below with regard to .

The routine begins at operation where a cache server in the distributed cache receives a call to its cache get method. As discussed above the cache get method allows a cache client to request a value from the in memory distributed cache . In order to request the value the requesting cache client provides a key to the cache server as a part of the call to the cache get method.

From operation the routine proceeds to operation . At operation the cache server determines whether the requested key is in the distributed cache . If the specified key has an associated value in the cache the routine proceeds from operation to operation where the cache server returns the value stored in the distributed cache to the requesting cache client in response to the request. If however the specified key does not have an associated value stored in the cache the routine proceeds from operation to operation .

At operation the cache server determines whether a predefined and possibly user configurable number of cache clients have previously indicated that they are fetching the requested value. As mention above and as will be described in greater detail below with regard to the cache server might expose a claim fetching method through which a cache client can provide such an indication.

If the cache server determines that the required number of cache clients have not indicated that they are fetching the requested value then the routine proceeds from operation to operation . At operation the cache server returns a null value in response to the request thereby indicating to the calling cache client that the requested value is not stored in the distributed cache . The routine then proceeds from operation to operation where it ends.

If at operation the cache server determines that the required number of cache clients have indicated that they are fetching the requested value the routine proceeds from operation to operation . At operation the cache server provides an indication in response to the request that the requesting cache client can wait for the requested value to become available in the distributed cache . If the cache client chooses to wait the cache client may make a call to the cache wait method exposed by the cache client . Details regarding the operation of the cache wait method will be provided below with regard to .

At operation the cache server increments a variable utilized to keep track of the number of cache clients that have indicated that they are fetching the value. Until the variable reaches a predefined value a null value will be returned to cache clients requesting the same value. After the variable has reached the predefined value cache clients will be permitted to wait on the requested value in the manner described below with regard to . By requiring a certain number of cache clients to indicate that they are fetching the value prior to permitting other cache clients to wait the cache server can increase the likelihood that at least one of the fetching clients will in fact add the value to the distributed cache . From operation the routine proceeds to operation where it ends.

In response to receiving such a call the routine proceeds from operation to operation where the cache server adds the identity of the calling cache client to a list or other type of data structure utilized to store data identifying each of the cache clients that are waiting for the requested value. As described briefly above and as will be described in detail below with regard to the cache server may call the cache client back with the requested value when another cache client adds the value to the distributed cache . From operation the routine proceeds to operation where it ends.

At operation the cache server determines whether any cache clients are waiting on the cache key just added to the distributed cache . As mentioned above this determination may be made by examining the list or other type of data structure utilized to keep track of the cache clients waiting on particular cache keys. If no cache clients are awaiting the cache key the routine proceeds from operation to operation where it ends. If however one or more cache clients are awaiting the newly added cache key the routine proceeds from operation to operation .

At operation the cache server returns the newly added value to the waiting cache clients . As mentioned above a call back or another type of mechanism might be utilized to provide the cache key to the waiting cache clients . Once the cache key has been provided to the waiting cache clients the routine proceeds from operation to operation .

At operation the cache server clears the list of cache clients waiting for the cache key. The cache server also resets the variable utilized to keep track of the number of cache clients indicating that they are fetching the cache key. From operation the routine proceeds to operation where it ends.

In response to receiving the value the application might then cause the received value to be stored in a cache such as the in memory distributed cache utilizing an appropriate mechanism such as by making a call to the cache add method described above. One of the cache nodes in the distributed cache will then store the specified value . For example in the cache node A stores the value .

In a typical installation the value stored in the distributed cache will be invalidated after its associated TTL value expires. At that time the application will need to request an updated value from the service and to store the updated value in the distributed cache . This process may continue indefinitely. The mechanism described below allows the application to instruct the service to update the value in the distributed cache each time the value changes. Through this mechanism the repeated calls from the application to the service for changed values can be avoided.

In order to provide this functionality the service may expose a push to cache method through which a caller can request that updated values be pushed by the service directly into the distributed cache . For instance in the example shown in the application has transmitted a call to the push to cache method exposed by the service . The call includes a field B storing the value to be updated and a field A storing the cache key associated with the value . The call might also include a field C storing a node ID that identifies the node A in the distributed cache that is storing the cache key for the value and a field D storing a TTL value specifying a lifetime for the request .

When the service receives the call to the push to cache method it stores the cache key the value the node ID and the TTL value if provided. The service then periodically determines whether the value has changed. For example the service might periodically recompute the value retrieve the value from another service or system or perform other types of processing in order to determine whether the value originally supplied in the request has changed. The service might also register for and receive an event indicating that the value has changed.

If the service determines that the value has changed the service then causes the value previously stored in the distributed cache to be updated with the changed value. For example the service may transmit a call to an update key method on the cache server of the cache node A to submit the changed value. This process may continue until the specified TTL for the request has expired. In this way the application can avoid having to continually retrieve the updated value from the service and re store the value in the distributed cache in the event of a cache miss. Additional details regarding this process will be provided below with regard to .

At operation the service stores the cache key value node ID and TTL value provided in the fields A D of the call . These values are utilized to update the value when the value changes in the manner described below. From operation the routine proceeds to operation where the service periodically determines whether the value specified in the call has changed. As discussed above the service might periodically recompute the value retrieve the value from another service or system or perform other types of processing in order to determine whether the value originally supplied in the request has changed. The service might also register for and receive an event indicating that the value has changed. From operation the routine proceeds to operation .

At operation the service determines whether the value has changed. If the value has changed the routine proceeds from operation to operation . At operation the service transmits a call to the cache update method of the cache node where the value is stored in order to update the stored value in the distributed cache . The routine then proceeds from operation to operation .

If at operation the service determines that the value has not changed the routine proceeds from operation to operation . At operation the service determines whether the TTL for the push to cache request specified in the field D of the call has expired. If the TTL has not expired the routine proceeds from operation to operation where updates to the value may be continually pushed into the distributed cache in the manner described above.

If at operation the service determines that the TTL for the push to cache request has expired the service deletes the cache key value node ID and TTL stored at operation described above. In this manner no further updating of the value in the distributed cache will occur. From operation the routine proceeds to operation where it ends.

As illustrated in a service A might utilize multiple other services B D to obtain information for responding to certain types of requests. For instance in the example shown in the service A has received a request for three data values A B and C . In order to satisfy the request the service A utilizes the service B to obtain the value A A utilizes the service C to obtain the value B B and utilizes the service D to obtain the value C C . Once the service A has obtained the values A C from the services B D the service A can provide a response to the request .

As also shown in the service A maintains a front end cache . The front end cache is typically utilized to cache the results for entire requests such as for the request . Accordingly in a typical implementation the service A will store a single key in the front end cache and an associated value for the request . In this case the key would be associated with all of the values A C. The individual values A C might also be cached separately in the distributed cache in the manner described above.

As also illustrated in each of the values A C retrieved from the services B D has a different TTL value. In particular the value A has an associated TTL of one hour the value B has an associated TTL of 30 minutes and the TTL for the value C is 2 minutes. The TTL for the cache key corresponding to the entire request is typically set to be the minimum of the TTL values for data retrieved from the services B D. As a result the TTL value for the cache key corresponding to the request would be set at two minutes i.e. the TTL of the value C retrieved from the service D .

When the TTL i.e. 2 minutes for the cache key corresponding to the request expires this cache key is invalidated. Accordingly when a subsequent request is received that is identical to the request it will be necessary to again retrieve the values A C from the services B D respectively. This will be true even though it may be unlikely that the values A and B have changed if the subsequent request is received shortly after the TTL for the value C expires. Consequently unnecessary service calls may be made to the services B and C utilizing such a mechanism for caching the entire request . These calls utilize valuable network bandwidth and central processing unit CPU cycles.

One embodiment disclosed herein includes a mechanism for avoiding the unnecessary service calls described above. In particular according to this mechanism separate keys are stored in the front end cache for each of the values A C each having its own associated TTL value. For instance in the example shown in the cache key KEYA has been stored in the front end cache for the value A along with a TTL of one hour. Similarly the key KEYB has been stored in the front end cache for the value B along with a TTL of thirty minutes. Likewise the key KEYC has been stored in the front end cache for the value C along with a TTL of two minutes.

In addition to the separate cache keys stored in the front end cache for each of the values A C a cache key is also stored in the front end cache corresponding to the request . The cache key for the request is associated with the cache keys for the values A C. In the example shown in for instance a cache key REQUESTKEY has been stored in the front end cache that includes the cache key KEYA for the value A the cache key KEYB for the value B and the cache key KEYC for the value C. The cache key for the request might also be given its own unique TTL value that is not dependent upon the TTL values associated with the values A C. By storing the cache key for the request in this manner a dependency graph is created in the front end cache indicating that the value of the request is dependent upon the values A C also stored in the cache.

Storing cache keys and dependency information in the front end cache in the manner described above allows the cache keys for the values A C to be invalidated individually. Moreover storing the cache keys and the dependency information in the manner described above also allows cache keys to be invalidated at the time that cache keys upon which they are dependent are invalidated. For instance using the example presented above the cache key for the value C might be invalidated after two minutes. As a result the cache key for the request will also be invalidated because it is dependent upon the cache key associated with the value C which has been invalidated.

The cache keys for the values A and B are not however invalidated when the cache key associated with the value C is invalidated. As a result when the service A receives a subsequent request that is identical to the request the service A will query the front end cache and the front end cache will return null values for the cache key corresponding to the request and for the cache key corresponding to the value C. However the front end cache will return the cached values A and B. In this way the service only needs to perform a service call to the service D to obtain an updated value for the value C and can then generate a response to the request. The unnecessary calls to the services B and C described above are avoided through the use of this mechanism. Additional details regarding the operation of this mechanism will be provided below with regard to .

From operation the routine proceeds to operation where another cache key is added to the cache that defines a dependency graph utilizing the cache keys stored at operation . For instance in the example described above with regard to a cache key REQUESTKEY has been stored in the front end cache that includes the cache key KEYA for the value A the cache key KEYB for the value B and the cache key KEYC for the value C. This creates a dependency graph indicating that the cache key for the request is dependent upon the three specified cache keys. As mentioned above the cache key for the request might also be given its own unique TTL value that is not dependent upon the TTL values associated with the values A C. From operation the routine proceeds to operation where it ends.

From operation the routine proceeds to operation where additional calls are made to the cache get method for each of the cache keys obtained above at operation . As discussed above if any of the cache keys have been invalidated a null value will be returned. In the example described above with regard to the service A will then obtain updated values for any invalidated keys by calling the appropriate services B D. The service A can then satisfy the request . From operation the routine proceeds to operation where it ends.

The computer includes a baseboard or motherboard which is a printed circuit board to which a multitude of components or devices may be connected by way of a system bus or other electrical communication paths. In one illustrative embodiment one or more central processing units CPUs operate in conjunction with a chipset . The CPUs are standard programmable processors that perform arithmetic and logical operations necessary for the operation of the computer .

The CPUs perform operations by transitioning from one discrete physical state to the next through the manipulation of switching elements that differentiate between and change these states. Switching elements may generally include electronic circuits that maintain one of two binary states such as flip flops and electronic circuits that provide an output state based on the logical combination of the states of one or more other switching elements such as logic gates. These basic switching elements may be combined to create more complex logic circuits including registers adders subtractors arithmetic logic units floating point units or the like.

The chipset provides an interface between the CPUs and the remainder of the components and devices on the baseboard. The chipset may provide an interface to a random access memory RAM used as the main memory in the computer . The chipset may further provide an interface to a computer readable storage medium such as a read only memory ROM or non volatile RAM NVRAM for storing basic routines that help to startup the computer and to transfer information between the various components and devices. The ROM or NVRAM may also store other software components necessary for the operation of the computer in accordance with the embodiments described herein.

According to various embodiments the computer may operate in a networked environment using logical connections to remote computing devices and computer systems through a network such as a local area network LAN a wide area network WAN the Internet or any other networking topology known in the art that connects the computer to remote computers. The chipset includes functionality for providing network connectivity through a network interface controller NIC such as a gigabit Ethernet adapter.

For example the NIC may be capable of connecting the computer to other computing devices over a network such as a local area network LAN or a wide area network WAN such as the Internet. It should be appreciated that multiple NICs may be present in the computer connecting the computer to other types of networks and remote computer systems.

The computer may be connected to a mass storage device that provides non volatile storage for the computer. The mass storage device may store system programs application programs other program modules and data which have been described in greater detail herein. The mass storage device may be connected to the computer through a storage controller connected to the chipset . The mass storage device may consist of one or more physical storage units. The storage controller may interface with the physical storage units through a serial attached SCSI SAS interface a serial advanced technology attachment SATA interface a FIBRE CHANNEL FC interface or other standard interface for physically connecting and transferring data between computers and physical storage devices.

The computer may store data on the mass storage device by transforming the physical state of the physical storage units to reflect the information being stored. The specific transformation of physical state may depend on various factors in different implementations of this description. Examples of such factors may include but are not limited to the technology used to implement the physical storage units whether the mass storage device is characterized as primary or secondary storage or the like.

For example the computer may store information to the mass storage device by issuing instructions through the storage controller to alter the magnetic characteristics of a particular location within a magnetic disk drive unit the reflective or refractive characteristics of a particular location in an optical storage unit or the electrical characteristics of a particular capacitor transistor or other discrete component in a solid state storage unit. Other transformations of physical media are possible without departing from the scope and spirit of the present description with the foregoing examples provided only to facilitate this description. The computer may further read information from the mass storage device by detecting the physical states or characteristics of one or more particular locations within the physical storage units.

In addition to the mass storage device described above the computer might have access to other computer readable media to store and retrieve information such as program modules data structures or other data. It should be appreciated by those skilled in the art that computer readable media can be any available media that may be accessed by the computer including computer readable storage media and communications media. Communications media includes transitory signals. Computer readable storage media includes volatile and non volatile removable and non removable storage media implemented in any method or technology. For example computer readable storage media includes but is not limited to RAM ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM flash memory or other solid state memory technology compact disc ROM CD ROM digital versatile disk DVD high definition DVD HD DVD BLU RAY or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that can be used to store the desired information. Computer readable storage media does not include transitory signals.

The mass storage device may store an operating system utilized to control the operation of the computer . According to one embodiment the operating system comprises the LINUX operating system. According to another embodiment the operating system comprises the WINDOWS SERVER operating system from MICROSOFT Corporation of Redmond Wash. According to further embodiments the operating system may comprise the UNIX or SOLARIS operating systems. It should be appreciated that other operating systems may also be utilized. The mass storage device may store other system or application programs and data utilized by the computer . For instance when utilized to implement a cache node the mass storage device might store the cache server component . When utilized to implement an application server the mass storage device might store the cache client component . The mass storage device might also store other types of programs and data when utilized to implement other computing systems.

In one embodiment the mass storage device or other computer readable storage media may be encoded with computer executable instructions which when loaded into the computer transform the computer from a general purpose computing system into a special purpose computer capable of implementing the embodiments described herein. These computer executable instructions transform the computer by specifying how the CPUs transition between states as described above. According to one embodiment the computer has access to computer readable storage media storing computer executable instructions that when executed by the computer perform the various routines and operations described herein.

The computer may also include an input output controller for receiving and processing input from a number of input devices such as a keyboard a mouse a touchpad a touch screen an electronic stylus or other type of input device. Similarly the input output controller may provide output to a display device such as a computer monitor a flat panel display a digital projector a printer a plotter or other type of output device. It will be appreciated that the computer may not include all of the components shown in may include other components that are not explicitly shown in or may utilize an architecture completely different than that shown in .

Based on the foregoing it should be appreciated that technologies for providing an improved in memory distributed cache have been presented herein. Although the subject matter presented herein has been described in language specific to computer structural features methodological acts and computer readable media it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features acts or media described herein. Rather the specific features acts and mediums are disclosed as example forms of implementing the claims.

The subject matter described above is provided by way of illustration only and should not be construed as limiting. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure. Various modifications and changes may be made to the subject matter described herein without following the example embodiments and applications illustrated and described and without departing from the true spirit and scope of the present invention which is set forth in the following claims.

