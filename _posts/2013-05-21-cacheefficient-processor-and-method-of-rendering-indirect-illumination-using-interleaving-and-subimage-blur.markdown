---

title: Cache-efficient processor and method of rendering indirect illumination using interleaving and sub-image blur
abstract: A cache-efficient processor and method for rendering indirect illumination using interleaving and sub-image blur. One embodiment of the processor is configured to render an indirect illumination image and includes: (1) a buffer restructurer configured to organize a reflective shadow map (RSM), rendered with respect to a reference point, into a plurality of unique sub-RSMs, each having sub-RSM pixels, (2) an indirect illumination computer configured to employ interleaved sampling on the plurality of unique sub-RSMs to generate a plurality of indirect illumination sub-images, and (3) a filter operable to smooth accumulated light values of the indirect illumination sub-images for subsequent interleaving into the indirect illumination image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09129443&OS=09129443&RS=09129443
owner: NVIDIA CORPORATION
number: 09129443
owner_city: Santa Clara
owner_country: US
publication_date: 20130521
---
This application is directed in general to computer graphics rendering and more specifically to the rendering of indirect illumination.

Many computer graphic images are created by mathematically modeling the interaction of light with a three dimensional scene from a given viewpoint. This process called rendering generates a two dimensional image of the scene from the given viewpoint and is analogous to taking a photograph of a real world scene.

As the demand for computer graphics and in particular for real time computer graphics has increased computer systems with graphics processing subsystems adapted to accelerate the rendering process have become widespread. In these computer systems the rendering process is divided between a computer s general purpose central processing unit CPU and the graphics processing subsystem architecturally centered about a graphics processing unit GPU . Typically the CPU performs high level operations such as determining the position motion and collision of objects in a given scene. From these high level operations the CPU generates a set of rendering commands and data defining the desired rendered image or images. For example rendering commands and data can define scene geometry lighting shading texturing motion and or camera parameters for a scene. The graphics processing subsystem creates one or more rendered images from the set of rendering commands and data.

Scene geometry is typically represented by geometric primitives such as points lines polygons for example triangles and quadrilaterals and curved surfaces defined by one or more two or three dimensional vertices. Each vertex may have additional scalar or vector attributes used to determine qualities such as the color transparency lighting shading and animation of the vertex and its associated geometric primitives.

Many graphics processing subsystems are highly programmable through an application programming interface API enabling complicated lighting and shading algorithms among other things to be implemented. To exploit this programmability applications can include one or more graphics processing subsystem programs which are executed by the graphics processing subsystem in parallel with a main program executed by the CPU. Although not confined merely to implementing shading and lighting algorithms these graphics processing subsystem programs are often referred to as shading programs programmable shaders or simply shaders. 

A variety of shading programs are directed at modeling illumination in a scene. The physical plausibility of rendered illumination often depends on the application more specifically whether or not the rendering is done in real time. Physically plausible illumination at real time frame rates is often achieved using approximations. For example ambient occlusion is a popular approximation because of its high speed and simple implementation. Another example is directional occlusion. Many algorithms can only approximate direct illumination which is light coming directly from a light source.

Global illumination is a concept that accounts for both direct illumination and indirect illumination which is light that reflects off other surfaces in rendering the scene. In doing so a significantly more realistic image is achievable. However real time global illumination remains problematic for large and dynamic scenes. Efforts to mitigate the latency introduced by these comprehensive illumination algorithms are ongoing. For example some algorithms partially pre compute illumination. Another example is instant radiosity which models indirect lighting as a set of point lights the contributions of which are accumulated over multiple rendering passes. Yet another approach is to limit indirect lighting to a single bounce under the assumption that one bounce indirect illumination is sufficiently realistic. Still real time frame rates are typically only achievable through approximations.

One aspect provides a processor configured to render an indirect illumination image. In one embodiment the processor includes 1 a buffer restructurer configured to organize a reflective shadow map RSM rendered with respect to a reference point into a plurality of unique sub RSMs each having sub RSM pixels 2 an indirect illumination computer configured to employ interleaved sampling on the plurality of unique sub RSMs to generate a plurality of indirect illumination sub images and 3 a filter operable to smooth accumulated light values of the indirect illumination sub images for subsequent interleaving into the indirect illumination image.

Another aspect provides a method of rendering indirect illumination for a full resolution image of a scene. In one embodiment the method includes 1 rendering the scene into a RSM in light space and a camera view G buffer 2 restructuring the RSM into sub RSMs and the camera view G buffer into camera view sub buffers representing sub images of the full resolution image 3 employing interleaved sampling on the sub RSMs and the camera view sub buffers to compute indirect illumination for each pixel in each of the sub images thereby generating indirect illumination sub images 4 blurring the indirect illumination sub images and 5 interleaving blurred indirect illumination sub images into a higher resolution indirect illumination image.

Yet another aspect provides a graphics processing subsystem. In one embodiment the subsystem includes 1 a memory configured to store a light space RSM data structure according to which a RSM rendered with respect to a light source is represented by a plurality of unique reduced resolution sub RSMs and 2 a processor configured to gain access to the memory via a data bus and operable to 2a employ the plurality of unique reduced resolution sub RSMs to compute a plurality of reduced resolution indirect illumination sub images 2b apply a blurring effect to each of the plurality of reduced resolution indirect illumination sub images and 2c interleave the plurality of reduced resolution indirect illumination sub images into a higher resolution indirect illumination image.

Indirect illumination is typically implemented in renderers as a one bounce approximation of diffuse inter reflected light. For simplicity assume a scene has a single light source. One way to achieve the approximation is by rendering a scene with respect to the light source or from the vantage point of the light otherwise referred to as light space. The resulting buffer would be considered a shadow map as it depicts every surface the light source reaches. These are often used to generate shadows as the intersection of the shadow map and a screen space image or an image rendered from the vantage point of the camera would be a rendering of direct illumination. Continuing the assumption of a single light source all one bounce indirect illumination can be approximated by surfaces visible in the shadow map. Each pixel in the shadow map can be considered a small area light source that illuminates the scene. Because the shadow map is of a limited resolution small areas casting indirect light may be underrepresented. The light contributions of each of the small area light sources to each pixel in the screen space image can be calculated in a variety of ways based on the data available in the geometry buffers G buffers rendered from the vantage point of the camera or in screen space and data available in light space buffers. A buffer rendered in light space is sometimes referred to as a reflective shadow map RSM as it typically contains data relevant to indirect illumination.

Ideally when calculating the indirect illumination of a pixel in screen space every pixel in light space or in the RSM would be considered. Practically considering every pixel would be computationally expensive and unnecessary. Light space pixels are typically sampled and the number of small area light sources limited. Some implementations further reduce the number of small area light sources considered by using interpolation. A common approach is to project the illuminated pixel into light space and sample nearby small area light sources. The idea being that nearby pixels in light space are generally nearby in screen space and are therefore most likely to reflect and contribute light to the pixel being illuminated. The light contribution of each small area light source sample can then be determined based on a variety of light space RSM and camera view G buffer data including position depth surface normal color energy flux material parameters and others. The contributions are accumulated for each pixel in screen space producing an indirect illumination image.

This procedure which assumes a single light source for the scene can be repeated for every light source. Additionally the direct illumination of each light source can be accumulated for each pixel in screen space. These accumulations can all be combined and processed to produce a realistic global illumination image. Processing may include interpolation up sampling down sampling blurring normalizing and a variety of other processes.

It is realized herein the sampling process is a significant limitation of conventional indirect illumination algorithms. Each light space pixel is represented in a RSM in memory as a texel. Likewise each screen space pixel is represented in memory as a texel in a camera view G buffer. As nearby light space pixels are sampled texels are fetched from memory. The RSM and camera view G buffers are initially rendered into one block of memory where they remain for as long as is needed for rendering that frame. When texels are fetched from the one block they are moved into a second smaller block known as a texture cache. When compared to retrieving G buffer data or RSM data from the one block retrieving from the texture cache is much faster. Once a texel is in the texture cache the latency of subsequent fetch operations to this texel or to neighboring texels is reduced. However the capacity of the texture cache is limited and the random sampling often employed in indirect illumination algorithms results in cache trashing. For example consider sampling and fetching about adjacent pixels in the RSM. Random sampling of the full resolution RSM about the adjacent pixels results in fetching of non adjacent texels for indirect illumination processing.

It is realized herein the G buffers and RSM rendered for indirect illumination can be restructured into reduced resolution sub buffers and sub RSMs and the full resolution images restructured into reduced resolution sub images. This allows the same amount of data to be represented in interleaved sub images each containing a fraction of the pixels and the sub buffers and sub RSMs each containing a fraction of the texels of the full resolution. It is further realized herein that as each sub image is sampled the texture cache hit rate is improved for fetching data from the sub buffers and sub RSMs. Given the sub images sub buffers and sub RSMs indirect illumination sub images can be generated and interleaved to produce a full resolution indirect illumination image. Alternatively the sub RSMs and sub images can be paired with a full resolution camera view G buffer to use in computing indirect illumination. It is also realized herein that rendering from the vantage point of the light source is not necessary as indirect illumination can be calculated based on data rendered from any point of view including the camera view screen space . However rendering in light space and restructuring does yield reliably good sub RSMs and sub images that produce physically plausible indirect illumination.

It is also realized herein that in certain embodiments each sub RSM pixel is drawn from the full resolution RSM at irregular intervals. This shuffling of pixels in the full resolution image before restructuring can introduce useful noise that helps hide structured artifacts.

It is realized herein that further latency and memory bandwidth improvements can be made by carrying out processing on indirect illumination sub images as opposed to processing higher resolution images. A common stage of indirect illumination is to blur or smooth the accumulated light. Applying blur or filtering the sub images it is realized herein smoothens the accumulated light while preserving detected geometric discontinuities. One example of such filtering is cross bilateral blurring which uses per pixel data to compute weights for averaging values of nearby pixels. Cross bilateral blurring can use color depth normal and other data from the light space and camera view sub buffers. Cross bilateral blurring can also be applied multiple times for example applying a cross bilateral filter horizontally to the image and then applying a cross bilateral filter vertically to the resulting image. The blurred indirect illumination sub images can then be interleaved into a higher resolution indirect illumination image. Additionally it is realized herein the higher resolution indirect illumination image can be further blurred for instance by applying yet another cross bilateral filter to the higher resolution indirect illumination image.

It is also realized herein that a direct illumination image can be rendered from the camera view G buffer that can be combined with the indirect illumination image provided the respective resolutions match. Cross bilateral up sampling can be used to bring the resolution of one image up to the other. For example applying cross bilateral up sampling to the higher resolution indirect illumination image to bring it up to the full resolution of the camera view G buffer.

Before describing various embodiments of the processor and method for rendering indirect illumination introduced herein a computing system within which the processor or method maybe embodied or carried out will be described.

As shown the system data bus connects the CPU the input devices the system memory and the graphics processing subsystem . In alternate embodiments the system memory may connect directly to the CPU . The CPU receives user input from the input devices executes programming instructions stored in the system memory operates on data stored in the system memory and configures the graphics processing subsystem to perform specific tasks in the graphics pipeline. The system memory typically includes dynamic random access memory DRAM employed to store programming instructions and data for processing by the CPU and the graphics processing subsystem . The graphics processing subsystem receives instructions transmitted by the CPU and processes the instructions in order to render and display graphics images on the display devices .

As also shown the system memory includes an application program an application programming interface API and a graphics processing unit GPU driver . The application program generates calls to the API in order to produce a desired set of results typically in the form of a sequence of graphics images. The application program also transmits zero or more high level shading programs to the API for processing within the GPU driver . The high level shading programs are typically source code text of high level programming instructions that are designed to operate on one or more shading engines within the graphics processing subsystem . The API functionality is typically implemented within the GPU driver . The GPU driver is configured to translate the high level shading programs into machine code shading programs that are typically optimized for a specific type of shading engine e.g. vertex geometry or fragment .

The graphics processing subsystem includes a graphics processing unit GPU an on chip GPU memory an on chip GPU data bus a GPU local memory and a GPU data bus . The GPU is configured to communicate with the on chip GPU memory via the on chip GPU data bus and with the GPU local memory via the GPU data bus . The GPU may receive instructions transmitted by the CPU process the instructions in order to render graphics data and images and store these images in the GPU local memory . Subsequently the GPU may display certain graphics images stored in the GPU local memory on the display devices .

The GPU includes one or more streaming multiprocessors . Each of the streaming multiprocessors is capable of executing a relatively large number of threads concurrently. Advantageously each of the streaming multiprocessors can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying of physics to determine position velocity and other attributes of objects and so on. Furthermore each of the streaming multiprocessors may be configured as a shading engine that includes one or more programmable shaders each executing a machine code shading program i.e. a thread to perform image rendering operations. The GPU may be provided with any amount of on chip GPU memory and GPU local memory including none and may employ on chip GPU memory GPU local memory and system memory in any combination for memory operations.

The on chip GPU memory is configured to include GPU programming code and on chip buffers . The GPU programming may be transmitted from the GPU driver to the on chip GPU memory via the system data bus . The GPU programming may include a machine code vertex shading program a machine code geometry shading program a machine code fragment shading program or any number of variations of each. The on chip buffers are typically employed to store shading data that requires fast access in order to reduce the latency of the shading engines in the graphics pipeline. Since the on chip GPU memory takes up valuable die area it is relatively expensive.

The GPU local memory typically includes less expensive off chip dynamic random access memory DRAM and is also employed to store data and programming employed by the GPU . As shown the GPU local memory includes a frame buffer . The frame buffer stores data for at least one two dimensional surface that may be employed to drive the display devices . Furthermore the frame buffer may include more than one two dimensional surface so that the GPU can render to one two dimensional surface while a second two dimensional surface is employed to drive the display devices .

The display devices are one or more output devices capable of emitting a visual image corresponding to an input data signal. For example a display device may be built using a cathode ray tube CRT monitor a liquid crystal display or any other suitable display system. The input data signals to the display devices are typically generated by scanning out the contents of one or more frames of image data that is stored in the frame buffer .

Having described a computing system within which the processor or method for rendering indirect illumination may be embodied or carried out various embodiments of the processor and method will be described.

GPU includes a buffer restructurer an indirect illumination computer an interleaving circuit a smoothing filter and a direct illumination computer . Buffer restructurer is configured to gain access to memory via data bus and restructure RSM into sub RSMs through N. In certain embodiments buffer restructurer is further configured to restructure camera view G buffer into camera view sub buffers through N. Indirect illumination computer is configured to approximate one bounce indirect illumination for each pixel represented in camera view G buffer . Each pixel is projected to a light space position about which nearby RSM pixels are sampled. Each RSM pixel sampled is considered a small area light source that potentially contributes light. Indirect illumination computer uses data in sub RSMs through N and in camera view sub buffers through N to compute the sampled pixels contribution and accumulate an indirect illumination value for each screen space pixel yielding indirect illumination sub images. In alternate embodiments indirect illumination computer uses data in light space sub buffers through N with the full resolution data in camera view G buffer to form the indirect illumination sub images.

The indirect illumination sub images produced by indirect illumination computer are run through smoothing filter which smoothens out the accumulated light while preserving discontinuities where geometric discontinuities are detected. This is known as sub image blurring. The resulting blurred indirect illumination sub images are then interleaved by interleaving circuit to form a higher resolution indirect illumination image. In certain embodiments GPU is configured to apply smoothing filter a second time on the higher resolution indirect illumination image. GPU is operable to repeat this process for each light source in a particular scene.

Direct illumination computer is configured to use data from either camera view G buffer or screen space sub buffers through N to compute direct illumination on each screen space pixel from each light source. The resulting direct illumination image can then be combined with the higher resolution indirect illumination image to form a global illumination image.

In a computing step interleaved sampling is used to sample light space pixels or RSM pixels about a screen space pixel projected into light space. From the sampled light space pixels which are each considered small area light sources a one bounce indirect illumination value is accumulated for the screen space pixel. This is repeated for each pixel in screen space producing indirect illumination sub images. The indirect illumination sub images are blurred at sub image blurring step . In certain embodiments a cross bilateral blurring is first applied horizontally to the indirect illumination sub images and then secondly applied vertically. The blurred indirect illumination sub images are interleaved into a higher resolution indirect illumination image in an interleaving step .

In alternate embodiments a direct illumination image is generated from the data in the camera view G buffer rendered in rendering step . Other embodiments may employ the restructured camera view sub buffers to produce the direct illumination image. The direct illumination image can be combined with the higher resolution indirect illumination image produced at interleaving step .

In other embodiments the higher resolution indirect illumination image may undergo further blurring in addition to that carried out in sub image blurring step . The additional blurring helps smoothen the accumulated light while preserving geometric discontinuities. The method then ends in an end step .

Those skilled in the art to which this application relates will appreciate that other and further additions deletions substitutions and modifications may be made to the described embodiments.

