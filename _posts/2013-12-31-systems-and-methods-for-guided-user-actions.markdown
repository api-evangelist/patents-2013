---

title: Systems and methods for guided user actions
abstract: Systems and methods for guided user actions are described, including detecting a first action performed by a user; gathering information associated with the first action; retrieving a predictive model based on the information; determining an applicability level of the predictive model to the first action, the predictive model suggests a second action; providing the second action in a user interface when the applicability level meets a threshold level; and receiving input from the user selecting the second action or a third action.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519408&OS=09519408&RS=09519408
owner: GOOGLE INC.
number: 09519408
owner_city: Mountain View
owner_country: US
publication_date: 20131231
---
The subject matter discussed herein relates generally to data processing and more particularly to systems and methods for guided user actions.

Users frequently create content such as new photos videos and posts for sharing with family friends acquaintances and other users. However the sharing process can be cumbersome. For example even if a user is on an email system or social network with groups or social circles of contacts already set up the user must manually identify and select the user with whom he or she wants to share a particular photo video post or other content.

For example a person e.g. Alice is on a trip taking photos every day. Alice wants to share some of the photos with her family almost daily. Every time she shares photos with her family Alice needs to select the photos to be shared select a method of sharing e.g. via email social network etc. and select her family as the recipient.

The subject matter includes methods for guided user actions including detecting a first action performed by a user gathering information associated with the first action retrieving a predictive model based on the information determining an applicability level of the predictive model to the first action the predictive model suggests a second action providing the second action in a user interface when the applicability level meets a threshold level and receiving input from the user selecting the second action or a third action.

The methods are implemented using one or more computing devices and or systems. The methods may be stored in computer readable media.

The subject matter described herein is taught by way of example implementations. Various details have been omitted for the sake of clarity and to avoid obscuring the subject matter. The examples shown below are directed to structures and functions for implementing systems and methods for guided user action.

Remaining in in the model application portion of system when the user attempts to share data e.g. photo video etc. or take one or more sharing actions system e.g. prediction engine identifies and uses one or more predictive models based on actions to provide the user with one or more predictions which may include one or more action options such as a sharing prediction e.g. share with the user s family by email and one or more other sharing options e.g. share with the user s family by a user selected method share with user selected recipients by a predicted method of sharing through the user s social network account a third sharing option etc. . Actions become part of user history if the user has given permissions to use actions .

The user may provided user input via for example a user interface not shown to select or change one of the predictions or action options. A user may select a sharing prediction predicted by the prediction engine . A user may change some part of the sharing prediction or select one of the other sharing options. The user s selection becomes the final action . In some implementations the final action e.g. the user s selection is provided as feedback to the history . The model application portion of system is further described in below.

Sharing content is used as an example to describe the subject matter herein. It should be noted that the subject matter herein applies to all user actions and is not limited to sharing content. For example one of the user actions may be browsing on the Internet. Many browsers allow users to browse in a private browsing mode e.g. incognito browsing in Chrome InPrivate browsing in Internet Explorer Private Browsing in Firefox and Safari .

The model generation portion or system may learn from a user s browsing habits and history to generate one or more predictive models. For example the user may browse some kinds of websites e.g. websites of schools news organization government etc. in open mode and other kinds of websites e.g. websites relating to personal finance health online shopping etc. in private mode.

When the user starts browsing a website of a financial institution system may predict based on one of more models that the user may want to browse in private mode and provide the prediction in one of the options. The user may accept that prediction and start browsing in private mode. If the user starts browsing in another mode or changes any part of the prediction feedback of the user s actions or selections is provided back to system e.g. history to fine tune the system e.g. machine learning engine and or models .

As used herein information about content or action or IACA is any information about content any information about one or more actions taken in association with the content or both. As used herein content is any digital or digitized content. Content is any collection of information represented in digital form e.g. represented in binary data . Examples of content include but are not limited to one or more files document images videos audios posts communication messages e.g. emails short message tests video messages audio messages etc. any combination thereof games any portion thereof and any combination thereof.

As used herein information about content is any information associating with the content. The information about content can be metadata which includes but is not limited to application metadata e.g. metadata defined in a language or a file format such as HTML HyperText Markup Language JPEG Joint Photographic Experts Group etc. descriptive metadata e.g. description of a resource for identification and retrieval such as file name title author and abstract etc. structural metadata e.g. relationships within and among object such as paragraphs pages chapters etc. administrative metadata e.g. for managing resources such as versioning timestamps access control storage directories or locations etc. . This information is only used in the example implementation with the consent of the user.

In some example implementations the information about content includes any data recorded or generated about the content. For example the information may include a webpage e.g. the uniform resource locator or URL of the webpage visited by a user the last webpage visited by the user e.g. the referrer in HyperText Transfer Protocol or HTTP the time when the webpage is visited the location of the user when the webpage is visited the mode of a tool such as the private mode of a browser the type of the webpage whether the webpage requires authentication etc.

The examples above regarding the webpage and other examples herein in connection with a user are described with the assumption that the implementations obtain the user s consent for recording the described information. If no consent is given by the user in connection with apiece of information that piece of information is not recorded. In addition a user may delete data in the user s history or the entire history .

Other examples of data recorded or generated about the content include but are not limited to user generated device generated and application generated information. For example user generated information includes information generated by any user or administrator. A user may provide description feedback and or comments about some content. An administrator may record an incident about some content. Device generated information may include for example type of device resources included in the device applications used to open the content states of the device etc.

Application generated information may include for example text information of an image. The application may be analyzing an image e.g. pixel data metadata and or vector data and generate text information about the image. For an image of a picnic in the park for example the generated text data may include names or identities of the people in that picture or video e.g. from facial recognition description of the image e.g. picnic party in a park with trees and grass drinking sodas from content analysis and metadata e.g. the image is taken by a certain model of camera using a certain f stop in a certain image resolution etc. .

In some example implementations the information about content includes one or more fields of the content that is structured. For example if the content is information stored in or retrieved from a database any fields of the content can be used as information about content. If the content is an email message and fields e.g. To From Subject CC BCC body etc. can be used as information about content.

As used herein information about one or more actions taken in association with the content is any information associating with actions or information about actions. Information about actions includes but is not limited to history usage information e.g. usage records or usage logs information about the network system devices operating systems applications modules software etc. used to perform the actions information about the environment date time location when the actions are performed and other available information e.g. recipient information languages of the application used to perform the actions etc. . The information about actions can overlap the information about content in some implementations. For example whenever a user sets sharing permissions on some content e.g. a photo video post link the user s permissions are associated with the content e.g. stored the permissions as metadata . In some implementations a user s environment may be recorded with consent given by the user. For example identities of other known users in the vicinity by tracking their devices or locations of the user.

Referring to previous actions e.g. actions include for example the information about content or action IACA as shown in Table 1.

Table 1 shows an implementation that considers for example eight pieces or fields of IACA rows 1 7 . An implementation can consider and IACA information e.g. any fields and any number of fields . The fields can be different based on content. For example action includes an URL as a target and a browsed privately action for the data type of a link e.g. a reference that are not included or used in actions and with data types of photo and video.

The IACA information shown in actions are only examples IACA. There may be different and or other IACA fields. For example there may be an IACA device field not shown for providing device information such as a phone tablet laptop or another device.

Even for a given IACA field such as the location field the may be different or other information. For example for the location field there may be different or other kinds of location information such as latitude and longitude inside or outside of a certain thing e.g. building in a private space or public space. There may be different ways of capturing relevant location information that can be independent of on another e.g. can be implemented to any combination or all of location information for using in generating the predictive models .

The machine learning which can be a system a device an application or a software module may be implemented as a black box to process user history to produce predictions or predictive models . Machine learning may be implemented in any way to execute instructions of any one or more algorithms. One of the algorithms for example may be processing user history e.g. actions to generating shared with and or shared by models with a threshold of for example 50 e.g. generate a model if the threshold of 50 or above is met .

After actions are processed machine learning generates for example the example models shown in Table 2 for predicting who to share content with and or how to share the content by based on one or more attributes of the content.

Table 2 shows that for example three models or predictive models M1 M3 are generated from history e.g. actions . For clarity in illustration four actions are shown and described. M1 may be generated using the IACA of actions and . M2 and M3 each may be generated using the IACA of only one action or respectively. In some implementations a model is generated only if the data set that supports the model i.e. the IACA used to generate the model is of a certain sample size. For example in the example of Table 2 if there is a data set size or sample size requirement of 2 models M2 and M3 will not be generated due to insufficient of data set of 1. Model M1 will still be generated due to the data set size of 2 actions and . In some implementations predictive strength may be estimated based on sample size. Predictive strength may also be estimated by one or more algorithm used by system .

The models M1 M3 as well as other models described herein are only examples. In actual implementation there may be different and or other models. In addition different models may be combined into fewer models. Yet in other implementations models are conceptual models or dynamic models generated on the fly.

As described above machine learning may be implemented as a black box that provides one or more predictions based on user history . One or more of any number of algorithms may be dynamically applied in this black box. What is common is that data goes in and models come out . In some implementations instead of or in addition to models machine learning produces output for prediction generator to generate one or more predictions. For example in some implementations some of models M1 M3 may be generated. For example system may be implemented with different pipelines or processes for different domains. One process pipeline may be for browsing e.g. using one or more browsers another pipeline may be sharing on a social network a third pipeline may be relating to email communication one or more pipelines may be based on content type e.g. a pipeline for photos one pipeline for audio and or video etc. .

For example sharing photos the machine learning algorithm will determine internally what is relevant based on the history data it receives and provide output to prediction generator to produce the predictions. Similarly for other processing domains such as browsing a different machine learning algorithm will determine internally what is the relevant browser setting to use based on the history data machine learning processes.

In actual implementations history contains information of a much bigger set of usage history and or user actions. History is likely to grow over time and the amount of information about content or action IACA associated history also grows larger. A bigger data set in general leads to more accurate models being generated. In implementations that include a data set size when the data set is sufficiently large e.g. at least the required data set size the system can start to make user action predictions based on previous actions e.g. generating and applying predictive models based on history .

As another example with a user Alice if 100 of Alice s photos contain Alice s relative Alice may have shared 90 of the 100 photos Alice s family online social circle e.g. one or more contacts put in a group with a label family and shared 10 of the 100 photos with Alice s co worker online social circle. The system as authorized by Alice determines or learns that Alice tends to share photos of Alice s relative with Alice s family online social circle e.g. machine learning generates a model M4 based on that learning . If Alice has taken 50 photos at home Alice may have shared 45 of the 50 photos with Alice s family online social circle and 5 of the 50 photos with Alice s extended friends online social circle. The system learns that Alice tends to share photos taken at home with Alice s family online social circle e.g. machine learning generated a model M5 based on that learning . The result is that in aggregate Alice has a multi dimensional model e.g. M4 and M5 that is able to associate different kinds of IACA e.g. location time of day identities of people etc. with different sharing preferences.

In some implementations predictive models may be generated based on privacy preferences of a user. These predictive models or privacy preferences models can be used to make predictions of desired privacy sharing setting or preferences. For example Alice takes a picture of Alice s relative at 3 30 PM in the park and wants to share that the 3 30 picture . The system analyzes past sharing actions e.g. history with similar IACA. The system learns that and creates one or more models to the effect of Alice tends to share pictures and videos of Alice s relative with the family online social circle model M6 except when the pictures and videos are taken in public in which case Alice shares with extended friends model M7 . Media e.g. pictures and videos captured in the afternoon tends to be shared more widely model M8 . In the example of the 3 30 picture the privacy preferences models M6 and M7 or M8 lead to a prediction that Alice would want to share the 3 30 picture of her relative with her family M6 and extended friends M7 park in public or M8 3 30 PM afternoon online social circles since the picture was captured in a public place during the day. All of the foregoing is performed with the consent of the user.

Depending on implementations different algorithms can be used to generate models which may be based on privacy preferences of a user. For example the machine learning black box if data in predictions out can function in many different ways using different algorithms. The algorithms that produce the most accurate predictions e.g. based on final actions may be retained or floated to the top of an algorithm application priority queue. The user can decide at any point whether or not to set their privacy preference e.g. consent so as to participate in this example implementation.

If prediction engine is implemented at block IACA associated with action and or the corresponding photo e.g. content is extracted. Some example fields of the extracted IACA may include a data type of photo a timestamp a location of home and an identification of a person on the photo being the relative. At block one or more models are identified or selected based on the extracted IACA. For example model M1 shown in Table 2 may be identified based on the data type of photo the location of home and or the people being a family member e.g. relative being the family member in this example implementation .

In some implementations one or more models may be identified based on actions or potential actions such as social network sharing emailing browsing etc. In some implementations models may be selected based on both actions and data type such as sharing photos on a social network sharing audio content on a social network etc.

If more than one model is identified at as in the case of the 3 30 picture above with models M6 M8 a determination is made at block to use one or more of the identified models. One example implementation of block may involve assigning weights to one or more pieces or fields of the extracted IACA. For example data type can be assigned a weight of X location a weight of Y and people a weight of Z. If each X Y Z is enough to meet a threshold level then a model with the highest weight is chosen. If it takes the combination of two or more weights X Y and Z to meet the threshold level then the models that contribute to the sum of weights that meet the threshold level are chosen. If more than one prediction can be predicted from the chosen models the predictions may be presented to the user in order of decreasing weights or sums of weights as shown in screenshot B which is described below. In some implementations the determination is done not using weights but using different factors which can be any factors.

If prediction generator is implemented prediction generator may process existing output from machine learning or may request machine learning to provide output on demand or on an as needed basis. For example prediction generator may process actions as described in box . Instead of box prediction generator may request machine learning to generate output from history based on IACA of actions . If more than one prediction is generated the predictions may be prioritized ranked or reduced. Machine learning and prediction generator may function as a black box predictive engine that continue to grow based on history and feedback from final action . In some implementations both and may be implemented with different pipelines or processes for different domains. For example prediction generator may be implemented in the domain of sharing photos and prediction engine may be implemented in the domain of browsing the Internet.

At block one or more predictions may be presented to the user e.g. Alice . In some implementations a user may decide e.g. through configuration or setting that if one of the predictions meets a certain level e.g. has a weight or sum of weights of 80 or 90 that prediction may be automatically selected and used without the input of a consenting user e.g. automatically shares the 3 30 picture to Alice s family online social circle without presenting the predictions Alice for selection although Alice has previously consented to use of the system . If one or more predictions are presented to the user at the user may provide input using a user interface not shown to identify or select one of the predictions. The user may also provide input e.g. who to share content with and or how to share the content by etc. that is not in any of the predictions. The user s input may be provided as feedback to for example history in . Machine learning may incorporate or account for the user s feedback in generating models and or to changes one or more models already generated. In some implementations predictive models may be managed by a manager that changes or deletes one or more models based on the user feedback.

As with the foregoing example implementations the user remains in control of whether this feature is used e.g. consent and can at any time decide to not use this feature.

At block the final action is taken such as sharing the 3 30 picture to Alice s family online social circle on a social network sending a document by email to the identified recipients switching or using the private mode of a browser to visit a website etc.

The example shared by predictions in screenshot B are Bluetooth Soc network Z.com E mail and others which are hidden in the See all submenu. The shared by predictions may be presented in the order of highest to lowest of predictions certainties or weight scores. For example Bluetooth may have a score of 90 Soc network Z.com may have a score of 88 and E mail may have a score of 65 . Other predictions meeting the minimal requirement threshold e.g. 50 may be hidden in the See all submenu.

In screenshot B for example the user provides input to select the Soc network Z.com option which may be provided as a feedback back to the system as described above. The user s selection leads to screenshot C where the shared with predictions may be presented to the user. Share by Soc network Z.com is shown and the user in this example is John XYZ. One prediction is shown predicting that John XYZ would want to share the photo with his Family online social circle . John can enter more recipients and or replace the Family online social circle which may be provided as a feedback back to the system as described above. As disclosed above the example implementation is only performed with the consent of the user in this case John XYZ.

In screenshot C the prediction of sharing with John s Family online social circle is a correct default prediction based on John not changing the prediction. When John presses the Share button or widget the photo taken in screenshot A is shared with John s Family online social circle on Soc network Z.com.

In some implementations the shared by predictions and the shared with predictions may be presented together in one user interface or screen. For example in screenshot B next to each shared by options may be one or more shared with options.

Depending on implementations different devices or different applications of one device can make use of predictions in different ways. For example a camera application can pre populate one or more sharing settings with predicted privacy preferences e.g. family online social circle . In some implementations predictions or privacy preference may offered as shortcuts and or suggestions e.g. in addition one or more default settings or predictions which allow the user to access with a single tap or click. In all example implementations the user may decide to not participate or consent.

In some implementations user action prediction may be implemented to apply to batch sharing e.g. sharing or emailing of media . For example if Alice takes 10 photos of Alice s relative then takes 5 photos of a co worker then takes 10 more photos of Alice s relative an implementation of user action prediction may prompt Alice to first share all 20 photos of Alice s relative with Alice s family online social circle on a social network and then prompt Alice to send the 5 photos of Alice s co worker by email to Alice s team at work using one or more email addresses . In all example implementations the user remains in control of participation and may decide to consent or not consent at any time.

As described above user action prediction can be implemented to apply to any content using any application and in connection with any user action. For example privacy preferences models based on Alice s browsing may be generated based on Alice s browsing habits and history. The models may be used every time Alice is browsing. One model may indicate that when Alice browsed some kinds of websites e.g. health information websites she tends to browse in private mode of the browser. Applying the model whenever Alice starts browsing a kind of website that Alice typically browses in private mode and Alice is not browsing in that mode the browser may either suggest to Alice to use the private mode or automatically enable the private mode based on Alice s configuration or setting on the browser. As noted above Alice may decide to consent or not consent.

At one or more predicted actions from the models determined to be used based on the applicability levels meeting a threshold level are provided or presented in a user interface. At input from a user is received selecting one predicted action or another predicted action or modifying a predicted action or providing an action not predicted . The action selected in is performed. The user s selection or input may be provided as feedback to the system for example to improve the system e.g. accuracy performance predictions etc. .

In some examples process may be implemented with different fewer or more blocks. Process may be implemented as computer executable instructions which can be stored on a medium loaded onto one or more processors of one or more computing devices and executed as a computer implemented method.

An example of one or more devices may be computing device described below in . Devices may include but are not limited to a computer e.g. a laptop computing device a mobile device e.g. smartphone or tablet a television a device associated with a vehicle a server computer computing devices storage and .

In some implementations devices may be considered user devices such as devices used by users to create content and or issue requests such as sharing content on a social network. Devices may be devices associated with service providers e.g. used by service providers to provide services and or store data such as webpages text text portions images image portions audios audio segments videos video segments and or information thereabout .

For example a user e.g. Alice may access view and or share content or a photo using user device on a social network supported by one or more devices . Device may be running an application that implements guided user actions or user action prediction. After Alice takes a photo with device as shown in Alice taps the Share button . The application that implements guided user actions used models generated based on Alice s history data to provide one or more predictions as shown in screenshots B C. Alice taps the Share button to accept the default or predicted sharing action which may include who to share the photo with and how to share the photo by e.g. using what application or service to share the photo .

Computing device can be communicatively coupled to input user interface and output device interface . Either one or both of input user interface and output device interface can be a wired or wireless interface and can be detachable. Input user interface may include any device component sensor or interface physical or virtual that can be used to provide input e.g. buttons touch screen interface keyboard a pointing cursor control microphone camera braille motion sensor optical reader and or the like . Output device interface may include a display television monitor printer speaker braille or the like. In some example implementations input user interface and output device interface can be embedded with or physically coupled to the computing device . In other example implementations other computing devices may function as or provide the functions of input user interface and output device interface for a computing device .

Examples of computing device may include but are not limited to highly mobile devices e.g. smartphones devices in vehicles and other machines devices carried by humans and animals and the like mobile devices e.g. tablets notebooks laptops personal computers portable televisions radios and the like and devices not designed for mobility e.g. desktop computers other computers information kiosks televisions with one or more processors embedded therein and or coupled thereto radios and the like .

Computing device can be communicatively coupled e.g. via I O interface to external storage and network for communicating with any number of networked components devices and systems including one or more computing devices of the same or different configuration. Computing device or any connected computing device can be functioning as providing services of or referred to as a server client thin server general machine special purpose machine or another label.

I O interface can include but is not limited to wired and or wireless interfaces using any communication or I O protocols or standards e.g. Ethernet 802.11x Universal System Bus WiMax modem a cellular network protocol and the like for communicating information to and or from at least all the connected components devices and network in computing environment . Network can be any network or combination of networks e.g. the Internet local area network wide area network a telephonic network a cellular network satellite network and the like .

Computing device can use and or communicate using computer usable or computer readable media including transitory media and non transitory media. Transitory media include transmission media e.g. metal cables fiber optic signals carrier waves and the like. Non transitory media include magnetic media e.g. disks and tapes optical media e.g. CD ROM digital video disks Blu ray disks solid state media e.g. RAM ROM flash memory solid state storage and other non volatile storage or memory.

Computing device can be used to implement techniques methods applications processes or computer executable instructions in some example computing environments. Computer executable instructions can be retrieved from transitory media and stored on and retrieved from non transitory media. The executable instructions can originate from one or more of any programming scripting and machine languages e.g. C C C Java Visual Basic Python Perl JavaScript and others .

Processor s can execute under any operating system OS not shown in a native or virtual environment. One or more applications can be deployed that include logic unit application programming interface API unit input unit output unit models management actions processing prediction engine and inter unit communication mechanism for the different units to communicate with each other with the OS and with other applications not shown . For example models management actions processing and prediction engine may implement one or more processes described and shown in . The described units and elements can be varied in design function configuration or implementation and are not limited to the descriptions provided.

In some example implementations when information or an execution instruction is received by API unit it may be communicated to one or more other units e.g. logic unit input unit output unit models management actions processing and prediction engine . For example after input unit has detected a user action prediction engine process that action and interfaces with models management to retrieve one or more predictive models to provide one of more predicted actions. The models may be generated by actions processing based on previous actions or user history. Input unit may then provide input from a user selecting or modifying one of the predicted actions. Output unit then performs the final action based on the user s input.

In some instances logic unit may be configured to control the information flow among the units and direct the services provided by API unit input unit output unit models management actions processing and prediction engine in some example implementations described above. For example the flow of one or more processes or implementations may be controlled by logic unit alone or in conjunction with API unit .

In situations in which the systems discussed here collect persona information about users or may make use of personal information the users may be provided with an opportunity to control whether programs or features collect user information e.g. information about a user s social network social actions or activities profession a user s preferences or a user s current location or to control whether and or how to receive content from the content server that may be more relevant to the user. In addition certain data may be treated in one or more ways before it is stored or used so that personally identifiable information is removed. For example a user s identity may be treated so that no personally identifiable information can be determined for the user or a user s geographic location may be generalized where location information is obtained such as to a city ZIP code or state level so that a particular location of a user cannot be determined. Thus the user may have control over how information is collected about the user and used by a content server.

Although a few example implementations have been shown and described these example implementations are provided to convey the subject matter described herein to people who are familiar with this field. It should be understood that the subject matter described herein may be implemented in various forms without being limited to the described example implementations. The subject matter described herein can be practiced without those specifically defined or described matters or with other or different elements or matters not described. It will be appreciated by those familiar with this field that changes may be made in these example implementations without departing from the subject matter described herein as defined in the appended claims and their equivalents.

