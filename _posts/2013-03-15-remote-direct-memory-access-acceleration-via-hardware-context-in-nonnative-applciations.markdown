---

title: Remote direct memory access acceleration via hardware context in non-native applciations
abstract: Provided are techniques generating a data structure, wherein the data structure specifies both a specified size of a memory space to allocate within an application and a virtual address within the application to locate a data path transmission queue; including within a verb for allocating the data path transmission queue the defined data structure; in response to a call of the verb, allocate, within the application, the data path transmission queue of the specified size and at the virtual location; in response to a request to transmit control data, employ a remote direct memory access (RDMA) transmission path; and, in response to a request to transmit data, employ the data path transmission queue rather than an RDMA transmission path.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09258365&OS=09258365&RS=09258365
owner: International Business Machines Corporation
number: 09258365
owner_city: Armonk
owner_country: US
publication_date: 20130315
---
The claimed subject matter relates generally to computing services and more specifically to providing non native applications enhanced access to remote direct memory access RDMA operations.

Remote direct memory access RDMA is a mechanism for direct memory access communication from a userspace to remote memory resources. One standard for RDMA is OpenFabrics Enterprise Distribution OFED which is written to be C C compatible. Applications written in higher level languages such as JAVA are typically required to translate native verbs to OFED verbs via tools such as JAVA native interface JNI . Such applications are typically be written against backward compatible application programming interfaces APIs such as Sockets Direct protocol SDP Internet Small Computer System Interface iSCSI extension for RDMA iSER Small Computer System Interface SCSI RDMA protocol SRP Network File System NFS over RDMA NFSoRDMA and so on.

As the Inventors herein have realized current approaches such as those described above for enabling a higher level language such as JAVA access to RDMA present some disadvantages. For example current approaches incur a kernel context switch cost and tend to provide no statistically significant benefit with respect to small messages. Therefore small messages are typically addressed via a copy whereas large messages are registered on the fly when the registration cost is outweighed by the benefit of large data transfers.

Provided are mechanisms whereby an application written in any language can access the highest theoretical performance of an underlying RDMA device including small message transfers. Non native applications seeking the lowest latency can perform hardware HW context specific operations natively when a translation cost outweighs latency requirements. The disclosed technology optimizes the development of non native applications for exploiting RDMA.

One focus of the disclosed technology is optimizing the development of non native applications for exploitation of RDMA. For example as the Inventors herein have realized when jVerbs develops a user space component in JAVA there is a high cost for the development and maintenance effort. This disclosure describes techniques that may bound the development overhead for such applications to a minimum. This is achieved by having an application perform control path operations via standard calls through JNI or similar translations such that development and maintenance cost for the jVerbs application is primarily in the datapath. A significant reduction in development and operational cost is thus realized as the application is then primarily responsible for HW specific descriptor encoding decoding.

Provided are techniques generating a data structure wherein the data structure specifies both a specified size of a memory space to allocate within an application and a virtual address within the application to locate a data path transmission queue including within a verb for allocating the data path transmission queue the defined data structure in response to a call of the verb allocate within the application the data path transmission queue of the specified size and at the virtual location in response to a request to transmit control data employ a remote direct memory access RDMA transmission path and in response to a request to transmit data employ the data path transmission queue rather than an RDMA transmission path.

This summary is not intended as a comprehensive description of the claimed subject matter but rather is intended to provide a brief overview of some of the functionality associated therewith. Other systems methods functionality features and advantages of the claimed subject matter will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational actions to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Turning now to the figures is a block diagram of a computing architecture that may implement the claimed subject matter. A computing system includes a central processing unit CPU coupled to a display a keyboard and a pointing device or mouse which together facilitate human interaction with elements of architecture and computing system . Also included in computing system and attached to CPU is a computer readable storage medium CRSM which may either be incorporated into client system i.e. an internal device or attached externally to CPU by means of various commonly available connection devices such as but not limited to a universal serial bus USB port not shown . CRSM is illustrated storing an operating system OS a JAVA native interface JNI and an application that is configured in accordance with the claimed subject matter. Components and and their relationship with the claimed subject matter are described in more detail below in conjunction with .

Computing system and CPU are connected to the Internet which is also connected to a server computer or simply server. . Server is coupled to a CRSM . Computing system is also coupled to a local area network which is coupled to a second computing system . Computing system is coupled to a CRSM . Although in this example computing system and server are communicatively coupled via the Internet they could also be coupled through any number of communication mediums such as but not limited to a LAN such as LAN . In the following description application is used as one example of a program that may take advantage of the disclosed technology. It should be noted there are many possible configurations of computing system architectures and computing systems that may implement the claimed subject matter of which architecture and computing system are only simple examples.

Bus represents one or more of any of several types of bus structures which for the sake of simplicity are not shown including a memory bus or memory controller a peripheral bus an accelerated graphics port and a processor or local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnects PCI bus.

Memory typically includes a variety of computer system readable media. Such media may be any storage media that is accessible CPU via bus and includes both volatile and non volatile media. Computing system and memory may also further include other volatile non volatile computer system storage media. In this example memory includes random access memory RAM and cache memory or simply cache . RAM is illustrated as separated into user space and kernel space . RAM is also illustrated storing in user space an application which is a copy of program stored on CRSM . In other words program corresponds to logic associated with program that has been loaded into RAM for execution on CPU . Program may be stored in one or more locations in memory including RAM which includes user space US and kernel space KS and may also be paged out to other storage media such as but not limited to CRSM . Within kernel space are buffers . Possible components of buffers are explained below in conjunction with .

Kernel mediated communication is typically multiplexed with both protocol and buffer L3 and L4 controlled by a host CPU which in the example is CPU . Such a configuration provides low bandwidth for small messages and a high power consumption cost. Contention among shared resources is typically controlled by use of buffer L3 and L4 and locks not shown . One feature of kernel mediated communication is that First Failure Data Capture FFDC is readily available.

Although the use of buffers and NICs should be familiar to those with skill in the relevant arts the claimed subject matter necessitates that buffers and and NIC be modified and that L2 and L3 be newly designed. In other words new mechanisms tar kernel buffer and protocol management are needed to use RDMA in conjunction with the claimed subject matter. Modifications in accordance with the claimed subject matter are explained in more detail below in conjunction with .

In contrast to kernel mediated communication RDMA communication has lower memory bus bandwidth consumption higher bandwidth for small message sizes lower utilization of CPU lower power consumption and higher processing system capacity. However RDMA communication has a one sided data placement mechanism and there is no FFDC readily available for L3 and L4 . The claimed subject matter necessitates that buffer and RNIC be modified and that cache buffers and be newly designed. Modifications in accordance with the claimed subject matter are explained in more detail below in conjunction with .

User processes such as hut not limited to a kernel direct access programming library kDAPL a session description library SDP and Internet Small Computer System Interface iSCSI extensions for RDMA iSER also access MID kernel . CDLI access HW specific drivers via an ent core . OFED kernel access HW specific drivers via a RDMA core . Finally HW specific drivers provide access in this example to RNIC in HW and thereby access to Internet and LAN . The claimed subject matter necessitates that ent core and HW specific be modified and that librdrma HW specific and RDMA core be newly designed. Modifications in accordance with the claimed subject matter are explained in more detail below in conjunction with .

In this example uJverbs access HW specific via a data path and OFED API via a control path . OFED API accesses libRDAM via a control path . In other words rather than a single path for both control and data messages there are different paths and for data and control messages respectively. In this manner an application not shown may perform control path operations via standard calls through JNI or similar translations such that development and maintenance cost for a jVerbs application is primarily in the datapath. A significant reduction in development and operational cost is thus realized as the application is then primarily responsible for HW specific descriptor encoding decoding.

To implement this technology an application which in this example is app is provided means to generate application specific memory within app memory space specifically a Send Queue SQ a Received Queue RQ and a Completion Queue CQ .

The flowing CODE EXAMPLE 1 illustrates modifications to a standard ibv cq data structure used as input to various verbs that control CQ by enabling attributes of CQ to be defined 

In the example above line 6 has been added to define attributes associated with CQ . Extensions to the verb ibv create cq are then added to enable a caller to provide a specific size and virtual address corresponding to the CQ when it is created. In addition specific verbs e.g. JAVA jVerbs that are modified in this example to take advantage of the modified data structure iby cq described above include but are not necessarily limited to ibv create cq ibv poll cq ibv req notify cq and ibv cq event.

Line 4 of the following CODE EXAMPLE 2 illustrates additions to a standard iby qp structure used as inputs to verbs that control SQ and RQ by enabling attributes associated with SQ and RQ to be defined 

Process starts in a Begin Establish Queue block and proceed immediately to a Determine Hardware HW Size Requirements . During processing associated with block a determination is made as to the size of queue need for a particular hardware device for which a queue is to be created. During processing associated with a Determine Location in Application block a determination is made as to a particular location within an applications memory space that may be utilized by the queue being established. In one embodiment information about both the size and the location of the queue to be created may be supplied by the application. During processing associated with a Populate Data Structure block a data structure is generated to store the values calculated during processing associated with blocks and . In this example if the queue being generated is a control queue the app cq attrs structure shown above at line 6 of CODE EXAMPLE 1 is populated. If the queue being generated is a control queue the app qp attrs structure shown above at line 4 of CODE EXAMPLE 2 is populated.

During processing associated with a Call Queue Create block the data structure populated during processing associated with block is included in a call to a function to create a queue as in CODE EXAMPLE 3 above. During processing associated with a Creation Successful block a determination is made as to whether or not the call made during processing associated with block was successful. If not control proceeds to a Throw Exception block . During processing associated with block appropriate measures are taken to notify the administrator that initiated process is notified so that remedial actions may be taken. In one embodiment a JAVA native interface JNI callback is employed. If queue creation was successful control proceeds to an Employ Queue block . During processing associated with block the created queue is used for its intended purpose. Finally control proceeds to an End Establish Queue block in which process is complete.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

