---

title: API platform that includes server-executed client-based code
abstract: A technique for providing an API from a server to one of more endpoint devices including receiving a request for data from a endpoint device, retrieving one or more data resources from the data resources available within the server, based upon the request, manipulating the data within the retrieved data resources into a response optimized for the endpoint device, and transmitting the response to the endpoint device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09485305&OS=09485305&RS=09485305
owner: NETFLIX, Inc.
number: 09485305
owner_city: Los Gatos
owner_country: US
publication_date: 20130509
---
This application claims benefit of U.S. provisional patent application Ser. No. 61 644 977 filed May 9 2012 and U.S. provisional patent application Ser. No. 61 794 579 filed Mar. 15 2013 both of which are herein incorporated by reference.

Embodiments of the present invention generally relate to computer science and more specifically to an application programming interface API that includes server executed client based code.

In a traditional API model the network serves as a hard boundary between a client application and an API server tier. The API server tier provides a generalized interface for accessing certain data resources to all types of client applications. Each client application may request these generalized data resources from the API server tier. By providing a generalized interface the traditional API server tier establishes a clear set of rules that allow many different client applications potentially running on dissimilar devices to retrieve the same data resources in the same manner.

Computing devices have proliferated in recent years and many companies would like to provide their content to as many different devices as possible. Oftentimes this results in client applications being built specifically for each device. Across these myriad devices there is a high degree of variability in functionality including from game consoles TVs set top boxes smartphones etc. This variability of functionality results in a divergence in the data resource requirements of the client applications specific to the different devices. For instance different devices may have different memory capacity may require a unique or proprietary format or delivery method or may have different screen real estate sizes. Although a client application may require specific data in a specific format the API server tier only provides the generalized data resources. For instance an API server tier providing access to movie information may respond to all requests for suggested movie titles with a generalized data resource containing 100 movie titles regardless of how many movie titles a particular client application actually displays on a device or what data formats are required by the device. As the number of different types of client applications running on these different devices continues to expand the traditional API model of generalized data resources poses significant development challenges.

Although APIs built with the traditional model may not be optimized for the specific client applications the client applications may extract the data from the generalized data resources. However this data extraction can cause significant inefficiencies. Different client applications may perform large numbers of requests to retrieve the required data which consumes network bandwidth. Furthermore to gather the required content the same or different client applications may request receive and then discard significant amounts of extra data. For instance a client application running on a mobile device may receive 100 movie titles from an API but only display five movie titles so the other 95 movie titles are simply discarded. These inefficiencies may result in network latencies which could cause an application to load or respond slowly.

Furthermore the development and maintenance of a traditional API that supports myriad client applications can become increasingly difficult. As the number of client applications increases the number of different requirements increases. Supporting an increasing number of requirements consumes more development time and resources and or delays client application production. For instance if a new device requires data in a unique format then API development resources have to be diverted to create new data resources for the device. Likewise the production of a client application for the device may be delayed until the API is appropriately updated to accommodate the unique data format.

As the foregoing illustrates there remains a need for more effective techniques for providing data resources optimized for an expanding number of different client applications.

One embodiment of the present invention sets forth a method for providing an API from a server to one of more endpoint devices including receiving a request for data from a endpoint device retrieving one or more data resources from the data resources available within the server based upon the request manipulating the data within the retrieved data resources into a response optimized for the endpoint device and transmitting the response to the endpoint device.

Other embodiments of the present invention include without limitation a computer readable storage medium including instructions that when executed by a processing unit cause the processing unit to implement aspects of the approach described herein as well as a system that includes different elements configured to implement aspects of the approach described herein.

One advantage of the approach described herein is that it allows more efficient interactions between the device and the server since most calls that otherwise would be going across the network can be handled on the server. Wide area network transactions are expensive so reducing the number of network requests improves performance. Another advantage provided by this technique is a distributed nature of API development. Specifically given that UI development teams can create and modify their own server side components independently from the API server this architecture allows them to be much more nimble in development without having server teams dictating interaction and data models being a bottleneck for their development or risking other device implementations with tactical changes in their device specific APIs.

Embodiments of the invention may be used to provide data resources optimized for different client applications. Client applications running on different devices may have diverse data resource requirements. For instance if an API server tier provides access to movie information such as pictures of movie box art then a client application designed for a mobile device with a small display space may require smaller pictures than a client application designed for a TV with a much larger display space. To provide support for both such client applications the API server tier may provide distinct data resources optimized for each client applications.

In one embodiment the client application extends to encompass both code running on the device and the API server tier. The capability to extend a client application across the device and API server tier is accomplished by defining and managing server components that are tightly coupled to individual device platforms. The API server tier enables the creation of endpoints customized for each device. Each endpoint supports data resources specific to the targeted device. The client application is configured to extend from a client application front end running on the device through the network to a client adapter running in the API server tier. The client adapter handles requests to the endpoint from the target device and responds in the most optimal way possible for device. To respond with the request data the client adapter retrieves data from other server components.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details.

The network includes a plurality of network communications systems such as routers and switches configured to facilitate data communication between the API Server the CDN and the endpoint device . Persons skilled in the art will recognize that many technically feasible techniques exist for building the network including technologies practiced in deploying the well known internet communications network.

The UI content servers provide content browsing guides manage account information regarding users of the endpoint device and provide DRM licenses associated with protected content that is viewed by those users.

The CDN comprises one or more computer systems configured to serve download requests for digital content files such as digital video files received from the endpoint device . The digital content files may reside on a mass storage system accessible to the computer system. The mass storage system may include without limitation direct attached storage network attached file storage or network attached block level storage. The digital content files may be formatted and stored on the mass storage system using any technically feasible technique. A data transfer protocol such as the well known hyper text transfer protocol HTTP may be used to download digital content files from the CDN to the endpoint device .

The endpoint device may comprise a computer system a set top box a mobile device such as a mobile phone or any other technically feasible computing platform that has network connectivity and is coupled to or includes a display device and speaker device for presenting video frames and generating acoustic output respectively. The endpoint device may include a client application front end . The client application front end provides a UI that allows a user to browse through and watch digital content files that are served by the CDN . In order to render the UI the client application front end requests and assembles UI content from the API server . A data transfer protocol such as HTTP may be used to transfer UI content from the API Server to the endpoint device .

The API Server includes one or more client adapters an internal API and a fault tolerance layer . The API Server gathers prepares and delivers UI content from the UI content servers to the client application front end . To support the requests for UI content from the client application front end the API Server requests different types of UI content from the different UI content servers . The API server and the UI content servers may use a data transfer protocol such as HTTP and data formats such as XML or JSON to communicate over the network .

Conventionally client code is all code that lives on a given endpoint device while server code is the code that resides on the API server . The divide between the two is traditionally the network border. The client adapter within the API server pushes the border back into the API server . All of the client application front end code on the endpoint device is still client code but some client code also resides and executes on the API server . The client code on the API server forms the client adapter . The client application front end makes a network request to the client adapter residing on the API server which can handle the request in a manner specific to the endpoint device . The request may be for UI content specific to a UI of the endpoint device such as the UI content of the application home screen rather than a generalized data resource.

On the API server the client adapter expands the request from the client application front end to a series of sub requests to the internal API to gather the requested UI content. The client adapter may be a Groovy script where the requests would be java method calls to a Java based internal API . The client adapter may make the sub requests concurrently so that the internal API may process the sub requests in parallel.

The parallel execution of the client adapter sub requests is an important performance factor for the internal API which can affect the performance of the content distribution system . The internal API may implement a functional reactive programming FRP model to provide for concurrent method calls from the client adapter . Following the FRP model the methods provided by the internal API return observables. An observable is a data type that allow a producer the internal API to push UI content to a consumer the client adapter as the UI content becomes available. From the perspective of the client adapter the observables asynchronously emit the requested UI content so the client adapter may make concurrent sub requests and then react as the UI content becomes available. Likewise the FRP model allows the internal API to return the UI content to the client adapter asynchronously so the internal API is able to retrieve and process different UI content from the different UI content servers in parallel.

The UI content is stored within the UI content servers . In response to the sub requests from the client adapter the internal API makes requests to the UI content servers . However the content distribution system may include many UI content servers so at some point communications with one or more UI content server may fail. A failure to retrieve the UI content could potentially jeopardize the functionality of the internal API . Therefore the internal API accesses the UI content servers through the fault tolerance layer . The fault tolerance layer isolates the internal API and thus the client adapter from potential communication failures. To isolate the internal API from these failures the fault tolerance layer may wrap requests to the UI content servers in separate threads. The fault tolerance layer may also implement fallback logic to provide graceful responses to failures such as returning default UI content.

Assuming that the internal API is able to retrieve the requested UI content from the UI content servers the internal API returns the UI content to the requesting client adapter . As discussed the internal API may asynchronously push the UI content to the client adapter through an observable data type. Depending on the responses from the internal API the client adapter may submit subsequent sub requests for additional UI content. The client adapter may also handle errors returned by the internal API . The client adapter may be configured to handle the responses all together or as each sub request returns.

The internal API returns UI content that is generalized and not specific to the endpoint device . The client adapter manipulates the generalized UI content to make the UI content specific to the endpoint device . The client adapter prunes and formats the generalized UI content into a single optimal response for the client application front end . Ideally formatting and interaction models are defined on a per endpoint device type basis. In some cases the system may need to format the data to a proprietary XML structure required by a particular endpoint device . Other endpoint device may want the UI content delivered in different JSON or XML document formats while others may want to receive bits streamed over the network. Once the optimized response includes the requested UI content the client adapter delivers a single data payload across the network to the client application front end .

Upon receipt the client application front end parses the optimized response and may directly populate a UI specific to the endpoint device . As the foregoing illustrates with the client adapter portion of the client application optimizing responses from the API Server the client application is advantageously able to populate a UI from a single response which could reduce the wait time of the user.

Although in the above description the content distribution system is shown with one endpoint device and one CDN persons skilled in the art will recognize that the architecture of contemplates only an exemplary embodiment of the invention. Other embodiments may include any number of endpoint devices and or CDNs . Thus is in no way intended to limit the scope of the present invention in any way.

As shown the method begins at step when the client adapter receives and parses a request for UI content from the client application front end . As discussed above the client application front end and the client adapter are both parts of the same client application developed for a particular type of endpoint device . The request may be an HTTP request with JSON or XML content.

At step the client adapter expands the request into sub requests to the internal API . These sub requests may be method calls performed concurrently or in series according to the design of the client adapter .

At step the client adapter receives the UI content from the internal API . If the internal API method calls initially return observables then the internal API asynchronously produces UI content through the observables. The client adapter may process each response from the internal API as the response is received or may wait to process all of the UI content together after all the internal API sub requests have completed. The internal API returns generalized UI content which the client adapter manipulates into the UI content specifically required by the client application front end .

At step the client adapter optimally formats the response for the client application front end . The formatting may be specific to the type of endpoint device .

At step the client adapter sends the response to the client application front end . The transmission protocol used to send the response may be specific to the type of endpoint device . The response includes the requested UI content for the home screen of the client application front end in a single optimized payload.

The CPU is configured to retrieve and execute programming instructions stored in the memory subsystem . Similarly the CPU is configured to store and retrieve application data residing in the memory subsystem . The interconnect is configured to facilitate transmission of data such as programming instructions and application data between the CPU graphics subsystem I O devices interface mass storage network interface secure memory space and memory subsystem .

The graphics subsystem is configured to generate frames of video data and transmit the frames of video data to display device . In one embodiment the graphics subsystem may be integrated into an integrated circuit along with the CPU . The display device may comprise any technically feasible means for generating an image for display. For example the display device may be fabricated using liquid crystal display LCD technology cathode ray technology and light emitting diode LED display technology either organic or inorganic . An input output I O device interface is configured to receive input data from user I O devices and transmit the input data to the CPU via the interconnect . For example user I O devices may comprise one of more buttons a keyboard and a mouse touchpad or other pointing device. The I O device interface also includes an audio output unit configured to generate an electrical audio output signal. User I O devices includes a speaker configured to generate an acoustic output in response to the electrical audio output signal. In alternative embodiments the display device may include the speaker or the display device may be a touch screen which also acts as an I O device . A television is an example of a device known in the art that can display video frames and generate an acoustic output. A mass storage unit such as a hard disk drive or flash memory storage drive is configured to store non volatile data. A network interface is configured to transmit and receive packets of data via the network . In one embodiment the network interface is configured to communicate using the well known Ethernet standard. The network interface is coupled to the CPU via the interconnect .

The memory subsystem includes programming instructions and data that comprise an operating system and the client application front end . The operating system performs system management functions such as managing hardware devices including the network interface mass storage unit I O device interface and graphics subsystem . The operating system also provides process and memory management models for the client application front end . Persons skilled in the art will recognize the various operating systems that are well known in the art and suitable for incorporation into the endpoint device .

The client application front end includes a DRM engine and a playback engine . The client application front end allows users to browse through and watch digital content that is served by the CDN . The client application front end provides the UI experience with UI content retrieved from a client adapter within the API server . The DRM engine is configured to decrypt protected digital content received from the CDN . The playback engine is configured to render the decrypted digital content.

Although shown in memory subsystem the operating system and the client application front end may be stored in memory subsystem mass storage or split between memory subsystem and mass storage .

The CPU is configured to retrieve and execute programming instructions stored in the memory subsystem . Similarly the CPU is configured to store and retrieve application data residing in the memory subsystem . The interconnect is configured to facilitate transmission of data such as programming instructions and application data between the CPU I O devices interface mass storage unit network interface and memory subsystem .

The memory subsystem includes programming instructions and data that comprise an operating system a Java Virtual Machine JVM one or more client adapters the internal API the fault tolerance layer and a user interface . The operating system performs system management functions such as managing hardware devices including the network interface mass storage unit and I O devices interface . The operating system also provides process and memory management models for the JVM the user interface the client adapters the internal API the fault tolerance layer and the user interface . The JVM is a program that executes the bytecode of the client adapters the internal API and the fault tolerance layer .

The client adapters are code written by developers such as the developers of the client applications for the endpoint devices . The client adapters are configured to execute on the API server and be accessed by external applications such as the client application front ends . A client adapter receives requests from the client application front end transmitted over the network via the network interface . The client adapter also transmits optimized responses specific to an endpoint device back to the client application front end . To compose the optimized responses the client adapter expands the request from the client application front end into a series of sub requests to the internal API to gather the requested UI content. In response to the sub requests from the client adapter the internal API returns generalized UI content data to the client adapter . The internal API retrieves the UI content from the UI content servers . The communications between the internal API and the UI content servers are transmitted over the network via the network interface . The fault tolerance layer wraps these communications in separate threads to isolate the internal API and thus the client adapter from potential communication failures with UI content servers .

The user interface provides a specific structure such as a window and an object metaphor or a command line interface for user interaction with the API server . A user may employ the user interface to manage the client adapters . In one embodiment the user interface presents a management web page for managing operation of the client adapters . The API server may include one or more versions of a client adapter associated with a specific endpoint device . The management of the client adapters may include the uploading publishing overwriting and or modification of new client adapters or new versions of client adapters . The user may also manage the volume of requests or network traffic transmitted to specific versions of a client adapter where the requests may be divided between one or more client adapters . Persons skilled in the art will recognize the various operating systems and user interfaces that are well known in the art and suitable for incorporation into the API server .

Although shown in memory subsystem the operating system the JVM the user interface the client adapters the internal API and the fault tolerance layer and the user interface may be stored in memory subsystem mass storage or split between memory subsystem and mass storage .

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored.

The invention has been described above with reference to specific embodiments. Persons of ordinary skill in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

