---

title: Headset computer (HSC) as auxiliary display with ASR and HT input
abstract: The present invention related to human/computer interfaces and more particularly to a headset computing display device that accepts voice commands and tracks head motions to provide command inputs to and receive display information from a software application executed on a host computing device. An example embodiment of the present invention includes a method of, and corresponding system for, operating a native Smartphone or PC application, simultaneously displaying an output of the application through the Smartphone or PC screen and a headset computing display device, and using speech and head tracking commands to control the native application. The present invention enables hands-free operation of a Smartphone or PC application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08929954&OS=08929954&RS=08929954
owner: Kopin Corporation
number: 08929954
owner_city: Westborough
owner_country: US
publication_date: 20130313
---
This application claims the benefit of U.S. Provisional Application No. 61 638 419 by Jacobsen et al. entitled Improved Headset Computer filed on Apr. 25 2012 U.S. Provisional Application No. 61 653 474 by Jacobsen et al. entitled Headset Computer HSC As Auxiliary Display With ASR And HT Input filed on May 31 2012 and U.S. Provisional Application No. 61 748 444 by Parkinson et al. entitled Smartphone API For Processing VGH Input filed on Jan. 2 2013 and U.S. Provisional Application No. 61 749 155 by Parkinson et al. entitled Smartphone Application Programming Interface API For Controlling HC Differently From Smartphone Display filed on Jan. 4 2013.

This application is related to U.S. application Ser. No. 12 774 179 by Jacobsen et al. entitled Remote Control Of Host Application Using Motion And Voice Commands filed May 5 2010 which claims the benefit of U.S. Provisional Application No. 61 176 662 filed on May 8 2009 entitled Remote Control of Host Application Using Tracking and Voice Commands and U.S. Provisional Application No. 61 237 884 filed on Aug. 28 2009 entitled Remote Control of Host Application Using Motion and Voice Commands .

The present application relates to human computer interfaces and more particularly to a headset computing display device that accepts voice commands and tracks head motions to provide command inputs to and receive display information from a software application executed on a remote host computing device.

Mobile computing devices such as notebook personal computers PC s Smartphones and tablet computing devices are now common tools used for producing analyzing communicating and consuming data in both business and personal life. Consumers continue to embrace a mobile digital lifestyle as the ease of access to digital information increases with high speed wireless communications technologies becoming ubiquitous. Popular uses of mobile computing devices include displaying large amounts of high resolution computer graphics information and video content often wirelessly streamed to the device. While these devices typically include a display screen the preferred visual experience of a high resolution large format display cannot be easily replicated in such mobile devices because the physical size of such devices is limited to promote mobility. Another drawback of the aforementioned device types is that the user interface is hands dependent typically requiring a user to enter data or make selections using a keyboard physical or virtual or touch screen display. As a result consumers are now seeking a hands free high quality portable color display solution to augment or replace their hands dependent mobile devices.

Recently developed micro displays can provide large format high resolution color pictures and streaming video in a very small form factor. One application for such displays can be integrated into a wireless headset computer worn on the head of the user with a display positioned within the field of view of the user similar in format to eyeglasses an audio headset or video eyewear. A wireless computing headset device includes one or more small high resolution micro displays and optics to magnify the image. The WVGA micro displays can provide super video graphics array SVGA 800 600 resolution or extended graphic arrays XGA 1024 768 or even higher resolutions. A wireless computing headset contains one or more wireless computing and communication interfaces enabling data and streaming video capability and provides greater convenience and mobility than hands dependent devices.

For more information concerning such devices see co pending U.S. application Ser. No. 12 348 646 entitled Mobile Wireless Display Software Platform for Controlling Other Systems and Devices by Parkinson et al. filed Jan. 5 2009 PCT International Application No. PCT US09 38601 entitled Handheld Wireless Display Devices Having High Resolution Display Suitable For Use as a Mobile Internet Device by Jacobsen et al. filed Mar. 27 2009 and U.S. Application No. 61 638 419 entitled Improved Headset Computer by Jacobsen et al. filed Apr. 25 2012 each of which are incorporated herein by reference in their entirety.

Example embodiments of the present invention include a method of and corresponding system for operating a Smartphone or PC application including executing an application on a Smartphone or PC the executed application being native to the Smartphone or PC. The invention method and system generating an output of the native application for simultaneous display through the Smartphone or PC screen and a headset computing display device. In one embodiment display output for the headset computing device is in a markup language. The headset computing device translates the received display output for rendering through the headset display in response to requesting and receiving the display output generated by the Smartphone or PC. The headset computing device operating in a speech recognition and head tracking user interface mode monitors for recognized user speech voice commands and head tracking commands head motions from an end user wearing the headset computing device. The headset computing device in response to received speech recognition and head tracking commands end user inputs translates the received speech recognition and head tracking commands to equivalent Smarthphone or PC commands e.g. touch screen keyboard and or mouse commands and transmitting the equivalent commands to the Smartphone or PC to control the native application.

A further example embodiment of the present invention includes a method of and corresponding system for operating a Smartphone or PC including executing a native image and or video viewing application on a Smartphone. The embodiment operates a headset computing device in a speech recognition and head tracking user interface mode monitoring for user speech recognition and head tracking commands from an end user at the headset computing device. The embodiment translating received speech recognition and head tracking commands to equivalent Smartphone commands at the headset computing device in response to received speech recognition and head tracking commands. The equivalent Smartphone commands include capturing an image or video on a display of the headset computing device transmitting the equivalent Smartphone command to the Smartphone to control the native image and video viewing application and displaying the captured image and or video through the headset computing display device and through the Smartphone display simultaneously.

The example embodiments may further include the use of a markup language included with generated display output such as Hyper Text Markup Language 5 HTML5 . Example embodiments may present to the end user menu selections and prompts in terms of speech recognition and head tracking commands such as audible and visual prompts. A wireless communications link between the host Smartphone or PC and the headset computing device. May use wireless communications links such as Bluetooth or Wi Fi wireless standards.

Still further example embodiments may further still effectively enable a speech recognition and hands free user interface and control of the native application executed on a Smartphone or PC.

Further example methods of and corresponding devices for displaying on a headset computer output from a Smartphone application. Embodiments execute an application on the Smartphone generating output of the executed application for display through a headset computer. The Smartphone configures and transmits instructions in a description language indicating actions for the headset computer to display the output of the executed application. Embodiments receive over low bandwidth at the headset computer the configured instructions and in response thereto the headset computer forms a display of the generated output based on indicated actions to perform. The actions include any of on screen notifications messages graphical elements request to play one of a plurality of predefined sound sequences and control a component of the headset computer.

The actions of the respective element types and for each element type the instructions can indicate one of a plurality of styles predefined for the headset computer. The description language can be HTML 5 or other markup language. The formed display rendered at the headset in the headset domain can include menu selections and prompts presented in terms of a speech recognition head tracking user interface. The menu selections and outputs can be audibly and visually presented to a user. The receiving by the headset computer and the transmitting by the Smartphone can be over a wireless communications link. The wireless communications link can be any of Bluetooth Wi Fi or other protocol.

Example methods can further include monitoring for input from a speech recognition head tracking user interface at the headset computer. In response to a received speech recognition head tracking command input the headset computer translates the received speech recognition head tracking command to an equivalent Smartphone command and transmits the equivalent Smartphone command to the Smartphone to control the executed application. The display by the headset computer can effectively enable speech and hands free user interaction with the Smartphone.

A Headset Computer HSC having computational and operational capabilities sufficient at least for use as an auxiliary display and end user input device is operationally connected to a host or alternatively main or controller computing device enabling a conventional software application executed on the host to be displayed simultaneously through the host and the HSC and controlled using end user inputs received at the HSC. Host computing devices may include Smartphones tablets or personal computers PC s . The HSC and host can be operatively couple using wires or preferably wirelessly.

According to an example method of the present invention a Smartphone or PC can be the primary or main computing device and the HSC can be an auxiliary display and user interface to the Smartphone or PC computing device. The Smartphone or PC can run its own native software using its own display in a conventional and customary manner. The HSC alone cannot execute such a software application due to its lack of traditional user interface hardware such as a touch screen keyboard and or mouse. Therefore in order to accommodate hands free computing the Smartphone or PC can execute a second class of application that while running directly on the Smartphone or PC is specifically designed to use the HSC as a display output for the native application and to use the Automatic Speech Recognizer ASR and Head Tracker HT functionally built into the HSC user input devices.

In example embodiments of the present invention the HSC contains at least sufficient computational and operational capabilities to i display a screen full of information ii monitor head gesture tracking and feed head movement information back to the main computer e.g. Smartphone or PC and iii monitor and process speech feeding speech recognition results back to the main computer. By pairing the HSC with the main computer Smartphone or PC the main computer may effectively hold specially created hands free applications that primarily run on the main computer but use the display of and augmented input from the HSC.

In one embodiment the HSC may take the form of the HSC described in a co pending U.S. patent application Ser. No. 13 018 999 entitled Wireless Hands Free Computing Headset With Detachable Accessories Controllable By Motion Body Gesture And Or Vocal Commands by Jacobsen et al. filed Feb. 1 2011 which is hereby incorporated by reference in its entirety.

Example embodiments of the HSC can receive user input through recognizing voice commands sensing head movements and hand gestures or any combination thereof. Microphone s operatively coupled or preferably integrated into the HSC can be used to capture speech commands which are then digitized and processed using automatic speech recognition ASR techniques. Gyroscopes accelerometers and other micro electromechanical system sensors can be integrated into the HSC and used to track the user s head movement to provide user input commands. Cameras or other motion tracking sensors can be used to monitor a user s hand gestures for user input commands. The voice command automatic speech recognition and head motion tracking features such a user interface overcomes the hands dependant formats of other mobile devices.

The headset computing device can be used as a remote auxiliary display for streaming video signals received from a remote host computing device shown in . The host may be for example a notebook PC Smartphone tablet device or other computing device having sufficient computational complexity to communicate with the HSC execute a native application generate and transmit an output display feed and receive user input commands from the HSC . The host may be further capable of connecting to other networks such as the Internet. The HCS and host can wirelessly communicate via one or more wireless protocols such as Bluetooth Wi Fi WiMAX or other wireless radio link . Bluetooth is a registered trademark of Bluetooth Sig Inc. of 5209 Lake Washington Boulevard Kirkland Wash. 98033. 

A head worn frame and strap are generally configured so that a user can wear the headset computer device on the user s head. A housing is generally a low profile unit which houses the electronics such as the microprocessor memory or other storage device low power wireless communications device s along with other associated circuitry. Speakers provide audio output to the user so that the user can hear information such as the audio portion of a multimedia presentation or audio prompt alert or feedback signaling recognition of a user command.

Micro display subassembly is used to render visual information such as images and video to the user. Micro display is coupled to the arm . The arm generally provides physical support such that the micro display subassembly is able to be positioned within the user s field of view preferably in front of the eye of the user or within its peripheral vision preferably slightly below or above the eye. Arm also provides the electrical or optical connections between the micro display subassembly and the control circuitry housed within housing unit .

According to aspects that will be explained in more detail below the HSC display device with micro display can enable an end user to select a field of view within a much larger area defined by a virtual display . The user can typically control the position extent e.g. X Y or 3D range and or magnification of the field of view .

While the example embodiments of an HSC shown in are monocular micro displays presenting a single fixed display element supported within the field of view in front of the face of the user with a cantilevered boom it should be understood that other mechanical configurations for the auxilliary display device HSC are possible.

In an example embodiment of the present invention an external smart device also referred to herein as a host device or controller is used in conjunction with a HSC to provide information and hands free control to a user. The example embodiment uses the transmission of small amounts of data between the host and HSC and thus provides a more reliable data transfer method and control method for real time control.

A preferred embodiment involves the collaboration between two devices one of which is an HSC . The other device controller or host is a smart device which is a device that executes an application processes data and provides functionality to the user. Example controllers include but are not limited to Smartphones tablets and laptops.

The controller and HSC can be paired over a suitable transport typically a wireless bi directional communications link such as Bluetooth. Because the amount of data transferred by such a suitable protocol is low the transport can be shared with other activities requiring higher bandwidth.

The controller can run software such as a second class of application running at a top layer of a software stack that enables it to send instructions to the HSC . In order to avoid having to send data outlining the entire screen contents on the HSC the controller instead can send instructions that the HSC can interpret using software functioning on the HSC . The instructions sent from the controller can describe actions to perform including on screen notifications messages and other graphical elements. Such instructions can also include requests to play one of a set of pre set predefined sound sequences or control other components of the HSC .

The instructions can further include pre set styled elements . Styled elements can include short hand instructions or code relating to how to lay out a display screen which text to display text font font size and other stylistic element information such as drawing arrows arrow styles and sizes background and foreground colors images to include or exclude etc. Therefore for each element type notification message textbox picturebox etc. there are multiple display styles. The styled elements can allow the controller great flexibility in how information is displayed on the HSC . In this way for given information visual elements displayed on the HSC can differ from the visual elements displayed on the display of controller .

Higher bandwidth activities can be requested while the bi directional communications protocol is transferring display instruction. Higher bandwidth traffic can be separate from the low bandwidth traffic of the present invention. For example the HSC can be utilized for a video call whereby a request is sent to acquire access and control of the display camera and audio communications peripherals microphone and speaker and to display live video and play live audio on the HSC . Such requests can be part of the accessory protocol e.g. low bandwidth instructions for HSC but the high bandwidth video call traffic can be outside of it.

Through the transmission of styled elements the amount of data to be transmitted over the connection is small simple instructions on how to lay out a screen which text to display and other stylistic information such as drawing arrows or the background colors images to include etc. Additional data can be streamed over the same link or another connection and displayed on screen such as a video stream if required by the controller .

In another embodiment after the bi directional communications link is established a software application native to the host computing device can be executed by the host processor. The native application can generate a feed of output images for display. So that the output images may be used for multiscreen display a second class of application can be executed by the host to append the output images with a markup language such as Hyper Text Markup Language 5 HTML5 . The host can communicate the marked up display data to the HSC for simultaneous display of application output through the displays of both the host device and the HSC but in respective format layout user interface. The HSC may process the marked up display data to present available menu selections and prompts to the end user of HSC so that the end user can interface through HSC with the application running on the host in a hands free manner. For example a visual prompt may include one or more text boxes indicating recognized verbal commands and or arrows or other motion indicators indicating head tracking and or hand motion commands. Audio prompts may for example include a text to speech machine recitation of recognized verbal commands.

The HSC device can receive vocal input from the user via the microphone hand movements or body gestures via positional and orientation sensors the camera or optical sensor s and head movement inputs via the head tracking circuitry such as 3 axis to 9 axis degrees of freedom orientational sensing. These command inputs can be translated by software in the HSC device into equivalent host device commands e.g. touch gesture keyboard and or mouse commands that are then sent over the Bluetooth or other wireless interface to the host . The host then can interpret the translated equivalent commands in accordance with the host operating system and executed native application software to perform various functions.

Among the equivalent commands may be one to select a field of view within the virtual display and return that selected screen data to the HSC device . Thus it should be understood that a very large format virtual display area might be associated with application software or an operating system running on the host . However only a portion of that large virtual display area within the field of view can be returned to and actually displayed by the micro display of HSC device .

In the present example embodiment at least for purposes of illustration the HSC can be equipped with sufficient processing equipment and capabilities to only process display data monitor user speech and motion input and translate such input into equivalent commands. In the illustrative example embodiment of the HSC is not equipped with a GPS receiver module and does not have a direct Internet Connection.

The host computing device e.g. Smartphone or other primary computing device equipped with a GPS receiver can generate a map screen image based on its current coordinates. Typically a Smartphone is equipped with a GPS receiver and associated processing software such that the Smartphone can provide its current location. Further the Smartphone usually is equipped with Internet connectivity to enable the downloading of a relevant map graphic. The map graphic can be post processed by a second class of application running on the Smartphone such that the post processed marked up graphic data is sent to the HSC for rendering and display to the user through field of view . The post processed data can include a set of recognized speech commands sent in text form to the HSC such as Satellite Pan Zoom In and Quit as illustrated in . The HSC after receiving and processing the marked up data can start listening for the user to select one of the commands by speaking uttering the same.

While the map is being displayed on the HSC through field of view head gesture movements can be monitored by the HSC translated to equivalent touch screen or keyboard physical or virtual commands and fed directly back to the Smartphone via the bi directional communications link for processing in accordance with the GPS map based application. For example if the user s head is moved left then the Smartphone may pan the map left and send an updated graphic to the HSC display . In this way Smartphone can perform the processing work while the HSC can provide an auxiliary display and user interface.

At the same time the user may speak a valid recognized command such as Satellite . The user may be made aware that Satellite is a valid command by being visually or audibly prompted through the HSC processing the marked up data produced from the Smartphone application which when processed by the HSC instructs the HSC to listen for valid commands . In recognizing the command word Satellite the HSC can turn the spoken language into an equivalent digital command and send the digital command back to the Smartphone . The Smartphone can then respond to the received equivalent digital command by generating a new map view and sending the new generated view to the HSC for display through the field of view of the micro display as is shown in . As such the Smartphone does not need to have voice recognition capabilities this functionality can be handled by the HSC .

It is further envisioned that an end user of the HSC can select from an array of native applications stored in the memory or other storage device of the Smartphone for hands free operation. The HSC user will be able to select which application to operate via an onscreen HSC screen menu and associated voice commands. Such a menu can be generated by the second class of application and sent to the HSC from the Smartphone in the manner described above. Once executed the second class of application can determine which native applications are compatible and can be accessed with the HSC .

During all of the HSC operations normal functionality of the host computing device Smartphone or PC may continue. Such an approach allows the HSC to be a much simpler device than in previously known HSC embodiments without giving up any functionality as perceived by the end user. Computational intelligence is provided mainly by the host . However it should be understood that all of the advances of the HSC can remain available such as providing hands free operation and navigation using head tracking and input commands via combination of head tracking and speech commands etc.

In the example of at least for purposes of illustration the HSC is equipped with sufficient processing equipment and capabilities to mostly process display data monitor user speech and motion input and translate such inputs into equivalent commands the HSC is not equipped with an Internet connection.

The host computing device here depicted as an iPhone generates a screen image based on its native e mail application. iPhone is a registered trademark of Apple Inc. Cupertino Calif. Typically an iPhone or Smartphone is equipped with an e mail application and associated processing and communications capabilities such that the iPhone can access an e mail server via an Internet connection. The e mail application display output graphic feed is post processed by a second class of applications running on the Smartphone such that the post processed marked up graphic data is sent to the HSC for rendering and display to the user through field of view . The post processed data can include a set of recognized speech commands sent in text form to the HSC such as Reply Reply All Discard Next Inbox and Quit as illustrated in . The HSC after receiving and processing the marked up data can start listening for the user to speak utter one or more of the commands .

While the e mail application is being displayed on the HSC through field of view head gesture movements can be monitored by the HSC translated to equivalent touch screen or keyboard physical or virtual commands and fed directly back to the Smartphone for processing in accordance with the e mail application. For example if the user s head is moved left as prompted by arrow then the HSC generates and transmits a corresponding Smartphone compatable command. In response the Smartphone may return to the Inbox and send an updated graphic to the HSC for presentation at display . In this way Smartphone can perform the processing work while the HSC can provide an auxiliary display and user interface.

At the same time the user may speak a valid recognized command such as Reply as previously described. Upon recognizing the command words such as Reply the HSC can turn the spoken language into an equivalent digital command and send the generated command back to the Smartphone . The Smartphone can then respond to the received equivalent command by generating an updated graphic representing a reply message and send the reply message screen view modified for HSC domain to the HSC for display through the field of view of the micro display .

In parallel with steps and or in series before or after a bi directional communications link can be established between host device and HSC step . Also in parallel with steps and or in series before or after the HSC can be operated in an automatic speech recognition ASR and head tracking HT mode of operation during which end user input e.g. spoken verbal commands and or head motion is monitored and recognized as user commands . After beginning operation in ASR HT mode HSC can request display output from host step of the executing native application on host .

The HSC Auxiliary application a second class of application can receive the input request from the HSC and the display output generated by the executed native application and then append mark up instructions to the display output data step . The appended marked up display data can then transmitted to the HSC via the established communications link shown as in step . The HSC can next determine whether the display output as modified marked up by host was received step . If the output was not received then the request can be made again step . If the output was received then the received display output data can be translated for rendering through the micro display step .

Next the translated data is rendered and displayed through the HSC display for example micro display step . Displaying the output generated by the native application though the host display step and through the HSC display step can occur substantially simultaneously but in respective domains formats. After displaying the output generated by the native application though the HSC display step HSC determines whether user input ASR HT at the HSC has been recognized step . If end user input ASR HT at HSC has been detected at step then such input can be translated to equivalent host device commands and transmitted to the host device as user input step . If no end user input at HSC is determined then HSC determines whether the HSC process is completed step . If the process at HSC is not yet complete the process can continue to operate according to the ASR HT mode step . If the HSC process is complete then the method can end step .

Applications running within the context of the HSC Display Application may include a Speech Recognition input Head Tracking input translation module for translating marked up display output from Host and for translating ASR HT input at HSC to equivalent Host commands and Virtual Network Connection which allows a bi directional communications link between the HSC and host device to be established.

A host software stack can include a kernal of an operating system OS such as a Linux kernal libraries and runtime libraries for implementing functions built into the programming language during the execution of an application such as those of Libraries Runtime stack application framework for implementing the standard structure of an application such as Application Framework an application which can run on top of the OS kernal libraries and framework such as Native Application and a second class of application that runs on top of the stack and Native Application such as HCS Auxiliary Display Interface Application . As described above in detail the HCS Auxiliary Display Interface Application can allow the end user to use the HSC as an auxiliary display and hands free user interface to control the Native Application executing an host . Applications running within the context of the HCS Auxiliary Display Interface Application may include a Virtual Network Connection which allows a bi directional communications link between the host device and HSC to be established. The host software stack can be more extensive and complex than the HSC software stack .

The actions can be of respective element types and for each element type the instructions can indicate one of a plurality of styles predefined for the headset computer. The styles can be style elements. The formed display rendered in the headset domain can include menu selections and prompts presented in terms of a speech recognition head tracking user interface. Such menu selections and outputs can be visually and audibly presented to a user. The communications link between the Smartphone and headset computer can be a wireless communications link for example Bluetooth Wi Fi or other communications protocol.

The alternative example process illustrated in can further include monitoring for input from a speech recognition head tracking user interface at the headset computer in response to receiving the speech recognition head tracking command input translating the received speech recognition head tracking command to an equivalent Smartphone command at the headset computer and transmitting the equivalent Smartphone command to the Smartphone to control the executed application. Such a method can effectively enable speech voice command and hands free head motion tracking user control of the executed application.

Further example embodiments of the present invention may be configured using a computer program product for example controls may be programmed in software for implementing example embodiments of the present invention. Further example embodiments of the present invention may include a non transitory computer readable medium containing instruction that may be executed by a processor and when executed cause the processor to complete methods described herein. It should be understood that elements of the block and flow diagrams described herein may be implemented in software hardware firmware or other similar implementation determined in the future. In addition the elements of the block and flow diagrams described herein may be combined or divided in any manner in software hardware or firmware. If implemented in software the software may be written in any language that can support the example embodiments disclosed herein. The software may be stored in any form of computer readable medium such as random access memory RAM read only memory ROM compact disk read only memory CD ROM and so forth. In operation a general purpose or application specific processor loads and executes software in a manner well understood in the art. It should be understood further that the block and flow diagrams may include more or fewer elements be arranged or oriented differently or be represented differently. It should be understood that implementation may dictate the block flow and or network diagrams and the number of block and flow diagrams illustrating the execution of embodiments of the invention.

The teachings of all patents published applications and references cited herein are incorporated by reference in their entirety.

While this invention has been particularly shown and described with references to example embodiments thereof it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the scope of the invention encompassed by the appended claims.

