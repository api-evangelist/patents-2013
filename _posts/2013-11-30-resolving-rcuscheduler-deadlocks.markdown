---

title: Resolving RCU-scheduler deadlocks
abstract: A technique for resolving deadlocks between an RCU subsystem and an operating system scheduler. An RCU reader manipulates a counter when entering and exiting an RCU read-side critical section. At the entry, the counter is incremented. At the exit, the counter is manipulated differently depending on the counter value. A first counter manipulation path is taken when the counter indicates a task-context RCU reader is exiting an outermost RCU read-side critical section. This path includes condition-based processing that may result in invocation of the operating system scheduler. The first path further includes a deadlock protection operation that manipulates the counter to prevent an intervening RCU reader from taking the same path. The second manipulation path is taken when the counter value indicates a task-context RCU reader is exiting a non-outermost RCU read-side critical section, or an RCU reader is nested within the first path. This path bypasses the condition-based processing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08997110&OS=08997110&RS=08997110
owner: International Business Machines Corporation
number: 08997110
owner_city: Armonk
owner_country: US
publication_date: 20131130
---
This application is a continuation under 35 U.S.C. 120 of application Ser. No. 13 475 003 filed May 18 2012 entitled Resolving RCU Scheduler Deadlocks. 

The present disclosure relates to computer systems and methods in which data resources are shared among data consumers while preserving data integrity and consistency relative to each consumer. More particularly the disclosure concerns an implementation of a mutual exclusion mechanism known as read copy update also known as RCU in an operating system kernel environment wherein RCU uses the operating system scheduler and the scheduler uses RCU.

By way of background read copy update also known as RCU is a mutual exclusion technique that permits shared data to be accessed for reading without the use of locks writes to shared memory memory barriers atomic instructions or other computationally expensive synchronization mechanisms while still permitting the data to be updated modify delete insert etc. concurrently. The technique is well suited to both uniprocessor and multiprocessor computing environments wherein the number of read operations readers accessing a shared data set is large in comparison to the number of update operations updaters and wherein the overhead cost of employing other mutual exclusion techniques such as locks for each read operation would be high. By way of example a network routing table that is updated at most once every few minutes but searched many thousands of times per second is a case where read side lock acquisition would be quite burdensome.

The read copy update technique implements data updates in two phases. In the first initial update phase the actual data update is carried out in a manner that temporarily preserves two views of the data being updated. One view is the old pre update data state that is maintained for the benefit of read operations that may have been referencing the data concurrently with the update. The other view is the new post update data state that is seen by operations that access the data following the update. In the second deferred update phase the old data state is removed following a grace period that is long enough to ensure that the first group of read operations will no longer maintain references to the pre update data. The second phase update operation typically comprises freeing a stale data element to reclaim its memory. In certain RCU implementations the second phase update operation may comprise something else such as changing an operational state according to the first phase update.

It is assumed that the data element list of is traversed without locking by multiple readers and occasionally updated by updaters that delete insert or modify data elements in the list. In the data element B is being referenced by a reader r1 as shown by the vertical arrow below the data element. In an updater u1 wishes to update the linked list by modifying data element B. Instead of simply updating this data element without regard to the fact that r1 is referencing it which might crash r1 u1 preserves B while generating an updated version thereof shown in as data element B and inserting it into the linked list. This is done by u1 acquiring an appropriate lock to exclude other updaters allocating new memory for B copying the contents of B to B modifying B as needed updating the pointer from A to B so that it points to B and releasing the lock. In current versions of the Linux kernel pointer updates performed by updaters can be implemented using the rcu assign pointer primitive. As an alternative to locking during the update operation other techniques such as non blocking synchronization or a designated update thread could be used to serialize data updates. All subsequent post update readers that traverse the linked list such as the reader r2 will see the effect of the update operation by encountering B as they dereference B s pointer. On the other hand the old reader r1 will be unaffected because the original version of B and its pointer to C are retained. Although r1 will now be reading stale data there are many cases where this can be tolerated such as when data elements track the state of components external to the computer system e.g. network connectivity and must tolerate old data because of communication delays. In current versions of the Linux kernel pointer dereferences performed by readers can be implemented using the rcu dereference primitive.

At some subsequent time following the update r1 will have continued its traversal of the linked list and moved its reference off of B. In addition there will be a time at which no other reader process is entitled to access B. It is at this point representing an expiration of the grace period referred to above that u1 can free B as shown in .

In the context of the read copy update mechanism a grace period represents the point at which all running tasks e.g. processes threads or other work having access to a data element guarded by read copy update have passed through a quiescent state in which they can no longer maintain references to the data element assert locks thereon or make any assumptions about data element state. By convention for operating system kernel code paths a context switch an idle loop and user mode execution all represent quiescent states for any given CPU running non preemptible code as can other operations that will not be listed here . The reason for this is that a non preemptible kernel will always complete a particular operation e.g. servicing a system call while running in process context prior to a context switch.

In four tasks 0 1 2 and 3 running on four separate CPUs are shown to pass periodically through quiescent states represented by the double vertical bars . The grace period shown by the dotted vertical lines encompasses the time frame in which all four tasks that began before the start of the grace period have passed through one quiescent state. If the four tasks 0 1 2 and 3 were reader tasks traversing the linked lists of or none of these tasks having reference to the old data element B prior to the grace period could maintain a reference thereto following the grace period. All post grace period searches conducted by these tasks would bypass B by following the updated pointers created by the updater.

Grace periods may synchronous or asynchronous. According to the synchronous technique an updater performs the first phase update operation blocks waits until a grace period has completed and then implements the second phase update operation such as by removing stale data. According to the asynchronous technique an updater performs the first phase update operation specifies the second phase update operation as a callback then resumes other processing with the knowledge that the callback will eventually be processed at the end of a grace period. Advantageously callbacks requested by one or more updaters can be batched e.g. on callback lists and processed as a group at the end of an asynchronous grace period. This allows asynchronous grace period overhead to be amortized over plural deferred update operations.

In some RCU implementations designed for preemptible operating system kernels asynchronous grace period processing is the norm but a synchronous expedited grace period sometimes referred to as a Big Hammer grace period is also available for updaters that need it. This expedited grace period forces a context switch and thus a quiescent state on each processor so that an updater can quickly perform its second phase update operation. Existing callbacks associated with asynchronous grace periods are not affected. They must await the end of an asynchronous grace period before becoming ripe for processing. In other RCU implementations designed for preemptible operating system kernels the RCU grace period mechanism includes the capability of priority boosting reader tasks that were preempted within their RCU read side critical sections so that such tasks do not unduly delay the end of a grace period.

In the foregoing preemptible kernel based RCU implementations the RCU subsystem can invoke the operating system scheduler from the rcu read unlock primitive which is invoked by reader tasks when they exit their RCU read side critical sections. The rcu read unlock primitive is a companion to the rcu read lock primitive which is invoked by reader tasks when they enter their RCU read side critical sections. Two scenarios in which the rcu read unlock primitive will result in invocation of the operating system scheduler are 1 when RCU priority boosting is enabled and the reader task that invoked rcu read unlock needs to be deboosted and 2 when the reader task that invoked rcu read unlock is the last reader holding up an RCU expedited grace period and the updater task that requested the expedited grace period needs to be awakened. These operations require the scheduler to acquire runqueue locks and priority inheritance locks.

However some operating system schedulers such as the scheduler in current versions of the Linux kernel can themselves implement RCU read side critical sections. Applicant submits that there are scenarios in which such usage could cause deadlock problems if the scheduler invoked by a non scheduler reader task itself invokes rcu read unlock and attempts to obtain runqueue or priority inheritance locks that it already holds. The present disclosure presents a solution that addresses this issue.

A method system and computer program product are provided for resolving deadlocks between an RCU subsystem and an operating system scheduler. According to an example embodiment an RCU registration component of the RCU subsystem allows an RCU reader to manipulate an rcu read lock nesting counter when the RCU reader enters an RCU read side critical section. An RCU unregistration component of the RCU subsystem allows an RCU reader to manipulate the rcu read lock nesting counter when the RCU reader leaves an RCU read side critical section. The unregistration component provides first and second rcu read lock nesting manipulation paths that are dependent on a current value of the rcu read lock nesting counter. The first rcu read lock nesting manipulation path is taken when the current value of the rcu read lock nesting counter is indicative of a task context RCU reader exiting an outermost RCU read side critical section. It includes condition based read side helper processing that may result in invocation of the operating system scheduler. This path further includes a deadlock protection operation that temporarily manipulates the rcu read lock nesting counter to prevent any intervening RCU reader from taking the first rcu read lock nesting manipulation path while a task context RCU reader is within that path. The second rcu read lock nesting manipulation path is taken when the current value of the rcu read lock nesting counter is indicative of a task context RCU reader exiting a non outermost RCU read side critical section or an RCU reader being nested within the first rcu read lock nesting manipulation path such as due to an interrupt handler interrupting the path to run the scheduler or an explicit call to the scheduler from within the path . This path bypasses the condition based read side helper processing.

According to an example embodiment the RCU registration component allows an RCU reader to manipulate the rcu read lock nesting counter by incrementing it. The RCU unregistration component allows an RCU reader to manipulate the rcu read lock nesting counter by either decrementing it or setting it to a value depending on which manipulation path is taken by the RCU reader. The first manipulation path may include setting the rcu read lock nesting counter to a deadlock protection value and the second manipulation path may include decrementing the rcu read lock nesting counter.

More particularly the first manipulation path may taken when the rcu read lock nesting counter has a first count value that is indicative of the task context RCU reader exiting all RCU read side critical section processing and may comprise setting the rcu read lock nesting counter to an arbitrary second count value representing the deadlock protection value performing the read side helper processing and setting the rcu read lock nesting counter to a third count value that is indicative of the task context RCU reader being outside of an RCU read side critical section. The arbitrary second count value may be a large negative number.

The second manipulation path may be taken when the rcu read lock nesting counter has any value other than the first count value and may comprise decrementing the rcu read lock nesting counter and bypassing the read side helper processing.

Turning now to the drawing et seq. wherein like reference numerals represent like elements in all of the several views illustrates an example multiprocessor computer system in which the subject matter disclosed herein may be implemented. By way of example only the computer system is shown as including multiple processors . . . a system bus and a program memory . There are also cache memories . . . and cache controllers . . . respectively associated with the processors . . . . A conventional memory controller is associated with the memory .

The computer system may represent any of several different types of computing apparatus. Such computing apparatus may include but are not limited to general purpose computers special purpose computers portable computing devices communication and or media player devices set top devices embedded systems and other types of information handling machines. The term processor as used with reference to the processors . . . encompasses any program execution unit capable of executing program instructions including but not limited to a packaged integrated circuit device such as a microprocessor a processing core within a packaged integrated circuit device such as a microprocessor core or a hardware thread comprising one or more functional units within a processing core such as an SMT thread . Each such execution unit may be referred to as a CPU central processing unit . The processors . . . may be situated within a single computing device or node e.g. as part of a single node SMP system or they may be distributed over plural nodes e.g. as part of a NUMA system a cluster or a cloud . The memory may comprise any type of tangible storage medium capable of storing data in computer readable form for use in program execution including but not limited to any of various types of random access memory RAM various flavors of programmable read only memory PROM such as flash memory and other types of primary storage i.e. program memory . The cache memories . . . may be implemented in several levels e.g. as level 1 level 2 and level 3 caches and the cache controllers . . . may collectively represent the cache controller logic that supports each cache level. As illustrated the memory controller may reside separately from processors . . . for example as part of a discrete chipset. Alternatively the memory controller could be provided by plural memory controller instances that are respectively integrated with the processors . . . .

Each CPU embodied by a given processor is operable to execute program instruction logic under the control of a software program stored in the memory or elsewhere . As part of this program execution logic update operations updaters may execute within a process thread or other execution context hereinafter task on any of the processors . Each updater runs periodically to perform updates on a set of shared data that may be stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual data updaters that respectively execute on the several processors . . . . As described in the Background section above the updates performed by an RCU updater can include modifying elements of a linked list inserting new elements into the list deleting elements from the list and other types of operations. To facilitate such updates the processors are programmed from instructions stored in the memory or elsewhere to implement a read copy update RCU subsystem as part of their processor functions. In reference numbers . . . represent individual RCU instances that may periodically execute on the several processors . . . . Any given processor may also execute a read operation reader . Each reader runs from program instructions stored in the memory or elsewhere in order to periodically perform read operations on the set of shared data stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual reader instances that may respectively execute on the several processors . . . . Such read operations will typically be performed far more often than updates this being one of the premises underlying the use of read copy update. Moreover it is possible for several of the readers to maintain simultaneous references to one of the shared data elements while an updater updates the same data element.

During operation of the computer system an updater will occasionally perform an update to one of the shared data elements . In accordance the philosophy of RCU a first phase update is performed in a manner that temporarily preserves a pre update view of the shared data element for the benefit of readers that may be concurrently referencing the shared data element during the update operation. Following the first phase update the updater may register a callback with the RCU subsystem for the deferred destruction of the pre update view following a grace period second phase update . As described in the Background section above this is known as asynchronous grace period processing. Alternatively the updater may request a synchronous expedited grace period.

The grace period processing performed by the RCU subsystem entails starting new grace periods and detecting the end of old grace periods so that the RCU subsystem knows when it is safe to free stale data or take other actions . Grace period processing may further entail the management of callback lists that accumulate callbacks until they are ripe for batch processing at the end of a given grace period. In addition reader priority boosting may be performed on behalf of readers that are blocking the end of a grace period. The foregoing grace period processing operations may be performed by periodically running RCU subsystem instances . . . on the several processors . . . .

Turning now to example components of the RCU subsystem are shown. These components include an RCU reader API Application Programming Interface an RCU updater API an RCU grace period API and a set of grace period detection and callback processing functions . As shown in the RCU subsystem also uses several fields in the task structure of each reader . As discussed in more detail below these fields include an rcu read lock nesting counter A and an rcu read unlock special flag B .

The RCU reader API comprises a reader registration component A and a reader unregistration component B. These components are respectively invoked by readers as they enter and leave their RCU read side critical sections thereby allowing the RCU subsystem to track reader operations and determine when readers are engaged in RCU protected read side critical section processing. In an example embodiment the reader registration component A and the reader unregistration component B may be respectively implemented using the rcu read lock and rcu read unlock primitives found in existing read copy update implementations but with the rcu read unlock primitive being modified to address the deadlock problem discussed in the Background section above.

When a reader enters an RCU read side critical section and invokes the reader registration component A the latter increments the rcu read lock nesting counter A see in the reader s task structure. When the reader leaves an RCU read side critical section and invokes the reader unregistration component B the latter decrements the rcu read lock nesting counter A. The term nesting as used in the name of this counter refers to the fact that a given reader s RCU read side critical sections can be nested or overlapping. In conventional implementations of the rcu read unlock primitive a counter value of zero is commonly used to indicate that a reader is not performing any RCU read side critical section processing. This counter value also triggers the conventional rcu read unlock primitive to check whether special read side helper processing see below is needed. As described in more detail below a modified version of the rcu read unlock primitive may be used to bypass this test for scheduler based invocations of the RCU subsystem .

The RCU updater API may comprise a register callback component A and an expedited grace period component B. The register callback component is used by the updaters to register a callback following a first phase update to a shared data element . In an example embodiment this component may be implemented using the call rcu primitive found in existing read copy update implementations. A call to the register callback component A initiates processing that places the callback on an RCU callback list not shown associated with the processor that runs the updater . This starts an asynchronous grace period so that the callback can be processed after the grace period has ended as part of second phase update processing to remove stale data or take other actions . The expedited grace period component B is used by the updaters to request a synchronous expedited grace period following a first phase update to a shared data element . The updater blocks while the expedited grace period is in progress then performs second phase update processing to free stale data or take other actions . In an example embodiment this component may be implemented using the synchronize rcu expedited primitive found in existing read copy update implementations.

The RCU grace period API may comprise a check callbacks component A. This component may be run periodically e.g. in response to a scheduler clock interrupt in order to check for new callbacks start a new grace period if one is needed and request callback processing. In an example embodiment this component may be implemented using the rcu preempt check callbacks primitive found in existing read copy update implementations. As discussed below the check callbacks component A also manipulates the rcu read unlock special flag B see if necessary to advance a grace period.

The grace period detection and callback processing functions may comprise various components conventionally found in existing read copy update implementations including but not limited to a quiescent state grace period tracking component a callback processor a blocked reader handler and a reader priority boosting component. Of particular relevance to the present disclosure is a read side helper component A that is implemented when a reader is delaying the end of a grace period. In an example embodiment this component may be implemented using the rcu read unlock special primitive found in existing read copy update implementations. Its operations may include advising the RCU subsystem that a delayed reader is exiting an RCU read side critical section and that a quiescent state has been reached if this is the last reader removing the reader from one or more blocked task lists used to identify readers that are blocking the end of a grace period and invoking the scheduler to unboost the reader s priority if it was previously boosted.

As described in the Background section above the present disclosure describes a technique that addresses the problem of deadlock that may occur in modern operating systems whose schedulers make increasing use of RCU and wherein RCU makes increasing calls to the scheduler. Current versions of the Linux kernel configured for kernel level preemption are one example. As shown in a preemptible operating system kernel that implements the RCU subsystem may operate in task context A e.g. due to a system call and scheduler context B also referred to herein as the scheduler . The RCU subsystem can be invoked from both task context A and scheduler context B in the event that either context needs to perform RCU read side critical section processing as an RCU reader . These respective invocations of the RCU subsystem are shown by the arrows and each of which represents a pair of calls to the reader registration component A e.g. rcu read lock and the reader unregistration component B e.g. rcu read unlock of . In addition an RCU reader operating in task context A can invoke the scheduler B from the reader unregistration component B e.g. rcu read unlock via the read side helper component A of e.g. rcu read unlock special . This is shown by the arrow . For example the read side helper component A may need to deboost the current task when RCU priority boosting is enabled or to wake up the task if it requested an expedited RCU grace period and it is the last such task that was blocking the end of that grace period.

In current implementations of the Linux kernel the rcu read unlock function that provides the reader unregistration component B invokes a work function known as rcu read unlock . The rcu read unlock function in turn conditionally invokes the rcu read unlock special function that provides the read side helper component A. The conditions that lead to the invocation of rcu read unlock special are determined from the two fields A and B in the reader s task structure see . As previously stated the first field A is an rcu read lock nesting counter that maintains a count of the number of times the reader has recursively entered an RCU read side critical section. In a conventional RCU implementation a counter value of zero signifies that the reader is not within such a critical section. The second field B is the rcu read unlock special flag that is set by the check callbacks component A of . In current implementations of the Linux kernel the rcu read unlock special function that provides the read side helper component A is invoked when 1 the rcu read lock nesting counter A is zero indicating that the reader has completed all RCU read side critical section processing and 2 the rcu read unlock special flag B is set indicating that additional actions are required on behalf of this reader .

Example C language source code for a conventional rcu read unlock work function that performs the foregoing condition processing is shown in . Line decrements and tests the rcu read lock nesting counter A for zero. If true and following a memory ordering barrier compiler directive in line a check is made in line to determine the state of the rcu read unlock special flag B. If the rcu read unlock special flag B is set the rcu read unlock special function is invoked in line .

The operations performed by the rcu read unlock special function that provides the read side helper component A will not be described in detail but as mentioned above may include deboosting the current task when RCU priority boosting is enabled or waking up the task that requested an expedited RCU grace period when the current task is the last one executing . Referring back to these operations can result in the RCU subsystem invoking the task scheduler B see arrow to acquire its runqueue locks and its priority inheritance locks. If the scheduler B independently invokes rcu read unlock while holding the runqueue and priority inheritance locks and if that invocation of rcu read unlock reinvokes the scheduler in the same manner as the initial rcu read unlock operation there is the possibility of deadlock under certain scenarios.

Such scenarios can be avoided if the scheduler B disables interrupts when acquiring its runqueue and priority inheritance locks. As long as the scheduler s RCU read side critical sections are completely contained in a given runqueue or priority inheritance lock s critical section then that RCU read side critical section cannot be interrupted blocked or preempted. There can therefore be no reason for rcu read unlock to reinvoke the scheduler. In particular there can be no priority boosting during the scheduler s RCU read side critical because there can be no preemption with interrupts disabled. Moreover the scheduler s RCU read side critical section cannot be the last RCU read side critical section to end for an expedited grace period because interrupts are disabled and there can be no preemption by reschedule IPIs interprocessor interrupts .

However consider an implementation of rcu read unlock in a hierarchical RCU implementation designed for systems with many processors. In current versions of the Linux kernel the hierarchical RCU kernel configuration option is known as CONFIG TREE PREEMPT RCU. In this implementation it is possible for the following sequence of events to occur 

The problem in this situation is that the interrupt handler s RCU reader code path is nested within the task level RCU reader s code path and the interrupt handler s instance of the rcu read unlock primitive is seeing the state that is intended for the task level  rcu read unlock . A proposed solution to this problem is to use separate first and second rcu read lock nesting manipulation paths in the reader unregistration component B that are dependent on different values of the rcu read lock nesting counter A see . The first rcu read lock nesting manipulation path includes condition based read side helper processing that may result in invocation of the operating system scheduler B. This path is taken when the current value of the rcu read lock nesting counter is indicative of a task context RCU reader exiting an outermost RCU read side critical section. It includes a deadlock protection operation that temporarily manipulates the rcu read lock nesting counter to prevent any intervening RCU reader from taking the first rcu read lock nesting manipulation path while the task context RCU reader is within that path. The second rcu read lock nesting manipulation path bypasses the condition based read side helper processing. This path is taken when the rcu read lock nesting counter is indicative of a task context RCU reader exiting a non outermost RCU read side critical section or when the current value of the rcu read lock nesting counter is indicative of an RCU reader being nested within the first rcu read lock nesting manipulation path such as due to an interrupt handler interrupting the path to run the scheduler or an explicit call to the scheduler from within the path.

In an example embodiment the RCU unregistration component allows an RCU reader to manipulate the rcu read lock nesting counter by either decrementing it or setting it to a value depending on which manipulation path of the reader unregistration component is taken. In particular the first manipulation path includes setting the rcu read lock nesting counter to a deadlock protection value and the second manipulation path includes decrementing the rcu read lock nesting counter. Still more particularly the first manipulation path may be taken when the rcu read lock nesting counter has a first count value that is indicative of the task context RCU reader exiting all RCU read side critical section processing and may comprise setting the rcu read lock nesting counter to an arbitrary second count value representing the deadlock protection value performing read side helper processing and resetting the rcu read lock nesting counter to a third count value that is indicative of the task context RCU reader being outside of an RCU read side critical section. The arbitrary second count value may be a large negative number. The second manipulation path of the unregistration component may be taken when the rcu read lock nesting counter has any value other than the first count value and may comprise decrementing the rcu read lock nesting counter and bypassing the read side helper processing.

Example C language code implementing this solution is shown in . This has roughly the same overhead as the conventional code of the decrement and assignment operation of line of has been replaced by the decrement operation of line of for the first rcu read lock nesting manipulation pathway or the two assignment operations at lines and of for the second rcu read lock nesting manipulation pathway . When a task context reader exits its outermost RCU read side critical section and reaches line of it will find that the rcu read lock nesting counter A is equal to one. Execution will jump to line a memory ordering barrier compiler directive provided in line and the rcu read lock nesting counter A will be set to INT MIN which can be a large negative number in line . This represents the above mentioned deadlock protection value. Following another memory ordering barrier compiler directive in line lines will be implemented and rcu read unlock special will be invoked if necessary i.e. according to the state of the rcu read unlock special flag B in the reader s task structure see . Once the invocation of rcu read unlock special by the task context RCU reader is no longer a possibility another memory ordering barrier compiler directive is provided on line and the rcu read lock nesting counter A is set to zero on line . The foregoing processing represents the first rcu read lock nesting manipulation path mentioned above. This path is taken by task context readers that are exiting their outermost RCU read side critical sections.

Advantageously if a nested scheduler level RCU reader is invoked while the task context RCU reader is within the first rcu read lock nesting manipulation path the scheduler level RCU reader upon reaching line of will find that the rcu read lock nesting counter A is not equal to 1. The rcu read lock nesting counter A will equal INT MIN 1 due to the scheduler level RCU reader having previously invoked the reader registration component A which increments the rcu read lock nesting counter . Line will then decrement the rcu read lock nesting counter A setting it to INT MIN but the code path of lines that leads to rcu read unlock special and the deadlock problem described above will be bypassed. The foregoing processing represents the second rcu read lock nesting manipulation path mentioned above. This path is taken by any RCU reader that is nested within the first rcu read lock nesting manipulation path. As previously mentioned this could be an interrupt handler that interrupts the first path or an explicit call to the scheduler B from within that path. This first rcu read lock nesting manipulation path is also taken by task context readers that are not exiting an outermost RCU read side critical section.

The flow diagram of illustrates the foregoing processing. In block the test represented by line of is implemented. Block represents the decrement of line of and block represents the assignment of line of . In block the condition test represented by line of is implemented. Block represents the conditional invocation of rcu read unlock special set forth on line of . Block represents the operation of line of in which the rcu read lock nesting counter is set to zero.

Accordingly a technique for has been disclosed for implementing read copy update in a manner that resolves RCU scheduler deadlocks in an operating system kernel. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine useable storage media for use in controlling a data processing system to perform the required functions. Example embodiments of a data processing system and machine implemented method were previously described in connection with . With respect to a computer program product digitally encoded program instructions may be stored on one or more computer readable data storage media for use in controlling a computer or other digital machine or device to perform the required functions. The program instructions may be embodied as machine language code that is ready for loading and execution by the machine apparatus or the program instructions may comprise a higher level language that can be assembled compiled or interpreted into machine language. Example languages include but are not limited to C C assembly to name but a few. When implemented on a machine comprising a processor the program instructions combine with the processor to provide a particular machine that operates analogously to specific logic circuits which themselves could be used to implement the disclosed subject matter.

Example data storage media for storing such program instructions are shown by reference numerals memory and cache of the multiprocessor system of . The system may further include one or more secondary or tertiary storage devices not shown that could store the program instructions between system reboots. A further example of storage media that may be used to store the program instructions is shown by reference numeral in . The storage media are illustrated as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such storage media can store the program instructions either alone or in conjunction with an operating system or other software product that incorporates the required functionality. The storage media could also be provided by other portable storage media such as floppy disks flash memory sticks etc. or storage media combined with drive systems e.g. disk drives . As is the case with the memory and the cache of the storage media may be incorporated in data processing platforms that have integrated random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the storage media could comprise any electronic magnetic optical infrared semiconductor system or apparatus or device or any other tangible entity representing a machine manufacture or composition of matter that can contain store communicate or transport the program instructions for use by or in connection with an instruction execution system apparatus or device such as a computer. For all of the above forms of storage media when the program instructions are loaded into and executed by an instruction execution system apparatus or device the resultant programmed system apparatus or device becomes a particular machine for practicing embodiments of the method s and system s described herein.

Although various example embodiments have been shown and described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the disclosure. It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

