---

title: Adjusting thread priority to optimize computer system performance and the utilization of computer system resources
abstract: The present invention optimizes the utilization of computer system resources by considering predefined performance targets of multithreaded applications using the resources. The performance and utilization information for a set of multithreaded applications is provided. Using the performance and utilization information, the invention determines overutilized resources. Using the performance information, the invention also identifies threads and corresponding applications using an overutilized resource. The priority of the identified threads using said overutilized resource is adjusted to maximise a number of applications meeting their performance targets. The adjustments of priorities are executed via a channel that provides the performance and utilization information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08701118&OS=08701118&RS=08701118
owner: International Business Machines Corporation
number: 08701118
owner_city: Armonk
owner_country: US
publication_date: 20130311
---
In general the present invention relates to optimizing the performance of applications running on a computer system. More particularly the present invention relates to optimizing the utilization of a computer system s resources considering predefined performance targets of applications using said resources. Still more particularly the present invention applies especially to applications as for example distributed data movement applications comprising several independently executable tasks wherein each task comprises at least one thread and each thread uses mainly one resource. Further the present invention assumes that performance information on thread level is provided for each of these applications and that utilization information of the computer system s resources is available.

It is well known in the art that most applications use several different resources during execution. A backup restore client application for example comprises the independently executable tasks of reading data from a storage device performing a data compression and sending the data over a network to a server component. Each of these processes uses one particular resource which determines the performance of this process. So the most important characteristics for the performance of reading data are speed and throughput of the storage device although the CPU is utilized as well for reading data.

Usually the utilization of the different resources varies depending on the number and priorities of applications accessing said resources. This may result in an overutilization of some resources impacting the performance of those applications using an overutilized resource.

The Application Response Measurement ARM standard describes a procedure to determine the utilization of resources or the duration of transactions used or processed by a data manipulation process. This measurement of the utilization or the transaction times is initiated by the application itself. However the ARM standard covers measurement only. The usage of this utilization information is not part of the standard. Instead workload managers like IBM Workload Manager or IBM Enterprise Workload Manager WLM eWLM make use of these values to control external schedulers for some resources. State of the art schedulers need permanent and dynamic adjustment. They are only able to prioritize applications but can not prioritize single threads or tasks within an application see .

A starting point for the present invention is an infrastructure and a monitoring mechanism as described in IPCOM000138798D . The central module of this infrastructure is a Performance Monitor Interface providing performance measurement capabilities to the applications to be monitored. To collect detailed performance information this interface measures the runtime of each particular thread within an application during the process flow. The results of these measurements are monitored by a central monitoring component serving as a User Interface. By correlating this information and in consideration of the total process duration it is possible to draw conclusions about the whole system environment concerning performance and utilization.

The present invention optimizes the utilization of computer system resources by considering predefined performance targets of multithreaded applications using the resources. The performance and utilization information for a set of multithreaded applications is provided. Using the performance and utilization information the invention determines overutilized resources. Using the performance information the invention also identifies threads and corresponding applications using an overutilized resource. The priority of the identified threads using said overutilized resource is adjusted to maximise a number of applications meeting their performance targets. The adjustments of priorities are executed via a channel that provides the performance and utilization information.

According to the present invention the claimed method for optimizing the utilization of a computer system s resources considering predefined performance targets of applications using said resources where the applications performance information on thread level together with the utilization information of the resources is used to determine overutilized resources. The performance information is used to identify all threads and corresponding applications using an overutilized resource. Then the priority of said identified threads using said overutilized resource is varied to maximise the number of applications meeting their performance targets.

In one preferred embodiment a central monitoring component collects and analyses the performance and utilization information to determine overutilized resources and to identify all threads and corresponding applications using an overutilized resource and to automatically vary the priority of said identified threads by scheduling said threads to maximise the number of applications meeting their performance targets.

The invention uses the same channel that collects the performance information of applications on thread level and utilization information of the resources used by these applications to perform an adjustment of the priority of threads competing for an over utilized resource. The monitoring facility collects performance data of the application e.g. transaction times throughput CPU utilization and sends this information via the channel to the central component of the monitoring facility. The central component of the monitoring facility can send adjustment actions via channel to the monitoring facility which performs the required adjustments to application. The adjustments are executed within the next monitoring cycle. The adjustment of priority is done considering the performance targets of the corresponding applications. So a process of an application with lower priority can be throttled when using an overutilized resource to privilege the competing process of an application with higher priority. The present invention even allows to trade threads or tasks against each other which belong to one and the same application and compete for an over utilized resource to improve the performance of said application. One major advantage of the present invention is that it allows adjustment of the performance and priority of applications regarding multiple different resources without adjusting the corresponding external schedulers which are only able to prioritize applications as a whole. This strategy results in better overall resource utilization than the state of the art technology using external schedulers for the different resources.

The present invention may be used in addition to such external state of the art schedulers in cases where a scheduler can not be adjusted. The present invention can be used for resources e.g. networks which are not capable of scheduling. Usually data to be sent over a network is prioritized using Quality of Service QOS concepts which provide each data package with a flag indicating if this data package should be handled with higher priority than others or to guarantee a certain transfer time.

The invention uses an infrastructure which gathers performance information on thread level for each application running on the same system or multiple distributed systems and utilization information for the resources used by the applications. This is done by a single application programming interface API call. According to the invention this API call also initiates an analysis of this information to automatically vary the priority of threads using an overutilized resource. Therefore the claimed infrastructure includes a central monitoring component that uses information about the importance of the monitored applications i.e. their performance targets to decide which thread may be throttled whenever a global resource limit is reached.

The same infrastructure is used to adjust the priorities of the observed applications and or threads. describes how the adjustment actions are executed to the application. This is achieved by delaying the application and or thread of the application while it is passing the performance information to the monitoring infrastructure. In a preferred embodiment of the present invention the monitored applications call functions of the monitoring infrastructure to allow the collection of the performance information. Applications and or threads that are considered to heavily utilize a certain resource while still fulfilling the performance targets are delayed in their execution while passing the performance information to the monitoring infrastructure . This is achieved by stopping the execution of the actual thread of an observed application while it delivers the performance data to the monitoring infrastructure.

In the context of the present invention the actual performance of applications running on a computer system can easily be observed by monitoring and analysing the corresponding thread level performance information. Thus it is possible to determine whether such an application fulfils its performance target and to value its performance.

In a preferred embodiment of the present invention overutilized resources are identified using the available performance information of applications which do not fulfil their performance targets. As the performance information is provided on thread level it identifies the threads limiting the performance of an application and the resources mainly used by these threads. Together with the utilization information of these resources it is then possible to determine whether a resource is actually overutilized thus impacting the application performance.

Once having identified an overutilized resource the applications performance information is used to determine all threads and corresponding applications using the overutilized resource.

There are several strategies and ways to vary the priority of threads using an overutilized resource according to the present invention. In a preferred embodiment the performance information of each application using an overutilized resource is considered with respect to the corresponding performance target to decide whether the thread mainly using the overutilized resource can be throttled. A thread to be throttled should belong to an application which fulfils its performance target. Even better results are achievable when throttling only threads of applications which overfulfil their performance target by a predefined percentage. The thread limiting the performance of an application and the thread to be throttled to improve said application s performance should belong to different tasks to avoid undesirable side effects.

Advantageously a thread is throttled by simply delaying it. The delay of a particular thread or process can be chosen on arbitrary granularity or time slice. In some cases it may be of benefit to do this on relatively large time slices because each switching between two processes which compete for one resource consumes time and resource capacity for the switching itself. Avoiding switching results in a higher performance e.g. in a reduced transaction time. State of the art schedulers use quite fine time slices to make sure interactive processes look to the user as running continuously. Differently the present invention allows a coarse grained scheduling for selected non interactive processes e.g. delaying stopping the process for 1 sec within a time frame of 10 sec instead of delaying it 500 times for 20 msec in the same time frame. Thereby the infrastructure of a computer system e.g. caches is utilized much more efficiently. To further increase the efficiency of the whole system the delay may be increased gradually as long as the corresponding application fulfils or overfulfils its performance target and as long as the resource mainly used by said thread is overutilized.

In a preferred embodiment of the present invention the delay of a thread is recorded as adjustment information associated with the application having initiated this adjustment. Thus adjustments can easily be reset for example in a case where the application having initiated these adjustments has finished.

As the utilization of the different resources is usually varying a resource may only be overutilized for a certain period of time but may have unused capacities afterwards. That is why the throttling of a process using said resource may be reasonable for a certain period of time but is dispensable afterwards. To take advantage of this aspect when optimizing the utilization of resources a preferred embodiment of the present invention also handles the case where an application does overfulfil its performance target. In this case the adjustment information mentioned above is used to reduce the adjustments i.e. the delays imposed on other applications. Thus an optimal utilization of resources is approximated.

One core idea of the present invention is to use the same channel that is used to collect the performance information to trade independent application processes which are competing for the same over utilized resource against each other.

The invention preferably uses the same channel that collects the performance information of applications on thread level and utilization information of the resources used by these applications to perform an adjustment of the priority of threads competing for an overutilized resource.

The present invention may be used in addition to such external state of the art schedulers in cases where a scheduler can not be adjusted. The present invention can be used for resources e.g. networks which do not know scheduling. Usually data to be sent over a network is prioritized using Quality of Service QOS concepts which provide each data package with a flag indicating if this data package should be handled with higher priority than others or to guarantee a certain transfer time.

The invention uses an infrastructure which gathers performance information on thread level for each application running on the same system or multiple distributed systems and utilization information for the resources used by said applications. This is done by a single application programming interface API call. According to the invention this API call also initiates an analysis of this information to automatically vary the priority of threads using an over utilized resource. Therefore the claimed infrastructure includes a central monitoring component that uses information about the importance of the monitored applications i.e. their performance targets to decide which thread may be throttled whenever a global resource limit is reached.

The same infrastructure is used to adjust the priorities of the observed applications and or threads. describes how the adjustment actions are executed to the application . This is achieved by delaying the application and or thread of the application while it is passing the performance information to the monitoring infrastructure . In a preferred embodiment of the present invention the monitored applications call functions of the monitoring infrastructure to allow the collection of the performance information. Applications and or threads that are considered to heavily utilize a certain resource while still fulfilling the performance targets are delayed in their execution while passing the performance information to the monitoring infrastructure . This is achieved by stopping the execution of the actual thread of an observed application while it delivers the performance data to the monitoring infrastructure .

In the context of the present invention the actual performance of applications running on a computer system can easily be observed by monitoring and analysing the corresponding thread level performance information. Thus it is possible to determine whether such an application fulfils its performance target and to value its performance.

To identify independent processes or tasks of an application the present invention uses a structure as shown in . This embodiment assumes that each application consists of a number of threads wherein each thread mainly uses only one particular resource. The threads of an application are grouped according to their interdependencies wherein each group of interdependent threads forms an independent task of that application.

The invention proposes to enhance the central component to be able to specify certain performance targets for threads and or resources. Furthermore it proposes to use the same channel that is used to receive the performance data to send the control information how long a specific thread should be suspended from execution back to the data collecting part which performs the adjustment of the threads .

The application structure exemplarily shown in comprises Thread to Thread . The arrows indicate the dependencies between Threads to . Accordingly Thread and Thread depend on Thread which in turn depends on Thread and . Similarly Thread depends on Thread which depends on Thread . As all interdependent threads belong to the same task a first task with task ID A is formed by Thread to while thread to form another independent task with task ID B.

Returning to the example of a backup restore client application mentioned above shows an infrastructure which allows retreival of performance information on thread level from such an application. Thread level performance information is necessary for optimizing the utilization of a computer system s resources according to the present invention. The infrastructure comprises three layers a process layer a performance analysis layer and an adjustment layer .

The backup restore application belongs to the process layer which illustrates the use of resources and the data flow connected with said application . First application accesses a database system to read data from a disk storage device. Then after having performed some data manipulation e.g. data compression application sends the data over a TSM API network to a TSM server . So application uses three different resources a disk subsystem CPU and a network.

The performance analysis layer is represented by a performance monitor interface providing performance measurement capability to the backup restore application . The main idea behind this interface is to measure the time periods the different threads within the process flow are running. The backup application read call for example may therefore be enclosed with the two functions startDiskAccess and stopDiskAccess. Thus it is possible to get information about the disk subsystem performance. The other performance critical threads are observed in the same way.

The adjustment layer is represented by an administration assistant . This component collects and analyses the performance information provided by the performance monitor interface in connection with information about the utilization of the system s resources. Thus it determines overutilized resources identifies all threads and corresponding applications using an overutilized resource and varies the priority of said identified threads by scheduling said threads to maximise the number of applications meeting their performance targets. This will be explained in detail in connection with the flowchart of .

Process illustrated in represents a preferred embodiment of the present invention. It uses the measured time necessary to perform the separate threads of each application as actual performance information to optimize the utilization of a computer system s resources considering predefined performance targets of said applications using said resources. This actual thread level performance information is retrieved in step which will be explained in detail in connection with . In step a monitoring application analyses the actual thread level performance information to determine the actual performance of an application and to compare this actual application performance with the application s performance targets.

In case that these targets are not met process continues with step where the thread level performance information of the application is analysed to determine the bottleneck i.e. the thread which needs a disproportional amount of the performance time. Then the utilization information of the corresponding resource is analysed to determine whether this resource is overutilized. If it is considered overutilized the performance information of all applications using said resource is analysed and compared to the corresponding performance targets to decide whether the respective threads using said overutilized resource can be throttled. In a preferred embodiment of the invention these threads belong to an application which overfulfils its performance target by a predefined percentage. In this preferred embodiment the thread limiting the performance and the thread to be throttled belong to different tasks.

If such a thread is found in step an adjustment in the form of a delay is calculated in step and recorded as adjustment information associated with the application having initiated this adjustment. Then it is sent to the thread in step . The delay is reflected in step which will be explained in detail in connection with . Thus the priority of threads using an overutilized resource is varied to maximise the number of applications meeting their performance targets.

In case that an application does meet its performance target or even overfulfils it by a predefined percentage process flows from step to step to check whether there are any adjustments in effect that have been initiated by said application. Therefore process uses the recorded adjustment information. If there is any throttling of other applications initiated by said application this throttling is reduced in step and the adjustment information is modified accordingly. Then process continues with step by sending the reduction to the respective thread.

The flowchart of illustrates that thread processing and monitoring is interwoven such that step of process comprises not only monitoring aspects but also scheduling aspects.

As already mentioned above thread level performance information is retrieved by enclosing each thread with two get actual time commands and wherein the actual time retrieved from step is considered as start time and the actual time retrieved from step is considered as end time. Thus the actual processing time for a thread is calculated in step after having performed said thread . In the following step it is checked whether an adjustment is available for said thread . If not the calculated processing time is sent to the monitoring application in step . In case that an adjustment is available for said thread further processing is delayed according to that adjustment in step . Thus the adjustments determined in steps and and sent to the threads in step of process are accomplished in step which is part of step of process .

