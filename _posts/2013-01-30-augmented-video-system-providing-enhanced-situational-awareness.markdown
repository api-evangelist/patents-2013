---

title: Augmented video system providing enhanced situational awareness
abstract: A facility, comprising systems and methods, for providing enhanced situational awareness to captured image data is disclosed. The disclosed techniques are used in conjunction with image data, such as a real-time or near real-time image stream captured by a camera attached to an unmanned system, previously captured image data, rendered image data, etc. The facility enhances situational awareness by projecting overlays onto captured video data or “wrapping” captured image data with previously-captured and/or “synthetic world” information, such as satellite images, computer-generated images, wire models, textured surfaces, and so on. The facility also provides enhanced zoom techniques that allow a user to quickly zoom in on an object or area of interest using a combined optical and digital zoom technique. Additionally, the facility provides a digital lead indicator designed to reduce operator-induced oscillations in commanding an image capturing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09380275&OS=09380275&RS=09380275
owner: Insitu, Inc.
number: 09380275
owner_city: Bingen
owner_country: US
publication_date: 20130130
---
Unmanned systems e.g. unmanned aerial or aircraft systems unmanned ground systems and unmanned underwater systems provide a low cost and low risk alternative to a variety of reconnaissance type tasks performed by manned systems. Unmanned aircraft systems for example are used by TV news stations by the film television industry the oil industry for maritime traffic monitoring border shore patrol civil disaster surveillance drug enforcement activities spotting and monitoring fleets of fish e.g. tuna etc. Law enforcement agencies use manned helicopters and airplanes as an integral part of their operations but unmanned aircraft systems are being used in a growing number of situations. The uses for aviation equipment in law enforcement that can be filled by unmanned aerial systems include for example 

Unmanned systems can include a Global Positioning System GPS receiver to obtain adequate near real time position data to indicate where the system is and calculate attitude with feedback information from solid state rate gyros. Unmanned aerial systems capable of for example automated take off launch flight via programmed way points and snag type recovery have been developed so as to reduce the acquisition and operation costs when compared to manned aircraft e.g. single pilot fixed and rotor aircraft .

Typical unmanned systems may be remotely operated by a user or controller at a fixed or mobile remote control station. From the ground control station the controller can observe the behavior of the unmanned system control the unmanned system receive feedback and information from the unmanned system such as information gathered by various sensors installed on the unmanned system e.g. information about the state e.g. position orientation velocity of the unmanned system information about the surrounding area information about other vehicles systems in the surrounding area and so on. Typical unmanned systems however do not provide and or display information that allows users or controllers to for example identify and locate targets identify and locate restricted operating zones or view captured information in the context of a surrounding environment such as geographical information.

A facility comprising systems and methods for providing enhanced situational awareness to captured image data and increasing actionable intelligence is disclosed. The disclosed techniques are used in conjunction with image data such as a real time or near real time image stream captured by an image capturing device e.g. color or black and white camera infrared sensor or ultraviolet sensor carried by an unmanned system and or previously captured image data and or rendered image data and so on. The image data may include analog or digital video streams such as STANAG 4609 compliant video streams. In some embodiments the disclosed systems and methods provide techniques for overlaying reference information and symbols onto or in conjunction with captured video data wrapping real time or near real time video data with synthetic world information e.g. previously captured image data or generated models of surrounding information and providing a virtual camera configured to navigate the wrapped live video data. In this manner the disclosed techniques can augment the display of captured video data to provide additional context and a greater level of situational awareness of areas and surrounding areas monitored by unmanned systems. By augmenting the video that users and operators see with geographical and other information the facility improves the ability to obtain situational awareness of a particular area.

In some embodiments the facility enhances situational awareness by projecting overlays onto captured video data. For example one or more overlays may be displayed over and simultaneously with the display of a video feed such as a live video feed or a recorded video feed. Individual overlays can include symbols and or text to help identify and monitor objects with the video feed. The overlays may include for example target overlays map annotation overlays street overlays border overlays boundary overlays e.g. restricted operating zones airspace classes detectability overlays heading and groundspeed overlays unsafe elevation overlays reticle overlays aircraft route overlays military grid reference system overlays and so on. For example target overlays may alert the user or operator of various objects or targets of interest e.g. a building a school of fish a vehicle a runway and other unmanned systems within the captured image data. In this manner the facility can highlight and alert the user or operator to objects of interest and related information.

In some embodiments the facility wraps captured image data such as images from a real time camera stream with previously captured and or synthetic world information such as satellite images computer generated images wire models textured surfaces and so on. In this manner captured image data can be viewed in the context of surrounding information such as satellite imagery terrain information structures bathymetric information and so on. For example the facility can augment the display of a live camera feed to include previously captured satellite imagery of the area around the area captured within the live camera feed. Thus a user can view the live camera feed in the context of the area surrounding the area within the view of the camera to enhance a viewer s situational awareness. Moreover multiple camera feeds can be included so that a user or operator can view multiple live areas wrapped with synthetic or other information. In this manner a user s view is not limited to the images captured by a single camera but rather can include information about the surrounding area.

In some embodiments the facility provides enhanced zoom techniques that allow a user to quickly zoom in on an object or area of interest using a combined optical and digital zoom technique. In some instances an image capturing device may have a zoom rate that prevents a user from optically zooming in on or out from an object or area of interest at a desired rate. In other words the user may not be able to optically zoom in on an object as fast as the user would like due to limitations of the camera. The facility overcomes this problem by in response to a request from a user to perform a zoom in operation determining whether the camera is capable of performing the desired zoom within a predetermined period e.g. 1 millisecond 1 second 10 seconds and so on . If the camera cannot perform the desired zoom within the predetermined period the system digitally zooms in on the desired object or area and while the camera is optically zooming periodically e.g. every millisecond 5 milliseconds 1 second and so on updates the display using the newly captured and optically zoomed image data. In this manner the user is quickly presented with digitally zoomed data at a desired zoom level or magnification factor while the camera zooms. Furthermore the digitally zoomed in data is regularly updated while the camera optically zooms in to provide images with increasing resolution while the camera zooms in.

In some embodiments the system provides a digital lead indicator. The digital lead indicator is designed to reduce operator induced oscillations in commanding an image capturing device. Typically when an operator is controlling an image capturing device to track a moving object using for example a joystick the operator may induce oscillations into the motion of the image capturing device as the image capturing device swings past the moving object and the operator repeatedly corrects the orientation of the image capturing device. The digital lead indicator is designed to avoid these operator induced oscillations by displaying a digital lead indicator in the form of a dot or other shape at a point where the image capturing device is predicted to be pointing in a specified period of time e.g. 0.5 seconds 1.0 seconds 10 milliseconds .

In some embodiments the facility may be commanded to automatically track an object by repeatedly performing object recognition techniques such as those disclosed in U.S. Provisional Patent Application No. 61 659 935 entitled STATISTICAL APPROACH TO IDENTIFYING AND TRACKING TARGETS WITHIN CAPTURED IMAGE DATA filed Jun. 14 2012 which is herein incorporated by reference in its entirety. The facility can then automatically command an image capturing device to keep the object at or near the center or other location of a video display. This tracking mode allows a user to maintain focus on a particular object or area.

The computing devices on which the disclosed techniques may be implemented can include a central processing unit memory input devices e.g. keyboard and pointing devices output devices e.g. display devices and storage devices e.g. disk drives . The memory and storage devices are computer readable storage media that may be encoded with computer executable instructions that implement the technology which means a computer readable storage medium that stores the instructions. In addition the instructions data structures and message structures may be transmitted via a computer readable transmission medium such as a signal on a communications link. Thus computer readable media includes both computer readable storage media for storing information and computer readable transmission media for transmitting information. Additionally data used by the facility may be encrypted. Various communications links may be used such as the Internet a local area network a wide area network a point to point dial up connection a cell phone network wireless networks and so on.

The disclosed technology may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures and so on that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments including cloud based implementations.

Many embodiments of the technology described herein may take the form of computer executable instructions including routines executed by a programmable computer. Those skilled in the relevant art will appreciate that aspects of the technology can be practiced via computer systems other than those shown and described herein. Embodiments of the technology may be implemented in and used with various operating environments that include personal computers server computers handheld or laptop devices multiprocessor systems microprocessor based systems programmable consumer electronics digital cameras network PCs minicomputers mainframe computers computing environments that include any of the above systems or devices and so on. Moreover the technology can be embodied in a special purpose computer or data processor that is specifically programmed configured or constructed to perform one or more of the computer executable instructions described herein. Accordingly the terms computer or system as generally used herein refer to any data processor and can include Internet appliances and hand held devices including palm top computers wearable computers cellular or mobile phones multi processor systems processor based or programmable consumer electronics network computers mini computers and the like . Information handled by these computers can be presented at any suitable display medium including a CRT display LCD LED display OLED display and so on.

The technology can also be practiced in distributed environments where tasks or modules are performed by remote processing devices linked through a communications network. In a distributed computing environment program modules or subroutines may be located in local and remote memory storage devices. Aspects of the technology described herein may be stored or distributed on computer readable media including magnetic or optically readable or removable computer disks. Furthermore aspects of the technology may be distributed electronically over networks. Data structures and transmissions of data particular to aspects of the technology are also encompassed within the scope of the technology.

The facility may maintain or receive overlay files for any of a number of geographical areas. Moreover overlay files for different geographical areas and even different types of overlays may be combined into a single overlay file. Overlay files may be created by processing user interactions with video frames to receive and store position dimension and label information for various objects represented in an overlay file. For example in response to receiving a request from a user to create or update overlay information for an object the facility may prompt the user to provide information for the object by for example drawing a box around the object tracing the shape of the object and providing a label for the object. Alternatively location dimension and label information may be received from other sources such as the SKETCHUP www.sketchup.com provided by TRIMBLE of Mountain View Calif. or the TRIMBLE 3D WAREHOUSE sketchup.google.com 3dwarehouse powered by GOOGLE of Sunnyvale Calif. In some cases overlay information may be dynamically updated. For example position and dimension information for a moving object of interest such as a moving vehicle may be transmitted to the facility periodically as the object of interest moves. The position and dimension information may be provided by the object of interest and or another data source such as another vehicle or person tracking the object or by the facility itself while in tracking mode or using shape recognition techniques. Thus the facility can take advantage of dynamically collected information and automatically adjust overlays in real time. Similarly while the facility is in tracking mode the component can estimate the speed and direction of moving objects based on where the moving object is recognized from video frame to video frame and the distance between the image capturing device and the moving object. The distance between the image capturing device and the moving object can be calculated based on position information for the moving object and the image capturing device and or information collected from a rangefinder.

In blocks the component loops through for each frame each of the selected overlays converts information associated with the overlay into screen coordinates and then displays the converted information with the selected frame e.g. over the selected frame or blended with the selected frame . In block the component selects a video frame. In block the component selects one of the selected overlays. In decision block if the selected overlay is a dashboard overlay then the component continues at block else the component continues at block . A dashboard overlay is an overlay that is not affected by the perspective of the captured image data such as an overlay that displays current coordinates of the image capturing device or an associated vehicle an overlay that displays mileage or fuel information for a vehicle to which the image capturing device is affixed and so on. A non dashboard overlay is one that is affected by the perspective of the captured image data because it transforms overlay objects in an attempt to align the overlay objects with actual objects. In block the component invokes a convert component to convert the position of overlay objects into screen coordinates. In block the component displays the overlay by rendering the overlay objects at corresponding screen coordinates using various rendering techniques and libraries such as OpenGL provided by Silicon Graphics International Corp. of Fremont Calif. DirectX provided by Microsoft of Redmond Wash. The rendered objects may represent the shape of the corresponding object or simply highlight the object by for example rendering a circle perforated square and or other shape at the corresponding screen coordinates. For example the component may render the overlay objects over the captured image data or may blend the overlay objects with the captured image data using alpha compositing techniques. Furthermore the facility may assign different colors to different overlays and or different overlay objects to better distinguish between overlay objects associated with different overlays. For example object of interest overlay objects may be rendered in red while building overlay objects are rendered in blue. Additionally overlay objects associated with the same overlay may be displayed in different colors. In block the component loops back to block for processing of the next selected overlay if any. In block the component loops back to block for processing of the next frame if any.

From the foregoing it will be appreciated that specific embodiments of the technology have been described herein for purposes of illustration but that various modifications may be made without deviating from the disclosed technology. For example the facility can include additional components or features and or different combinations of the components or features described herein. For example the digital lead indicator may be displayed simultaneously with the display of various overlays and overlay information hybrid data detectability information and or other suitable displayable information. Similarly overlays and overlay information may be displayed simultaneously with a dynamic reticle enhanced zoomed data revealed area and or other suitable displayable information. Moreover various blocks within the Figures may be rearranged without changing the functionality of the disclosed techniques. Additionally while advantages associated with certain embodiments of the new technology have been described in the context of those embodiments other embodiments may also exhibit such advantages and not all embodiments need necessarily exhibit such advantages to fall within the scope of the technology. Accordingly the disclosure and associated technology can encompass other embodiments not expressly shown or described herein.

