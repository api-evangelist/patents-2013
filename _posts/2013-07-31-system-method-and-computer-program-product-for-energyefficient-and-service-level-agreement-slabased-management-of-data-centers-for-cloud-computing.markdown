---

title: System, method and computer program product for energy-efficient and service level agreement (SLA)-based management of data centers for cloud computing
abstract: Improving the utilization of physical resources and reducing energy consumption in a cloud data center includes providing a plurality of virtual machines in the cloud data center; periodically reallocating resources of the plurality of virtual machines according to a current resource demand of the plurality of virtual machines in order to minimize a number of active physical servers required to handle a workload of the physical servers; maximizing a mean inter-migration time between virtual machine migrations under the quality of service requirement based on a Markov chain model; and using a multisize sliding window workload estimation process for a non-stationary workload to maximize the mean inter-migration time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09363190&OS=09363190&RS=09363190
owner: Manjrasoft Pty. Ltd.
number: 09363190
owner_city: Melbourne, Victoria
owner_country: AU
publication_date: 20130731
---
The embodiments herein generally relate to energy efficient management of distributed computing resources and data centers and more particularly to cloud computing.

Within this application several publications are referenced by Arabic numerals within brackets. Full citations for these and other publications may be found at the end of the specification immediately preceding the claims. The disclosures of all these publications in their entireties are hereby expressly incorporated by reference into the present application for the purposes of indicating the background of the invention and illustrating the general state of the art.

Cloud computing has revolutionized the information and communications technology ICT industry by enabling on demand provisioning of computing resources based on a pay as you go model. An organization can either outsource its computational needs to the Cloud avoiding high up front investments in a private computing infrastructure and consequent maintenance costs or implement a private Cloud data center to improve the resource management and provisioning processes. However the problem of data centers is high energy consumption which has risen by 56 from 2005 to 2010 and in 2010 accounted to be between 1.1 and 1.5 of the global electricity use 20 . Apart from high operating costs this results in substantial carbon dioxide CO emissions which are estimated to be 2 of the global emissions 14 . The problem has been partially addressed by improvements in the physical infrastructure of modern data centers. As reported by the Open Compute Project Facebook s Oregon data center achieves a Power Usage Effectiveness PUE of 1.08 which means that 93 of the data center s energy consumption are consumed by the computing resources. Therefore now it is important to focus on the resource management aspect i.e. ensuring that the computing resources are efficiently utilized to serve applications.

One method to improve the utilization of data center resources which has been shown to be efficient 25 32 40 15 16 33 19 39 21 17 7 4 is dynamic consolidation of Virtual Machines VMs . This approach leverages the dynamic nature of Cloud workloads the VMs are periodically reallocated using live migration according to their current resource demand in order to minimize the number of active physical servers referred to as hosts required to handle the workload. The idle hosts are switched to low power modes with fast transition times to eliminate the static power and reduce the overall energy consumption. The hosts are reactivated when the resource demand increases. This approach has basically two objectives namely minimization of energy consumption and maximization of the Quality of Service QoS delivered by the system which form an energy performance trade off.

Prior approaches to host overload detection for energy efficient dynamic VM consolidation proposed in the literature can be broadly divided into three categories periodic adaptation of the VM placement no overload detection threshold based heuristics and decision making based on statistical analysis of historical data. One of the first works in which dynamic VM consolidation has been applied to minimize energy consumption in a data center has been performed by Nathuji and Schwan 25 . They explored the energy benefits obtained by consolidating VMs using migration and found that the overall energy consumption can be significantly reduced. Verma et al. 32 modeled the problem of power aware dynamic VM consolidation as a bin packing problem and proposed a heuristic that minimizes the data center s power consumption taking into account the VM migration cost. However the authors did not apply any algorithm for determining when it is necessary to optimize the VM placement the proposed heuristic is simply periodically invoked to adapt the placement of VMs.

Zhu et al. 40 studied the dynamic VM consolidation problem and applied a heuristic of setting a static CPU utilization threshold of 85 to determine when a host is overloaded. The host is assumed to be overloaded when the threshold is exceeded. The 85 utilization threshold has been first introduced and justified by Gmach et al. 15 based on their analysis of workload traces. In their more recent work Gmach et al. 16 investigated the benefits of combining both periodic and reactive threshold based invocations of the migration controller. VMware Distributed Power Management 33 operates based on the same idea with the utilization threshold set to 81 . However static threshold heuristics may be unsuitable for systems with unknown and dynamic workloads as these heuristics do not adapt to workload changes and do not capture the time averaged behavior of the system.

Jung et al. 19 investigated the problem of dynamic consolidation of VMs running multi tier web applications to optimize a global utility function while meeting service level agreement SLA requirements. The approach is workload specific as the SLA requirements are defined in terms of the response time pre computed for each transaction type of the applications. When the request rate deviates out of an allowed interval the system adapts the placement of VMs and the states of the hosts. Zheng et al. 39 proposed automated experimental testing of the efficiency of a reallocation decision prior to its application once the response time specified in the SLAs is violated. In the approach proposed by Kumar et al. 21 the resource allocation is adapted when the application s SLAs are violated. Wang et al. 34 applied control loops to manage resource allocation under response time QoS constraints at the cluster and server levels. If the resource capacity of a server is insufficient to meet the applications SLAs a VM is migrated from the server. All these works are similar to threshold based heuristics in that they rely on instantaneous values of performance characteristics but do not leverage the observed history of system states to estimate the future behavior of the system and optimize the time averaged performance.

Guenter et al. 17 implemented an energy aware dynamic VM consolidation system focused on web applications whose SLAs are defined in terms of the response time. The authors applied weighted linear regression to predict the future workload and proactively optimize the resource allocation. This approach is in line with the Local Regression LR algorithm proposed in 3 which is used as one of the benchmark algorithms. Bobroff et al. proposed a server overload forecasting technique based on time series analysis of historical data 7 . Unfortunately the algorithm description is generally too high level which does not allow for easy implementation to compare it with previous approaches. Weng et al. 35 proposed a load balancing system for virtualized clusters. A cluster wide cost of the VM allocation is periodically minimized to detect overloaded and underloaded hosts and reallocate VMs. This is a related work but with the opposite objective the VMs are deconsolidated to balance the load across the hosts.

As mentioned above the common limitations of the prior works are that due to their heuristic basis they lead to sub optimal results and do not allow the system administrator to explicitly set a QoS goal. Accordingly there remains a need for a new and improved energy efficient and SLA based management of data centers for cloud computing.

In view of the foregoing an embodiment herein provides a method of improving a utilization of physical resources and reducing energy consumption in a cloud data center the method comprising providing a plurality of virtual machines in the cloud data center periodically reallocating resources of the plurality of virtual machines according to a current resource demand of the plurality of virtual machines in order to minimize a number of active physical servers required to handle a workload of the physical servers wherein the reallocating comprises determining when a physical server is considered to be overloaded so that some of the virtual machines are migrated from the overloaded physical server to other physical servers in order to meet a quality of service requirement determining when a physical server is considered to be underloaded so that the virtual machines of the physical server are migrated to other physical servers wherein the physical server is switched to a lower power mode selecting particular virtual machines to migrate from the overloaded physical server and allocating the selected virtual machines for migration to other active or re activated physical servers. The method further comprises maximizing a mean inter migration time between virtual machine migrations under the quality of service requirement based on a Markov chain model and using a multisize sliding window workload estimation process for a non stationary workload to maximize the mean inter migration time.

The Markov chain model allows a derivation of a randomized control policy that optimally maximizes the mean inter migration time between virtual machine migrations under an explicitly specified quality of service requirement for any known stationary workload and a given state configuration in an online setting. The method may further comprise maximizing an activity time of the overloaded physical server and minimizing an activity time of an underloaded physical server. A workload of a physical server comprises a central processing unit utilization created over a period of time by a set of virtual machines allocated to the physical server wherein the workload may be stationary. The non stationary workload is approximated as a sequence of stationary workloads that are enabled one after another.

The method may further comprise submitting a virtual machine provisioning request through a cloud user interface processing the request and instantiating required virtual machines collecting data on resource utilization of virtual machines instantiated on a compute host passing the data to a local consolidation manager that invokes physical server overload detection physical server underload detection a virtual machine selection process passing outcomes generated by the local consolidation manager to a global consolidation manager invoking a virtual machine placement process to determine a new placement of a virtual machine required to be migrated initiating virtual machine migrations as determined by the virtual machine placement process migrating the virtual machines as instructed by the global consolidation manager and upon completion of the required migrations the global consolidation manager switching the physical servers from and to a lower power mode wherein the lower power mode comprises a sleep mode. The quality of service requirement may be specified in terms of a workload independent quality of service metric. The overload detection occurs using an offline process.

A system and non transitory program storage device readable by computer tangibly embodying a program of instructions executable by the computer to perform the method of improving a utilization of physical resources and reducing energy consumption in a cloud data center are also provided and includes computer code means for performing the method and a display unit that displays the maximized mean inter migration time.

These and other aspects of the embodiments herein will be better appreciated and understood when considered in conjunction with the following description and the accompanying drawings. It should be understood however that the following descriptions while indicating preferred embodiments and numerous specific details thereof are given by way of illustration and not of limitation. Many changes and modifications may be made within the scope of the embodiments herein without departing from the spirit thereof and the embodiments herein include all such modifications.

The embodiments herein and the various features and advantageous details thereof are explained more fully with reference to the non limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. Descriptions of well known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments herein. The examples used are intended merely to facilitate an understanding of ways in which the embodiments herein may be practiced and to further enable those of skill in the art to practice the embodiments herein. Accordingly the examples should not be construed as limiting the scope of the embodiments herein.

The embodiments herein provide a new and improved energy efficient and SLA based management of data centers for cloud computing. Referring now to the drawings and more particularly to where similar reference characters denote corresponding features consistently throughout the figures there are shown preferred embodiments.

The QoS requirements can be defined in terms of a variety of metrics and are formalized in the SLAs. In this work to specify the QoS requirements a modification of the workload independent metric proposed in 3 is applied. Therefore the problem transforms into minimization of energy consumption under QoS constraints. This problem is too complex to be treated analytically as a whole as just the VM placement which is a part of dynamic VM consolidation is an NP hard problem 32 19 7 . Moreover many aspects of the problem have to be addressed e.g. the heterogeneity of physical resources and VMs non stationary and unknown workloads as observed in Infrastructure as a Service IaaS environments power and performance costs of VM migrations and the large scale of Cloud data center infrastructures. Another argument for splitting the problem is decentralization of the resource management algorithm which is desirable for scaling the resource management system for efficient handling of thousands of servers. Therefore to make the problem of dynamic VM consolidation tractable and provide decentralization it is proposed to divide it into 4 sub problems 

1. Deciding when a host is considered to be overloaded so that some VMs should be migrated from it to other hosts to meet the QoS requirements.

2. Deciding when a host is considered to be underloaded so that its VMs should be migrated and the host should be switched to a low power mode.

A system e.g. a cloud data center implementing this model is shown in . The basic actions performed by the system are the following 

3. The resource utilization monitor collects the data on the resource utilization of VMs instantiated on a compute host and passes these data to the local consolidation manager which invokes host overload detection e.g. MHOD host underload detection and VM selection algorithms and passes the outcomes to the global consolidation manager .

4. The global consolidation manager which is on the controller host processes requests received from local consolidation managers and invokes a VM placement algorithm to determine a new placement of VM required to be migrated. Then the global consolidation manager initiates VM migrations as determined by the VM placement algorithm.

5. VMs are migrated as instructed by the global consolidation manager . Upon completion of the required migrations the global consolidation manager switches hosts from and to the sleep mode accordingly.

First with respect to the first sub problem the problem of host overload detection. Detecting when a host becomes overloaded directly influences the QoS since if the resource capacity is completely utilized it is highly likely that the applications are experiencing resource shortage and performance degradation. What makes the problem of host overload detection complex is the necessity to optimize the time averaged behavior of the system while handling a variety of heterogeneous workloads placed on a single host. To address this problem most of the current approaches to dynamic VM consolidation apply either heuristic based techniques such as utilization thresholds 40 15 16 33 decision making based on statistical analysis of historical data 17 7 or simply periodic adaptation of the VM allocation 25 32 . The limitations of these approaches are that they lead to sub optimal results and do not allow the administrator to explicitly set a QoS goal. In other words the performance in regard to the QoS delivered by the system can only be adjusted indirectly by tuning parameters of the applied host overload detection algorithm. In contrast the embodiments herein enable the system administrator to explicitly specify a QoS goal in terms of a workload independent QoS metric. The underlying analytical model allows a derivation of an optimal randomized control policy for any known stationary workload and a given state configuration. The embodiments herein provide the following features in the context of algorithm method model 

1. It is analytically shown that to improve the quality of VM consolidation it is necessary to maximize the mean time between VM migrations initiated by the host overload detection algorithm.

2. An optimal offline algorithm is proposed for host overload detection and its optimality is proven.

3. A novel Markov Chain model is introduced that allows a derivation of a randomized control policy that optimally solves the problem of maximizing the mean time between VM migrations under an explicitly specified QoS goal for any known stationary workload and a given state configuration in the online setting.

4. To handle unknown non stationary workloads the Multisize Sliding Window workload estimation approach 22 is applied to heuristically build an adapted algorithm which leads to approximately 15 higher mean inter migration time compared to the best benchmark algorithm for the input workload traces used in our experiments. The adapted algorithm leads to approximately 88 of the mean inter migration time produced by the optimal offline algorithm.

1. An architecture of an extensible software framework computer program product for dynamic VM consolidation designed to transparently integrate with OpenStack installations and allowing configuration based substitution of multiple implementations of algorithms for each of the four defined sub problems of dynamic VM consolidation.

2. An implementation of the framework in Python released under the Apache 2.0 license and publicly available online.

3. An implementation of several algorithms for dynamic VM consolidation including the MHOD algorithm proposed and evaluated by simulations described above and below.

4. An initial version of a benchmark suite comprising the software framework workload traces performance metrics and methodology for evaluating and comparing dynamic VM consolidation solutions following the distributed model.

5. Experimental evaluation of the framework on a 5 node OpenStack deployment using real world application workload traces collected from more than a thousand PlanetLab VMs hosted on servers located in more than 500 places around the world 27 . According to the estimates of potential energy savings the algorithms reduce energy consumption by up to 33 with a limited performance impact.

The embodiments herein use static and dynamic threshold heuristics as benchmark algorithms in the experimental evaluation of the proposed approach. The embodiments herein evaluate the algorithm by simulations using real world workload traces from more than a thousand PlanetLab VMs hosted on servers located in more than 500 places around the world. The experiments show that the introduced algorithm outperforms the benchmark algorithms while meeting the QoS goal in accordance with the theoretical model. The algorithm uses a workload independent QoS metric and transparently adapts its behavior to various workloads using a machine learning technique therefore it can be applied in an environment with unknown non stationary workloads such as IaaS.

The model provided by the embodiments herein is based on Markov chains requiring a few fundamental modeling assumptions. First the workload must satisfy the Markov property which implies memoryless state transitions and an exponential distribution of state transition delays. These assumptions must be taken into account in an assessment of the applicability of the proposed model to a particular system. A more detailed discussion of the modeling assumptions and validation of the assumptions is given below.

Benini et al. 6 describe the power management of electronic systems using Markov decision processes. A Markov chain model is created for the case of a known stationary workload and a given state configuration. Using a workload independent QoS metric a Non Linear Programming NLP problem formulation is derived. The solution of the derived NLP problem is the optimal control policy that maximizes the time between VM migrations under the specified QoS constraint in the online setting. Since most real world systems including IaaS experience highly variable non stationary workloads the Multisize Sliding Window workload estimation technique proposed by Luiz et al. 22 is applied to heuristically adapt the proposed model to non stationary stochastic environments and practical applications. Although the final approach is a heuristic approach in contrast to the previous works it is based on an analytical model that allows the computation of an optimal control policy for any known stationary workload and a given state configuration.

To improve the quality of VM consolidation it is necessary to maximize the time intervals between VM migrations from overloaded hosts. Since VM consolidation is applied to reduce the number of active hosts the VM consolidation quality is inversely proportional to H the mean number of active hosts over n time steps 

To investigate the impact of decisions made by host overload detection algorithms on the quality of VM consolidation consider an experiment where at any time step the host overload detection algorithm can initiate a migration from a host due to an overload. There are two possible consequences of a decision to migrate a VM relevant to host overload detection Case 1 when a VM to be migrated from an overloaded host cannot be placed on another active host due to insufficient resources and therefore a new host has to be activated to accommodate the VM and Case 2 when a VM to be migrated can be placed on another active host. To study host overload detection in isolation it is assumed that no hosts are switched off during the experiment i.e. once a host is activated it remains active until n.

Let p be the probability of Case 1 i.e. an extra host has to be activated to migrate a VM from an overloaded host determined by the host overload detection algorithm. Then the probability of Case 2 is 1 p . Let T be a random variable denoting the time between two subsequent VM migrations initiated by the host overload detection algorithm. The expected number of VM migrations initiated by the host overload detection algorithm over n time steps is n E T where E T is the expected inter migration time.

Based on the definitions given above the number of extra hosts switched on due to VM migrations initiated by the host overload detection algorithm over n time steps can be defined as X B n E T p which is a binomially distributed random variable. The expected number of extra hosts activated is E X np E T . Let A be a random variable denoting the time during which an extra host is active between the time steps and n. The expected value of A can be defined as follows 

The first term ais a constant denoting the number of hosts that have been initially active and remain active until the end of the experiment. The second term

Since the objective is to improve the quality of VM consolidation it is necessary to minimize E H . From 8 10 the only variable that can be directly controlled by a host overload detection algorithm is E T therefore to minimize E H the objective of a host overload detection algorithm is to maximize E T i.e. to maximize the mean time between migrations from overloaded hosts.

To impose QoS requirements on the system an extension of the workload independent QoS metric introduced in 3 is applied. The embodiments herein assume a host can be in one of two states in regard to its load level 1 serving regular load and 2 being overloaded. It is assumed that if a host is overloaded the VMs allocated to the host are not being provided with the required performance level leading to performance degradation. To evaluate the overall performance degradation a metric denoted Overload Time Fraction OTF is defined as follows 

The exact definition of the state of a host when it is overloaded depends on the specific system requirements. However the value of the CPU utilization threshold udefining the states of a host does not affect the proposed model which allows setting the threshold to any value. For example in the experiments it is defined that a host is overloaded when its CPU utilization is 100 in which case the VMs allocated to this host do not get the required CPU capacity leading to performance degradation. The reasoning behind this is the observation that if a host serving applications is experiencing 100 utilization the performance of the applications is constrained by the host s capacity therefore the VMs are not being provided with the required performance level.

It has been claimed in the literature that the performance of servers degrade when their load approaches 100 38 30 . For example the study of Srikantaiah et al. 30 has shown that the performance delivered by the CPU degrades when the utilization is higher than 70 . If due to system requirements it is desirable to avoid performance degradation the proposed OTF metric allows the specification of the CPU utilization threshold at the required level below 100 . The host is considered to be overloaded when the CPU utilization is higher than the specified threshold.

In general other system resources such as memory disk and network bandwidth should also be taken into account in the definition of QoS requirements. However emphasis is placed on CPU as it is one of the main resources that are usually oversubscribed by Cloud providers.

Verma et al. 31 proposed a similar metric for estimating the SLA violation level in a system which they defined as the number of time instances when the capacity of a server is less than the demand of all applications placed on it. However their metric shows a non normalized absolute value which for example cannot be used to compare systems processing the same workload for different periods of time. In contrast the OTF metric is normalized and does not depend on the length of the time period under consideration.

In the next section based on the objective of a host overload detection algorithm derived above the OTF metric introduced in this section an optimal offline algorithm for the host overload detection problem is proposed and its optimality is proved.

As shown above it is necessary to maximize the mean time between VM migrations initiated by the host overload detection algorithm which can be achieved by maximizing each individual inter migration time interval. Therefore the problem formulation is limited to a single VM migration i.e. the time span of a problem instance is from the end of a previous VM migration and to the end of the next. Given the above the problem of host overload detection can be formulated as an optimization problem 12 13 .

In the offline setting the state of the system is known at any point in time. Consider an offline algorithm that passes through the history of system states backwards starting from the last known state. The algorithm decrements the time and re calculates the OTF value

Theorem 1 Algorithm 1 is an optimal offline algorithm OPT for the problem of host overload detection.

Let the time interval covered by the system state history be t t and tbe the time returned by Algorithm 1. Then according to the algorithm the system states corresponding to the time interval t t do not satisfy the constraint 13 . Since tis the right bound of the interval t t then tis the maximum possible time that satisfies the constraint 13 . Therefore tis the solution of the optimization problem 12 13 and Algorithm 1 is an optimal offline algorithm for the host overload detection problem.

In the following sections the proposed model is based on the definitions of Markov chains a mathematical framework for statistical modeling of real world processes.

This section introduces the basic definitions of the Markov chains modeling framework. Bolch 8 provides a detailed introduction to Markov chains.

A stochastic process X X . . . X . . . at the consecutive points of observation 0 1 . . . n 1 constitutes a Discrete Time Markov Chain DTMC if the following relation on the conditional Probability Mass Function PMF holds n N and s S N . 14 

Given an initial state s a DTMC evolves step by step according to the one step transition probabilities . 15 

If the conditional PMF is independent of the time parameter n the DTMC is referred to as time homogeneous and 15 reduces to p P X j X i n T. Starting from a state i the DTMC transitions to a state j so that

Let t T be the time parameter where TR 0 let S be the state space of the stochastic process comprising all possible values of X for each t T . A stochastic process X t T constitutes a Markov process if for all 0 t

A stochastic process X t T constitutes a Continuous Time Markov Chain CTMC if for arbitrary t R with 0 t

The embodiments herein focus on time homogeneous Markov chains which can also be described as Markov chains with stationary transition probabilities. Time homogeneous Markov chains correspond to stationary workloads i.e. workloads whose statistical properties do not change over time. As provided below it is shown how a time homogeneous Markov model can be adapted to cases of non stationary workloads.

Another characteristic that describes transitions of a CTMC between the states is the instantaneous transition rate q t of the CTMC traveling from state i to state j. The non negative finite continuous functions q t satisfy the following conditions 

A vector t t i S contains the probabilities that the CTMC will be in the state i at the time t. Using the Kolmogorov forward equation 8 the following equation for the unconditional state probability vector t can be derived 

A transition probability matrix P of an ergodic DTMC e.g. a DTMC with all the transition probabilities being non zero can be transformed into an infinitesimal generator matrix of the corresponding CTMC as follows 20 where I is the identity matrix. Next using the definitions given in this section a Markov chain model for the host overload detection problem is introduced. The Host Model

Each VM allocated to a host at each point in time utilizes a part of the CPU capacity determined by the application workload. The CPU utilization created over a period of time by a set of VMs allocated to a host constitutes the host s workload. For the initial analysis it is assumed that the workload is known a priori stationary and satisfies the Markov property. In other words the CPU utilization of a host measured at discrete time steps can be described by a single time homogeneous DTMC.

There is a controller component which monitors the CPU utilization of the host and according to a host overload detection algorithm decides when a VM should be migrated from the host to satisfy the QoS requirements while maximizing the time between VM migrations. As provided above the problem formulation is limited to a single VM migration i.e. the time span of a problem instance is from the end of a previous VM migration to the end of the next.

To describe a host as a DTMC states are assigned to N subsequent intervals of the CPU utilization. For example if N 11 the state 1 is assigned to all possible values of the CPU utilization within the interval 0 10 2 to the CPU utilization within 10 20 . . . N to the value 100 . The state space S of the DTMC contains N states which correspond to the defined CPU utilization intervals. Using this state definition and knowing the workload of a host in advance by applying the Maximum Likelihood Estimation MLE method it is possible to derive a matrix of transition probabilities P. The matrix is constructed by estimating the probabilities of transitions

An additional state N 1 is added to the Markov chain called an absorbing state. A state k S is said to be an absorbing state if and only if no other state of the Markov chain can be reached from it i.e. p 1. In other words once the Markov chain reaches the state k it stays in that state indefinitely. The resulting extended state space is S S N 1 . According to the model provided by the embodiments herein the absorbing state N 1 represents the state where the DTMC transitions once a VM migration is initiated. According to this definition the control policy can be described by a vector of the probabilities of transitions from any non absorbing state to the absorbing state N 1 i.e. the probabilities of VM migrations which are denoted m where i S. To add the state N 1 into the model the initial transition probability matrix P is extended with a column of unknown transition probabilities m m i S resulting in an extended matrix of transition probabilities P 

In general the workload experienced by the host s VMs can lead to any CPU utilization from 0 to 100 therefore the original DTMC can be assumed to be ergodic. Later the extended DTMC will be restricted to the states in S therefore using Q P I 8 the extended matrix of transition probabilities P can be transformed into a corresponding extended matrix of transition rates Q 

In the next section a QoS constraint is formulated in terms of the introduced model derived extended matrix of transition rates Q and OTF metric.

Let N denote the state of a host when it is overloaded e.g. when the CPU utilization is equal to 100 then the expected time spent in the state N before absorption can be calculated by finding L from a solution of the system of linear equations 26 . Similarly the total expected time of the host being active can be found as

By the solution of 26 closed form equations for . . . are obtained. The unknowns in these equations are m m . . . m which completely describe the policy of the controller. In the model provided by the embodiments herein the utility function is the total expected time until absorption as the objective is to maximize the inter migration time. To introduce the QoS goal in the problem formulation a limit M on the maximum allowed value of the OTF metric is specified as a constraint resulting in the following optimization problem 

The equations 28 29 form an NLP problem. The solution of this NLP problem is the vector m of the probabilities of transitions to the absorbing state which forms the optimal control policy defined as a PMF m m i S. At every time step the optimal control policy migrates a VM with the probability m where i S is the current state. The control policy is deterministic if k S m 1 and i S i m 0 otherwise the policy is randomized.

Since the total time until absorption and Tare non negative the problem formulation 28 29 can be simplified to 30 31 .

The introduced model allows the computation of the optimal control policy of a host overload detection controller for a given stationary workload and a given state configuration. It is important to take into account that this result is based on a few fundamental modeling assumptions. First it is assumed that the system satisfies the Markov property or in other words the sojourn times i.e. the time a CTMC remains in a state are exponentially distributed. Assuming an exponential distribution of sojourn times may not be accurate in many systems. For instance state transition delays can be deterministic due to a particular task scheduling or follow other than exponential statistical distribution such as a bell shaped distribution. Another implication of the Markov property is the assumption of memoryless state transitions which means that the future state can be predicted solely based on the knowledge of the current state. It is possible to envision systems in which future states depend on more than one past state.

Another assumption is that the workload is stationary and known a priori which does not hold in typical computing environments. In the next section it is shown how the introduced model can be heuristically adapted to handle unknown non stationary workloads. The proposed heuristically adapted model removes the assumption of stationary and known workloads however the assumptions implied by the Markov property must still hold. Further below the proposed heuristically adapted model is evaluated and the assumptions are tested through a simulation study using real workload traces from more than a thousand PlanetLab VMs. The simulation results show that the model is efficient for this type of mixed computing workloads.

With a correct understanding of the basic model assumptions and careful assessment of the applicability of the proposed model to a particular system an application of the model can bring substantial performance benefits to the resource management algorithms. As demonstrated by the simulation study provided below the proposed approach outperforms the benchmark algorithms in terms of both the mean inter migration time and the precision of meeting the specified QoS goal.

The model introduced above works with the assumption that the workload is stationary and known. However this is not the case in systems with unknown non stationary workloads such as IaaS. One of the ways to adapt the model defined for known stationary workloads to the conditions of initially unknown non stationary workloads is to apply the Sliding Window workload estimation approach proposed by Chung et al. 10 .

The base idea is to approximate a non stationary workload as a sequence of stationary workloads U u u . . . u that are enabled one after another. In this model the transition probability matrix P becomes a function of the current stationary workload P u .

Chung et al. 10 called a policy that makes ideal decisions for a current stationary workload uthe best adaptive policy. However the best adaptive policy requires the perfect knowledge of the whole sequence of workloads U and the times at which the workloads change. In reality a model of a workload ucan only be built based on the observed history of the system behavior. Moreover the time at which the current workload changes is unknown. Therefore it is necessary to apply a heuristic that achieves results comparable to the best adaptive policy. According to the Sliding Window approach a time window of length lslides over time and is always capturing the last levents. Let cbe the observed number of transitions between states i and j i j S during the last window l. Then applying the MLE method the transition probability pis estimated as

1. The biased estimation error which appears when the window length lis shorter than the length of a sequence of outliers.

2. The resolution error referred to as the sampling error by Luiz et al. 22 which is introduced due to the maximum precision of the estimates being limited to 1 l.

3. The adaptation time referred to as the identification delay by Luiz et al. 22 which is a delay required to completely fill the window with new data after a switch from a stationary workload uto a new stationary workload u.

Luiz et al. 22 extended the Sliding Window approach by employing multiple windows with different sizes where a window to use is selected dynamically using the information about the previous system state and variances of the estimates obtained from different windows. They referred to the extended approach as the Multisize Sliding Window approach. The proposed algorithm dynamically selects the best window size to eliminate the bias estimate error and benefit from both the small sampling error of large window sizes and small identification error of small window sizes. The embodiments herein use the Multisize Sliding Window approach to the model introduced above to adapt it to initially unknown non stationary workloads.

The calculation of the expected OTF 27 is adapted by transforming it to a function of t R to incorporate the information that is known by the algorithm at the time of decision making 

This section briefly introduces the Multisize Sliding Window approach for more details reasoning and analysis please refer to Luiz et al. 22 . A high level view of the estimation algorithm is shown in with reference to . First to eliminate the biased estimation error the previous history is stored separately for each state in S resulting in S state windows W i 1 2 . . . S.

Let J D and Nbe positive numbers the following represents a sequence of window sizes 2 1 1 is the maximum window size. At each time t the Previous State Buffer stores the system state sat the time t 1 and controls the window selector which selects a window Wsuch that s i. The notation W t denotes the content of the window Win a position k at the time t. The selected window shifts its content one position to the right to store the current system state 1 . . . discards the rightmost element W t and stores sin the position W t . Once the selected state window Wis updated new probability estimates are computed based on this state window for all window sizes as follows 

Similar to the update process of the state windows the selected estimate windows shift their contents one position to the right discard the rightmost element E t and store p t L in the position E t . To evaluate the precision of the probability estimates the variance S i j t m of the probability estimates obtained from every updated estimate window is estimated 

Using the function of acceptable variance probability estimates are considered to be adequate if S i j t m V p t m m 

Based on the definitions given above a window size selection algorithm can be defined Algorithm 2 . According to the selected window sizes transition probability estimates 24 are selected from the estimate windows.

1. The biased estimation error is eliminated by introducing dedicated history windows for each state even if a burst of transitions to a particular state is longer than the length of the window the history of transitions from the other states is preserved.

2. The sampling error is minimized by selecting the largest window size constrained by the acceptable variance function.

3. The identification error is minimized by selecting a smaller window size when the variance is high which can be caused by a change to the next stationary workload.

A control algorithm based on the model introduced above is referred to as the Optimal Markov Host Overload Detection MHOD OPT algorithm. The MHOD OPT algorithm adapted to unknown non stationary workloads using the Multisize Sliding Window workload estimation technique introduced above is referred to as the Markov Host Overload Detection MHOD algorithm. A high level view of the MHOD OPT algorithm is shown in Algorithm 3. In the online setting the algorithm is invoked periodically at each time step to make a VM migration decision.

Closed form equations for L L . . . L are precomputed offline from 26 therefore the run time computation is not required. The values of transition probabilities are substituted into the equations for . . . and the objective and constraint functions of the NLP problem are generated by the algorithm. To solve the NLP problem a brute force search algorithm with a step of 0.1 is applied as its performance was sufficient for the purposes of simulations. In MHOD OPT a decision to migrate a VM is made only if either no feasible solution can be found or the migration probability corresponding to the current state is 1.

The justification for this is the fact that if a feasible solution exists and the migration probability is less than 1 then for the current conditions there is no hard requirement for an immediate migration of a VM.

The MHOD algorithm shown in Algorithm 4 can be viewed as a wrapper over the MHOD OPT algorithm which adds the Multisize Sliding Window workload estimation. During the initial learning phase T which was set to 30 time steps the algorithm does not migrate a VM. Once the learning phase is over the algorithm applies the Multisize Sliding Window technique to estimate the probabilities of transitions between the states and invokes the MHOD OPT algorithm passing the transition probability estimates as the argument. The result of the MHOD OPT algorithm invocation is returned to the user.

The proposed models and algorithms are suitable for both single core and multi core CPU architectures. The capacity of a single core CPU is modeled in terms of its clock frequency F. A VM s CPU utilization uis relative to the VM s CPU frequency fand is transformed into a fraction of the host s CPU utilization U. These fractions are summed up over the N VMs allocated to the host to obtain the host s CPU utilization as shown in 37 .

For the purpose of the host overload detection problem multi core CPUs are modeled as proposed in 3 . A multi core CPU with n cores each having a frequency f is modeled as a single core CPU with the nf frequency. In other words F in 37 is replaced by nf. This simplification is justified as applications and VMs are not tied down to a specific core but can by dynamically assigned to an arbitrary core by a time shared scheduling algorithm. The only physical constraint is that the CPU capacity allocated to a VM cannot exceed the capacity of a single core. Removing this constraint would require the VM to be executed on more than one core in parallel. However automatic parallelization of VMs and their applications cannot be assumed.

The purpose of this section is to show that the precision of the workload estimation technique is desirable to achieve high performance of the MHOD algorithm. To show this an artificial workload was constructed that illustrates a case when the MHOD algorithm with the Multisize Sliding Window workload estimation leads to lower performance compared to MHOD OPT due to its inability to adapt quickly enough to a highly non stationary workload.

The simulation results are shown in Table 2. According to the results for the workload defined in Table 1 the MHOD OPT algorithm provides exactly the same performance as the optimal offline algorithm OPT . However the MHOD algorithm migrates a VM at the beginning of the third stationary workload because it is not able to immediately recognize the change of the workload as shown for pand pin with reference to .

In summary even though the Multisize Sliding Window workload estimation provides high quality of estimation 22 in some cases it may result in an inferior performance of the MHOD algorithm compared to MHOD OPT. This result was expected as MHOD OPT skips the estimation phase and utilizes the knowledge of real transition probabilities. The artificial workload used in this section was specifically constructed to show that imprecise workload estimation may lead to unsatisfactory performance of the MHOD algorithm. However as shown in the next section the MHOD algorithm performs closely to OPT for real world workloads.

In an environment with multiple hosts the MHOD algorithm operates in a decentralized manner where independent instances of the algorithm are executed on every host. Therefore to evaluate the MHOD algorithm under a real world workload a single host with a quad core CPU serving a set of heterogeneous VMs was simulated. The clock frequency of a single core of the host was set to 3 GHz which according to the model introduced above transforms into 12 GHz. These CPU characteristics correspond to a mid range Amazon EC2 physical server type 24 . The amount of the host s memory is assumed to be enough for the VMs. The CPU frequency of a VM was randomly set to one of the values approximately corresponding to the Amazon EC2 instance types 1.7 GHz 2 GHz 2.4 GHz and 3 GHz. The CPU utilization of the VMs was simulated based on the data provided as a part of the CoMon project a monitoring infrastructure for PlanetLab 27 . The project provides the data measured every five minutes from more than a thousand VMs running in more than 500 locations around the world. For the experiments ten days were randomly selected from the workload traces collected during March and April 2011.

For a simulation run a randomly generated set of VMs with the CPU utilization traces assigned is allocated to the host. At each time step the host overload detection algorithm makes a decision of whether a VM should be migrated from the host. The simulation runs until either the CPU utilization traces are over or until a decision to migrate a VM is made by the algorithm. At the end of a simulation run the resulting value of the OTF metric is calculated according to 11 . The algorithm of assigning the workload traces to a set of VMs is presented in Algorithm 5. To avoid trivial cases and stress the algorithms with more dynamic workloads the original workload traces were filtered. The maximum allowed OTF after the first 30 time steps was constrained to 10 and the minimum overall OTF was constrained to 20 . Using the workload assignment algorithm 100 different sets of VMs that meet the defined OTF constraints were pregenerated. Every algorithm was run for each set of VMs.

In addition to the optimal offline algorithm introduced above a number of benchmark algorithms were implemented. The benchmark algorithms were run with different parameters to compare with the proposed MHOD algorithm. This section gives a brief overview of the benchmark algorithms a detailed description of each of them is given in 3 . The first algorithm is a simple heuristic based on setting a CPU utilization threshold THR which monitors the host s CPU utilization and migrates a VM if the defined threshold is exceeded. This threshold based heuristic was applied in a number of related works 40 15 16 33 . The next two algorithms apply statistical analysis to dynamically adapt the CPU utilization threshold based on the median absolute deviation MAD and on the interquartile range IQR .

Two other algorithms are based on estimation of the future CPU utilization using local regression and a modification of the method robust to outliers referred to as robust local regression. These algorithms are denoted Local Regression LR and Local Regression Robust LRR respectively. The LR algorithm is in line with the regression based approach proposed by Guenter et al. 17 . Another algorithm continuously monitors the host s OTF and decides to migrate a VM if the current value exceeds the defined parameter. This algorithm is referred to as the OTF Threshold OTFT algorithm. The last benchmark algorithm the OTF Threshold Migration Time OTFTM algorithm is similar to OTFT however it uses an extended metric that includes the VM migration time 

To shorten state configuration names of the MHOD algorithm they are referred to by denoting the thresholds between the utilization intervals. For example a 3 state configuration 0 80 80 100 100 is referred to as 80 100. The following 2 and 3 state configurations of the MHOD algorithm were simulated 80 100 90 100 and 100 a 2 state configuration . Each state configuration with the OTF parameter set to 10 20 and 30 was simulated. For experiments the VM migration time was set to 30 secs.

In order to find out whether different numbers of states and different state configurations of the MHOD algorithm significantly influence the algorithm s performance in regard to the time until a migration and the resulting OTF value paired t tests were conducted. The tests on the produced time until a migration data for comparing MHOD 80 100 with MHOD 100 and MHOD 90 100 with MHOD 100 showed non statistically significant differences with the p values 0.20 and 0.34 respectively. This means that the simulated 2 and 3 state configurations of the MHOD algorithm on average lead to approximately the same time until a migration. However there are statistically significant differences in the resulting OTF value produced by these algorithms 0.023 with 95 Confidence Interval CI 0.001 0.004 and p value 0.033 for MHOD 100 compared with MHOD 80 100 and 0.022 with 95 CI 0.000 0.004 and p value 0.048 for MHOD 100 compared with MHOD 90 100. However differences in the resulting OTF value in the order of less than 0.1 are not practically significant therefore the conclusion is that the simulated 2 and 3 state configurations produce approximately the same results. Further in this section only the 0 100 100 2 state configuration of MHOD is compared with the benchmark algorithms as it requires simpler computations compared with the 3 state configurations.

The experimental results comparing the 2 state configuration of the MHOD algorithm for the MHOD algorithm the OTF parameter is denoted in the suffix of the algorithm s name e.g. for 10 20 and 30 MHOD 10 MHOD 20 and MHOD 30 with the benchmark algorithms are depicted in with reference to . It is remarkable how closely the resulting OTF value of the MHOD algorithm resembles the value set as the parameter of the algorithm for 10 and 20 . The wider spread for 30 is explained by the characteristics of the workload in many cases the overall OTF is lower than 30 which is also reflected in the resulting OTF of the optimal offline algorithm OPT 30 . The experimental results show that the algorithm is capable of meeting the specified OTF goal which is consistent with the theoretical model introduced above.

As intended paired t tests for the comparison of MHOD with LR and MHOD with LRR showed non statistically significant differences in the resulting OTF values with both p values 0.9. Results of paired t tests for comparing the time until a migration produced by the algorithms with matching resulting OTF values are shown in Table 3. The MHOD and LRR algorithms are graphically compared in with reference to .

According to the results there is a statistically significant difference in the time until a migration produced by the algorithms the MHOD algorithm on average leads to approximately 10.5 and 11.3 shorter time until a migration than LR and LRR respectively with the same mean resulting OTF values. This means that the MHOD algorithm leads to a slightly lower quality of VM consolidation compared with the LR and LRR algorithms while providing the advantage of explicit specification of a QoS goal in terms of the OTF metric. In contrast the performance of the LR and LRR algorithms in regard to the QoS can only be adjusted indirectly by tuning the safety parameter. As seen in the lower time until a migration produced of the MHOD algorithm can be partially explained by the fact that the spread of the resulting OTF produced by the LRR algorithm is much wider than that of MHOD while MHOD precisely meets the specified QoS goal. This means that in many cases LRR provides worse QoS than MHOD which leads to a higher time until a migration.

OTFT and OTFTM are two other algorithms that apart from the MHOD algorithm allow explicit specification of the QoS goal in terms of the OTF parameter. To compare the performance of the OTFT OTFTM and MHOD algorithms another performance metrics introduced. This metric is the percentage of SLA violations relatively to the total number of VM migrations where SLA requirements are defined as OTF M M is the limit on the maximum allowed resulting OTF value. The SLA violation counter is incremented if after a VM migration the resulting OTF is higher than the value M specified in the SLAs.

The OTFT OTFTM and MHOD algorithms were simulated using the PlanetLab workload described earlier. The algorithms were simulated with the following values of the OTF parameter set as the SLA requirement 10 20 and 30 . The simulation results are shown in with reference to . The graphs show that MHOD leads to slightly lower resulting OTF values and time until a migration. The SLA violation levels caused by the algorithms are shown in Table 4. It is clear that the MHOD algorithm substantially outperforms the OTFT and OTFTM algorithms in the level of SLA violations leading to only 0.33 SLA violations whereas both OTFT and OTFTM cause SLA violations of 81.33 .

The obtained results can be explained by the fact that both OTFT and OTFTM are unable to capture the overall behavior of the system over time and fail to meet the SLA requirements. In contrast the MHOD algorithm leverages the knowledge of the past system states and by estimating future states avoids SLA violations. For instance in a case of a steep rise in the load OTFT and OTFTM react too late resulting in an SLA violation. In contrast MHOD acts more intelligently and by predicting the potential rise migrates a VM before an SLA violation occurs. As a result for the simulated PlanetLab workload the MHOD algorithm keeps the level of SLA violations at less than 0.5 .

There is a statistically significant difference in the time until a migration with the mean difference of 4 639 with 95 CI 3617 5661 . Relatively to OPT the time until a migration produced by the MHOD algorithm converts to 88.02 with 95 CI 86.07 89.97 . This means that for the simulated PlanetLab workload the MHOD algorithm on average delivers approximately 88 of the performance of the optimal offline algorithm which is highly efficient for an online algorithm.

This section introduces an architecture and implementation of OpenStack Neat a software framework computer program product for distributed dynamic VM consolidation in Cloud data centers based on the OpenStack platform. The framework is designed and implemented as a transparent add on to OpenStack which means that the OpenStack installation need not be modified or specifically configured to benefit from OpenStack Neat. with reference to depicts a typical system deployment of the key components of OpenStack and OpenStack Neat which may include multiple instances of compute and controller hosts . The framework acts independently of the base OpenStack platform and applies VM consolidation processes by invoking public Application Programming Interfaces APIs of OpenStack. The purpose of the OpenStack Neat framework is twofold 1 providing a fully operational software for dynamic VM consolidation that can be applied to existing OpenStack Clouds and 2 providing an extensible software framework for conducting research on dynamic VM consolidation.

OpenStack Neat is designed and implemented following the distributed approach to dynamic VM consolidation introduced previous sections. The target environment is an IaaS e.g. Amazon EC2 where the provider is unaware of applications and workloads served by the VMs and can only observe them from outside. The proposed approach to distributed dynamic VM consolidation consists in splitting the problem into four sub problems underload overload detection VM selection and VM placement.

The current implementation of OpenStack Neat assumes a single instance of the controller responsible for placing VMs selected for migrations on hosts. However due to distributed underload overload detection and VM selection algorithms the overall scalability is significantly improved compared with existing centralized solutions. Furthermore it is potentially possible to implement replication of OpenStack Neat s global manager which would provide a completely distributed system as discussed below.

Research work can be divided into two categories 1 theoretical work on various approaches to dynamic VM consolidation and 2 practically implemented and publicly available software systems. The framework presented in this case study follows the distributed approach to dynamic VM consolidation proposed in the previous sections where every compute host locally solves the problems of underload overload detection and VM selection. Then it sends a request to a global manager to place only the selected for migration VMs on other hosts.

A similar approach was followed by Wood et al. 36 in their system called Sandpiper aimed at load balancing in virtualized data centers using VM live migration. The main objective of the system is to avoid host overloads referred to as hot spots by detecting them and migrating overloaded VMs to less loaded hosts. The authors applied an application agnostic approach referred to as a black box approach in which VMs are observed from outside without any knowledge of applications resident in the VMs. A hot spot is detected when the aggregate usage of a host s resources exceeds the specified threshold for k out of n last measurements as well as for the next predicted value. Another proposed approach is gray box when a certain application specific data are allowed to be collected. The VM placement is computed heuristically by placing the most loaded VM to the least loaded host. The difference from the approach proposed in this case study is that VMs are not consolidated therefore the number of active hosts is not reduced to save energy.

Despite the large volume of research published on the topic of dynamic VM consolidation there are very few software implementations publicly available online. One of the earliest implementation of a VM consolidation manager is the Entropy project. Entropy is a VM consolidation manager for homogeneous clusters developed by Hermenier et al. 18 and released under the LGPL license. Entropy is built on top of Xen and focused on two objectives 1 maintaining a configuration of the cluster where all VMs are allocated sufficient resources and 2 minimizing the number of active hosts.

To optimize the VM placement Entropy applies a two phase approach. First a constraint programming problem is solved to find an optimal VM placement which minimizes the number of active hosts. Then another optimization problem is solved to find a target cluster configuration with the minimal number of active hosts that also minimizes the total cost of reconfiguration which is proportional to the cost of VM migrations. In comparison to OpenStack Neat Entropy may find a more optimal VM placement by computing a globally optimal solution for VM placement. However the required optimization problems must be solved by a central controller with limited opportunities for replication thus limiting the scalability of the system and introducing a single point of failure. This approach is applicable to relatively small scale private Clouds however it cannot be applied to large scale data centers with tens of thousands of nodes such as Rackspace 28 where decentralization and fault tolerance are essential.

Feller et al. 12 13 proposed and implemented a framework for distributed management of VMs for private Clouds called Snooze. In addition to the functionality provided by the existing Cloud management platforms such as OpenStack Eucalyptus and OpenNebula Snooze implements dynamic VM consolidation as one of its base features. Another difference is that Snooze implements hierarchical distributed resource management. The management hierarchy is composed of three layers local controllers on each physical node group managers managing a set of local controllers and a group leader dynamically selected from the set of group managers and performing global management tasks. The distributed structure enables fault tolerance and self healing by avoiding single points of failure and automatically selecting a new group leader if the current one fails.

Snooze also integrates monitoring of the resource usage by VMs and hosts which can be leveraged by VM consolidation policies. These policies are intended to be implemented at the level of group managers and therefore can only be applied to subsets of hosts. This approach partially solves the problem of scalability of VM consolidation by the cost of losing the ability of optimizing the VM placement across all the nodes of the data center. OpenStack Neat enables scalability by distributed underload overload detection and VM selection and potentially replicating the VM placement controllers. In contrast to Snooze it is able to apply global VM placement algorithms for the selected for migration VMs by taking into account the full set of hosts. Another difference is that OpenStack Neat transparently integrates with OpenStack a Cloud platform widely adopted and supported by the industry thus ensuring long term development of the platform.

The aim of the OpenStack Neat project is to provide an extensible framework for dynamic consolidation of VMs based on the OpenStack platform. Extensibility in this context means the ability to implement new VM consolidation algorithms and apply them in OpenStack Neat without the necessity to modify the source code of the framework itself. Different implementations of the algorithms can be plugged into the framework by modifying the appropriate options in the configuration file. More information on configuring and extending the framework is given below.

OpenStack Neat provides an infrastructure required for monitoring VMs and hypervisors collecting resource usage data transmitting messages and commands between the system components and invoking VM live migrations. The infrastructure is agnostic to VM consolidation algorithms in use and allows implementing custom decision making algorithms for each of the four sub problems of dynamic VM consolidation host underload overload detection VM selection and VM placement. The implementation of the framework includes the algorithms proposed in sections. The following sections discuss the requirements and assumptions integration of the proposed framework with OpenStack each of the framework s components as well as configuration and extensibility of the framework.

The components of the framework are implemented in the form of OS services running on the compute and controller hosts of the data center in addition to the core OpenStack services. The framework components interact through a Representational State Transfer REST interface therefore network communication via the corresponding port specified in the framework s configuration must be enabled.

OpenStack Neat relies on live migration to dynamically relocate VMs across physical machines. To enable live migration it is required to set up a shared storage and correspondingly configure OpenStack Nova i.e. the OpenStack Compute service to use this storage for storing VM instance data. For instance a shared storage can be provided using the Network File System NFS or the GlusterFS distributed file system 5 .

OpenStack Neat uses a database for storing information about VMs and hosts as well as resource usage data. It is possible to use the same database server used by the core OpenStack services. In this case it is only required to create a new database and user for OpenStack Neat. The required database tables are automatically created by OpenStack Neat on the first launch of its services.

Another requirement is that all the compute hosts must have a user which is enabled to switch the host into a low power mode such as Suspend to RAM. This user account is used by the global manager to connect to the compute hosts via the Secure Shell SSH protocol and switch them into the sleep mode when necessary. More information on deactivating and reactivating physical nodes is given below.

Since OpenStack Neat is implemented in Python VM consolidation algorithms to be plugged in should also be implemented in Python. It may be required to implement VM consolidation algorithms in another programming language for various reasons such as performance requirements. Integration of such algorithms can be achieved by providing Python wrappers that redirect calls to the corresponding external programs.

OpenStack Neat services are installed independently of the core OpenStack services. Moreover the activity of the OpenStack Neat services is transparent to the core OpenStack services. This means that OpenStack does not need to be configured in a special way to be able to take advantage of dynamic VM consolidation implemented by OpenStack Neat. It also means that OpenStack Neat can be added to an existing OpenStack installation without the need to modify its configuration.

The transparency is achieved by the independent resource monitoring implemented by OpenStack Neat and the interaction with the core OpenStack services using their public APIs. The OpenStack APIs are used for obtaining information about the current state of the system and performing VM migrations. In particular the APIs are used to get the current mapping of VMs to hosts hardware characteristics of hosts parameters of VM flavors i.e. instance types VM states and invoke VM live migrations. Although OpenStack Neat performs actions affecting the current state of the system by relocating VMs across hosts it is transparently handled by the core OpenStack services since VM migrations are invoked via the public OpenStack APIs which is equivalent to invoking VM migrations manually by the system administrator.

In the following sections hosts running the Nova Compute service i.e. hosting VM instances are referred to as compute hosts and a host running the other OpenStack management services but not hosting VM instances is referred to as the controller host.

OpenStack Neat is composed of a number of components and data stores some of which are deployed on the compute hosts and some on the controller host which can potentially have multiple replicas. As shown in with reference to the system is composed of three main components 

The deployment model may vary for each particular system depending on its requirements. For instance the central database can be deployed on a separate physical node or be distributed across multiple physical nodes. The location and deployment of the database server e.g. central database is transparent to OpenStack Neat which only requires a configuration parameter to be set to the network address of the database front end server. For simplicity in the experimental testbed used in this case study the database server e.g. central database is deployed on the same physical node hosting the global manager as shown in .

The global manager is deployed on the controller host and is responsible for making VM placement decisions and initiating VM migrations. It exposes a REST web service which accepts requests from local managers . The global manager processes two types of requests 1 relocating VMs from an underloaded host and 2 offloading a number of VMs from an overloaded host.

As shown in with reference to handling overload requests is similar to underload requests. The difference is that instead of sending just the host name the local manager also sends a list of UUIDs of the VMs selected by the configured VM selection algorithm to be offloaded from the overloaded host. Once the request is received the global manager invokes the specified in the configuration VM placement algorithm and passes as arguments the list of VMs received from the local manager to be placed on other hosts along with other system information. If some of the VMs are placed on hosts that are currently in the sleep mode the global manager reactivates them using the Wake on LAN technology as described below. Then similarly to handling underload requests the global manager submits VM live migration requests to the OpenStack Nova API .

The global manager exposes a REST web service REST API for processing VM migration requests sent by local managers. The service Uniform Resource Locator URL is defined according to configuration options specified in etc neat neat.conf which is discussed in detail below. The two relevant options are 

Using these configuration options the service URL is composed according to the following template http global manager host global manager port . The global manager processes two types of requests from local managers host underloads and host overloads discussed in the previous section. Both types of requests are served at a single resource accessed using the PUT method of the Hypertext Transfer Protocol HTTP . The type of a received request is determined by the global manager by analyzing the parameters included in the request. The following parameters are common to both types of requests 

If the request type specified by the reason parameter is 1 i.e. denoting an overload request there is an extra mandatory parameter vm uuids. This is a string parameter which must contain a coma separated list of Universally Unique Identifiers UUIDs of VMs selected for migration from the overloaded host.

If a request contains all the required parameters and the provided credentials are correct the service responds with the HTTP status code 200 OK. The service uses standard HTTP error codes to respond in cases of errors. The following error codes are used 

One of the main features required to be supported by the hardware and OS in order to take advantage of dynamic VM consolidation to save energy is the Advanced Configuration and Power Interface ACPI . The ACPI standard defines platform independent interfaces for power management by the OS. The standard is supported by Linux the target OS for the OpenStack platform. ACPI defines several sets of power states the most relevant of which is the sleep state S3 referred to as Suspend to RAM. Meisner et al. 23 showed that power consumption of a typical blade server can be reduced from 450 W in the active state to just 10.4 W in the S3 state. The transition latency is currently mostly constrained by the Power Supply Unit PSU of the server which leads to the total latency of approximately 300 ms. This latency is acceptable for the purposes of dynamic VM consolidation as VM live migrations usually take tens of seconds.

The Linux OS provides an API to programmatically switch the physical machine into the sleep mode. In particular CentOS supports a pm utils package which includes command line programs for changing the power state of the machine. First to check whether the Suspend to RAM state is supported the following command can be used pm is supported suspend. If the command returns 0 the Suspend to RAM state is supported otherwise it is not supported. If the state is supported the following command can be used to enable it pm suspend.

It is possible to reactivate a physical machine over the network using the Wake on LAN technology. This technology has been introduced in 1997 by the Advanced Manageability Alliance AMA formed by Intel and IBM and is currently supported by most modern servers. To reactivate a server using Wake on LAN it is necessary to send over the network a special packet called the magic packet. This can be done using the ether wake Linux program as follows ether wake i interface mac address where interface is replaced with the name of the network interface to send the packet from and mac address is replaced with the actual Media Access Control MAC address of the host to be reactivated.

The local manager component is deployed on every compute host as an OS service running in the background. The service periodically executes a function that determines whether it is necessary to reallocate VMs from the host. A high level view of the workflow performed by the local manager is shown in with reference to . At the beginning of each iteration it reads from the local storage the historical data on the resource usage by the VMs and hypervisor stored by the data collector . Then the local manager invokes the specified in the configuration underload detection algorithm to determine whether the host is underloaded. If the host is underloaded the local manager sends an underload request to the global manager s REST API to migrate all the VMs from the host and switch the host to a low power mode.

If the host is not underloaded the local manager proceeds to invoking the specified in the configuration overload detection algorithm. Then another decision process occurs. If the host is overloaded the local manager invokes the configured VM selection algorithm to select VMs to offload from the host. Once the VMs to migrate from the host are selected the local manager sends an overload request to the global manager s REST API to migrate the selected VMs. Similar to the global manager the local manager can be configured to use custom underload detection overload detection and VM selection algorithms using the configuration file discussed below.

The data collector is deployed on every compute host as an OS service running in the background. The service periodically collects the CPU utilization data for each VM running on the host as well as data on the CPU utilization by the hypervisor. The collected data are stored in the local file based data store and also submitted to the central database . The data are stored as the average number of MHz consumed by a VM during the last measurement interval of length T. In particular the CPU usage C t t of a VM i which is a function of the bounds of a measurement interval t t is calculated as shown in 39 .

The actual data are obtained using libvirt s API in the form of the CPU time consumed by VMs and hosts overall to date. Using the CPU time collected at the previous time step the CPU time for the last time interval is calculated. According to the CPU frequency of the host and the length of the time interval the CPU time is converted into the required average MHz consumed by the VM over the last time interval. Then using the VMs CPU utilization data the CPU utilization by the hypervisor is calculated. The collected data are stored both locally and submitted to the central database . The number of the latest data values to be stored locally and passed to the underload overload detection and VM selection algorithms is defined by the data collector data length option in the configuration file.

At the beginning of every iteration the data collector obtains the set of VMs currently running on the host using the Nova API and compares them to the VMs running on the host at the previous time step. If new VMs have been found the data collector fetches the historical data about them from the central database and stores the data in the local file based data store . If some VMs have been removed the data collector removes the data about these VMs from the local data store .

While OpenStack Neat oversubscribes the CPU of hosts by taking advantage of information on the real time CPU utilization it does not overcommit RAM. In other words RAM is still a constraint in placing VMs on hosts however the constraint is the maximum amount of RAM that can be used by a VM statically defined by its instance type rather than the real time RAM consumption. One of the reasons for that is that RAM is a more critical resource compared with the CPU as an application may fail due to insufficient RAM whereas insufficient CPU may just slow down the execution of the application. Another reason is that in contrast to the CPU RAM usually does not become a bottleneck resource as shown by an analysis of workload traces and information from the industry 29 1 .

The central database is used for storing historical data on the resource usage by VMs and hypervisors as well as hardware characteristics of hosts. The central database is populated by the data collectors deployed on compute hosts . There are two main use cases when the data are retrieved from the central database instead of the local storage of the compute hosts . First it is used by local managers to fetch the resource usage data after VM migrations. Once a VM migration is completed the data collector deployed on the destination host fetches the required historical data from the central database and stores them locally for use by the local manager .

The second use case of the central database is when the global manager computes a new placement of VMs on hosts. VM placement algorithms require information on the resource consumption of all the hosts in order to make global allocation decisions. Therefore every time there is a need to place VMs on hosts the global manager queries the central database to obtain the up to date data on the resource usage by hypervisors and VMs.

As shown in Table 6 the database schema contains four main tables hosts host resource usage vms and vm resource usage. The hosts table stores information about hosts such as the host names CPU frequency of a physical core in MHz number of CPU cores and amount of RAM in MB. The vms table stores the UUIDs of VMs assigned by OpenStack. The host resource usage and vm resource usage tables store data on the resource consumption over time by hosts and VMs respectively.

A local manager at each iteration requires data on the resource usage by the VMs and hypervisor of the corresponding host in order to pass them to the underload overload detection and VM placement algorithms. To reduce the number of queries to the central database over the network e.g. network in apart from submitting the data into the central database the data collector temporarily stores the data locally . This way the local manager can just read the data from the local file storage and avoid having to retrieve data from the central database .

The data collector stores the resource usage data locally in local data directory vms as plain text files where local data directory is defined in the configuration file discussed below. The data for each VM are stored in a separate file named after the UUID of the VM. The data on the resource usage by the hypervisor are stored in the local data directory host file. The format of the files is a new line separated list of integers representing the average CPU consumption in MHz during measurement intervals.

The configuration of OpenStack Neat is stored in the etc neat neat.conf file in the standard INI format using the character for denoting comments. It is assumed that this file exists on all the compute and controller hosts and contains the same configuration.

One of the ideas implemented in OpenStack Neat is providing the user with the ability to change the implementation and parameters of any of the four VM consolidation algorithms simply by modifying the configuration file. This provides the means of adding to the system and enabling custom VM consolidation algorithms without modifying the source code of the framework. The algorithms are configured using the options with the algorithm prefix. More information on adding and enabling VM consolidation algorithms is given below.

One of the main points of the framework s extensibility is the ability to add new VM consolidation algorithm to the system and enable them by updating the configuration file without the necessity in modifying the source code of the framework itself. There are four algorithms that can be changed through a modification of the configuration file underload overload detection VM selection and VM placement algorithms. The values of the corresponding configuration options should be fully qualified names of functions available as a part of one of the installed Python libraries. The fact that the functions are specified by their fully qualified names also means that they can be installed as a part of a Python library independent from OpenStack Neat. The four corresponding configuration options are the following 

Since an algorithm may need to be initialized prior to its usage the factory function pattern is applied. The functions specified as values of any of the algorithm   factory configuration options are not functions that actually implement VM consolidation algorithms rather they are functions that return initialized instances of functions implementing the corresponding VM consolidation algorithms. All functions implementing VM consolidation algorithms and their factories should adhere to the corresponding predefined interfaces. For example all factory functions of overload detection algorithms must accept a time step migration time and algorithm parameters as arguments. The function must return another function that implements the required consolidation algorithm which in turn must follow the interface predefined for overload detection algorithms.

Every function implementing an overload detection algorithm must 1 accept as arguments a list of CPU utilization percentages and dictionary representing the state of the algorithm and 2 return a tuple containing the decision of the algorithm as a boolean and updated state dictionary. If the algorithm is stateless it should return an empty dictionary as the state. Definitions of the interfaces of functions implementing VM consolidation algorithms and their factories are given in Table 7.

Using the algorithm   parameters configuration options it is possible to pass arbitrary dictionaries of parameters to VM consolidation algorithm factory functions. The parameters must be specified as an object in the JSON format on a single line. The specified JSON strings are automatically parsed by the system and passed to factory functions as Python dictionaries. Apart from being parameterized a consolidation algorithm may also preserve state across invocations. This can be useful for implementing stateful algorithms or as a performance optimization measure e.g. to avoid repeating costly computations. Preserving state is done by accepting a state dictionary as an argument and returning the updated dictionary as the second element of the return tuple.

Currently the data collector only collects data on the CPU utilization. It is possible to extend the system to collect other types of data that may be passed to the VM consolidation algorithms. To add another type of data it is necessary to extend the host resource usage and vm resource usage database tables by adding new fields for storing the new types of data. Then the execute function of the data collector should be extended to include the code required to obtain the new data and submit them to the central database . Finally the local managers and global managers need to be extended to fetch the new type of data from the central database to be passed to the appropriate VM consolidation algorithms.

OpenStack Neat needs to be deployed on all the compute hosts and controller hosts . The deployment includes installing dependencies cloning the project s Git repository installing the project and starting up the services. The process is cumbersome since multiple steps should be performed on each host. The OpenStack Neat distribution includes a number of Shell scripts that simplify the deployment process. The following steps are required to perform a complete deployment of OpenStack Neat 

Once all the steps listed above are completed OpenStack Neat s services should be deployed and started up. If any service fails the log files can be found in var log neat on the corresponding host.

As mentioned earlier OpenStack Neat is based on the approach to the problem of dynamic VM consolidation proposed in the previous sections which includes dividing the problem into four sub problems 1 host underload detection 2 host overload detection 3 VM selection and 4 VM placement. This section discusses some of the implemented algorithms.

In the experiments of this case study a simple heuristic is used for the problem of underload detection shown in Algorithm 6. The algorithm calculates the mean of the n latest CPU utilization measurements and compares it to the specified threshold. If the mean CPU utilization is lower than the threshold the algorithm detects a host underload situation. The algorithm accepts three arguments the CPU utilization threshold the number of last CPU utilization values to average and a list of CPU utilization measurements.

OpenStack Neat includes several overload detection algorithms which can be enabled by modifying the configuration file. One of the simple included algorithms is the averaging Threshold based THR overload detection algorithm. The algorithm is similar to Algorithm 6 while the only difference is that it detects overload situations if the mean of the n last CPU utilization measurements is higher than the specified threshold.

Another overload detection algorithm included in the default implementation of OpenStack Neat is based on estimating the future CPU utilization using local regression i.e. the Loess method referred to as the Local Regression Robust LRR algorithm shown in Algorithm 7 which has been introduced in 3 . The algorithm calculates the Loess parameter estimates and uses them to predict the future CPU utilization at the next time step taking into account the VM migration time. In addition the LR algorithm accepts a safety parameter which is used to scale the predicted CPU utilization to increase or decrease the sensitivity of the algorithm to potential overloads.

A more complex overload detection algorithm included in OpenStack Neat is the Markov Overload Detection MHOD algorithm introduced and described in detail in the previous sections.

Once a host overload has been detected it is necessary to determine what VMs are the best to be migrated from the host. This problem is solved by VM selection algorithms. An example of such an algorithm is simply randomly selecting a VM from the set of VMs allocated to the host. Another algorithm shown in Algorithm 8 is called Minimum Migration Time Maximum CPU utilization MMTMC . This algorithm first selects VMs with the minimum amount of RAM to minimize the live migration time. Then out of the selected subset of VMs the algorithm selects the VM with the maximum CPU utilization averaged over the last n measurements to maximally reduce the overall CPU utilization of the host.

The VM placement problem can be seen as a bin packing problem with variable bin sizes where bins represent hosts bin sizes are the available CPU capacities of hosts and items are VMs to be allocated with an extra constraint on the amount of RAM. As the bin packing problem is NP hard it is appropriate to apply a heuristic to solve it. OpenStack Neat implements a modification of the Best Fit Decreasing BFD algorithm which has been shown to use no more than 11 9 OPT 1 bins where OPT is the number of bins of the optimal solution 37 .

The implemented modification of the BFD algorithm shown in Algorithm 9 includes several extensions the ability to handle extra constraints namely consideration of currently inactive hosts and a constraint on the amount of RAM required by the VMs. An inactive host is only activated when a VM cannot be placed on one of the already active hosts. The constraint on the amount of RAM is taken into account in the first fit manner i.e. if a host is selected for a VM as a best fit according to its CPU requirements the host is confirmed if it just satisfies the RAM requirements. In addition similarly to the averaging underload and overload detection algorithms the algorithm uses the mean values of the last n CPU utilization measurements as the CPU constraints. The worst case complexity of the algorithm is n m 2 m where n is the number of physical nodes and m is the number of VMs to be placed. The worst case occurs when every VM to be placed requires a new inactive host to be activated.

OpenStack Neat is implemented in Python. The choice of the programming language has been mostly determined by the fact that OpenStack itself is implemented in Python therefore using the same programming language could potentially simplify the integration of the two projects. Since Python is a dynamic language it has a number of advantages such as concise code no type constraints and monkey patching which refers to the ability to replace methods attributes and functions at run time. Due to its flexibility and expressiveness Python typically helps to improve productivity and reduce the development time compared with statically typed languages such as Java and C . The downsides of dynamic typing are the lower run time performance and lack of compile time guarantees provided by statically typed languages.

To compensate for the reduced safety due to the lack of compile time checks several programming techniques are applied in the implementation of OpenStack Neat to minimize bugs and simplify maintenance. First the functional programming style is followed by leveraging the functional features of Python such as higher order functions and closures and minimizing the use of the object oriented programming features such as class hierarchies and encapsulation. One desirable technique that is applied in the implementation of OpenStack Neat is the minimization of mutable state. Mutable state is one of the causes of side effects which prevent functions from being referentially transparent. This means that if a function relies on some global mutable state multiple calls to that function with the same arguments do not guarantee the same result returned by the function for each call.

The implementation of OpenStack Neat tries to minimize side effects by avoiding mutable state where possible and isolating calls to external APIs in separate functions covered by unit tests. In addition the implementation splits the code into small easy to understand functions with explicit arguments that the function acts upon without mutating their values. To impose constraints on function arguments the Design by Contract DbC approach is applied using the PyContracts library. The approach prescribes the definition of formal precise and verifiable interface specifications for software components. PyContracts lets the programmer to specify contracts on function arguments via a special format of Python docstrings. The contracts are checked at run time and if any of the constraints is not satisfied an exception is raised. This approach helps to localize errors and fail fast instead of hiding potential errors. Another advantage of DbC is comprehensive and up to date code documentation which can be generated from the source code by automated tools.

To provide stronger guarantees of the correctness of the program it is desirable to apply unit testing. According to this method each individual unit of source code which in this context is a function should be tested by an automated procedure. The goal of unit testing is to isolate parts of the program and show that they perform correctly. One of the most efficient unit testing techniques is implemented by the Haskell QuickCheck library. This library allows the definition of tests in the form of properties that must be satisfied which do not require the manual specification of the test case input data. QuickCheck takes advantage of Haskell s rich type system to infer the required input data and generates multiple test cases automatically.

The implementation of OpenStack neat uses Pyqcy a QuickCheck like unit testing framework for Python. This library allows the specification of generators which can be seen as templates for input data. Similarly to QuickCheck Pyqcy uses the defined templates to automatically generate input data for hundreds of test cases for each unit test. Another Python library used for testing of OpenStack Neat is Mocktest. This library leverages the flexibility of Python s monkey patching to dynamically replace or mock existing methods attributes and functions at run time. Mocking is essential for unit testing the code that relies on calls to external APIs. In addition to the ability to set artificial return values of methods and functions Mocktest allows setting expectations on the number of the required function calls. If the expectations are not met the test fails. Currently OpenStack Neat includes more than 150 unit tests.

OpenStack Neat applies Continuous Integration CI using the Travis CI service. The aim of the CI practice is to detect integration problems early by periodically building and deploying the software system. Travis CI is attached to OpenStack Neat s source code repository through Git hooks. Every time modifications are pushed to the repository Travis CI fetches the source code and runs a clean installation in a sandbox followed by the unit tests. If any step of the integration process fails Travis CI reports the problem.

Despite all the precautions run time errors may occur in a deployed system. OpenStack Neat implements multi level logging functionality to simplify the post mortem analysis and debugging process. The verbosity of logging can be adjusted by modifying the configuration file. Table 8 provides information on the size of the current codebase of OpenStack Neat. Table 9 summarizes the set of libraries used in the implementation of OpenStack Neat.

To make experiments reproducible it is desirable to rely on a set of input traces to reliably generate the workload which would allow the experiments to be repeated as many times as necessary. It is also desirable to use workload traces collected from a real system rather than artificially generated as this would help to reproduce a realistic scenario. This case study uses workload trace data provided as a part of the CoMon project a monitoring infrastructure of PlanetLab 27 . The traces include data on the CPU utilization collected every five minutes from more than a thousand VMs deployed on servers located in more 500 places around the world. Ten days of workload traces collected during March and April 2011 have been randomly chosen which resulted in the total of 11 746 24 hour long traces.

The workload from PlanetLab VMs is representative of an IaaS Cloud environment such as Amazon EC2 in the sense that the VMs are created and managed by multiple independent users and the infrastructure provider is not aware of what particular applications are executing in the VMs. Furthermore this implies that the overall system workload is composed of multiple independent heterogeneous applications which also corresponds to an IaaS environment. However there is difference from a public Cloud provider such as Amazon EC2. The difference is that PlanetLab is an infrastructure mainly used for research purposes therefore the applications are potentially closer to the HPC type rather than web services which are common in public Clouds.

HPC applications are typically CPU intensive with lower dynamics in the resource utilization compared with web services whose resource consumption depends on the number of user requests and may vary over time. HPC workload is easier to handle for a VM consolidation system due to infrequent variation in the resource utilization. Therefore to stress the system in the experiments the original workload traces have been filtered to leave only the ones that exhibit high variability. In particular only the traces that satisfy the following two conditions have been selected 1 at least 10 of time the CPU utilization is lower than 20 and 2 at least 10 of time the CPU utilization is higher than 80 . This significantly reduced the number of workload traces resulting in only 33 out of 11 746 24 hour traces left. The set of selected traces and filtering script are available online 2 .

The resulting number of traces was sufficient for the experiments whose scale was limited by the size of the testbed described below. If a larger number of traces are required to satisfy larger scale experiments one approach is to relax the conditions of filtering the original set of traces. Another approach is to randomly sample with replacement from the limited set of traces. If another set of suitable workload traces becomes publicly available it can be included in the benchmark suite as an alternative.

For effective performance evaluation and comparison of algorithms it is essential to define performance metrics that capture the relevant characteristics of the algorithms. One of the objectives of dynamic VM consolidation is the minimization of energy consumption by the physical nodes which can be a metric for performance evaluation and comparison. However energy consumption is highly dependent on the particular model and configuration of the underlying hardware efficiency of power supplies implementation of the sleep mode etc. A metric that abstracts from the mentioned factors but is directly proportional and can be used to estimate energy consumption is the time of a host being idle aggregated over the full set of hosts. Using this metric the quality of VM consolidation can be represented by the increase in the aggregated idle time of hosts. However this metric depends on the length of the overall evaluation period and the number of hosts. To eliminate this dependency a normalized metric is proposed that is referred to as the Aggregated Idle Time Fraction AITF defined as shown in 41 .

One of the key points of the proposed performance evaluation methodology is the minimization of manual steps required to run an experiment through automation. Automation begins from scripted installation of the OS OpenStack services and their dependencies on the testbed s nodes as described in the OpenStack installation guide 5 . The next step is writing scripts for preparing the system for an experiment which includes starting up the required services booting VM instances and preparing them for starting the workload generation.

While most of the mentioned steps are trivial workload generation is complicated by the requirement of synchronizing the time of starting the workload generation on all the VMs. Another desirable aspect of workload generation is the way workload traces are assigned to VMs. Typically the desired behavior is assigning a unique workload trace out of the full set of traces to each VM. Finally it is desirable to create and maintain a specific level of CPU utilization for the whole interval between changes of the CPU utilization level defined by the workload trace for each VM.

This problem is addressed using a combination of a CPU load generation program and a workload distribution web service and clients deployed on VMs 2 . When a VM boots from a pre configured image it automatically starts a script that polls the central workload distribution web service to be assigned a workload trace. Initially the workload distribution web service drops requests from clients deployed on VMs to wait for the moment when all the required VM instances are booted up and ready for generating workload. When all clients are ready the web service receives a command to start the workload trace distribution. The web service starts replying to clients by sending each of them a unique workload trace. Upon receiving a workload trace every client initiates the CPU load generator and passes the received workload trace as an argument. The CPU load generator reads the provided workload trace file and starts generating CPU utilization levels corresponding to the values specified in the workload trace file for each time frame.

During an experiment OpenStack Neat continuously logs various events into both the database and log files on each host. After the experiment the logged data are used by special result processing scripts to extract the required information and compute performance metrics discussed above as well as the execution time of various system components. This process should be repeated for each combination of VM consolidation algorithms under consideration. After the required set of experiments is completed other scripts are executed to perform automated statistical tests and plotting graphs for comparing the algorithms.

The next section presents an example of application of the proposed benchmark suite and in particular applies 1 OpenStack Neat as the dynamic VM consolidation framework 2 the filtered PlanetLab workload traces above 3 the performance metrics defined above and 4 the proposed evaluation methodology. The full set of scripts used in the experiments is available online 2 .

In this section the embodiments herein evaluate OpenStack Neat and several dynamic VM consolidation algorithm discussed above

The testbed used for performance evaluation of the system comprises of the following example hardware 

The Dell Optiplex 745 machine was chosen to serve as the controller host running all the major OpenStack services and the global manager of OpenStack Neat. The 4 IBM System x3200 M3 servers were used as compute hosts i.e. running OpenStack Nova and local managers and data collectors of OpenStack Neat. All of the machines formed a local network connected via the Netgear FS network switch.

Unfortunately there was a hardware problem preventing the system from taking advantage of dynamic VM consolidation to save energy. The problem was that the compute nodes of the testbed did not support the Suspend to RAM power state which is the most suitable for the purpose of dynamic VM consolidation. This state potentially provides very low switching latency on the order of 300 ms while reducing the energy consumption to a negligible level 23 . Therefore rather than measuring the actual energy consumption by the servers the AITF metric introduced above was applied to evaluate the system which can be seen as a representation of potential energy savings.

From the point of view of experimenting with close to real world conditions it is interesting to allocate as many VMs on a compute host as possible. This would create a more dynamic workload and stress the system. At the same time it is desirable to use full fledged VM images representing realistic user requirements. Therefore the Ubuntu 12.04 Cloud Image 9 was used in the experiments which is one of the Ubuntu VM images available in Amazon EC2.

Since the compute hosts of the testbed contained limited amount of RAM to maximize the number of VMs served by a single host it was necessary to use a VM instance type with the minimum amount of RAM sufficient for Ubuntu 12.04. The minimum required amount of RAM was empirically determined to be 128 MB. This resulted in the maximum of 28 VMs being possible to instantiate on a single compute host. Therefore to maximize potential benefits of dynamic VM consolidation on the testbed containing 4 compute nodes the total number of VM instances was set to 28 so that in an ideal case all of them can be placed on a single compute host while the other 3 hosts are kept idle. Out of the 33 filtered PlanetLab workload traces discussed above 28 traces were randomly selected i.e. one unique 24 hour trace for each VM instance. The full set of selected traces is available online 2 .

During the experiments all the configuration parameters of OpenStack Neat were set to their default values except for the configuration of the overload detection algorithm. The overload detection algorithm was changed for each experiment by going through the following list of algorithms and their parameters 

Each experiment was run three times to handle the variability caused by random factors such as the initial VM placement workload trace assignment and component communication latency. All of the system initialization and result processing scripts along with the experiment result packages are available online 2 .

The results of experiments are graphically depicted in with reference to . The mean values of the obtained AITF and AOTF metrics and the number of VM migrations along with their 95 Confidence Intervals CIs are displayed in Table 10. The results of MAX ITF show that for the current experiment setup it is possible to obtain high values of AITF of up to 50 while incurring a high AOTF of more than 40 . All the THR LRR and MHOD allow tuning of the AITF values by adjusting the algorithm parameters. For the THR algorithm the mean AITF increases from 36.9 to 49.2 with the corresponding decrease in the QoS level from 15.4 to 42.2 by varying the CPU utilization threshold from 0.8 to 1.0. The mean number of VM migrations decreases from 167.7 for the 80 threshold to 11.3 for the 100 threshold. The THR algorithm with the CPU utilization threshold set to 100 reaches the mean AITF shown by the MAX ITF algorithm which is expected as setting the threshold to 100 effectively disables host overload detection. Similarly adjusting the safety parameter of the LRR algorithm from 1.1 to 0.9 leads to an increase of the mean AITF from 37.9 to 47.3 with a growth of the mean AOTF from 17.8 to 34.4 and decrease of the mean number of VM migrations from 195.7 to 28.3. THR 1.0 reaches the mean AITF of 49.2 with the mean AOTF of 42.2 while LRR 0.9 reaches a close mean AITF of 47.3 with the mean AOTF of only 34.4 which is a significant decrease compared with the AOTF of THR 1.0.

Varying the OTF parameter of the MHOD algorithm from 0.2 to 0.4 leads to an increase of the mean AITF from 37.7 to 40.7 with an increase of the mean AOTF from 16.0 to 21.4 . First it is desirable to note that the algorithm meets the specified QoS constraint by keeping the value of the AOTF metric below the specified OTF parameters. However the resulting mean AOTF is significantly lower than the specified OTF parameters 17.9 for the 30 OTF and 21.4 for the 40 OTF. This can be explained by a combination of two factors 1 the MHOD algorithm is parameterized by the per host OTF rather than AOTF which means that it meets the OTF constraint for each host independently 2 due to the small scale of the experimental testbed a single underloaded host used for offloading VMs from overloaded hosts is able to significantly skew the AITF metric. The AITF metric is expected to be closer to the specified OTF parameter for large scale OpenStack Neat deployments. A comparison of the results produced by LRR 1.1 and LRR 1.0 with MHOD 0.2 and MHOD 0.4 reveals that the MHOD algorithm leads to lower values of the AOTF metric higher level of QoS for approximately equal values of the AITF metric.

Using the obtained AITF and AOTF metrics for each algorithm and data on power consumption by servers it is possible to compute estimates of potential energy savings relatively to a non power aware system assuming that hosts are switched to the sleep mode during every idle period. To obtain a lower bound on the estimated energy savings it is assumed that when dynamic VM consolidation is applied the CPU utilization of each host is 80 when it is active and non overloaded and 100 when it is overloaded. According to the data provided by Meisner et al. 23 power consumption of a typical blade server is 450 W in the fully utilized state 270 W in the idle state and 10.4 W in the sleep mode. Using the linear server power model proposed by Fan et al. 11 and the power consumption data provided by Meisner et al. 23 it is possible to calculate power consumption of a server at any utilization level.

To calculate the base energy consumption by a non power aware system it is assumed that in such a system all the compute hosts are always active with the load being distributed across them. Since the power model applied in this study is linear it is does not matter how exactly the load is distributed across the servers. The estimated energy consumption levels for each overload detection algorithm along with the corresponding base energy consumption by a non power aware system and percentages of the estimated energy savings are presented in Table 11.

According to the estimates MAX ITF leads to the highest energy savings over the base energy consumption of approximately 33 by the cost of substantial performance degradation AOTF 40.4 . The THR LRR and MHOD algorithms lead to energy savings from approximately 25 to 32 depending on the specified parameters. Similarly to the above comparison of algorithms using the AITF metric LRR 0.9 produces energy savings close to those of THR 1.0 31.93 compared with 32.91 while significantly reducing the mean AOTF from 42.2 to 34.4 . The MHOD algorithm produces approximately equal or higher energy savings than the LRR algorithm with lower mean AITF values i.e. higher levels of QoS while also providing the advantage of specifying a QoS constraint as a parameter of the algorithm. The obtained experimental results confirm the hypothesis that dynamic VM consolidation is able to significantly reduce energy consumption in an IaaS Cloud with a limited performance impact.

Table 12 lists mean values of the execution time along with 95 CIs measured for each overload detection algorithm during the experiments for some of the system components processing underload and overload requests by the global manager GM overload detection algorithms executed by the local manager LM and iterations of the data collector DC . Request processing by the global manager takes on average between 30 and 60 seconds which is mostly determined by the time required to migrate VMs. The mean execution time of the MHOD algorithm is higher than those of THR and LRR while still being under half a second resulting in a negligible overhead considering that it is executed at most once in five minutes. The mean execution time of an iteration of the data collector is similarly under a second which is also negligible considering that it is executed only once in five minutes.

Scalability and eliminating single points of failure are desirable benefits of designing a dynamic VM consolidation system in a distributed way. According to the approach adopted in the design of OpenStack Neat the underload overload detection and VM selection algorithms are able to inherently scale with the increased number of compute hosts. This is due to the fact that they are executed independently on each compute host and do not rely on information about the global state of the system. In regard to the database setup there exist distributed database solutions e.g. the MySQL Cluster 26 .

On the other hand in the current implementation of OpenStack Neat there assumed to be only one instance of the global manager deployed on a single controller host . This limits the scalability of VM placement decisions and creates a single point of failure. However even with this limitation the overall scalability of the system is significantly improved compared with existing completely centralized VM consolidation solutions. Compared with centralized solutions the only functionality implemented in OpenStack Neat by the central controller is the placement of VMs selected for migration which constitute only a fraction of the total number of VMs in the system. To address the problem of a single point of failure it is possible to run a second instance of the global manager which initially does not receive requests from the local managers and gets automatically activated when the primary instance of the global manager fails. However the problem of scalability is more complex since it is necessary to have multiple independent global managers concurrently serving requests from local managers .

Potentially it is possible to implement replication of the global manager in line with OpenStack s approach to scalability by replication of its services. From the point of view of communication between the local managers and global managers replication can be simply implemented by a load balancer that distributes requests from the local managers across the set of replicated global managers . A more complex problem is synchronizing the activities of the replicated global managers . It is necessary to avoid situations when two global managers place VMs on a single compute host simultaneously since that would imply that they use an out of date view of the system state. One potential solution to this problem could be a continuous exchange of information between global managers during the process of execution of the VM placement algorithm i.e. if a host is selected by a global manager for a VM it should notify the other global managers to exclude that host from their sets of available destination hosts.

The embodiments herein proposed a Markov chain model and control algorithm for the problem of host overload detection as a part of dynamic VM consolidation. The model allows a system administrator to explicitly set a QoS goal in terms of the OTF parameter which is a workload independent QoS metric. For a known stationary workload and a given state configuration the control policy obtained from the Markov model optimally solves the host overload detection problem in the online setting by maximizing the mean inter migration time while meeting the QoS goal.

Using the Multisize Sliding Window workload estimation approach the model has been heuristically adapted to handle unknown non stationary workloads. In addition an optimal offline algorithm for the problem of host overload detection has been proposed to evaluate the efficiency of the MHOD algorithm. The conducted experimental study has led to the following conclusions 

1. For the simulated PlanetLab workload 3 state configurations of the MHOD algorithm on average produce approximately the same results as the 0 100 100 2 state configuration of the MHOD algorithm therefore the 2 state configuration is preferred as it requires simpler computations.

2. The 2 state configuration of the MHOD algorithm leads to approximately 11 shorter time until a migration than the LRR algorithm the best benchmark algorithm. However the MHOD algorithm provides the advantage of explicit specification of a QoS goal in terms of the OTF metric. In contrast the performance of the LR and LRR algorithms in regard to the QoS can only be adjusted indirectly by tuning the safety parameter. Moreover the spread of the resulting OTF value produced by the MHOD algorithm is substantially narrower compared with the LR and LRR algorithms which means the MHOD algorithm more precisely meets the QoS goal.

3. The MHOD algorithm substantially outperforms the OTFT and OTFTM algorithms in the level of SLA violations resulting in less than 0.5 SLA violations compared to 81.33 of OTFT and OTFTM.

4. The MHOD algorithm on average provides approximately the same resulting OTF value and approximately 88 of the time until a VM migration produced by the optimal offline algorithm OPT .

5. The MHOD algorithm enables explicit specification of a desired QoS goal to be delivered by the system through the OTF parameter which is successfully met by the resulting value of the OTF metric.

The introduced model is based on Markov chains requiring a few fundamental assumptions. It is assumed that the workload satisfies the Markov property which may not be true for all types of workloads. Careful assessment of the assumptions discussed above is desirable in an investigation of the applicability of the proposed model to a particular system. However the experimental study involving multiple mixed heterogeneous real world workloads has shown that the algorithm is efficient in handling them. For the simulated PlanetLab workload the MHOD algorithm performed within a 12 difference from the performance of the optimal offline algorithm which is highly efficient for an online algorithm.

The MHOD algorithm has been implemented and evaluated as part of a framework for dynamic VM consolidation in OpenStack Clouds called OpenStack Neat. The experimental results and estimates of energy consumption have shown that OpenStack Neat is able to reduce energy consumption by the compute nodes of a 4 node testbed by 25 to 33 while resulting in a limited application performance impact from approximately 15 to 40 AOTF. The MHOD algorithm has led to approximately equal or higher energy savings with lower mean AOTF values compared with the other evaluated algorithms while also allowing the system administrator to explicitly specify a QoS constraint in terms of the OTF metric.

The performance overhead of the framework is nearly negligible taking on average only a fraction of a second to execute iterations of the components. The request processing of the global manager takes on average between 30 and 60 seconds and is mostly determined by the time required to migrate VMs. The results have shown that dynamic VM consolidation brings significant energy savings with a limited impact on the application performance. The proposed framework can be applied in both further research on dynamic VM consolidation and real OpenStack Cloud deployments to improve the utilization of resources and reduce energy consumption.

The embodiments herein have proposed a novel system and framework for dynamic VM consolidation in OpenStack Clouds called OpenStack Neat. The framework follows a distributed model of dynamic VM consolidation where the problem is divided into four sub problems host underload detection host overload detection VM selection and VM placement. Through its configuration OpenStack Neat can be customized to use various implementations of algorithms for each for the four sub problems of dynamic VM consolidation. OpenStack Neat is transparent to the base OpenStack installation by interacting with it using the public APIs and not requiring any modifications of OpenStack s configuration. The embodiments herein have also proposed a benchmark suite comprising OpenStack Neat as the base software framework a set of PlanetLab workload traces performance metrics and methodology for evaluating and comparing dynamic VM consolidation algorithms following the distributed model.

Through a synchronization model and replication of global managers a complete distributed and fault tolerant dynamic VM consolidation system can be achieved. The data collector can be extended to collect other types of data in addition to the CPU utilization that can be used by VM consolidation algorithms.

The experimental results and estimates of energy consumption have shown that OpenStack Neat is able to reduce energy consumption by the compute nodes of a 4 node testbed by 25 to 33 while resulting in a limited application performance impact from approximately 15 to 40 AOTF. The MHOD algorithm has led to approximately equal or higher energy savings with lower mean AOTF values compared with the other evaluated algorithms while also allowing the system administrator to explicitly specify a QoS constraint in terms of the OTF metric. The performance overhead of the framework is nearly negligible taking on average only a fraction of a second to execute iterations of the components. The request processing of the global manager takes on average between 30 and 60 seconds and is mostly determined by the time required to migrate VMs. The results have shown that dynamic VM consolidation brings significant energy savings with a limited impact on the application performance.

The Markov chain model allows a derivation of a randomized control policy that optimally maximizes the mean inter migration time between virtual machine migrations under an explicitly specified quality of service requirement for any known stationary workload and a given state configuration in an online setting. The method may further comprise only maximizing an activity time of the overloaded physical server and only minimizing an activity time of an underloaded physical server. A workload of a physical server comprises a central processing unit utilization created over a period of time by a set of virtual machines allocated to the physical server wherein the workload may be stationary. The non stationary workload is approximated as a sequence of stationary workloads that are enabled one after another.

The method may further comprise submitting a virtual machine provisioning request through a cloud user interface processing the request and instantiating required virtual machines collecting data on resource utilization of virtual machines instantiated on a compute host passing the data to a local consolidation manager that invokes physical server overload detection physical server underload detection a virtual machine selection process passing outcomes generated by the local consolidation manager to a global consolidation manager invoking a virtual machine placement process to determine a new placement of a virtual machine required to be migrated initiating virtual machine migrations as determined by the virtual machine placement process migrating the virtual machines as instructed by the global consolidation manager and upon completion of the required migrations the global consolidation manager switching the physical servers from and to a lower power mode wherein the lower power mode comprises a sleep mode. The quality of service requirement may be specified in terms of a workload independent quality of service metric and the overload detection occurs using an offline process.

The techniques provided by the embodiments herein may be implemented on an integrated circuit chip not shown . The chip design is created in a graphical computer programming language and stored in a computer storage medium such as a disk tape physical hard drive or virtual hard drive such as in a storage access network . If the designer does not fabricate chips or the photolithographic masks used to fabricate chips the designer transmits the resulting design by physical means e.g. by providing a copy of the storage medium storing the design or electronically e.g. through the Internet to such entities directly or indirectly. The stored design is then converted into the appropriate format e.g. GDSII for the fabrication of photolithographic masks which typically include multiple copies of the chip design in question that are to be formed on a wafer. The photolithographic masks are utilized to define areas of the wafer and or the layers thereon to be processed.

The embodiments herein can include both hardware and software elements. The embodiments that are implemented in software include but are not limited to firmware resident software microcode etc. Furthermore the embodiments herein can take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any apparatus that can comprise store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium can be an electronic magnetic optical electromagnetic infrared or semiconductor system or apparatus or device or a propagation medium. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

A data processing system suitable for storing and or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input output I O devices including but not limited to keyboards displays pointing devices etc. can be coupled to the system either directly or through intervening I O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modem and Ethernet cards are just a few of the currently available types of network adapters.

A representative hardware environment for practicing the embodiments herein is depicted in with reference to . This schematic drawing illustrates a hardware configuration of an information handling computer system in accordance with the embodiments herein. The system comprises at least one processor or central processing unit CPU . The CPUs are interconnected via system bus to various devices such as a random access memory RAM read only memory ROM and an input output I O adapter . The I O adapter can connect to peripheral devices such as disk units and tape drives or other program storage devices that are readable by the system . The system can read the inventive instructions on the program storage devices and follow these instructions to execute the methodology of the embodiments herein. The system further includes a user interface adapter that connects a keyboard mouse speaker microphone and or other user interface devices such as a touch screen device not shown to the bus to gather user input. Additionally a communication adapter operatively connects the bus to a data processing network which operatively connects to the cloud data center and a display adapter connects the bus to a display device which may be embodied as an output device such as a monitor printer receiver transmitter or transceiver for example.

Dynamic consolidation of Virtual Machines VMs is an efficient method for improving the utilization of physical resources and reducing energy consumption in Cloud data centers. Determining when it is best to reallocate VMs from an overloaded host is an aspect of dynamic VM consolidation that directly influences the resource utilization and QoS delivered by the system required for meeting the SLAs. The influence on the QoS is explained by the fact that server overloads cause resource shortages and performance degradation of applications. Previous solutions to the problem of host overload detection are generally heuristic based or rely on statistical analysis of historical data. The limitations of these approaches are that they lead to sub optimal results and do not allow explicit specification of a QoS goal. The embodiments herein provide a novel approach that for any known stationary workload and a given state configuration optimally solves the problem of host overload detection by maximizing the mean inter migration time under the specified QoS goal based on a Markov chain model. The embodiments herein heuristically adapt the algorithm to handle unknown non stationary workloads using the Multisize Sliding Window workload estimation technique. Through simulations with real world workload traces from more than a thousand PlanetLab VMs it is demonstrated that the embodiments herein outperform the best benchmark algorithm and provides approximately 88 of the performance of the optimal offline algorithm.

The embodiments herein provide a system architecture and implementation of OpenStack Neat a computer program product acting as a framework for dynamic VM consolidation in OpenStack Clouds. OpenStack Neat can be configured to use custom VM consolidation algorithms and transparently integrates with existing OpenStack deployments without the necessity in modifying their configuration. In addition to foster and encourage further research efforts in the area of dynamic VM consolidation the embodiments herein propose a benchmark suite for evaluating and comparing dynamic VM consolidation algorithms. The proposed benchmark suite comprises OpenStack Neat as the base software computer program product framework a set of real world workload traces performance metrics and evaluation methodology. As an application of the proposed benchmark suite an experimental evaluation of OpenStack Neat and several dynamic VM consolidation algorithms on a Cloud data center testbed are conducted which shows significant benefits of dynamic VM consolidation resulting in up to 33 energy savings.

The foregoing description of the specific embodiments will so fully reveal the general nature of the embodiments herein that others can by applying current knowledge readily modify and or adapt for various applications such specific embodiments without departing from the generic concept and therefore such adaptations and modifications should and are intended to be comprehended within the meaning and range of equivalents of the disclosed embodiments. It is to be understood that the phraseology or terminology employed herein is for the purpose of description and not of limitation. Therefore while the embodiments herein have been described in terms of preferred embodiments those skilled in the art will recognize that the embodiments herein can be practiced with modification within the spirit and scope of the appended claims.

