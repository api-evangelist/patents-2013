---

title: Information processing device, computer-readable storage medium, and projecting system
abstract: An information processing device includes a storage unit configured to store a predetermined motion of a user who uses an operating device and an attribute of the predetermined motion per role of the user in association with each other; an image capturing unit configured to capture an image of a predetermined area including a projection area on which a projecting device projects an image; an identification unit configured to identify the attribute associated with the predetermined motion corresponding to a motion of light emitted to the predetermined area from the operating device based on the motion of light and an operation signal, referring to the storage unit; a synthetic image generation unit configured to generate a synthetic image by reflecting the attribute of the predetermined motion in the image projected; and a history record unit configured to generate history data including the synthetic image, the role, the attribute.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09176601&OS=09176601&RS=09176601
owner: RICOH COMPANY, LIMITED
number: 09176601
owner_city: Tokyo
owner_country: JP
publication_date: 20130320
---
The present application claims priority to and incorporates by reference the entire contents of Japanese Patent Application No. 2012 065530 filed in Japan on Mar. 22 2012.

The present invention relates to an information processing device a computer readable storage medium and a projecting system.

Conventionally at conferences at which a plurality of participants attend participants perform variously pointing out with respect to presentation materials used in presentation of a presenter. Further at such a conference minutes may be created to review development of the conference including for example pointing out to a presentation material later or tell the content of the conference for people who did not attend the conference. There is a difference in quality of minutes to be created depending on a skill level of a participant who is in charge of creating the minutes. When for example the skill level of a participant who is in charge of creating the minutes is low the minutes become unuseful and therefore the minutes are corrected by another participant of a higher skill level in some cases and time efficiency to create the minutes decreases. Hence a presenter of a high skill level may create the minutes.

Further U.S. Pat. No. 3 982 451 discloses a technique of associating and collectively managing different position information per application and assigning an association between a plurality of applications used upon a review. Furthermore U.S. Pat. No. 3 185 505 discloses a technique of creating files representing importance of conferences in time series based on for example frequency information of keywords and statements made during a conference.

However conventional techniques have a problem that it is difficult to easily create conference minutes without decreasing a proceeding speed of a conference. With regard to creation of minutes suitable minutes are preferably created by a person in charge of creating the minutes during a conference irrespectively of the degree of a skill level. In this regard no conventional technique is suitable for use in creating minutes during a conference. Further when a presenter of a high skill level creates minutes during a conference the presenter needs to create the minutes while making a presentation and therefore the proceeding speed of the conference becomes slow. As a result the conventional techniques have difficulty in easily creating conference minutes without decreasing a proceeding speed of a conference.

Therefore there is a need to provide an information processing device a computer readable storage medium and a projecting system which can easily create conference minutes without decreasing a proceeding speed of a conference.

It is an object of the present invention to at least partially solve the problems in the conventional technology.

According to an embodiment there is provided an information processing device that includes an operation information storage unit configured to store therein information on a predetermined motion of a user who uses an operating device and an attribute of the predetermined motion per role of the user in association with each other the operating device including a light source an operation signal receiving unit configured to receive an operation signal indicating that the operating device is operated from the operating device an image capturing unit configured to capture an image of a predetermined area including a projection area on which a projecting device projects an image an identification unit configured to identify the attribute associated with the predetermined motion corresponding to a motion of light emitted to the predetermined area from the operating device based on the motion of light whose image is captured by the image capturing unit and the operation signal received by the operation signal receiving unit referring to the operation information storage unit a synthetic image generation unit configured to generate a synthetic image by reflecting the attribute of the predetermined motion identified by the identification unit in the image projected by the projecting device and a history record unit configured to generate history data including the synthetic image generated by the synthetic image generation unit description of the role and description of the attribute.

According to another embodiment there is provided a non transitory computer readable storage medium with an executable program stored thereon and executed by a computer that includes an operation information storage unit configured to store therein information on a predetermined motion of a user who uses an operating device and an attribute of the predetermined motion per role of the user in association with each other the operating device including a light source an operation signal receiving unit configured to receive an operation signal indicating that the operating device is operated from the operating device and an image capturing unit configured to capture an image of a predetermined area including a projection area on which a projecting device projects an image. The program instructs the computer to perform identifying the attribute associated with the predetermined motion corresponding to a motion of light emitted to the predetermined area from the operating device based on the motion of light whose image is captured by the image capturing unit and the operation signal received by the operation signal receiving unit referring to the operation information storage unit generating a synthetic image by reflecting the attribute of the predetermined motion identified by the identification unit in the image projected by the projecting device and generating history data including the synthetic image generated description of the role and description of the attribute.

According to still another embodiment there is provided a projecting system that includes an information processing device a projecting device configured to project an image. The projecting system includes an operation information storage unit configured to store therein information on a predetermined motion of a user who uses an operating device and an attribute of the predetermined motion per role of the user in association with each other the operating device including a light source an operation signal receiving unit configured to receive an operation signal indicating that the operating device is operated from the operating device an image capturing unit configured to capture an image of a predetermined area including a projection area on which the projecting device projects the image an identification unit configured to identify the attribute associated with the predetermined motion corresponding to a motion of light emitted to the predetermined area from the operating device based on the motion of light whose image is captured by the image capturing unit and the operation signal received by the operation signal receiving unit referring to the operation information storage unit a synthetic image generation unit configured to generate a synthetic image by reflecting the attribute of the predetermined motion identified by the identification unit in the image projected by the projecting device and a history record unit configured to generate history data including the synthetic image generated by the synthetic image generation unit description of the role and description of the attribute a projection control unit configured to performs control of projecting on the projecting device the synthetic image generated by the synthetic image generation unit and a projection unit configured to project the synthetic image on the projection area under control of the projection control unit.

The above and other objects features advantages and technical and industrial significance of this invention will be better understood by reading the following detailed description of presently preferred embodiments of the invention when considered in connection with the accompanying drawings.

Embodiments of an information processing device a history data generating program and a projecting system according to the present invention will be described with reference to the following accompanying drawings. In addition the following embodiments by no means limit the present invention. Further each embodiment can be adequately combined in a range which does not contradict content.

A configuration of a projecting system according to a first embodiment will be described using . is a view illustrating a configuration example of the projecting system according to the first embodiment.

As illustrated in in a projecting system a projecting device an operating device an operating device an operating device an operating device and an information processing device are connected to networks. Among these devices the projecting device is for example a projector which projects a predetermined image on a projection area such as a screen. Further the projecting device is a device which is a target to be operated by a user using the operating device.

The operating device the operating device the operating device and the operating device have light sources which emit light and when operated by a user transmit operation signals indicating that the operating devices are operated to the information processing device . A user s operation of the operating device is performed by for example radiating light on a predetermined area including a projection area. A case will be described below as an example where the operating device is operated by a pointer A who plays a role for performing pointing out to a presentation material the operating device is operated by a pointer B the operating device is operated by a presenter who plays a role of explaining a presentation material and the operating device is operated by a facilitator who plays a role of leading a conference. That is a user who plays each role performs a gesture operation by moving light emitted to the predetermined area by operating the operating device. In addition the number of operating devices is not limited to four. Further the roles are by no means limited to the above. Furthermore a gesture gesture operation is an example of a predetermined motion of a user using the operating device.

The information processing device is a device such as a PC Personal Computer which has a camera which captures an image of the predetermined area including the projection area such as a screen. This information processing device receives operation signals transmitted from the operating devices and captures images of motions of lights emitted to the predetermined area from the operating device to the operating device by means of the camera. Further the information processing device identifies what gesture operation is performed using the operating device corresponding to any role based on the received operation signal and the motion of light emitted to the predetermined area the image of which is captured by the camera. Furthermore the information processing device generates minute data history data by generating a synthetic image which reflects the identified gesture operation in an image which is being projected and recording for example the generated synthetic image the role of the user who performs the gesture operation and an attribute of the gesture operation in time series.

Thus the information processing device generates development of a conference matching the gesture operation as minute data during the conference so that it is possible to easily create conference minutes without decreasing a proceeding speed of the conference. In addition although the information processing device employs a configuration including the camera with the present embodiment the information processing device is not limited to this and may employ a configuration to which a separate camera is connected.

Next the configuration of the information processing device according to the first embodiment will be described using . is a functional block diagram illustrating a configuration example of the information processing device according to the first embodiment.

As illustrated in the information processing device has a role determination storage unit a role storage unit a gesture information storage unit an image capturing unit an operation signal receiving unit an identification unit a role determination unit a synthetic image generation unit a history record unit and a projection control unit .

The role determination storage unit associates and stores a gesture and a role which are used to determine a role of a user who operates the operating device. is a view illustrating an example of information stored in the role determination storage unit . As illustrated in the role determination storage unit associates and stores a gesture using each operating device in response to the motion of light and a role of a user matching the gesture during a conference. With one example the role determination storage unit associates and stores a role facilitator and a circle gesture. With another example the role determination storage unit associates and stores a role presenter and a square gesture. This role determination storage unit is used to determine a role of a user who uses each operating device before a conference starts. When for example a gesture using the operating device is the circle gesture the role of the user who uses the operating device is determined as the facilitator . In addition a cross gesture is a gesture used to cancel a role which is determined once.

The image capturing unit captures an image of a predetermined area including the projection area of the projecting device . More specifically the image capturing unit is a camera which captures an image of the predetermined area including the projection area on which light is emitted when each user operates each operating device and outputs the motion of the captured light to the identification unit . The motion of light refers to for example a shape such as the above circle or square. In addition the image capturing unit may not be included in the information processing device and may be provided separately as a camera connected to the information processing device through the network or a camera connected to the information processing device through for example a cable.

The operation signal receiving unit receives an operation signal indicating that each operating device is operated from each operating device. More specifically the operation signal receiving unit receives an operation signal transmitted from each operating device when for example lights emitted by operating the operating device to the operating device are moved that is when each operating device is operated by each user. This operation signal also includes for example identification information of the operating device. Further the operation signal receiving unit outputs the received operation signal to the identification unit .

To determine a role of each user in a conference before the conference starts the identification unit instructs the synthetic image generation unit to output an image registration screen to determine the role of each user and outputs the gesture in response to the motion of light and the operation signal to the role determination unit . By this means the synthetic image generation unit which receives an instruction of outputting the registration screen performs control of projecting the registration screen on the projecting device through the projection control unit . Further the role determination unit determines the role of each user who uses each operating device by acquiring from the role determination storage unit the role associated with the gesture output from the identification unit and stores the determined role in the role storage unit together with identification information of each operating device. In addition the determined role is reflected in the registration screen by the synthetic image generation unit every time.

Each user makes a motion of registering the role of each user by checking the registration screen projected on the screen and operating the operating device which each user has based on this registration screen. With an example the role of the user who makes the circle gesture is the facilitator the role of the user who makes the square gesture is the presenter and the role of the user who makes a triangle gesture is the pointer . Further a user who makes a wrong gesture upon registration of a role makes the cross gesture cancel and makes a gesture associated with an intended role again. By this means identification information 1004 of the operating device of the facilitator identification information 1001 of the operating device of the presenter identification information 1002 of the operating device of the pointer and identification information 1003 of the operating device are reflected in a registration result. Meanwhile when there is an operating device which is not used the operating device is displayed as unregistered in the registration result. Subsequently when a slash gesture for starting the conference is made using the operating device corresponding to the facilitator the conference is started.

The roles determined in this way are stored in the role storage unit by the role determination unit . is a view illustrating an example of information stored in the role storage unit . As illustrated in as a result of role determination by the role determination unit the role storage unit associates and stores an operating device ID which is identification information of the operating device and a role of a user who uses the determined operating device. With an example the role storage unit associates and stores the operating device ID 1001 operating device and the role presenter .

The gesture information storage unit associates and stores for example the gesture and the attribute of the gesture per role of a user during the conference. In addition the gesture information storage unit is an example of an operation information storage unit. is a view illustrating an example of information stored in the gesture information storage unit according to the first embodiment. As illustrated in the gesture information storage unit associates and stores an attribute representing for example content or quality of a gesture a use frequency representing the frequency of use of the gesture a role of user representing the role of the user who uses the gesture and a gesture per role of the user during the conference. Further the gesture information storage unit further stores for the role pointer a marking color representing a color for marking and reflecting a pointed out matter in an image which is being projected. In addition details of reflection of the pointed out matter will be described below.

With an example the gesture information storage unit associates and stores an attribute correct a use frequency middle a role of a user pointer the gesture o and a marking color blue as gesture information for the pointer. Further the gesture information storage unit associates and stores an attribute page turn a use frequency high a role of a user presenter and a right arrow gesture as gesture information for the presenter. Furthermore the gesture information storage unit associates and stores an attribute start a use frequency low a role of a user facilitator and the slash gesture as gesture information for the facilitator.

Hereinafter a case will be described where the facilitator makes a gesture of starting a conference. The identification unit receives the operation signal from the operating device corresponding to the facilitator through the operation signal receiving unit and receives the slash gesture using the operating device from the image capturing unit . In this case the identification unit acquires the role facilitator from the role storage unit based on the operating device ID included in the operation signal and acquires the attribute start of the slash gesture associated with the role facilitator from the gesture information storage unit . By this means the identification unit identifies that the facilitator using the operating device makes a gesture of starting the conference.

Further the identification unit notifies the start of the conference to the synthetic image generation unit and notifies the history record unit that generation of minute data is started. Furthermore when notifying the start of the conference to the synthetic image generation unit the identification unit notifies the gesture which can perform an operation during a presentation of a presentation material and the attribute of the gesture per role.

The synthetic image generation unit which received a notice of the start of the conference from the identification unit acquires the presentation material from another device such as a user PC or a predetermined storage device generates a synthetic image obtained by synthesizing an image of the presentation material and an image representing the gesture which can perform an operation during the presentation and an attribute of the gesture per role and instructs the projection control unit to project the synthetic image. By this means the projection control unit performs control of projecting the synthetic image on the projecting device . Meanwhile the history record unit which received a notice that generation of minute data is started from the identification unit acquires a time stamp in this case and starts generating the minute data.

Hereinafter a case will be described where the presenter makes a gesture of page turn . The identification unit receives the operation signal from the operating device corresponding to the presenter through the operation signal receiving unit and receives the right arrow gesture using the operating device from the image capturing unit . In this case the identification unit acquires the role presenter from the role storage unit based on the operating device ID included in the operation signal and acquires the attribute page turn of the right arrow gesture associated with the role presenter from the gesture information storage unit . By this means the identification unit identifies that the presenter using the operating device makes a gesture of turning a page of the presentation material.

Further the identification unit notifies the synthetic image generation unit that a page is turned and notifies generation of minute data which records that the presenter made the gesture operation of turning the page to the history record unit .

The synthetic image generation unit which received a notice of page turn from the identification unit changes the presentation material which is being projected to a next page generates a synthetic image obtained by synthesizing an image of the presentation material and an image representing a gesture which can perform an operation during the presentation and an attribute of the gesture per role and instructs the projection control unit to project the synthetic image. By this means the projection control unit performs control of projecting the synthetic image on the projecting device . Meanwhile the history record unit which received a notice of generation of minute data from the identification unit acquires a time stamp in this case and generates the minute data which records that the presenter turned a page. In addition when the presenter makes not only a gesture operation of page turn but also another gesture during the presentation the same processing as the above is performed.

That is while the presenter explains the presentation material a gesture of the pointer is not received. To accept the gesture of the pointer the facilitator makes a gesture 3 change to pointer .

Hereinafter a case will be described where the facilitator makes a gesture of change to pointer . The identification unit receives the operation signal from the operating device corresponding to the facilitator through the operation signal receiving unit and receives the gesture 3 using the operating device from the image capturing unit . In this case the identification unit acquires the role facilitator from the role storage unit based on the operating device ID included in the operation signal and acquires the attribute change to pointer of the gesture 3 associated with the role facilitator from the gesture information storage unit . By this means the identification unit identifies that the facilitator using the operating device made a gesture of changing from the presenter to the pointer.

Further the identification unit notifies that the gesture operation is changed to the pointer to the synthetic image generation unit and notifies generation of minute data which records that the facilitator made the gesture operation of changing to the pointer to the history record unit .

The synthetic image generation unit which received a notice that the gesture operation is changed to the pointer from the identification unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing a gesture which can perform an operation during pointing out to the pointer and an attribute of the gesture and instructs the projection control unit to project the synthetic image. By this means the projection control unit performs control of projecting the synthetic image on the projecting device . Meanwhile the history record unit which received a notice of generation of minute data from the identification unit acquires a time stamp in this case and generates the minute data which records that the facilitator changes the gesture operation to the pointer.

Hereinafter a case will be described where the pointer makes a gesture of wrong . The identification unit receives the operation signal from the operating device corresponding to the pointer through the operation signal receiving unit and receives a tick gesture using the operating device and the pointed out position on the screen from the image capturing unit . In this case the identification unit acquires the role pointer from the role storage unit based on the operating device ID included in the operation signal and acquires the attribute wrong of the tick gesture associated with the role pointer and a marking color red from the gesture information storage unit . By this means the identification unit identifies which part of the presentation material the pointer using the operating device makes a gesture of pointing out wrong.

Further the identification unit notifies pointed out content a pointed out position and a marking color to the synthetic image generation unit and notifies generation of minute data which records pointed out content and the pointed out position by the pointer to the history record unit .

The synthetic image generation unit which receives the notice of the pointed out content the pointed out position and the marking color from the identification unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing a portion pointed out by the pointer as pointed out content wrong and marked by a marking color red in a predetermined shape and instructs the projection control unit to project the synthetic image. By this means the projection control unit performs control of projecting the synthetic image on the projecting device . Meanwhile the history record unit which received a notice of generation of minute data from the identification unit acquires a time stamp in this case and generates the minute data which records information indicating the pointed out matter pointed out portion and pointed out content by the pointer. In addition even when the pointer makes not only a gesture operation of wrong but also another gesture during pointing out the same processing as the above is performed. illustrates a case where the pointer makes pointing out wrong correct and less thought out with respect to a predetermined portion. Further when the pointer finishes pointing out and the presenter continues the presentation the facilitator performs a gesture 2 change to presenter .

Furthermore a case has been described with the above example where the pointer makes the tick gesture and the identification unit acquires the attribute wrong of the tick gesture from the gesture information storage unit . Upon identification of a gesture when there are a plurality of gesture candidates the identification unit acquires an attribute associated with a gesture of a higher use frequency from the gesture information storage unit . Citing the above example when the pointer makes a gesture similar to both of the tick gesture and a less than sign gesture there are gesture candidates of the tick and the less than sign and the identification unit refers to the gesture information storage unit and acquires an attribute addition of explanation associated with the less than sign gesture of a higher use frequency based on the use frequencies of the tick use frequency middle and the less than sign use frequency high of the respective gestures. In addition the same processing as the above is performed with respect to not only a gesture of the pointer but also gestures of the presenter or the facilitator.

Next a flow of entire processing according to the first embodiment will be described using . is a flowchart illustrating an example of the flow of the entire processing according to the first embodiment.

As illustrated in the image capturing unit captures an image of the predetermined area including the screen emitted by light when each user operates each operating device step S . Further when for example light emitted to the predetermined area is moved that is when each operating device is operated the operation signal receiving unit receives an operation signal transmitted from each operating device step S . Furthermore the identification unit identifies what gesture is made using an operating device corresponding to any role based on the motion of light the image of which is captured by the image capturing unit and the operation signal received by the operation signal receiving unit step S .

Still further when deciding that the gesture is made by a role which can perform an operation step S Yes the identification unit decides whether or not a gesture is a gesture of determining a role step S . Whether or not the gesture is a gesture made by a role which can perform an operation is decided based on whether or not the role corresponds to the role which can perform an operation in response to a gesture operation switched by the facilitator during for example the presentation or pointing out. By this means when deciding that the gesture is not a gesture made by a role which can perform an operation step S No the identification unit executes processing in step S again. Further whether or not a gesture is a gesture of determining a role is decided based on whether or not a state is a state before the conference starts that is whether or not information about a role is not stored in the role storage unit .

In this case when the identification unit decides that the gesture is a gesture of determining a role step S Yes the role determination unit acquires the role associated with the gesture from the role determination storage unit and determines the role of the user who uses the operating device step S . Meanwhile when deciding that the gesture is not a gesture of determining a role step S No the identification unit decides whether or not the gesture is a gesture of switching a role which can perform an operation step S . Whether or not the gesture is the gesture of switching the role which can perform an operation is decided based on whether or not the facilitator makes a gesture such as change to pointer or change to presenter during the conference.

In this case when deciding that the gesture is the gesture of switching the role which can perform an operation step S Yes the identification unit notifies the synthetic image generation unit that the gesture operation is changed to the pointer or the presenter and notifies generation of minute data which records that the gesture operation of changing the gesture operation to the pointer or the presenter was made to the history record unit . By this means the synthetic image generation unit which received the notice that the gesture operation is changed to the pointer or the presenter from the identification unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing a gesture of the pointer or the presenter who can perform an operation and an attribute of the gesture and instructs the projection control unit to project the synthetic image. Further the projection control unit performs control of projecting the synthetic image on the projecting device . In addition the history record unit which received the notice of generation of the minute data from the identification unit acquires a time stamp in this case and generates minute data which records that the facilitator changed the gesture operation to the pointer or the presenter.

Meanwhile when the identification unit decides that the gesture is not the gesture of switching the role which can perform an operation step S No the synthetic image generation unit generates a synthetic image which reflects the attribute of the gesture of the presenter or the pointer in the image step S . Further the history record unit generates minute data including the synthetic image generated by the synthetic image generation unit description of the role and description of the attribute step S . Furthermore the projection control unit performs control of projecting the synthetic image generated by the synthetic image generation unit on the projecting device step S .

Next a processing sequence of registering participants will be described using . is a processing sequence diagram illustrating an example of participant registration.

As illustrated in the synthetic image generation unit generates an initial image which is a registration screen according to an instruction from the identification unit before the conference starts step S . Further the synthetic image generation unit performs control of projecting the generated initial image on the projecting device through the projection control unit step S . By this means the registration screen illustrated in is projected on the screen.

Further according to an operation of each user using the operating device to the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit outputs the gesture in response to the motion of light and the operation signal to the role determination unit step S . In addition details of assembly of the signal will be described below.

Further the role determination unit determines the role of each user using each operating device by acquiring the role associated with the gesture output from the identification unit from the role determination storage unit step S . Furthermore the role determination unit notifies the role of each user using each determined operating device to the identification unit step S .

Still further the identification unit notifies the role notified by the role determination unit and each operating device ID to the synthetic image generation unit step S . By this means the synthetic image generation unit generates an image in which a registration result of the role notified by the identification unit and each operating device ID is reflected step S . Further the synthetic image generation unit performs control of projecting the generated image on the projecting device through the projection control unit step S . Furthermore the identification unit notifies the history record unit of participants the facilitator the presenter the pointer A and the pointer B for example used to generate minute data step S .

Next a processing sequence of reregistering participants will be described using . is a processing sequence diagram illustrating an example of participant reregistration. In addition a case will be described with the example of participant reregistration illustrated in where the user using the operating device registers participation as the presenter then cancels the participation and reregisters the participation as the facilitator.

As illustrated in the synthetic image generation unit generates an initial image which is the registration screen according to an instruction from the identification unit before the conference starts step S . Further the synthetic image generation unit performs control of projecting the generated initial image on the projecting device through the projection control unit step S .

Furthermore according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the square gesture presenter in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit outputs the square gesture and the operation signal to the role determination unit step S .

Further the role determination unit determines the role of the user using the operating device by acquiring the role presenter associated with the square gesture output from the identification unit from the role determination storage unit step S . Furthermore the role determination unit notifies the identification unit of the role presenter of the user using the determined operating device step S .

Still further the identification unit notifies the role presenter notified by the role determination unit and the operating device ID 1004 of the operating device to the synthetic image generation unit step S . By this means the synthetic image generation unit generates an image in which a registration result of the role presenter notified by the identification unit and the operating device ID 1004 operating device is reflected step S . Further the synthetic image generation unit performs control of projecting the generated image on the projecting device through the projection control unit step S . Furthermore the identification unit notifies the history record unit of the participant presenter who generates minute data step S .

Still further according to an operation of the user a user registered as the presenter using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the cross gesture cancel in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit outputs the cross gesture and the operation signal to the role determination unit step S .

Further the role determination unit determines the role of the user using the operating device by acquiring from the role determination storage unit the role cancel associated with the cross gesture output from the identification unit step S . Furthermore the role determination unit notifies the identification unit of the role cancel of the user using the determined operating device step S .

Still further the identification unit notifies the synthetic image generation unit of the role cancel notified by the role determination unit and the operating device ID 1004 of the operating device step S . By this means the synthetic image generation unit generates an image in which a registration result of the role cancel notified by the identification unit and the operating device ID 1004 operating device is reflected step S . The image generated in this case is an image in which the role of the operating device as the presenter registered in a previous stage is deleted and the role of the operating device is shown as unregistered . Further the synthetic image generation unit performs control of projecting the generated image on the projecting device through the projection control unit step S . Furthermore the identification unit notifies the history record unit of the participant cancellation of presenter who generates minute data step S .

Still further according to an operation of the user a user makes cancellation to be the presenter using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the circle gesture facilitator in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit outputs the circle gesture and the operation signal to the role determination unit step S .

Further the role determination unit determines the role of the user using the operating device by acquiring from the role determination storage unit the role facilitator associated with the circle gesture output from the identification unit step S . Furthermore the role determination unit notifies the identification unit of the role facilitator of the user using the determined operating device step S .

Still further the identification unit notifies the synthetic image generation unit of the role facilitator notified by the role determination unit and the operating device ID 1004 of the operating device step S . By this means the synthetic image generation unit generates an image in which a registration result of the role facilitator notified by the identification unit and the operating device ID 1004 operating device is reflected step S . Further the synthetic image generation unit performs control of projecting the generated image on the projecting device through the projection control unit step S . Furthermore the identification unit notifies the history record unit of the participant facilitator who generates minute data step S .

Next a processing sequence of starting a conference will be described using . is a processing sequence diagram illustrating an example of a start of a conference.

As illustrated in according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the slash gesture start in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role facilitator referring to the role storage unit based on the operating device ID 1004 included in the operation signal step S . Further the identification unit acquires an attribute start of the slash gesture associated with the role facilitator referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture of starting a conference was received from the user of the operating device who is the facilitator. Subsequently the identification unit notifies the synthetic image generation unit of the start of the conference step S .

Further when receiving a notice of the start of the conference from the identification unit the synthetic image generation unit acquires the presentation material from another device such as a user PC or a predetermined storage device step S . Furthermore the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material and an image representing the gesture which can perform an operation during the presentation and an attribute of the gesture per role and performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Still further the identification unit requests the history record unit to start generating minute data step S . By this means the history record unit acquires a time stamp in this case step S and starts generating the minute data step S .

Next a processing sequence during a presentation will be described using . is a processing sequence diagram illustrating an example during a presentation.

As illustrated in according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the right arrow gesture page turn in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role presenter referring to the role storage unit based on the operating device ID 1001 included in the operation signal step S . Further the identification unit acquires an attribute page turn of the right arrow gesture associated with the role presenter referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture of turning a page of the presentation material was received from the user of the operating device who is the presenter. Subsequently the identification unit notifies the synthetic image generation unit that the page of the presentation material is turned step S .

Further when receiving the notice that the page of the presentation material is turned from the identification unit the synthetic image generation unit turns the page of the presentation material which is being projected and changes the presentation material step S . More specifically the synthetic image generation unit generates a synthetic image obtained by synthesizing an image in which the page of the presentation material which is being projected is turned and an image representing a gesture which can perform an operation during the presentation and an attribute of the gesture per role. Further the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Furthermore the identification unit requests the history record unit to generate minute data which records that the presenter turned the page step S . By this means the history record unit acquires a time stamp in this case step S and generates the minute data step S .

Further according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of an up down arrow gesture enlargement of screen in response to the motion of light the image of which is captured by the image capturing unit and the position of an enlargement target. Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role presenter referring to the role storage unit based on the operating device ID 1001 included in the operation signal step S . Further the identification unit acquires an attribute enlargement of screen of the up down arrow gesture associated with the role presenter referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture of enlarging the screen of a predetermined position of the presentation material was received from the user of the operating device who is the presenter. Subsequently the identification unit notifies that the screen of the predetermined position of the presentation material is enlarged to the synthetic image generation unit step S .

Further when receiving the notice that the screen of the predetermined position of the presentation material is enlarged from the identification unit the synthetic image generation unit enlarges the screen of the predetermined position of the presentation material which is being projected and changes the presentation material step S . More specifically the synthetic image generation unit generates a synthetic image obtained by synthesizing an image in which the screen of the predetermined position of the presentation material which is being projected is enlarged and an image representing a gesture which can perform an operation during the presentation and an attribute of the gesture per role. Further the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Furthermore the identification unit requests the history record unit to generate minute data which records that the presenter enlarged the screen of the predetermined position of the presentation material step S . By this means the history record unit acquires a time stamp in this case step S and generates the minute data step S .

Next a processing sequence of switching a gesture operation will be described using . is a processing sequence diagram illustrating an example of switching of a gesture operation.

As illustrated in according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit while the presenter makes a presentation of the presentation material step S . In this case the identification unit also receives an input of the gesture 3 change to pointer in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role facilitator referring to the role storage unit based on the operating device ID 1004 included in the operation signal step S . Further the identification unit acquires an attribute change to pointer of the gesture 3 associated with the role facilitator referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture of changing a user who can perform a gesture operation from the presenter to the pointer was received from the user of the operating device who is the facilitator. Subsequently the user who can perform the gesture operation changes to the pointer and then the identification unit requests the synthetic image generation unit to change the image for the presenter to an image representing a gesture and an attribute of the gesture for the pointer who can perform an operation during pointing out step S .

Further when receiving the request of changing the image from the identification unit the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image which is an UI User Interface for the pointer and which represents the gesture and the attribute of the gesture for the pointer which can perform an operation during pointing out step S . Furthermore the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Still further the identification unit requests the history record unit to generate minute data which records that the pointers starts pointing out step S .

According to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit while the pointer performs pointing out to the presentation material step S . In this case the identification unit also receives an input of the gesture 2 change to presenter in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role facilitator referring to the role storage unit based on the operating device ID 1004 included in the operation signal step S . Further the identification unit acquires an attribute change to presenter of the gesture 2 associated with the role facilitator referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture of changing a user who can perform a gesture operation from the pointer to the presenter was received from the user of the operating device who is the facilitator. Subsequently the user who can perform the gesture operation changes to the presenter and then the identification unit requests the synthetic image generation unit to change the image for the pointer to an image representing a gesture and an attribute of the gesture for the presenter who can perform an operation during the presentation step S .

Further when receiving the request of changing the image from the identification unit the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image which is an UI for the presenter and which represents the gesture and the attribute of the gesture for the presenter who can perform an operation during the presentation step S . Furthermore the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Still further the identification unit requests the history record unit to generate minute data which records that the presenter resumes a presentation of the presentation material step S .

Next a processing sequence during pointing out will be described using . is a processing sequence diagram illustrating an example during pointing out. In addition a case will be described using where the user who is the pointer A operates the operating device .

As illustrated in according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit while the pointer performs pointing out to the presentation material step S . In this case the identification unit also receives a circle gesture correct in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal the motion of light step S . Subsequently the identification unit acquires the role pointer referring to the role storage unit based on the operating device ID 1002 included in the operation signal step S . Further the identification unit acquires an attribute correct of the circle gesture associated with the role pointer and the marking color blue referring to the gesture information storage unit step S . By this means the identification unit identifies that a gesture representing a pointed out matter correct of a predetermined portion was received from the user of the operating device who is the pointer. Subsequently the identification unit instructs the synthetic image generation unit to change the pointed out matter correct of the predetermined portion to an image marked by blue step S .

Further when receiving an instruction of changing the image from the identification unit the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing the predetermined portion marked by blue and the pointed out matter correct step S . Furthermore the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Still further the identification unit requests the history record unit to generate minute data which records pointed out matters of the pointer on the presentation material step S . By this means the history record unit acquires a time stamp in this case step S numbers pointing out numbers step S and generates the minute data step S .

Next a flow of signal assembly processing will be described using . is a flowchart illustrating an example of a flow of signal assembly processing.

As illustrated in the identification unit receives an operation signal transmitted from the operating device and the motion of light the image of which is captured by the image capturing unit and which is emitted to for example the screen using the operating device step S . Further the identification unit stores the received signal the motion of light in the memory step S . Furthermore the identification unit assembles the motion of light at this point of time step S .

Subsequently the identification unit decides whether or not there is a gesture matching the motion of the assembled light step S . Whether or not there is a gesture matching the motion of the assembled light is decided by acquiring a role associated with an operating device ID included in the operation signal from the role storage unit and deciding whether or not a gesture of the acquired role is stored in the gesture information storage unit . In this case when deciding that there is the gesture matching the motion of the assembled light step S Yes the identification unit instructs the synthetic image generation unit and the history record unit to generate an image and generate minute data step S .

Meanwhile when deciding that there is not a gesture matching the motion of the assembled light step S No the identification unit decides whether or not a predetermined time passed step S . In this case when deciding that the predetermined time passed step S Yes the identification unit clears initializes the motion of light stored in the memory step S . Meanwhile when deciding that the predetermined time did not pass step S No the identification unit executes processing in step S again. That is the user does not finish operating the operating device within the predetermined time the user is making a gesture in some cases and therefore when there is not a matching gesture when the predetermined time passes the motion of light stored in the memory at this point of time is cleared.

As described above the information processing device generates a synthetic image which reflects an attribute associated with a gesture in response to an operation of the operating device by the user who is a participant of a conference in an image projected by the projecting device and generates minute data including for example the synthetic image a role of the user at the conference and an attribute. As a result the information processing device can easily create conference minutes without decreasing a proceeding speed of the conference.

Further pointing out intended by the pointer by way of a gesture is represented by way of marking in the minute data so that it is possible to easily recognize the intension of the pointing out by the pointer even when the minute data is checked later. Furthermore when it is difficult to identify a similar gesture a gesture of a higher use frequency is adopted using a use frequency of a gesture so that it is possible to efficiently lead the conference without stopping the progress of the conference. Still further roles of the operating devices are not fixed to specific roles and can be dynamically determined so that it is possible to support various conferences at which various participants attend.

Although a case has been described with the above first embodiment where a pointer performs pointing out to a presentation of a presentation material by a presenter during a conference the presenter can respond to the pointing out and also adequately add a comment. Hence a case will be described with a second embodiment where the presenter responds to pointing out and adequately add a comment.

A configuration of a projecting system according to the second embodiment will be described using . is a view illustrating a configuration example of the projecting system according to the second embodiment.

As illustrated in in a projecting system a projecting device an operating device an operating device an operating device an operating device a user PC and an information processing device are connected to networks. The same configurations as those of the first embodiment will be assigned the same reference numerals in and will not be described. In the second embodiment the new user PC is added to the projecting system .

The user PC is an input device which is used by a user who plays a role of a clerk and which can receive an input of a comment. To input a comment from the user PC to the information processing device implementing means such as an API Application Programming Interface or a Web Service which is generally spreading is used instead of a gesture. Further a comment can be input in every scene such as during a presentation of the presenter during pointing out of a pointer or during the following response to the pointing out from the presenter and can also be included in minute data.

Next the configuration of the information processing device according to the second embodiment will be described using . is a functional block diagram illustrating a configuration example of the information processing device according to the second embodiment. The same configurations as those of the first embodiment will be assigned the same reference numerals in and will not be described. In the second embodiment a function a configuration and processing of each unit other than a gesture information storage unit a synthetic image generation unit a history record unit and a letter receiving unit described below are the same as those of the first embodiment.

As illustrated in the information processing device has a role determination storage unit a role storage unit the gesture information storage unit an image capturing unit an operation signal receiving unit an identification unit a role determination unit the synthetic image generation unit the history record unit a projection control unit and the letter receiving unit .

The letter receiving unit receives an input of a comment letter data from the user PC used by the user who plays the role clerk . The comment input from the user PC is adequately input in a scene such as during a presentation during pointing out or during a response. Further the letter receiving unit outputs the received comment to the synthetic image generation unit and to the history record unit .

The synthetic image generation unit generates a synthetic image by synthesizing the comment adequately output from the letter receiving unit and an image which is being projected and outputs the generated synthetic image to the projection control unit . The history record unit receives the comment adequately output from the letter receiving unit and generates minute data which records the received comment.

Further a case will be described with the second embodiment where the presenter responds to pointing out of the pointer. In this case the gesture information storage unit further stores information different from that of the gesture information storage unit according to the first embodiment. More specifically the gesture information storage unit associates and stores an attribute a use frequency a role of a user and a gesture of the presenter during pointing out and during a response.

With an example the gesture information storage unit associates and stores an attribute page turn a use frequency high a role of a user presenter and a right arrow gesture as gesture information during the presentation of the presenter. Further the gesture information storage unit associates and stores an attribute start of response the use frequency high the role of the user presenter and a circle gesture as gesture information during pointing out of the presenter. Furthermore the gesture information storage unit associates and stores the attribute page turn the use frequency high the role of a user presenter and the right arrow gesture as gesture information during a response of the presenter.

Still further a flow of processing of the identification unit according to the second embodiment is the same as a flow of processing of an identification unit according to the first embodiment. Hereinafter only processing of the identification unit which uses information of the gesture information storage unit different from the gesture information storage unit will be described.

The identification unit receives the operation signal from the operating device operated by the presenter during pointing out of the pointer through the operation signal receiving unit and receives the circle gesture using the operating device from the image capturing unit . In this case the identification unit acquires the role presenter from the role storage unit based on an operating device ID included in the operation signal and acquires the attribute start of response of the circle gesture associated with the role presenter from the gesture information storage unit . By this means the identification unit identifies that the presenter using the operating device made a gesture of starting responding to the pointing out.

Further the identification unit notifies that a response to the pointing out is started to the synthetic image generation unit and notifies the history record unit of the generation of minute data which records that the presenter starts responding to the pointing out.

The synthetic image generation unit which received a notice that a response to the pointing out is started from the identification unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing a gesture of the presenter who can perform an operation during a response and an attribute of the gesture and instructs the projection control unit to project the synthetic image. By this means the projection control unit performs control of projecting the synthetic image on the projecting device . Meanwhile the history record unit which received a notice of generation of minute data from the identification unit acquires a time stamp in this case and generates the minute data which records that the presenter starts responding to the pointing out. In addition the flow of processing of the identification unit during the response is the same as the above flow and therefore will not be described.

Next an image projected on a screen during pointing out and during a response according to the second embodiment will be described using . is a view illustrating an example of an image projected on the screen during pointing out and during a response according to the second embodiment.

As illustrated in an image projected on the screen during the pointing out includes a presentation material explained by the presenter during the presentation a gesture an attribute and a marking color for the pointer a gesture and an attribute for the facilitator a gesture and an attribute for the presenter and comments comment columns of the pointer and the respondent. Further the pointing out is on going so that a pointed out matter pointed out by the pointer and a portion of the pointed out matter are marked in the presentation material. In response to the pointing out of the pointer the presenter makes a gesture of starting responding to the pointing out and switches to an image during the response.

Further an image projected on the screen during the response includes a presentation material explained by the presenter during the presentation a gesture an attribute and a marking color for the pointer a gesture and an attribute for the facilitator a gesture and an attribute for the presenter and comments comment columns of the pointer and the respondent. Furthermore a pointed out matter pointed out by the pointer during pointing out and a portion of the pointed out matter are marked in the presentation material. The presenter makes a gesture such as page turn or enlargement of screen and responds to the pointing out.

Next minute data according to the second embodiment will be described using . is a view illustrating an example of minute data according to the second embodiment.

As illustrated in the minute data includes roles of participants who participated in a conference a start time and an end time of the conference images in which a pointed out matter is marked in each presentation material description of the pointed out matter a response to the pointing out and comments of the participants. Further similar to the pointed out matters responses are numbered response numbers such as response 2 1 in order of responses.

Next a processing sequence during a response will be described using . is a processing sequence diagram illustrating an example during a response.

As illustrated in according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the less than sign gesture addition of explanation in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal then acquires a role pointer referring to the role storage unit based on an operating device ID 1002 included in the operation signal and acquires an attribute addition of explanation of the less than sign gesture associated with the role pointer and a marking color yellow referring to the gesture information storage unit . By this means the identification unit identifies that a gesture of adding explanation to a predetermined portion was received from the user of the operating device who is the pointer. Subsequently the identification unit instructs the synthetic image generation unit to change the pointed out matter addition of explanation of the predetermined portion to an image marked by yellow step S .

Further when receiving an instruction of changing the image from the identification unit the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing the predetermined portion marked by yellow and the pointed out matter addition of explanation . Furthermore the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Still further the identification unit requests the history record unit to generate minute data which records pointed out matters of the pointer on the presentation material step S . By this means the history record unit acquires a time stamp in this case numbers pointing out numbers and generates the minute data.

Further according to an operation of a user using the user PC the comment of the pointer is input to the synthetic image generation unit through the letter receiving unit while the pointer performs pointing out step S . In response to this the synthetic image generation unit generates a synthetic image by synthesizing the received comment and the image which is being projected and performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Further according to an operation of a user using the user PC the comment of the pointer is input to the history record unit through the letter receiving unit while the pointer performs pointing out step S . In response to this the history record unit generates minute data which records the received comment.

Further according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit step S . In this case the identification unit also receives an input of the circle gesture start of response in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal then acquires the role presenter referring to the role storage unit based on an operating device ID 1001 included in the operation signal and acquires an attribute start of response of the circle gesture associated with the role presenter referring to the gesture information storage unit . By this means the identification unit identifies that a gesture of starting a presenter s response to the pointing out is received.

Further when identifying the start of the response the identification unit checks that there is a pointed out matter pointed out during pointing out step S . Furthermore the identification unit notifies the synthetic image generation unit of the start of the response to the pointing out and the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material which is being projected and an image representing a gesture of the presenter who can perform an operation during a response and an attribute of the gesture and controls projection of the synthetic image through the projection control unit . Subsequently the identification unit notifies generation of minute data which records that the presenter starts responding to the pointing out to the history record unit step S . In response to this the history record unit generates minute data which records that the response to the pointing is started. Further the identification unit stores in the memory a page of the presentation material projected when the response is started step S .

Furthermore according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit while the presenter make a response step S . In this case the identification unit also receives an input of the right arrow gesture page turn in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal then acquires the role presenter referring to the role storage unit based on an operating device ID 1001 included in the operation signal and acquires the attribute page turn of the right arrow gesture associated with the role presenter referring to the gesture information storage unit . By this means the identification unit identifies that the user of the operating device who is the presenter makes a gesture of turning a page of the presentation material. Subsequently the identification unit notifies the synthetic image generation unit that the page of the presentation material is turned step S .

Further when receiving the notice that the page of the presentation material is turned from the identification unit the synthetic image generation unit turns the page of the presentation material which is being projected and changes the presentation material step S . More specifically the synthetic image generation unit generates a synthetic image obtained by synthesizing an image in which the page of the presentation material which is being projected is turned and an image representing a gesture which can perform an operation during the response and an attribute of the gesture per role. Further the synthetic image generation unit performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Furthermore the identification unit requests the history record unit to generate minute data which records that the presenter turned the page and in response to this the history record unit acquires a time stamp in this case and generates minute data.

Still further according to an operation of the user using the user PC the comment of the presenter is input to the synthetic image generation unit through the letter receiving unit while the presenter makes a response step S . In response to this the synthetic image generation unit generates a synthetic image by synthesizing the received comment and the image which is being projected and performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S . Further according to an operation of the user using the user PC the comment of the presenter is input to the history record unit through the letter receiving unit while the presenter makes a response step S . In response to this the history record unit generates minute data which records the received comment.

Further according to an operation of the user using the operating device the operation signal is input to the identification unit through the operation signal receiving unit while the presenter make a response step S . In this case the identification unit also receives an input of a double slash gesture end of response in response to the motion of light the image of which is captured by the image capturing unit . Further the identification unit assembles the input signal then acquires the role presenter referring to the role storage unit based on the operating device ID 1001 included in the operation signal and acquires an attribute end of response of the double slash gesture associated with the role presenter referring to the gesture information storage unit . By this means the identification unit identifies that a gesture of ending a presenter s response was received.

Further when identifying the end of the response the identification unit acquires the page of the presentation material stored in the memory in step S step S . Furthermore the identification unit requests the synthetic image generation unit to change a page to the acquired page of the presentation material step S . Still further the synthetic image generation unit changes the presentation material to the specified page according to the received request step S . Moreover the synthetic image generation unit generates a synthetic image obtained by synthesizing an image of the presentation material of the specified page and an image representing the gesture which can perform an operation during the presentation and an attribute of the gesture per role and performs control of projecting the generated synthetic image on the projecting device through the projection control unit step S .

As described above the information processing device generates minute data which adequately records a status of a response to a pointed out matter and visualizes content of a conference during a conference as a comment so that it is possible to realize a more efficient conference and generate a more precise minute data.

Although embodiments of an information processing device and an information processing device according to the present invention have been described above the present invention may be implemented in various different embodiments other than the above embodiments. Hereinafter 1 a configuration and 2 a program of a different embodiment will be described.

Information including for example processing procedure control procedure specific names various items of data and various parameters described in the above description and illustrated in the drawings can be arbitrarily changed unless particularly described. For example information stored in a gesture information storage unit and a gesture information storage unit is by no means limited to the illustrated ones and can be adequately changed.

Further each component of the illustrated information processing device and information processing device is functionally conceptual and may not necessarily be physically configured as illustrated. That is a specific embodiment of dispersion and integration of each device is by no means limited to the illustrated ones and the entirety or part of each device may be functionally or physically dispersed or integrated in arbitrary units according to various loads or use situations.

Although the above embodiments have been described using a projecting system and a projecting system as examples the present invention can be realized by a system configuration different from those of the projecting system and the projecting system . are views illustrating configuration examples of a projecting system according to a third embodiment.

As illustrated in in a projecting system an information processing device in which a projecting device and an information processing device are integrated an operating device an operating device an operating device and an operating device are connected to networks. In addition the function of each device is the same as described in the above embodiments.

As illustrated in in a projecting system the projecting device and an information processing device in which the operating device to the operating device and an information processing device are integrated are connected to networks. In the projecting system the information processing device employs a configuration of identifying a gesture when a user makes a gesture with respect to a display touch panel display or operates a touch panel. In addition the other functions are the same as described in the above embodiments.

According to the embodiments a history data generating program executed by the information processing device is provided by being recorded in a storage medium such as a CD ROM a flexible disk FD a CD R or a digital versatile disk DVD which can be read by a computer as a file in an installable format or an executable format. Further the history data generating program executed by the information processing device may be provided by being stored in a computer connected to a network such as Internet and being downloaded through the network. Furthermore the history data generating program executed by the information processing device may be provided or distributed through the network such as Internet. Still further the history data generating program may be provided by being embedded in for example a ROM.

The history data generating program executed by the information processing device employs a module configuration including each of the above function units the identification unit the synthetic image generation unit and the history record unit and when a CPU processor which serves as actual hardware reads the history data generating program from the storage medium and executes the history data generating program so that each of the above function units is loaded on a main storage device and the identification unit the synthetic image generation unit and the history record unit are generated on the main storage device.

According to the embodiments there is provided an effect of easily creating conference minutes without decreasing a proceeding speed of a conference.

Although the invention has been described with respect to specific embodiments for a complete and clear disclosure the appended claims are not to be thus limited but are to be construed as embodying all modifications and alternative constructions that may occur to one skilled in the art that fairly fall within the basic teaching herein set forth.

