---

title: Automated scalable verification for hardware designs at the register transfer level
abstract: A system and methods are provided for verifying a hardware design for an electronic circuit. The method may include: providing a hardware design description for the electronic circuit; extracting a set of design constraints from the hardware design description, where the set of design constraints represents the electronic circuit in terms of signals and logical operations performed on the signals; creating an abstraction model from the set of design constraints, where the abstraction model abstracts one or more of the logical operations in the set of design constraints by replacing the abstracted logical operations with uninterpreted functions; and property checking the abstraction model in relation to one or more design properties. When a violation in the electronic circuit is detected by the property checking step, the feasibility of the violation is then checked and, if the violation is deemed infeasible, the abstraction model is refined.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08954909&OS=08954909&RS=08954909
owner: The Regents of the University of Michigan
number: 08954909
owner_city: Ann Arbor
owner_country: US
publication_date: 20131203
---
This application is a continuation application of U.S. patent application Ser. No. 12 945 020 filed Nov. 12 2010 which claims the benefit of U.S. Provisional Application No. 61 260 445 filed on Nov. 12 2009. The entire disclosures of these applications are incorporated herein by reference.

This invention was made with government support under IIS0705103 awarded by the National Science Foundation and HR0011 04 3 0002 awarded by the Defense Advanced Research Projects Agency. The government has certain rights in the invention.

Automating and scaling pre silicon functional verification of state of the art hardware designs such as microprocessors and microcontrollers presents many challenges. These designs employ wide datapaths with arithmetic logical and memory units and complex control logic that coordinates their functionality. The latter typically includes a set of high level optimizations aimed at increasing a design s throughput and reducing its area and power consumption. The complexity of both the datapath and control logic results in an enormous state space with vast room for design errors. Furthermore the progression in the design of hardware systems like microprocessors leads to ever increasing control logic complexity and overall chip size as predicted by Moore s law.

In contrast to simulation which typically examines a relatively small number of scenarios when testing a design formal verification systematically proves correctness of a design by exhaustively examining the entire design s state space searching for violations to a well specified behavior. The size of the state space grows exponentially with the size of the design leading to the so called state explosion problem. Since the control logic and datapath of contemporary designs are also growing exponentially in both size and complexity the formal verification barrier grows doubly exponentially and significantly lags behind the design capability leading to an exponentially growing verification gap. The increase in complexity and size of today s designs as well as the difficulty of formally verifying these designs.

Verification thus cannot be made tractable without a divide and conquer approach that tailors different verification methodologies to various parts of the design with different structural patterns. To be effective these methodologies must be applied at suitable levels of abstraction. In particular descriptions given at the Register Transfer Level RTL accurately capture the functionality of hardware designs by preserving high level semantic information that is otherwise lost when moving to the gate or transistor level representations. It is therefore reasonable to assume that the design under verification be given as an RTL model in a suitable Hardware Description Language HDL such as Verilog.

At this level a reasonable distinction can be made between the datapath and the control logic and appropriate verification schemes can be applied to each. Datapath units can usually be isolated and verified separately with methods that exploit their structural regularity. Once verified many datapath elements can be reused across various designs and architectures. Control logic on the other hand globally routes the flow of data in a design and thus has to be verified at the level of the entire design. Moreover control circuitry is invariably custom made for the architecture and design at hand precluding the use of previous verification results.

Current verification efforts have tackled control logic verification by generating new mathematical models typically based on abstraction that correspond to the RTL description of the design and utilizing theorem provers to reason about them. Although these models simplify the datapath they are roughly as complex as the original RTL model. Consequently hundreds of man hours are required to manually regenerate the verification model from the RTL model. Moreover a cumbersome process is required to keep both models consistent and to prevent subtle bugs from being introduced in the abstract model or masked from the RTL model.

Theorem provers use a number of mathematical approaches to certify that a design complies with its desired functionality and typically incorporate a number of theories ranging from zero to first to higher order logics to incrementally prove correctness. In addition to the drawbacks of verifying an abstract model separately from the RTL description theorem provers are not fully automatic although equipped with a set of engines on their back end the user is required in many cases to guide the power by applying specific engines in the various phases of the proof. In the best case manual reasoning significantly impedes the verification task for complex designs and in the average case it makes it completely infeasible. This section provides background information related to the present disclosure which is not necessarily prior art.

A system and methods are provided for verifying a hardware design for an electronic circuit. The method may include providing a hardware design description for the electronic circuit extracting a set of design constraints from the hardware design description where the set of design constraints represents the electronic circuit in terms of signals and logical operations performed on the signals creating an abstraction model from the set of design constraints where the abstraction model abstracts one or more of the logical operations in the set of design constraints by replacing the abstracted logical operations with uninterpreted functions while the signals in the set of design constraints remain unabstracted in the abstraction model and property checking the abstraction model in relation to one or more design properties. When a violation in the electronic circuit is detected by the property checking step the feasibility of the violation is then checked and if the violation is deemed infeasible the abstraction model is refined.

This section provides a general summary of the disclosure and is not a comprehensive disclosure of its full scope or all of its features. Further areas of applicability will become apparent from the description provided herein. The description and specific examples in this summary are intended for purposes of illustration only and are not intended to limit the scope of the present disclosure.

The drawings described herein are for illustrative purposes only of selected embodiments and not all possible implementations and are not intended to limit the scope of the present disclosure. Corresponding reference numerals indicate corresponding parts throughout the several views of the drawings.

An approximation based framework for hardware verification is set forth in this disclosure. Formalization of the verification task is first presented followed by a description of the approximation framework. The framework assumes that the design is given as a reactive transition system which is described via sequential and combinational hardware components that are connected to the inputs and outputs of the design. Each component is characterized by a so called consistency function that characterizes its functional behavior by relating its outputs and inputs with appropriate constraints. In addition to the design description the framework requires a sequential bound k such that the correctness of the design is proven only up to that bound. While requiring a known bound may seem to limit the utility of the approach empirical observation suggests that it has application in many situations where such bounds are known as priori or can be easily derived from the particular structure of the design. Examples include verification of pipelined microprocessors packet routers and dataflow architectures common in filters etc.

Given the design s description and the bound k unrolling is used to derive a purely combinational description of the design s transition relation. This process is linear in k and the size of the design. If we let X denote the set of variables in the unrolled description then the consistency function of each interconnected component i can be described by a constraint E X and the formula

The verification problem can then be phrased as the question of establishing the validity of the formula exact X prop X where prop X indicates a specified correctness condition also known as verification criterion . An equivalent but slightly more convenient form of this formula is exact X p prop X p where p is a free variable not in X that represents the property being checked. In this form the sub formula p prop X can be viewed as the consistency function of the correctness property in the same way that exact X is the consistency function of the concrete design. For simplicity however and bearing in mind that it can be considered part of exact X we will omit p prop X from our formulas.

Checking the validity of exact X p is typically done by checking the satisfiability of its negation exact 3.1 

Proving the unsatisfiability of 3.1 establishes that the property holds while a satisfying solution X 0 demonstrates the existence of a design or specification bug.

Except for trivial designs checking the satisfiability of 3.1 directly is generally infeasible. Instead in the proposed scheme the property is verified on an approximation of the exact design which is a partial representation of the design s functionality. For such an approach to work the approximation must by construction be significantly easier to verify than the original design both computationally and practically. It also must be related to the original design in such a way that verifying it allows deriving conclusions about the original design. Along these lines we will introduce a generic notion of soundness and completeness with respect to a property p which are useful for deriving suitable approximations as we will show later. Throughout these definitions M X is used to denote a conjunction of constraints over X that models the design either exactly or approximately. For brevity M s explicit dependence on X is omitted.

Definition Relative Soundness and Completeness if M p M p is valid i.e. holds true for all assignments to X where M and Mis called a complete approximation of M.

It is easy to show that soundness as well as completeness are transitive reflexive and anti symmetric relations therefore defining partial orders over the possible models. Since completeness and soundness are dual we will unify the two orders and use such that MpMif M M is a sound complete approximation of M M . If we let E denote the constraints that exactly model the original design i.e. E exact X then a soundness and completeness notion can be defined for approximations of E as follows.

Approximations that are sound complete or both can be very useful particularly when it is significantly easier to check the validity of A p than to check the validity of E p and still draw meaningful conclusions about E. Approximation based methods are therefore based on the idea of deriving an approximation checking the property on it and drawing conclusions on the original model. For example if the property holds on a sound approximation it will definitely hold on the original model since EA A p E p . Conversely if the property is violated on a complete approximation it will definitely be violated on the original model.

We can reason about the space of sound and complete approximations by simplifying the expression in Relative Soundness and Completeness definition.

Therefore any sound and complete approximation A must satisfy Ep A E p which can also be written as A Ep E p . In this interval we have great latitude in choosing the approximation as illustrated pictorially in .

A final set of definitions introduce over and under approximations which are special cases of sound and complete approximations respectively.

Definition Relative Over and Under Approximation if M Mis valid then Mover approximates M and Munder approximates M.

Similarly to sound and complete approximations over and under approximations define partial orders over the possible models and are represented with the operator . Finally A is called an over approximation if EA and an under approximation if AE. It is important to note that over and under approximations can be defined without referencing the property p under consideration. As we will shortly show this will be very useful in our framework.

As mentioned earlier the goal of verification methods that use approximations is to find a sound and complete approximation that simplifies the verification task. Theoretically finding such an approximation is as hard as solving the original problem. Practical algorithms instead start with an approximation Aof E that is either sound or complete but not both and check the property on it. Then a sequence of more accurate approximations A A . . . Ais iteratively generated until the property can be proven to fail or hold on E.

Both approximation based approaches i.e. tightening versus relaxing are used nowadays in many verification contexts in hardware as well as software. The traditional verification scheme starts with simulating the design in order to hunt for bugs simulation is a form of approximation based verification since the property is verified given a specific input vector. The behavior of the design for this input vector is a complete approximation of the original design. In this context a false positive refers to the scenario wherein the property is violated by the original design and the violation is not caught when verifying the approximation i.e. simulating the design . The presence of false positives is a compromise that designers are willing to make in return for scaling up the verification i.e. simulation time. Recent methods guide the simulation based on formal methods and in turn correct the original approximation to lower the possibility of false positives. This can be considered a form of relaxation.

When reaching a certain level of confidence regarding the correctness of the design the designer becomes interested in proving the lack of bugs therefore the intuitive solution in this case is a top down iterative tightening based on sound approximations such as the algorithm we are presenting.

While an iterative approximation correction approach is appealing at a conceptual level its applicability hinges on two main premises. First the approximation process is computationally easy such that its benefit outweighs the inherent loss of information that requires correction to make it sound and complete. For instance linear time over or under approximations can be obtained via relaxing or tightening the design s constraints that are associated with certain components. This can be done independently of the property being checked this is true for a certain class of properties such as bounded safety which gives over and under approximations an edge over other types of sound and complete approximations. For example the full fledged functionality of an arithmetic unit is replaced with a restricted version that models say boundary cases such as an over flow computation or a division by zero flag this creates an under approximation of the design. Datapath abstraction which concerns us in this thesis is another example of an easy to derive over approximation that is independent of the property.

The second premise is that there exists a sound and complete approximation that is significantly different than the original design on which the property can be proven to hold or fail. The existence of any sound and complete approximation let alone one that significantly differs from the original design is not always obvious nor guaranteed. This is especially true when the approach is confined to a class of approximations such as over approximations. For example consider the circuit in in which a Boolean variable x is compared to y another Boolean variable that is equivalent to x through the AND gate. In this case exact X p as it can be inferred from the expression in c . However it can be shown by inspection that any over approximation A obtained by removing one or more constraints from exact X is sound but not complete i.e. A p. In this case and many similar cases applying iterative over approximation tightening is likely to be significantly slower than attempting to establish the validity of the exact formula since the iterative algorithm will gradually tighten the approximation until it is ultimately identical or very similar to it. Therefore the existence of such a hoped for approximation or the lack thereof can determine whether applying approximation is beneficial and can assist the verification engineer in developing an intuition regarding its applicability. In the context of datapath abstraction our method and experimental results confirm the following conjecture 

Conjecture 1 An approximation process wherein similar datapath components in the implementation and specification are abstracted similarly leads to an over approximation that is sound and very close to being complete.

Next how an iterative approximation correction approach can be utilized to verify the complex control logic of hardware designs is described. The system performs bounded model checking of safety properties on hardware designs described at the Register Transfer Level RTL e.g. in Verilog . It is understood that extensions of this approach can be applied to other HDLs without compromising the merits of the approach. A typical usage scenario involves providing two Verilog descriptions of the same hardware design such as a high level specification and a detailed implementation and checking them for functional equivalence. Given a Verilog description and a sequential bound k the system extracts a word level representation of the design s transition relation and unrolls it k times to create a combinational description of the design on which the approximation correction approach can be applied.

An overview of the Verilog hardware description language is provided and the verification problem of Verilog descriptions at the RTL is defined. That is followed with an algorithm based on the approximation scheme described earlier. The approach over approximates the design by removing datapath related constraints and performs verification on the constraints representing the control logic. In this new context the terms abstraction and relaxation will be used interchangeably to denote over approximation and refinement will be used to denote correction or tightening.

One of the major differences between RTL and gate level Verilog is that RTL Verilog descriptions operate at the word level i.e. they manipulate words of data usually referred to as bit vectors. Datapath elements are usually described using bit vectors. The control logic on the other hand uses single bit signals to control the computation with the use of multiplexors and logic gates that are respectively described by conditionals e.g. if then else and switch statements and Boolean expressions.

Formally an RTL Verilog description defines a set of signals R W I and M respectively denoting the registers wires inputs and memories in a flat representation of the design. Each signal in V R W I can be either single bit VV or multi bid VV and signals in M are multi dimensional arrays of bits. The interactions of the design components are defined in Verilog via assignments. For example the Verilog code fragment

defines the next state of a 32 big register r R as a function of other signals in the design i.e. r r.

Let X denote the set of variables in the unrolled description. Each interconnected component with output x X can be described by the consistency constraint C X x f X where f X defines a Verilog word or bit level expression 

The consistency constraint C x x x x x for example uses the operator to define a word level constraint that models a 32 bit adder by equating the signal xwith the sum of xand x where x x and xare 32 bit signals. Note that a compound constraint can be used to characterize two or more serially connected components. For example the constraint C x x x x x x 4 uses two word level operators namely addition and right shifting to compose a constraint that conjoins two simpler ones.

A common way to abstract design s elements is to replace them with terms uninterpreted functions UFs and uninterpreted predicates UPs . The resulting term level abstraction maintains the consistency of the removed elements without representing their detailed functionality and leads to a significant reduction in the size of the design s state space. The abstraction step is followed by property checking and refinement. Property checking determines if the abstracted design satisfies the specified property. Refinement determines if the abstraction was sufficient to establish whether the property holds or fails on the concrete design and if otherwise to refine the abstraction accordingly.

As mentioned earlier term based abstraction can be viewed as a relaxation of the system of constraints that characterize the concrete design. Specifically if each concrete consistency constraint C X is relaxed to a corresponding abstract consistency constraint A circumflex over X where X and circumflex over X denote the concrete design signals and their corresponding abstractions we can model the abstract design by the formula

Formally we introduce to denote the abstraction process. maps the concrete variables and operators to appropriate abstract counterparts. Specifically if is a concrete variable or operator its abstract counterpart is denoted by . Applying to the concrete constraint C x . . . x yields Cx . . . x C x . . . x circumflex over x . . . circumflex over x . In general any expression involving concrete variables and operators can be abstracted recursively applying to its sub expressions. For example applying to the constraint C R R R R R R 4 yields

Using the mappings add shift R circumflex over R and 4 four we have A circumflex over R circumflex over R circumflex over R circumflex over R add R shift circumflex over R four .

Different types of abstraction can be defined based on an appropriate mapping between the concrete constants variables and operators and their abstract equivalents. Conceptually this applies also to other abstraction methods. Furthermore this approach can take advantage of the design hierarchy and apply abstraction to the design at different levels of granularity. For instance an entire datapath unit such as the ALU can be replaced with a single UF or UP. Such heterogeneous abstraction can be automated based on syntactic rules and can also allow manual yet fairly intuitive intervention in the abstraction process. While manual hierarchy based abstraction has been mainly used with theorem proving our approach focuses on automating the abstraction at the level of the design signals and therefore is defined for each signal in the design.

In addition to abstracting combinational elements with tractable verification may require the abstraction of memory arrays. Applying only term based abstraction to an n word by m bit memory yields an n term abstraction. For memories of typical sizes in current designs n is on the order of thousands to millions of words. Memory abstraction allows modeling an n word memory by a formula whose size is proportional to the number of write operations dot over K rather than to n. Note that memory abstraction is distinct from term based abstraction. A useful mnemonic device is to think of term and memory abstraction as being respectively horizontal and vertical they can be applied separately as well as jointly.

The system implements memory abstraction using lamda expressions. In particular the expression M x ite x A D M x describes the next state of a memory array M after a write operation with address A and data D. The operate it e is an if then else construct simulating a multiplexer. Replacing memory writes with it e expressions and UF applications is performed during the process of unrolling such that the final formula is lambda free.

For example the Verilog code fragment set forth below describes the behavior of a 16 word memory that has two ports one for reading and one for writing and the table describes the state of all the design signals including the memory array in the first four cycles of execution after initialization.

Given these abstraction mechanisms the algorithm performs the satisfiability check on the abstraction of formula 3.1 i.e. circumflex over conc abst . 4.1 Using an appropriate abstraction operator 4.1 can be considerably simpler than 3.1 facilitating its quick solution by a suitable satisfiability checker. Next we will define the soundness criterion for this abstraction scheme and then describe two families of term based abstraction.

To reason about soundness note that maps Verilog equality to the interpreted equality predicate between terms. Thus circumflex over circumflex over X p has to adhere to two basic rules equality transitivity and functional consistency.

Definition Functional Consistency Functional Consistency w.r.t. any two sets of terms and x . . . xand y . . . yand a UF or UP f of arity n is defined by the relation x y . . . x y x . . . x y . . . y .

To relate circumflex over with circumflex over we have to show that the set of constraints arising in circumflex over are implied by the concrete formula circumflex over . To do so we examine the constraints affecting circumflex over based on its structure and semantics.

Consider for example the concrete constraint C x x x x x x introduced earlier. It embeds three different constraints implicitly a fan in constraint defining the relation C x x x x x x for some function a domain constraint defining the possible values of the variables in this case 0 x x x

To perform abstraction to the logic of Equality with Uninterpreted Functions commonly referred to as EUF the set of design signals X is divided into single bit control signals and multi bit data signals denoted by Xand Xrespectively. Xand Xin the unrolled design represent their counterparts Vand Vin the original design description. Generally speaking and as hinted by the notation datapath calculations are performed with signals in X whereas control logic is defined with signals in X. Classifying a signal as a datapath or a control signal as a datapath signal or vice versa does not compromise the correctness of the approach. Specifically a control signal that is abstracted as part of the datapath might yield a spurious counterexample and cause an increase in the number of refinement iterations. The less probable scenario of misclassifying a datapath signal as a control signal causes the abstract model to be unnecessarily detailed and possibly makes the property checking step intractable. Experimental results show that the overall algorithm is robust and quite scalable despite control data intermixtures that may lead to these scenarios.

By the same token Oand Oare used respectively to denote the control and data operators. A control operator is one that performs logical operations i.e. conjunction disjunction and negation on single bit signals. All other operators are considered data operators. Note that an operator is the occurrence of a symbol in a specific constraint rather than the mere syntactic token representing it. This is important since Verilog like other HDLs defines the semantics of each operation based on its context. For example the constraint C x x x x x x uses a 32 bit operator to perform addition the symbol might have semantics elsewhere. As we will see later the abstraction process uses context information to determine the abstract counterpart of each Verilog operator.

In order to be geared towards control logic verification datapath abstraction removes the detailed functionality of the datapath elements such as adders shifters etc. The interactions among the control signals however are preserved making it possible to perform meaningful verification of safety properties on the design s control logic. Along these lines consider the class of abstractions based on over approximation via that leave the control logic unabstracted i.e. is the identity function when applied to Xor O. For instance a c a a c c. Leaving the control logic in its concrete state preserves enough precision that allows discovering bugs in the control logic.

In this case circumflex over is a formula in the quantifier free first order logic FOL defined by the following rules 

Definition EUF Abstraction performs abstraction to the EUF logic by leaving the control logic unabstracted i.e. modeled via Boolean and it e constructs .

To illustrate EUF abstraction consider the exemplary Verilog design found in the appendix. The verification objective is to prove that signal p is always true indicating that the design satisfies the condition a o d f . The formula representing the concrete constraints of this design can be derived by inspection and is also given in abstract.

Using the semantics of bit vector operations such as extraction concatenation and shifting along with the standard Boolean connectives this formula can be translated in a straightforward fashion to propositional CNF so that it can be checked for satisfiability by standard SAT solvers. In fact for this simple example it is quite easy for a modern SAT solver to prove that concp is unsatisfiable which is the same as saying that conc p is valid.

The objective however is to establish this result using abstraction and refinement. A possible abstraction of this design is given in abstract where detailed bit vector operations have been replaced by UP and UF symbols. For example EX1 is a UP that corresponds to extracting the most significant bit of and SR2 is a UF that corresponds to a right shift of b by two bits. Terms in this abstract formula i.e. variables that correspond to bit vectors in the concrete formula are now considered to be unbounded integers. They can be compared for equality to enforce functional consistency but are otherwise uninterpreted having lost their concrete semantics. On the other hand variables in the abstract formula that correspond to single bits in the concrete formula such as m and l retain their Boolean semantics and can be combined with the standard Boolean connectives.

As mentioned above a necessary condition for the soundness of is that it is a 1 1 function w.r.t. variables. In fact a has to also be 1 1 w.r.t. operators as well. Consider for example the case where a maps both x 3 b000 and x 2 b00 to concat circumflex over x zero . This abstraction is not sound since the operator has different semantics in either case this leads to a scenario wherein concat circumflex over x zero concat circumflex over x zero is valid while x 3 b000 x 2 b00 is not. The two expressions should therefore be mapped to two distinct UFs under . The following lemma articulates that in the general case the over approximation criterion mentioned above is both necessary and sufficient.

In the algorithm a 1 1 a function is enforced with the use of a naming convention for UFs and UPs. In particular since operator semantics in Verilog are defined by its operation as well as the size of its arguments the name of a UF or UP is a concatenation of the operator type and argument sizes. For example a 32 bit addition is abstracted to the UF called add3232 .

Finally it is worth mentioning that since a is 1 1 its inverse is well defined. remaps terms back to their corresponding mulit bit variables and remaps uninterpreted functions to their corresponding bit level counterparts. The use of will be evident in the refinement back end of our algorithm.

CLU is a quantifier free first order logic that extends EUF with separation constraints and lambda expressions. Separation constraints allow the use of limited counting arithmetic useful in modeling certain hardware constructs such as memory pointers. Lambda expressions allow aggressive albeit consistent abstraction of memories. Note that we borrow Lambda expressions to model memory arrays even when using the UEF logic thus the main difference between EUF and CLU in this case is counting. a is used to differentiate CLU abstraction from EUF abstraction a .

The use of counting in CLU is done using an interpreted operator succthat allows adding an integer constant c to an abstract variable circumflex over x . Note that such use would not have been feasible if abstract variables are represented with non integer constructs such as bit vectors.

In hardware design there are two frequent occurrences of addition and subtraction of constants. The first occurrence which is rather implicit is in the use of any stand alone constant c in essence c is equivalence to succ circumflex over 0 . Constants are used frequently in decoders such as in IR 3 0 4 b0101 succ circumflex over 0 or in the control logic in counters such as in cnt 3 d4 succ circumflex over 0 . The second use of constant addition is in the incrementing of counters such as in cnt

In order to remain sound the abstraction of constant addition with the interpreted succ operator in CLU has to guarantee that is a 1 1 function. This is always true in the case of constants c can always be modeled with succ circumflex over 0 regardless of the size of the bit vector representation of c in Verilog. The latter is true since any two constants of the same value but of different bit width are still equal according to Verilog semantics. In practice we use the interpreted addition operator only with small constants. Constants that are greater than a pre defined threshold are abstracted similarly to variables in order not to overload the abstract solver.

This no longer holds for counting. If is obvious to the size of x then it will always abstract x c with succ circumflex over x although overflow occurs differently depending on the bit width of x and the value c. In general it is possible to assume that counters do not overflow as done in 4 . In particular one can rewrite certain counters to remove implicit overflow. For example the counter cnt

Early EUF solvers convert circumflex over to an equi satisfiable propositional formula using a suitable encoding. On the other hand Satisfiability Modulo Theories SMT solvers such as YICES operate on these formulas directly by integrating specialized theory solvers within a backtrack propositional solver. SMT solvers are thus able to take advantage of the high level semantics of the non propositional constraints e.g. EUF constraints while at the same time benefiting from the powerful reasoning capabilities of modern propositional SAT solvers.

Given the over approximated abstract formula circumflex over the algorithm checks its satisfiability using an SMT solver. If the solver determines that circumflex over is unsatisfiable the algorithm halts concluding that the property holds. Otherwise an abstract counterexample is produced and the refinement phase is invoked.

In this type of abstraction where terms are integer variables a satisfying solution to formula 4.1 is an assignment of integers and Booleans respectively to the terms and atoms in the variable vector circumflex over X 

An exemplary and basic refinement type is described that is based on refuting spurious counterexamples. In the refutation based refinement a spurious abstract counterexample is viewed as undesirable behavior and one or more succinct explanations are used to refine the abstraction for the next round of checking. This is similar to clause recording or learning in SAT solvers.

To determine if the violation reported by the validity checker is a real violation we need to evaluate it on the concrete formula. This step referred to as feasibility checking can be accomplished by applying to 4.2 yielding abst viol conc p cviol 4.3 where cviol X is the concretization of the abstract violation. The E superscript of and are omitted in this description and when obvious from the context. Unlike the rest of the formula elements concretizing constants is not obvious since the variables in the abstract formula are unbounded integers some assignments will not therefore fit within the bound of the originating concrete bit vector. However this problem can be avoided altogether by a more suitable representation of the violation as explained in the next section.

In general the process of feasibility checking consists of determining the satisfiability of 4.3 . If 4.3 is found to be satisfiable then the violation reported by the validity checker is a real violation indicating a real design or specification bug. If 4.3 is found to be unsatisfiable then the violation is spurious. This triggers abstraction refinement which strengthens the abstraction by eliminating this violation from it for the next round of validity checking. A superscript is used to denote the index of the iteration such that circumflex over circumflex over X p denotes formula 4.1 . The iiteration of the abstraction refinement loop then consists of the following computations 

This section focuses on the soundness of the abstraction as well as the interaction between the abstraction and unrolling processes and the latter s impact on soundness. shows two ways of computing an abstract formula abst circumflex over X using abstraction and unrolling. Starting from a Verilog Transition Relation over the variables R W I and M unrolling produces the concrete formula conc X which is in turn abstracted to abst circumflex over X via as described above. As illustrated in the figure the same result can be obtained via producing an abstract transition relation first followed by unrolling to create abst circumflex over X . Soundness is explained by 

The rationale behind a sound Verilog to CLID abstraction is explained with a small Verilog example and a series of improved abstractions. Consider the following Verilog fragment

If s is abstracted to TRUTH variable S and v 7 0 v 3 0 and v 5 2 are respectively abstracted to the TERMs V70 V30 and V52 a resulting intuitive UCLID abstraction which we call ABST is given below. Note that temporal abstraction of the clock signal clk is modeled with the function NEXT which represents a single cycle advancement of the transition relation.

Another possible abstraction which removes more constraints from the UCLID model and thus is coarser is 

In this abstraction called ABST arbitrary values are generated using free inputs denoted by the prefix FREE. This bears some similarity to localization reduction which abstracts state variables by turning them into free inputs.

ABST is sound since it is completely unconstrained. It is also easy to see that it is too coarse and does not serve as a meaningful abstraction. A meaningful and sound abstraction is derived similarly to ABSTand ABSTabove with a counter intuitive caveat ABSTand ABSTare not actually sound for the following reason. When s 0 in the Verilog model v 3 0 is modified due to the assignment in the else branch but more importantly v 7 0 is implicitly modified by virtue of its relation with v 3 0 on the other hand V70 remain unchanged in the abstraction when S is false disallowing a corresponding transition from taking place in the UCLID model. A similar analysis can also be carried out for the case of s 1.

For this example soundness is guaranteed by modeling every possible transition for each bit field of v. On the other hand it is possible to constrain the UCLID model further without compromising soundness of the abstraction. In particular the algorithm in Vapor 4 uses a more refined abstraction such that the arbitrary symbolic values given FREE are replaced with UCLID expressions that relate each bit vector with its bit fields. The following section describes the abstraction mechanism in Vapor.

As shown above multi bit signals typically consist of bit fields that are individually accessed for reading and or writing. Correct abstraction in such cases must account for the relation among the bit fields and between each bit field and its parent vector. Furthermore a na ve abstraction may lead to the unintended abstraction of critical control signals that are grouped in Verilog as multi bit vectors making the abstract UCLID model too coarse to be usable in verification. Finally abstraction of certain Verilog operators may lead to the generation of spurious errors since functional abstraction guarantees consistency under equality but is oblivious to properties such as associativity and communtativity for example abstracting integer addition with the UF add x y will insure functional consistency but will not treat add x y as identical to add y x as required by commutativity of addition.

The above observations suggest that an abstraction algorithm must not only examine the declared signal types in Verilog but also the way such signals are used in the body of the Verilog description. How Vapor abstracts various Verilog constructs to corresponding ones in UCLID is described further.

Based on their bit structure Verilog variables are classified into three main types. Single bit variables which are 2 valued and naturally modeled as UCLID TRUTH variables. Multi bit words which are viewed as unsigned integers and translated into corresponding UCLID TERM variables. Word arrays which typically denote memories or register files and are conveniently represented by UCLID UF variables. Except for the abstraction of bit vectors these mappings are straightforward. Bit vectors require additional machinery to insure that their abstraction is consistent. Specifically given a Verilog bit vector X we must not only create a UCLID TERM to represent X but also create additional TERMs to represent each of its individually accessed bit fields. Furthermore we must introduce a set of uninterpreted functions that relate these TERMs to each other. Otherwise UCLID treats these TERMs as completely independent potentially leading to the generation of numerous false errors or to the generation of unsound abstraction.

Without loss of generality assume that X is a vector of n bits such that X n 1 is the most significant bit. It is convenient to view X as the interval n 1 0 . Assume further that the set of individually accessed bit fields of X is denoted by X. Thus Xis a set of possibly overlapping subintervals of n 1 0 . Finally let X denote the coarsest partition of n 1 0 induced by X. For example if X is 15 0 and X 15 0 15 8 7 0 10 3 then X 15 11 10 8 7 3 2 0 .

Consistency can now be established by introducing TERMs for each of the bit fields in Xand X and a corresponding set of complementary uninterpreted extraction and concatenation functions that relate these TERMs. These functions are designed to insure that whenever a bit field in Xis changed appropriate updates are made to all the other bit fields that overlap it. These functions are named according to the naming convention described in above in order to insure soundness. In particular extraction functions are named extract m w X to indicate the extraction of w bits from bit vector X starting at bit position m. Without loss of generality bit vectors are assumed to be numbered such that bit is in the least significant position. Similarly concatenation functions are named concat w . . .  w X1 . . . X to indicate the concatenation of k bit vectors X. . . Xwhose bit widths are w . . . w. A similar naming convention is adopted for TERM and TRUTH variables e.g. the Verilog bit vector X a b is declared as the TERM X a b.

The general scheme described above can be simplified in certain situations and such simplifications can lead to significantly more efficient translations from Verilog to UCLID. For example if the individually accessed bit fields of a Verilog bit vector are mutually disjoint it is not necessary to introduce additional TERMs for the partition blocks. Extraction may also be simplified when applied on constants. These optimizations reduce the size of the propositional formula generated by UCLID since UCLID encodes TERMs using a bit string whose length is a function of the total of TERMs and UFs applications being processed. Furthermore we found that such an optimization eliminates many unnecessary false errors by avoiding the need for using extraction UFs.

In the process of obtaining the coarsest refinement over a set of bit vectors some of the blocks in the resulting partition may end up being single bits. These single bit fields can be modeled as TERMs and used in extraction and concatenation as described above. This however might allow them to get more than 2 different symbolic values. In such cases we use UPs instead of UFs as extraction functions. When the block TRUTH variable needs to be concatenated it has to be type cast to TERM using an appropriate ITE expression.

The abstraction and unrolling processes in Vapor examine the coarsest partition of all Verilog variables maps each bit field in this partition to a UCLID variable and defines the abstraction based on or as described previously. In this section we describe an improvement to the abstraction unrolling processes such that 

The practicality of this scheme relies on the fact that the methodology deploys a refinement back end allowing any false negatives arising from interacting bit fields to be resolved automatically. For example v 5 2 appears only in a RHS expression. This means that 1 it does not need to participate in the state modeling of v and 2 it can be expressed in the final concrete or abstract formula using v or using the combination of v 3 0 and v 7 4 . If false negatives are to arise due to these interactions the refinement back end will automatically resolve them.

Experiments show that the implementation details of the abstraction refinement approach can directly and greatly affect performance. In particular a number of techniques were found to be crucial for convergence and essential to the overall performance of the approach. The first group of techniques allow distilling powerful lemmas from abstract counterexamples in a process referred to as generalization. Using these lemmas to refine the abstract counterexample was essential for fast convergence of the refinement loop. The second group of techniques allow generating one or more extremely succinct lemmas in each refinement iteration and therefore further speeding up the convergence and overall performance significantly.

The counterexample reported by the validity checker can be viewed as a very specific violation. Checking the feasibility of such a violation is trivial since it can be done through SAT propagation in equation 4.3 . On the other hand the violation cannot be used to derive a useful refinement since it encodes only one particular case and out of bound constants cannot be concretized as described earlier. At the other extreme the checker can declare that the property is violated without reporting any information. This corresponds to requiring viol circumflex over X cviol X 1 leading to an expensive feasibility check when checking the satisfiability of 4.3 . This in fact amounts to doing the verification at the bit level without any abstraction. In this case there is no need for refinement if 4.3 is satisfiable a bug is reported otherwise the property holds.

In between these two extremes there is great latitude to choose a suitable representation of the violation subject to the following objectives 

Pseudo code for a counterexample generalization algorithm and supporting data structure are provided below 

The algorithm traverses starting from the top node and recursively invokes the procedures EvalTerm and EvalFormula. Given a term variable t when applying X by evaluating the interpreted operators in its sub tree. EvalFormula is invoked on formulas including atoms and it constructs the violation by calculating simplified atoms and their value under X . We use the auxiliary function controlling traditionally defined for logic gates as controlling AND 0 and controlling OR 1.

Given a spurious violation i.e. viol circumflex over X such that conc X p viol circumflex over X is unsatisfiable it is possible to further widen the footprint of the learnt lemma by explaining the unsatisfiability of the aforementioned formula via Minimally Unsatisfiable Subsets or MUSes for short. An MUS is an unsatisfiable subset of the formula that becomes satisfiable if any constraint is removed. The use of MUSes allows the refinement in the current iteration to block violations that might occur in future iterations. Formally one or more explanations are extracted as follows 

Concretization refinement is an alternative refinement technique used to analyze the abstract counterexample and in case it is spurious to concretize parts of the design in order to eliminate it. Concretization is the inverse of abstraction i.e. it restores the bit vector semantics for the refined parts which were initially abstracted away by UFs. Unlike refutation refinement which refines by aggregating lemmas concretization refinement modifies to eliminate the current counterexample and possibly other similar ones that may occur in future iterations.

Concretization bears slight similarity to unhiding registers in localization reduction with two clear distinctions. Localization reduction operates on gate level descriptions wherein the abstraction removes the entire logic that drives certain bit registers whereas concretization based DP CEGAR operates on word level descriptions and uses UF based abstraction making it a better candidate for equivalence checking.

To allow the representation of a partial abstraction in which parts of the datapath are concrete multi bit vectors remain unabstracted in other words the terms originated from them are represented as bit vectors. Let denote the abstraction used in iteration i. Initially each Verilog expression e EXP is abstracted by recursive application of which abstract all multi bit operators via UFs UPs while leaving multi bit signals unabstracted i.e. x x for any x X. The abstraction of operators is similar to the one described in the previous section except that the domain and ranges of Ufs Ups are finite size vectors.

The feasibility and refinement steps proceed as follows. A satisfying solution to 4.1 is an assignment of bit vector values and Booleans to the terms and atoms in the variable vector circumflex over X . If we view atoms as single bit vectors the abstract counterexample can be written as

The iiteration of the abstraction refinement loop consists of 4 steps the first three of which are similar to the refutation based CEGAR. The last step performing the refinement is significantly different. Instead of using the violation to refute the abstract counterexample it is used as a seed to pin point parts of the design that should be concretized.

In order to do that the automated verification system maintains an annotation map circumflex over X V N such that circumflex over x v i indicates that in the abstract formula corresponds to design s signal v at cycle i. is incrementally calculated during the unrolling with marginal cost. Given the signals in the violation circumflex over X circumflex over X circumflex over X defines a set of design variables and corresponding cycles. The set of operators linking signals in circumflex over x which we will denote by O can then be concretized. In other words the abstraction is modified such that op op for any op .

A more effective refinement is performed based on the observation that spurious counterexamples usually arise due to control data intermix. Furthermore if a spurious counterexample appeared due to the logic in a specific cycle it is very likely that similar spurious counterexamples will arise in another cycle based on the same circuit components. Therefore the concretization in the automated verification system is applied in all cycles to the components related by the spurious violation. In particular 

Next the design is abstracted to form an abstraction model. The abstraction step over approximates the design s constraints via uninterpreted functions UFs and uninterpreted predicates UPs . In an exemplary embodiment the logical operations in the set of design constraints are replaced with uninterpreted functions while the signals in the set of design constraints remain unabstracted in the abstraction model. It is further envisioned that only select logical operations in the set are abstracted. For example a system design may select which logical operations or types of operations are initially abstracted. In other embodiments logical operations and signals or subsets thereof may be abstracted to form the abstraction model.

The abstraction model is then property checked in relation to one or more design properties. In the exemplary embodiment the abstraction model is checked using a satisfiability or validity solver. When the design properties hold the hardware design is correct whereas when the design properties fail the solver outputs an assignment of variables that represent a violation of the design properties. While reference has been made to a satisfiability modulo theories solver other types of solvers as well as other property checking techniques are contemplated by this disclosure.

When the design properties fail the abstraction model may be refined and rechecked. First the abstract counterexamples output by the solver are checked for feasibility. In the exemplary embodiment feasibility is assessed by conjoining the abstract counterexamples i.e. the violation with the initial set of design constraints and inputting the conjoined set into the solver. More specifically select variable assignments in the assignment are replaced with relationships between variables to form a set of constraints that represent the violation conjoining the set of constraints that represent the violation with the set of design constraints to form a conjoined set and inputting the conjoined into the solver. If the solver outputs another assignment the violation is deemed feasible and reported by the system as an actual design defect. On the other hand if there is no assignment by the solver then the violation is deemed in feasible. In this case the abstraction model can be refined using the violation. Broader aspects of this disclosure contemplate other techniques for checking feasibility of a counterexample.

From a violation one or more lemmas are created and stored in a database where a lemma is created by negating the set of constraints that represent the violation. The lemmas are in turn stored in a database for subsequent iterations. The database of lemmas a allows the flexibility of aggregating one or more lemmas in each refinement iteration b allows the user to supply lemmas before the verification begins for the design at hand and c allows reusing lemmas across verification sessions invoked on different versions of the same design or different designs of the same family of designs .

The architecture may employ other techniques for refining the abstraction model as discussed above. For example select abstracted logical operators in the abstraction model may be unabstracted and then used to form the refined abstraction model. The steps of property checking and feasibility checking are then repeated using the refined model.

An exemplary implementation of the automated verification system is further described and may be referred to herein as the Reveal verification tool. The automated verification system is comprised of various components. The Hardware Relations library is a stand alone package that is used to manipulate word level expressions. The Reveal system uses it as its platform for communicating Verilog expressions as well as abstract lemmas. The Formula Generator described is the system s front end module. It is used to generate conc X . The Solver Module is Reveal s back end module for solving SMT formulas. The MUS Extractor is another back end module responsible for extracting infeasibility explanations from SMT formulas. The CEGAR Core orchestrates the entire process as described previously. Each of these components are further described below.

Hardware Relations module allows the Reveal system to efficiently store and manipulate word level expressions throughout the entire flow as well as to be extensible and applicable to other uses such as the verification of software. To achieve that it has to trade off three requirements simultaneously 

In order to be extensible yet support all of the system functionality the library supports three main functions 

The Solver module is responsible for determining the satisfiability or validity of FOL formulas. It interfaces with the YICES SMT solver via a C API. This module can determine for example whether a formula is valid in the EUF or CLU logics or satisfiable in the bit vector BV logic. This module makes use of the generic annotation mechanism in order to allow the CEGAR Core as well as the designer to control the way each expression is modeled in YICES. In particular each non leaf expression e op e . . . e is seen as a combinational component with output e inputs e . . . e and function op. In turn annotation is used to indicate to YICES how to model each component 

The MUS Extractor module is responsible for identifying MUSes from an unsatisfiable formula. The current implementation uses a modified version of the CAMUS MUS extraction algorithm that works directly with the YICES solver. This eliminates the need to generate a propositional encoding of the abstract formula and leads to significant speedup in MUS generation. It also reduces the number of all possible MUSes in the given conjunction since including or excluding constraints in the MUS is now done at a coarser granularity allowing CAMUS to scale better. It is worth mentioning that given an unsatisfiable formula CAMUS can be run in three modes single multiple or all MUS extraction where the last option is used in most of our experiments.

The CEGAR Core component is responsible for coordinating the abstraction solving MUS extraction and refinement processes. It also maintains the persistent lemma database that is accessed across invocations. In each iteration it modifies the lemma database and updates the abstraction for the next iteration. This module is also responsible for integrating user supplied lemmas into the database.

The foregoing description of the embodiments has been provided for purposes of illustration and description. It is not intended to be exhaustive or to limit the disclosure. Individual elements or features of a particular embodiment are generally not limited to that particular embodiment but where applicable are interchangeable and can be used in a selected embodiment even if not specifically shown or described. The same may also be varied in many ways. Such variations are not to be regarded as a departure from the disclosure and all such modifications are intended to be included within the scope of the disclosure. Example embodiments are provided so that this disclosure will be thorough and will fully convey the scope to those who are skilled in the art. Numerous specific details are set forth such as examples of specific components devices and methods to provide a thorough understanding of embodiments of the present disclosure. It will be apparent to those skilled in the art that specific details need not be employed that example embodiments may be embodied in many different forms and that neither should be construed to limit the scope of the disclosure. In some example embodiments well known processes well known device structures and well known technologies are not described in detail.

The terminology used herein is for the purpose of describing particular example embodiments only and is not intended to be limiting. As used herein the singular forms a an and the may be intended to include the plural forms as well unless the context clearly indicates otherwise. The terms comprises comprising including and having are inclusive and therefore specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof. The method steps processes and operations described herein are not to be construed as necessarily requiring their performance in the particular order discussed or illustrated unless specifically identified as an order of performance. It is also to be understood that additional or alternative steps may be employed.

