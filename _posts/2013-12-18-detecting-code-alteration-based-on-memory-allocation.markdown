---

title: Detecting code alteration based on memory allocation
abstract: Techniques are described for identifying potential code injection attacks against a process by analyzing the memory allocation for the process. Memory allocation data may be collected on one or more host computing devices, the memory allocation data describing the amount of memory allocated for a process or utilized by a process during its execution. The collected memory allocation data may be analyzed to identify instances of anomalous memory allocation during process execution. Statistical or machine learning algorithms may be employed to identify anomalous memory allocation based on the analysis of aggregated memory allocation data for the process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09348742&OS=09348742&RS=09348742
owner: AMAZON TECHNOLOGIES, INC.
number: 09348742
owner_city: Reno
owner_country: US
publication_date: 20131218
---
To support their operations providers of online services or other computing services may deploy a large number of executable code modules and libraries within a computing environment. Such large deployments may enable an organization to maintain quality of service under a variety of operating conditions. However a complex deployment of a large number of files may create challenges when ensuring the security and integrity of the deployed files.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

This disclosure describes implementations of systems devices methods and computer readable media for identifying potential security risks based on detecting an anomalous memory allocation during one or more executions of a process. Code injection is a technique that may be employed by malware attacker remote access tools or other types of attacks to establish command and control of a system. In such attacks executable code may be injected into or otherwise incorporated into an existing process on a target computing system. When the existing process executes the process may allocate additional memory e.g. active physical or runtime memory and copy the injected binary executable code into the newly allocated memory. The injected code may then be executed e.g. as a new thread to provide unauthorized access to the computing system read copy or alter files or registry entries perform cryptographic operations or perform other unauthorized operations on the computing system. The injected code may exhibit high volatility and may leave minimal or no detectable artifacts such as files or registry entries. However the process that is the target of the attack may have additional memory allocated in the process memory space to hold the injected code.

As described herein a potential security risk such as a potential code injection may include scenarios in which there is at least a likelihood that a security risk is present. Accordingly a potential security risk includes an actual security risk such as a scenario in which malicious code has been injected into a process or a scenario in which the process has been otherwise altered to perform unauthorized operations on a host computing device. On determining that a potential security risk is present with regard to a process implementations may flag the process as suspicious and provide information enabling further investigation of the process to determine whether the potential security risk is an actual security risk e.g. whether the anomalous memory allocation is evidence of an actual code injection that may compromise security of the host computing device.

Implementations detect potential code injections or other types of potential security risks by analyzing the memory allocation for a process executing on one or more host computing devices. In some implementations memory usage or allocation metrics are collected for one or more processes executing on a plurality of host computing systems. Such metrics may be incorporated into performance data which is sent to one or more analysis server devices for analysis. Based on the performance data collected from a plurality of host computing devices a baseline for memory usage may be established. The establishment of the baseline memory allocation may employ a statistical distribution to establish a typical or normal memory allocation for a process while it is executing. The establishment of the baseline memory allocation may also employ supervised or unsupervised machine learning techniques such as clustering or classification. Once a baseline memory allocation is established the performance data collected for executing processes may be compared to the baseline. A process that exhibits an anomalous memory allocation compared to the baseline may be designated as a potential security risk and flagged for further analysis to determine whether malicious code has been injected into the process.

One or more processes may be installed or otherwise presented in memory on the host computing device s . The process es may include any type of process that is executable on the host computing device s . The process es may include any number of code modules e.g. software modules in the form of files or components arranged according to any format. The process es may include execution instances of programs as compiled binary machine executable files or libraries. The process es may also include execution instances of scripts batch files or programs that are executable within a runtime a virtual machine or an execution engine. A process may include any number of software modules as executable programs libraries resources application programming interfaces APIs and so forth. In some cases the process es for which memory allocation is to be analyzed may be installed on a plurality of the host computing devices . Such process es may include frequently executed processes such as processes that execute as part of an operating system or processes that support widely deployed computing services. Moreover in some cases the process es to be analyzed may include processes that have privileged access to systems on the host computing device s . The frequent execution and privileged access of the process es may make them attractive targets for malicious code injection or other types of attacks.

The host computing device s may execute one or more data collection modules which operate to collect performance data on the host computing device s . The data collection module s may collect the performance data while the process es are executing such that the performance data describes a state environment or configuration of the host computing device s during execution of the process es . In some cases the data collection module s may execute periodically e.g. one or twice a day to collect the performance data . Alternatively the data collection module s may execute substantially continuously to collect the performance data .

The memory allocation data may include a process identifier that identifies the process . The process identifier may include one or more of a process name of the process . The process identifier may also include a description of a version of the process such as a version number build number date time stamp of the binary executable file for the process and so forth. In some cases the process identifier may be a Globally Unique Identifier GUID that identifies the process . The memory allocation data may also include a host computing device identifier that identifies the host computing device on which the process is executing or has executed. The host computing device identifier may include one or more of a host name or a network address such as an Internet Protocol IP address of the host computing device .

The memory allocation data may include an allocated memory describing the amount of memory allocated for the process . The allocated memory may describe the amount of memory using any unit of measure such as a number of kilobytes megabytes and so forth. In some implementations the memory allocation data may include date time information describing one or both of a date or a time when the allocated memory was determined for the process . The memory allocation data may also include an executable location or path describing a location of or path to the binary executable of the process in the file system of the host computing device .

The performance data may also include environment data that describes the operating state configuration or environment of the host computing device identified by the host computing device identifier . The environment data may include a description of processes executing on the host computing device such as a list of some or all of the processes e.g. other than the process being analyzed executing at the date and time indicated by the date time information . The environment data may include registry setting s listing some or all of the keys values or other settings present in the registry of the host computing device at the date and time indicated by the date time information . In some implementations the environment data may include an identification of the operating system installed on the host computing device including a name description version number build number or other information regarding the operating system present on the host computing device at the date and time indicated by the date time information .

In some cases the environment data may include a description of files present on the host computing device listing some or all of the files installed or otherwise present on the host computing device at the date and time indicated by the date time information . In some implementations the description of files present on the host computing device may be a hash of the files installed on the host computing device . The environment data may include a description of hardware components included in the host computing device listing some or all of the hardware components incorporated into the host computing device or connected to the host computing device e.g. as peripheral or external devices . The environment data may include a total memory allocation for the host computing device describing a total amount of memory allocated for all executing processes on the host computing device or a total amount of memory available for executing processes or data storage on the host computing device .

The environment data may include a description of shared libraries or objects loaded in memory such as a description of dynamic link libraries DLLs or other types of shared libraries or shared objects that are loaded in memory on the host computing device during the execution of the process . The environment data may also include a description of network connection s on the host computing device including a list of network connections open from the host computing device to other devices during the execution of the process . The environment data may also include other environment data such as the amount of time the host computing device has been operating e.g. up time central processing unit CPU load on the host computing device and so forth. The performance data may be described as a vector of data the vector including any number of data elements or dimensions such as the various data elements included in the memory allocation data and the environment data .

Returning to the performance data may be communicated directly or indirectly from the data collection module s to one or more storage device s that may store the performance data . The stored performance data may describe the performance of any number of execution instances of any number of processes executing on any number of host computing devices . The storage device s may be in communication or otherwise accessible from one or more analysis server device s . The storage device s may comprise any type of data storage system or datastore such as a relational or a non relational datastore. Implementations support any type or format of data storage for the storage device s including but not limited to a database an array a structured list a tree a key value storage flat files unstructured data or any other data structure or format. Although the storage device s are depicted as external to the host computing device s and the analysis server device s in some implementations the storage device s may be at least partly incorporated into the host computing device s the analysis server device s or both the host computing device s and the analysis server device s .

The analysis server device s may be any type of computing device including but not limited to those types of computing devices described with reference to the host computing device s . In some cases two or more of the analysis server devices may comprise a cluster cloud farm or other grouping of multiple devices that coordinate operations to provide load balancing failover support parallel processing capabilities shared storage resources or other aspects. The analysis server device s are described further with reference to .

The analysis server device s may execute an analysis module which performs operations to retrieve the performance data from the storage device s and analyze the performance data collected on one or more host computing devices . Operations of the analysis module are described further with reference to . In some implementations the analysis module may include a machine learning module configured to perform one or more machine learning algorithms or techniques to analyze the performance data . Such machine learning may include unsupervised machine learning such as clustering as described further with reference to . The machine learning may also include supervised machine learning such as the training of a classifier as described further with reference to . Although clustering and classification are provided as examples of machine learning techniques that may be employed implementations are not limited to these examples. Implementations support machine learning algorithms that may include but are not limited to one or more of the following artificial neural networks inductive logic programming support vector machines SVMs clustering classification Bayesian networks decision tree learning association rule learning reinforcement learning representation learning similarity learning metric learning sparse dictionary learning and so forth.

The analysis module may analyze the performance data and identify zero or more execution instances of the process es for which the memory allocation is atypical or otherwise anomalous. Such execution instances may be described in anomaly information . The anomaly information may be sent to an alert module executing on the analysis server device s . The alert module may generate and send one or more alerts describing the execution instances of the process es for which the memory allocation is anomalous as described in the anomaly information . The alert s may be sent to one or more users such as system administrators developers security analysts and so forth. The alert s may also be sent to any number of other computing devices or processes. The alert s may enable users devices or processes to further investigate the execution instances that exhibit anomalous memory allocation to determine whether such instances indicate that a process has been the target of a code injection attack or has been otherwise compromised. In some cases the alert module may also perform one or more automatic interdiction actions to mitigate the risk due to the potentially compromised process . Automatic interdiction actions may include isolating the host computing device where the process executed terminating the process on one or more host computing devices preventing the process from launching on one or more host computing devices limiting the communications performed by the process on one or more host computing devices or otherwise limiting the execution or functionality of the process . Such interdiction actions are described further with reference to .

The various devices of the environment may communicate with one another using one or more networks. Such networks may include public networks such as the Internet private networks such as an institutional or personal intranet or some combination of private and public networks. The networks may include any type of wired or wireless network including but not limited to local area networks LANs wide area networks WANs wireless WANs WWANs wireless LANs WLANs mobile communications networks e.g. 3G 4G etc. and so forth. In some implementations communications between the various devices in the environment may be encrypted or otherwise secured. For example such communications may employ one or more public or private cryptographic keys ciphers digital certificates or other credentials supported by a security protocol such as any version of the Secure Sockets Layer SSL or the Transport Layer Security TLS protocol.

In cases where the performance data may include data associated with one or more end users interacting with the process es executing on the host computing devices implementations may ensure the privacy of user data by requesting the permission of users to collect and analyze the user data. In some cases such requests for permission may function as an opt in such that the user data may not be collected or analyzed without the associated user s explicit permission. Alternatively the requests for permission may function as an opt out such that the user data may be collected and analyzed unless the associated user explicitly requests that such activities not be performed. In either case security measures may be employed on the host computing device s or the analysis server device s to ensure the confidentiality of the performance data .

In some cases the clusters may include a first set of one or more clusters that include instances of the performance data that are substantially similar to one another in that they describe a substantially typical normal or average memory allocation for the process . In some cases the clusters may include multiple clusters that describe substantially typical normal average or otherwise non suspicious memory allocations for the process executing in a plurality of different environments or under a variety of conditions that are not indicative of an anomalous execution. Instances of performance data that are substantially separate from the clusters e.g. separate in the performance data vector space may be designated as anomalous execution instance s . In the example of the instance of performance data is outside the one or more clusters that correspond to substantially typical performance data . Accordingly the performance data may be designated as an anomaly for further analysis.

In some cases the cluster data may also include a one or more clusters that include instances of the performance data that describe a substantially atypical abnormal or otherwise anomalous memory allocation for one or more execution instances of the process . Accordingly the instances included in the cluster s may exhibit a memory allocation that differs from the instances included in the cluster s . The instances for which the performance data is included in the cluster s may be designated as anomalous execution instances and included in the anomaly information for further analysis.

Implementations support the identification of anomalous execution instance s that may include one or more individual instances of the performance data as outlier s from the cluster s such as the performance data shown in . Implementations also support the identification of clusters of anomalous execution instance s . Such cluster s may include multiple instances of the performance data in cases where multiple instances of the executing process may have been similarly compromised through code injection or otherwise. In cases where there are infrequent occurrences of code injections or other types of security compromises of the process es implementations may identify one or more anomalous execution instance s that each manifests as a singular outlier relative to the cluster s . In some cases outlier s may be identified as those instance s of the performance data that are at least a threshold distance from the nearest cluster . The distance measurement may be relative to a variance a deviation a width or some other measure of the size of the cluster s . For example the performance data may be designated as an anomalous execution instance based on a determination that the performance data is at a distance from the centroid of the nearest cluster where the distance is at least six times the size of the smallest cluster . In cases where the vector space of the performance data is an N dimensional space the distances may be distances within the N dimensional space.

In cases where code injections are more frequent or at least somewhat systemic implementations may identify cluster s of anomalous execution instances . In some cases the cluster s e.g. of anomalous performance data may include a smaller number of instances of the performance data than are included in the cluster s e.g. of normal performance data . In such cases a determination may be made of the proportion of the number of instances of the performance data in the cluster s compared to the number of instances of the performance data in the cluster s or compared to a total number of instances of the performance data . If the proportion is below a predetermined threshold proportion the cluster s may be designated as anomalous execution instance s . For example if a cluster includes less than 10 of the instances of performance data as one or more other clusters or less than 1 of the total number of instances of performance data the smaller population e.g. low density cluster may be designated as including anomalous or atypical performance data .

In some cases the cluster s may include multiple clusters that each corresponds to a particular configuration of the host computing device s on which the process es are executing. For example the cluster s may include multiple clusters that each corresponds to an operating system or an operating system version that is running on the host computing device s or that each corresponds to a particular hardware configuration e.g. processor speed storage capacity networking capability etc. of the host computing device s . In such cases the multiple clusters may correspond to configuration variations within a normal or typical operating environment for the process es .

In some implementations the unsupervised machine learning module may employ an initial number of centroids that each corresponds to a point within the multi dimensional vector space of the performance data . The unsupervised machine learning algorithm employed by the unsupervised machine learning module may then begin building a cluster around each of the centroids by determining which instances of the performance data are within a distance of the centroid in the vector space. In some implementations the number of centroids employed may correspond to a number of different hardware and or software configurations among the host computing devices . For example the number of centroids may correspond to a number of different operating systems or different versions of an operating system that are installed and executing on the host computing devices .

In some cases if the number of centroids employed by the unsupervised machine learning algorithm is too small e.g. less than an optimal number of clusters for describing normal or typical performance data any anomalous execution instance s may be subsumed in the cluster s and mischaracterized as typical or normal performance data . Accordingly in some implementations the unsupervised machine learning algorithm may iterate to determine cluster s based on different numbers or positions of centroids. An optimal configuration e.g. an optimal number and position of centroids may be determined as the number and position of centroids that produces cluster s including the largest number of instances of the performance data among the different analyzed configurations of centroids. Alternatively an optimal configuration of centroids may be determined as the number and position of centroids that produces cluster s that include at least a predetermined threshold proportion of the instances of the performance data that are included in the cluster s e.g. at least 95 . In such cases the number or proportion of instances of the performance data that are included in the cluster s may be employed as a metric to measure a quality of the clustering based on a particular configuration of centroids.

The initial number of centroids employed may be based on variations in configurations of the host computing device s such as variations of operating system operating system version or revision or hardware configuration. The unsupervised machine learning algorithm may then vary the position of the centroid s the number of the centroid s or both the position and number of centroid s until the algorithm determines a configuration of centroid s which results in an optimal e.g. maximal or above threshold number of instances of performance data in the cluster s . Accordingly the unsupervised machine learning algorithm may receive input parameters that include an initial number of centroids and a cluster width. The cluster width may indicate a maximum distance from an instance of the performance data to the centroid for which the instance of the performance data may be designated ask being within the cluster . The input parameters may also include the threshold distance e.g. six times the cluster width beyond which an instance of performance data may be designated as an outlier e.g. an anomalous execution instance .

In some implementations the classifier may operate as a binary classifier that classifies each set of incoming performance data as either anomalous or not anomalous e.g. either typical or atypical . Alternatively the classifier may classify each set of incoming performance data into one of any number of categories or classes e.g. the classifier may operate as an N class classifier where N is greater than 1. For example the classifier may classify performance data into three classes such as a high risk class a medium risk class or a low risk class describing the level of risk that the process has been subjected to code injection or otherwise compromised. The classes may be subjectively described e.g. high medium or low or described according to a scale or continuum of classes e.g. a scale of 0 to 10 describing a risk level . As another example the classes may be described as low risk e.g. reflecting typical or normal performance high risk e.g. indicating that a code injection is likely to have occurred or medium risk e.g. indicating a lower but still substantial possibility that a code injection has occurred . In some cases the classifier may classify the performance data into multiple classes that each indicates a different type of code injection that was made using a particular tool set attack technique or malware. For example different classes may indicate code injections made to different targeted processes or made to load different types of malicious code.

In some implementations the performance data may be employed as training data to train the classifier . In some cases additional training data may be employed to train the classifier . Such additional training data may be generated based on operations of the unsupervised machine learning module such as the results of the clustering algorithm described with reference to . For example the instances of performance data placed into the cluster s e.g. indicating normal or typical performance data may be employed as true negatives e.g. instances of performance data that describe normal or typical behavior of the process es . The instances of the performance data placed into the cluster s or otherwise designated as anomalous execution instances may be employed as true positives e.g. instances of performance data that describe anomalous behavior of the process es . The true negative and true positive instances may then be employed as training data to train the classifier .

In some cases manual code injections may be made to a process to create a modified version of the process . The modified version of the process may then be executed and additional performance data may be collected during execution of the modified version. The collected additional performance data may then be employed as additional training data to train the classifier . In some cases one or more instances of the performance data may be manually altered to synthesize additional training data. In some cases training data may be created by altering operating conditions on one or more of the host computing devices . For example processor load networking load storage capacity e.g. used or available storage or other operating conditions may be adjusted on a host computing device while a process is executing and the performance data may be collected during such conditions. The collected performance data may then be employed as training data that exhibits typical or normal performance of the process . In cases where the classifier classifies into multiple classes that are associated with different attack tool sets attack techniques or attack malware training data may be generated manually by employing the particular tool sets techniques or malware against the process es in a test environment.

In some implementations the classifier to be trained may be a two class e.g. binary classifier and the initial training of the classifier may employ training data associated with one class such as the performance data for typical performance of the process es . Such training may generate a classifier that identifies a boundary between typical and atypical performance data where the boundary is a line or N dimensional plane in the performance data vector space separating typical and atypical performance data . The classifier may then begin classifying incoming performance data based on the boundary. The results of the initial classification may be analyzed e.g. manually and instances of the performance data that were accurately classified as atypical or typical may be employed as additional training data to further train the classifier .

The host computing device may include one or more input output I O devices . The I O device s may include input devices such as a keyboard a mouse a pen a game controller a touch input device an audio input device e.g. a microphone a gestural input device a haptic input device an image or video capture device e.g. a camera or other devices. In some cases the I O device s may also include output devices such as a display an audio output device e.g. a speaker a printer a haptic output device and so forth. The I O device s may be physically incorporated with the host computing device or may be externally placed.

The host computing device may include one or more I O interfaces to enable components or modules of the host computing device to control interface with or otherwise communicate with the I O device s . The I O interface s may enable information to be transferred in or out of the host computing device or between components of the host computing device through serial communication parallel communication or other types of communication. For example the I O interface s may comply with a version of the RS 232 standard for serial ports or with a version of the Institute of Electrical and Electronics Engineers IEEE 1284 standard for parallel ports. As another example the I O interface s may be configured to provide a connection over Universal Serial Bus USB or Ethernet. In some cases the I O interface s may be configured to provide a serial connection that is compliant with a version of the IEEE 1394 standard. The host computing device may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the host computing device .

The host computing device may include one or more network interfaces that enable communications between the host computing device and other network accessible computing devices such as the analysis server device s . The network interface s may include one or more network interface controllers NICs or other types of transceiver devices configured to send and receive communications over a network.

The host computing device may include one or more memories described herein as memory . The memory comprises one or more computer readable storage media CRSM . The CRSM may include one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium a mechanical computer storage medium and so forth. The memory provides storage of computer readable instructions that may describe data structures program modules processes applications or other data for the operation of the host computing device . In some implementations the memory may provide storage of computer readable instructions or other information in a non transitory format.

The memory may include an operating system OS module . The OS module may be configured to manage hardware resources such as the I O device s the I O interface s and the network interface s and to provide various services to applications processes or modules executing on the processor s . The OS module may include one or more of the following any version of the Linux operating system any version of iOS from Apple Corp. of Cupertino Calif. USA any version of Windows or Windows Mobile from Microsoft Corp. of Redmond Wash. USA any version of Android from Google Corp. of Mountain View Calif. USA and its derivatives from various sources any version of Palm OS from Palm Computing Inc. of Sunnyvale Calif. USA and its derivatives from various sources any version of BlackBerry OS from Research In Motion Ltd. of Waterloo Ontario Canada any version of VxWorks from Wind River Systems of Alameda Calif. USA or other operating systems.

The memory may include one or more of the modules described above as executing on the host computing device such as the process es and the data collection module s . The memory may also include one or more other modules such as a user authentication module or an access control module to secure access to the host computing device and so forth.

The memory may include data storage to store data for operations of the host computing device . The data storage may comprise a database array structured list tree or other data structure and may be a relational or a non relational datastore. The data storage may store data such as that described above including one or more of the performance data the memory allocation data or the environment data . The data storage may also store other data such as user authentication information or access control data. In some implementations at least a portion of the information stored in the data storage may be stored externally to the host computing device on other devices that may communicate with the host computing device via the I O interface s or via the network interface s .

The analysis server device may include one or more memories described herein as memory . The memory comprises one or more CRSM as described above with reference to the memory . The memory may include an OS module that is configured to manage hardware resources such as the I O device s the I O interface s and the network interface s and to provide various services to applications processes or modules executing on the processor s . The OS module may include one or more of the operating systems described above with reference to the OS module . The memory may include one or more of the modules described above as executing on the analysis server device such as the analysis module the machine learning module the unsupervised machine learning module the supervised machine learning module the alert module and the classifier . In various implementations the machine learning module may include one or both of the unsupervised machine learning module and the supervised machine learning module . Although the unsupervised machine learning module and the supervised machine learning module are described herein as sub modules sub components or sub processes of the machine learning module and the machine learning module is described herein as a sub module sub component or sub process of the analysis module one or more of these modules may execute independently as a separate module component or process. The memory may also include one or more other modules such as a user authentication module or an access control module to secure access to the analysis server device and so forth.

The memory may include data storage to store data for operations of the analysis server device . The data storage may comprise a database array structured list tree or other data structure and may be a relational or a non relational datastore. The data storage may store data such as that described above including one or more of the performance data the memory allocation data the environment data the anomaly information the alert s or the cluster data . The data storage may also store other data such as user authentication information or access control data. In some implementations at least a portion of the information stored in the data storage may be stored externally to the analysis server device on other devices that may communicate with the analysis server device via the I O interface s or via the network interface s .

At the performance data is received from the host computing device s retrieved from the storage device s or otherwise accessed. As described above the performance data may include any number of sets or vectors of performance data each set or vector collected on a host computing device during the execution of a process . In some cases the performance data may include a plurality of sets or vectors of performance data collected during the execution of the same process on a plurality of host computing devices .

At an analysis of the performance data may be performed. The analysis may employ a machine learning algorithm as described further with reference to . In some cases the analysis may employ a statistical method to identify deviations from a norm or average as described further with reference to .

At based on the analysis of the performance data a determination may be made of at least one anomalous execution instance of the process on at least one of the plurality of host computing devices . The at least one anomalous execution instance may exhibit an anomalous memory allocation that is different from the memory allocation for other execution instances of the process on other host computing devices . The at least one anomalous execution instance may be described in the anomaly information .

At the at least one anomalous execution instance of the process may be designated as a potential security risk based on the anomalous memory allocation determined at . The potential security risk may include a potential injection of malicious or otherwise unauthorized executable code into the process where such code injection may have led to the anomalous memory allocation during execution of the process . In some implementations the potential security risk may be designated based on correlating the at least one anomalous execution instance of the process with one or more elements of the environment data collected during execution of the process as described above.

At one or more alerts may be sent to notify one or more users of the potential security risk evidenced by the anomalous memory allocation. The alert s may include information to enable a manual investigation of the potential security risk by the one or more users. Moreover in some implementations the alert s may be sent to other processes or devices which may perform further operations in response to receiving the alert s . In some cases the alert s may include additional information to enable users processes or devices to investigate the potential security risk such as a stack dump a record of the code mapped to memory information regarding stack allocation a description of open network connections and so forth.

At in some implementations one or more interdiction operations may be automatically performed to mitigate the potential security risk. Such interdiction operations may include but are not limited to one or more of the following 

at least partly restricting communications involving the host computing device s where the anomalous execution instance s of the process were executed e.g. to isolate or quarantine the potentially comprised host computing device s 

at least partly inhibiting e.g. terminating the execution of the process on the host computing device s where the anomalous execution instance s of the process were executed or on other host computing device s 

otherwise limiting the execution or functionality of the process or limiting the operations of the host computing device s or

performing one or more operations e.g. a binary diff to identify differences between a binary executable of the process that exhibited the anomalous memory allocation and a known good e.g. uncompromised version of the binary executable.

Moreover in some implementations the interdiction operation s may include pausing the execution of all processes on the host computing device where the anomalous memory allocation was exhibited. Such pausing may include pausing the executing processes between instructions or between CPU cycles to enable an analysis of the state of the paused system. In such cases the executing processes including the potentially compromised process may not be aware that instruction processing has paused on the host computing device enabling an analysis of the system state to proceed without triggering any potential countermeasures or circumvention measures incorporated into the malicious code. The pausing may be enabled on a host computing device that includes processor s particularly configured to enable the pausing. The pausing may also be available in cases where the host computing device is a hypervisor or virtualization with a configurable software emulation of the processor s .

At the performance data is received or otherwise accessed as described above with reference to . At a range of allocated memory is determined for the process . The range may be a typical or normal range of the amount of memory allocated for the process during its execution. In some cases the range may include the amount of memory allocated during at least a proportion e.g. a majority of the execution instances of the process . For example based on the performance data it may be determined that 90 of the execution instances of a particular process exhibit memory allocation ranging between 100 and 200 kilobytes and this range may be designated as the typical or normal range of memory allocation for the process . In some cases the range may be determined based on the allocated memory included in the performance data for a plurality of execution instances and may be adjusted based on the environment data .

At each set or vector of the performance data may be analyzed to determine whether it describes a memory allocation that is outside the range determined at . Such outliers may be designated as anomalous execution instances of the process and may be incorporated into the anomaly information . As described herein an execution instance for which the memory allocation is higher than the range may indicate that the process has been the target of a code injection or is otherwise compromised. In some cases an execution instance for which the memory allocation is lower than the range may indicate that the process has been replaced with another process e.g. a malicious process that is impersonating the replaced process . In either case the anomalous execution instance may be designated as a security risk for further analysis.

Implementations support the use of any statistical measures or methods to identify anomalous execution instances for the process . In some implementations at anomalous execution instance s may be identified as those execution instances for which the memory allocation is outside a predetermined number of statistical variances or standard deviations e.g. sigmas of the distribution of memory allocation statistics for the process . For example an anomalous execution instance may be identified if it exhibits a memory allocation that is outside two standard deviations from the mean or average of the distribution of memory allocations.

At the performance data is received or otherwise accessed as described above with reference to . At an unsupervised machine learning algorithm may be employed to determine a plurality of clusters of the performance data collected on the plurality of host computing devices as described above with reference to .

At at least one anomalous execution instance of the process may be determined for which the performance data is outside the cluster s that include typical or normal memory allocation for the process as described with reference to . The anomalous execution instance s of the process may be described in the anomaly information . In some cases the determination that a set or vector of performance data is outside the cluster s may be an automatic determination performed by the analysis module or some other process. Alternatively the determination may be based on a manual examination of the cluster data by one or more users.

At the performance data is received or otherwise accessed as described above with reference to . At a supervised machine learning algorithm may be employed to train the classifier using the collected performance data as training data as described above with reference to .

In some implementations manual testing may be employed to generate additional training data to train the classifier . At the executable code of the process may be altered to generate a modified version of the process to be executed on one or more host computing devices . The altering may include injecting code to simulate a malicious code injection attack against the process . At the modified version of the process may be executed on one or more host computing devices . At additional performance data may be collected during the execution of the modified version of the process . The additional performance data may describe the amount of memory allocated for the modified version of the process during its execution. The additional performance data collected at may be employed as additional training data to train the classifier . In this way implementations may enable the generation of positive or negative test cases of known results to be used in further training the classifier .

In some implementations at additional training data may be generated based on the results of an unsupervised machine learning algorithm such as the clustering operations described with reference to . At additional training data may be manually generated based on user identification of true positives e.g. instances where implementations correctly identified an anomalous execution instance false positives e.g. instances where implementations incorrectly identified an anomalous execution instance true negatives e.g. instances where implementations correctly identified a non anomalous execution instance and false negatives e.g. instances where implementations incorrectly identified a non anomalous execution instance . At the additional training data generated at and may be employed to further train the classifier based on the supervised machine learning algorithm.

At the classifier may be employed to analyze subsequently collected and received performance data for an execution instance of the process and to classify the performance data . As described above with reference to in some cases the classifier may perform a binary classification of the performance data into either an anomalous class or a non anomalous class. Alternatively the classifier may classify the performance data into one of any number of classes that describe degrees or gradations of risk that the performance data indicates a security breach e.g. a code injection . The classification of the performance data as anomalous may include incorporating a description of the at least one anomalous execution instance into the anomaly information .

Although the examples herein describe analyzing the memory allocation for the process to identify a potentially malicious code injection into the process implementations may also be employed to identify other types of attacks or security risks based on memory allocation analysis. For example in some cases the memory allocation or utilization for a process may increase if the process is the target of a denial of service DOS attack. Implementations may identify potential DOS attacks based on anomalous memory allocation for the process .

Those having ordinary skill in the art will readily recognize that certain steps or operations illustrated in the figures above may be eliminated combined or performed in an alternate order. Any steps or operations may be performed serially or in parallel. Moreover the methods described above may be implemented as one or more software programs for a computer system and may be encoded in a computer readable storage medium as instructions executable on one or more processors.

Embodiments may be provided as a computer program product including one or more non transitory computer readable storage media having stored thereon instructions in compressed or uncompressed form that may be used to program a computer or other electronic device to perform processes or methods described herein. The computer readable storage media may include one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium and so forth. For example the computer readable storage media may include but are not limited to hard drives floppy diskettes optical disks read only memories ROMs random access memories RAMs erasable programmable ROMs EPROMs electrically erasable programmable ROMs EEPROMs flash memory magnetic or optical cards solid state memory devices or other types of physical media suitable for storing electronic instructions. Further embodiments may also be provided as a computer program product including a transitory machine readable signal in compressed or uncompressed form . Examples of machine readable signals whether modulated using a carrier or unmodulated include but are not limited to signals that a computer system or machine hosting or running a computer program may be configured to access including signals transferred by one or more networks. For example a transitory machine readable signal may comprise transmission of software by the Internet.

Separate instances of these programs can be executed on or distributed across any number of separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art readily recognize that the techniques described above can be utilized in a variety of devices environments and situations. Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art. It is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

