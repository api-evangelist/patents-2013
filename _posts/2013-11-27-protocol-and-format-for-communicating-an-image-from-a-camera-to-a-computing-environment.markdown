---

title: Protocol and format for communicating an image from a camera to a computing environment
abstract: A media feed interface may be provided that may be used to extract a media frame from a media feed. The media feed interface may access a capture device, a file, and/or a network resource. Upon accessing the capture device, file, and/or network resource, the media feed interface may populate buffers with data and then may create a media feed from the buffers. Upon request, the media feed interface may isolate a media frame within the media feed. For example, the media feed interface analyze media frames in the media feed to determine whether a media frame includes information associated with, for example, the request. If the media frame includes the requested information, the media feed interface may isolate the media frame associated with the information and may provide access to the isolated media frame.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09215478&OS=09215478&RS=09215478
owner: Microsoft Technology Licensing, LLC
number: 09215478
owner_city: Redmond
owner_country: US
publication_date: 20131127
---
This application is a divisional application of U.S. patent application Ser. No. 12 485 741 filed Jun. 16 2009 which claims the benefit of U.S. Provisional Patent Application No. 61 182 491 filed May 29 2009. U.S. patent application Ser. No. 12 485 741 is incorporated by reference herein in its entirety. U.S. provisional patent application No. 61 182 491 is incorporated by reference herein in its entirety.

Many computing applications such as computer games multimedia applications or the like use controls to allow users to manipulate game characters or other aspects of an application. Typically such controls are input using for example controllers remotes keyboards mice or the like. Unfortunately such controls can be difficult to learn thus creating a barrier between a user and such games and applications. Furthermore such controls may be different than actual game actions or other application actions for which the controls are used. For example a game control that causes a game character to swing a baseball bat may not correspond to an actual motion of swinging the baseball bat.

Disclosed herein are systems and methods for providing a media feed interface that may be used to extract a media frame from a media feed. For example a capture device a file and or a network resource may be accessed by the media feed interface. Upon accessing the capture device file and or network resource the media feed interface may receive a media feed. When the media feed interface receives a request to retrieve a media frame from for example an application the media feed interface may isolate a media frame within the media feed. In one embodiment the media frame interface may receive a request to retrieve a media frame that may include data associated with a model such as a skeletal model a mesh human model or the like that may be associated with a human target. The media feed interface may analyze one or more media frames to determine whether the media frame includes data associated with the model. The media feed interface may then isolate one or more media frames that include the data associated with the model. The data associated with the model may then be provided to the application such that the application may process the data associated with the one or more isolated media frames.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

As shown in the target recognition analysis and tracking system may include a computing environment . The computing environment may be a computer a gaming system or console or the like. According to an example embodiment the computing environment may include hardware components and or software components such that the computing environment may be used to execute applications such as gaming applications non gaming applications or the like. In one embodiment the computing environment may include a processor such as a standardized processor a specialized processor a microprocessor or the like that may execute instructions including for example instructions for accessing a capture device receiving depth images from the captured device creating a media feed associated with information of the depth images analyzing the media feed to determine whether one or more media frames includes information such as information or data corresponding to a model associated with for example a human target in the depth images isolating a media frame within the media feed that includes the information or any other suitable instruction which will be described in more detail below.

As shown in the target recognition analysis and tracking system may further include a capture device . The capture device may be for example a camera that may be used to visually monitor one or more users such as the user such that gestures performed by the one or more users may be captured analyzed and tracked to perform one or more controls or actions within an application as will be described in more detail below.

According to one embodiment the target recognition analysis and tracking system may be connected to an audiovisual device such as a television a monitor a high definition television HDTV or the like that may provide game or application visuals and or audio to a user such as the user . For example the computing environment may include a video adapter such as a graphics card and or an audio adapter such as a sound card that may provide audiovisual signals associated with the game application non game application or the like. The audiovisual device may receive the audiovisual signals from the computing environment and may then output the game or application visuals and or audio associated with the audiovisual signals to the user . According to one embodiment the audiovisual device may be connected to the computing environment via for example an S Video cable a coaxial cable an HDMI cable a DVI cable a VGA cable or the like.

As shown in the target recognition analysis and tracking system may be used to recognize analyze and or track a human target such as the user . For example the user may be tracked using the capture device such that the movements of user may be interpreted as controls that may be used to affect the application being executed by computing environment . Thus according to one embodiment the user may move his or her body to control the application.

As shown in in an example embodiment the application executing on the computing environment may be a boxing game that the user may be playing. For example the computing environment may use the audiovisual device to provide a visual representation of a boxing opponent to the user . The computing environment may also use the audiovisual device to provide a visual representation of a player avatar that the user may control with his or her movements. For example as shown in the user may throw a punch in physical space to cause the player avatar to throw a punch in game space. Thus according to an example embodiment the computing environment and the capture device of the target recognition analysis and tracking system may be used to recognize and analyze the punch of the user in physical space such that the punch may be interpreted as a game control of the player avatar in game space.

Other movements by the user may also be interpreted as other controls or actions such as controls to bob weave shuffle block jab or throw a variety of different power punches. Furthermore some movements may be interpreted as controls that may correspond to actions other than controlling the player avatar . For example the player may use movements to end pause or save a game select a level view high scores communicate with a friend etc. Additionally a full range of motion of the user may be available used and analyzed in any suitable manner to interact with an application.

In example embodiments the human target such as the user may have an object. In such embodiments the user of an electronic game may be holding the object such that the motions of the player and the object may be used to adjust and or control parameters of the game. For example the motion of a player holding a racket may be tracked and utilized for controlling an on screen racket in an electronic sports game. In another example embodiment the motion of a player holding an object may be tracked and utilized for controlling an on screen weapon in an electronic combat game.

According to other example embodiments the target recognition analysis and tracking system may further be used to interpret target movements as operating system and or application controls that are outside the realm of games. For example virtually any controllable aspect of an operating system and or application may be controlled by movements of the target such as the user .

As shown in the capture device may include an image camera component . According to an example embodiment the image camera component may be a depth camera that may capture the depth image of a scene. The depth image may include a two dimensional 2 D pixel area of the captured scene where each pixel in the 2 D pixel area may represent a depth value such as a length or distance in for example centimeters millimeters or the like of an object in the captured scene from the camera.

As shown in according to an example embodiment the image camera component may include an IR light component a three dimensional 3 D camera and an RGB camera that may be used to capture the depth image of a scene. For example in time of flight analysis the IR light component of the capture device may emit an infrared light onto the scene and may then use sensors not shown to detect the backscattered light from the surface of one or more targets and objects in the scene using for example the 3 D camera and or the RGB camera . In some embodiments pulsed infrared light may be used such that the time between an outgoing light pulse and a corresponding incoming light pulse may be measured and used to determine a physical distance from the capture device to a particular location on the targets or objects in the scene. Additionally in other example embodiments the phase of the outgoing light wave may be compared to the phase of the incoming light wave to determine a phase shift. The phase shift may then be used to determine a physical distance from the capture device to a particular location on the targets or objects.

According to another example embodiment time of flight analysis may be used to indirectly determine a physical distance from the capture device to a particular location on the targets or objects by analyzing the intensity of the reflected beam of light over time via various techniques including for example shuttered light pulse imaging.

In another example embodiment the capture device may use a structured light to capture depth information. In such an analysis patterned light i.e. light displayed as a known pattern such as grid pattern or a stripe pattern may be projected onto the scene via for example the IR light component . Upon striking the surface of one or more targets or objects in the scene the pattern may become deformed in response. Such a deformation of the pattern may be captured by for example the 3 D camera and or the RGB camera and may then be analyzed to determine a physical distance from the capture device to a particular location on the targets or objects.

According to another embodiment the capture device may include two or more physically separated cameras that may view a scene from different angles to obtain visual stereo data that may be resolved to generate depth information.

The capture device may further include a microphone . The microphone may include a transducer or sensor that may receive and convert sound into an electrical signal. According to one embodiment the microphone may be used to reduce feedback between the capture device and the computing environment in the target recognition analysis and tracking system . Additionally the microphone may be used to receive audio signals that may also be provided by the user to control applications such as game applications non game applications or the like that may be executed by the computing environment .

In an example embodiment the capture device may further include a processor that may be in operative communication with the image camera component . The processor may include a standardized processor a specialized processor a microprocessor or the like that may execute instructions including for example instructions for accessing a capture device receiving depth images from the captured device creating a media feed associated with information of the depth images analyzing the media feed to determine whether one or more media frames includes information such as information or data corresponding to a model associated with for example a human target in the depth images isolating a media frame within the media feed that includes the information or any other suitable instruction which will be described in more detail below.

The capture device may further include a memory component that may store the instructions that may be executed by the processor images or frames of images captured by the 3 D camera or RGB camera or any other suitable information images or the like. According to an example embodiment the memory component may include random access memory RAM read only memory ROM cache Flash memory a hard disk or any other suitable storage component. As shown in in one embodiment the memory component may be a separate component in communication with the image camera component and the processor . According to another embodiment the memory component may be integrated into the processor and or the image camera component .

As shown in the capture device may be in communication with the computing environment via a communication link . The communication link may be a wired connection including for example a USB connection a Firewire connection an Ethernet cable connection or the like and or a wireless connection such as a wireless 802.11b g a or n connection. According to one embodiment the computing environment may provide a clock to the capture device that may be used to determine when to capture for example a scene via the communication link .

Additionally the capture device may provide and or capture data such as depth images RGB images IR images and or any other information or data captured by for example the 3 D camera and or the RGB camera to the computing environment . Additionally the capture device may provide for example a model such as a skeletal model a mesh model or the like that may be generated by the capture device to the computing environment . In an example embodiment the capture device may create a media feed within the capture device using the captured data and or the model. For example the capture device may populate buffers with the captured data and or the model and may then create a media feed from the buffers.

According to an example embodiment the capture device may provide the captured data the generated model and or the media feed to the computing environment via the communication link . For example as shown in the computing environment may include the media frame interface . The media frame interface may provide communication between for example the capture device and components of the computing environment such as application programs a gesture library and an operating system that may be executed by the computing environment . The capture device may provide a media feed that may be created thereby to the media feed interface using communication link .

According to another embodiment the media feed interface may access the capture device to retrieve the captured data and or model and create a media frame. For example as described above the capture device may provide captured data and or a model to the media feed interface via the communication link . The media feed interface may populate buffers with the captured data and or model received from the capture device and may create a media feed from the buffers.

The media frame interface may provide data such as a media frame associated with the media feed to for example the applications programs the gesture library and or the operating system . For example the media feed interface may receive a request from for example one of the application programs the gesture library and or the operating system . When the media feed interface receives the request the media feed interface may receive the media feed and may isolate a media frame within the media feed. As described above the media feed interface may then analyze the media frame determine whether the media frame includes a model of a human target or the like which will be described in more detail below. Additionally the media feed interface may retrieve a model associated with the media frame from the media feed.

In one embodiment the application programs the gesture library and or the operating system may use the isolated media frame to for example control an application such as a game or word processor. For example as shown in the computing environment may include the gesture library . The gesture library may include a collection of gesture filters each comprising information concerning a gesture that may be performed by the model as the user moves . The media feed including each of the media frames may include data captured and or generated by the camera the RGB camera and the capture device including the model and movements associated with the model. According to an example embodiment the model in the media feed may be compared to the gesture filters in the gesture library to identify when a user as represented by the model has performed one or more gestures. Those gestures may be associated with various controls of an application. Thus the computing environment may use the gesture library to interpret movements of the model and to control an application based on the movements based on a media feed that includes data captured and or generated by for example the capture device .

A graphics processing unit GPU and a video encoder video codec coder decoder form a video processing pipeline for high speed and high resolution graphics processing. Data is carried from the graphics processing unit to the video encoder video codec via a bus. The video processing pipeline outputs data to an A V audio video port for transmission to a television or other display. A memory controller is connected to the GPU to facilitate processor access to various types of memory such as but not limited to a RAM Random Access Memory .

The multimedia console includes an I O controller a system management controller an audio processing unit a network interface a first USB host controller a second USB controller and a front panel I O subassembly that are preferably implemented on a module . The USB controllers and serve as hosts for peripheral controllers a wireless adapter and an external memory device e.g. flash memory external CD DVD ROM drive removable media etc. . The network interface and or wireless adapter provide access to a network e.g. the Internet home network etc. and may be any of a wide variety of various wired or wireless adapter components including an Ethernet card a modem a Bluetooth module a cable modem and the like.

System memory is provided to store application data that is loaded during the boot process. A media drive is provided and may comprise a DVD CD drive hard drive or other removable media drive etc. The media drive may be internal or external to the multimedia console . Application data may be accessed via the media drive for execution playback etc. by the multimedia console . The media drive is connected to the I O controller via a bus such as a Serial ATA bus or other high speed connection e.g. IEEE 1394 .

The system management controller provides a variety of service functions related to assuring availability of the multimedia console . The audio processing unit and an audio codec form a corresponding audio processing pipeline with high fidelity and stereo processing. Audio data is carried between the audio processing unit and the audio codec via a communication link. The audio processing pipeline outputs data to the A V port for reproduction by an external audio player or device having audio capabilities.

The front panel I O subassembly supports the functionality of the power button and the eject button as well as any LEDs light emitting diodes or other indicators exposed on the outer surface of the multimedia console . A system power supply module provides power to the components of the multimedia console . A fan cools the circuitry within the multimedia console .

The CPU GPU memory controller and various other components within the multimedia console are interconnected via one or more buses including serial and parallel buses a memory bus a peripheral bus and a processor or local bus using any of a variety of bus architectures. By way of example such architectures can include a Peripheral Component Interconnects PCI bus PCI Express bus etc.

When the multimedia console is powered ON application data may be loaded from the system memory into memory and or caches and executed on the CPU . The application may present a graphical user interface that provides a consistent user experience when navigating to different media types available on the multimedia console . In operation applications and or other media included within the media drive may be launched or played from the media drive to provide additional functionalities to the multimedia console .

The multimedia console may be operated as a standalone system by simply connecting the system to a television or other display. In this standalone mode the multimedia console allows one or more users to interact with the system watch movies or listen to music. However with the integration of broadband connectivity made available through the network interface or the wireless adapter the multimedia console may further be operated as a participant in a larger network community.

When the multimedia console is powered ON a set amount of hardware resources are reserved for system use by the multimedia console operating system. These resources may include a reservation of memory e.g. 16 MB CPU and GPU cycles e.g. 5 networking bandwidth e.g. 8 kbs etc. Because these resources are reserved at system boot time the reserved resources do not exist from the application s view.

In particular the memory reservation preferably is large enough to include the launch kernel concurrent system applications and drivers. The CPU reservation is preferably constant such that if the reserved CPU usage is not used by the system applications an idle thread will consume any unused cycles.

With regard to the GPU reservation lightweight messages generated by the system applications e.g. popups are displayed by using a GPU interrupt to schedule code to render popup into an overlay. The amount of memory required for an overlay depends on the overlay area size and the overlay preferably scales with screen resolution. Where a full user interface is used by the concurrent system application it is preferable to use a resolution independent of application resolution. A scaler may be used to set this resolution such that the need to change frequency and cause a TV resynch is eliminated.

After the multimedia console boots and system resources are reserved concurrent system applications execute to provide system functionalities. The system functionalities are encapsulated in a set of system applications that execute within the reserved system resources described above. The operating system kernel identifies threads that are system application threads versus gaming application threads. The system applications are preferably scheduled to run on the CPU at predetermined times and intervals in order to provide a consistent system resource view to the application. The scheduling is to minimize cache disruption for the gaming application running on the console.

When a concurrent system application requires audio audio processing is scheduled asynchronously to the gaming application due to time sensitivity. A multimedia console application manager described below controls the gaming application audio level e.g. mute attenuate when system applications are active.

Input devices e.g. controllers and are shared by gaming applications and system applications. The input devices are not reserved resources but are to be switched between system applications and the gaming application such that each will have a focus of the device. The application manager preferably controls the switching of input stream without knowledge the gaming application s knowledge and a driver maintains state information regarding focus switches. The camera the RGB camera and capture device may define additional input devices for the multimedia console .

In the computing environment comprises a computer which typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS including the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically includes data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through an non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a keyboard and pointing device commonly referred to as a mouse trackball or touch pad. Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . The camera the RGB camera and capture device may define additional input devices for the multimedia console . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through a output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory storage device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

In one embodiment the media feed interface may be integrated into the application programs such that the application programs may execute the media feed interface . Alternatively the media feed interface may be integrated into either the gesture library or the operating system or the media feed interface may be an independent application executing on the computing environment .

As further shown in the media feed interface may receive and or access data that may be included in a media feed from a plurality of sources such as the capture device described above with respect to a capture file and or a network resource. For example in one embodiment the media feed interface may access the capture device to retrieve for example video camera data IR camera data depth camera data mic array data or any other data that may be captured by the capture device . Additionally the media feed may include data associated with a model that be generated for a user by for example the capture device Upon retrieving the data in the media feed the media interface may create the media feed may isolate a media frame within the media feed and or may provide data from the media feed to an end user application such as the applications programs the gesture library and or the operating system .

In one embodiment upon retrieving the data the media interface may populate one or more buffers with the captured data. In populating the buffers with the captured data the media feed interface may packetize time stamp and interleave the captured data such that the media feed interface may packetize time stamp and interleave the data in the media feed along a timeline to create media frames that enable a synchronized playback experience. For example the media feed interface at the request of the application programs may retrieve a media frame that includes an RGB image that corresponds to a specific time based on the packetized time stamped and interleaved captured data in the media feed created by the media feed interface .

In another embodiment the media feed interface may access a capture file to retrieve capture file data that may be included in the media feed . The capture file data may include stored data that may have been previously captured by the capture device . For example the capture device may create a capture file that may include the capture file data that may have been previously by the captured device .

In yet another embodiment the media feed interface may access a network resource to retrieve network resource data that may be included in the media feed . The network resource data may include data associated with a model of the user depth images RGB images sound infrared data or the like that may be included. According to example embodiments the network resource data may include capture file data and or data captured by a capture device that may be accessible through a network such as a home network the Internet an intranet WAN LAN or the like. For example data captured by a capture device such as the capture device located at a remote location may be accessed as a network resource such that data captured by the remote captured device may be received by the media feed interface in the network resource data .

After retrieving the capture file data and or the network resource data the media feed interface may use the data to populate buffers as described above such that the media feed interface may packetize time stamp and interleave the data in the media feed along a timeline to create media frames that enable a synchronized playback experience.

At a capture device a file and or a network resource may be accessed. For example a media feed interface such as the media feed interface described above with respect to may access a capture device such as the capture device a capture file and or a network resource. In accessing the capture device the capture file and or the network resource the media feed interface may be responding to a request issued by application programs such as the application programs a gesture library such as the gesture library an operating system such as the operating system and or a computing environment such as the computing environment described above with respect to .

In one embodiment the media feed interface may access the capture device at to retrieve captured depth information depth images sound infrared data data associated with a model or any other data capable of being provided by the capture device. Additionally the media feed interface may also access the capture file and or network resource to retrieve captured depth information depth images sound infrared data data associated with a model of the user or the like.

As shown in the model may include one or more joints j j. According to an example embodiment each of the joints j j may have data including a respective X value Y value and Z value associated therewith that may be stored in the one or more data structures. Additionally each of the joints j j may define one or more body parts therebetween that may move relative to one or more other body parts. For example a model of the user may include a plurality of rigid and or deformable body parts that may be defined by one or more structural members such as bones with the joints j j located at the intersection of adjacent bones. The joints J may enable various body parts associated with the bones and joints j j to move independently of each other. As described above each of the joints j j and the bones defined therebetween may be defined as data or a mathematical vector in the one or more data structures associated with the model .

Referring back to at buffers may be populated with data received from the capture device the capture file and or the network resource. For example the media feed interface may populate buffers with data received from the capture device the capture file and or the network resource. A buffer may be a region of memory that is used to temporarily and or permanently stored data. The buffer may be implemented in either hardware or software and may include random access memory RAM read only memory ROM cache Flash memory a hard disk or any other suitable storage component.

In one embodiment the media feed interface may provide the application programs the gesture library the operating system and or the computing environment with direct access to the buffers. For example upon receiving a request from the application programs the media feed interface may supply the application programs with the memory address of the buffer that includes data populated from the capture device. In another embodiment the media feed interface may provide the application programs the gesture library the operating system and or the computing environment with indirect access to the buffers. For example upon receiving a request from the application programs the media feed interface may retrieve data included within the populated buffer. Upon retrieving the data included within the buffer the media feed interface may provide the data to the application programs without revealing the memory address of the buffer.

In another embodiment the media feed interface may also save the populated buffers to a capture file and or a network resource. In saving a buffer the media feed interface may save the data within the buffer to an existing capture file and or network resource or may create a new capture file and or network resource. Additionally the media feed interface may have the capability to save the buffer in response to a request from the application programs the gesture library the operating system and the computing environment.

At a media feed such as the media feed described above may be created. For example the media feed interface may create a media feed at using the buffers that may have been populated with data from the capture device the capture file and or the network resource at . In creating the media feed the media feed interface may packetize time stamp and interleave data from capture device the capture file and or the network resource along a timeline to create media frames that enable a synchronized playback experience as described above.

In one embodiment the media feed interface may filter the data that may be used to create the media feed at such that media feed may include filtered data taken from the capture device the capture file and or the network resource. For example the media feed interface may receive IR RGB and depth image data from the capture device however the media feed interface may filter the IR and depth image data such that only the RGB data may be included in the media feed. According to an example embodiment the data may be filtered at the request of the application programs the gesture library the operating system and or the computing environment.

In another embodiment the media feed interface may enable the application programs the gesture library the operating system and the computing environment to select the appropriate filters that may be applied to the data before media frames are created at and included in the media feed such that unneeded media frames may not be included in the created media feed.

At a request to retrieve data captured by the capture device data associated with a model network resource data capture file data or the like that may be included in the media feed may be received. For example the media feed interface may receive a request to data retrieve captured by the capture device data associated with a model network resource data capture file data or the like that may be included in the media feed. In example embodiments the request may be from application programs such as the applications programs a gesture library such as the gestures library an operating system such as the operating system and or a computing environment such as the computing environment described above with respect to .

At the created media feed may be received and or accessed. For example the media feed interface may receive and or access the media feed created at for example . According to an example embodiment the created media feed may be received and or accessed by the media feed interface in response to the request received at . For example application programs may request access to data such as data associated with a model such as the model described above with respect to of the user that may be included in the media feed. The media feed interface may receive such request and upon receiving the request the media feed interface may retrieve and or access the media feed.

At a media frame associated with the media feed may be isolated. For example as described above the media feed interface may create the media feed at such that the media feed may include on or more media frames that may include various data received from the capture device the capture file and or the network resource. In one embodiment the media feed interface may isolate a media frame with the media feed in response to a request for specific data in the media feed made by for example the application programs the gesture library the operating system and or the computing environment at . In isolating the media frame the media feed interface may isolate a specific media frame a range of frames or the like that may be associated with the requested data. According to an example embodiment one or more media frame may include media frames associated with RGB images IR data sound data depth data 3 D data data associated with a model of the user and or any other data at a specific point in time over a time range or the like.

At access may be provided to the isolated media frame. For example in one embodiment after isolating the media frame the media feed interface may provide the application programs the gesture library the operating system and or the computing environment access to the data in the isolated media frame. Additionally according to another embodiment the media feed interface may automatically isolate the media frame and may provide access to the isolated media frame without receive a specific request from the application programs the gesture library the operating system and or the computing environment.

In one embodiment the application programs the operating system the gesture library and or the computing environment process the isolated media frame provided by the media feed interface. For example the application programs the operating system the gesture library and or the computing environment may use the data in the isolated media frame to track the model of the user render an avatar associated with the model determine clothing skin and other colors based on a corresponding RGB image and or determine which controls to perform in an application executing on the computer environment based on for example the model.

In another embodiment the visual appearance of an on screen character may then be changed in response to data accessed in the isolated media frame. For example a user such as the user described above with respect to playing an electronic game on a gaming console may be tracked by the gaming console as described herein. In particular a model such as a skeletal model may be used to represent a game player. As the game player straightens one arm the computer environment may track this motion by accessing the data associated with the model such as the model of the target game player in media frames of the media feed. The computing environment may then adjust a body model of a player avatar associated with the user using the data associated with the model of the user accessed in the media frame of the media feed.

It should be understood that the configurations and or approaches described herein are exemplary in nature and that these specific embodiments or examples are not to be considered limiting. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such various acts illustrated may be performed in the sequence illustrated in other sequences in parallel or the like. Likewise the order of the above described processes may be changed.

The subject matter of the present disclosure includes all novel and nonobvious combinations and sub combinations of the various processes systems and configurations and other features functions acts and or properties disclosed herein as well as any and all equivalents thereof.

