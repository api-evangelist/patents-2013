---

title: Methods and apparatus for point-in-time volumes
abstract: Methods and apparatus for point-in-time volumes are provided. A relationship is enabled between a source volume and point-in-time volume. Copying a data chunk to the point-in-time volume before a write operation modifies the data chunk on the source volume dynamically creates the point-in-time volume. The point-in-time volume can be accessed in read/write mode as a general purpose data storage volume. Other embodiments comprising additional features, such as a forced migration process, are also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09087013&OS=09087013&RS=09087013
owner: DataCore Software Corporation
number: 09087013
owner_city: Fort Lauderdale
owner_country: US
publication_date: 20130314
---
This is a continuation application of application Ser. No. 13 217 417 filed Aug. 25 2011 which is a continuation application of application Ser. No. 10 893 477 filed Jul. 15 2004 now U.S. Pat. No. 8 010 756 which is a divisional of application Ser. No. 10 044 327 now U.S. Pat. No. 6 799 258 which claims priority to Provisional Patent App. Ser. Nos. 60 261 036 filed Jan. 10 2001 and Ser. No. 60 261 583 filed Jan. 14 2001. These applications are incorporated herein by reference in their entireties.

Like other important assets data needs to be protected against loss or damage. Conventionally data backups are used for safeguarding important data. A data backup process generally involves duplicating large amounts of data on a backup device such as a tape. The time required to copy a data set is a function of the size of the data set. With current data sets in the range of several terabytes and future data sets even larger much time is required to perform a data backup process.

During typical data backup procedures the source volume cannot be written to until the backup procedure is complete. This is necessary to maintain file system or volume integrity during the backup process. A transaction processing application for example must not be allowed to change data on the source volume during the backup process because the resulting data backup may be corrupted by partial or incomplete transactions. Typically this limitation requires the source volume to be unavailable to production applications during the backup procedure.

Further the amount of time required to perform a data backup coupled with the unavailability of the production data set makes it impractical to perform full data backups on modern data processing systems. These systems work on data continuously and cannot afford to be unavailable during a data backup. Even in environments that can tolerate data unavailability during non business hours the backup process may not have sufficient time to complete during the non business hours.

In the event of loss or damage to production data the data must be restored. Similar to conventional data backups restoring a system to a prior state is also a time consuming process during which data is unavailable to production systems. The downtime associated with restoring data after e.g. a virus infection often translates into lost revenue and higher administration costs.

Point in time technology addresses limitations of conventional data storage processing and protection techniques. In the event of file system corruption for example point in time methods could be used to restore the file system without a time consuming conventional restoration from a backup set.

Point in time technology also solves the problem of data availability during a backup process. The state of a storage system can be saved at a particular point in time with minimal disruption. Unlike conventional data backup processes a typical point in time process can complete without making the source volume unavailable to production applications. Thus point in time processes enable data protection in environments where conventional data backups are not feasible due to availability concerns.

Existing point in time technologies however have a number of limitations. In some point in time implementations there is continued dependence on a source volume because the source volume is not fully replicated. This dependence generates extra input output requests to the source volume that consume bandwidth and storage system resources.

Other backup and point in time implementations have been application specific. These approaches have the disadvantage that the point in time image cannot be used as a general purpose volume available for both reading and writing while the source volume upon which the point in time volume is based is in use.

Conventional backup and point in time implementations also lack desirable data sharing features. Data sharing is the ability of multiple applications or multiple machines to access and to process the same or a similar data set. Data sharing is often not feasible using conventional point in time methods because these methods lack general purpose volume availability.

What is therefore needed is a method and apparatus for point in time volumes that is minimally disruptive of the availability of the source volume does not consume bandwidth and storage system resources because of dependence on the source volume can be used as a general purpose volume available for both reading and writing and provides for efficient data sharing.

An embodiment of the present invention provides a method and apparatus for point in time volumes. A point in time volume represents the contents of a source volume in a particular past state. A point in time volume can be dynamically created without disrupting the availability of the source volume. Data chunks are copied to the point in time volume before a data write operation modifies the data chunk on the source volume. The point in time volume therefore includes data chunks from the source volume in a past state.

In an embodiment the point in time volume is used to restore the source volume to its prior state. In another embodiment the point in time volume is used as a general purpose data storage volume. Data processing and sharing applications therefore can read and write to a point in time volume.

In further embodiments a forced migration process can replicate a source volume to a point in time volume. In the event of a failure of the source volume a point in time volume can be used for disaster recovery. In an embodiment of the present invention point in time volumes are accessible in read write mode so an independent point in time volume could be mapped in place of a failed or damaged source volume.

Further features of the invention its nature and various advantages will be more apparent from the accompanying drawings and the following detailed description.

The present invention now will be described more fully with reference to the accompanying figures in which several embodiments of the invention are shown. The present invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the invention to those skilled in the art.

Storage domain server virtualizes the interface between application server and data storage and disk array . In a preferred embodiment storage domain server presents storage resources to application server . The storage resources presented represent virtual volume images that application server can mount or otherwise access. From the perspective of application server the virtual volume image appears to the operating system like a storage device to which application server can read and write data blocks. Storage domain server processes the input and output requests on these virtual volumes to generate read and write requests to the physical storage resources e.g. data storage .

As an example of virtualization in this exemplary embodiment data storage provides physical resources for both volume 1 image and volume 2 image . Volume 3 image however physically resides on disk array . Data storage has a capacity of e.g. 1 terabyte. Storage domain server equally allocates 500 gigabytes to both volume 1 image and volume 2 image . Thus from the perspective of application server 1 volume 1 image looks like a storage device with a capacity of 500 gigabytes.

Storage domain server can selectively present virtual storage volumes to servers. Thus storage domain server can unmap volume 2 image from application server 2 and present volume 2 image to backup server . Backup server could map both volume 3 image as shown as well as volume 2 image not shown .

Application server 1 maps source volume and application server 2 maps point in time volume 1 . Backup server maps point in time volume 2 . Source volume point in time volume 1 and point in time volume 2 are accessed through storage network . Storage domain server virtualizes accesses to the backend data storage.

In operation the relationship between source volume and point in time volume 1 snapshot relationship is enabled at time t. After the point in time volume relationship is enabled application server 1 continues to manipulate data on source volume . Although data blocks have been read and modified on source volume at time t point in time volume 1 continues to reflect the contents of source volume at time twhen the relationship was enabled. Thus point in time volume 1 is said to be a snapshot of source volume at time t.

Similarly the relationship between source volume and point in time volume 2 is enabled at time t. Point in time volume 2 is said to be a snapshot of source volume at time t. As discussed above in this embodiment storage domain server presents point in time volume 2 to backup server . Backup server maps point in time volume 2 and performs a file level backup operation on the volume to tape drive . Importantly application server 1 can concurrently read and write data blocks on source volume while backup server performs a file level backup.

Further application server 2 can read and write data blocks to point in time volume 1 while application server 1 is modifying data blocks on source volume upon which point in time volume 1 is based. For example application server 2 could be performing virus scanning and cleaning on point in time volume 1 while source volume is concurrently available for production use by application server 1 .

The concurrent availability of these volumes allows for time shifting. Time shifting is the ability to shift the processing of data to a more optimal time. For example with reference to it may be desirable to backup source volume each Monday at 17 00 hours. Point in time volume 2 could be created or enabled at 17 00 hours on Monday. Backup server can then perform the backup process on point in time volume 2 at some later time yet the backed up data is as of Monday at 17 00 hours regardless of when the actual backup process is completed. Because the point in time process preserves the state of source volume at the particular point in time the relationship was enabled application server 1 can continue to read and write source volume after Monday at 17 00 hours. That is source volume is available for production use. Backup server uses a snapshot of source volume to time shift the backup operation to a more convenient time. For example it may be desirable for the backup to run only during business hours when an employee can service tape drive .

In an embodiment of the present invention point in time volumes are mapped as general purpose data volumes available for both reading and writing. From a server s perspective a point in time volume appears like a normal data storage volume such as volume 1 . Multiple machines processes or processors therefore can perform data sharing on a volume or file level.

By way of an example with further reference to point in time volume 1 is a snapshot of volume 1 . Volume 1 is a production database volume used by application server . Point in time volume 1 is presented to and mapped by recovery server . Recovery server performs a database recovery on the table space and transaction logs. The recovery procedure produces a known good image of the database. If a logical error or other failure occurs on volume 1 the recovered database on point in time volume 1 can be presented to application server . Thus application server and recovery server were able to share the data on volume 1 to perform their tasks accordingly.

In source volume and point in time volume are attached to storage domain server . Storage domain server includes data maps . Storage domain server is connected to storage network for interfacing with clients or servers not shown . In this illustration source volume is logically segmented into data chunks 0 . . . N wherein each data chunk contains 4 data blocks. When the point in time relationship is enabled point in time volume is dynamically constructed based on the data of source volume . In a preferred embodiment of the present invention data is not copied to point in time volume until the data is about to be changed on source volume . That is a data chunk from source volume is copied to data chunk storage before the data is changed on source volume thus preserving the point in time relationship. For example a data write to block 1 of source volume threatens to change corresponding data chunk 0 so data chunk 0 is copied to point in time volume before the data write to block 1 occurs on source volume . Data chunks that are copied to a point in time volume due to data writes on the corresponding source volume are termed point in time data chunks.

In an alternative embodiment data chunks are copied from source volume to point in time volume regardless of whether data writes threaten to modify data blocks on source volume . Because point in time volume is preferably created dynamically without replicating data point in time volume is dependent on source volume . In this regard copying data chunks from source volume to point in time volume increases the independence of the point in time data set. Data chunks transferred in this manner are termed migration data chunks.

Depending on a user s needs or system configuration it may be desirable to combine the embodiments of point in time data chunks with migration data chunks. This is discussed below with reference e.g. to . Storage domain server handles input output requests from servers on storage network and manages the relationships among volumes including the copying of data chunks between volumes. Data maps are data structures used to manage the relationship between e.g. source volume and point in time volume . Data maps are preferably stored in local data storage on storage domain server however data maps could be stored elsewhere e.g. local memory a remote node on the storage network source volume or point in time volume .

In an embodiment each input output request to source volume or point in time volume is treated as an atomic transaction. A transaction is a read request or a write request to either source volume or point in time volume in a relationship. A read or write input output request to source volume or point in time volume must wait if the input output request affects a chunk involved in a currently active input output request.

In the case of a source volume read or source volume write the chunk or chunks in all enabled snapshot relationships associated with the source volume that will be referenced by the read or write operation are first locked by the locking algorithm of the driver. The operation on the chunk or chunks is completed. The chunks in all snapshot relationships associated with the volume that will be referenced by the read or write operation are unlocked using the locking algorithm of the driver and the original read or write request is completed. Further if the read or write operation is to a point in time volume then the lock for the chunk or chunks is taken in only the specific enabled snapshot relationship that is associated with the point in time volume. But if the read or write is to the source volume then all enabled relationships that share the same source volume will have their chunk s locked for the operation. Although transaction based locking is described one skilled in the art will appreciate that other block or chunk locking consistency or integrity techniques can be implemented.

As an example with reference to in the chunk 0 entries migration table indicates true and delta table also indicates true. Chunk 0 likely represents a point in time data chunk because the data chunk was copied to the point in time volume as indicated by migration table and a data write occurred on either the source volume or the point in time volume as indicated by delta table . In migration table the entries for data chunks 1 and 2 are both true yet the corresponding entries in delta table for data chunks 1 and 2 are both false. Thus data chunks 1 and 2 are migration data chunks having been copied from the source volume to the point in time volume without the occurrence of a data write. In a preferred embodiment migration table need not discriminate between migration data chunks and point in time data chunks because as explained further below migration table is used to determine whether a data chunk has been copied to a point in time volume not the reason the data chunk was copied.

Although migration table and delta table are illustrated as distinct data structures one skilled in the art will appreciate that the type of state data e.g. metadata represented in migration table and delta table can be accessed and stored in numerous configurations of software or hardware.

In step the storage domain server receives an input output request from e.g. an application server . Depending on the type of operation involved control proceeds to step step or step . These steps correspond to the following operations writing to the source volume writing to the point in time volume and reading from the point in time volume. One skilled in the art will appreciate that reading from the source volume is a typical read operation that does not require teaching of a specific implementation.

A method of performing a write to the source volume is now explained. Step begins the process of performing data writes to the source volume. Application servers e.g. perform writes to data blocks. In step the data chunk associated with the data block to be written is determined. For example with reference to source volume of a data write to block 3 corresponds to a write to data chunk 0. This determination is preferably made by mathematical calculation given the number of data blocks on the source volume and the data chunk size configured in step above. One skilled in the art will appreciate however that other methods of relating data blocks and data chunks can be implemented e.g. a database . Next in step migration table is used to determine whether the data chunk to be written has been copied to the related point in time volume. As explained above with respect to migration table a set bit or true status indicates that the data chunk has been copied to the point in time volume. If the data chunk has been copied control jumps to step otherwise control proceeds to step .

In step the data chunk determined in step is read from the source volume. This point in time data chunk is then written to the point in time volume in step . Thus the original contents of the data chunk from the source volume are preserved on the point in time volume before new data is written. In step the entry for the data chunk in migration table is set to true to reflect that the point in time data chunk has been copied to the point in time volume.

In step the data block is written to the source volume. In step the entry for the data chunk corresponding to the data block in delta table is set to true to reflect that the data chunk has been modified on the source volume. That is the contents of the data chunk on the source volume and point in time volume differ In a preferred embodiment the state data maintained in delta table is used for implementing source update and point in time volume update features as explained below e.g. .

Next in step the storage domain server tests whether the relationship has been disabled. If the relationship is disabled control proceeds to step where the process ends. Otherwise control returns to step . In a preferred embodiment data maps and chunk storage are stored such that the relationship between source volume and point in time volume may be re enabled at the point where operations were suspended.

Returning to step the storage domain server receives a read or write request from e.g. an application server . Having already discussed a method of performing a write to the source volume a method of performing a write to the point in time volume is now explained beginning with step .

Point in time volumes are general purpose volumes to which data can be written. The process of writing data blocks to the point in time volume is analogous to the process described above of writing to the source volume. In step similar to step the data chunk associated with the data block to be written is determined. In step similar to step migration table is used to determine whether the data chunk to be written has been copied to the related point in time volume. If the data chunk has been copied control jumps to step otherwise control proceeds to step .

In step similar to step the data chunk determined in step is read from the source volume. This point in time data chunk is then written to the point in time volume in step . Thus the data chunk is copied to the point in time volume so that new data can be written without affecting the data chunk on the source volume. In step the entry for the data chunk in migration table is set to true to reflect that the point in time data chunk has been copied to the point in time volume.

In step the data block is written to the point in time volume. In step the entry for the data chunk corresponding to the data block in delta table is set to true to reflect that the data chunk has been modified on the point in time volume. That is the contents of the data chunk on the source volume and point in time volume differ.

Next in step the storage domain server tests whether the relationship has been disabled. The process of step is described above. Having already discussed a method of performing a write to the source volume and a method of performing a write to the point in time volume reading from the point in time volume is now explained beginning with step .

Point in time volumes are general purpose volumes from which data can be read. A method of reading from a point in time volume begins at step . Next in step similar to steps and the data chunk associated with the data block to be read is determined. In step similar to steps and migration table is used to determine whether the data chunk to be read has been copied to the related point in time volume. If the data chunk has been copied control jumps to step otherwise control proceeds to step .

In step the data block is read from the source volume. Because the associated data chunk has not been copied to the point in time volume the data block is read from the source volume. As described above data writes to the source volume result in a point in time data chunk being transferred to the point in time volume to preserve the contents of the data chunk at a particular point in time. If the data chunk therefore has not been copied to the point in time volume then that particular data chunk has not been modified on the source volume since the relationship was enabled.

Alternatively in step the data block is read from the point in time volume. The corresponding data chunk is either a point in time data chunk or a migration data chunk. In the case of a point in time data chunk the data block must be read from the point in time volume to retrieve the data as it existed in a past state the same data chunk on the source volume has been modified and no longer reflects the particular point in time . In the case of a migration data chunk the data block could be read from either the source volume or the point in time volume because the contents of the data chunks of both volumes are equivalent. In a preferred embodiment a migration data chunk is read from the point in time volume to reduce consumption of bandwidth and storage system resources. Migration data chunks therefore increase the independence of the point in time volume because data block reads to migration data chunks can be performed on the point in time volume rather than exclusively on the source volume. Next in step the storage domain server tests whether the relationship has been disabled. The operation of step is described above.

With reference to a forced migration begins in step by determining the next data chunk to migrate. A storage domain server preferably performs step by sequentially selecting the next chunk marked false in migration table . One skilled in the art however will appreciate that other algorithms can be implemented e.g. selecting the next chunk based on the last volume transaction performed.

In step the selected data chunk is read from the source volume. Next in step the data chunk is written to the point in time volume. In step the migration table is updated to reflect that the selected chunk has been copied to the point in time volume.

In the embodiment illustrated in in step the process delays for a predetermined amount of time e.g. 20 milliseconds. After delaying control loops to step where the next data chunk to migrate if any is selected. The delay time is selected such that the forced migration process does not overburden the source volume thereby starving or interrupting e.g. an application server s access to the source volume. One skilled in the art will appreciate that longer or shorter delay times may be appropriate considering data storage system utilization storage volume throughput storage network configuration or other parameters. In another embodiment an algorithm that evaluates the utilization of the source volume and transfers bursts of data chunks to the point in time volume when the source volume is underutilized could replace the delay of step .

In another embodiment source update process includes a delay before step loops to step . Similar to step of the delay time is selected such that the source update process does not overburden system resources. One skilled in the art will appreciate that longer or shorter delay times may be appropriate considering data storage system utilization storage volume throughput storage network configuration or other parameters.

In another embodiment point in time volume update process includes a delay before step loops to step . Similar to step of the delay time is selected such that the point in time volume update process does not overburden system resources. One skilled in the art will appreciate that longer or shorter delay times may be appropriate considering data storage system utilization storage volume throughput storage network configuration or other parameters.

Transaction based chunk locking is now described with respect to the source update process and point in time volume update process. In an embodiment all chunks are initially locked using the driver locking algorithm discussed above. The driver decides whether to copy the chunk based on whether a write has previously occurred on that chunk. As discussed above if a write has previously occurred the chunk is copied. The driver then clears the delta table and removes the lock associated with the copied chunk. Then the driver repeats the process on the next chunk. The locks are removed as the data is processed. This locking strategy is termed a decaying lock. At the end of either update process all locks will have been removed. This locking scheme is used to guarantee that no change to either the source volume or point in time volume occurs while the process is determining what needs to be changed based on previously recorded differences.

Further in the source update case chunk locks will be taken for all enabled relationships sharing the same source volume configuration. This is because it is the source volume that is being changed by the update process and as a result of changes to the source volume that may occur other relationships sharing the same source volume may have their data migrated from the source volume to their respective point in time volume before the source volume is changed due to the source update process on a particular snapshot relationship.

With respect to the forced migration process a chunk is locked while the process determines if the chunk has already been migrated from the source volume to the point in time volume. If it has not been migrated the chunk is migrated and the migration table is updated. Once migrated the chunk lock is removed and the driver evaluates the next chunk.

As illustrated in if forced migration is desired control proceeds to step in which an embodiment of a forced migration process is described above. If a source update is desired control proceeds to step . Source update generally requires a quiet source volume. In a preferred embodiment in step the source volume is unmounted from e.g. application servers to quiet the volume. Next a source update is performed beginning with step on .

Similarly if a point in time volume update is desired control proceeds to step . Point in time volume update also requires a quiet volume. In a preferred embodiment in step the point in time volume is unmounted from e.g. application servers to quiet the volume. Next a point in time volume update is performed beginning with step on .

Additionally a point in time volume read and write usage mode can be selected. In step point in time volume is used as a general purpose data storage volume as described above and with reference to . A storage domain server follows the methods disclosed in to perform read write operations on the source volume or point in time volume. In another embodiment a storage domain server disables or an application server unmounts a source volume and the data producer or consumer e.g. application servers or clients uses the point in time volume in accordance with step . It is often desirable to perform for example application testing on the point in time volume without altering the source volume. The source volume can be considered a golden volume a known good data set from which several point in time testing volumes can be created and manipulated. In this embodiment the source volume can be used to return instantly to a prior state by disabling and re enabling.

One skilled in the art will appreciate that selecting a particular usage mode does not prohibit concurrent operations of other usage modes i.e. each usage mode does not necessarily operate exclusively on a source volume or point in time volume. For example read and write operations can occur on a source or point in time volume during a forced migration process.

As discussed above the relationship between a source volume and point in time volume snapshot relationship can be configured and managed via a graphical user interface a command line interface or an application programming interface. Table 1 is an example of a list of interface commands where DcsSnap is a parameter that identifies the relationship. One skilled in the art will appreciate how to implement and to use these commands in view of the above detailed description.

Additionally the relationship between a source volume and point in time volume snapshot relationship can be configured and managed via an application programming interface API . Table 2 is an example of an API. One skilled in the art will appreciate how to implement and to use an API in view of the above detailed description.

Having described preferred embodiments of methods and apparatus for point in time volumes which are intended to be illustrative and not limiting it is noted that modifications and variations can be made by persons skilled in the art in light of the above teachings. It is therefore to be understood that changes may be made in the particular embodiments of the invention disclosed that are within the scope and spirit of the invention as defined by the appended claims and equivalents.

