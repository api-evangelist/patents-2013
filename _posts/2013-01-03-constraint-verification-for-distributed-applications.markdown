---

title: Constraint verification for distributed applications
abstract: Systems and methods are described for analyzing and verifying distributed applications. In one embodiment, an application program is executed as independently executable components. During execution, redundant portions of application program data are aggregated. A property of the application program is verified using the aggregated application program data to represent code execution paths.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09448820&OS=09448820&RS=09448820
owner: Amazon Technologies, Inc.
number: 09448820
owner_city: Reno
owner_country: US
publication_date: 20130103
---
A data center is one example of a computing environment that houses computer systems various networking storage and other related components. The computing resources provided by a data center may include various types of resources such as data processing resources data storage resources data communication resources and the like. To facilitate increased utilization of data center resources virtualization technologies may allow a single physical computing machine to host one or more instances of virtual machines VMs that appear and operate as independent computer machines to a remotely connected computer user. Such complex computing environments allow for use of distributed services and scalable applications. However it is increasingly difficult to analyze and verify operation of distributed applications in such environments.

The following detailed description is directed to technologies for verification and analysis tasks in a distributed computing environment. In the examples described herein a data center is one example computing environment in which the described embodiments can be implemented. Furthermore a distributed program is one example of an application for the described embodiments. However the described concepts can apply generally to other computing environments and software.

Determinism wherein program execution has a repeatable and well defined sequence of causes and effects can be difficult or impossible to achieve in a complex and distributed computing environment such as a data center. For example the computing and network settings in a data center can be vast and diverse. Because of the sheer number and variety of computing resources in a data center it can be difficult to test and verify software and hardware in such a setting let alone characterize the environment with respect to specific performance metrics. It can also be difficult to automate and manage the testing in a production capacity. Rigorous verification by examining many or all code paths of a distributed application can be infeasible. Even techniques such as whitebox fuzzing may be infeasible given the enormous numbers of program code flow variations.

In one embodiment the present disclosure describes a deterministic container model that simplifies the detection and handling of non determinism for distributed services. A program can be divided into a plurality of potentially nondeterministic execution spaces which may be referred to as containers. Each container may operate independently on a portion of the program. Relationships between the execution spaces may be defined by the container model and determinism may be enforced between containers.

In another embodiment the present disclosure describes methods for providing constraint analysis using a virtualized version of a distributed application. Application message passing may be encapsulated using an envelope format that includes application data and condition variables for program analysis. Redundantly derived message exchanges may be collapsed into a single exchange using combinations of the condition variables.

In another embodiment the present disclosure describes the use of virtualized program execution to prune the number of program code flow variations resulting from non determinism and message passing. A program may be divided into multiple program execution units. Each execution unit may execute inside a virtual environment that permits adjustment of the program determinism. Symbolic evaluation of the execution units may be performed to generate test inputs for the program. Redundant or non productive portions of the input space may be pruned by collapsing messaging interactions between the execution units and dynamically adjusting the determinism of program execution.

A user administrator service or any computing resource in computing environment may send a request to verification and analysis system for verification of a particular computing property of a distributed software application. As another example the request may indicate that a computing device will be upgraded and that distributed software applications will be affected by the upgrade. In one embodiment verification and analysis system may divide the distributed software application into a plurality of execution spaces. Each execution space may operate independently on a portion of the distributed software application. Relationships between the execution spaces may be defined by a container model that enforces constraints on determinism between execution spaces. Verification and analysis system may also perform constraint analysis against a virtualized version of a distributed application. Verification and analysis system may encapsulate application messages and collapse redundantly derived message exchanges into a single exchange. Furthermore symbolic evaluation of the execution spaces may be performed to generate test inputs for the distributed software application. Services provided by verification and analysis system may be requested directly by a customer of the data center by an administrator of the data center a service or any computing resource within the data center such as server . Server may also send a request on behalf of itself or on behalf of other servers.

Verification and analysis system may also access information regarding available computing devices for analysis and verification. The analysis and verification may be prioritized based on factors such as cost and policy information. Verification and analysis system may access information describing test parameters and performance metrics or benchmarks analysis results and resource schedules. Verification and analysis system may also access previously conducted analysis results and resource schedules. Verification and analysis system may send information regarding the results to the requestor.

Data center may be configured to provide computing resources for executing applications on a permanent or an as needed basis. The computing resources provided by data center may include various types of resources such as data processing resources data storage resources data communication resources and the like. Each type of computing resource may be general purpose or may be available in a number of specific configurations. For example data processing resources may be available as virtual machine instances. The instances may be configured to execute applications including Web servers application servers media servers database servers and the like. Data storage resources may include file storage devices block storage devices and the like.

Each type or configuration of computing resource may be available in different sizes such as large resources consisting of many processor cores large amounts of memory and or large storage capacity and small resources consisting of fewer processor cores smaller amounts of memory and or smaller storage capacity. Customers may choose to allocate a number of small processing resources as Web servers and or one large processing resource as a database server for example.

Data center may include servers and which may be referred herein singularly as a server or in the plural as the servers that provide computing resources available as virtual machine instances and which may be referred herein singularly as a virtual machine instance or in the plural as the virtual machine instances . The virtual machine instances may be configured to execute applications including Web servers application servers media servers database servers and the like. Other resources that may be provided include data storage resources not shown and may include hard drives solid state storage drives or other storage devices and the like.

The availability of virtualization technologies for computing hardware has provided benefits for providing large scale computing resources for customers and allowing computing resources to be efficiently and securely shared between multiple customers. For example virtualization technologies such as those provided by VMware or other virtualization systems may allow a physical computing device to be shared among multiple users by providing each user with one or more virtual machine instances hosted by the physical computing device. A virtual machine instance may be a software emulation of a particular physical computing system that acts as a distinct logical computing system. Such a virtual machine instance provides isolation among multiple operating systems sharing a given physical computing resource. Furthermore some virtualization technologies may provide virtual resources that span one or more physical resources such as a single virtual machine instance with multiple virtual processors that spans multiple distinct physical computing systems.

Referring to communications network may for example be a publicly accessible network of linked networks and possibly operated by various distinct parties such as the Internet. In other embodiments communications network may be a private network such as for example a corporate or university network that is wholly or partially inaccessible to non privileged users. In still other embodiments communications network may include one or more private networks with access to and or from the Internet.

Communication network may provide access to computers . User computers may be computers utilized by users or other users of data center . For instance user computer or may be a server a desktop or laptop personal computer a tablet computer a wireless telephone a personal digital assistant PDA an e book reader a game console a set top box or any other computing device capable of accessing data center . User computer or may connect directly to the Internet e.g. via a cable modem or a Digital Subscriber Line DSL . Although only two user computers and are depicted it should be appreciated that there may be multiple user computers.

User computers may also be utilized to configure aspects of the computing resources provided by data center . In this regard data center might provide a Web interface through which aspects of its operation may be configured through the use of a Web browser application program executing on user computer . Alternatively a stand alone application program executing on user computer might access an application programming interface API exposed by data center for performing the configuration operations. Other mechanisms for configuring the operation of the data center including deploying updates to an application might also be utilized.

Servers shown in may be standard servers configured appropriately for providing the computing resources described above and may provide computing resources for executing one or more applications. In one embodiment the computing resources may be virtual machine instances . In the example of virtual machine instances each of the servers may be configured to execute an instance manager or which may be referred herein singularly as an instance manager or in the plural as the instance managers capable of executing the virtual machine instances . The instance managers may be a virtual machine monitor VMM or another type of program configured to enable the execution of virtual machine instances on server for example. As discussed above each of the virtual machine instances may be configured to execute all or a portion of an application.

It should be appreciated that although the embodiments disclosed above discuss the context of virtual machine instances other types of implementations can be utilized with the concepts and technologies disclosed herein. For example the embodiments disclosed herein might also be utilized with computing systems that do not utilize virtual machine instances.

In the example data center shown in a router may be utilized to interconnect the servers and . Router may also be connected to gateway which is connected to communications network . Router may manage communications within networks in data center for example by forwarding packets or other data communications as appropriate based on characteristics of such communications e.g. header information including source and or destination addresses protocol identifiers etc. and or the characteristics of the private network e.g. routes based on network topology etc. . It will be appreciated that for the sake of simplicity various aspects of the computing systems and other devices of this example are illustrated without showing certain conventional details. Additional computing systems and other devices may be interconnected in other embodiments and may be interconnected in different ways.

It should be appreciated that the network topology illustrated in has been greatly simplified and that many more networks and networking devices may be utilized to interconnect the various computing systems disclosed herein. These network topologies and devices should be apparent to those skilled in the art.

It should also be appreciated that data center described in is merely illustrative and that other implementations might be utilized. Additionally it should be appreciated that the functionality disclosed herein might be implemented in software hardware or a combination of software and hardware. Other implementations should be apparent to those skilled in the art. It should also be appreciated that a server gateway or other computing device may comprise any combination of hardware or software that can interact and perform the described types of functionality including without limitation desktop or other computers database servers network storage devices and other network devices PDAs tablets cellphones wireless phones pagers electronic organizers Internet appliances television based systems e.g. using set top boxes and or personal digital video recorders and various other consumer products that include appropriate communication capabilities. In addition the functionality provided by the illustrated modules may in some embodiments be combined in fewer modules or distributed in additional modules. Similarly in some embodiments the functionality of some of the illustrated modules may not be provided and or other additional functionality may be available.

The capacity of purchased computing resources provided by data center can be scaled in response to demand. In this regard scaling refers to the process of instantiating which may also be referred to herein as launching or creating or terminating which may also be referred to herein as de scaling instances of computing resources in response to demand. In this manner the capacity of resources purchased by a customer of data center can be scaled on demand.

Auto scaling is one mechanism for scaling computing resources in response to increases or lulls in demand for the resources. Auto scaling allows customers of data center to configure data center to scale their purchased computing resources according to conditions defined by the customer. For instance rules may be defined for scaling up capacity in a particular manner in response to the occurrence of specified conditions such as a spike in demand. Similarly rules might also be defined to scale down capacity in a particular manner in response to the occurrence of other conditions such as a lull in demand. The mechanisms disclosed herein for launching virtual machine instances might be utilized when instances are manually launched by a customer or when instances are launched by an auto scaling component in data center .

Data center may also be configured with a deployment component to assist customers in the deployment of new instances of computing resources. The deployment component may receive a configuration from a customer that includes data describing how new instances should be configured. For example the configuration might specify one or more applications or software components that should be installed in new instances provide scripts and or other types of code to be executed in new instances and other types of information. The deployment component utilizes the customer provided configuration to launch and configure customer workloads on computing resources.

Various aspects of the disclosure are now described with regard to certain examples and embodiments which are intended to illustrate but not to limit the disclosure. It should be appreciated that the subject matter presented herein may be implemented as a computer process a computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types.

Those skilled in the art will also appreciate that the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described herein including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants e readers cellular telephone devices special purposed hardware devices network appliances and the like. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

In the following detailed description references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific embodiments or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures.

In a distributed computing environment it is desirable to test computing configurations by iterating through various settings in a controlled way to determine optimal test settings for a particular computing configuration and software application. When new hardware and software configurations are added to an environment such as a data center for example fleet fragmentation can result and the overall ability of the computing environment to meet performance goals and manage capacity can be compromised. By thoroughly testing hardware and software configurations it is possible to achieve greater integration of the computing configuration into the computing environment s products and services. And by testing a variety of configurations a given set of hardware and software may be determined to be able to support a number of computing services. Pools or groupings of computing resources can be identified based on such capabilities and maintained based on frequently used settings and configurations.

When a customer requests verification and or analysis of a particular software application a service in the data center such as verification and analysis system of that is implemented in one or more computing devices may be invoked. Verification and analysis system may in conjunction with other services be configured to determine suitable computing resources that can potentially accommodate the verification and analysis initiate a workflow to perform the verification and analysis and report the results to the customer. The results may also be made available to other customers who may request similar tasks.

In various embodiments a verification and analysis system such as verification and analysis system of may be implemented in one or more computing devices and configured to receive requests to verify and or analyze a software application. Verification and analysis system can be implemented across several computing devices or on one computing device.

Verification and analysis system may create workflows to perform the verification and analysis tasks on specific resources i.e. servers . Verification and analysis system may also be configured to optimize the placement of verification and analysis tasks based on various factors such as minimization of disruption to existing services.

In some embodiments verification and analysis system may be configured to interact with other computing environment services such as a fleet management service and a configuration management service to provide the above described capabilities. For example when a request for a verification and analysis task is received the configuration management service can identify one or more servers available for performing the verification and analysis task. Verification and analysis system may perform the verification and analysis task and utilize the available servers to instantiate virtual machines and other resources.

In some embodiments verification and analysis system may be configured to include an expert system and a knowledge base to provide a decision making capability regarding the verification and analysis tasks. The expert system can consider benchmarks or metrics such as system throughput processor utilization and network bandwidth. Furthermore verification and analysis system may employ one or more fitness functions to determine how close a given input is to achieving one or more verification objectives. The fitness function may be used to perform permutation testing and determine optimal test inputs. In one embodiment functions such as a genetic algorithm may be used as a search heuristic to efficiently execute searches for satisfactory test inputs.

When a change is implemented in a computing environment such as data center it is desirable to analyze affected software applications and perform one or more tests to verify that the change provides the functionality associated with the change and that the computing environment otherwise continues to function as expected and meets predetermined metrics or benchmarks. Changes that may be analyzed and tested can include for example hardware or software changes firmware changes or changes in a configuration or arrangement such as a change in the network topology. It can be appreciated that analysis and testing may be desirable in response to any number of changes within or outside the computing environment. The principles described herein are applicable to any situation where analysis and testing in a computing environment is desirable.

A user may send a request for a verification task to verification and analysis system via server . Verification and analysis system may interact with capacity management service to request resources for the task. Capacity management service may interact with configuration service to identify requirements for configuring an available server computer that can support the requested verification task. For example requirements may include device hardware and any software or firmware that needs to be installed or execution of a test to verify that a virtual computing instance of a particular type can function with updated computing configuration. The information may also indicate when evaluation tasks can be performed. For example the information may include an evaluation schedule that minimizes potential disruptions to existing services being provided to customers.

Many computing environments such as data centers are large and complex and can include a vast number of interconnected devices. Technologies such as virtualization can increase the complexity. Computing environments thus may include a mix of various types of data flowing through both virtual and physical components. Computing devices such as servers and routers may have complex interactions and behaviors in one area can affect the performance of the entire computing environment. Changes in the computing environment should therefore be analyzed and tested not only in its local environment but in conjunction with other devices in the computing environment to ensure that the computing environment on the whole provides an expected level of performance. Furthermore the tests should be repeatable and relevant to metrics or benchmarks of interest. Metrics or benchmarks may include performance metrics that indicate how the computing environment performs under load. Performance metrics are useful for capacity planning and ensuring customer satisfaction. Such performance metrics may include throughput latency and frame loss.

As the number of computing devices in a computing environment increases the scope of potential parameters test interfaces and performance metrics may increase dramatically. This makes it extremely difficult for test administrators and planners to analyze the configurations and parameters to identify a set of tests that can verify changes and satisfy applicable performance metrics.

Various aspects of the disclosure are now described with regard to certain examples and embodiments which are intended to illustrate but not to limit the disclosure. Determinism wherein program execution has a repeatable and well defined sequence of cause and effect can provide a predictable model for developers. Increasingly hardware and service providers have relaxed requirements for determinism for the sake of efficiency by providing features such as multi core processors and distributed services. These features may permit developers to build scalable applications but may also introduce data races and other sources of program errors. Many programming languages provide synchronization primitives or other techniques for rationally handling non deterministic program conditions. These techniques may require advanced development skills or be costly to retrofit to an existing program.

In various embodiments disclosed herein a computing environment such as data center of may implement a framework such as verification and analysis system of . Verification and analysis system may implement a deterministic container model that can be used to simplify the detection and handling of non deterministic conditions in distributed services. In one embodiment an application can be divided into a plurality of execution spaces. Each execution space may operate independently on a portion of the application. The execution spaces can be referred to herein as containers. Relationships between the containers may be defined by the container model and can enforce determinism constraints between containers.

In some embodiments a policy element may describe access permissions for nondeterministic input sources. For example a policy element may grant or deny permission to access an input source. The request to access an input source may be sent from one or more containers. A container may access nondeterministic input sources by sending requests through other containers. A policy element may describe ordering or access constraints for such requests.

In one embodiment a policy element may describe responses to determinism violations as may be described in the same or other policy elements. For example when a violation of a determinism policy is detected a policy element may specify that the container should be deleted or otherwise destroyed or that the container should be attached to a debugger. In some embodiments a policy element may specify a causal ordering policy in response to a violation of a determinism policy. Such an ordering policy may describe a fixed order of resolution for nondeterministic events allowing determinism to be effectuated without interrupting program execution. For example an ordering policy may provide a repeatable order for performing read and write operations so that executing the program repeatedly with the same inputs always provides the same outputs.

In other embodiments a policy element may specify that execution of a program should be halted in some cases because an ordering policy may not resolve race conditions depending on the particular set of inputs. For example an ordering policy may not be suitable for secure processing or other sensitive operations that may rely on specific determinism guarantees.

Referring again to a mechanism for enforcing determinism may include a program launch configuration store storing thereon one or more launch configurations describing the program environment. A program launch configuration may for example include information for creating or provisioning resources needed to run a thread process application or other unit of execution specified by policy to have a determinism boundary. For example a program launch configuration may specify how to create a virtual machine to run an application describe file system resources used by the application or provide similar instructions for resource provisioning.

A mechanism for enforcing determinism may also include deterministic containers and which may be referred herein singularly as a container or in the plural as the containers configured to enforce determinism boundaries. It will be appreciated that some embodiments may involve additional containers. In one embodiment containers may be arranged as an acyclic directed graph of container relationships. The acyclic graph may be defined for example by the creation of program units through operating system functions such as fork or exec or through hypervisor functions such as launching new applications or services. These functions may be hooked trapped or virtualized in the operating environment so as to cause the creation of deterministic containers rather than continuing to execute their usual functions. For example a first container may be created as a root or entry point container. As new processes are initiated a decision can be made as to whether the new process should be included in the current container or whether a new container should be created. The policy elements can be used to make this determination. A container may comprise one virtual machine or multiple virtual machines.

The containers may include program modules configured to control program execution within respective containers. The program module may be based at least in part on launch configuration information from program launch configuration store .

Containers may include private work sets controlling ephemeral program storage. The private work sets may include memories file systems or other isolated storage areas accessible by the program module. The contents of private work sets may be identified by a private identifier space specified by program modules such as process identifiers memory addresses or file names that are decoupled from similarly named entities created by other program modules. The initial contents of one of the private work sets may be based at least in part on others of the private work sets owned by the container s parent according to the acyclic graph by branching the contents of the parent work set. For example in container may be the parent for containers and . Container may be the parent for containers and . The parent and child containers may exchange updates to their private work sets through PUT and GET operations on named entities. When a child container is destroyed the parent may inspect and incorporate portions of the remaining data by merging the contents of the child s work set. It can be appreciated that containers may include software hardware or a combination thereof.

Policy elements may determine whether changes in private work sets can be viewed by other containers. If a container has been demonstrated to be safe i.e. there are no non deterministic behaviors or all non deterministic behaviors have been addressed then a privilege log may indicate that the container is allowed to interact with other containers. In one embodiment containers may only communicate between directly spawned containers i.e. between parent and children containers.

Containers may be configured to directly access one or more nondeterministic input sources such as external web services databases or storage services as specified by determinism policies. Such direct access links may permit the containers to copy data between a nondeterministic input source and private work sets .

Containers may log modifications to the private work sets . Containers may include policies to trigger log replication or the exchange of updates to their private work sets. For example containers may include a policy to flush the log when it reaches a determined size. As another example containers may include a policy to flush the log based on the age of the oldest log entry. Containers may checkpoint the log to batch together modifications to the private work sets or may permit exchanging updates in a different order than logged. Containers may send invalidation notifications to their parent and or child containers to maintain partial coherency in response to changes to the private work sets .

Containers may be configured to trap GET PUT operations between a parent container and child container and delay reorder or otherwise mutate the operation requests to enforce determinism or to apply ordering policies. Containers may be configured to check for determinism violations when a GET PUT occurs. For example container may verify that there are no non deterministic orderings of reads and writes such as race conditions through GET PUT operations. Containers may apply determinism policies such as terminating the container or applying a fixed ordering when a determinism violation is detected.

Containers may be configured to trap file system requests network requests or other attempts to access data outside the private work set by the program module. Containers may marshal the trapped requests to a suitable container to complete the operation. For example a container may be configured to follow the acyclic graph to locate the nearest ancestor container permitted to access the requested nondeterministic resource. Container may marshal the request to the ancestor container for execution. The ancestor container may incorporate the results of the request into its private work set and perform GET PUT operations to propagate the results to descendent containers along the acyclic graph until they reach the original container.

When a non deterministic behavior occurs the behavior can be logged. Additionally and optionally the behavior can cause the program to be aborted and a debugger can be launched. Alternatively an artificial ordering can be imposed and recorded.

Various aspects of the disclosure are now described with regard to examples and embodiments for constraint verification. Application verification is one process for determining that an implementation accurately reflects the conceptual specification of an application developer. Rigorous verification such as examining many or all code paths of the application as opposed to running select test cases may be feasible for simple deterministic applications. When the number of code paths is manageable code paths may be enumerated for testing against a constraint specification. Distributed applications that may exhibit non determinism and distributed message passing may create numerous variant code paths that can grow exponentially in terms of the number of program statements. Traditional analysis may thus be infeasible to complete in a reasonable amount of time and within reasonable cost constraints.

The present disclosure describes various embodiments for performing constraint analysis by using a virtualized version of a distributed application. In one embodiment ordinary application message passing may be encapsulated with an envelope format that includes the application data as well as condition variables for program analysis. Redundantly derived message exchanges may be collapsed into a single exchange with combinations of the condition variables. In some embodiments portions of the distributed application may be instanced to perform analyses in parallel.

Referring again to a launch configuration store may store thereon a plurality of application modules and at least one virtual environment specification for executing the application modules. An application module such as virtual application modules in may comprise source code binary executables scripts or other data operable to exercise the application. A virtual environment specification may include descriptions of how to create or provision private copies of resources such as virtual machines storage spaces databases or other computing resources used by the application modules.

Constraint verifiers may be configured to perform symbolic analysis or logical analysis of an application module running inside a virtual environment. Constraint verifiers may include storage for analysis states derived during the analysis. Analysis states may be consulted when exchanging application messages between constraint verifiers .

An envelope format may be used to support the exchange of verification messages between constraint verifiers . The envelope format may include one or more application messages produced by virtual application modules and one or more condition variables describing a portion of the analysis states related to the application messages . The envelope format may include additional metadata such as routing data for directing the delivery of a plurality of application messages in a batch to different portions of the application. In some embodiments the envelope format may support externalized entity references. For example the same application message may be sent multiple times under different program conditions. The envelope format may replace the repeated application message with an identifier operable to allow constraint verifier to retrieve the original application message.

In one embodiment constraint verifiers may access launch configuration store and instantiate a plurality of virtualized application modules . Constraint verifiers may use launch configuration information from launch configuration store to provision private copies of virtual machines storage spaces or other resources needed to execute virtualized application modules . Constraint verifiers may initialize an analysis engine running either inside the virtual environment or acting as a hypervisor for the virtual environment with one or more constraints from constraint specification store .

Constraint verifiers may be configured to analyze the program until a branch or other multivariate condition is reached. Constraint verifiers may create condition variables to augment analysis states at the branch point. Condition variables may include for example logical expressions of program variables. For example for an IF THEN ELSE branch constraint verifiers may create a Boolean condition variable whose value reflects whether program execution takes the THEN branch or the ELSE branch. As additional examples constraint verifiers may create condition variables whose value reflects the choice in a switch statement the completion of a loop iterator or the nondeterministic acquisition of a lock.

In one illustrative embodiment a first one of constraint verifiers may transmit an application message encapsulated in an envelope format to a second one of constraint verifiers . The second constraint verifier may be verifying for example a virtual application module operable to process application message . The envelope format may include application message and logical expressions representing program variables and condition variables . One of the constraint verifiers may batch multiple application messages into one encapsulated message or replace at least a portion of application message with entity references to reduce the size of the transmitted messages.

The second constraint verifier may analyze the program until it is ready to transmit a second application message to the first constraint verifier. The second constraint verifier may aggregate multiple code paths leading to a second application message. For example if a first code path with condition variable A leads to sending an application message and a second code path with condition variable B leads to sending the same application message the second constraint verifier may send the application message once with a combined condition based on the predicate A or B. The second constraint verifier may simplify or reduce logical expressions representing program variables and condition variables for the second application message as may be inferred from the combined condition. For example the second constraint verifier may reduce expressions involving condition variable A and integer program variable X where A and X

The second constraint verifier may relax logical expressions to promote simplification or reduction. For example the second constraint verifier may reduce expressions involving condition variable A and integer program variable X where X

Subsequent to receiving the second application message the first constraint verifier may complete verification of the program. The first constraint verifier may use the simplified or reduced expressions from the second application message to coalesce multiple code paths arising from nondeterministic execution of the program or nondeterministic application message processing. The first constraint verifier may update its analysis state to cancel outstanding requests covered by the second application message.

Constraint verifiers may perform at least a portion of the analyses in parallel. For example a first one of the constraint verifiers and a second one of the constraint verifiers may perform their respective analyses in parallel in separate virtual environments. As another example multiple copies of a virtual application module may be instantiated and analyzed in parallel. The multiple copies may perform periodic synchronization of their analysis states to eliminate duplicate code paths or application messages generated in common between the constraint verifiers. The synchronization may replicate the outstanding requests of each of the constraint verifiers so that either copy may process responses to the requests.

Upon completion of the analysis an output may be provided that indicates e.g. TRUE or FALSE whether the property of interest has been verified. The analysis may be performed more than once in order to achieve a desired or predetermined level of confidence in the results. If the property of interest could not be verified then counterexamples can be provided to demonstrate conditions which violate the property of interest.

Various aspects of the disclosure are now described with regard to examples and embodiments applicable to fuzz testing. Fuzzing or fuzz testing is a software testing methodology in which random input data is used to test a computer application. Fuzzing may be used to identify unexpected or exceptional conditions. Security fuzzing is the process of subjecting a program to various input permutations for the purpose of detecting security vulnerabilities. Traditional fuzzing approaches use blackbox fuzzing randomly mutating an initial program input to generate additional test inputs and running the program with the additional inputs. In whitebox fuzzing the initial program inputs are mutated by symbolically evaluating portions of the program to identify unexecuted code paths. Symbolic evaluation can be a time consuming part of the fuzzing process thus constraining the number of test cases that may be considered. In particular distributed message passing and nondeterministic program execution may create enormous numbers of program code flow variations that limit the utility of whitebox fuzzing under such conditions.

The present disclosure describes various embodiments for pruning the number of program code flow variations created by non determinism and message passing through the use of virtualized program execution. In one embodiment a program under analysis may be divided into multiple program execution units or containers. Each program execution unit may be executed inside a virtual environment which permits adjustment of the program s non deterministic behaviors. Symbolic evaluation of the execution units may be performed to generate test inputs for the program. Redundant or non productive portions of the input space may be pruned by collapsing messaging interactions between the program execution units and dynamically adjusting the determinism of program execution.

Referring to the fuzzer subsystem may perform symbolic evaluation of at least some of the program execution units to gather constraints for reaching unexecuted portions of the program. For example the fuzzer subsystem may construct a constraint specification specifying expected program execution constraints and symbolically evaluate a program execution unit to detect conditions under which the constraint specification may be violated. Program execution constraints may include constraints on the possible range of values for a variable constraints to always execute or to never execute a particular portion of the program constraints to send a particularly formatted message and the like. The fuzzer subsystem may collect additional constraints for program execution based at least in part on the violated specification.

The fuzzer subsystem may create a plurality of expressions negating the additional constraints. The fuzzer subsystem may select a plurality of subsets of a set of the additional constraints. For each selected subset the fuzzer subsystem may construct an expression wherein the additional constraints included in the subset are satisfied and the additional constraints not included in the subset are not satisfied. The constructed expression may incorporate at least part of an expression corresponding to the constraint specification for the initial input.

In one embodiment the fuzzer subsystem may create a search tree of program inputs by constraint solving the plurality of expressions. The fuzzer subsystem may solve each constructed expression to generate new program inputs whose execution is expected to satisfy the subsets of additional constraints.

The fuzzer subsystem may identify at least a portion of search tree nodes whose behavior is identical up to the order of execution. For example the fuzzer subsystem may execute at least some of the program execution units in a virtualized environment to identify inputs whose behavior is identical up to a nondeterministic race condition. The fuzzer subsystem may execute the program execution units with one of the inputs detect a collection of nondeterministic access operations during the execution apply a hash function to the detected collection and compare the hash result to the hash results of the other inputs to identify aliased inputs .

The fuzzer subsystem may adjust program determinism to replace the portion of search tree nodes with a single source tree node with a fixed order of execution. The fuzzer subsystem may construct a determinism policy for the virtualized environment that enforces a particular desired order of execution based at least in part on the collected nondeterministic access operations.

The fuzzer subsystem may recursively analyze the single source tree node and select new candidate inputs . The fuzzer subsystem may continue to construct the constraint specification corresponding to the program input for the single source tree node and symbolically evaluate at least some of the program execution units to gather constraints for reaching unexecuted portions of the program. If the fuzzer subsystem determines that the unexecuted portions of the program have been reached or that the program has been tested to a predetermined threshold then testing can be completed and the findings reported .

In some embodiments the test environment may maintain a database of information for tracking data related to the execution and analysis activities and use search algorithms to identify a set of test inputs for fulfilling the objectives of the test. As the complexity of the testing environment and the complexity of a program increases the search space of possible test inputs can grow exponentially. In some cases it may be difficult or impossible to identify a finite number of test conditions within a reasonable time and cost constraints that can completely verify a program. In some embodiments the search space may be analyzed to identify a candidate set of test inputs that satisfies a set of criteria or constraints. In one embodiment the candidate set of inputs may comprise a subset of possible test inputs that satisfy the criteria or constraints in accordance with a fitness function.

In some embodiments one or more metrics or benchmarks for evaluating the fitness of a test input can be identified. Verification and analysis system can be used to generate test inputs to optimize the level and scope of verification within a set of constraints. Once a set of test inputs has been generated verification and analysis system may cause the automatic execution of the test and analysis activities on one or more computing devices in the test environment. In an embodiment the computing devices may be selected by mapping samples of the search space to available computing resources and running tests on the computing resources. Additionally the results of an initial set of tests can provide feedback to verification and analysis system and can be used to determine a new set of test conditions to further optimize the test inputs.

As discussed above a fitness function can be used to determine a set of test inputs. Any one of various fitness functions that can determine the closeness of a candidate solution to an objective can be used. A genetic function is one example of a heuristic search function that can be used for search and optimization of the test inputs.

In one embodiment candidates can be selected based on biasing to influence the selection. For example the data in the sample space can be weighted to indicate relevance of the parameters to one or more metrics thus resulting in an increased likelihood of optimizing around the selected metrics.

In various embodiments verification and analysis system may employ probabilistic methods to guide and narrow the selection of test inputs. In order to provide test results that more thoroughly cover the potential flows through a program the most relevant test inputs should be selected. However the complexity of distributed computing environments with hundreds or thousands of networked devices may preclude a deterministic or exhaustive solution. In some embodiments a heuristic model can be used to find satisfactory solutions that provide an acceptable confidence level in the results. For example experience based techniques such as expert modeling can be used to aid initial selection of inputs. The heuristic model can probabilistically indicate parameters of likely impact through for example tagging various metadata related to a particular metric. Feedback from an initial round of tests can be used to further refine the initial selection thus implementing a closed loop system that generates high impact tests in situations where programmatic or rigorous approaches may be impractical or infeasible. As an example Markov modeling or variations thereof e.g. hidden Markov model and hierarchical hidden Markov model can be used in some embodiments to identify solutions that may otherwise be missed using traditional methods. Monte Carlo methods finite element analysis and computational fluid analysis can also be used to generate results in various embodiments.

In many computing environments the amount of resources available for testing may be limited at any given time. For example in a typical data center the majority of resources may continuously be in use in order to provide services for customers. In some embodiments verification and analysis system may interact with a fleet management system. For example referring to verification and analysis system may interact with a capacity management service to identify spare or otherwise usable computing resources for hosting virtual machines for analysis and testing. Additionally the inputs selected for testing and analysis can be based on availability of spare resources and the configuration of the spare resources. For example the available test resources may include configurations that deviate from a desired test configuration. The variances in the configurations of test resources from the desired test configurations may be considered in generating a best available solution and update the test inputs.

In some embodiments verification and analysis system may interact with a configuration service that may be implemented in the computing environment and configured to manage configurations. Configuration service may create and manage workflows and map configurations to computing devices in the computing environment. The configuration management system can be part of a test workflow for verifying performance and operation of various configurations.

Verification and analysis system may interact with configuration service and map desired configurations to available configurations in the computing environment. The available test resources may be evaluated to determine the particular configurations that are implemented on the test resources. The configurations that need to be changed to conform to the desired test configurations may be evaluated to determine the scope of required changes and the cost associated with updating the test resources. The cost associated with updating the test resources may be balanced against the value of implementing the exact desired configurations to determine if the configurations should be implemented. Verification and analysis system may thus incorporate a cost evaluation mechanism that uses cost thresholds to determine if available configurations are sufficiently close to the desired configurations and if the costs associated with updating the configurations will provide results of sufficient value. The information from the cost evaluation mechanism may be provided as additional input to the search algorithms to identify an optimized set of test inputs that considers cost thresholds. In one embodiment verification and analysis system may interact with configuration service to determine available test resources and integrate information regarding available configurations and costs associated with the available configurations to achieving a desired population state and determine and adjust the next set of tests.

By interacting with a fleet management infrastructure that may include configuration management service and other fleet management subsystems verification and analysis system can determine costs associated with loss of revenue when candidate test resources are pulled from production. The cost of removing a particular candidate resource from production can be determined based on current market conditions for the services provided by the resource. This cost can be compared to the value of testing the particular set of conditions to determine if the benefit of testing exceeds the cost of pulling the resource. For example a current cost per minute of pulling a resource and the expected time to conduct a set of tests may be determined. If the current cost per minute falls below a predetermined level the verification and analysis system can occupy the resource and conduct the tests.

Referring to operation begins the operational procedure. Operation may be followed by operation . Operation illustrates that an application program for execution in a distributed computing environment is received.

Operation may be followed by operation . Operation illustrates that the application program is divided into a plurality of independently executable components. In some embodiments the dividing may be performed on in accordance with one or more determinism policies. Additionally the executable components may be separately executable as independent processes.

Operation may be followed by operation . Operation illustrates executing the components in a plurality of virtual machines. In some embodiment the virtual machines are configured to independently execute one of the components. The components may be executed using one or more shared states. Additionally relationships between the components may be defined by one or more determinism policies.

Operation may be followed by operation . If a non deterministic event has not occurred between at least two of the virtual machines in accordance one or more determinism policies then operation may be followed by operation .

If a non deterministic event has occurred between at least two of the virtual machines in accordance one or more determinism policies then operation may be followed by operation . Operation illustrates modifying the non deterministic event in order to effectuate a deterministic result. Operation may be followed by operation .

Referring to operation begins the operational procedure. Operation may be followed by operation . Operation illustrates receiving an application program for execution in a distributed computing environment. Operation may be followed by operation . Operation illustrates dividing the software application into a plurality of components. In one embodiment the software application may be divided in accordance with one or more constraints. Furthermore the components may be executable as independent processes.

Operation may be followed by operation . Operation illustrates instantiating a plurality of virtual machines and executing the plurality of independently executable components in the plurality of virtual machines. Operation may be followed by operation . Operation illustrates generating condition variables based on execution of the components.

Operation may be followed by operation . Operation illustrates determining that application program data is to be communicated between at least two of the components. If application data is to be communicated between at least two of the components then operation may be followed by operation . Operation illustrates generating routing information for the application program data.

Operation may be followed by operation . Operation illustrates generating a data packet that encapsulates the application program data. In one embodiment the data packet may include associated condition variables and data path information.

Operation may be followed by operation . Operation illustrates sending the data packet to a destination virtual machine for the data packet. Operation may be followed by operation . Operation illustrates aggregating application program data from multiple communication events and combining respective condition variable and data path information.

Operation may be followed by operation . Operation illustrates verifying a runtime property of the application program by using the aggregated application program data to represent code execution paths of the application program. Operation may be followed by operation .

If application data is not to be communicated between at least two of the components then operation may be followed by operation .

Referring to operation begins the operational procedure. Operation may be followed by operation . Operation illustrates receiving an application program operable to execute in a distributed computing environment.

Operation may be followed by operation . Operation illustrates parsing the application program. In an embodiment the parsing can be performed in accordance with one or more verification constraints. Operation may be followed by operation . Operation illustrates dividing the application program into a plurality of independently executable components. In an embodiment the components may be executable as independent processes.

Operation may be followed by operation . Operation illustrates determining an initial set of test inputs to the independently executable components. Operation may be followed by operation . Operation illustrates instantiating a plurality of virtual machines and executing the independently executable components in respective ones of the virtual machines.

Operation may be followed by operation . Operation illustrates determining that a non deterministic event has occurred between at least two of the virtual machines. If a non deterministic event has occurred between at least two of the virtual machines the operation may be followed by operation . Operation illustrates modifying a non deterministic event in order to effectuate a deterministic result in accordance with one or more determinism policies. If a non deterministic event has not occurred between at least two of the virtual machines the operation may be followed by operation .

Operation illustrates determining that application data is to be communicated between at least two of the virtual machines. If application data is to be communicated between at least two of the virtual machines then operation may be followed by operation . Operation illustrates generating a data packet that encapsulates the application data along with associated condition variables and routing information. Operation may be followed by operation . Operation illustrates sending the data packet to a destination for the data packet. Operation may be followed by operation . Operation illustrates aggregating application data and combining respective condition variable and data path information. Operation may be followed by operation .

If application data is not to be communicated between at least two of the virtual machines then operation may be followed by operation .

Operation illustrates verifying the one or more verification objectives by using aggregated data packets to represent code execution paths. Operation may be followed by operation . Operation illustrates iteratively generating new test inputs based on the verifying until the one or more verification objectives are validated.

Each of the processes methods and algorithms described in the preceding sections may be embodied in and fully or partially automated by code modules executed by one or more computers or computer processors. The code modules may be stored on any type of non transitory computer readable medium or computer storage device such as hard drives solid state memory optical disc and or the like. The processes and algorithms may be implemented partially or wholly in application specific circuitry. The results of the disclosed processes and process steps may be stored persistently or otherwise in any type of non transitory computer storage such as e.g. volatile or non volatile storage.

The various features and processes described above may be used independently of one another or may be combined in various ways. All possible combinations and subcombinations are intended to fall within the scope of this disclosure. In addition certain method or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence and the blocks or states relating thereto can be performed in other sequences that are appropriate. For example described blocks or states may be performed in an order other than that specifically disclosed or multiple blocks or states may be combined in a single block or state. The example blocks or states may be performed in serial in parallel or in some other manner. Blocks or states may be added to or removed from the disclosed example embodiments. The example systems and components described herein may be configured differently than described. For example elements may be added to removed from or rearranged compared to the disclosed example embodiments.

It will also be appreciated that various items are illustrated as being stored in memory or on storage while being used and that these items or portions of thereof may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively in other embodiments some or all of the software modules and or systems may execute in memory on another device and communicate with the illustrated computing systems via inter computer communication. Furthermore in some embodiments some or all of the systems and or modules may be implemented or provided in other ways such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the modules systems and data structures may also be stored e.g. as software instructions or structured data on a computer readable medium such as a hard disk a memory a network or a portable media article to be read by an appropriate drive or via an appropriate connection. The systems modules and data structures may also be transmitted as generated data signals e.g. as part of a carrier wave or other analog or digital propagated signal on a variety of computer readable transmission media including wireless based and wired cable based media and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly the present invention may be practiced with other computer system configurations.

Conditional language used herein such as among others can could might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While certain example embodiments have been described these embodiments have been presented by way of example only and are not intended to limit the scope of the inventions disclosed herein. Thus nothing in the foregoing description is intended to imply that any particular feature characteristic step module or block is necessary or indispensable. Indeed the novel methods and systems described herein may be embodied in a variety of other forms furthermore various omissions substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions disclosed herein. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of certain of the inventions disclosed herein.

