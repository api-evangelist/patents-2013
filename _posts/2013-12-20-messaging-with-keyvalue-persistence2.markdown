---

title: Messaging with key-value persistence
abstract: Techniques are described for providing a messaging service that employs a distributed key-value store for message persistence. On receiving a message to be enqueued for subsequent delivery, a message identifier is generated and employed as a key to store the message in the key-value store. The message identifier may be generated based on an available location in a message tracking data structure. In some cases, the message tracking data structure may be an append tree data structure that is substantially self-balancing as an increasing number of messages are tracked using the append tree data structure. The message tracking data structure may be further employed to determine a message identifier for a message to be vended from the key-value store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09578120&OS=09578120&RS=09578120
owner: Amazon Technologies, Inc.
number: 09578120
owner_city: Reno
owner_country: US
publication_date: 20131220
---
A computing environment may employ a messaging system to send store and deliver messages between entities within the computing environment where such entities may include users processes and computing devices. In many cases messaging systems may not scale efficiently and may exhibit degradations in the quality of service as the number of processed messages increases.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

This disclosure describes implementations of systems devices methods and computer readable media for providing a messaging service that employs a key value store for storing messages. In implementations messages may be received from one or more message generating entities stored in a key value store and delivered to one or more message consuming entities. The message generating entities and message consuming entities may include one or more computing devices one or more processes executing on the computing device s or one or more users. In some cases the messages may carry data that is exchanged between hardware or software components within a computing environment.

Implementations support an Application Programming Interface API that includes at least three callable methods enqueue dequeue and ack. The callable methods of the API may be employed by message generating or message consuming entities to request storage retrieval or deletion of messages from the key value store. The enqueue method may be employed by entities to request the storage of a message and may include the message as a parameter. The dequeue method may be employed by entities to request one of the stored messages and may return a message along with a message identifier ID corresponding to the message. The ack method may be employed by entities to request the deletion or removal of a message from storage and may include the message ID as a parameter. Table 1 provides example signatures or declarations for the three methods.

In some implementations the stored messages may be delivered to requesters approximately in an order in which the messages were received and stored. A particular message may be delivered to any number of message consuming entities in response to any number of dequeue requests until an ack request is received to delete the message from storage. Because the ack request includes the message ID for the message to be deleted and the message ID is provided with the delivery of the message in response to a dequeue request the message may not be deleted until it has been delivered to at least one message consuming entity. Accordingly implementations provide a guaranteed messaging system in which each received message is delivered at least once prior to being deleted.

Implementations support the handling of messages to be stored in any number of queues and to be delivered e.g. vended out of the queue s . A message may be received in an enqueue request and the message may include a queue ID indicating a particular queue in which the message is to be stored. In some implementations a queue may be logically divided into a plurality of partitions and each partition may be managed by a different messaging server device at any particular time. On receiving a message to be stored a messaging server device may select a partition to be used for managing the message. The messaging server device may access a message tracking data structure that provides a namespace for message identifiers of messages that are managed using the partition. Based on a next available location in the message tracking data structure a message ID may be designated for the message. The message ID may then be employed as a key to store the message in a key value store. An enqueue ID may track the next available location in the message tracking data structure the next available location to be used as a next message ID for storing a subsequently received message. Implementations support the use of any type of data structure for the message tracking data structure. In some implementations the message tracking data structure is an append tree data structure that is substantially self balancing and that may be traversed efficiently.

Implementations may also provide a dequeue ID indicating a location in the message tracking data structure corresponding to a message that may be delivered. On receiving a request for a message e.g. a dequeue request a message handing device may employ the dequeue ID to determine a message ID corresponding to a message that may be vended to the requesting entity. The message ID may then be used as a key to retrieve the message from the key value store. On receiving a request to delete a message e.g. an ack request the message ID included in the request may be used as a key to remove the message from the key value store. By employing a key value store implementations may provide for a guaranteed messaging service that scales reliably e.g. that provides an appropriate quality of service as the number of managed messages increases. A key value store may be any type of data storage in which any amount of data e.g. any number of bytes of data is stored and associated with a key of any size or data type. The key value store described herein may include but is not limited to an associative array a map a table a hash map a hash table and so forth. In some implementations the key value store may comprise at least a portion of the file system on one or more computing devices. In such cases the file name of a file may be employed as the key to access the contents of the file stored in the file system and the files may store the messages.

The host device s may include host device s that execute one or more message generating processes . The message generating process es may generate one or more message s to be stored and vended as described herein. The message s may be sent to one or more messaging server devices . In some cases the message s may be sent in one or more enqueue requests that each includes a message as a parameter as described above. The messaging server device s may be any type of computing device including but not limited to those types of computing devices described with reference to the host device s . In some cases two or more of the messaging server devices may comprise a cluster cloud farm or other grouping of multiple devices that coordinate operations to provide load balancing failover support parallel processing capabilities shared storage resources or other aspects. The messaging server device s are described further with reference to .

The messaging server device s may execute one or more messaging service modules . The messaging service module s may perform operations to analyze the message s store the message s in a key value store track the message s respond to requests for the message s and remove the message s from the key value store. For example the messaging service module s may process and respond to enqueue dequeue and ack requests regarding the message s . Operations of the messaging service module s are described further with reference to .

In some implementations the messaging service module s may employ a message tracking data structure to track the messages handled by the messaging service module s and to determine a message ID for each of the received message s . Implementations support any type of data structure for the message tracking data structure including but not limited to a table a list e.g. a linked list a tree e.g. a binary search tree and so forth. In some implementations the message tracking data structure may be an append tree data structure that is substantially self balancing. The append tree data structure is described further with reference to . In some implementations the message tracking data structure may be in active or runtime memory e.g. not written to disk on the messaging server device s to enable efficient access to the message tracking data structure .

The messaging server device s may also include in memory an enqueue ID that indicates an available location e.g. a next available location in the message tracking data structure for tracking messages . In some implementations the enqueue ID is a message ID for the next message to be stored in the key value store and the message ID is the file name under which the message may be stored in the key value store . On receiving an enqueue request with a message to be stored and vended the messaging service module s may employ the enqueue ID to determine an available location in the message tracking data structure . A message ID corresponding to the message may be generated based on the available location in the message tracking data structure . The message may be stored in a key value store using the message ID as a key as shown in . The enqueue ID may be advanced to a next available location in the message tracking data structure in preparation for receiving a next message to be stored.

In some implementations the message tracking data structure may be built up and created in memory on the messaging server device s and a copy of the message tracking data structure may also be stored in the key value store . The stored copy of the message tracking data structure may enable message tracking to continue on another messaging server device after the messaging server device fails e.g. crashes or when the management of a queue partition associated with the message tracking data structure passes from one messaging server device to another messaging server device as described further with reference to .

In some implementations where the key value store is at least a portion of the file system of the messaging server device s the message ID may be employed as a file name to store the message in a file within the key value store . Accordingly the message tracking data structure may be employed as a namespacing tool to determine the file name under which to store the message .

The key value store may include any number of data storage devices or data storage services executing on any number of computing devices. Implementations support the use of any type of key value store for storing message s . In some cases the key value store may be managed using an implementation of the Dynamo structured storage system such as the Apache Cassandra database management system provided by the Apache Software Foundation. In some cases the key value store may be managed using DynamoDB developed at Amazon.com of Seattle Wash. USA. Implementations also support other types of the key value store including NoSQL data storage systems or databases such as an associative array a map a table a hash map a hash table and so forth.

As shown in the host device s may also include host device s that execute one or more message consuming processes . The message consuming process es may send one or more message requests to the messaging server device s each message request requesting the delivery of a message that is stored in the key value store . The message request s may be dequeue requests as described above. On receiving a message request the messaging service module s may access a dequeue ID that indicates a location in the message tracking data structure corresponding to the message ID for a message that may be vended. Based on the dequeue ID a message ID may be determined corresponding to the location in the message tracking data structure . A message may then be retrieved from the key value store using the message ID as a key. The retrieved message may then be sent to the message consuming process that sent the message request . The dequeue ID may be advanced to a next location in the message tracking data structure in preparation for receiving a next message request for a message to be vended e.g. sent to a message consuming process . In some implementations the enqueue ID and the dequeue ID may be strings that are maintained in memory e.g. in active memory and that include the message IDs for the next messages that may be enqueued and dequeued respectively.

Although not shown in the messaging service module s may also perform operations to respond to requests to delete message s stored in the key value store . For example the message generating process es the message consuming process es or other entities may send an ack message that includes a message ID as a parameter. The messaging service module s may employ the message ID as a key to delete the corresponding message from the key value store .

Although the host device s e.g. message generating devices and the host device s e.g. message consuming devices are depicted in as separate devices implementations are not so limited. In some cases one or more host devices may operate as both message generating devices and message consuming devices and may execute both message generating process es and message consuming process es . Moreover in some cases one or more processes may operate as both a message generating process and a message consuming process .

Although depicts examples in which a same set of one or more messaging server device s performs operations for storing and vending messages implementations are not so limited. In some implementations the operations of the messaging server device s may be distributed among multiple computing devices that perform various operations. For example depicts an environment in which a messaging server device operates as a load balancing device distributing received messages to be handled by a plurality of messaging server devices that operate as message handling devices. In some cases the messaging server devices may be physically separate computing devices. Alternatively the messaging server devices may be separate virtual servers such as hypervisors virtual machines emulations and so forth executing on one or more computing devices.

In the example of the received message s may each include a queue ID that identifies a queue for storing the message . In some implementations messages may be received to be stored in a plurality of queues. Such queues may correspond to various business or technical operations within an organization. For example a first queue may be employed to track messages that each triggers a notification to be sent to a user e.g. via email text message and so forth . A second queue may be employed to track messages that each triggers an addition of one or more records to a database.

The messaging server device e.g. the load balancing device may execute one or more messaging service modules that include a load balancing module . On receiving the message the load balancing module may determine one of a plurality of messaging server devices e.g. message handling devices to handle e.g. store and or vend the message . In some cases the selection of the messaging server device may be random or may employ a round robin load balancing algorithm to distribute the incoming message s substantially uniformly among the plurality of messaging server devices .

In some implementations each of the messaging server devices may manage message s in a logical partition of the queue identified by the queue ID . The messaging server device s may execute messaging service module s that include a partition router module . If the partition router module is not executing when the message is received an instance of the partition router module may be created and executed. The partition router module may perform operations to determine a partition of the queue to be managed by the messaging server device that received the message . To determine a partition the partition router module may access queue description data that describes the logical partitions associated with one or more queues. Based on the queue ID the partition router module may retrieve from the queue description data queue partition data that describes the one or more partitions associated with the queue.

As shown in the example of the queue description data may be stored on a messaging server device that operates as a messaging information device. Alternatively the queue description data may be stored on the messaging server device s . The queue partition data may include a list of logical partitions associated with a queue. For example for queue ID Q13 the queue partition data may be Q13 p0 p1 p2 p3 p4 indicating that the Q13 queue has five partitions designated as p0 p1 p2 p3 and p4. In some cases the queue partition data for a particular queue may be a particular file among a plurality of files in the queue description data . Based on the queue partition data the partition router module may select one of the partitions of the queue identified by the queue ID if the messaging server device is not currently handling a partition. In some cases the selection may be random. The partition router module may also select one or more backup partitions in case the selected partition is already managed by another messaging server device .

The partition router module may execute an instance of the partition manager module to manage the partition. The partition manager module may enable the messaging server device to manage the partition e.g. to take ownership of the partition or to achieve a lock on the partition. In some cases the messaging server device may manage the partition for a predetermined period of time e.g. 10 seconds . To begin managing the partition the partition manager module may access partition files and open a particular partition file corresponding to the selected partition. The partition manager module may edit the partition file to establish ownership of the partition. As shown in the partition files may be stored on the messaging server device . Alternatively the partition files may be stored on the messaging server devices or elsewhere. Moreover in some implementations the key value store may be incorporated into the messaging server device or into one or more of the messaging server devices .

As shown in the example of in some implementations a same set of one or more messaging server devices may include the queue description data the partition files and the key value store . The key value store may store the message s and the message tracking data structure s corresponding to one or more partitions. In some implementations one or both of the queue description data and the partition files may also be stored in the same key value store as the messages . In some cases the key value store may be at least a portion of the file system of the messaging server device s in which any number of files may be stored and the file names of the files may be employed as keys to access the files. In some implementations the key value store may be a distributed key value store that is distributed among any number of the messaging server devices . For example the key value store may include at least a portion of the file system of multiple messaging server devices . Such a distribution of the key value store may enable scalability of the messaging service.

In some cases the partition router module may receive an ack request to delete a message the ack request specifying the message ID of the message to be deleted. Based on the message ID the partition router module may determine that the message is associated with a partition currently being managed by another messaging server device . The partition router module may then forward the ack request to the other messaging server device that is currently managing the partition.

In some cases an enqueue message including the message may be sent to a messaging server device that is currently managing a partition. The partition router module on the messaging server device may forward the request to another messaging server device that is not currently managing a partition instead of handling the message on the local messaging server device if there is at least one other messaging server device that is not currently managing a partition. Otherwise the local messaging server device may handle the message . In this way implementations may mitigate the chances of a greedy load balancing in which a particular messaging server device may handle a disproportionate number of messages compared to other messaging server devices .

In some cases the partition router module may initiate a cooling period on the messaging server device on which the petition router module is executing. During the cooling period received enqueue requests may be routed to another messaging server device while received dequeue requests may be handled locally. The partition router module may initiate the cooling period based on information received from the partition manager module . For example a cooling period may be initiated based on the number of currently handled messages being higher than a predetermined threshold or based on a failure rate being higher than a predetermined threshold. Implementations also support the use of any other routing techniques to distribute incoming messages among the messaging server devices .

Returning to the partition manager module may analyze the partition file for the selected partition of the queue. If the message handling device ID in the partition file is not null the partition manager module may wait for the time period to expire before attempting again to establish a lock on the partition. In some implementations the partition manager module may save data indicating a time when the partition manager module last attempted to access the partition file . After a particular time period from the last attempt the partition manager module may reattempt the lock. In some cases the time period before the reattempt may be the entire time period . For example a clock on the messaging server device executing the partition manager module may indicate that the current time is 10 30 33 and the time period may be 10 seconds. The partition manager module may in 10 seconds attempt to claim ownership of the partition e.g. at 10 30 43 . In this way implementations may ensure that two or more messaging server devices may not take a lock on the same partition in cases where the clocks of the messaging server devices indicate a different current time e.g. in case of clock skew between devices having uncoordinated clocks . Alternatively in some implementations the clocks of the messaging server devices may be substantially synchronized to reduce the likelihood that two or more messaging server devices may attempt to take a lock on a same partition. In such cases the time period may include an expiration time stamp.

To establish a lock on the partition and begin managing the partition the partition manager module may edit the partition file to identify the messaging server device in the message handling device ID . The partition manager module may also create a new instance of the message tracking data structure in memory e.g. in active runtime memory on the messaging server device by instantiating a first block of the message tracking data structure . The message tracking data structure may also be stored in the key value store and the head pointer may be edited to indicate the file name of the new block file of the newly instantiated message tracking data structure . The partition manager module may also edit the time period .

Having established a lock on the partition the partition manager module may determine a message ID for the received message and employ the message ID as a key to store the message in the key value store . In some implementations the message tracking data structure is an append tree data structure in which each node of the append tree is a block in memory and the block may include a plurality of positions e.g. positions each corresponding to a message ID . The partition manager module may determine an available location in the append tree e.g. a position in a block of the append tree corresponding to the message ID for the message and advance the enqueue ID to a next location in the append tree. Employing the append tree data structure to track message IDs is described further with reference to .

a block start address indicating the start address in memory of the block of the append tree corresponding to the message ID 

a random number to prevent two instances of the partition manager module from writing to a same block and

On receiving additional enqueue request s with additional message s the messaging server device may determine message IDs for the message s based on the message tracking data structure and store the message s in the key value store based on the message IDs . The partition manager module may advance the enqueue ID for each stored message and update the head pointer in the partition file as new blocks are allocated to track messages using the message tracking data structure . In some implementations the head pointer may indicate the block file name for the most recently allocated block of the message tracking data structure .

The messaging server device e.g. the load balancing device may also route dequeue and ack requests to the messaging server devices to substantially balance the load of responding to such requests. On receiving a dequeue request such as the message request the partition manager module may access the message tracking data structure to determine a message ID corresponding to a current value of the dequeue ID and retrieve the message from the key value store based on the message ID . The partition manager module may send the message to the message consuming process that sent the dequeue request and advance the dequeue ID . If the partition manager module determines that there are currently no messages to vend from the partition e.g. based on the dequeue ID being set to an initial value the partition manager module may forward the dequeue request to another messaging server device .

On receiving an ack request that includes a message ID the partition manager module may examine the message ID and determine whether it corresponds to a partition that is currently owned by the partition manager module . If not the partition manager module may examine the partition files to determine which messaging server device is currently managing the partition e.g. based on the message handling device ID and forward the ack request to the appropriate messaging server device . If the partition manager module is currently managing the partition identified in the message ID the partition manager module may employ the message ID to delete the message from the key value store . The partition manager module may also remove the reference to the message ID from its location in the message tracking data structure .

In some implementations the messaging service module s executing on the messaging server device e.g. the message handling device may also include a data structure manager module and a message redelivery module . The data structure manager module may perform operations to manage the message tracking data structure on the messaging server device . For example if the partition manager module requests a new message ID from the message tracking data structure and no location is currently available in the message tracking data structure the partition manager module may allocate a new block in memory and add the new block to the message tracking data structure . This process is described further with reference to . The partition manager module may also perform cleanup operations to remove blocks for which all the message IDs identify messages that have been deleted e.g. in response to ack requests .

The message redelivery module may manage the redelivery of messages that have been delivered in response to dequeue requests but that have not yet been deleted in response to an ack request. In some implementations the message redelivery module may maintain two data structures e.g. two tree structures one organized by message IDs and the other organized by time. Following the delivery of a message in response to a dequeue request the message ID may be moved from one location to another in the time based data structure to ensure that the same message is not redelivered immediately in response to another dequeue request. Following a dequeue request the dequeue ID may be advanced to a next message ID based on information in the time based data structure for redelivery. The ID based data structure may include a reference into the time based data structure for each message that is available for redelivery. The ID based data structure may be sorted by message ID enabling a particular node to be reached efficiently for a particular message ID . On receiving an ack request for a message ID the ID based data structure may be employed to determine the location of the message ID in the time based data structure and the nodes corresponding to the message to be deleted may be removed from both the time based and ID based data structures.

When the lock on a partition that is held by a first messaging server device expires or when the first messaging server device that is managing the partition crashes or otherwise fails a second messaging server device may take a lock on the partition and begin handling messages within that partition. In such cases the second messaging server device may establish a lock on the partition as described above. The second messaging server device may copy the message tracking data structure from the messaging server device s into memory on the second messaging server device beginning with the head block of the message tracking data structure the head block indicated by the head pointer included in the partition file . Having copied the head block into memory the second messaging server device may begin enqueuing newly received messages into the head block. The second messaging server device may then traverse the message tracking data structure copying each block into memory until it reaches the oldest block. The second messaging server device may then begin providing messages in response to dequeue requests.

The various devices of the environments and may communicate with one another using one or more networks. Such networks may include public networks such as the Internet private networks such as an institutional or personal intranet or some combination of private and public networks. The networks may include any type of wired or wireless network including but not limited to local area networks LANs wide area networks WANs wireless WANs WWANs wireless LANs WLANs mobile communications networks e.g. 3G 4G etc. and so forth. In some implementations communications between the various devices in the environments and may be encrypted or otherwise secured. For example such communications may employ one or more public or private cryptographic keys ciphers digital certificates or other credentials supported by a security protocol such as any version of the Secure Sockets Layer SSL or the Transport Layer Security TLS protocol.

The host device may include one or more input output I O devices . The I O device s may include input devices such as a keyboard a mouse a pen a game controller a touch input device an audio input device e.g. a microphone a gestural input device a haptic input device an image or video capture device e.g. a camera or other devices. In some cases the I O device s may also include output devices such as a display an audio output device e.g. a speaker a printer a haptic output device and so forth. The I O device s may be physically incorporated with the host device or may be externally placed.

The host device may include one or more I O interfaces to enable components or modules of the host device to control interface with or otherwise communicate with the I O device s . The I O interface s may enable information to be transferred in or out of the host device or between components of the host device through serial communication parallel communication or other types of communication. For example the I O interface s may comply with a version of the RS 232 standard for serial ports or with a version of the Institute of Electrical and Electronics Engineers IEEE 1284 standard for parallel ports. As another example the I O interface s may be configured to provide a connection over Universal Serial Bus USB or Ethernet. In some cases the I O interface s may be configured to provide a serial connection that is compliant with a version of the IEEE 1394 standard. The host device may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the host device .

The host device may include one or more network interfaces that enable communications between the host device and other network accessible computing devices such as the messaging server device s . The network interface s may include one or more network interface controllers NICs or other types of transceiver devices configured to send and receive communications over a network.

The host device may include one or more memories described herein as memory . The memory comprises one or more computer readable storage media CRSM . The CRSM may include one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium a mechanical computer storage medium and so forth. The memory provides storage of computer readable instructions that may describe data structures program modules processes applications or other data for the operation of the host device . In some implementations the memory may provide storage of computer readable instructions or other information in a non transitory format.

The memory may include an operating system OS module . The OS module may be configured to manage hardware resources such as the I O device s the I O interface s and the network interface s and to provide various services to applications processes or modules executing on the processor s . The OS module may include one or more of the following any version of the Linux operating system any version of iOS from Apple Corp. of Cupertino Calif. USA any version of Windows or Windows Mobile from Microsoft Corp. of Redmond Wash. USA any version of Android from Google Corp. of Mountain View Calif. USA and its derivatives from various sources any version of Palm OS from Palm Computing Inc. of Sunnyvale Calif. USA and its derivatives from various sources any version of BlackBerry OS from Research In Motion Ltd. of Waterloo Ontario Canada any version of VxWorks from Wind River Systems of Alameda Calif. USA or other operating systems.

The memory may include one or more of the modules described above as executing on the host device such as the message generating process es and the message consuming process es . The memory may also include one or more other modules such as a user authentication module or an access control module to secure access to the host device and so forth.

The memory may include data storage to store data for operations of the host device . The data storage may comprise a database array structured list tree or other data structure and may be a relational or a non relational datastore. The data storage may store data such as that described above including one or more of the message s or the message request s . The data storage may also store other data such as user authentication information or access control data. In some implementations at least a portion of the information stored in the data storage may be stored externally to the host device on other devices that may communicate with the host device via the I O interface s or via the network interface s .

The messaging server device may include one or more memories described herein as memory . The memory comprises one or more CRSM as described above with reference to the memory . The memory may include an OS module that is configured to manage hardware resources such as the I O device s the I O interface s and the network interface s and to provide various services to applications processes or modules executing on the processor s . The OS module may include one or more of the operating systems described above with reference to the OS module . The memory may include one or more of the modules described above as executing on the messaging server device s such as the messaging service module s the partition router module the partition manager module the data structure manager module and the message redelivery module . The memory may also include one or more other modules such as a user authentication module or an access control module to secure access to the messaging server device and so forth.

The memory may include data storage to store data for operations of the messaging server device . The data storage may comprise a database array structured list tree or other data structure and may be a relational or a non relational datastore. The data storage may include data that is in active memory on the messaging server device or data that is written to a hard drive disk or other non volatile storage on the messaging server device . The data storage may store data such as that described above including one or more of the message tracking data structure the message s the queue ID the message IDs the queue partition data the queue description data the partition files the enqueue ID or the dequeue ID . The data storage may also store other data such as user authentication information or access control data. In some implementations at least a portion of the information stored in the data storage may be stored externally to the messaging server device on other devices that may communicate with the messaging server device via the I O interface s or via the network interface s .

At a message is received from a message generating process or another message generating entity such as a computing device or a user. The message may be sent in an enqueue request indicating that the message is to be stored in a queue for subsequent delivery to one or more message consuming processes or other message consuming entities such as computing devices or users. The queue for storage may be indicated by a queue ID included in the message . Alternatively the queue may be determined based on the particular message generating entity that sent the message .

At the message tracking data structure may be accessed. As described above the message tracking data structure may be configured to track a plurality of messages stored in at least a portion of the queue. In cases where there is no instance of the message tracking data structure present an instance may be created. In some implementations the message tracking data structure may be an append tree data structure as described further with reference to .

At a message ID may be determined for the message . As described above the message ID may be determined based on an available location in the message tracking data structure and the available location may be indicated by the enqueue ID . At the message may be stored in the key value store using the determined message ID as a key.

As described above in some implementations the message tracking data structure may be immutable in that the data stored in each block of the message tracking data structure may not be altered after the block has been allocated in memory and added to the message tracking data structure . In such cases blocks of the message tracking data structure may be employed to allocate namespaces for the message indexes to be used in the message IDs . The message IDs may then be employed as file names to store the messages in the key value store . Accordingly the blocks themselves may not store the message IDs for the tracked messages . Alternatively in some implementations each of the blocks may store the message IDs in one or more positions within the block.

At the enqueue ID may be advanced to indicate a next available location in the message tracking data structure . In some implementations the enqueue ID is the message ID that identifies the message . The message ID may also be added to the two data structures maintained by the message redelivery module to manage one or more potential redeliveries of the message . The process may continue as described with reference to .

At a message request e.g. a dequeue request may be received from a message consuming process or another message consuming entity such as a computing device or a user.

At the dequeue ID may be accessed. As described above the dequeue ID may indicate a location in the message tracking data structure the location corresponding to the message ID of a message stored in the key value store . At based on the dequeue ID a message ID may be determined corresponding to a deliverable message . In some implementations the dequeue ID is the message ID for the next deliverable message . At the determined message ID may be employed as a key to retrieve the message from the key value store . At the retrieved message may be sent to the message consuming entity that sent the message request . At the dequeue ID may be advanced to indicate a message ID for a next message that may be vended in response to a dequeue request. The delivered message may remain stored in the key value store and available for delivery to one or more other message consuming entities that send dequeue requests. In some implementations the two data structures maintained by the message redelivery module may also be modified to adjust the potential redelivery timing of the message in response to future dequeue requests as described above.

At a request may be received to remove the message from the queue and from the key value store . As described above the request may be an ack request that specifies the message ID for the message to be deleted. At the message ID may be employed as a key to remove the message from the key value store .

In some implementations when a message is removed from the key value store in response to an ack request the message ID may be marked as deleted in hash set hash table or other data structure storing the message IDs corresponding to a particular block of the message tracking data structure . When the hash set for a block indicates that all of the message IDs tracked in a block correspond to deleted messages the block may then be de allocated from memory and removed from the message tracking data structure . In cases where the blocks are stored in block files in the key value store the block file may also be deleted from the key value store .

At a message may be received at the messaging server device e.g. the load balancing device . As described above the message may be received in an enqueue request from a message generating entity to be stored in a queue for subsequent delivery to one or more message consuming entities. In some cases the message may include the queue ID identifying the queue for storing the message .

At the load balancing device may select a messaging server device e.g. a message handing device to handle the storing tracking and vending of the message . As described above the message handling device may be selected randomly through a round robin load balancing algorithm or otherwise to distribute the message load substantially evenly among a plurality of message handling devices. At the message may be forwarded to the selected message handling device.

At the queue description data may be accessed to retrieve the queue partition data describing a plurality of partitions e.g. logical partitions of the queue identified by the queue ID included in the message . At one of the partitions may be selected to be managed by the message handling device. At the partition file for the partition may be accessed.

At the partition file may be read to determine whether another message handling device is currently managing the partition. If not the process may proceed to . If it is determined that another message handling device is currently managing the partition e.g. based on the message handling device ID in the partition file the process may proceed to and forward the message to the other message handling device that is indicated by the partition file . If there is no active lock on the partition based on the message handling device ID being null the message handling device may attempt to gain a lock on the partition and begin managing the partition.

If the process attempts to gain a lock on a partition and the partition file indicates that another message handing device is currently managing the initially selected partition the process may select another partition e.g. a backup partition and attempt to gain a lock on that partition. In some cases the partition manager module or another module may store data indicating the timestamp when the attempt was made to gain a lock on the initially selected partition. The process may not attempt again to gain a lock on the initially selected partition e.g. to handle a subsequently received message until a particular amount of time has elapsed the amount of time corresponding to the duration of the time period indicated in the partition file . As described above the process may delay its subsequent attempt until the whole duration of the time period has elapsed since the initial attempt even if the current time appears to be in the middle of the time period . Delaying the entire duration of the time period may prevent two different message handling devices from attempting to manage the same partition. The process may then proceed to .

At the partition file may be edited to begin management of the partition e.g. to obtain a lock on the partition that is either the initially selected partition or another backup partition. Such editing may include editing the message handling device ID to identify the message handling device editing the time period and editing the head pointer to be an address of the head block of the message tracking data structure as described above. The process may proceed as described with reference to .

At an instance of the message tracking data structure may be created in memory on the message handling device. The enqueue ID and the dequeue ID may be initialized to indicate the message IDs for the next messages that may be enqueued and dequeued. In some implementations the message tracking data structure may be created by allocating a first block of the message tracking data structure . The head pointer may be set to point to the first allocated block and the enqueue ID may be initialized to indicate the first available message ID in the namespace defined by the block. In some implementations the dequeue ID may not be initialized until a first dequeue request is received. At the partition file may be edited to set the head pointer to an address of the most recently allocated block of the message tracking data structure in memory as described above. In some implementations the head pointer may be a name of the most recently created block file for the message tracking data structure in the key value store . In some implementations the write operations at and may be included in a single write operation to update the partition file .

The operations at and may be performed in cases where the message handling device is not currently managing a partition when it receives the message . In cases where the message handling device is currently managing a partition the process may employ that partition to handle the message . In such cases the operations at and may be omitted.

At the message ID for the message may be determined based on the next available location in the message tracking data structure as described above. At the message may be stored in the key value store using the message ID as a key. In implementations where the key value store is at least a portion of the file system of one or more messaging server devices storing the message may include writing the message to a file in the file system where the file has a file name that is the message ID .

At a reference to the message may be added to the two data structures maintained by the message redelivery module to manage one or more potential redeliveries of the message . The added reference may be the message ID of the message . At the enqueue ID may be advanced to indicate a next available message ID for the next message to be enqueued.

At one or more subsequent messages may be received in enqueue requests. At for each subsequently received message a message ID may be determined and employed to store the message in the key value store as described above.

The block may also include an indication of a plurality of positions each position being available to reference to a message . In some implementations the positions may be indicated in the name of the block file that stores the block . For example a file name of queue11234567890 99 may indicate that the block is to track message indexes e.g. positions 0 through 99 for a particular partition. In such cases the file name of the block file may be employed as a namespace for determining the message IDs for messages and the message IDs may not be stored within the block . In some implementations the file name of the block may be a string that comprises 

a block size indicating a size of the block and a number of messages that may be tracked using the block e.g. 0 99 .

For example a file name of queue11234567890 99 may include a queue name of queue a partition name of 1 a block start address of 123456789 and a block size of 0 99 . In some implementations the block file name may also include a random number. The message ID for a particular message may be determined by appending a message index e.g. one of the available message indexes 0 99 to the block file name that is the block identifier. In some implementations the message indexes may be globally unique identifiers GUIDs that may be randomly or pseudo randomly generated and stored in the block and a GUID stored at a particular position may be appended to the block file name to generate the message ID . The use of such GUIDs as message indexes may obfuscate the number or order of messages being managed through a particular block .

Alternatively the positions may be locations in memory that are employed to store the message indexes to be included in the message IDs corresponding to the messages . In such cases the message indexes may be random numbers pseudo random numbers or other information stored in the positions . A block may indicate any number of positions . For example a block may indicate positions that may be employed as message indexes in message IDs for messages .

The message tracking data structure may be a tree structure such as an append tree data structure that includes any number of nodes that are hierarchically arranged. In some cases one or more pairs of the nodes may be hierarchically related as parent to child such that the child pointer of a parent node points to a child node. In some cases one or more pairs of the nodes may be related as siblings on a same hierarchical level of the message tracking data structure such that the previous pointer of a node points to a sibling node. Each of the nodes in the message tracking data structure may be one or more of a child node a parent node or a sibling node with respect to one or more other nodes. In some cases each node of the message tracking data structure may be a block as described with reference to .

In some cases the append tree data structure may be immutable in that the value s of the data stored at a node of the append tree data structure may not be altered after the node e.g. a block has been instantiated and added to the append tree data structure. The immutability of the append tree data structure may provide for greater efficiency in message processing given that implementations may not alter the data stored in the nodes of the append tree. For example implementations may perform write operations to allocate new nodes but not to alter data stored in existing nodes. Although the data stored in each node of the append tree may not be changed e.g. may be immutable in some implementations nodes may be removed from the tree e.g. pruned . For example when the messages being tracked using a particular block have all been deleted e.g. through ack requests the block may be de allocated from memory and its block file deleted from the key value store . Although other blocks may retain pointers pointing to the de allocated block those pointers may reference an empty location in memory after the block has been de allocated. Thus the node corresponding to the de allocated block may be effectively removed from the append tree.

In the message tracking data structure depicts a first state in which the append tree includes one block . The message tracking data structure may be initiated by allocating a first block to track an initial set of messages in a partition of a queue. In this first state the enqueue ID may indicate a particular message index in the first block indicating that the block has one or more positions corresponding to message IDs available for tracking messages .

When all the positions in the block have been employed in message IDs for enqueued messages a second block may be allocated to provide additional positions for tracking messages . The message tracking data structure depicts a second state in which the append tree includes two blocks and . The previous pointer of the block points to the block . On adding the new block to the append tree the enqueue ID may be updated to indicate a position in the block indicating that the block has position s available for tracking messages .

When the positions in the blocks and have been used a third block may be allocated. As shown by the message tracking data structure the child pointers of the block may point to the blocks and such that the blocks and are children of the block . The enqueue ID may be updated to indicate a position in the block . As each block is added to the message tracking data structure the pointers in the previously added blocks may not be modified. In some cases a parent block such as the block may be added such that it does not currently have any child blocks for example when the blocks that may have otherwise been related as child blocks have been de allocated following a deletion of all the messages tracked by the child blocks. In such cases the newly added parent block may include child pointers that are null or that point to locations in memory that no longer hold the de allocated child blocks.

With reference to the message tracking data structure depicts the append tree after a fourth block has been added. The fourth block may be added as another leaf block with leaf blocks and . A leaf block may be situated at la lowest hierarchical level of the message tracking data structure and may not have any child blocks. As shown in the previous pointer of the fourth block may point to the block . The enqueue ID may be updated to indicate a position in the newly added block . In some implementations a newly added leaf block may be added such that its previous pointer points to the previously allocated block e.g. the most recently allocated block .

The message tracking data structure depicts the append tree after a fifth block has been added. The fifth block may be added as another leaf block and the previous pointer of the block may point to the block . The enqueue ID may be updated to indicate a position in the newly added block .

The message tracking data structure depicts the append tree after a sixth block has been added. The sixth block may be added at the same hierarchical level as the block and the child pointers of the block may point to the blocks and as child blocks. The previous pointer of the block may point to the block . The enqueue ID may be updated to indicate a position in the newly added block .

With reference to the message tracking data structure depicts the append tree after a seventh block has been added. The seventh block may be added as a parent block relative to the blocks and and the child pointers of the block may point to the blocks and . The enqueue ID may be updated to indicate a position in the newly added block . In some implementations the previous pointer of a newly added parent node such as the block may point to a same node as the previous pointer of the left child node of the newly added parent node. In the example of the message tracking data structure the previous pointer of the block is null so the previous pointer of the newly added block is also null. A null pointer may be a pointer storing null data or a pointer that points to a location in memory that stores random data or data that is not indicative of a currently active node or block .

The message tracking data structure depicts the append tree after an eighth block has been added. The eighth block may be added as another leaf block and the previous pointer of the block may point to the block . The enqueue ID may be updated to indicate a position in the newly added block .

In some implementations each of the blocks may be identified by a block ID. The block ID may correspond to the block file name for the block . In the case of the leaf blocks the block ID may include a leaf block counter . In some implementations the leaf block counter may be a binary number including any number of binary digits. The leaf block counter may increment with each newly added leaf block to count 000 001 010 011 100 101 110 and so forth. When adding a new block to the append tree data structure the leaf block counter s may be employed to determine whether the newly added block is to be a new leaf block or a new parent block. In some cases the leaf block counter of the right most leaf block may be examined and the number of 1 digits may be counted e.g. via right shift operation s from the right before a 0 digit is encountered. For example based on the leaf block counters for the blocks and respectively the count is 0 1 0 2 and 0. The count indicates the number of parent blocks to be added to the append tree before the next leaf block is added. For example the leaf block counter for the block exhibits a count of 2. Accordingly after the addition of the block in the message tracking data structure two additional parent blocks and are to be allocated prior to adding another leaf block .

Table 2 includes an example of pseudo code that may be employed to allocate a new leaf node or parent node for the append tree data structure based on the leaf block counters as described above.

The append tree data structure illustrated in exhibits a property of being substantially self balancing as additional blocks are added and as an increasing number of messages are tracked using the append tree data structure. The append tree is substantially self balancing given the method which is employed to expand the append tree starting with leaf nodes and expanding out e.g. adding additional leaf nodes to the right while expanding up to add additional parent nodes for each pair of leaf nodes. The self balancing property of the append tree is associated with the immutability of the nodes of the append tree. For example the immutability of the nodes may inhibit a manual re balancing of the tree given that the pointers included in a node e.g. in a block may not be altered. Because the append tree is substantially self balancing implementations may forego additional operations to rebalance the append tree data structure.

Moreover the append tree data structure is configured so that reaching the tail of the append tree e.g. the oldest allocated block from the head of the append tree e.g. the newest allocated block may be accomplished in a time that scales on the order of log N where N is the number of messages tracked by the append tree data structure. In cases where the message tracking data structure is a linked list traversing the tree may be accomplished in a time that scales on the order of N. Accordingly use of the append tree data structure as the message tracking data structure may enable the oldest enqueued message to be identified more efficiently by traversing back from the head of the data structure.

At a request may be received for a message ID to be employed to store a message in the key value store . As described above the request may be received based on receiving an enqueue request indicating a message to be managed within a partition of a queue.

At a determination is made whether there is an available instance of a message tracking data structure that may be employed to determine a message ID for the message . If so the process may proceed to . If not the process may proceed to and create a new instance of the message tracking data structure e.g. in memory . The process may then proceed to . At the message tracking data structure may be accessed.

At a determination is made whether there is an available position in a block of the message tracking data structure . If so the process may proceed to and provide the message ID corresponding to the available position in the block . The enqueue ID may be advanced to the next available position .

If it is determined at that there is not currently an available position in the message tracking data structure the process may proceed to . At a new block may be added to the message tracking data structure as a leaf block or as a parent block. As described with reference to the determination of whether the new block is a leaf or a parent may be based on the leaf block counter for the most recently allocated e.g. right most leaf block. At the message ID may be provided corresponding to the first available position in the newly added block . The enqueue ID may be advanced to the next available position .

Implementations support the use of any number of messaging server devices e.g. message handling devices to handle messages within any number of partitions of a message queue. In some implementations one message handling device may be employed to manage a single partition e.g. in cases where the queue is not divided into logical partitions. In such implementations the partition locking described above may not be employed given that there is one message handling device managing the single partition of the queue. In such configurations the message tracking data structure and the storage of messages the key value store may still enable recovery from a failure of the message handling device. For example if the message handling device crashes and loses state e.g. loses in memory data the message handling device may recover and begin processing enqueue and dequeue requests after a load time. During the load time the message tracking data structure may be recreated in memory on the message handling device based on the copy of the message tracking data structure stored e.g. on disk on the messaging server device s . Enqueues may begin after a first block of the message tracking data structure is written to memory. Dequeues may begin after the loading of the oldest messages which may be determined after a traversal of the message tracking data structure . As described above the traversal may be completed in a time that is proportional to log N where N is the number of messages currently being tracked using the message tracking data structure . After loading the oldest block a number of read operations corresponding to the block size may be performed to scan for the oldest message that is currently being tracked and stored in the key value store .

In some implementations multiple message tracking devices may be employed to manage a single partition of a queue. In such implementations the partition locking may be employed given that the partition locking substantially reduces the chance of multiple message handling devices processing the same partition simultaneously which may result in message loss or other incorrect behavior. A queue may be more available in this configuration because a failure of a single message handling device may lead to a short period of outage e.g. based on the time period of the lock before another message handling device takes over message processing. Accordingly this configuration may enable failover in the system. Such implementations may not include a separate discovery mechanism for new message handling devices and may not include manual setup of new message handling devices given that newly added message handling devices may begin attempting to take partition locks as the devices are brought online. Once a lock is taken by a newly added message handling device the device s routing information may be added to the partition file enabling other message handling devices to forward messages to the new message handling device. Accordingly implementations enable the number of message handling devices to be increased by bringing the devices online and routing queue traffic to them.

In some implementations a single message handling device may be employed to manage multiple partitions of a queue. With multiple partitions the throughput capability for message handling may be increased. In some cases where a single partition is employed throughput may be constrained by serial I O to access single file objects in the key value store . In the single partition configuration where the blocks and partition files are written in succession the performance gains achieved through the use of one block for multiple messages may eventually reach a performance bottleneck. Using multiple independently managed partitions may allow for independent I O operations and may improve performance. Because the keys e.g. the message IDs are independent of one another in the message tracking data structure the messages and the multiple queues the message storage load may be distributed substantially evenly across the distributed key value store . Accordingly implementations may provide performance gains compared to other techniques for implementing message queues on single hosts using local data stores given that such techniques may experience performance bottlenecks as they concentrate messages onto a small number of hosts and saturate I O.

In some implementations multiple message handling devices may be employed to handle messages within multiple partitions of one or more queues. In this configuration performance may be optimized by spreading I O across computing devices and across files with respect to the messaging server devices e.g. the message handling devices as well as the messaging server devices that provide the distributed key value store . Any number of partitions and message handling devices may be added to the system to enable any throughput level of throughput for handling messages for one or more queues. Adding additional message handling devices may be accomplished through the partition locking as described above. Moreover as described above the message handling devices may forego a coordinated time source to synchronize their clocks because the locking is based on the independent clocks of the message handling devices not exceeding a maximum skew within a lock period e.g. the time period . Automatic failover for each partition is provided by the partition locking as described above. Moreover implementations may also enable arbitrarily high availability for enqueue operations given that any particular enqueue request may be sent to any number of message handling devices handling different partitions until an enqueue succeeds.

The implementations described herein may employ a key value store e.g. a distributed key value store supporting conditional put and conditional get operations. In some implementations a file system may be employed as the key value store . The use of a file system as the key value store may enable rapid setup and operation of the messaging service on a wide range of supporting platforms. Although the above examples describe employing the append tree data structure to determine message IDs for tracking messages stored in the key value store implementations also support the use of the append tree data structure in other scenarios contexts and environments. The append tree data structure may be employed to store any type and any amount of data.

Those having ordinary skill in the art will readily recognize that certain steps or operations illustrated in the figures above may be eliminated combined or performed in an alternate order. Any steps or operations may be performed serially or in parallel. Moreover the methods described above may be implemented as one or more software programs for a computer system and may be encoded in a computer readable storage medium as instructions executable on one or more processors.

Embodiments may be provided as a computer program product including one or more non transitory computer readable storage media having stored thereon instructions in compressed or uncompressed form that may be used to program a computer or other electronic device to perform processes or methods described herein. The computer readable storage media may include one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium and so forth. For example the computer readable storage media may include but are not limited to hard drives floppy diskettes optical disks read only memories ROMs random access memories RAMs erasable programmable ROMs EPROMs electrically erasable programmable ROMs EEPROMs flash memory magnetic or optical cards solid state memory devices or other types of physical media suitable for storing electronic instructions. Further embodiments may also be provided as a computer program product including a transitory machine readable signal in compressed or uncompressed form . Examples of machine readable signals whether modulated using a carrier or unmodulated include but are not limited to signals that a computer system or machine hosting or running a computer program may be configured to access including signals transferred by one or more networks. For example a transitory machine readable signal may comprise transmission of software by the Internet.

Separate instances of these programs can be executed on or distributed across any number of separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art readily recognize that the techniques described above can be utilized in a variety of devices environments and situations. Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art. It is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

