---

title: Shared network-available storage that permits concurrent data access
abstract: Techniques for providing shared access to, e.g., a small computer system interface (SCSI) storage device in a computer network include providing an operational mode on SCSI interfaces with a first media agent and a second media agent such that, in response to inquiry messages on the SCSI interfaces, the SCSI storage device appears as a SCSI target device to the first media agent and the second media agent and mapping data operations between the first media agent and the SCSI storage device and the second media agent and the SCSI storage device to logically unique channel numbers for the first media agent and the second media agent to perform data storage operations over their respective SCSI interfaces by concurrently sharing the SCSI storage device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639297&OS=09639297&RS=09639297
owner: Commvault Systems, Inc
number: 09639297
owner_city: Tinton Falls
owner_country: US
publication_date: 20130311
---
The present documents claims the benefit of priority under 35 U.S.C. 119 e from U.S. Provisional Patent 61 617 929 entitled SHARED NETWORK AVAILABLE STORAGE THAT PERMITS CONCURRENT DATA ACCESS filed on Mar. 30 2012 incorporated by reference herein.

A primary copy of data is generally a production copy or other live version of the data which is used by a software application and is generally in the native format of that application. Primary copy data may be maintained in a local memory or other high speed storage device that allows for relatively fast data access if necessary. Such primary copy data is typically intended for short term retention e.g. several hours or days before some or all of the data is stored as one or more secondary copies for example to prevent loss of data in the event a problem occurred with the data stored in primary storage.

To protect primary copy data or for other purposes such as regulatory compliance secondary copies alternatively referred to as data protection copies can be made. Examples of secondary copies include a backup copy a snapshot copy a hierarchical storage management HSM copy an archive copy and other types of copies.

A backup copy is generally a point in time copy of the primary copy data stored in a backup format as opposed to in native application format. For example a backup copy may be stored in a backup format that is optimized for compression and efficient long term storage. Backup copies generally have relatively long retention periods and may be stored on media with slower retrieval times than other types of secondary copies and media. In some cases backup copies may be stored at an offsite location.

After an initial full backup of a data set is performed periodic intermittent or continuous incremental backup operations may be subsequently performed on the data set. Each incremental backup operation copies only the primary copy data that has changed since the last full or incremental backup of the data set was performed. In this way even if the entire set of primary copy data that is backed up is large the amount of data that must be transferred during each incremental backup operation may be significantly smaller since only the changed data needs to be transferred to secondary storage. Combined one or more full backup and subsequent incremental copies may be utilized together to periodically or intermittently create a synthetic full backup copy. More details regarding synthetic storage operations are found in commonly assigned U.S. patent application Ser. No. 12 510 059 entitled Snapshot Storage and Management System with Indexing and User Interface filed Jul. 27 2009 now U.S. Pat. No. 7 873 806 which is hereby incorporated by reference herein in its entirety.

An archive copy is generally a copy of the primary copy data but typically includes only a subset of the primary copy data that meets certain criteria and is usually stored in a format other than the native application format. For example an archive copy might include only that data from the primary copy that is larger than a given size threshold or older than a given age threshold and that is stored in a backup format. Often archive data is removed from the primary copy and a stub is stored in the primary copy to indicate its new location. When a user requests access to the archive data that has been removed or migrated systems use the stub to locate the data and often make recovery of the data appear transparent even though the archive data may be stored at a location different from the remaining primary copy data.

Archive copies are typically created and tracked independently of other secondary copies such as other backup copies. For example to create a backup copy the data storage system transfers a secondary copy of primary copy data to secondary storage and tracks the backup copy using a backup index separate from the archive index. To create an archive copy a conventional data storage system transfers the primary copy data to be archived to secondary storage to create an archive copy replaces the primary copy data with a link or stub and tracks the archive copy using an archive index. Accordingly the data storage system will transfer two separate times to secondary storage a primary copy data object that is both archived and backed up.

Since each transfer consumes network and computing resources the data storage system may not be able to devote such resources to other tasks. Moreover the data storage system is required to devote resources to maintaining each separate index. In some cases the archive index may be unaware of the other secondary copy and the other secondary index may be unaware of the archive copy which may lead to further inefficiencies. Moreover in some cases in the event that an archive copy is moved or transferred e.g. to another tier of secondary storage the archive index may not be able to be updated to reflect the move or transfer. In such cases the data storage system may be unable to use the stub to locate the archived data object.

To be able to store and retrieve the above described various versions of data primary secondary archive etc. a computer device needs to access a storage device. In many computer networks e.g. a corporate network it may be beneficial to couple a storage device to the network such that the storage device is accessible to computers coupled to the network. In current systems data traffic to or from such multiple client computers may flow on a local area network LAN . In addition in current computer networks storage devices that use specialized data interfaces such as a fibre channel or small computer system interface SCSI cannot be shared by multiple clients.

The need exists for systems and methods that overcome the above problems as well as systems and methods that provide additional benefits. Overall the examples herein of some prior or related systems and methods and their associated limitations are intended to be illustrative and not exclusive. Other limitations of existing or prior systems and methods will become apparent to those of skill in the art upon reading the following Detailed Description.

The techniques disclosed in this document are useful in one aspect in solving the above discussed problems related to providing shared access to storage devices. In another aspect the disclosed techniques are useful in off loading storage related data transfers from local area network to locally attached storage devices. Other benefits are also realized by the system disclosed herein.

The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the disclosure.

A software firmware and or hardware system for archiving data objects using secondary copies the system is disclosed. The system creates one or more secondary copies of primary copy data e.g. production data stored by a production computing system . The primary copy data contains multiple data objects e.g. multiple files emails or other logical groupings or collections of data . The system maintains a first data structure that tracks the data objects for which the system has created secondary copies and the locations of the secondary copies.

To provide shared access to a storage device the system provides an access media agent described in greater detail below which is a media agent adapted to provide other media agents with shared access to a storage device where each of the media agents in turn are responsible for storage operations for one or more clients. In some implementations the access media agent is adapted to look like a target device for storage operations. The access media agent may communicate with other media agents over a dedicated data channel such as a small computer system interface SCSI a parallel SCSI interface a serial attached SCSI SAS interface a Fibre Channel interface an ATA interface an Integrated Development Environment IDE interface etc. In one aspect the use of such dedicated interfaces offloads storage data traffic between media agents and a storage device from a local area network LAN that may be used for communication.

In some computer networks multiple servers may be simultaneously performing data archival restoration operations. For example one server may be an Oracle server another could be a SQL server a third one could be an Exchange database which may be transferring data to storage typically using media agents described below and transferring data over a local area network. In the past each of these individual media agents had corresponding disk storage for backup. However with the advent of storage area network SAN based storage it may be possible to share the storage capacity between the various servers. For example Oracle server may be in a need for additional 2 Tbytes of storage which may not be locally available but because the Exchange server is under utilizing its local storage capacity 2 Terabytes may be available at the Exchange server storage. However if the storage is local it cannot be shared by another serer in the network. Therefore such localized resourcing of storage leads to frequent addition of storage capacity at one server and associated provisioning while excess capacity may be available at another server. Such provisioning may take away time from already busy system administrators. The techniques presented in this document in one aspect relieve a system administrator of having to perform such un necessary provisioning when storage is available in the network by centralizing storage and allowing various servers to share the storage concurrently through a storage server.

As further described below a storage server advantageously hides the working details of data block management on the storage device from each application server that utilizes the storage. Furthermore application servers do not end up over writing each other because the storage server exposes the storage simply as Logical Unit Numbers LUNs to each application server. Therefore from each application server s perspective data read write operations can be performed when desired with the concurrency of multiple applications being achieved by arbitration performed by the storage server.

In one advantageous aspect storage efficiency can be increased by sharing deduplication operation across multiple application servers. For example a data block written to the storage by one media agent for one application server may be available for reading by another media agent controlled by the storage server . The storage server e.g. offers simultaneous access to the same data block by all media agents attempting to read the block.

Various examples will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand however that the invention may be practiced without many of these details. Likewise one skilled in the relevant art will also understand that the invention may include many other obvious features not described in detail herein. Additionally some well known structures or functions may not be shown or described in detail below so as to avoid unnecessarily obscuring the relevant description.

While the embodiments described below generally refer to Linux based implementations applicability of the disclosed techniques to other operating system OS frameworks such as various OSs from vendors such as Microsoft Apple and Sun now Oracle will be appreciated and understood by one of skill in the art. Furthermore while the embodiments are described using the use of Fibre Channel and Small Computer System Interface SCSI transport protocol examples the applicability to other data bus technologies would be appreciated by one of skill in the art. Therefore the term SCSI as used herein encompasses other industry standards such as iSCSI SAS IDE etc.

The terminology used below is to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific examples of the invention. Indeed certain terms may even be emphasized below however any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section.

Aspects of the technologies described herein may be practiced in an information management environment which will now be described while referencing . As shown in the environment includes multiple computing devices that execute numerous software applications to facilitate the operations of an organization or multiple affiliated organizations such as a household corporation or other business entity a non profit organization an educational institution or a governmental agency. The computing devices may include one or more servers such as mail servers file servers database servers print servers and web servers personal computers workstations or other types of fixed computing systems such as mainframe computers and minicomputers not shown . The servers may include network attached storage NAS filers.

The environment may include virtualized computing resources such as a virtual machine provided to the organization by a third party cloud service vendor or a virtual machine running on a virtual machine host operated by the organization. For example the organization may use one virtual machine A as a database server and another virtual machine B as a mail server. The environment may also include mobile or portable computing devices such as laptops tablet computers personal data assistants mobile phones such as smartphones and other mobile or portable computing devices such as embedded computers set top boxes vehicle mounted devices wearable computers etc.

Of course other types of computing devices may form part of the environment . As part of their function each of these computing devices creates accesses modifies writes and otherwise uses production copies of data and metadata that are typically stored in a persistent storage medium having fast I O times. For example each computing device may regularly access and modify data files and metadata stored on semiconductor memory a local disk drive or a network attached storage device. Each of these computing devices may access data and metadata via a file system supported by an operating system of the computing device.

The environment may also include hosted services that provide various online services to the organization or its constituent members e.g. the organization s departments employees independent contractors etc. such as social networking services e.g. Facebook Twitter Pinterest hosted email services e.g. Gmail Yahoo Mail Hotmail or hosted productivity applications or other hosted applications e.g. Microsoft Office 365 Google Docs Salesforce.com . Hosted services may include software as a service SaaS platform as a service PaaS application service providers ASPs cloud services and all manner of delivering computing or functionality via a network. As it provides services to users each hosted service may generate additional hosted data and metadata that is associated with each user. For example Facebook may generate and store photos wall posts notes videos and other content that are associated with a particular Facebook user s account.

The organization directly or indirectly employs an information management system to protect and manage the data and metadata used by the various computing devices in the environment and the data and metadata that is maintained by hosted services on behalf of users associated with the organization. One example of an information management system is the CommVault Simpana system available from CommVault Systems Inc. of Oceanport N.J. The information management system creates and manages non production copies of the data and metadata to meet information management goals such as permitting the organization to restore data metadata or both data and metadata if an original copy of the data metadata is lost e.g. by deletion corruption or disaster or because of a service interruption by a hosted service allowing data to be recovered from a previous time complying with regulatory data retention and electronic discovery e discovery requirements reducing the amount of data storage media used facilitating data organization and search improving user access to data files across multiple computing devices and or hosted services and implementing information lifecycle management ILM or other data retention policies for the organization. The information management system may create the additional non production copies of the data and metadata on any suitable non production storage medium such as magnetic disks magnetic tapes other storage media such as solid state storage devices or optical disks or on cloud data storage sites e.g. those operated by third party vendors . Further details on the information management system may be found in the assignee s U.S. patent application Ser. No. 12 751 850 filed Mar. 31 2010 entitled DATA OBJECT STORE AND SERVER FOR A CLOUD STORAGE ENVIRONMENT INCLUDING DATA DEDUPLICATION AND DATA MANAGEMENT ACROSS MULTIPLE CLOUD STORAGE SITES now U.S. Patent Publication Number 2010 0332456 which is hereby incorporated by reference herein in its entirety.

The information management system accesses or receives copies of the various production copies of data objects and metadata and via an information management operation such as a backup operation archive operation or snapshot operation creates non production copies of these data objects and metadata often stored in one or more non production storage mediums different than the production storage medium where the production copies of the data objects and metadata reside. A non production copy of a data object represents the production data object and its associated metadata at a particular point in time non production objects A C . Since a production copy of a data object or metadata changes over time as it is modified by an application hosted service or the operating system the information management system may create and manage multiple non production copies of a particular data object or metadata each representing the state of the production data object or metadata at a particular point in time. Moreover since a production copy of a data object may eventually be deleted from the production data storage medium and the file system from which it originated the information management system may continue to manage point in time representations of that data object even though a production copy of the data object itself no longer exists.

For virtualized computing devices such as virtual machines the operating system and applications A D may be running on top of virtualization software and the production data storage medium may be a virtual disk created on a physical medium such as a physical disk. The information management system may create non production copies of the discrete data objects stored in a virtual disk file e.g. documents email mailboxes and spreadsheets and or non production copies of the entire virtual disk file itself e.g. a non production copy of an entire .vmdk file .

Each non production object A C may contain copies of or otherwise represent more than one production data object. For example non production object A represents three separate production data objects C and C represented as C and respectively . Moreover as indicated by the prime mark a non production object may store a representation of a production data object or metadata differently than the original format of the data object or metadata e.g. in a compressed encrypted deduplicated or otherwise optimized format. Although shows that a single production data object e.g. C and its associated data object metadata e.g. Meta are represented by the contents of only a single non production object e.g. A the entire contents of a single production data object and or its metadata at a particular point in time may instead span across numerous non production objects. Also a single non production object may contain copies of or otherwise represent production data objects that originated from different computing devices.

Non production copies include backup copies archive copies and snapshot copies. Backup copies are generally used for shorter term data protection and restoration purposes and may be in a native application format or in a non native format e.g. compressed encrypted deduplicated and or otherwise modified from the original application format . Archive copies are generally used for long term data storage purposes and may be compressed encrypted deduplicated and or otherwise modified from the original application format. In some examples when an archive copy of a data object is made a logical reference or stub may be used to replace the production copy of the data object in the production storage medium . In such examples the stub may point to or otherwise reference the archive copy of the data object stored in the non production storage medium so that the information management system can retrieve the archive copy if needed. The stub may also include some metadata associated with the data object so that a file system and or application can provide some information about the data object and or a limited functionality version e.g. a preview of the data object. A snapshot copy represents a data object at a particular point in time. A snapshot copy can be made quickly and without significantly impacting production computing resources because large amounts of data need not be copied or moved. A snapshot copy may include a set of pointers derived from the file system or an application where each pointer points to a respective stored data block so collectively the set of pointers reflect the storage location and state of the data object at a particular point in time when the snapshot copy was created. In copy on write if a block of data is to be deleted or changed the snapshot process writes the block to a particular data storage location and the pointer for that block is now directed to that particular location. The set of pointers and or the set of blocks pointed to by a snapshot may be stored within the production data storage medium .

Non production copies of a data object or metadata may be distinguished from a production copy of a data object or metadata in several ways. First a non production copy of a data object is created to meet the different information management goals described above and is not directly used or modified by applications A D hosted services or the operating system . Second a non production copy of a data object is stored as one or more non production objects that may have a format different from the native application format of the production copy of the data object and thus often cannot be directly used by the native application or a hosted service without first being modified. Third non production objects are often stored on a non production storage medium that is inaccessible to the applications A D running on computing devices and hosted services . Also some non production copies may be offline copies in that they are not readily available e.g. not mounted tape or disk. Offline copies include copies of data that the information management system can access without any human intervention e.g. tapes within an automated tape library but not yet mounted in a drive and copies that the information management system can access only with at least some human intervention e.g. tapes located at an offsite storage site .

The information management system also generates information management data such as indexing information that permit the information management system to perform its various information management tasks. As shown in a computing device may include one or more data management agents that provide client side functions for the information management system.

The storage manager may be a software module or other application that coordinates and controls information management operations performed by one or more information management cells to protect and control copies of non production data objects and metadata. As shown by the dashed lines and the storage manager may communicate with some or all elements of the information management cell such as the media agents and computing devices to initiate and manage backup operations snapshot operations archive operations data replication operations data migrations data distributions data recovery and other information management operations. The storage manager may control additional information management operations including ILM deduplication content indexing data classification data mining or searching e discovery management collaborative searching encryption and compression. Alternatively or additionally a storage manager may control the creation and management of disaster recovery copies which are often created as secondary high availability disk copies using auxiliary copy or replication technologies.

The storage manager may include a jobs agent a management agent a network agent and an interface agent all of which may be implemented as interconnected software modules or application programs. The jobs agent monitors the status of information management operations previously performed currently being performed or scheduled to be performed by the information management cell . The management agent provides an interface that allows various management agents in multiple information management cells or in a global storage manager to communicate with one another. This allows each information management cell to exchange status information routing information capacity and utilization information and information management operation instructions or policies with other cells. In general the network agent provides the storage manager with the ability to communicate with other components within the information management cell and the larger information management system e.g. via proprietary or non proprietary network protocols and application programming interfaces APIs including HTTP HTTPS FTP REST virtualization software APIs cloud service provider APIs hosted service provider APIs . The interface agent includes information processing and display software such as a graphical user interface GUI an API or other interactive interface through which users and system processes can retrieve information about the status of information management operations or issue instructions to the information management cell and its constituent components. The storage manager may also track information that permits it to select designate or otherwise identify content indices deduplication databases or similar databases within its information management cell or another cell to be searched in response to certain queries.

The storage manager may also maintain information management data such as a database of management data and policies. The database may include a management index that stores logical associations between components of the system user preferences user profiles that among other things map particular information management users to computing devices or hosted services management tasks or other useful data. The database may also include various information management policies which are generally data structures or other information sources that each include a set of criteria and rules associated with performing an information management operation. The criteria may be used to determine which rules apply to a particular data object system component or information management operation an may include 

As noted above each computing device may include one or more data management agents . Each data management agent is a software module or component that helps govern communications with other system components. For example the data management agent receives commands from the storage manager and sends to and receives from media agents copies of data objects metadata and other payload as indicated by the heavy arrows . Each data management agent accesses data and or metadata stored in a production data storage medium and arranges or packs the data and metadata in a certain format e.g. backup or archive format before it is transferred to another component. Each data management agent can also restore a production copy of a data object or metadata in a production data storage medium from a non production copy. A data management agent may perform some functions provided by a media agent which are described further herein such as compression encryption or deduplication. Each data management agent may be specialized for a particular application e.g. a specified data management agent customized to handle data generated or used by Exchange by Microsoft Corp. . Alternatively or additionally a more generic data management agent may handle data generated or used by two or more applications.

Each computing device may also include a data distribution and live browsing client module herein distribution client module . The distribution client module is responsible for inter alia associating mobile devices and or hosted service accounts with users of the information management system setting information management policies for mobile and other computing devices pushing data objects to a distribution module for distribution to other computing devices providing unified access to a user s data via an interface and providing live browsing features. The various functions of the distribution client module are described in greater detail herein.

A media agent which may be implemented as a software module conveys data as directed by the storage manager between a computing device or hosted service and one or more non production storage mediums . Each media agent may control one or more intermediary storage devices such as a cloud server or a tape or magnetic disk library management system to read write or otherwise manipulate data stored in a non production storage medium . Each media agent may be considered to be associated with a storage device and its related non production storage media if that media agent is capable of routing data to and storing data in the storage media managed by the particular storage device. A media agent may communicate with computing devices hosted services storage devices A D and the storage manager via any suitable communications path including SCSI a Storage Area Network SAN a Fibre Channel communications link or a wired wireless or partially wired wireless computer or telecommunications network including the Internet.

To perform its functions the media agent may include a media file system module a data classification module a content indexing module a deduplication module an encryption module a compression module a network module a distribution module and a media agent database . The media file system module is responsible for reading writing archiving copying migrating restoring accessing moving sparsifying deleting sanitizing destroying or otherwise performing file system operations on various non production storage devices of disparate types. The media file system module may also instruct the storage device to use a robotic arm or other retrieval means to load or eject certain storage media such as a tape.

The network module permits the media agent to communicate with other components within the system and hosted services via one or more proprietary and or non proprietary network protocols or APIs including cloud service provider APIs virtual machine management APIs and hosted service provider APIs . The deduplication module performs deduplication of data objects and or data blocks to reduce data redundancy in the cell. The deduplication module may generate and store data structures to manage deduplicated data objects such as deduplication tables in the media agent database . The encryption module performs encryption of data objects data blocks or non production objects to ensure data security in the cell. The compression module performs compression of data objects data blocks or non production objects to reduce the data capacity needed in the cell.

The content indexing module analyzes the contents of production copies or non production copies of data objects and or their associated metadata and catalogues the results of this analysis along with the storage locations of or references to the production or non production copies in a content index stored within a media agent database . The results may also be stored elsewhere in the system e.g. in the storage manager along with a non production copy of the data objects and or an index cache. Such index data provides the media agent or another device with an efficient mechanism for locating production copies and or non production copies of data objects that match particular criteria. The index data or other analyses of data objects or metadata may also be used by the data classification module to associate data objects with classification identifiers such as classification tags in the media agent database or other indices to facilitate information management policies and searches of stored data objects.

The distribution module may be a set of instructions that coordinates the distribution of data objects and indices of data objects. The distribution may occur from one computing device to another computing device and or from hosted services to computing devices . As a first example the distribution module may collect and manage data and metadata from hosted services or mobile devices . As another example the distribution module may synchronize data files or other data objects that are modified on one computing device so that the same modified files or objects are available on another computing device. As yet another example the distribution module may distribute indices of data objects that originated from multiple computing devices and or hosted services so a user can access all of their data objects through a unified user interface or a native application on their computing device. The distribution module may also initiate live browse sessions to permit communications between different computing devices so that the devices can interchange data and metadata or so the devices can provide computing resources such as applications to each other. The functions performed by the distribution module are described in greater detail herein.

As previously discussed the presently disclosed techniques allow shared access to a SAN storage device. Briefly and in general terms using the disclosed techniques multiple media agents which may be implemented using different operating systems can transfer data to from the same SAN Storage server simultaneously over a high speed connection such as a Fibre Channel. In some implementations storage read write data therefore does not flow on the LAN.

In on aspect the use of an access media agent allows concurrent access to a storage device from multiple media agents. In another aspect storage capacity can be added to the storage device without the media agents having to provision for the added storage capacity as would have to be done without the access media agent.

Network attached data storage devices NAS that are attachable to a LAN using e.g. a Gigabit Ethernet connection are well known in the art. However in such networks data transfers between media agents and the data storage device typically uses the same LAN bandwidth that is shared with other data traffic on the network. Such configurations may suffer from the drawback that the data read write operations travel over the LAN e.g. network and compete for resources with other data traffic thereby impacting the performance of the LAN .

In some implementations media agents may be configured to access data storage devices over dedicated data interfaces such as SCSI SATA IDE SAS etc. which are well known in the art. However when a data storage device is accessible using such a dedicated data connection two or more servers cannot simultaneously look at the data storage device as a target. Allowing two or more servers to read write to the storage device over the same dedicated interface may result e.g. in data corruption because the two or more servers may end up writing data to the storage device in the same locations.

The above discussed operational issues can be addressed in one aspect by using an intermediate Access Media Agent that controls or arbitrates the access by multiple media agents to the data storage device . The access media agent may be coupled to multiple media agents over their respective dedicated data interfaces such as a Fibre Channel SCSI interface. The interfaces may possibly be routed to the Access Media Agent through a switch e.g. a Fibre Channel switch . In some implementations the Access Media Agent may be a software application running on a SAN storage server platform. The SAN storage server may also be coupled to the LAN . In one aspect the Access Media Agent may control the SAN storage server to look like a SCSI target to each media agent for their respective data transfers to from the data storage device . In other words the Access Media Agent may provide in one aspect an abstraction layer or a virtualization layer by which the media agents can share the SCSI interface to the data storage device with the Access Media Agent controlling or arbitrating the access by each media agent to ensure no data corruption takes place. Several possible embodiments of the Access Media Agent are further described below.

As previously described in one aspect the Access Media Agent may allow multiple media agents to simultaneously transfer data to the storage device over a dedicated data connection such as a Fibre Channel without having any of the data to be stored flow over the LAN . The media agents may be implemented to operate with any Operating System OS and the Access Media Agent functionality may thus be transparent to the media agents regardless of implementation details of the operating systems. By providing such an abstraction layer in one aspect the Access Media Agent relieves the media agents of having to provision any changes to the data storage device e.g. addition of storage capacity etc. . Furthermore in another aspect the data storage device may be coupled to the SAN storage server externally by connecting to the SAN storage server using a transport type such as parallel SCSI SAS IDE or SATA which may be available to the other media agents via a variety of packet delivery frameworks.

In some implementations the Access Media Agent may be implemented on the SAN storage server as a Linux application. The Linux platform executing on the SAN storage server may be based on e.g. Red Hat Enterprise Linux 6 release. A socket framework further described below may be used for data delivery. The use of a socket layer interface in one aspect allows for code reuse by relying on the mechanism of maintaining data buffers at the kernel level by sharing the data buffers with application layer as is further described below.

The data delivery over the Fibre Channel may be performed using a connection less protocol such as the User Datagram Protocol UDP . The UDP framework in one aspect allows for an easy mix and match of media agents that use OS such as Linux AIX Solaris Windows HP Unix and so on. In another aspect the UDP framework allows re use of code that may be used for sharing storage devices over a LAN connection such as a network attached storage framework. In some implementation an application layer packet retry mechanism may be implemented to improve reliability of data transmissions.

In some implementations the SAN storage server may include a Fibre Channel Host Bus Adapter HBA such as a product from QLogic Emulex or LSI Logic. Each server hosting a media agent may be fitted with at least one Fibre Channel HBA. The HBA installed in the SAN storage server may be adapted to initialize in SCSI target mode. Such a behavior of the HBA may be accomplished by modifying the Linux protocol stack on the SAN storage server . For greater throughput the modification may be done at the kernel level in kernel modification instead of an application layer level modification user land modification as further described below.

Some implementations of the SAN storage server may use SCSI Target Subsystem SCST which is a robust open source implementation of Target Mode SCSI. In one aspect the SCST is beneficial because it provides device independent Target Mode SCSI operation leaving device dependent detail to be implementation specific. The term device handler is often used to refer to the device dependent functionality. As described below some implementations of the Access Media Agent may use a virtual disk device handler that controls the lower level detail of mapping data transfers to storage device locations.

On the media agent the protocol stack includes an upper layer application layer and a kernel level protocol layer that includes a module configured to operate in the Fibre Channel FC Host Bus Adapter HBA initiator mode e.g. operating on the client side . The kernel level protocol layer is communicatively coupled with a module in the protocol stack configured to operate in the FC HBA Target Mode e.g. on the SAN storage server . In the protocol stack of the target mode device e.g. SAN storage server a Target Driver is in communication with an SCST upper layer . The SCST in turn interfaces with an upper layer in kernel virtual disk device handler module and a User Land Device Handler module . The file system and the SCSI Upper Layer Driver module a SCSI middle layer module and a SCSI low layer driver module are provided on the Target Mode device and are in communication with the SCST and the User Land Device Handler which operates at the application layer.

As depicted in and previously described the SCST thus provides target mode functionality while providing a level of abstraction between target device drivers and the in kernel virtual disk device handler described below.

A channel may be a logical connection through which packet delivery is achieved between a media agent and the access media agent . A channel may represent the combination of a Logical Unit Number LUN and a Logical Block Address LBA that makes the channel identification unique within a combination of the media agents and the access media agent in a given computer network. Each channel may be full duplex in nature. In some implementations socket interface API is used for data transfers over a channel thereby abstracting the internal details about channel management and data transfer.

In some implementations the combination of a channel and LBA may represent a unique access resource. Therefore it may be possible that two separate media agents e.g. share a same virtual disk e.g. via different channels as depicted e.g. by channel .

It will be appreciated that in one aspect the virtualization performed by the media access agent may make the same storage device appear to have distinct Logical Unit Numbers LUNs to different data sources e.g. media agents . Furthermore these LUNs may be different from the LUN used by the access media agent to access the storage device over its local data interface. The access media agent tracks or translates such LUNs to implement the above functionality.

In a SCSI implementation when the access media agent receives an INQUIRY command descriptor block CDB for reading Vital Product Data VPD page 0x83 the access media agent may report a new vendor ID. For example disk vendor may be identified as CVLT FIO for access media agent implementations by CommVault. Furthermore a response which includes the host name of the access server may be provided to an INQUIRY message received to read VPD Page 0xC0. In some implementations the combination of the disk vendor name and the host name may be used to uniquely identify the storage device made available for storage access. For example one data storage device may be identified as Western Digital Disk 0x0F on Server XYZ while another storage device may be identified as Seagate Disk 0x0F on Server ABC and so on.

As previously described the use of logically unique channel numbers by the Access Media Agent at the SAN storage server in one advantageous aspect simplifies the task of uniquely identifying source of a data transfer with the sector on the storage device where the data is stored. In some implementations the Access Media Agent may arbitrate access to the shared data storage by enforcing operator rules related to how much storage capacity to expose to which media agent and read write speeds to be offered to various media agents. For example one operator enforced rule may grant a greater portion of all available storage capacity to a media agent that is handling critical backup operations. Furthermore in some implementations described above because data transfers are exposed to the application layer at the SAN storage server data may be encrypted en route the storage device and correspondingly decrypted when read back from the storage device . The encryption may use e.g. different encrypted keys that are based on a corresponding channel on which the data is transferred.

The Access Media Agent may further perform load balancing between various media agents by keeping track of demand for storage capacity by each media agent . It would be appreciated that in some implementations the Access Media Agent is able to provide simultaneous read access to the same data block stored in the storage device by simply transferring the data block multiple times over the SCSI connection to the media agents .

It will be appreciated that the system described herein includes a centralized server that arbitrates shared data storage e.g. a storage area network SAN by exposing to media agents a common pool of data storage devices as logical units. The centralized server eliminates the need for provisioning storage devices to individual media agents or application servers. The centralized server traps and responds to discovery requests from media agents by employing a virtualization layer implemented as a shared access media agent. The centralized server and access media agent also arbitrates read writes to shared data storage devices to permit concurrent data access of the shared storage devices.

It will also be appreciated that the disclosed techniques in one aspect allow for multiple media agents possibly implemented using different operating systems to simultaneously transfer data to from a storage area network SAN storage server over Fibre Channel. It will further be appreciated that the data transfer may be performed without using a local area network LAN .

It will further be appreciated that techniques are provided that in one aspect allow simultaneous access by multiple servers to a data storage device over a data transfer interface such as a SCSI ATA IDE or SAS interface which in conventional art can only act as a target device for data transfers with a single server. In one aspect the disclosed technique provide the advantage that each server need not have to incur the computational overhead of having to manage details such as where on the storage device to store data data capacity available on the storage device and so on.

Systems and modules described herein may comprise software firmware hardware or any combination s of software firmware or hardware suitable for the purposes described herein. Software and other modules may reside on servers workstations personal computers computerized tablets PDAs smart phones and other devices suitable for the purposes described herein. Modules described herein may be executed by a general purpose computer e.g. a server computer wireless device or personal computer. Those skilled in the relevant art will appreciate that aspects of the invention can be practiced with other communications data processing or computer system configurations including Internet appliances hand held devices including personal digital assistants PDAs wearable computers all manner of cellular or mobile phones multi processor systems microprocessor based or programmable consumer electronics set top boxes network PCs mini computers mainframe computers and the like. Indeed the terms computer server host host system and the like are generally used interchangeably herein and refer to any of the above devices and systems as well as any data processor. Furthermore aspects of the invention can be embodied in a special purpose computer or data processor that is specifically programmed configured or constructed to perform one or more of the computer executable instructions explained in detail herein.

Software and other modules may be accessible via local memory a network a browser or other application in an ASP context or via another means suitable for the purposes described herein. Examples of the technology can also be practiced in distributed computing environments where tasks or modules are performed by remote processing devices which are linked through a communications network such as a Local Area Network LAN Wide Area Network WAN or the Internet. In a distributed computing environment program modules may be located in both local and remote memory storage devices. Data structures described herein may comprise computer files variables programming arrays programming structures or any electronic information storage schemes or methods or any combinations thereof suitable for the purposes described herein. User interface elements described herein may comprise elements from graphical user interfaces command line interfaces and other interfaces suitable for the purposes described herein.

Examples of the technology may be stored or distributed on computer readable media including magnetically or optically readable computer disks hard wired or preprogrammed chips e.g. EEPROM semiconductor chips nanotechnology memory biological memory or other data storage media. Indeed computer implemented instructions data structures screen displays and other data under aspects of the invention may be distributed over the Internet or over other networks including wireless networks on a propagated signal on a propagation medium e.g. an electromagnetic wave s a sound wave etc. over a period of time or they may be provided on any analog or digital network packet switched circuit switched or other scheme .

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in the sense of including but not limited to. As used herein the terms connected coupled or any variant thereof means any connection or coupling either direct or indirect between two or more elements the coupling or connection between the elements can be physical logical or a combination thereof. Additionally the words herein above below and words of similar import when used in this application refer to this application as a whole and not to any particular portions of this application. Where the context permits words in the above Detailed Description using the singular or plural number may also include the plural or singular number respectively. The word or in reference to a list of two or more items covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above Detailed Description is not intended to be exhaustive or to limit the invention to the precise form disclosed above. While specific examples for the invention are described above for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. For example while processes or blocks are presented in a given order alternative implementations may perform routines having steps or employ systems having blocks in a different order and some processes or blocks may be deleted moved added subdivided combined and or modified to provide alternative or subcombinations. Each of these processes or blocks may be implemented in a variety of different ways. Also while processes or blocks are at times shown as being performed in series these processes or blocks may instead be performed or implemented in parallel or may be performed at different times. Further any specific numbers noted herein are only examples alternative implementations may employ differing values or ranges.

The teachings of the invention provided herein can be applied to other systems not necessarily the systems described herein. The elements and acts of the various examples described above can be combined to provide further implementations of the invention.

Any patents and applications and other references noted above including any that may be listed in accompanying filing papers are incorporated herein by reference. Aspects of the invention can be modified if necessary to employ the systems functions and concepts of the various references described above to provide yet further implementations of the invention.

These and other changes can be made to the invention in light of the above Detailed Description. While the above description describes certain examples of the invention and describes the best mode contemplated no matter how detailed the above appears in text the invention can be practiced in many ways. Details of the system may vary considerably in its specific implementation while still being encompassed by the invention disclosed herein. As noted above particular terminology used when describing certain features or aspects of the invention should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics features or aspects of the invention with which that terminology is associated. In general the terms used in the following claims should not be construed to limit the invention to the specific examples disclosed in the specification unless the above Detailed Description section explicitly defines such terms. Accordingly the actual scope of the invention encompasses not only the disclosed examples but also all equivalent ways of practicing or implementing the invention under the claims.

While certain examples are presented below in certain forms the applicant contemplates the various aspects of the invention in any number of claim forms. Accordingly the applicant reserves the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the invention.

