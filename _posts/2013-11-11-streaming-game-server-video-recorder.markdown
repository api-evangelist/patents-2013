---

title: Streaming game server video recorder
abstract: A content provider may operate computing nodes configured to provide graphics rendering services to a client running a game or other application. A graphics frame may be rendered and encoded in a format compatible with a client's display device. A second version of the frame may be encoded in a format having selected storage characteristics and compatible with a plurality of display types. The frame may be added to the end of a video stored by the content provider. Frames may be deleted from the video to prevent the video from exceeding a maximum length.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09374552&OS=09374552&RS=09374552
owner: Amazon Technologies, Inc.
number: 09374552
owner_city: Reno
owner_country: US
publication_date: 20131111
---
This application is related to the following applications each of which is hereby incorporated by reference in its entirety U.S. patent application Ser. No. 14 076 718 filed Nov. 11 2013 entitled VIDEO ENCODING BASED ON AREAS OF INTEREST U.S. patent application Ser. No. 14 076 821 filed Nov. 11 2013 entitled ADAPTIVE SCENE COMPLEXITY BASED ON SERVICE QUALITY U.S. patent application Ser. No. 14 077 127 filed Nov. 11 2013 entitled SERVICE FOR GENERATING GRAPHICS OBJECT DATA U.S. patent application Ser. No. 14 077 136 filed Nov. 11 2013 entitled IMAGE COMPOSITION BASED ON REMOTE OBJECT DATA U.S. patent application Ser. No. 14 077 165 filed Nov. 11 2013 entitled MULTIPLE PARALLEL GRAPHICS PROCESSING UNITS U.S. patent application Ser. No. 14 077 084 filed Nov. 11 2013 entitled ADAPTIVE CONTENT TRANSMISSION U.S. patent application Ser. No. 14 077 180 filed Nov. 11 2013 entitled VIEW GENERATION BASED ON SHARED STATE U.S. patent application Ser. No. 14 077 186 filed Nov. 11 2013 entitled MULTIPLE STREAM CONTENT PRESENTATION U.S. patent application Ser. No. 14 077 149 filed Nov. 11 2013 entitled DATA COLLECTION FOR MULTIPLE VIEW GENERATION U.S. patent application Ser. No. 14 076 815 filed Nov. 11 2013 entitled LOCATION OF ACTOR RESOURCES U.S. patent application Ser. No. 14 077 146 filed Nov. 11 2013 entitled SESSION IDLE OPTIMIZATION FOR STREAMING SERVER U.S. patent application Ser. No. 14 077 023 filed Nov. 11 2013 entitled APPLICATION STREAMING SERVICE U.S. Patent Application No. 61 902 740 filed Nov. 11 2013 entitled EFFICIENT BANDWIDTH ESTIMATION .

Graphics rendering which may be described as a process for generating images for use in games and other computer applications may utilize specialized computing resources such as graphics processing units that may not be available on some computing devices. In some cases even if such resources are available their use would consume excess power run at an insufficient speed or provide an insufficient level of graphical quality. Computing devices may therefore be configured to rely on graphics rendering capabilities provided by computing resources located at a remote facility. The facility may for example be equipped with banks of graphical processing units GPUs or other hardware specialized for the provision of rendering services. A device such as a game console or mobile phone may offload certain graphics processing tasks to services operated at the remote facility possibly achieving improved speed and a higher level of detail than the device could achieve on its own.

In accordance with some example features of the disclosed techniques one or more rendered views of a scene of a particular content item such as a video game movie television program sports broadcast and so forth may be generated by a content provider and transmitted from the provider to multiple different clients. A sequence of frames may form a rendered video. In some cases a content provider may encode rendered frames in a format compatible with a video display device of a client. Embodiments may store a version of the rendered frame in a format compatible with multiple clients. In some cases frames may be retained to form a rendered video. The rendered video may be associated with a maximum number of frames or a maximum length of the rendered video. Embodiments may for example delete a frame from the beginning of the video when adding a frame to the end when a count of the number of frames in the sequence exceeds a maximum number of frames. Embodiments might also delete a frame when a replay time of the video exceeds a maximum length. In some embodiments frames deleted from a video might be transferred to a long term storage device. Rendered videos may be saved to a long term storage device transmitted to a client and so forth. A content provider may receive instructions from a client to retain or distribute segments of a rendered video. In various embodiments a frame may be a composite of all graphics objects backgrounds and so forth analogous to a frame of movie or television program. In other embodiments a frame may be for one or more rendered objects. As used herein the term frame may apply to a complete scene or to one or more objects. For example a video game character might comprise various rendered objects corresponding to the characters face body and clothing. These might be rendered encoded and stored separately from other objects in the rendered content. In a sports broadcast a rendered object might be arrows goal lines or other renderings graphical information which could be superimposed on other graphical images.

In accordance with other example features of the disclosed techniques a client of a content provider may provide metadata corresponding to events occurring in an application for which the content provider is providing rendering services. An application may be associated with graphical content such as video content. The term video content may be used to describe various types of graphical or visual output associated with an application. Video content may also be associated with audio. In various embodiments video content may comprise live video transmissions and recorded video which may be presented from a different perspective than the live transmission. The content provider may associate metadata with the rendered video or with a frame of the rendered video. The content provider may receive metadata indicative of factors such as a time corresponding to a frame of the rendered video an in game event a user of the client and so forth. In some embodiments a content provider may receive information indicative of relationships between rendered videos. As used herein the term metadata may refer to data supplied and or maintained by any combination of a client and or a content provider. For example metadata might comprise user information supplied by a client and game state information generated and maintained by a content provider.

A content provider may provide rendering services to one or more clients. A rendering process may comprise one or more computing nodes configured with instructions and or circuitry corresponding to performing stages of a rendering pipeline . Although shows one rendering pipeline embodiments may employ a number of rendering pipelines which may be distributed across multiple computing nodes and may be dynamically allocated. Embodiments may employ encoders to convert rendered bitmaps to a format compatible with various video display types. In some cases encoders may write encoded frames to encoder output buffers for transmission over network to a client such as game console . In some cases encoders may write a number of frame formats to encoder output buffers . For example encoders might write frames compatible with tablet computer to encoder output buffers . Game console and tablet computer might in some cases receive these rendered frames in real time. For example game console might receive rendered frames while playing a three dimensional video game. At the same time tablet computer might participate in a spectator mode involving user observing a game played on game console by user . Frames written to encoder output buffers may be deleted upon transmission to a respective client.

A content provider may have access to state and metadata information corresponding to the rendered frames or objects. In various embodiments this might comprise complete state information for a game animated movie or other content. For example in a game state and metadata information might comprise a representation of the playing field location of in game characters and so forth. Metadata might also correspond to an event in the game such as completion of a level. In a movie there might be state and metadata information corresponding to characters in the movie corresponding actors plot events and so forth. In various embodiments metadata and state information may be divided shared synchronized or otherwise distributed between a content provider and one or more clients such as game console tablet computer and mobile phone .

Embodiments may store a version of encoded frames in recorder buffers . Encoded frames may be stored in a format compatible with replaying a sequence of frames on various display types. For example encoded frames may be stored in recorder buffers in a format determined based in part on clients receiving a real time transmission of the video. In other cases encoded frames may be stored in recorder buffers based on compatibility with clients who might view the video at a later time. For example user might view a video stored in recorder buffers while using a display of mobile phone . In various embodiments video stored in recorder buffers may be transferred to a storage device for long term storage and subsequently transmitted to a client which may for example include game console tablet computer or mobile phone .

In some cases encoders may write frames successively to encoder output buffers and recorder buffers . For example an encoder of encoders might write a frame compatible with video of 1080 lines per frame utilizing a progressive scan format to encoder output buffers and a frame compatible with 480 lines per frame using an interlaced scan format to recorder buffers .

Other embodiments may perform actions such as transcoding on a frame stored in encoder output buffers to produce a frame in a second format for storage in recorder buffers . In some cases the format of frames stored in encoder output buffers may be the same as frames to be stored in recorder buffers . Some embodiments may in such cases copy frames from one location to the other.

Embodiments may utilize combined stages of a rendering pipeline and encoders to produce encoded videos from multiple perspectives. For example while rendering pipeline and one or more encoders might transmit frames rendered from a first person perspective to client viewing content live rendering pipeline and one or more encoders might render and encode frames from an isometric perspective. In various embodiments state and metadata information may be employed in rendering and encoding a video for recording. For example a video might be rendered and recorded corresponding to the viewpoint of an opponent using game state information. Embodiments might employ state and or metadata information to render additional objects not present in video rendered for live transmission. An embodiment might for example render an enhanced version of a projectile or other object and encode the enhanced version in a recorded video.

Operation depicts transformation in which various mathematical or computational algorithms may be performed on geometric models vertices and so forth. Various non limiting examples of transformations include positional rotational and size transformations. Camera based transformations which may be described as transforming data for rendering a graphics scene from a particular viewpoint may also be performed.

Operation depicts rasterization which may involve generating pixel based representations of the graphics scene based on the model. In various embodiments rasterization may be performed on geometric models arrays of vertices and so forth after transformation. In some embodiments rasterization may involve clipping geometric primitives and preparing geometric primitives for pixel shading .

As depicted by operation pixel shading may involve processing of rasterized geometric primitives generating pixel values such as color and or luminosity and so on. In some cases and embodiments texture data may be incorporated into pixel shading operation .

An output assembly operation may involve incorporating output from previous pipeline stages into pixels determined to be visible in the rendered frame. Pixel values from previous stages may in some embodiments be blended to form a pixel shown in the rendered image. Output assembly may involve writing pixels to one or more render targets which may comprise memory buffers or other structures for storing a rendered image.

Operation may involve encoding the rendered frame in a format compatible for display on a rendering service client s display device. Although depicted as a discrete operation in in various embodiments encoding operation may be comprised of various encoding pipeline stages. Encoding operation may in various cases and embodiments comprise encoding the rendered frame to a format for video display. This may for example comprise operations involving resolution color representation frames per second interlaced or progressive scan transmission compression and so forth. Embodiments may encode one or more versions of a rendered frame. Each of these encoded frames corresponds to the same moment in time or more generally the same moment in an animated sequence. Embodiments may also employ multiple rendering operations to render and encode a number of frames each of which may be from a different viewpoint but correspond to the same point in time or the same point in an animated sequence. A different viewpoint may comprise different camera position distance orientation and so forth. For example a second version of a frame might be rendered and encoded from the viewpoint of a different character. Some embodiments may employ combined rendering and encoding operations to produce multiple encoded versions of a frame corresponding to the same point in time.

As indicated by arrow an encoding operation may be repeated for real time transmission to multiple devices. For example a game console may be executing an application which is a client of a rendering service of a content provider. Encoding operation may be performed in relation to transmission of rendered video content to the game console for display on a video display device associated with the game console. Encoding operation may also be performed in relation to transmission of the same rendered video content to another device on which a user is simultaneously viewing the rendered content. For example while a user of a game console is playing the game another user might be viewing the game in a spectator mode on a mobile device. Encoding operations might be performed to encode the rendered video in a format compatible with a display associated with the game console and in a format compatible with a display device associated with the mobile device. Encoding operations may be employed to supply rendered content in a format in which it may be displayed. In addition to rendering video in a format compatible with a display device this might comprise alternative encodings which might allow rendered content to be displayed. Embodiments may also perform encoding operations to provide for flexible post encoding operations such as combination with additional rendered objects application of filters or other image effects formation of alternative views perspectives or zoom levels and so on.

In various embodiments encoding operations may also be utilized to provide additional encoded video for transmission or recording. The additional encoded video may be used to display content from additional viewpoints or perspectives. For example in one embodiment state and metadata information may be used to identify in application events. For the in application events a zoomed perspective may be employed. In other embodiments additional views may be provided that are zoomed out to a distance in which all players are captured in the video. In yet another embodiment a client may send information indicating that an alternative perspective or zoom level should be employed in a version of a video to be replayed later.

Operation involves recording encoded output which may in some embodiments involve storing output of operation . Encoded frames may be stored on storage devices communicatively coupled to computing nodes on which a rendering process is executing. Encoded frames may be buffered so that a video sequence comprising encoded frames is limited by a factor such as a maximum length of the video or a maximum number of frames in the video.

In some cases and embodiments as depicted by arrow encoding operation may be repeated to encode video in a format for recording. For example while live video might involve transmission of 720 lines of resolution per frame recorded video might involve storing 480 lines of resolution per frame. If so encoding operation might be performed twice to encode frames for transmission with 720 lines of resolution and again to encode for recording video at 480 lines of resolution per frame.

Operation depicts receiving input for encoding. This may in some embodiments comprise rendered frames or sequences of frames from a rendering pipeline. In some cases and embodiments encoding may proceed on partially formed input. A rendering pipeline and encoding pipeline may for example proceed in parallel. In some embodiments various aspects of graphics processing and encoding may be performed in parallel or in an integrated fashion. Embodiments may for example utilize GPU accelerated encoding.

Operation depicts a decoding stage. In some cases and embodiments decoding may involve conversion from one format to another format. The destination format may for example comprise normalized representations of data on which subsequent encoding pipeline stages may operate.

As depicted by operation various pre processing operations may be performed on data in the encoding pipeline. These may comprise various operations common to encoding in each destination format. For example if each destination format is to be rendered at 1080 pixels per line a pre processing operation might convert a rendered image line to 1080 pixels. Various embodiments may omit pre processing operations.

Operation depicts encoding rendered video in a first encoding format. The encoded video may then be transmitted as depicted by operation . Transmission may comprise buffering frame sequences for transmission to a client device.

Operation depicts performing an additional encoding of the rendered video to form a version of the rendered frame in a second format. The second format may be compatible with storage requirements of the content provider. This may for example comprise compressed or lower resolution formats allowing for greater storage efficiency. The second format may also be compatible with a broad range of potential display devices. In some cases and embodiments the second format may be compatible with a device associated with the rendering service client such as a game console for which the content was originally rendered as well as additional devices which might view the recorded content such as a tablet computer or mobile device. A second version of a rendered frame may in some embodiments be rendered from a different viewpoint or perspective than the first version of the frame. For example a second frame might be rendered and encoded to show the same graphical object or scene but from a different distance or from the point of view of a different character. The viewpoint used may be based in part on state or metadata corresponding to the current application.

At operation the additional encoding of the rendered frame may be recorded. A frame may be recorded by storing the encoded frame in a temporary or long term storage location. A temporary location could include a variety of storage device types and mechanisms including a primary memory of a computing node. Long term storage could include most types of storage devices and mechanisms including solid state and mechanical disk drives databases and so forth. In either case some embodiments may retain encoded frames indefinitely. Other embodiments might retain recorded frames up to a maximum length retaining newly added frames and discarding earliest added frames.

In various embodiments output from multiple rendering targets or output from rendering pipelines may be merged. This may for example comprise overlaying rendered graphics with copyright information watermarks promotional information information pertaining to in game events and so forth. In some embodiments rendered graphics from multiple clients may be overlaid or juxtaposed. For example in a multiplayer game multiple game consoles may each utilize rendering services of a content provider. Rendered video from pipelines associated with each user might be merged and encoded in a video comprising the gameplay as viewed by each user.

Operations and depict receiving output from a first and second rendering operation. In this context a rendering operation may include for example output of a rendering pipeline output of a stage of a rendering pipeline and so forth. For example an embodiment that overlays copyright information might merge output from intermediate stages of a rendering operation while an embodiment that juxtaposes the viewpoints of players in a multiplayer game might merge output from rendering pipelines. The output of a rendering operation may be described as a graphical element. A graphical element may include in various non limiting examples a rendered frame a rendered object text video photographs and so forth.

In various embodiments output from a rendering operation may be altered for optimized combination and or transformation in the encoding stage. In some embodiments rendering and encoding pipeline stages may be combined. A wide variety of optimizations and transformations are possible. Embodiments may for example encode metadata during the rendering phase that may be employed during the encoding phase or used for purposes such as indexing. Embodiments may perform partial rendering render in a format that is optimized for a particular encoding format render additional objects render additional perspectives and so on. Various encoding operations may be performed during the rendering stage. Embodiments may spawn additional rendering and or encoding pipelines in order to provide additional rendering and or encoding services. In some embodiments additional pipelines may operate on additional computing nodes which may be dynamically allocated according to a current level of resource utilization.

Operation depicts merging the output. This may comprise various positional transformations occlusion culling and so forth to produce a combined rendered image. The output may then be encoded in a format suitable for recording and display on a desired display device type. In various embodiments operations and may be performed in parallel or as an integrated operation. For example an overlay of copyright information might be superimposed on the rendered image during the encoding stage rather than as a discrete operation.

Embodiments may provide for control of video recording by a client of a content provider. For example a client comprising a game console and or an application running on the game console could issue requests indicative of controlling various aspects of recording and playback. depicts an embodiment of a system for issuing recording control requests. Those of ordinary skill in the art will appreciate that the depicted example is intended to be illustrative of various possible combinations and permutations and should not be construed as limiting the scope of the present disclosure.

A client may be various types of devices and or applications running on devices such as game consoles smartphones mobile devices tablet computers personal computers and so forth. The term client may refer to the device to an operating system of a device an application running on the device an API used on the device and so on. For example in client might comprise both client process and rendering service API . Accordingly the term client may be used herein to refer to various combinations of hardware devices circuitry software applications software libraries and so forth that may rely collectively or individually on rendering services provided by a content provider.

A client process may consist of various combinations of hardware circuitry and executable instructions such as software that perform some function on a client device. Client process may comprise one or more modules implementing various aspects of an application s functionality. Client processes include but are not limited to video games video playback services video editing animation search linking simulation and so forth. Modules may include any combination of computer readable instructions circuitry and so forth. A module may for example include statically and dynamically linked libraries business objects component objects graphics processing units physics processing units and so on. A client process may in some embodiments comprise modules receiving input from a user transmitting information indicative of the input to a content provider and displaying frames rendered by the content provider. Various additional aspects of gameplay such as artificial intelligence maintaining state information representative of the game and so forth may also be implemented by the content provider. Other embodiments may incorporate greater or lesser amounts of functionality on the client.

One example of an application among many possible examples is a game program. Client process might interface with rendering service API to request that rendering services be performed by a content provider on behalf of a client. In various embodiments an API might also comprise various modules exposing or facilitating the use of various objects methods protocols or functions involving control of recording and playback operations performed by a content provider. Non limiting examples of modules related to control or recording and playback operations include user metadata game event metadata recording control and playback control .

User metadata module may involve providing various forms of user related metadata to the content provider for use in conjunction with video recording. User metadata may comprise information indicative of a user s name email address nickname and so forth. A content provider may receive user metadata and store associations between user metadata and recorded video sequences. For example a video sequence might be stored and associated with a user of the console on which the game corresponding to the video sequence was played.

User metadata is one example of metadata that may be provided by a client and stored by a content provider. Other examples include information related to application publisher application version date and time hardware configuration and so forth. A content provider may store the metadata and record an association between stored metadata and corresponding video sequences. Embodiments may also associate metadata with individual frames of a video sequence or a subset of frames of a video sequence.

Event metadata module may involve a client providing information to a content provider related to in game events which may also be referred to as in application events. Non limiting examples of such events are achievement of a high score winning an in game contest finishing a game level and so on. A content provider may receive information sent to it by event metadata module . Aspects of the received information may be stored and associated with a video a subset of frames of a video sequence or an individual frame of a video sequence. In some cases and embodiments metadata may pertain to movies television broadcast sports events and so on. In one embodiment rendered graphics may be combined with a broadcast program. Metadata may correspond to various characters occurrences or other aspects of the broadcast program and may be associated with a recorded video that combines the rendered graphics with the broadcast program.

Recording control module may involve aspects of controlling recording of video by a content provider on behalf of a client for which the content provider provides rendering services. Aspects of control include but are not limited to lengthening or shortening maximum lengths of automatically retained videos saving automatically retained videos to a long term storage location retaining individual frames for long term storage controlling resolution of recorded videos and frames pausing recording resuming recording changing perspective of viewing zooming in zooming out panning shifting perspective and so forth. A client may transmit or otherwise send a request to a content provider to perform one or more of these and similar actions. For example a client might send a request to a content provider to permanently retain one or more frames from the last ten seconds of gameplay. In some embodiments requests to perform an action related to recording control may be sent in a same message as a request to perform a rendering service.

Playback control module may involve aspects of controlling transmission of video previously recorded by a content provider. This may involve a variety of active and passive mechanisms. Examples of active playback control mechanisms include processing a request to send a client a recorded video or one or more frames from a recorded video. Embodiments may provide for sending recorded video and frames via email messaging and other communications mechanisms. An example of passive playback control mechanisms involves associating recorded video with users groups or roles authorized to view the video. Another example involves associating recorded video with metadata comprising information such as date time creator game game publisher game category and various other descriptive keywords. Recorded video may also be marked as searchable.

Operation depicts receiving a request to render a frame of graphics on behalf of a client. Typically a frame is one of a sequence of frames rendered to form an animated sequence or more generally a video. A video may be described as comprising a sequence of frames ordered in time such that the first frame corresponds to the earliest time of the video and the last frame corresponds to the latest time of the video. In some formats such as an interlaced format a rendered frame may span more than one refresh cycle in an encoded file.

At operation the request frame may be rendered by a rendering process hosted by a content provider. A rendering process may utilize resources such as geometric models textures and so forth stored by the content provider and associated with a game or other process running on a client. A rendering process may utilize a rendering pipeline such as the one depicted in to produce a rendered graphics frame.

Operation depicts encoding a first version of the rendered graphics frame in a format compatible with a display device associated with the client. In some embodiments this format may be optimized for real time transmission to the client. A client may supply information such as a desired minimum frame rate such as 60 frames per second. A format for encoding for live transmission may be selected based in part on the desired frame rate. Other possible factors may include but are not limited to resolution color density compression ratios and so forth.

Operation depicts transmitting the first version of the frame to a client. In some cases and embodiments the frame may be transmitted to a client that had issued a corresponding request to perform a rendering operation and to one or more additional clients operating in spectator mode. Embodiments may perform multiple encoding operations to form additional versions of the rendered frame in formats compatible with other devices operating in a spectator mode.

Operation depicts encoding a second version of the rendered frame in a format compatible with a display device associated with a client as well as with additional display device types which may not be known at encoding time but may be used to view the video after it has been recorded. The format of the second version may also be compatible with storage requirements. It may for example be desirable to store video in a format that is more space efficient than the transmitted format. Some embodiments might record video in a format that graphically improves upon the transmitted frame. For example if the original video was rendered for a mobile device embodiments might transmit video in real time using a low definition format but store video using a high definition encoding format.

In some cases and embodiments the first and second formats may be the same. Embodiments may therefore use the first encoded version of the rendered frame as the second encoding version and a step for encoding the second version may involve only copying the first version while storing it.

Operation depicts storing the second version of the encoded frame. Embodiments may employ a variety of storage locations and storage strategies. Non limiting examples include a primary memory of a computing node of the content provider a storage device such as a solid state or mechanical disk drive a database and so on. Some embodiments may retain a certain number of frames on one type of device and archive frames on another type.

As depicted by operation embodiments may remove the oldest frame in a sequence of frames upon adding a new frame to the end of the sequence. Removal of the oldest frame may be conditioned upon exceeding a threshold value. The threshold value may correspond to a maximum number of frames a playback time of the sequence of frames and so forth. The earliest frame in a sequence of frames may be removed upon adding a new frame to the sequence and determining that the threshold has been exceeded. Content providers may receive requests or other information from a client that indicates an adjustment to the threshold value.

A content provider may operate one or more computing nodes such as computing node on which rendering process may operate. In some cases and embodiments a rendering process may correspond to an instance of an executable application. However a rendering process may instead comprise component invocations library calls objects multiple instances of an executable application and so on.

A rendering process may be associated with a set of one or more clients such as client . A client process may operate on client . Client process may be a game or other application which may rely on the graphics rendering services of content provider . A rendering service API may be used in conjunction with client process or in conjunction with an operating system of client to provide rendering services.

A content provider may associate client or an aspect thereof such as client process with rendering process . Application may issue requests to rendering process to render graphics frames. Requests may be issued through rendering service API . Frames rendered by rendering process in response to the requests may be transmitted in real time to client or an element thereof. A network such as the Internet may be used as a transmission medium. As used herein the term real time means while application is running and within a time frame sufficient to provide an impression to a user of client that the graphics are rendered in response to events occurring in client process . The term real time may also be defined in terms of contrast with after the fact viewing. For example a user of client might view video in real time while actively playing a game corresponding to client process . Later he might view a replay of the gameplay. The latter case is not real time. A live spectator may also receive frames rendered by rendering process in real time.

Frames rendered by rendering process may be retained in one or more storage devices such as storage . Embodiments may associate storage with searching and indexing which may comprise indexes describing recorded frames or sequences of frames. Indexing may refer to any of various techniques for allowing data to be located or accessed. In some embodiments storage and searching and indexing may be integrated for example by storing data in a relational database. Embodiments may store associations between metadata and recorded frames or sequences of frames. For example recorded frames and sequences of frames may be stored in association with distribution format exchange profile DFXP which may also be referred to as time and text markup language. Other embodiments may store tags in an index which refers to frames or sequences of frames. In various cases and embodiments recorded video may be associated with timestamps time codes subtitles copyright information and so forth. The term timestamp may be used to refer to any form of date and or time information including absolute date or time values relative date and or time values and offsets. Recorded video may in some embodiments be associated with session information such as the date and time a game was played the users involved the game played and so on. Associations may also be recorded between video recorded by multiple users such as multiple users involved in a common multiplayer game. In some embodiments users may provide annotations which may be associated with recorded videos or particular frames of a recorded video. Annotations may be textual audio visual or some combination thereof. Annotations may also comprise various forms of metadata such as timestamps comments information about game events publisher information game information and so forth.

A recorded video service may perform various services in conjunction with storage and or indexing . For example recorded video service may utilize index to provide search features related to recorded video. In various cases and embodiments video may be searched during or after it is recorded.

Recorded video may be transmitted to viewer device which may be a device capable of displaying received video transmissions. In some embodiments recorded video service may response to a request from viewer device to transmit one or more frames associated with recorded video. The request by viewer device may be in response to searches performed on behalf of viewer device by recorded video service . For example recorded video service might provide a web page which lists recorded video pertaining to a game. A user of viewer device might select one of these for viewing. In response recorded video service might retrieve the video from storage and transmit it to viewer device .

A content provider may in some cases render and transmit content item views to clients over an electronic network such as the Internet. Content may in some cases be provided upon request to clients using for example streaming content delivery techniques. An example computing environment that enables rendering and transmission of content to clients will now be described in detail. In particular illustrates an example computing environment in which the embodiments described herein may be implemented. is a diagram schematically illustrating an example of a data center that can provide computing resources to users and which may be referred herein singularly as user or in the plural as users via user computers and which may be referred herein singularly as computer or in the plural as computers via a communications network . Data center may be configured to provide computing resources for executing applications on a permanent or an as needed basis. The computing resources provided by data center may include various types of resources such as gateway resources load balancing resources routing resources networking resources computing resources volatile and non volatile memory resources content delivery resources data processing resources data storage resources data communication resources and the like. Each type of computing resource may be general purpose or may be available in a number of specific configurations. For example data processing resources may be available as virtual machine instances that may be configured to provide various web services. In addition combinations of resources may be made available via a network and may be configured as one or more web services. The instances may be configured to execute applications including web services such as application services media services database services processing services gateway services storage services routing services security services encryption services load balancing services application services and the like. These services may be configurable with set or custom applications and may be configurable in size execution cost latency type duration accessibility and in any other dimension. These web services may be configured as available infrastructure for one or more clients and can include one or more applications configured as a platform or as software for one or more clients. These web services may be made available via one or more communications protocols. Data storage resources may include file storage devices block storage devices and the like.

Each type or configuration of computing resource may be available in different sizes such as large resources consisting of many processors large amounts of memory and or large storage capacity and small resources consisting of fewer processors smaller amounts of memory and or smaller storage capacity. Customers may choose to allocate a number of small processing resources as web servers and or one large processing resource as a database server for example.

Data center may include servers which may be referred herein singularly as server or in the plural as servers that provide computing resources. These resources may be available as bare metal resources or as virtual machine instances and which may be referred herein singularly as virtual machine instance or in the plural as virtual machine instances . Virtual machine instances and are shared state virtual machine SSVM instances. The SSVM virtual machine instances and may be configured to perform all or any portion of the shared content item state techniques and or any other of the disclosed techniques in accordance with the present disclosure and described in detail below. As should be appreciated while the particular example illustrated in includes one SSVM virtual machine in each server this is merely an example. A server may include more than one SSVM virtual machine or may not include any SSVM virtual machines.

The availability of virtualization technologies for computing hardware has afforded benefits for providing large scale computing resources for customers and allowing computing resources to be efficiently and securely shared between multiple customers. For example virtualization technologies may allow a physical computing device to be shared among multiple users by providing each user with one or more virtual machine instances hosted by the physical computing device. A virtual machine instance may be a software emulation of a particular physical computing system that acts as a distinct logical computing system. Such a virtual machine instance provides isolation among multiple operating systems sharing a given physical computing resource. Furthermore some virtualization technologies may provide virtual resources that span one or more physical resources such as a single virtual machine instance with multiple virtual processors that spans multiple distinct physical computing systems.

Referring to communications network may for example be a publicly accessible network of linked networks and possibly operated by various distinct parties such as the Internet. In other embodiments communications network may be a private network such as a corporate or university network that is wholly or partially inaccessible to non privileged users. In still other embodiments communications network may include one or more private networks with access to and or from the Internet.

Communication network may provide access to computers . User computers may be computers utilized by users or other customers of data center . For instance user computer or may be a server a desktop or laptop personal computer a tablet computer a wireless telephone a personal digital assistant PDA an e book reader a game console a set top box or any other computing device capable of accessing data center . User computer or may connect directly to the Internet e.g. via a cable modem or a Digital Subscriber Line DSL . Although only two user computers and are depicted it should be appreciated that there may be multiple user computers.

User computers may also be utilized to configure aspects of the computing resources provided by data center . In this regard data center might provide a gateway or web interface through which aspects of its operation may be configured through the use of a web browser application program executing on user computer . Alternately a stand alone application program executing on user computer might access an application programming interface API exposed by data center for performing the configuration operations. Other mechanisms for configuring the operation of various web services available at data center might also be utilized.

Servers shown in may be standard servers configured appropriately for providing the computing resources described above and may provide computing resources for executing one or more web services and or applications. In one embodiment the computing resources may be virtual machine instances . A virtual machine instance may be referred to as a virtual machine. As discussed above each of the virtual machine instances may be configured to execute all or a portion of an application. In the example of virtual machine instances Data center may be configured to execute an instance manager or which may be referred herein singularly as instance manager or in the plural as instance managers capable of executing the virtual machine instances . The instance managers may be a virtual machine monitor VMM or another type of program configured to enable the execution of virtual machine instances on server for example. It will be appreciated that the configuration of instance managers as depicted by is subject to change and that instance managers may for example be configured to operate as a front end to router . In some embodiments instance managers may be hosted on servers or on other computing nodes.

It should be appreciated that although the embodiments disclosed above discuss the context of virtual machine instances other types of implementations can be utilized with the concepts and technologies disclosed herein. For example the embodiments disclosed herein might also be utilized with computing systems that do not utilize virtual machine instances.

In the example data center shown in a router may be utilized to interconnect the servers and . Router may also be connected to gateway which is connected to communications network . Router may be connected to one or more load balancers and alone or in combination may manage communications within networks in data center for example by forwarding packets or other data communications as appropriate based on characteristics of such communications e.g. header information including source and or destination addresses protocol identifiers size processing requirements etc. and or the characteristics of the private network e.g. routes based on network topology etc. . It will be appreciated that for the sake of simplicity various aspects of the computing systems and other devices of this example are illustrated without showing certain conventional details. Additional computing systems and other devices may be interconnected in other embodiments and may be interconnected in different ways.

It should be appreciated that the network topology illustrated in has been greatly simplified and that many more networks and networking devices may be utilized to interconnect the various computing systems disclosed herein. These network topologies and devices should be apparent to those skilled in the art.

It should also be appreciated that data center described in is merely illustrative and that other implementations might be utilized. Additionally it should be appreciated that the functionality disclosed herein might be implemented in software hardware or a combination of software and hardware. Other implementations should be apparent to those skilled in the art. It should also be appreciated that a server gateway or other computing device may comprise any combination of hardware or software that can interact and perform the described types of functionality including without limitation desktop or other computers database servers network storage devices and other network devices PDAs tablets cellphones wireless phones pagers electronic organizers Internet appliances television based systems e.g. using set top boxes and or personal digital video recorders and various other consumer products that include appropriate communication capabilities. In addition the functionality provided by the illustrated modules may in some embodiments be combined in fewer modules or distributed in additional modules. Similarly in some embodiments the functionality of some of the illustrated modules may not be provided and or other additional functionality may be available.

In at least some embodiments a server that implements a portion or all of one or more of the technologies described herein may include a general purpose computer system that includes or is configured to access one or more computer accessible media. depicts a general purpose computer system that includes or is configured to access one or more computer accessible media. In the illustrated embodiment computing device includes one or more processors and or which may be referred herein singularly as a processor or in the plural as the processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

In some embodiments a graphics processing unit GPU may participate in providing graphics rendering and or physics processing capabilities. A GPU may for example comprise a highly parallelized processor architecture specialized for graphical computations. In some embodiments processors and GPU may be implemented as one or more of the same type of device.

System memory may be configured to store instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripherals in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other device or devices attached to a network or networks such as other computer systems or devices for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet networks for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs storage area networks or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer accessible medium configured to store program instructions and data as described above for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible media. Generally speaking a computer accessible medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer accessible storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc. that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer accessible medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as those that may be implemented via network interface . Portions or all of multiple computing devices such as those illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

A compute node which may be referred to also as a computing node may be implemented on a wide variety of computing environments such as tablet computers personal computers smartphones game consoles commodity hardware computers virtual machines web services computing clusters and computing appliances. Any of these computing devices or environments may for convenience be described as compute nodes or as computing nodes.

A network set up by an entity such as a company or a public sector organization to provide one or more web services such as various types of cloud based computing or storage accessible via the Internet and or other networks to a distributed set of clients may be termed a provider network. Such a provider network may include numerous data centers hosting various resource pools such as collections of physical and or virtualized computer servers storage devices networking equipment and the like needed to implement and distribute the infrastructure and web services offered by the provider network. The resources may in some embodiments be offered to clients in various units related to the web service such as an amount of storage capacity for storage processing capability for processing as instances as sets of related services and the like. A virtual computing instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor .

A number of different types of computing devices may be used singly or in combination to implement the resources of the provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like. In some embodiments a client or user may be provided direct access to a resource instance e.g. by giving a user an administrator login and password. In other embodiments the provider network operator may allow clients to specify execution requirements for specified client applications and schedule execution of the applications on behalf of the client on execution platforms such as application server instances Java virtual machines JVMs general purpose or special purpose operating systems platforms that support various interpreted or compiled programming languages such as Ruby Perl Python C C and the like or high performance computing platforms suitable for the applications without for example requiring the client to access an instance or an execution platform directly. A given execution platform may utilize one or more resource instances in some implementations in other implementations multiple execution platforms may be mapped to a single resource instance.

In many environments operators of provider networks that implement different types of virtualized computing storage and or other network accessible functionality may allow customers to reserve or purchase access to resources in various resource acquisition modes. The computing resource provider may provide facilities for customers to select and launch the desired computing resources deploy application components to the computing resources and maintain an application executing in the environment. In addition the computing resource provider may provide further facilities for the customer to quickly and easily scale up or scale down the numbers and types of resources allocated to the application either manually or through automatic scaling as demand for or capacity requirements of the application change. The computing resources provided by the computing resource provider may be made available in discrete units which may be referred to as instances. An instance may represent a physical server hardware platform a virtual machine instance executing on a server or some combination of the two. Various types and configurations of instances may be made available including different sizes of resources executing different operating systems OS and or hypervisors and with various installed software applications runtimes and the like. Instances may further be available in specific availability zones representing a logical region a fault tolerant region a data center or other geographic location of the underlying computing hardware for example. Instances may be copied within an availability zone or across availability zones to improve the redundancy of the instance and instances may be migrated within a particular availability zone or across availability zones. As one example the latency for client communications with a particular server in an availability zone may be less than the latency for client communications with a different server. As such an instance may be migrated from the higher latency server to the lower latency server to improve the overall client experience.

In some embodiments the provider network may be organized into a plurality of geographical regions and each region may include one or more availability zones. An availability zone which may also be referred to as an availability container in turn may comprise one or more distinct locations or data centers configured in such a way that the resources in a given availability zone may be isolated or insulated from failures in other availability zones. That is a failure in one availability zone may not be expected to result in a failure in any other availability zone. Thus the availability profile of a resource instance is intended to be independent of the availability profile of a resource instance in a different availability zone. Clients may be able to protect their applications from failures at a single location by launching multiple application instances in respective availability zones. At the same time in some implementations inexpensive and low latency network connectivity may be provided between resource instances that reside within the same geographical region and network transmissions between resources of the same availability zone may be even faster .

Each of the processes methods and algorithms described in the preceding sections may be embodied in and fully or partially automated by code modules executed by one or more computers or computer processors. The code modules may be stored on any type of non transitory computer readable medium or computer storage device such as hard drives solid state memory optical disc and or the like. The processes and algorithms may be implemented partially or wholly in application specific circuitry. The results of the disclosed processes and process steps may be stored persistently or otherwise in any type of non transitory computer storage such as e.g. volatile or non volatile storage.

The various features and processes described above may be used independently of one another or may be combined in various ways. All possible combinations and subcombinations are intended to fall within the scope of this disclosure. In addition certain methods or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence and the blocks or states relating thereto can be performed in other sequences that are appropriate. For example described blocks or states may be performed in an order other than that specifically disclosed or multiple blocks or states may be combined in a single block or state. The example blocks or states may be performed in serial in parallel or in some other manner. Blocks or states may be added to or removed from the disclosed example embodiments. The example systems and components described herein may be configured differently than described. For example elements may be added to removed from or rearranged compared to the disclosed example embodiments.

It will also be appreciated that various items are illustrated as being stored in memory or on storage while being used and that these items or portions thereof may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively in other embodiments some or all of the software modules and or systems may execute in memory on another device and communicate with the illustrated computing systems via inter computer communication. Furthermore in some embodiments some or all of the systems and or modules may be implemented or provided in other ways such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the modules systems and data structures may also be stored e.g. as software instructions or structured data on a computer readable medium such as a hard disk a memory a network or a portable media article to be read by an appropriate drive or via an appropriate connection. The systems modules and data structures may also be transmitted as generated data signals e.g. as part of a carrier wave or other analog or digital propagated signal on a variety of computer readable transmission media including wireless based and wired cable based media and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly the present invention may be practiced with other computer system configurations.

Conditional language used herein such as among others can could might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While certain example embodiments have been described these embodiments have been presented by way of example only and are not intended to limit the scope of the inventions disclosed herein. Thus nothing in the foregoing description is intended to imply that any particular feature characteristic step module or block is necessary or indispensable. Indeed the novel methods and systems described herein may be embodied in a variety of other forms furthermore various omissions substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions disclosed herein. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of certain of the inventions disclosed herein.

