---

title: Multiple concurrent audio modes
abstract: Embodiments described herein include devices and processes for concurrently processing different audio streams with different hardware-based audio processing modes. A computing device for such embodiments may have multiple hardware audio signal processing modes capable of parallel execution. An operating system or audio stack thereof may manage audio paths or streams for audio sources producing respective types of audio signals. Which of the audio paths or streams will be connected with which of the hardware audio signal processing modes may be determined according to the types of the audio signals. A first hardware audio signal processing mode may be processing a first type of audio signal of a first audio path or stream while concurrently a second hardware audio signal processing mode processes a second type of audio signal of a second audio path or stream.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519708&OS=09519708&RS=09519708
owner: Microsoft Technology Licensing, LLC
number: 09519708
owner_city: Redmond
owner_country: US
publication_date: 20130529
---
Computing devices often are equipped with specialized audio hardware for performing audio signal processing. Typically such audio hardware includes one or more digital signal processing chips or algorithms that perform signal processing on audio signals being captured or generated by a computing device. Such signal processing may cause specific audio effects such as enhancing a music signal removing echo from a VoIP voice over Internet Protocol signal reducing noise simulating reverberation and so forth. In some cases such dedicated audio hardware or audio cards often connected via a host bus are able to provide a variety of such hardware based signal processing modes or effects.

Previously computing devices were unable to use more than one such hardware based signal processing mode at a time even when a dedicated audio signal processing device is configured with multiple of such modes. An operating system would usually handle the availability of multiple modes by alternatively shifting all audio processing for all audio paths or streams from one mode to another. At any given time all audio being processed by the computing device would be processed by a same hardware based audio signal processing mode.

This approach has shortcomings recognized only by the instant inventors. At times different applications on a computing device may have different signal processing preferences. For example a VoIP application might need echo cancellation processing at its input and minimal processing at its output while at the same time a music player rendering music might need noise reduction signal processing to enhance the rendered audio which likely introduces latency. In addition the prior single mode approach has prevented full utilization of audio hardware resources. Regardless of whether audio hardware has been capable of concurrent multi mode processing operating systems managing such hardware have not been designed to take advantage of such a capability.

The following summary is included only to introduce some concepts discussed in the Detailed Description below. This summary is not comprehensive and is not intended to delineate the scope of the claimed subject matter which is set forth by the claims presented at the end.

Embodiments described herein include devices and processes for concurrently processing different audio streams with different hardware based audio processing modes. A computing device for such embodiments may have multiple hardware audio signal processing modes capable of parallel execution. An operating system or audio stack thereof may manage audio paths or streams for audio sources producing respective types of audio signals. Which of the audio paths or streams will be connected with which of the hardware audio signal processing modes may be determined according to the types of the audio signals. A first hardware audio signal processing mode may be processing a first type of audio signal of a first audio path or stream while concurrently a second hardware audio signal processing mode processes a second type of audio signal of a second audio path or stream.

Many of the attendant features will be explained below with reference to the following detailed description considered in connection with the accompanying drawings.

Embodiments discussed below relate to providing multiple audio modes that can be concurrently applied to different audio streams. Discussion will begin with an overview of a computing device configured with audio signal processing hardware. Next an audio stream management scheme implemented by an operating system will be discussed. Details of an audio stream stack will be described next followed by discussion of processes performed thereby.

An operating system on the computing device controls access to and use of the audio hardware by one or more applications possibly with the use of a device driver not shown . In particular an audio stack audio functions of the operating system may manage audio pathways also referred to as paths or streams linking audio signals to from applications with the audio hardware . While implementation details will vary for different operating systems audio streams are flows of digital audio signal data between sources and destinations. Depending on the direction of an audio stream sources and destinations might be applications microphones loudspeakers storage etc. The operating system may provide application programming interfaces APIs to enable applications to invoke functionality such as initiating reading writing closing and otherwise managing audio streams. The operating system may transparently perform other functions such as buffering linking components in an audio pathway interacting with an audio device driver to control use of and access to the audio hardware etc.

It will be appreciated by those skilled in the art of audio processing systems for computing devices that forming and managing audio streams may involve complexity not depicted in . For example instances of tees for splitting signals mixers for mixing signals utility signal processing modules CPU based and possibly even multiple signal processing modes e.g. a software based mode and a hardware based mode may be combined in various ways to form complex graphs of audio data flow. Regardless of such implementation details the operating system and or its audio stack provide data pathways to enable exchange of audio signal data to from applications through the audio signal processing hardware audio hardware and in some cases from to sound generating devices or sound capturing devices e.g. loudspeakers microphones .

To facilitate concurrent multi mode audio signal processing the audio stack may perform a process such as process . When an application needs an audio stream for example to output sound rendered by the application the application issues a call or request perhaps via an audio API to the operating system . When the operating system or audio stack receives the request the audio type for the requested audio stream is identified. The audio type can be ascertained by a variety of means. For example the requesting application can tag the audio stream with typing information as a parameter of the call requesting the new audio stream.

Other means of categorizing identifying or determining an audio type may be used. For example an application can specify an audio type by embedding an identifier in the audio data or in the stream itself. The audio stack can reference metadata associated with the requesting application that identifies a type of audio associated with the application. In another embodiment a last type of audio that the application used or another stream in use by the application may be referenced to determine the audio type for the new audio stream. In yet another embodiment the audio stack may setup the requested audio stream without knowing the audio type receive some audio signal data from the application buffer the audio signal data provided from the application and analyze the buffered audio data sound data to determine a type of sound in the audio data e.g. music voice etc. .

Returning to process when the audio type of the requested audio stream is determined an appropriate one of the audio signal processing modes is selected for processing the new audio stream. In one embodiment the audio stack maintains association information associating audio types with the particular audio signal processing modes . Other embodiments are discussed later with reference to .

Regardless of how an audio signal processing mode is selected the audio stack proceeds to link the new audio stream with the selected audio signal processing mode. For example if the application is App and the audio signal processing mode is a movie type of mode audio data generated by the application flows through the audio stream is processed by the audio signal processing mode movie and is emitted as sound by the loudspeaker .

While one or more audio streams are already carrying audio data to one or more of the audio signal processing modes an application may request yet another audio stream again invoking process . The new audio stream is built and configured in the same manner as discussed above. In the event that the new audio stream employs an audio signal processing mode that is not currently in use the requested audio stream may nonetheless be implemented according to its type. In other words different modes may concurrently process audio signal data. The ability of the operating system and or the audio stack to track and differentiate between audio stream types facilitates the concurrent processing of audio streams by different hardware based audio signal processing modes.

Further regarding types of audio streams the types or categories of audio streams are not limited the types of audio streams can correspond to any characteristic or feature of an audio stream. For example stream types can correspond to audio format traits. Streams might be labeled or tagged to indicate features such as bitrates codec types used for encoding the audio content buffering modes buffer sizes data block sizes sampling rate channel count etc. Other information related to an application or its audio stream may also be used such as information identifying a content producer corresponding to the audio content information indicating a device used to produce the audio content date information and so forth.

In one embodiment an offload path may be included. The offload path when requested by an application allows the application to bypass substantially all of the signal processing of the audio stack . An offload mode may differ from the raw mode. An offload path allows the application to talk directly to the audio device bypassing the operating system. The audio device may provide mode specific processing in the hardware or provide no processing at all raw . A raw path is one which has no signal processing in its path. The raw path may be non offload i.e. implemented by the operating system or may be implemented by the hardware as an offload path where the application talks to the audio device directly and the audio device renders the audio without applying any mode specific processing . Usually the only processing that exists in the raw path is the mandatory processing. Raw processing assures an application that the audio data it renders captures will not go through any non mandatory signal processing implemented by the operating system or the hardware.

As discussed above the raw audio signal processing mode can be requested by an application to avoid any audio effects or signal processing and to allow the corresponding audio stream to be rendered or captured as a raw signal. Hardware protecting signal processing may be transparently and mandatorily applied when using the raw mode or other modes to address signal traits that might damage the audio hardware. The offload path or other of the modes can be implemented as a software based mode i.e. one that runs on the host CPU.

A default audio signal processing mode may also be included. The default audio signal processing mode can implement any signal processing algorithms but preferably performs only lightweight or basic signal processing. The default audio signal processing mode may be implemented to optimize sound for the particular audio hardware being used. Alternatively the default audio signal processing mode can implement a signal processing standard providing for a signal processing baseline across platforms. Regardless of the processing that default audio signal processing mode performs the fact that there is a designated default mode allows the system to have a fallback mode when a type of an audio stream is not found to have an available corresponding mode as will be discussed with reference to .

In addition to the offload path some embodiments may include a loopback path that can be requested by applications. The loopback path allows an application to receive audio data directly post process perhaps in the form it would have when passed to the loudspeaker . In other embodiments individual loopbacks may be provided for each audio processing mode. The loopback path can be useful for purposes such as echo cancellation and basic sound capturing. Note that if the audio device implements multiple signal processing modes it might need to also provide a loopback path to return post mix audio back to any application that requests it.

When multiple sound outputting applications request audio streams that will pass through a same given audio signal processing mode the audio stack may mix their audio streams together into one submix before passing them into a signal processing path that passes through the given audio signal processing mode which allows one audio pipeline to support multiple applications. Similarly when several applications are receiving audio through a same mode the audio streams may be split before being processed and then they are split and passed to the applications.

The audio path module may also handle logic for matching audio types with audio processing modes. One implementation may use a table that maps audio types to audio modes. Each audio type has a list of corresponding audio signal processing modes ordered by priority. When the audio stack has determined that an audio stream has a particular audio type such as type then the audio path module looks up the audio type in the table and selects from the list the first mode that is available or operational. If the audio type is type then mode is selected or if mode is unavailable mode is selected. The inclusion of a default modes may be omitted in an embodiment where the default mode is automatically selected when a stream specific mode is either unavailable or indeterminable. In one embodiment the table or other mapping information is not used rather there is no distinction between audio types and audio signal processing modes and modes or types are used directly on a one to one basis. In other words the streams and modes all have the same categories or types. For example the audio stack may assign each audio signal processing mode a closest determined audio type and applications specify modes types directly.

Embodiments and features discussed above can be realized in the form of information stored in volatile or non volatile computer or device readable devices. This is deemed to include at least devices such as optical storage e.g. compact disk read only memory CD ROM magnetic media flash read only memory ROM or devices for storing digital information. The stored information can be in the form of machine executable instructions e.g. compiled executable binary code source code bytecode or any other information that can be used to enable or configure computing devices to perform the various embodiments discussed above. This is also deemed to include at least volatile memory such as random access memory RAM and or virtual memory storing information such as central processing unit CPU instructions during execution of a program carrying out an embodiment as well as non volatile devices storing information that allows a program or executable to be loaded and executed. The embodiments and features can be performed on any type of computing device including portable devices workstations servers mobile wireless devices and so on.

Embodiments and features discussed above can be realized in the form of information stored in volatile or non volatile computer or device readable devices. This is deemed to include at least devices such as optical storage e.g. compact disk read only memory CD ROM magnetic media flash read only memory ROM or any other devices for storing digital information in physical matter. The stored information can be in the form of machine executable instructions e.g. compiled executable binary code source code bytecode or any other information that can be used to enable or configure computing devices to perform the various embodiments discussed above. This is also deemed to include at least volatile memory such as random access memory RAM and or virtual memory storing information such as central processing unit CPU instructions during execution of a program carrying out an embodiment as well as non volatile media storing information that allows a program or executable to be loaded and executed. The embodiments and features can be performed on any type of computing device including portable devices workstations servers mobile wireless devices and so on.

