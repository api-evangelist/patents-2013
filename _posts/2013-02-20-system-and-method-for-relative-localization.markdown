---

title: System and method for relative localization
abstract: Localization systems and methods for unambiguously determining the range, bearing, and relative heading of a neighboring object relative to a reference point are provided. The systems and methods utilize a triangulation-based approach, wherein the range and heading information is based on measurements of angles between a reference coordinate system superposed on the reference point to a minimum of three target points on the neighboring object. The target points can include a minimum of three uniquely discernible beacons mounted to the neighboring object. A sensor capable of detecting the beacons is mounted at the reference point. The range and heading of the neighboring object can be calculated by an analysis of the geometries of the beacons and the reference point.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09134403&OS=09134403&RS=09134403
owner: The United States of America as represented by the Secretary of the Navy
number: 09134403
owner_city: Washington
owner_country: US
publication_date: 20130220
---
The invention described herein may be manufactured and used by or for the Government of the United States of America for governmental purposes without the payment of any royalties.

The present invention relates to localization. More particularly the present invention relates to localization systems and methods to unambiguously determine the range bearing and relative heading of an object relative to a reference point.

Localization approaches can be broadly categorized by methods that use direct measurement of range and bearing information with derived heading or that use some form of trilateration range based or triangulation angle based algorithm to determine state information not directly measured. Examples of techniques that use direct measurements of range and bearing are radar sonar and lidar.

When the transmitter s and receiver s are co located range is based on either time of flight or frequency modulation and bearing may be determined by using gimbaled elements or multiple elements including phased arrays. Using the Doppler effect the radial velocity component of a contact can be determined but the total velocity can only be determined from a series of measurements.

Trilateration approaches to localization use measured range information to reference points about which some absolute or relative position information is known to determine a position relative to these references. An example of a trilateration system is GPS which uses derived range information from multiple satellites serving as beacons.

A key feature of GPS is that range information is based on a known satellite broadcast schedule which is known to all receivers. A major disadvantage of GPS is signal availability. In regions with sufficient interference such as canyons streets surrounded by high structures or indoors position cannot be determined. Additionally commercial GPS accuracy limits the ranges at which coordination of multiple agents such as autonomous mobile vehicles can practically occur.

Acoustic long and short baseline navigation systems are local trilateration techniques and require a minimum of three reference beacons with positions known to a central controller or to the object being localized. Limitations of long baseline navigation include the requirement to accurately determine the relative locations of the beacons the potential difficulties in placing beacons in a navigable area and limitations in range associated with aliasing. Short baseline systems partially mitigate some of the limitations of long baseline systems although accuracy typically decreases.

Acoustic ultra short baseline systems use time of flight information to obtain range but can calculate bearing from the phase difference of signals. For almost all acoustic baseline system applications scalability to multi vehicle operations is a limitation. If the configuration requires vehicles to transmit in order to localize long periods between transmissions will result when a sufficient number of vehicles are used if signals are required to be vehicle specific. These long periods equate to infrequent updates that make the system impractical.

Triangulation approaches to localization use measured angular information to reference points about which some absolute or relative position information is known to determine a position relative to these references. A triangulation algorithm typically requires two reference locations with a known distance between them and the angles relative to the baseline formed by these reference locations to the object to be localized to determine the relative object position.

An illustrative triangulation approach is optical three dimensional localization using stereo vision. This approach uses two cameras with known distance and orientation relative to each other. The angles to a particular location in space taken from each of the images are used to calculate the range from each camera. Practical limitations include compensating for distortions in images from the lenses methods to ensure the images are comparable and the accuracy of methods to correlate features in each image.

Structured light is also based on a triangulation technique although a paired emitter and receiver form the baseline rather than two sensors. Limitations to structured light include difficulty in detecting transparent translucent or reflective materials and surfaces with certain curvatures. The structured light approach would also necessitate the use of some object recognition or tracking algorithm to identify features of the object used for localization.

Object recognition is a machine learning approach to localization that does not rely on active radiation or a trilateration or triangulation algorithm in use although information used to train the system may employ one or more of these methods. In the case of relative localization a recognition algorithm would need to be trained with a set of images of an object from a variety of ranges and orientations. Potential disadvantages are the possibility of a large training set necessary to suitably characterize the object to be localized and the processing required to identify relevant portions of an image.

A disadvantage of all of the localization techniques described except the object recognition approach is that the instantaneous heading information can not be calculated from a single measurement. A time series consisting of a minimum of two positions is required to determine relative velocity. In the case of a moving reference point such as a mobile robot the motion of the reference must be taken into account to determine the relative velocity and heading of the localized object meaning the actual motion of the reference point must be known.

Thus a need has been recognized in the state of the art to provide localization systems and methods that are low cost and achievable with commonly available cameras and known image processing algorithms while also having an accuracy comparable or better to other known localization techniques. Additionally the systems and methods should be capable of being used in a variety of applications requiring relative range bearing and or heading localization. Further the systems and methods should enable scalable multi agent interaction such as coordination of multiple autonomous agents.

It is therefore a general purpose and primary object of the present invention to provide localization systems and methods for unambiguously determining the range bearing and relative heading of a neighboring object relative to a reference point. The systems and methods utilize a triangulation based approach wherein the range and heading information is based on measurements of angles between a reference coordinate system superposed on the reference point to a minimum of three target points on the neighboring object.

The target points can include a minimum of three uniquely discernible beacons mounted to the neighboring object. A sensor capable of detecting the beacons is mounted at the reference point. The range and heading of the neighboring object can be calculated by an analysis of the geometries of the beacons and the reference point.

In one embodiment a method for localization of a first target includes sensing at a reference point a relative position of each of three or more beacons that have a predetermined geometric relationship on the target determining a bearing angle for each of the beacons relative to the reference point and determining a configuration of the beacons based on the relative position. The method also includes calculating a range from each of the beacons to the reference point based on the predetermined geometric relationship the bearing angle for each of the beacons and the configuration. The method additionally includes determining a heading of the target relative to the reference point based on the ranges for the beacons and the configuration.

In one embodiment calculating the ranges further includes calculating an angle between a line r from the reference point O to a rightmost one of the beacons R and a line from a center one of the beacons C to R. Calculating an angle can include numerically analyzing an expression for the angle wherein sin sin sin sin when the configuration has a line r from point O to C that intersects a line between a leftmost one of the beacons L and R. When the configuration is such that line rdoes not intersect line the expression takes the form of sin sin sin sin wherein in both expressions is a line from L to C is an angle formed between line and line is an angle formed between line and line is an absolute value of a difference between a bearing of line rand a bearing of a line r from point O to L is an absolute value of a difference between the bearing of line rand a bearing of line r and is an absolute value of a difference between the bearing of line rand the bearing of line r.

Further calculating a range can include solving expressions for line r line rand line r wherein for said first configuration 

In one embodiment the method further includes emitting radiation from each of the beacons at differing wavelengths to enable identification. In one embodiment the method further includes pulsing each of the beacons at differing frequencies to enable identification. In one embodiment numerically analyzing includes application of Newton s method a method of bisection a genetic algorithm or an optimization algorithm.

In one embodiment calculating a range includes analyzing expressions for the ranges r rand r wherein 2cos 2cos and 2cos .

In one embodiment the timing of emissions from the beacons can correspond with a predetermined schedule. Additional targets can be localized by differing the timing for each of the targets according to the schedule.

In one embodiment a target localization system includes a set of at least three beacons located on the target in a predetermined geometric relationship and a sensor located a distance from the target and attuned to receive emissions from each of the beacons. The system can also include a processor connected to the sensor and processor readable medium disposed on the processor. The medium can contain instructions for determining a bearing angle for each of the beacons relative to said sensor and calculating a range from each of the beacons to the sensor based on the predetermined geometric relationship and the bearing angle for each of the beacons.

In one embodiment the instructions also provide for determining a configuration of the beacons based on the bearing angle for each of the beacons and determining a heading of the target relative to the sensor based on the calculated ranges and the determined configuration. The system can also include a controller connected to the beacons which pulses the beacons at differing frequencies to enable identification of each of the beacons by the sensor. The controller can also differ the wavelengths of the emissions from each beacon to enable identification.

Referring now to there is shown a schematic plan view of localization system . Sensor is located at reference point O. Sensor is directed towards target so as to detect target points or beacons and . Beacons and are uniquely identifiable by sensor and have a known geometry on target .

The reference coordinate system is defined by orthogonal axes X and Y wherein sensor is directed along axis Y i.e. axis Y is collinear with the center of the field of view of sensor . Additionally controller can provide for coordinated operation of beacons and as may be required. Processor is connected to sensor .

Referring to there is shown an idealized image of beacons and captured by sensor of . As shown in beacons and lie in the horizontal plane defined by axes X and Y so as to simplify the geometry to two dimensions. However it is understood that the approach described herein applies to the more general case of three dimensions given that the geometry of beacons and on target is known.

The range and heading of target can be calculated by an analysis of the geometries of beacons and and reference point O. Referring also to there are shown respective possible general geometries for system as captured in image illustrated in . Since illustrate general cases positional assignments in the field of view of sensor L for leftmost R for rightmost and C for center can be used to describe the positions of beacons and

In both L C and R are distributed in triangle LRC with lengths between L and C between C and R and between L and R. The two internal angles of triangle LRC at vertices L and R are and respectively. As previously mentioned herein the geometry of triangle LRC is known. In C is located further from point O than is line between L and R. In C is located closer to point O than is line . Thus C lies outside triangle LRO formed by O L and R in while C lies inside triangle LRO in .

L C and R are located at some initially unknown distances or ranges from reference point O represented by r rand r respectively. These lengths are oriented at respective angles and with respect to the reference coordinate system shown in . These angles are determined by processor e.g. by mapping the positions of beacons and from image . Angles and not shown are defined as the absolute differences between the measured beacon angles. Specifically and . The angles and are formed at the intersections of lines rand and of lines rand respectively.

According to the law of sines where the ratio of a leg of a triangle to the sine of the opposing angle is constant for a given triangle the relationships given in the following equations are true 

Substituting this expression for into Equation 2 and arranging terms with respect to rresults in the following expression 

The value of can be solved numerically by any of a number of known algorithms such as Newton s method or the method of bisection in the region of 0 360. Two solutions are possible although any negative angle can be disregarded. The value of can be substituted into Equation 4 to solve for r.

The positions of beacons and relative to sensor can be calculated based on the calculated ranges. The relative heading of target can then be determined by calculating the orientation of the frame of reference for target from the known relative positions of beacons and on target .

In the description of the lengths and angles is identical to that for . However because legs and are on the interior of the triangle formed by O L and R the equivalent expression for Equation 3 is as follows . 8 The expression for requivalent to Equation 4 is 

As described previously relative to the value of can be solved numerically. Again any negative or unrealistic solution that results in negative values for r rand rcan be discarded. The solution for can be used in Equation 9 to calculate the value of r. The value of rcan be calculated from the following developed from the law of sines 

The use of the two geometries in along with the knowledge of the relative distribution of beacons and on target allows for the unambiguous determination of the position and heading of target . Without specifying the relative distribution of beacons and and given only the relative bearings from sensor to each of beacons and the geometries in are both valid configurations. Knowing the relative distribution of beacons and on target and the relative positions of beacons and in image given that target is upright invalidates one of the possible geometries.

Referring now to there are illustrated plan views of the six possible configurations of beacons and as observed by sensor . The line OF corresponds to a line projecting radially from the center of sensor in the plane of the triangle formed by beacons and . Lines are drawn from point O to each of beacons and to illustrate their relative positions.

If beacon is the leftmost and the rightmost is beacon or beacon is the leftmost and the rightmost is beacon or beacon is the leftmost and the rightmost is beacon then beacons and must have the geometry shown in . Similarly if beacon is the leftmost and the rightmost is beacon or beacon is the leftmost and the rightmost is beacon or beacon is the leftmost and the rightmost is beacon then beacons and must have the geometry shown in .

An alternate approach to the law of sines applies the law of cosines. According to the law of cosines using the same notations relative to the relationships between the measured angles the geometry of beacons and and the distances between reference point O and beacons and are as follows 2cos 13 2cos 14 and 2cos . 15 

As was the case in using the law of sines the values of r rand rcan be solved numerically based on Equations 13 14 and 15 . Two solutions exist with positive real roots. One such solution will correspond to the correct geometry and the other to a reflected image in which the order of beacons and is reversed. As previously described the correct solution will have the same order as in corresponding image . This additional constraint results in an unambiguous localization solution assuming target remains upright.

Referring now to there is shown a block diagram of method for localization of a target. At block sensor observes beacons and to form image . By observing beacons and angles and are determined block . Additionally based on the positions of beacons and in image and knowing the possible configurations shown in the configuration of target can be determined to conform either to or to block .

At block processor numerically solves for the value of based on the configuration and the known geometry of beacons and . At block processor further solves for r rand r. As previously described the equations used by processor at blocks and will depend on the configuration determined at block . For a configuration conforming to processor uses Equation 5 to solve for the value of and Equations 4 6 and 7 to solve for r rand r respectively. For a configuration conforming to processor uses Equation 10 to solve for the value of and Equations 9 11 and 12 to solve for r rand r respectively.

The positions of beacons and relative to sensor can be calculated based on the calculated ranges block . The relative heading of target can then be determined by calculating the orientation of the frame of reference for target from the known relative positions of beacons and on target block .

Obviously many modifications and variations of the present invention may become apparent in light of the above teachings. For example beacons and can be uniquely identifiable by a number of means. Each beacon can be of a unique wavelength or the beacons can have identical wavelengths but pulse at prescribed frequencies.

Additionally if multiple targets are to be localized and the beacon sets on each target are identical each target can be uniquely identified by activating beacons and according to a schedule that is shared by beacon controller and processor . Processor and beacon controller for each target can be time synchronized such that only one set of target beacons is activated at any given time. The target identity for the active set of beacons is determined uniquely by association in the schedule. Alternately each possible target can have a unique set of beacons.

Although the approach shown determines the relative position and orientation of target it is understood that the absolute position and orientation of target can be determined if the absolute position and orientation of sensor are known. Also three beacons are shown in the figures since this is the minimum number of beacons necessary to determine the target s relative position. However more than three beacons can be used for each target so as to ensure that at least three beacons are visible from sensor .

Although a numerical approach for solving the range and aspect has been presented in the discussion alternative approaches can be used. For example genetic algorithms or optimization algorithms that iterate a solution based on a fitness function can also be used.

What have thus been described are systems and methods for unambiguously determining the range bearing and relative heading of a neighboring object or target relative to a reference point. The systems and methods utilize a triangulation based approach wherein the range and heading information is based on measurements of angles between a reference coordinate system superposed on the reference point to beacons mounted to the target. The beacons can include a minimum of three uniquely discernible beacons mounted to the neighboring object. A sensor capable of detecting the beacons is mounted at the reference point. The range and heading of the target or neighboring object can be calculated by an analysis of the geometries of the beacons and the reference point.

Because three beacons are located on the target the systems and methods described herein are able to determine the aspect of the target in addition to the range in the reference coordinate system given prior information on the relative orientation of beacons to each other and the target. The relative orientation of beacons also introduces an additional constraint that enables identification of the appropriate geometry that results in a unique solution for the range and aspect of the target.

As described herein the relative localization systems and methods have a number of advantages over current localization systems and methods. These include the fact that the systems and methods described herein have no communication requirements i.e. sensor does not communicate directly with target . Additionally the components are currently widely commercially available and are low cost. The beacons can be any luminous source including light emitting diode arrays.

Although the beacons serve as emitters position information or state information is not broadcast explicitly. Further energy used for detection is not radiated as it is for active radar sonar or lidar systems. Rather the systems and methods described herein can be viewed as analogous to a passive sonar system.

It will be understood that many additional changes in details materials steps and arrangements of parts which have been described herein and illustrated in order to explain the nature of the invention may be made by those skilled in the art within the principle and scope of the invention as expressed in the appended claims.

