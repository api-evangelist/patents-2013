---

title: Operating and maintaining a cluster of machines
abstract: A method of operating a cluster of machines includes receiving a request for a disruption, determining a subset of machines of the cluster affected by the requested disruption, and determining a set of jobs having corresponding tasks on the affected machines. The method also includes computing a drain time for a drain that drains the tasks of the jobs from the affected machines, and scheduling on a drain calendar stored in non-transitory memory a drain interval for the drain. The drain interval has a start time and an end time. A maintenance system that includes a scheduler may execute such a method to maintain a cluster of machines.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09128777&OS=09128777&RS=09128777
owner: Google Inc.
number: 09128777
owner_city: Mountain View
owner_country: US
publication_date: 20130128
---
A computer cluster generally includes a set of loosely connected computers working together as a single system. The components of a cluster are usually connected to each other through local area networks each node e.g. computer used as a server running its own instance of an operating system. Computer clusters emerged as a result of convergence of a number of computing trends including the availability of low cost microprocessors high speed networks and software for distributed computing.

To maintenance one or more nodes of a cluster the entire cluster drained of jobs and or storage requests to allow physical maintenance on the nodes. This may result in a significant disruption to clients using the cluster.

The present disclosure provides a maintenance system that enables relatively faster more predictable machine drains allowing cluster management to execute large scale maintenance tasks in relatively less time than current systems. The maintenance system may coordinate drain behavior among multiple clients reducing contention for disruptor resources of a machine cluster and making drain times more predictable. The maintenance system may build a predictive model of a drain s duration and provides those predictions to other infrastructure components allowing those components to anticipate upcoming drains and to change their operation accordingly.

The maintenance system can be used in computer clusters that include a set of loosely connected computers working together as a single system and rack switch reboots. For example in super clusters the maintenance system may schedule mini system maintenances that drain production tasks away from machines for a limited period of time. For contracts the maintenance system may execute permanent drains to allow modification of hardware an owner or a configuration of affected machines. For rack switch reboots the maintenance system may schedule short e.g. 5 minute disruptions of single racks covering an entire cluster over a period of weeks.

One aspect of the disclosure provides a method of operating a cluster of machines. The method includes receiving a request for a disruption determining a subset of machines of the cluster affected by the requested disruption and determining a set of jobs having corresponding tasks on the affected machines. The method also includes computing on a data processor a drain time for a drain that drains the tasks of the jobs from the affected machines and scheduling on a drain calendar stored in non transitory memory a drain interval for the drain the drain interval having a start time and an end time.

Implementations of the disclosure may include one or more of the following features. In some implementations the method includes determining the scheduled drain interval based on the computed drain time and other scheduled drain times of the calendar. The method may include determining the scheduled drain interval based on attributes of the disruption request. The attributes may include at least one of a drain type a request to start as soon as possible a request to start as soon as possible after a desired start time a request to complete before a desired end time or a list of affected machines.

In some implementations the method includes computing the drain time based on a service level objective stored in non transitory memory. The service level objective may include an eviction rule allowing a maximum number of task evictions per job over a period of drain time. In some examples the eviction rule allows a maximum number of task evictions per job over a period of drain time based on a machine location of each task and a schedule of disruptions for the cluster. The service level objective may include an eviction quota defining an allowable amount of machine disruption over a period of time across the entire cluster.

The method may include limiting machine disruption to a failure domain of the cluster. The failure domain includes a subset of machines of the cluster where the cluster includes multiple failure domains.

The method may include executing the drain and draining the tasks of the jobs from the affected machines. This may include evicting the tasks from the affected machines and moving the evicted tasks to other machines in the cluster unaffected by the disruption request for example by a scheduled maintenance time and or according to a service level objective. The method may include monitoring a progress of the drain and providing a notification of the drain progress.

In some implementations the method includes temporarily or permanently draining memory or jobs from the affected machines. The method may include computing a job drain time to drain the tasks each job or a storage drain time to drain memory of each affected machine.

The method may include maintaining in non transitory memory a disruption request calendar for tracking disruption requests and a machine granularity calendar for tracking disruption activity on the machines. The disruption request calendar may store for each disruption request at least one of a disruption request identifier a drain identifier an initial scheduled drain start time an initial scheduled drain end time a latest scheduled drain start time a latest scheduled drain end time a current drain status or a last notification. The machine granularity calendar may store a sequences of records one sequence per machine each record including at least one of a current state of jobs a storage identifier an owner label a disruption event identifier a drain start time or an expected drain end time.

When the drain is complete the method may include notifying a machine state agent of the drain completion. The machine state agent may not label the affected machines for repair when the affected machines go off line based on the received drain completion notification. Moreover the method may include placing non transitory memory of the affected machines in a read only mode when the drain is complete.

Another aspect of the disclosure provides a maintenance system for a cluster of machines. The maintenance system includes a scheduler executing on a data processor. In response to receiving a request for a disruption the scheduler determines a subset of machines of the cluster affected by the requested disruption and determines a set of jobs having corresponding tasks on the affected machines. The scheduler computes a drain time for a drain that drains the tasks of the jobs from the affected machines and schedules on a drain calendar stored in non transitory memory a drain interval for the drain the drain interval having a start time and an end time.

In some implementations the scheduler determines the scheduled drain interval based on the computed drain time and other scheduled drain times of the calendar. The scheduler may determine the scheduled drain interval based on attributes of the disruption request. The attributes may include at least one of a drain type a request to start as soon as possible a request to start as soon as possible after a desired start time a request to complete before a desired end time or a list of affected machines.

The scheduler may compute the drain time based on a service level objective stored in non transitory memory. The service level objective may include an eviction rule allowing a maximum number of task evictions per job over a period of drain time. In some examples the eviction rule allows a maximum number of task evictions per job over a period of drain time based on a machine location of each task and a schedule of disruptions for the cluster. The service level objective may include an eviction quota defining an allowable amount of machine disruption over a period of time across the entire cluster. The scheduler may limit machine disruption to a failure domain of the cluster. The failure domain includes a subset of machines of the cluster where the cluster includes multiple failure domains.

In some implementations the maintenance system includes a drain executer executing the drain and draining the tasks of the jobs from the affected machines. The drain executer may evict the tasks from the affected machines and move the evicted tasks to other machines in the cluster unaffected by the disruption request for example by a scheduled maintenance time and or according to a service level objective. The scheduler may monitor a linear or non linear progress of the drain and provide a notification of the drain progress.

The drain executer may temporarily or permanently drain memory or jobs from the affected machines. The scheduler may compute a job drain time to drain the tasks each job and or a storage drain time to drain memory of each affected machine.

The maintenance system may include a calendar store in communication with the scheduler and maintaining in non transitory memory a disruption request calendar for tracking disruption requests and a machine granularity calendar for tracking disruption activity on the machines. The disruption request calendar may store for each disruption request at least one of a disruption request identifier a drain identifier an initial scheduled drain start time an initial scheduled drain end time a latest scheduled drain start time a latest scheduled drain end time a current drain status or a last notification. The machine granularity calendar may store a sequences of records one sequence per machine each record including at least one of a current state of jobs a storage identifier an owner label a disruption event identifier a drain start time or an expected drain end time.

The scheduler may notify a machine state agent of a drain completion. The machine state agent may not label the affected machines for repair when the affected machines go off line based on the received drain completion notification. Moreover the machine state agent may placing non transitory memory of the affected machines in a read only mode when the drain is complete.

The details of one or more implementations of the disclosure are set forth in the accompanying drawings and the description below. Other aspects features and advantages will be apparent from the description and drawings and from the claims.

Referring to in some implementations a cluster system includes a cluster of machines e.g. memory hosts computing processors computers etc. grouped in cells . The cluster may implement a distributed system that includes loosely coupled machines e.g. computers or servers implemented as memory hosts or processors each having a computing resource e.g. one or more processors in communication with storage resources e.g. non transitory memory flash memory dynamic random access memory DRAM phase change memory PCM and or disks . The distributed system may include a storage abstraction e.g. key value store or file system overlain on the storage resources that allows scalable use of the storage resources by one or more clients . The clients may communicate with the machines through a network . In some implementations the clients send jobs each having one or more tasks to the machines .

The cluster machines may be in communication with a maintenance system a cluster wide job scheduler that coordinates and schedules jobs on the machines and or a service level objective SLO manager via the network . The cluster wide job scheduler and the service level objective SLO manager may each execute on a computing processor of a machine and optionally be stored in non transitory memory . The SLO manager may communicate with service level objectives which may be stored in non transitory memory .

The maintenance system reduces the amount of disruption caused by scheduled maintenance to the cluster to provide a higher quality of service to tenant jobs of the cluster . Instead of taking the entire cluster offline e.g. removing the cluster from active use and conducting maintenance on the entire cluster the maintenance system may subdivide the cluster into independent failure domains . A failure domain may be a group of machines or one or more groups of racks of machines . Other divisions of the cluster are possible as well. In the example shown each cell is a failure domain however other configurations are possible. The failure domain may include a portion of a cell a single cell or multiple cells . The maintenance system may perform maintenance on one or more failure domains at a time.

Before maintenance occurs the maintenance system drains affected machines referred to as doomed machines by moving all tasks of the doomed machines to remaining computing capacity in the cluster i.e. remaining machines in the cluster . Moreover when the doomed machines are drained and become inactive the computing capacity of the cluster may change since the total of number of active machines in the cluster may have decreased. The maintenance system may need to move the tasks of the doomed machines by a threshold period of time before the scheduled maintenance so that work can be performed on empty machines . The migration of tasks may need to occur sufficiently slowly e.g. over a duration of time so as not to kill a number of tasks and reduce the serving capacity of the jobs in the cluster . If a job has tasks and the maintenance system is taking down 1 10 of the cluster the maintenance system does not wish to cause the cluster to suddenly lose a number of data replicas but rather spreads that disruption over a period of time. A service level objective SLO may dictate how fast the maintenance system may disrupt a given job in the cluster .

The maintenance system may support temporary or permanent drains on storage and jobs e.g. temporary or permanent removal of tasks from machines . Moreover the maintenance system may monitor or track the commencement and completion of drains . The maintenance system may coordinate with other systems the migration of jobs out of a cluster or a failure domain to allow service or maintenance on machines of that cluster or failure domain . For example the maintenance system may inform an underlying cluster architecture when maintenance is taking place and the duration of that maintenance.

An eviction service level objective SLO for the cluster wide job scheduler can act as a gatekeeper on how quickly a drain may execute. To maintain a reliable execution environment for client jobs the cluster wide job scheduler may for example have an SLO that guarantees the following eviction scheduling behavior for conforming production jobs 1 no more than max 21 tasks tasks for each job may be evicted in any trailing seven day period 2 no more than max 3 0.01 tasks tasks for each job may be evicted in any trailing 30 minute period and or 3 no planned evictions may execute while more than max 1 0.01 tasks tasks are unscheduled in a pending state . Other eviction scheduling behaviors for conforming production jobs may also be specified or the specifics may be modified to adapt to conditions associated with the cluster . For example a service level objective may institute a set of rules that govern how and when tasks are evicted to accommodate maintenance crew schedules peak computing times during the day holiday schedules etc. Service level objectives may be configured to accommodate business and other objectives as well.

The cluster wide job scheduler may distribute tasks of each job through the cluster on the basis of available resources at job scheduling time which may lead to a situation where many or all tasks of a job reside on the same maintenance domain e.g. a PMDC which is a power conditioner and generator pair having about 2 Megawatts capacity which may be a standard large unit of failure in a cluster . This may force the maintenance system to take a minimum period of time e.g. one week to drain the maintenance domain . External disruptions from opportunistic tools such as kernel upgrades technicians running maintenance scripts or machine rack level failure increase the drain time even further by consuming an eviction budget for the job . The eviction budget may correspond to an eviction SLO .

Referring to in some implementations a user such as a client a maintenance calendar a user interface and or contracted machine owners may interact with the maintenance system through a maintenance system application programming interface API executing on a computing processor . The maintenance system API allows clients or other users through the user interface to obtain the status of drains query for information view status pages measure if a drain is going over time and or determine how close an actual drain time is to an estimated drain time.

The maintenance system API may include a permanent drain scheduling object for scheduling a permanent drain a temporary drain scheduling object for scheduling a temporary drain a drain scheduling reply object a notification configuration object and or a messages object . The permanent and temporary drain scheduling objects may each receive a requesting user identifier a drain priority a cluster identifier and or scheduling options. The scheduling options may include 1 start as soon as possible 2 start as soon as possible after a desired start time or 3 complete before a desired end time. The permanent and temporary drain scheduling objects may also receive a list of affected machines racks or failure domain s or a system identifier identifying a particular system e.g. whole machine storage or job s to drain. The permanent drain scheduling object may receive an action to execute after completion of the drain e.g. a machine database label change . The temporary drain scheduling object may receive an expected disruption duration and or a maximum disruption duration. The maintenance system API may include a drain scheduling reply object which receives a drain identifier and returns success failure indicator an estimated drain start time and or an estimated drain end time.

A user of the maintenance system API may use a notification configuration object to set notification parameters. The notification configuration object may receive a username an email address a Boolean setting to email a notification when a drain completes default true a Boolean setting to email a notification if no progress for a threshold progress period of time e.g. in minutes default off a Boolean setting to email a notification if a drain will be overdue by greater than a threshold overdue period of time e.g. in minutes default 0 minutes a Boolean setting to email a notification if a drain is canceled default true a Boolean setting to email a notification if a drain is rescheduled by more than a threshold rescheduling period of time e.g. in minutes default off and or a Boolean setting to email a notification of a suppression period default off .

The maintenance system API may include a messages object that allows a user to start stop all drain activity e.g. in a cluster get a status of a drain get a status of a machine get a list of disruptions in a time interval get a start time for disruptive activity of a temporary drain get an end time of a temporary drain and or cancel modify a drain.

A calendar store may maintain a persistent store of scheduled disruptions . In some implementations the calendar store includes two calendars a first calendar tracks each disruption as it moves from submitted to scheduled to active and to complete and a second calendar that tracks disruption activity at the machine level. These calendars may store all scheduled and active disruptions and optionally historical data on completed disruptions . The first calendar a disruption request calendar may store the following information for each scheduled disruption a disruption request identifier a drain identifier an initial scheduled drain start time an initial scheduled drain end time a latest scheduled drain start time a latest scheduled drain end time a current status and a last notification e.g. notification time and or event . The second calendar a machine granularity calendar may store sequences of records one sequence per machine . Each record may include a current state of jobs a storage identifier an owner label a disruption event identifier a drain start time and or an expected drain end time . The maintenance system may load the persistent store into non transitory memory on startup and commit all schedule changes and status updates to the persistent calendar store . The calendar store can be implemented on top of low level replicated storage. This provides a reliable transaction oriented storage layer that has very few external dependencies making it suitable for integration with the cluster wide job scheduler .

When the maintenance system receives a disruption request through the maintenance system API a scheduler may first compute a set of machines affected by each drainable scope and compute the set of affected jobs . The scheduler may maintain a model of available eviction quota based on the location of each task retrieved from the scheduler and a schedule of disruptions e.g. from the calendar store including completed disruptions . Using this information the scheduler may compute start intervals for each drain which are time intervals where there exists sufficient disruption quota to drain the requisite number of tasks without affecting previously scheduled drains . The disruption quota may define an amount of allowable disruption to the computing capacity of the cluster over a period of time e.g. continuous time set days of a week or other time increments where disruption may be caused by executing a drain . The disruption quota may be influenced by one or more service level objectives . In some examples a service level objective sets or defines the disruption quota. A drain can be scheduled in any interval that is part of the intersection of all affected jobs start intervals. Once a suitable start time is found the scheduler may perform a simulation of the drain s progress by replaying all scheduled disruptions and quota availability events and then generate a projected end time for the chosen start time of the requested disruption .

For opportunistic disruption events such as kernel upgrades and rack switch firmware upgrades the maintenance system may choose start and end drain times that are as early as possible to minimize the effect on hardware maintenance drains which are scheduled as late as possible. As scheduled hardware maintenance drains are known well in advance this allows the maintenance system to schedule them with a large gap between the drain and any opportunistic activity. It is important to be able to guarantee the completion of these drains on time as technician hours and hardware migrations are expensive if wasted.

In some implementations the scheduler analyzes each job of the cluster to determine how many tasks of each job are in a region of doomed machines and then estimates how long e.g. based on a service level objective SLO it will take to drain those tasks out of the doomed machines without unduly affecting the job and without violating an eviction SLO . The scheduler may analyze all jobs in the cluster and their determined drain times to select the worst drain time of all of the jobs and use that drain time as the estimated drain time for the drain which may start at a particular time .

The scheduler may schedule drains in advance and determine whether two or more drains conflict. The scheduler may maintain a calendar of drains e.g. in the calendar store each having corresponding start and end times on one or more machines . The scheduler may maintain drain start and end times maintenance work start and end times and or service restoration times for each machine of the cluster . When one or more drains are scheduled to commence the scheduler may notify a scheduling service such as the cluster wide job scheduler of a scheduled drain e.g. by issuing issue one or more commands and a corresponding set of doomed machines that are no longer hospitable for production jobs. Over a period of time the scheduling service evicts tasks of jobs from the doomed machines and moves the evicted jobs to other machines having capacity for those jobs . The scheduling service may act in compliance with a service level objective e.g. by evicting and migrating jobs at a rate in compliance with a minimum drain time. The scheduler may track actual drain times for comparison with the estimated drain times so as to estimate more accurate drain times in the future. When the estimated drain time ends all of the machines should be empty.

In some implementations when a user schedules a disruption e.g. via the maintenance system API the scheduler selects a time that allows the disruption to complete within any requested start stop interval while respecting the overall capacity and disruption budgets of an affected collection of machines such as a cell . The scheduler may determine an estimated job drain time Tfor a disruption request as follows max 1 global job scheduler task limit number of tasks to drain 2 

where x is a maximum drain time for the job based on the job size and the number of affected tasks y is a maximum drain rate per second S is a safety margin time and D is an estimated disruption duration time .

The scheduler may determine an estimated storage drain time Tfor a disruption request as follows 2 max 15min. 3 

where n is the number of affected racks b is a maximum number of bytes in any one rack and r is a maximum drain rate bytes second .

After computing an estimated drain time T T the scheduler determines a scheduled time for the drain among existing drains packing drains as early as possible. In some implementations the scheduler handles one active drain at a time. If there is no valid packing the scheduler may reschedule jobs in the same priority band by removing sets of jobs from the schedule and then rescheduling the jobs with the largest first. If that does not work the scheduler may remove a lower priority disruption repeat the process and then try to reschedule the evicted disruption request .

In some implementations the scheduler provides an estimate of how long it will take to evict all tasks of a particular job as well as an estimated duration of an entire drain which may include one or more jobs . Given a proposed drain and the drain schedule the scheduler may determine whether the proposed drain is feasible and an estimated drain time. The scheduler may break down the drain into jobs and corresponding tasks and based on a service level objective how much disruption quota will be used for evicting each job . Given a proposed start time the scheduler may determine a corresponding end time and whether the drain is feasible at all.

The drain scheduler may schedule a drain based on attributes of the drain such as a drain type e.g. for certain types of maintenance or on certain types of machines and or defined criteria such as desired start and end times. For any given drain the drain scheduler may identify a valid timeslot and pack drains together over a certain time horizon. Depending on the drain type the scheduler may try to schedule the drain as early as possible or as late as possible or as close as possible to a desired time. For example for rack maintenance the scheduler may try to determine an earliest possible start time for the scheduled drain . In another example a large and involved maintenance may be scheduled as close as possible to a desired end time to accommodate workers and avoid idle worker time or idle machine time.

The scheduler may perform checks to ensure that the scheduled disruptions will not place an affected cell in an unsafe state. In some examples the scheduler determines an available machine capacity via a job scheduler interface or an available storage capacity if draining storage . The scheduler may not reduce a free pool below a safe level or make tasks impossible to schedule.

The scheduler may run when a user adds a new disruption e.g. for a feasibility check and scheduling before starting any disruption e.g. to make sure the schedule drain calendar is still valid any time a disruption does not occur according to the estimated plan e.g. runs over time or when a disruption completes significantly ahead of schedule e.g. to allow rescheduling disruptions earlier if possible . The maintenance system may execute the scheduler to run continual regular checks on the status of all disruptions .

In some implementations whenever the scheduler schedules a new drain mutates a drain to change its timing or contents i.e. affected machines checks the feasibility of a drain checks the progress of a drain e.g. every 10 min. the scheduler uses the calendar store .

For example if the calendar store has five scheduled drains the scheduler removes the drain under consideration and splits the remaining four drains into sets of expected evictions for each job in the cluster . If two drains already occurred and three drains remain the scheduler estimates a drain time for the first of the last three drains . The scheduler removes an amount of disruptions corresponding to the first two drains from a disruption quota determines when the fourth drain is due to start which is a boundary by which the third drain must finish to avoid a drain conflict and estimates a drain time for the drain under consideration. The drain time estimation includes for a particular drain determining all of the affected machines determining which jobs have tasks on the affected machines and for each job having at least one task on the affected machines determining a drain time to evict that at least one task on the affected machines . The estimated job drain time may be based on the size of the job the amount of disruption quota already consumed by previous drains past drain times for other jobs and or a service level objective e.g. eviction policy . The scheduler may use the estimated drain time to determine when to schedule that drain .

In some implementations a drain executer executes the drains and may communicate with the cluster wide job scheduler and the machine state agent to designate machines as being not suitable for production jobs. The calendar store may notify the drain executer and the scheduler that a disruption should begin. The scheduler may check the feasibility of the drain to ensure that it is still feasible and then the drain executer notifies a machine state agent of the drain via label changes in a machine database . The exact set of label changes depends on the type of drain e.g. a temporary drain or a permanent drain .

For temporary drains the drain executer marks affected machines in the machine database with a problem label having a symptom of laming and a note of lame excluded server server type servertype . The drain executer may monitor the status of the drain to determine when the drain is finished. Once all affected machines have the lame label the disruptive activity can start. Once the activity begins the drain executer applies an expiration label such as stop expires YYYMM DD HH MM SS.000 drain in the machine database and the problem label is removed. This prevents the machine state agent from repairing the machine while the activity is ongoing. Notifying the drain executer that the activity is complete or exceeding the maximum activity duration may cause the stop label to be removed which allows the machine state agent to restore the machine to a working condition.

For permanent drains the drain executer may notify the machine state agent of the drain via the machine database by setting a jobs label to none and or a storage label to none. The drain executer may track a machine state by checking server notes in machine database to determine if the machine has stopped. Once all the machines have been drained the drain is complete.

In some implementations when it s time for a drain to start the drain executer may makes sure that there are no other running drains . If the system is not busy the drain executer may perform basic safety checks and set draining labels for the doomed machines in the machine database . These labels are picked up by the machine state agent which sets a priority of the machines e.g. to a maximum priority . This prevents any further production jobs from being scheduled on the machine and causes the cluster wide job scheduler to evict all non exempt production jobs from the doomed machine under the eviction SLO which is mediated by the SLO manager . By using the labels in the machine database the cluster wide job scheduler avoids rescheduling jobs into machines e.g. PMDCs that will be under maintenance in a near future time horizon such as within the next 24 72 hours as this would trigger an unnecessary eviction. Once the machine state agent reads the machine as lame it sets the appropriate labels in the machine database and the drain is complete.

In some implementations the SLO manager enforces quotas of the service level objectives and may act as a gate keeper and timekeeper for when job or task evictions may occur by preventing disruptions of tasks storage or machines from occurring too quickly. The scheduler may communicate with the SLO manager before evicting any jobs . The SLO manager may indicate whether a particular task may be evicted at that moment. Since the SLO manager may be an instantaneous function rather than a predictive function the scheduler may merely query the SLO manager to obtain an eviction approval disapproval for that moment in time.

The SLO manager may enforce an the eviction SLO as either a fixed interval model where one eviction is allowed every certain period of time or as a quota model where a job can accumulate quota if it has no evictions and then rapidly evict multiple tasks . The cluster wide job scheduler may have an SLO that reserves the right to evict up to 4 racks per day e.g. 1 per hour with no advance notice outside of other SLOs . This quota is typically unused and is invoked only when there are unexpected network or power events. While this is a much more impactful operation than SLO bound gradual evictions the maintenance system may use this as a mechanism of last resort if drains appear to be failing.

A contract machine owner may specify a preferred service level objective or eviction policy. Exemplary policies include opting out of eviction requesting en mass eviction in the case that each individual task eviction sets the job as a whole back giving a task a threshold period of time e.g. 15 seconds 15 minutes to gracefully shutdown before its eviction or having a task evict at an opportunistic time.

In some implementations the service level objective SLO may be given a job of n replicas the maintenance system may disrupt m replicas per week. This may mean that on any given week the maintenance system may disrupt the same replica m times or m replicas each once that week or a permutation in between. The SLO may provide a level of burstiness which may be a rate of disruption within that week. For example the SLO may allow eviction of a percentage of a job over a certain period of time e.g. 1 over 30 minutes . Based on the SLO s the scheduler may determine a minimum drain time e.g. using a maximum of one job or task per a minimum drain time . Rather than using an interval based system the scheduler may track the intervals between evictions and a disruption quota usage e.g. quota used per week . Using a disruption quota usage history the scheduler may determine a relative possible rate of disruption for a given job . If no job evictions occurred over a recent period of time the scheduler may determine that a current job may use the disruption quota at a relatively greater rate. A quota based estimation accounts for a history of job evictions over a period of time which allows the scheduler to determine relatively more accurate drain time estimations.

While the drain executer is executing a drain the scheduler may re compute the expected drain end time using the current set of tasks on each machine . If a drain is running over time the scheduler may reschedule the expected end time and verify that it will not interfere with other scheduled drains . If it will the scheduler may either remove or reschedule the conflicting drains in the case of opportunistic work or raise an alert in the case of scheduled maintenances .

Once a drain begins but before the disruptive activity starts the drain executer may monitor a status of the drain for determining its progression. The drain executer may maintain an internal model for estimating whether the drain is likely to complete on time or run late. The model may account for different draining scenarios such as when blocks of machines are held up and then drain rather quickly or the time to drain having a long tail with a small number of machines taking a very long time. Once a drain has fallen behind schedule the drain executer may issue a notification to the notifier e.g. so that action can be taken to either unstick the drain or delay the activity . In some implementations the internal model may include or communicate with a service level objective or policy. The internal model may receive data about why a machine cannot be drained and or how long until an issue will be resolved.

The notifier may provide push and or pull notifications to drain creators. In some examples the notifier provides push notifications via a Paxos based client API and or via email to drain creators. The notifier may provide pull notifications via the persistent calendar store which can be read by any user and or via an API. In order to support tasks that may need to take action before a disruption the notifier may publish upcoming and active disruptions to a Paxos file. An observer may monitor the Paxos file note relevant changes to the disruption schedule and call a callback at a configurable interval before disruption is to begin. The observer may be used by storage servers in super clusters as they are not be migrated ahead of scheduled maintenance but instead switch non transitory memory to read only mode.

The distributed storage layer may listen to the notifier for upcoming disruptions on machines and put the machine in a maintenance mode e.g. place non transitory memory of the affected machine a read only mode . If a storage manager is unable to communicate with the machine whether due to disruption in the machine itself reboot or its network connectivity rack upgrade the storage manager may consider the machine DOWN. Clients may have to reconstruct any slices on the machine while it is DOWN but the system will not reconstruct missing slices on that machine . The distributed storage layer may notice when the maintenance is over and transition the machine either from READ ONLY to HEALTHY if currently reachable or DOWN to DEAD if unreachable .

Once a drain is complete the maintenance system may notify a storage infrastructure and or machine management infrastructure machine database that maintenance will be performed on a set of machines so that those infrastructures know that the machines will be unavailable for a period of time.

The machine state agent e.g. a master machine lifecycle service may indicate that the machine stopped and is not suitable for production and may be responsible for sending machines to repairs and migrating certain classes of jobs . The maintenance system notifies the machine state agent of the drain so that the machine state agent does not send any affected machines to repairs when they go off line e.g. thinking that those machines have issues . For example the maintenance system may assign stop labels to the doomed machines so that the machine state agent does not send those machines to repairs e.g. a repair diagnosis service when those machines are no longer available for a period of time.

A distributed storage layer may place non transitory memory of the doomed machines in a read only mode upon receiving an indication from the maintenance system that the doomed machines will become unavailable for a discrete period of time. While in the read only mode the doomed machines cannot receive data writes. When the doomed machines go off line the distributed storage layer may suppress reconstruction of the corresponding data since the distributed storage layer knows that the machines will eventually come back online. Whereas if the machines went off line for a period of time e.g. two hours without receiving a drain notification from the maintenance system the distributed storage layer may attempt to reconstruct the data which appears lost to re attain a certain replication level of those host machines.

Once the machine state agent and the distributed storage layer are notified of the drains and the doomed machines have been drained maintenance work may ensue on the doomed machines which are off line. Once the maintenance work is complete on the doomed machines the doomed machines can be restored to a serving state.

The maintenance system may use a notifier e.g. executing on a computing processor to issue notifications. The notifier may include a push and or a pull notification application programming interface API which allows a client e.g. another cluster component to check on the status of drains . In some implementations the maintenance calendar which controls when maintenance is scheduled pulls notification information from the notifier to monitor progression of a drain or to discern a conflict between drain times.

In some implementations the maintenance calendar maintains a calendar of scheduled disruptions such as start and end times of scheduled drains the machines affected by the drains start and end times of scheduled work etc. The data storage layer may access the maintenance calendar to receive notification of a scheduled disruption so as to determine when to transition into a read only mode and when to suppress reconstruction of data.

In some implementations the method includes determining the scheduled drain interval based on the computed drain time and other scheduled drain times of the calendar . The method may include determining the scheduled drain interval based on attributes of the disruption request . The attributes may include at least one of a drain type a request to start as soon as possible a request to start as soon as possible after a desired start time a request to complete before a desired end time or a list of affected machines .

In some implementations the method includes computing the drain time based on a service level objective stored in non transitory memory . The service level objective may include an eviction rule allowing a maximum number of task evictions per job over a period of drain time. In some examples the eviction rule allows a maximum number of task evictions per job over a period of drain time based on a machine location e.g. on a certain rack of each task and a schedule of disruptions for the cluster . The service level objective may include an eviction quota defining an allowable amount of machine disruption over a period of time across the entire cluster .

The method may include limiting machine disruption to a failure domain of the cluster . The failure domain includes a subset of machines of the cluster where the cluster includes multiple failure domains .

The method may include executing the drain and draining the tasks of the jobs from the affected machines . This may include evicting the tasks from the affected machines and moving the evicted tasks to other machines in the cluster unaffected by the disruption request for example by a scheduled maintenance time and or according to a service level objective . The method may include monitoring a progress of the drain and providing a notification of the drain progress.

In some implementations the method includes temporarily or permanently draining memory or jobs from the affected machines . The method may include computing a job drain time Tto drain the tasks of each job or a storage drain time Tto drain memory of each affected machine .

The method may include maintaining in non transitory memory a disruption request calendar for tracking disruption requests and a machine granularity calendar for tracking disruption activity on the machines . The disruption request calendar may store for each disruption request at least one of a disruption request identifier a drain identifier an initial scheduled drain start time an initial scheduled drain end time a latest scheduled drain start time a latest scheduled drain end time a current status or a last notification e.g. notification time and or event . The machine granularity calendar may store sequences of records one sequence per machine . Each record may include a current state of jobs a storage identifier an owner label a disruption event identifier a drain start time and or an expected drain end time

When the drain is complete the method may include notifying a machine state agent of the drain completion. The machine state agent may not label the affected machines for repair when the affected machines go off line based on the received drain completion notification. Moreover the method may include placing non transitory memory of the affected machines in a read only mode when the drain is complete.

Various implementations of the systems and techniques described here can be realized in digital electronic and or optical circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product non transitory computer readable medium apparatus and or device e.g. magnetic discs optical disks non transitory memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Moreover subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a non transitory memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more of them. The terms data processing apparatus computing device and computing processor encompass all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as an application program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user one or more aspects of the disclosure can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor or touch screen for displaying information to the user and optionally a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

One or more aspects of the disclosure can be implemented in a computing system that includes a backend component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a frontend component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such backend middleware or frontend components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some implementations a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

While this specification contains many specifics these should not be construed as limitations on the scope of the disclosure or of what may be claimed but rather as descriptions of features specific to particular implementations of the disclosure. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multi tasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results.

