---

title: Sensor controller for interpreting natural interaction sensor for web handling
abstract: A sensor controller for web handling applications is described. The sensor controller is provided with a first port, a second port, a computer readable medium, and a processor. The first port receives a sequence of data frames capturing an area of a material web having a width to height ratio between 0.10 and 100. The computer readable medium stores logic indicative of identifying properties of a first group of data points of a feature of the material web extending in a web direction of travel. The processor scans the sequence of data frames to locate a transition between a property of the first group of data points and a property of a second group of data points in the data frames and generates a series of location signals indicative of lateral locations of the transition within the data frames. The second port outputs the location signals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09415963&OS=09415963&RS=09415963
owner: Fife Corporation
number: 09415963
owner_city: Oklahoma City
owner_country: US
publication_date: 20130130
---
Pneumatic photoelectric and ultrasonic systems have been used for guiding material webs by edge detection or line detection. Photoelectric based systems for example using optical sensors or infrared sensors have been used to guide material webs based on features of the material web such as an edge an aspect of a material web at a given point on the material or a printed graphic running longitudinally along the material web. Most sensors detect the web or its features by transmitting a signal and comparing a received signal through open atmosphere in relation to a received signal which has been passed through or interrupted by a web.

C shape sensors are common in web edge detection where the web passes through a gap in the C shape. Sensors are often housed in arms of the C extending at least partially across the web. The sensors may be divided between transmitter and receiver elements. The gap of the C shape sensors extend between the arms and may limit acceptable deviations in the web plane of the traveling web while passing through the C shape sensor. In order to overcome this limitation C shape sensors may be mounted on or connected to an articulable element known as a moving sensor guide that allows the C shape sensors to move in response to changes in the width of the material web. In addition rollers may be employed such as fixed support bars close to the C shape sensors enabling better control over the web plane and enabling use of C shape sensors using smaller gaps. A plurality of C shape sensors have been used to guide a single material web with sensors on either side of the material web to simultaneously perform edge detection on opposing edges of the material web.

C shape sensors may be used in ultrasonic guiding systems for example as described in U.S. Pat. No. 7 415 881. C shape sensors are also used in photoelectric systems as described in U.S. Pat. No. 4 291 825 that uses infrared sensing devices to perform web edge sensing to guide the material web.

Line sensors may be used which scan graphical patterns on the web without performing edge detection for guiding the material web. Line sensors may capture images and guide the material web based on a comparison of the images and the location of the graphical patterns with a stored set point. Line sensors may have a horizontal field of view that spans a portion or the entirety of the material web between opposing edges. However the line sensors have a field of view in the web direction of travel that is limited to one pixel and encompasses no more than 5 7 microns of the web in the web direction of travel. Other sensors used in web guiding may include laser curtain sensors ragged edge sensors fiber optics sensors raised feature sensors capacitance or inductance sensors and mechanical paddle or finger sensors.

Visual inspection systems for providing quality assurance to moving webs of material currently exist. One visual inspection system is sold under the trademark InPrint by Fife Corporation the assignee of the present patent application. This visual inspection system provides quality assurance by allowing direct live image viewing of a moving web. In particular this visual inspection system captures images of a moving web at 10 images second and compares the captured images to a reference image of the web to detect deviations of the captured image from the reference image. When deviations are detected the visual inspection system sounds an alarm and or directs a particular product to an appropriate location to be manually inspected.

Web handling systems exist to control the tension in a web of material. The tension in the web is detected by a load cell bearing on the web of material and the tension is controlled by a brake or clutch system that can vary the rate of movement of a roller for feeding and or retrieving of the web of material.

Natural interaction sensors use depth sensors which respond to emitted radiation such as infrared IR frequency wavelengths of light to measure distances between an object and the sensor. Further natural interaction sensors may also employ audio and optical sensors to combine image data sound data and distance data to provide three dimensional interactions between an object and a computer system. Commercially available natural interaction sensors are sold under a variety of trade names including KINECT LEAP and XTION PRO LIVE . However natural interaction sensors have not previously been used in web handling systems.

There is a need for a web handling system capable of guiding and or tensioning material webs based on one or a combination of factors including a location of one web edge or multiple web edges while enabling improved quality inspection of the web in an automated setting.

This summary is provided to introduce a selection of concepts that are further described in the detailed description. This summary is not intended to identify key or essential features of the claimed subject matter nor is it intended to be used as an aid in limiting the scope of the claimed subject matter.

In one version the present disclosure describes a sensor controller having a first port one or more non transitory computer readable medium and one or more processor. The first port is configured to receive a sequence of data frames captured at distinct instants of time. The data frames capture an area of a material web having a width to height ratio between 0.10 and 100. The data frames can be either image data frames or depth image frames for example and may be generated by supplying a medium into a field of view and capturing reflections of the medium. The medium can be electromagnetic waves such as light and or radio frequency signals. The one or more non transitory computer readable medium stores logic indicative of information identifying properties of a first group of data points e.g. pixels or the like of the feature of the web. The one or more processor analyzes the sequence of data frames having the first group of data points depicting the feature of the web and a second group of data points depicting a background transverse to the feature the one or more processor scanning the sequence of data frames to locate a transition between a property of the first group of data points and one or more property of the second group of data points in the data frames and to generate a series of location signals indicative of a lateral location of the transition. The second port outputs the location signals.

In another version the sensor controller has a first port a second port one or more non transitory computer readable medium and one or more processor. The first port is configured to receive a data stream of image data and or depth data of a web. The one or more non transitory computer readable medium stores first logic indicative of information identifying a first group of data points of a first feature e.g. a web edge or printed pattern extending in a web direction of travel of the web and second logic indicative of information identifying a second group of data points of a second feature e.g web edge or printed pattern extending in a web direction of travel of the web. The one or more processor is configured to analyze the data stream the data stream having a sequence of data frames e.g. image data frames and or depth data frames with the first group of data points of the first feature a third group of data points depicting a background transverse to the first feature and the second group of data points depicting the second feature the second feature spaced a distance laterally from the first feature the data frames captured at distinct instants of time the processor scanning the sequence of data frames to locate a first transition between the first group of data points and the third group of data points in the data frames and a second transition between the second group of data points and the third group of data points in the data frames and to generate a web handling signal indicative of at least one of the locations of the first and second transitions and a lateral distance between the first and second transitions.

Another embodiment of the disclosure describes a sensor controller having a first port a second port one or more non transitory computer readable medium and one or more processor. The first port is configured to receive a sequence of signals from a topographic sensor having a field of view encompassing a feature of a web the sequence of signals including a series of depth maps. The one or more non transitory computer readable medium stores web handling information indicative of a desired aspect of the feature of the web. The one or more processor is configured to determine a current aspect of the feature of the web using at least one of the depth maps in the series of depth maps and to determine an error signal indicative of a difference between the desired aspect and the web handling information stored on the one or more non transitory computer readable medium. The second port outputs the error signal.

In another version the sensor controller has a first port one or more non transitory computer readable medium one or more processor and a second port. The first port is configured to receive a sequence of signals from a topographic sensor having a field of view encompassing a feature of a web the sequence of signals including a series of depth maps the first port also being configured to receive a sequence of video frames of the feature of the web synchronized with the depth maps. The one or more non transitory computer readable medium stores web handling information indicative of a desired location and desired quality inspection aspect of the feature of the web. The one or more processor is configured to determine a current location of the feature of the web using at least the sequence of video frames and to determine a current quality inspection aspect of the feature of the web using at least one of the depth maps in the series of depth maps and to determine error signals indicative of a difference between the desired location and current locations and desired and current quality inspection aspects. The second port outputs the error signals.

The present disclosure also describes a web handling system having a natural interaction sensor or movement sensor and a sensor controller. The natural interaction sensor supplies a medium to reflect off of a surface of the web and receives reflections of the medium from the surface of the web the natural interaction sensor developing a series of topographical maps indication of a location of at least one feature extending in a web direction of travel of the web. The sensor controller has a first port configured to receive the topographical maps from the natural interaction sensor one or more processor configured to analyze the topographical maps received from the natural interaction sensor by scanning the topographical maps to locate a transition in the topographical maps and to generate a series of location signals indicative of a lateral location of the transition.

A method is also presented for handling a material web. The method is performed by receiving a sequence of signals from a topographic sensor having a field of view encompassing a feature of a web with the sequence of signals including a series of depth maps. Web handling information indicative of a desired aspect of the feature of the web is stored. A current aspect of the feature of the web is determined using at least one of the depth maps in the series of depth maps and to determine an error signal indicative of a difference between the desired aspect and the web handling information. The error signal is then output to a web controller.

In another aspect a web handling system is described for guiding a web movable in a web direction through a travel path threaded around at least one steering roller of the web handling system. The web handling system also has a base a platform a natural interaction sensor a sensor controller a web controller and a platform drive. The platform is mounted on the base to move through a guiding range. The platform may be any suitable type of assembly for steering the web such as a steering guide or a displacement guide. The at least one steering roller is mounted on the platform and disposed transversely of a transversely to the web direction of travel when the web travels across the platform. The natural interaction sensor supplies a medium to reflect off of a surface of the web and receives reflections of the medium from the surface of the web the natural interaction sensor developing a series of topographical maps indication of a location of at least one feature extending in a web direction of travel of the web. The sensor controller has a first port configured to receive data from the natural interaction sensor one or more processor configured to analyze the data received from the natural interaction sensor which can be image data and or depth data. The one or more processor scans the data to locate a transition in the topographical maps to generate a series of location signals indicative of a lateral location of the transition. The sensor controller also has a second port coupled to the one or more processor and outputting the location signals. The controller is configured to generate control signals responsive to the signals produced by the sensor controller and configured to automatically correct a deviation from a predetermined position of the web. The platform drive is configured to be responsive to the control signals generated by the controller for laterally moving the platform and thereby controlling an angular position of the platform relative to the base.

Specific embodiments of the present disclosure will now be described in detail with reference to the accompanying drawings. Further in the following detailed description of embodiments of the present disclosure numerous specific details are set forth in order to provide a more thorough understanding of the disclosure. However it will be apparent to one of ordinary skill in the art that the embodiments disclosed herein may be practiced without these specific details. In other instances well known features have not been described in detail to avoid unnecessarily complicating the description.

Unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by anyone of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the inventive concept. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Finally as used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

The terminology and phraseology used herein is for descriptive purposes and should not be construed as limiting in scope. Language such as including comprising having containing or involving and variations thereof is intended to be broad and encompass the subject matter listed thereafter equivalents and additional subject matter not recited.

Referring now to the figures shown in is a web handling system for handling a continuous material web that is moving past a background . The web handling system may be used in web guiding tension control and quality inspection industries for example. The web handling system is shown by way of example as a web guiding system. The web handling system is capable of detecting one or multiple web edges measuring web width and detecting web defects including quality inspection aspects. Detecting one or multiple edges and measuring web width provides the web handling system with the ability to detect lateral changes in the location of the material web as well as to monitor tension within the material web based on changes in width of the material web . For example for certain types of material including plastics and woven materials decreases in the width of the material web are indications of stretching caused by increased tension.

The web handling system may guide the material web with depth information using algorithms to interpret depth maps in a series of depth maps generated by one or more sensors. The sensors may generate color and depth information and in some embodiments depth images generated from the depth information may have color information artificially generated to detail depth differences for display purposes. The depth maps may be created by supplying a medium to reflect off of a surface of the material web and the background and receiving reflections of the medium from the surface of the web. The medium may be light or radio frequency signals. For example the depth image may be created by painting a field of view with infrared points of light from an emitter and observing the resulting reflected image with a depth sensor. For example the depth maps and depth images may be created in a manner set forth in U.S. Pat. No. 8 050 461 the entire content of which is hereby incorporated by reference. The depth maps may also be created by sonar or radar techniques that interpret echoes reflected off of the surface of the material web and the background .

The web handling system may comprise a base supporting a platform . The platform is mounted on the base and is configured to provide a range of movement to enable guiding of the material web . The web handling system also includes a plurality of sensors two being shown and designated by the reference numerals and for purposes of clarity to detect and analyze one or more characteristics and one or more position of the material web and supply data signals via one or more communication links a sensor controller configured to receive data from the plurality of sensors via the communication link s and provide sensor control signals indicative of the characteristics and position of the material web a web controller which may also be referred to as a web controller and may be configured to generate error signals responsive to the sensor control signals produced by the sensor controller and a platform drive configured to be responsive to the error signals generated by the web controller to guide the material web . The plurality of sensors may be components of a natural interaction sensor which may be photoelectric based sonar based non photoelectric based or a combination thereof. The natural interaction sensor as will be explained in more detail below may have one or more high frame rate digital cameras e.g. 30 290 frames per second one or more topographical sensors such as infrared depth sensors one or more audio sensors and combinations thereof. For example the natural interaction sensor may use infrared light with an advanced CCD camera positioned behind a dark IR filter to sense an object as small as 0.01 mm and at max. frame rate of 290 frame sec. The sensor controller as will be explained in more detail below may be comprised of a computer system a signal converter and one or more ports to connect to the plurality of sensors such as the natural interaction sensor.

The web handling system may at times guide the material web relative to and in proximity to the background which may be located transverse to the material web and within the field of view of the sensors . Preferably the material web has a first side and a second side . The sensors may face the first side and the background may face the second side as shown in . Thus in this embodiment the web handling system does not require sensors to be located on the first side and the second side .

The background may be used to enable performance of tracking quality inspection and other functions. In one embodiment the web handling system may simultaneously guide a plurality of material webs past the background . Although the web handling system may guide a plurality of material webs for the sake of clarity the web handling system will be described as guiding a single material web . However it will be understood by one skilled in the art that the web handling system may guide one or the plurality of material webs as will be described below without departing from the present disclosure. The plurality of material webs may be positioned side by side or overlap on top of each other so long as the sensors can detect a transition between the plurality of material webs and or the plurality of material webs and the background . For example two of the plurality of material webs may overlap but be provided with different colors such that the sensors can detect a transition in the overlapping part of the material webs .

The base may be connected to the platform via a suitable mechanism enabling the base to support the platform while allowing at least a portion of the platform to move laterally to the web direction of travel in response to the control signals generated by the web controller . The base may be created from metal plastic or any other suitable material capable of supporting the platform . The base may also be connected to the platform drive such that the platform drive may be used to move the platform in relation to the base without moving the base . In other words the base is preferably stationary and the platform is moveable with respect to the base .

The platform may be connected to the base to allow movement relative to the base and is used to support at least one steering roller . The base platform and the at least one steering roller can be implemented in a variety of manners such as a steering type guide providing web position correction by bending the material web through a long entering span. In another embodiment the base platform and the at least one steering roller can be a displacement type guide which may pivot to twist the material web usually using more than one steering roller . As shown in the platform supports two steering rollers and by way of example on opposite ends thereof. However it will be understood by one skilled in the art that the platform may be used to support fewer or greater steering rollers sufficient to direct the material web . The platform may be pivotally connected to the base via linear slides and or any other suitable mechanism such that the platform may articulate e.g. pivot or move in an arc about an axis in a predetermined range such that articulating the platform may change an angular position of the platform relative to the base and thereby cause a correction in a deviation of the material web from a predetermined position as the material web moves along a web direction of travel . The steering rollers and may be mounted to the platform transversely to the web direction of travel along a travel path of the material web through the web handling system .

The plurality of sensors detect and analyze characteristics of the material web such as one or multiple web edges web plane changes web width web quality with respect to images stored in the sensor controller and web defects for example. As shown in certain of the plurality of sensors may be combined together in a housing to form a natural interaction sensor which may be photoelectric based sonar based non photoelectric based and combinations thereof. The sensors may supply and or detect a medium such as light in a visible spectrum and or an infrared spectrum. Further the sensors may supply and or detect one or more laser beams or radio frequency signals. The natural interaction sensor as will be described below in more detail may comprise the plurality of sensors or certain of the plurality of sensors and may be positioned to have a field of view extending from the natural interaction sensor that encompasses a feature of the material web a section of the material web a portion of the material web and a portion of the background or combinations thereof. The field of view has a width to height ratio between 0.10 and 100 and may encompass an area of the material web and or the background having a maximum width of 20 feet and a maximum height of 15 feet for example.

The plurality of sensors may be implemented as audio sensors topographic sensors optical sensors such as high frame rate digital cameras or any other suitable sensors which may capture and provide information indicative of characteristics and positioning of the material web relative to the background . For example the topographical sensors may be implemented as infrared IR sensors capable of capturing information related to a distance between the plurality of sensors and the material web and or the background . The topographical sensors may also be configured to determine distances between the material web and the background irrespective of the distance from the topographical sensor. An optical sensor of the plurality of sensors may be implemented as a digital still camera or digital video camera capable of capturing a plurality of images of the material web and background for example.

In one embodiment the plurality of sensors when implemented as the natural interaction sensor may provide a sequence of synchronized depth images color video images and audio streams. The natural interaction sensor may use parallel computational logic. The natural interaction sensor may receive a light coding infrared pattern as input and produce a depth image of the material web in a data matrix I J where I and J are in a range from 1 to 60 000 and are desirably larger than 1. For example I can be 640 and J can be 480. The data matrix I J may have an aspect ratio i.e. width to height ratio between 0.10 and 100. However in certain embodiments described in more detail herein the aspect ratio is between about 1.3 and 1.7. The natural interaction sensor may be implemented in a long range version spaced away from the material web between 0.8 to 3.5 m or a short range version spaced away from the material web between 0.3 to 1.5 m. In general the natural interaction sensor may be spaced from the material web any suitable distance such that the field of view of the natural interaction sensor encompasses the features to be detected in the particular web handling application. Further in one embodiment the natural interaction sensor may include an array of multiple sensors sensing information together with the combined information placed into a single data matrix such that the number of pixels within the single data matrix is more than the maximum pixel count of any individual sensor within the array.

The sensor controller which will be explained in more detail below may be configured to receive data from the plurality of sensors and provide signals indicative of characteristics and position of the material web relative to another material web and or the background . The sensor controller may be electrically connected to the plurality of sensors and the web controller by wired connections wireless connections or any other suitable connections sufficient to receive information from the sensors and transmit sensor control information e.g. location signals to the web controller . As shown in the sensor controller is connected to the web controller via signal path

The web controller may be electrically connected to the sensor controller and the platform drive via wired connections such as signal paths and respectively or via wireless connections. For example as shown in the sensor control information sent by the sensor controller via signal path may be received and processed by the web controller . The web controller may in turn transmit control signals to the platform drive via signal path causing the platform drive to actuate and move the platform based on the control signals sent from the web controller . In response to receiving the sensor control information the web controller may compare such signals to a predetermined guide point position and then send the control signals to the platform drive for adjustment of the platform . The web controller may be preprogrammed to process the sensor control signals to produce control signals that may be used to maintain the travel path of the material web in a same position on the steering rollers and for example by correcting the angular position of the platform in response to any deviations of the travel path of the material web from the predetermined guide point position.

The platform drive may be implemented as a motor engine one or more actuators one or more servos one or more hydraulics or other mechanical or electrical mechanism capable of manipulating the platform . The platform drive may be configured to receive control signals from the web controller and control the angular position of the platform relative to the base based on the control signals of the web controller . The platform drive may be electrically connected to the web controller through wired or wireless connections such that the platform drive is capable of receiving control signals from the web controller and may be mechanically connected to the platform such that actuation of the platform drive via the control signals may cause the platform to move relative to the base .

Shown in is an embodiment of the natural interaction sensor which may comprise the plurality of sensors . The natural interaction sensor may be provided with one or more processor one or more emitter for supplying wavelengths of light which may be infrared light or light outside of the infrared spectrum one or more non transitory computer readable medium one or more optical sensor for capturing a plurality of pixels used to detect features of the material web and one or more depth sensor for capturing depth data due to reflections of the wavelengths supplied by the emitter to detect a depth of a feature of the material web and or the background . In one embodiment the natural interaction sensor may also be provided with one or more audio sensors configured to provide a synchronization data stream for synchronizing the optical sensor and the depth sensor . In yet another embodiment the natural interaction sensor may be photoelectric based as described above or may be sonar based. The natural interaction sensor may also be provided with both photoelectric and sonar sensors used in combination. In certain embodiments the natural interaction sensor may be a commercially available device sold under a variety of trade names including KINECT LEAP and XTION PRO LIVE 

The one or more processor may be implemented as a single processor or multiple processors working together or independently to process the plurality of pixels from the optical sensor and or the depth data from the depth sensor . Embodiments of the processor may include an image processor a digital signal processor DSP a central processing unit CPU a microprocessor a multi core processor an application specific integrated circuit a field programmable data array and combinations thereof. The processor is coupled to and configured to receive information from and transmit control signals to the non transitory computer readable medium emitter the optical sensor and the depth sensor . The non transitory computer readable medium can be a single non transitory computer readable medium or multiple non transitory computer readable medium functioning logically together or independently. The processor may be capable of communicating with the Emitter the non transitory computer readable medium the optical sensor and the depth sensor via paths and respectively. The paths may include multidrop topology a daisy chain topology or one or more switched hubs. The paths can also be a serial topology a parallel topology a proprietary topology or combinations thereof.

In one embodiment the emitter may be configured to supply light in a wavelength range of between about 750 nm 1 mm which is within the IR range of wavelengths. However it should be understood that the emitter may be configured to supply light outside of the infrared spectrum of light. The depth sensor is adapted to receive and interpret reflections of the light supplied by the emitter and may be implemented as a depth camera for example configured to receive a depth data stream e.g. reflected light indicative of a distance between the depth sensor and a target such as the material web and or the background . For example the depth data stream data may be reflected IR light that was supplied by the emitter and reflected by the material web and the background . The depth sensor receiving the depth data stream may produce depth data frames in a matrix d I J for example. The depth data frames d I J may be used alone to detect the web edge by detecting a difference in depth between the depth sensor and the material web and the depth sensor and the background . The depth data stream may be represented by characters having any suitable maximum number of bits such as 16 bits 32 bits 64 bits or the like. Further it should be understood that the characters may encompass less bits than the maximum number of bits. For example in one embodiment the depth data stream is 16 bit data while only carrying 12 bits of information. Each pixel of the depth data frame d I J may represent the distance in a unit of measurement such as centimeters for example from the depth sensor to an object which in this instance may be the material web and or the background . In one embodiment the resolution of the depth sensor may be 640 480 pixels and may produce the sequence of depth data frames at a rate of about 30 frames per second. However it will be understood by one skilled in the art that the resolution and the frame rate of the depth sensor may vary and use a greater resolution lower resolution greater frame rate or a lower frame rate. For example the amount of data in the depth data frames produced by the depth sensor may be about 18 Mbytes per second in one embodiment. The depth data frames produced by the depth sensor may use significant bandwidth to transfer the depth data frames to the sensor controller . The sensor controller may mitigate the bandwidth requirement in one embodiment by requesting the natural interaction sensor transmit only the depth data frames only video data from the optical sensor or a combination of the depth data frames and the video data.

The optical sensor may be implemented as a digital video camera digital still frame camera or other suitable optical sensors e.g. charge coupled device s capable of producing image data at a suitable frame rate per second which comprises a plurality of data points which will be described herein as pixels by way of example. The plurality of pixels may be logically subdivided into a plurality of groups of pixels. The optical sensor may produce a sequence of data frames comprising frames of video data or still image data. In one embodiment the optical sensor may be configured for a resolution of about 640 480 pixels and may be configured to produce the sequence of data frames at a frame rate of between 30 290 frames per second. However it will be understood by one skilled in the art that the resolution and the frame rate of the optical sensor may vary. For example the optical sensor may produce the sequence of data frames where each data frame may be comprised of a plurality of pixels in a data matrix I J where I and J are greater than 1 but less than 60 000. The data matrix may be a color data matrix. I of the data matrix may be representative of a horizontal field of view i array where is equal to 1 to N. J in the data matrix may be representative of a vertical field of view j array where j is equal to 1 to M. N and M in some embodiments may represent a maximum pixel value of the respective field of view arrays. The data matrix I J may be used to detect web edges by an image contrast principle in which changes in color values between the material web and the background are used to locate the edges of the material web .

In one embodiment the video data from the optical sensor may be produced in a 32 bit red green blue alpha RGBA format where the A component is not used. The alpha value may be used to control pixel transparency when rendering images on an output device such as a display. RGBA may support 16 million colors by virtue of 24 bits of color information spread across the RGB components. It should be understood that other color spaces can be used such as a Hue Saturation Value HSV color space.

The audio sensors may be implemented as one or more microphones or other sensor capable of or configured to receive and interpret audio signals such as sound waves and be used to produce a sequence of data frames indicative of sonic aspects of the material web such as quality inspection aspects and tracking and guidance aspects for example. In one embodiment the audio sensors may be configured to receive audio signals in a frequency or pattern indicative of a quality inspection aspect of the material web such as misalignment within the web handling system termination of the material web or other tracking guidance and quality inspection aspects which may produce detectable audio signals. For example a baseline audio recording can be made when the material web is being handled properly and deviations from the baseline can be detected by comparing the sonic aspects of the material web with the baseline. As an example a fourier analysis of the baseline audio recording can be generated to identify the frequencies in the baseline audio recording. Then a fourier analysis of the sonic aspects of the material web can be generated in real time during web handling. The absence of certain frequencies and or addition of certain frequencies can be used to generate an error signal to sound an alarm or take other appropriate action such as stopping the movement of the material web .

The sequence of data frames produced by the optical sensors the depth sensor and the audio sensors may be synchronized such that the sequence of data frames produced by each of the sensors may be transmitted simultaneously to the sensor controller . The synchronized sequence of data frames may be used to perform redundant operations such as error checking of one of the sequence of data frames from the optical sensors the depth sensor or the audio sensors .

Referring now to the sensor controller may comprise one or more processor one or more non transitory computer readable medium processor executable code stored on the one or more non transitory computer readable medium a first port and a second port coupled to the processor . The one or more non transitory computer readable medium may store a set point indicative of a desired location of a feature extending along the material web and logic indicative of information identifying properties of a first group of pixels of the feature of the material web . The one or more processor may be configured to analyze the one or more sequence of data frames captured by the natural interaction sensor scan the sequence of data frames to locate a lateral location of a transition and generate a series of location signals indicative of the lateral locations of the transition with the data frames. The lateral locations can be compared to the set point to generate an error signal indicative of a difference in location of the transition relative to the set point. The first port may be configured to receive the sequence of data frames and may also be configured to receive transceiver outputs from the plurality of sensors of the natural interaction sensor generating the data matrix I J and the depth data d I J . The second port may be configured to output control information such as error signals. In particular the second port may also be configured to output edge data for one or more edges of the material web including lateral position and polarity. The second port may also be configured with separate depth output for determining plane change roll diameter sensing edge sensing and the like.

The one or more processor may be implemented as a single processor or multiple processors working together or independently to execute the processor executable code described herein. Embodiments of the processor may include a digital signal processor DSP a central processing unit CPU a microprocessor a multi core processor and combinations thereof. The processor is coupled to the non transitory computer readable medium . The non transitory computer readable medium can be a single non transitory computer readable medium or multiple non transitory computer readable medium functioning logically together or independently.

The processor is coupled to and configured to communicate with the non transitory computer readable medium via a path which can be implemented as a data bus for example. The processor may be capable of communicating with an input device and an output device via paths and respectively. Paths and may be implemented similarly to or differently from path . For example paths and may have a same or different number of wires and may or may not include a multidrop topology a daisy chain topology or one or more switched hubs. The paths and can be a serial topology a parallel topology a proprietary topology or combination thereof.

The processor is further capable of interfacing and or communicating with one or more network via a communications device and a communications link such as by exchanging electronic digital and or optical signals via the communications device using a network protocol such as TCP IP. The communications device may be a wireless modem digital subscriber line modem cable modem Network Bridge Ethernet switch direct wired connection or any other suitable communications device capable of communicating between the processor and the network . It is to be understood that in certain embodiments using more than one processor the processors may be located remotely from one another located in the same location or comprising a unitary multicore processor not shown . The processor is capable of reading and or executing the processor executable code and or creating manipulating altering and storing computer data structures into the non transitory computer readable medium .

The non transitory computer readable medium stores processor executable code and may be implemented as random access memory RAM a hard drive a hard drive array a solid state drive a flash drive a memory card a CD ROM a DVD ROM a BLU RAY a floppy disk an optical drive and combinations thereof. The non transitory computer readable medium may also store the sequence of data frames the set point and other information. When more than one non transitory computer readable medium is used one of the non transitory computer readable mediums may be located in the same physical location as the processor and another one of the non transitory computer readable mediums may be located remote from the processor . The physical location of the non transitory computer readable mediums can be varied and the non transitory computer readable medium may be implemented as a cloud memory i.e. non transitory computer readable medium which is partially or completely based on or accessed using the network . In one embodiment the non transitory computer readable medium may store a database of sensor data accessible by the sensor controller to serve as baseline set points desired aspect or desired locations of the material web used in comparison with sensor data taken at distinct instants of time for guiding the material web . The database may include one or more set points indicative of a desired location of one or more features of the material web web handling information indicative of a desired aspect of a feature of the material web quality aspect information indicative of a desired quality of the material web other sensor data and combinations thereof. In this embodiment the non transitory computer readable medium may also store sensor data from the one or more audio sensor . In another embodiment the one or more non transitory computer readable medium may store web handling information indicative of a desired aspect of a feature of the material web . The desired aspect of the feature of the material web may be a web plane change such as the distance between the material web and the natural interaction sensor a width of the material web a quality of the material web with respect to a stored image a defect in the material web a tension of the material web a roll diameter aspect or one or more positional aspects of the material web such as its lateral position of the material web on the steering roller for example. In another embodiment the one or more non transitory computer readable medium may store web handling information indicative of a desired location and a desired quality inspection aspect of the feature of the material web . The web handling information indicative of the desired quality inspection aspect may comprise a control image serving as a quality standard against which images of the material web taken using certain of the plurality of sensors may be compared to determine one or more qualities of the material web .

The first port may be configured to receive a data stream indicative of the sequence of data frames from the natural interaction sensor . The first port may transmit the received data stream to the processor and can be implemented as a USB port HDMI port Firewire port DIN port digital video port D subminiature port Ethernet port SCSI port fiber optics port infrared port optical port or other suitable port. In one embodiment for example the first port may be implemented as a plurality of first ports such as a plurality of USB hubs such that each of the plurality of sensors including the depth sensor and the optical sensor of the natural interaction sensor may be isolated on individual USB hubs. The first port may be configured to receive a sequence of signals such as the sequence of data frames from a topographic sensor such as the depth sensor having a field of view encompassing a feature of the material web and providing information indicative of the three dimensional location of the web material and or the background preferably relative to the topographic sensor where the sequence of signals may include a series of depth maps. In another embodiment the first port may be configured to receive the sequence of data signals from the topographic sensor with a field of view encompassing a feature of the material web and to receive a sequence of video frames of the feature of the material web from an optical sensor such as the optical sensor . In this embodiment the sequence of signals may include a series of depth maps and the sequence of video frames may be synchronized with the depth maps so that the three dimensional information in the depth maps as well as the visual information within the video frames can be used to guide or otherwise handle the material web as described herein.

The data stream received by the first port may include the sequence of data frames captured at distinct instants of time by the natural interaction sensor . The sequence of data frames may comprise a first group of data points which may be pixels depicting a first feature a second group of data points which may be pixels depicting a second feature with the second feature spaced a distance transversely from the first feature and a third group of data points which may be pixels depicting a background transverse to the first and second feature. The third group of pixels may also depict a third feature with the third feature spaced a distance transversely from the first feature and the second feature. The sequential data frames may comprise a plurality of depth maps where a first group of data points which may be pixels are indicative of a first distance between a topographic sensor and a feature of the material web and a second group of data points which may be pixels are indicative of a second distance between the topographic sensor and the background where the second distance is greater than the first distance to cause a transition in depth that can be detected. The sequence of data frames may comprise a sequence of data signals from a topographic sensor having a field of view encompassing a feature of a web the sequence of signals including a series of depth maps. Further the sequence of data frames may also include a sequence of video frames of first second and or third feature synchronized with the depth maps so that the location of the edges of the material web can be determined in multiple ways as discussed below.

The second port is configured to output one or more signals from the one or more processor . The second port receives the one or more signals from the processor and may transmit the one or more signals to the web controller configured to control aspects of the travel of a material web . The second port may be implemented as a USB port HDMI port Firewire port DIN port digital video port D subminiature port Ethernet port Modbus port SCSI port fiber optics port infrared port optical port or other suitable port.

The one or more signals may comprise one or more error signal indicative of a difference in location of a transition relative to the set point for a material web . The error signal may also be indicative of a difference in location of a first transition and or a second transition relative to the set point. Further the error signal may be indicative of a difference between a desired aspect and a web handling information stored on the one or more non transitory computer readable medium. The error signal may also be indicative of a difference between a desired location and current locations of a web edge for example. In another embodiment the error signal may be indicative of desired and current quality inspection aspects. The error signal may also be indicative of a difference in location of a transition relative to a set point.

The input device transmits data to the processor and can be implemented as a keyboard a mouse a touch screen a camera a cellular phone a tablet a smart phone a PDA a microphone a network adapter a camera a scanner and combinations thereof. The input device may be located in the same location as the processor or may be remotely located and or partially or completely network based. The input device communicates with the processor via path .

The output device transmits information from the processor to a user such that the information can be perceived by the user. For example the output device may be implemented as a server a computer monitor a cell phone a tablet a speaker a website a PDA a fax a printer a projector a laptop monitor and combinations thereof. The output device communicates with the processor via the path .

The network may permit bi directional communication of information and or data between the processor and the network . The network may interface with the processor in a variety of ways such as by optical and or electronic interfaces and may use a plurality of network topographies and protocols such as Ethernet TCP IP circuit switched paths file transfer protocol packet switched wide area networks and combinations thereof. For example the one or more network may be implemented as the Internet a LAN a wide area network WAN a metropolitan network a wireless network a cellular network a GSM network a CDMA network a 3G network a 4G network a satellite network a radio network an optical network a cable network a public switched telephone network an Ethernet network and combinations thereof. The network may use a variety of network protocols to permit bi directional interface and communication of data and or information between the processor and the network . For example in one embodiment the bi directional communication of information via the network may facilitate communication between the processor the one or more non transitory computer readable medium the natural interaction sensor and or one or more remote monitors of the web handling system .

The one or more non transitory computer readable medium may store the processor executable code which may comprise a web sensing program . The non transitory computer readable medium may also store other processor executable code such as an operating system such as Windows iOS or Linux and applications programs such as a word processor for example. The processor executable code for the web sensing program and the other processor executable code may be written in any suitable programming language such as C C Java or Python for example. The web sensing program may also be written using application programming interfaces for example. In one embodiment all or a portion of the web sensing program may be stored on one or more computer readable medium within the natural interaction sensor .

Referring now to in one embodiment the web sensing program may cause the processor to receive a sequence of image data frames . shows an exemplary embodiment of a image data frame from the sequence of image data frames . In this embodiment the sequence of image data frames is captured by the optical sensor and a field of view encompasses the web material and the background . The image data frame as captured by the optical sensor may be a raw image and provided to the processor as a processed image such as a raster image via the processor of the natural interaction sensor . In this embodiment each image data frame of the sequence of image data frames output by the optical sensor to the processor may be represented by a color image data matrix I J .

The image data frame has a field of view encompassing at least a portion of the material web . As shown in the field of view shows the material web with a first edge and a second edge and the background extending past the first and second edges and . The field of view may be understood as a horizontal field of view and a vertical field of view where the horizontal field of view is indicative of an array of pixels I of the data matrix I J and the vertical field of view is indicative of an array of pixels J of the data matrix I J . The array of pixels I may have a value of 1 to N while the array of pixels J may have a value of 1 to M. For example for the image data frame may have a resolution of 640 480 pixels. In this example the array of pixels I is 640 pixels and the array of pixels J is 480 pixels. As discussed above a ratio of the horizontal field of view vertical field of view may be in a range from 0.1 to 100 and is more desirably in a range from 1.3 to 1.7. In one embodiment the ratio of the horizontal field of view vertical field of view is 640 480 and in another embodiment is 16 9.

In the embodiment shown in the background may be a first color and the material web may be a second color to cause the image data frame to have first color values indicating the background and second color values indicating the material web . The first edge and the second edge of the material web may create a transition between the first color values indicating the first color and the second color values indicating the second color . The transitions located at the first or second edges and may be indicated by a range of pixels in the horizontal field of view and a range of pixels in the vertical field of view with the range of pixels in the horizontal and vertical fields of view and in one embodiment being in a range from 1 to 60 000. For example due to the resolution of the optical sensor the transition may be a transition from the background which may be dark to the material web which may be light. The transition may be spread across a range of several pixels in the horizontal field of view and may span the entire vertical field of view in the range of pixels in the horizontal field of view . As another example shows a subset of pixels of the image data frame where the transition is at the first edge and the first edge may be uneven or ragged. In this embodiment a location of the transition may be indicated by averaging or otherwise scanning the values of a range of pixels in the horizontal field of view and a range of pixels in the vertical field of view because of the uneven nature of the first edge . The location of the transition within the image data frame and other data frames within the sequence of image data frames can be determined by the web sensing program to determine the location of the first edge in real time as the image data frames are captured and sent to the sensor controller to guide the material web as will be explained in more detail below.

Referring now to therein shown is a diagrammatic representation of one embodiment of logic to determine a feature of the material web within a first group of pixels . The feature can be the location of the transition indicative of the location of the first edge for example. The logic may also be indicative of information identifying properties of a second group of pixels such as the background as shown in . The logic causes the processor to scan the sequence of image data frames to determine the transition between the first color and the second color representing the transition between the background and the material web and indicating the first edge . In determining the transition the logic may cause the processor to scan each pixel of the image data frame to determine a first color value a second color value and a third color value . The first second and third color values may be representative of a color balance of the first color and the second color of the image data frame

As shown in the logic is looking for the color white for example which is indicated by RGB color values where a red content is greater than 150 a green content is greater than 150 and a blue content is greater than 150. The transition may be located by scanning each pixel to determine a color balance for the pixel. The logic may cause the processor to scan each row of pixel data for a contrast between the first color and the second color . When the transition is crossed an edge may be declared at a current column counter marking the row and column at which the transition is detected. In this embodiment if any of the first second or third color values is determined to be below a predetermined threshold the color of the pixel may be identified as the first color indicative of the background . However if the first second and third color values are above the predetermined threshold the logic may cause the processor to identify the pixel as being the second color indicative of the material web and branch to a step where the processor stores a value indicating a column number of the first end . The logic may determine the first second and third color values sequentially in any order as shown in or may determine the first second and third color values at the same time. The logic may cause the processor to store a pixel value or a range of pixel values where the transition occurs in the step for example where pixel value or range of pixel values delineate the transition where the first color lies on a first side of the transition and the second color lies on a second side of the transition opposite the first side of the transition .

To account for ragged or non linear edges the logic may cause the processor to determine the transition at a single pixel value along the horizontal field of view by averaging and comparing multiple pixel values adjacent to the single pixel value along the vertical field of view . In this instance the multiple pixel values may include two or more pixel values where an upper limit of the pixel values is the maximum number of pixel values in the vertical field of view . In this instance the transition may be located at or about the center of the range of pixel values along the horizontal field of view

Referring now to in one embodiment the web sensing program may cause the processor to receive a sequence of image data frames . shows an exemplary embodiment of an image data frame from the sequence of image data frames . In this embodiment the sequence of image data frames is captured by the optical sensor . The image data frame as captured by the optical sensor may be similar to the image data frame described above. However the image data frame may encompass a field of view showing the background the material web and a graphic . The graphic is a line extending longitudinally along a predominant surface of the material web . The field of view may be logically divided into a horizontal field of view and a vertical field of view similar to the horizontal field of view and the vertical field of view respectively and similarly forming a data matrix I J .

In the embodiment shown in the image data frame may depict the background the material web and the graphic . The material web may be indicated by a color values indicating a first color and the graphic may be indicated by color values indicating a second color causing one or more transition between the first color of the material web and the second color of the graphic . Where the graphic creates two transitions as shown in the two transitions may be opposite one another where a first transition is a transition between the first color and the second color and a second transition may be a transition between the second color and the first color or a third color . Regardless of the embodiment the one or more transition may be indicated similar to the transition by a single pixel value or a range of pixel values in the horizontal field of view and a range of pixel values in the vertical field of view . The one or more transition may be used by the web sensing program to guide the material web as will be explained in more detail below. The image data frame may be logically divided into a plurality of groups of pixels .

Referring now to therein shown is a diagrammatic representation of one embodiment of logic to identify properties of a first group of pixels having a feature of the material web which has reddish color by way of example. In this embodiment the first group of pixels shown in is indicative of the material web . The logic may also be indicative of information identifying properties of a second group of pixels representing the graphic for example. The logic may cause the processor to scan the sequence of image data frames to determine the transition between the first color and the second color representing the transition between the material web and the graphic . In determining the transition the logic may cause the processor to scan each pixel of the image data frame to determine a first relative color intensity and a second relative color intensity . The first relative color intensity may be indicative of the color intensity of red over green and the second relative color intensity may be indicative of the color intensity of red over blue for example. In this embodiment the second color the graphic may be predominantly red in color indicating a higher intensity of red than green or blue. However it will be understood by one skilled in the art that the relative color intensity may identify the second color by the intensity of a predominant color of the second color regardless of whether it is red blue or green. The logic may determine a singular pixel value in the horizontal field of view and the vertical field of view where the transition between the first color and the second color occurs. Although explained in reference to a single transition it will be understood by one skilled in the art that the logic may determine any number of transitions and may average pixel values in the vertical field of view to even out false detections which may occur due to ragged transitions or the like.

As shown in the logic may determine the transition by scanning each pixel to determine the relative intensities of the colors within the pixel. The logic may cause the processor to scan a range of rows of pixel data for a contrast between the first color and the second color . When the transition is crossed an edge representing the edge of the graphic may be declared at a current column counter and the processor may store the row and column at which the transition is detected. In this embodiment if either the first relative color intensity or the second relative color intensity of the predominant color is determined to be below a color to which it is compared the color of the pixel may be identified as the first color . If the first relative color intensity and the second relative color intensity of the predominant color is greater than the colors to which the predominant color is compared the pixel may be identified as the second color . After identifying each pixel within the image data frame as being either the first color or the second color the logic may cause the processor to store a pixel value or a range of pixel values where the transition occurs for example where the pixel value or range of pixel values delineate the transition where the first color lies on a first side of the transition and the second color lies on a second side of the transition opposite the first side of the transition . The logic may determine the first and second relative color intensities and in any order or at the same time.

Where the logic causes the processor to determine the transition occurs at column along the horizontal field of view and a range of pixel values along the vertical field of view the logic may cause the processor to identify the column as the transition . Where the logic determines as shown in that the transition occurs at a range of pixel values along the horizontal field of view and a range of pixel values along the vertical field of view the logic may cause the processor to average the location of the transition within the range of pixel values located along the horizontal field of view . In this instance the transition may be located at or about the center of the range of pixel values along the horizontal field of view

Depicted in in one embodiment the web sensing program may cause the processor to receive a sequence of depth data frames having pixel values indicating distances from the depth sensor . By way of example shows an exemplary embodiment of a depth data frame from the sequence of depth data frames . In this embodiment the sequence of depth data frames is captured by the depth sensor and may be representative of objects located at differing distances from the depth sensor . The depth data frame may be represented graphically as an image with two or more colors with each color representing a depth or a depth range relative to the depth sensor . In this embodiment each depth data frame of the sequence of depth data frames output by the depth sensor to the processor may be represented by a matrix d I J where each pixel within the depth data frame represented by the matrix d I J is indicative of a distance measurement representing the distance of the object from the depth sensor at a specified point. As shown in the field of view may be understood as a horizontal field of view and a vertical field of view similar to the field of view discussed in relation to the image data frame . The sequence of depth data frames of which the depth data frame is a part may be captured similar to the sequence of image data frames as described above. In one embodiment the sequence of depth data frames may be captured by the depth sensor at a resolution of 640 480 pixels and at a frame rate of 30 frames per second.

The field of view encompasses at least a portion of the material web . As shown in the data frame shows a depth map of the material web and the background where the background is represented by a first color and the material web is represented by a second color . In this case to obtain suitable values in the data frame the background should be spaced a distance between a minimum resolution and a maximum sensing depth of the depth sensor . For example the background can be spaced between one 1 to ten 10 feet away from the material web . The first and second colors and may be graphical representations of a first distance and a second distance respectively from the depth sensor . It will be understood by those skilled in the art that the first distance and the second distance may be indicative of a distance measurement or a range of distance measurements such that the first distance and the second distance do not overlap and show the location of the material web relative to the background .

The depth data frame may depict the background indicated by the first color and the material web indicated by the second color . A transition may be created at an intersection of the first color and the second color indicative of a first edge of the material web . The transition similar to the transition may be indicated by a range of pixels in the horizontal field of view and a range of pixels in the vertical field of view similar to the ranges of pixels discussed with regards to transition . The depth data frame may be logically divided for example along the line of the transition into a plurality of pixels groups . For instance the depth data frame may be divided into a first group of pixels and a second group of pixels such that the first group of pixels is representative of the material web and the second group of pixels is representative of the background with a division between the first and second groups of pixels and occurring at the transition .

In another embodiment the depth data frame may be divided into a first group of pixels depicting a first feature of the material web a second group of pixels depicting a second feature of the material web and a third group of pixels depicting the background . The second group of pixels are spaced a distance transversely from the first group of pixels . A first transition and a second transition may exist with the first transition between the first group of pixels and the third group of pixels and the second transition between the second group of pixels and the third group of pixels . A web handling signal may be generated based on the distance between the first transition and the second transition

Referring now to therein shown is a diagrammatic representation of one embodiment of logic to determine the location or other properties of a feature of the material web within the first group of pixels . In this embodiment the first group of pixels is indicative of the material web and the feature is indicative of the first edge of the material web . The logic may also be indicative of information identifying properties of the second group of pixels which may represent the background . The logic may cause the processor to scan the sequence of depth data frames to determine the transition between the first distance represented by the second group of pixels and the first color and a second distance represented by the first group of pixels and the second color . In determining the transition the logic may cause the processor to scan each row of pixel data for a contrast between the first distance and the second distance . When the contrasting transition is crossed an edge representing the edge of the material web may be declared at a current column counter and the processor may store the row and column at which the transition is detected.

For example as shown in the logic may determine the transition by causing the processor to scan each pixel as described above to determine whether the distance measurement for each pixel is above or equal to a minimum depth of interest at block . The logic may then cause the processor to determine for each pixel whether the distance measurement is less than a maximum depth of interest at block . The logic may scan each pixel in a row determining whether the distance measurement for each pixel is above or equal to the minimum depth of interest and less than the maximum depth of interest. Pixels depicting the background may be represented by distance measurements which are above the minimum depth of interest but exceed the maximum depth of interest. Pixels depicting the material web may be represented by distance measurements which are above or equal to the minimum depth of interest and do not exceed the maximum depth of interest. The processor may sequentially scan each pixel stepping through columns within a row until determining that a distance measurement for a pixel meets the requirements of both blocks and thereby identifying a distance measurement of a pixel which is indicative of the first edge . The logic may cause the processor to store the location information row and column of the pixel indicating the transition at the first edge . The logic may cause the processor to perform the above described steps for each row within the vertical field of view . As the processor scans the pixels of the depth data frame pixels indicative of the transition may be found within a range of columns. The logic as described above in relation to logic may cause the processor to store the range of columns represented by a pixel range in the horizontal field of view indicative of the transition .

In another embodiment of the logic the logic may generate web handling signals based on the distance between the first transition and the second transition of the depth data frame . The logic may enable determination and storage of a set point indicative of a desired operational aspect of the material web and the web handling signal may be indicative of an actual state of the first operational aspect of the material web . The first operational aspect of the material web may be a tension of the material web measured in one embodiment by the distance between the first transition and the second transition . In yet another embodiment the first operational aspect of the material web may be a desired location of the material web and the web handling signal may be an error signal indicative of a difference in relative locations between the first and second transitions and of the set point. The generation and storage of the set point will be explained in more detail below.

Referring now to therein shown is a diagrammatic representation of one embodiment of the web sensing program . The processor of the sensor controller may execute the processor executable code for the web sensing program at block . Execution of the web sensing program may cause the processor to determine whether the natural interaction sensor is in communication with the processor at block . Where the processor determines the natural interaction sensor is not in communication the processor may generate and display an error message at block . Where the natural interaction sensor is in communication the processor may configure the natural interaction sensor for a selected resolution and frame rate at block . For example as previously discussed the resolution of the optical sensor and the depth sensor may be 640 480 pixels with a frame rate of 30 to 290 frames per second. However it will be understood that the resolution and frame rate of the natural interaction sensor may vary.

The web sensing program may cause the natural interaction sensor to capture a sequence of data frames and cause the processor to receive the sequence of data frames from the natural interaction sensor at block . The sequence of data frames may be the sequence of data frames or as described above for example. The web sensing program may cause the processor receiving the sequence of data frames to identify a desired location of a feature within the sequence of data frames and store a set point indicative of the desired location of the feature . The feature may be the feature or as described above for example. Once identified and stored the set point may be used to determine positional changes within the material web traveling across the steering rollers of the web handling system . The processor may store the set point in the one or more non transitory computer readable medium . In one embodiment the processor may store a plurality of set points for a plurality of features for instance where the web sensing program is designed to guide the material web by a plurality of edges by an edge and a graphic by depth data from the depth sensor and the graphic captured by the optical sensor by a feature of the background and a feature of the web or where the web sensing program is guiding a plurality of material webs for example.

The web sensing program may also cause the processor at block to store logic indicative of information identifying properties of a first group of pixels of the feature of the material web . The logic may be representative of the logic or for example and may be stored on the one or more non transitory computer readable medium by the processor . The logic may also be indicative of information identifying properties of a second group of pixels . The first group of pixels may be representative of the first group of pixels or and the second group of pixels may be representative of the second group of pixels or for example.

After the set point and logic have been stored the processor may cause the material web to initiate travel through the web handling system . At block the web sensing program may cause the natural interaction sensor to capture the sequence of data frames at distinct instants of time and cause the processor to receive the sequence of data frames . At block the web sensing program may cause the processor to determine whether new data is ready or whether each of the data frames in a current sequence of data frames have been analyzed. If no new data is present the web sensing program may cause the processor to wait for new data. If new data is present the web sensing program may cause the processor to execute the logic to scan the pixels in the sequence of data frames to locate a transition between a property of the first group of pixels and one or more property of the second group of pixels with in the sequence of data frames at block . The transition may be representative of the transition or .

At block the web sensing program may cause the processor to generate a series of error signals indicative of a lateral location of the transition and or a difference in location of the transition relative to the set point . The web sensing program may also cause the processor to output location signals and or the error signals at block . The location signals may update the analog outputs of the web handling system by transmitting the location signals to the web controller which may generate and transmit a control signal to the platform drive to change the angular position of the platform relative to the base in order to adjust the lateral position vertical or horizontal of the material web . Adjustment of the lateral position of the material web may be performed until a desired distance relationship between the transition relative to the set point is restored. The set point can be stored in either the sensor controller and or the web controller .

In one embodiment of the web sensing program the material web is a first material web the feature is a first feature the background is a first background the transition is a first transition the series of location signals and or error signals is a first series of location signals and or error signals . In this embodiment the sequence of data frames may be provided with a third group of pixels depicting at least one second feature extending in a web direction of travel on a second material web and a fourth group of pixels depicting a second background transverse to the second feature . The web sensing program in this embodiment may cause the processor to scan the sequence of data frames as previously described to locate a second transition between the third group of pixels and the fourth group of pixels in the sequence of data frames . The web sensing program may also cause the processor to generate a second series of location signals and or error signals similar to the series of location signals and or error signals indicative of the lateral locations of the second transition within the data frames and or a difference in location of the second transition relative to the set point .

In another embodiment the web sensing program may cause the processor to monitor the material web by causing the depth sensor of the natural interaction sensor to capture the sequence of data frames which in this embodiment are indicative of a sequence of depth maps. The processor may receive the sequence of data frames and store web handling information indicative of a desired tension for the material web . In this embodiment the web handling information may include the set point indicative of the desired location of the feature . The feature may be indicative of the desired web tension and be indicated by a measured width of the material web as compared to a desired width of the material web . To determine the feature the processor may determine a desired width of a properly tensioned material web from the depth sensor and store that desired distance as the set point . The processor may then execute the logic which may cause the processor to determine a current web tension of the material web using at least one of the depth maps in the sequence of data frames . The processor may then determine the error signal indicative of a difference between the desired web tension and the current web tension and output the error signal . The error signal may be output to the web controller to correct web tension using known techniques.

In yet another embodiment the web sensing program may cause the processor to determine a difference between a desired quality inspection aspect and a current quality inspection aspect. The processor may receive the sequence of data frames captured by the optical sensor having a field of view encompassing at least a portion of the material web wherein the sequence of data frames is indicative of a sequence of signals. In this embodiment the sequence of data frames may be a sequence of images of the feature captured by the optical sensor . The processor may determine and store the set point which may be an image representative of the feature of the material web at a desired quality. The desired quality of the feature may be represented as an image one of the sequence of data frames depicting the feature at the desired quality. The desired quality of the feature may be for example a color quality dimensional quality opacity transparency or any other quality aspect discernible from an image. The processor may store the web quality inspection information indicative of the desired quality of the feature of the material web on the one or more non transitory computer readable medium . The processor may then determine a current quality of the feature of the material web using at least one of the data frames of the sequence of data frames based on a comparison of the aspects of the desired quality of the feature stored in the set point relative to the current quality of the feature . The processor may then determine the error signal indicative of a difference between the desired quality and the current quality of the material web and output the error signal for instance to a user or other component of the web handling system .

Referring now to shown therein is the natural interaction sensor disposed in a first enclosure configured to receive and support the natural interaction sensor . The first enclosure may be provided with a housing portion partially surrounding a space configured to receive the natural interaction sensor a face plate configured to be secured to the housing portion between the natural interaction sensor and the material web and a sensor window configured to be secured to the face plate . The face plate is provided with an opening to permit the natural interaction sensor to sense the material web and the background through the opening and a first recess surrounding the opening to receive the sensor window such that the sensor window covers the opening and the face plate supports the sensor window . The sensor window in one embodiment may be transparent to visible and IR spectrum of light so that the natural interaction sensor can sense the material web and the background through the sensor window . The face plate may also be provided with a second recess sized and shaped to matingly receive the housing portion .

In one embodiment the first enclosure may be provided with one or more vibration dampeners configured to dampen vibrations within the first enclosure . The vibration dampeners may be selected from a group comprising O rings rubber inserts plastic inserts and securing straps. In one embodiment as shown in a first vibration dampener may be provided as an O ring positioned between the face plate and the sensor window . The first vibration dampener may be configured to reduce or eliminate vibrations within the sensor window to mitigate interference with the natural interaction sensor generated by vibrations within the sensor window . Second and third vibration dampeners and respectively may be provided as securing straps configured to engage a rear surface of the housing portion to maintain the housing portion within the second recess of the face plate . The second and third vibration dampeners and may comprise plastic hard rubber springs or similar materials which may provide vibration tolerance and reduce vibrations which may affect the natural interaction sensor . In one embodiment a single vibration dampener may be used in place of the second and third vibration dampeners and . It will be understood by one skilled in the art that greater or fewer vibration dampeners may be used so long as they provide sufficient support for the natural interaction sensor and reduce vibrations such that the vibrations to not adversely affect the natural interaction sensor .

As shown in a second enclosure may be configured to receive and support the first enclosure containing the natural interaction sensor and the sensor controller . The second enclosure includes a front a back a first side and a second side a top and a bottom . The front the back the first side and the second side partially or completely surround a space receiving the first enclosure and the sensor controller . An opening is formed through the front with the opening aligned with the sensor window to permit the natural interaction sensor to sense the material web and the background through the opening sensor window and the opening . The second enclosure includes a connection panel on the back to provide communication connections power to the sensor controller and the natural interaction sensor . For example the connection panel will include the second port to permit the sensor controller to be connected to the web controller . The first and second enclosures and may be connected by screws bolts clamps straps or any other suitable mechanism. As one skilled in the art will understand the second enclosure is attached to a support mechanism not shown such that the front faces the material web and the background such that the natural interaction sensor can sense the material web and the background .

Although a few embodiments of the present disclosure have been described in detail above those of ordinary skill in the art will readily appreciate that many modifications are possible without materially departing from the teachings of the present disclosure. Accordingly such modifications are intended to be included within the scope of the present disclosure as defined in the claims.

