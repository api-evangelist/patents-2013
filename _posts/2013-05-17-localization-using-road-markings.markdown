---

title: Localization using road markings
abstract: One or more embodiments of techniques or systems for creating a road marking classification template and vehicle localization using road markings are provided herein. A road marking classification template database includes templates of training images taken from different navigation environments. A training image with a road marking can be rectified and enhanced. Corners can be calculated for the road marking using the rectified or enhanced image. Locations can be determined for the corners and stored as part of a template. Similarly, a runtime image can also be rectified, enhanced, boosted, etc. Additionally, corners can be calculated for the runtime image and matched against corners of templates from the template database. A location or a pose of a vehicle can be determined using the match. In this way, vehicle localization is provided such that drift or other issues associated with GPS, such as occlusion, are mitigated, for example.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09488483&OS=09488483&RS=09488483
owner: HONDA MOTOR CO., LTD.
number: 09488483
owner_city: Tokyo
owner_country: JP
publication_date: 20130517
---
Generally localization for a vehicle is accomplished by using a global positioning system GPS . For example GPS is a space based satellite navigation system that is capable of determining a location based on multiple GPS satellites so long as there is an unobstructed view to the GPS satellites. However GPS units are generally accurate to the order of about ten meters which is not sufficient for lane level localization. Often GPS units suffer from drift as a result of accumulation or compounding of errors. Additionally because GPS requires an unobstructed view to GPS satellites inclement weather conditions urban regions mountainous terrain or other occlusions often pose challenges to vehicle localization.

This summary is provided to introduce a selection of concepts in a simplified form that are described below in the detailed description. This summary is not intended to be an extensive overview of the claimed subject matter identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

One or more embodiments of techniques or systems for vehicle localization using road markings are provided herein. As an example an image capture device or camera can be used to capture images which are then compared to templates thereby enabling one to determine their location. In one or more embodiments a camera is mounted to a car to capture images to be compared to database images in order to determine a location for the car. In one or more embodiments a cell phone camera can be used to capture images which are compared to images in a database to determine a location for the cell phone. Processing such as performing a bird s eye view transform on a capture image can occur prior to database comparison. Road markings generally include markings associated with an absolute position such as markings painted on or placed upon a road surface turn arrows pedestrian crossings crosswalks speed limits bike lane markings other postings etc. Location information features or data pertaining to these road markings can be surveyed and compiled into a template of a database such as a road marking classification template or template for a template database including one or more templates. A template can represent a location such as a GPS location and be used to identify the location based on features such as corners stored within the template. As used herein a corner is generally associated with corner detection such as an approach used within computer vision systems to extract features or infer the contents of an image. Because road markings are generally associated with an absolute position accumulation of error and drift can be mitigated and accuracy of localization improved. Additionally a road marking detection component such as one or more cameras or one or more image capture devices can be used to gather or capture images such as runtime images of a navigation environment of a vehicle. The template database or system may then be used to facilitate vehicle localization or determine a pose of a vehicle by comparing runtime image s to training image s from the template database. According to one or more aspects the pose of the vehicle can include a bearing in which the vehicle is facing.

As an example when a training image of a navigation environment including one or more road markings is received e.g. from a camera the training image can be rectified to mitigate perspective distortion lens distortion or other distortion etc. In other words the training image can be transformed such that the perspective may be similar to a bird s eye view of the navigation environment. The rectified training image can have a bird s eye view of the road markings. A bounding box region or other delegator can be assigned or created around a road marking within the rectified training image to identify or highlight the road marking. Additionally portions of the rectified training image within the bounding box can be enhanced to segment or distinguish the road marking from the remainder of the rectified training image. One or more corners can be calculated or computed for the road marking within the bounding box. Corners can be found or calculated in corner detection in association with computer vision systems to extract features or infer contents of an image. For example a corner generally has a well defined position and can be robustly detected. In other words a corner can be a detected portion of a road marking which has an absolute location associated therewith and used for localization herein.

Additionally corners can be associated with one or more locations such as a GPS location e.g. based on a GPS coordinate system or a pixel location e.g. based on a pixel coordinate system . To this end a template for the training image can be created or stored where the template includes the corners and associated locations or coordinates e.g. based on different coordinate systems . Because a template can be feature based or includes multiple features multiple corners etc. comparison or matching possibilities are improved. That is if one or more features are not detected at runtime prior to localization matching and thus localization may still be possible.

When a vehicle is outfitted with a road marking sensor such as a camera the camera can take a runtime image of a navigation environment and compare aspects or features such as corners of the runtime image with corners from templates of a template database. For example a runtime image can be received and transformed or rectified in a similar manner as the training image. In one or more embodiments shadow boosting and image enhancement techniques can be used to prepare an image for corner detection or corner calculation. After corners are calculated the corners can be classified such as by road marking type for example. The corners can be matched against templates from the template database and a location for the vehicle or a pose for the vehicle can be determined accordingly. Because pixel locations for road markings GPS locations of the road markings can be determined from the matched template a pixel location of the camera can be determined from the runtime image and a height of the camera on the vehicle is known the location and pose of the vehicle can be determined by mapping from the pixel coordinate system to the GPS coordinate system. Additionally navigation instructions can be provided based on the location of the vehicle the pose of the vehicle one or more or the road markings etc.

It will be appreciated that while a boundary such as a bounding box is described herein it is understood that other shapes can be employed without departing from the spirit or scope of the disclosure.

The following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects are employed. Other aspects advantages or novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

Embodiments or examples illustrated in the drawings are disclosed below using specific language. It will nevertheless be understood that the embodiments or examples are not intended to be limiting. Alterations and modifications in the disclosed embodiments and further applications of the principles disclosed in this document are contemplated as would normally occur to one of ordinary skill in the pertinent art.

It will be appreciated that for one or more of the figures herein one or more boundaries such as boundary or of for example are drawn with different heights widths perimeters aspect ratios shapes etc. relative to one another merely for illustrative purposes and are not necessarily drawn to scale. For example because dashed or dotted lines are used to represent different boundaries if the dashed and dotted lines were drawn on top of one another they would not be distinguishable in the figures and thus are drawn with different dimensions or slightly apart from one another in one or more of the figures so that they are distinguishable from one another. As another example where a boundary is associated with an irregular shape the boundary such as a box drawn with a dashed line dotted lined etc. does not necessarily encompass an entire component feature marking etc. in one or more instances. Conversely a drawn box does not necessarily encompass merely an associated component feature marking etc. in one or more instances but encompasses at least a portion of one or more other component feature marking etc. as well. Additionally it will be appreciated that a component feature marking etc. may be encompassed by a dashed line or dotted line merely for identification such as or of for example.

Generally vehicle localization is achieved by a global positioning system GPS which is a space based satellite navigation system that enables one to determine a current location based on an unobstructed line of sight to multiple GPS satellites. A GPS receiver can calculate an associated location based on a timing of a signal and positions of GPS satellites during signal transmission. However GPS can be inaccurate due to drift or satellite occlusion. In one or more embodiments vehicle localization can be achieved by surveying or receiving training images of road markings storing associated feature information in a template database of one or more training templates or templates and comparing a runtime image with corresponding training images from templates of the template database. As an example a template can include a rectified training image e.g. or other images derived therefrom such as boosted images enhanced images etc. derived from a training image. Further the template can include one or more corners that are based on road markings within the training image and the rectification or bird s eye view transform performed on the training image. One or more corresponding locations associated with the corners can be determined and stored as part of the template. For example a corner of a road marking within a rectified training image can be associated with a GPS location and a pixel location. The GPS location corresponds to a GPS coordinate system in the real world while the pixel location corresponds to a pixel coordinate system within the rectified training image.

A road marking may include but is not limited to markings painted or placed upon on a road surface turn arrows pedestrian signs crosswalks speed limits lane markings bike markings other traffic postings etc. Additionally a road marking as used herein may include shapes words or other indicia or combination thereof. Because a road marking detection component or camera may be mounted to face a same direction as a driver of the vehicle the training image may be associated with a perspective or first person view. The training image of includes one or more training road markings indicated at and for example. In this example is a first railroad crossing road marking and is a second railroad crossing road marking.

In one or more embodiments the rectified training image can be derived from the training image in by applying an inverse perspective transform on the training image . The inverse perspective transform may be based on at least one of a height or an angle of at least one of a road marking detection component camera or sensor with respect to a ground plane of the vehicle. When the height of the camera the angle of the camera and GPS coordinates of the camera are known distances or real world locations such as GPS coordinates can be determined for one or more pixels of the rectified training image . In other words a pixel of the rectified training image can be associated with a distance in the real world or assigned a set of GPS coordinates based on the height of the camera the angle of the camera or GPS coordinates of the camera. Additionally a tilt angle of a ground plane associated with the vehicle can be measured according to one or more embodiments. When a vehicle is travelling or resting on a ground plane that is not flat such as a hill rectification of the training image may be adjusted based on the tilt angle of the ground plane accordingly. For example a gyroscope component can be configured to measure the tilt angle of the ground plane for the vehicle. Additionally an image processing component can be configured to transform a training image into a rectified training image based on the tilt angle of the ground plane.

In one or more embodiments image enhancement can be performed on the rectified training image . For example image enhancement not shown can be performed on one or more road marking regions associated with the first bounding box the second bounding box or the third bounding box . A region extraction algorithm such as a maximally stable external regions MSER algorithm can be used to extract or segment a road marking or a road marking region from the rectified training image . By performing image enhancement such as MSER on the rectified training image road marking features can be highlighted thereby facilitating identification of the road marking features for storage within a road marking classification template or template for example. The MSER algorithm effectively transforms an input image such as a road marking portion of the rectified training image into a binary image. For example image enhancement can be used to transform an image or portions of an image from color or grayscale to black and white thereby highlighting one or more road markings for corner detection computation or calculation and storage as will be described herein. In one or more embodiments an image enhancement component can be configured to perform the image enhancement such as by applying the MSER transformation on an image such as the rectified training image .

Generally corner detection can be used to extract features and infer contents of an image. A corner often has a well defined position e.g. physical or GPS location based on a real world coordinate system and can be robustly detected. Because of this a corner can be a representation of a detection portion of a road marking and can be considered a reliable location indicator for vehicle localization. In other words corner detection or calculation can enable a vehicle localization system to translate markings associated with an absolute location such as road markings from the real world to a template by associating or outlining a set of points or pixels within an image with pixel coordinates e.g. based on a pixel coordinate system for example. Accordingly a pixel location within a rectified training image can be determined for a corner because a corner can be a pixel within the rectified training image e.g. a template corner . In one or more embodiments one or more template corners can be calculated for one or more of the road markings based on corresponding bounding boxes for the respective road markings. In other embodiments one or more template corners can be calculated for one or more of the road markings based on enhanced training road marking regions such as an MSER enhanced road marking region. In one or more embodiments one or more template corners can be based on features from accelerated segment test FAST corner detection. In one or more embodiments a corner component can be configured to calculate one or more corners or template corners for one or more road markings or one or more training road markings based on one or more road marking regions enhanced road marking regions within bounding boxes such as bounding box or . Additionally the corner component can be configured to compute FAST corners based on FAST corner detection.

It will be appreciated that an image such as the rectified training image of can include one or more pixels. In one or more embodiments each pixel can be associated with a set of pixel coordinates e.g. 0 0 0 1 etc. . For example corners A B C D and E within the third bounding box can be associated with a set of pixel coordinates that are unique from one another within an image. In one or more embodiments a corner can be associated with a patch of surrounding pixels. Descriptors can be calculated based on the patch of pixels. In the following example a corner pixel is in a center of a 5 5 patch of pixels where C a corner or a corner pixel and X other pixels 

In one or more embodiments one or more descriptors can be calculated for a corner based on the patch of surrounding pixels. For example a histogram of oriented gradients HOG descriptor not shown in can be calculated and stored along with the pixel coordinate information. Generally a HOG descriptor is a feature descriptor and can be used in computer vision and image processing for object detection. A number of occurrences of a gradient orientation in a portion of an image can be determined. Due to variations in lighting or scale a HOG descriptor comparison e.g. between images may offer improved accuracy for object detection over direct pixel comparison between a runtime image and a training image for example. It will be appreciated that a size or set of dimensions associated with a patch of pixels can vary or be adjusted. For example a 3 3 patch or a 7 7 patch may be used in other embodiments. It will be appreciated that a corner pixel may not always necessarily be at the center of a patch such as when a corner pixel is at an edge of a rectified image or rectified training image for example.

In one or more embodiments each pixel can be associated with a set of physical coordinates such as GPS coordinates in addition to the set of pixel coordinates. In other words pixels can referenced on paper e.g. within a rectified image or rectified training image using a first set of coordinates such as the pixel coordinate system and also referenced in the real world e.g. representing a physical distance etc. using a second set of coordinates such as a GPS coordinate system. In one or more embodiments a GPS component can determine a location for a road marking detection component such as a camera or image capture device configured to capture or receive a training image such as the training image of . Based on at least one of an angle a height or other position etc. of at least one of the camera or road marking detection component one or more GPS coordinates can be determined for the corners A B C D and E calculated within the rectified training image of . In one or more embodiments a GPS component can be placed physically at a corner to determine a GPS location or set of GPS coordinates for the corner. In other embodiments the GPS component or a corner component can calculate the GPS location for a corner using variables such as the height or angle of the camera in conjunction with the GPS location of the camera or other methods such as triangulation etc.

Corners or associated corner pixels e.g. template corners from a training image can thus be associated with coordinates from multiple coordinate systems. When corners from a runtime image e.g. runtime corners are compared with corners from a training image e.g. template corners as will be described herein a GPS coordinate can be determined for a camera capturing the runtime image based on pixel locations of template corners GPS locations of template corners pixel locations of runtime corners and a pixel location of the camera from the runtime image. In other words the location for the camera can be determined by mapping pixel locations of matching corners from a runtime image and a training image to GPS locations or coordinates. In one or more embodiments this mapping can be based on FAST corners calculated for a rectified runtime image and a rectified training image. Additionally the mapping can be based on HOG descriptors calculated from a patch of pixels where the patch of pixels includes a corner pixel. In one or more embodiments a corner component can be configured to determine a patch of pixels for a corner and calculate a corresponding HOG descriptor for the corner.

In one or more embodiments a set of corners corresponding to a road marking a road marking region or a bounding box can be classified such as by being manually labeled with a classification e.g. a road marking labeled as a railroad crossing etc. .

In one or more embodiments a template can be created by storing one or more of the corners corresponding locations such as GPS locations GPS coordinates pixel locations pixel coordinates and descriptors such as HOG descriptors. In other words the template can be learned from a training image a rectified training image one or more associated template corners of an image bounding boxes etc. A template can include a training image one or more corners calculated or detected within the training image GPS locations for the corners pixel locations for the corners and HOG descriptors for the corners. For example the templates can be stored in a template database. It will be appreciated that the template database can be a local database a remote database stored on memory such as flash memory etc.

In one or more embodiments a mobile device such as a smartphone can be equipped with an application configured to utilize a camera of the smartphone to capture images for use as a runtime image thereby enabling the smartphone to be used for localization. The mobile device can be mounted to a vehicle such as a bicycle or held by a user during capture of a runtime image for example.

In one or more embodiments a road marking detection component can be configured to receive a runtime image of a navigation environment associated with a perspective from a vehicle where the runtime image can include one or more runtime road markings or road markings. The runtime image is captured as a point of comparison against training images of templates of a template database to find a match and thereby facilitate vehicle localization. As an example a GPS receiver can be a primary localization system and a vehicle localization system using road markings can supplement the GPS receiver with localization information. Alternatively the vehicle localization system based on or augmented with road markings can be a standalone GPS system in other embodiments.

In one or more embodiments an image processing component can be configured to transform the runtime image into a rectified runtime image by reducing perspective distortion associated with the runtime image where the rectified runtime image includes a rectified view of the one or more runtime road markings such as and . As an example the image processing component can be configured to achieve this by performing an inverse perspective transform on the runtime image similarly to . As a result of the rectification or the inverse perspective transform perspective distortion associated with the runtime image can be mitigated or removed. Additionally a gyroscope component can be configured to measure a tilt angle of a ground plane associated with the vehicle. Here the image processing component can be configured to transform the runtime image into the rectified runtime image based on the tilt angle of the ground plane. When a vehicle is on a hill where the tilt angle of the ground plane is not zero for example a runtime image or a rectified runtime image can be adjusted to compensate for the hill based on the tilt angle measured by the gyroscope component.

In one or more embodiments a shadow component such as the shadow component as will be discussed in can be configured to equalize a blue spectrum across the rectified view of the one or more runtime road markings within the rectified runtime image. Generally an amount of blue is greater in a shadowed region of an image than a non shadowed region of the image. This is because shadowed regions are lit up by scattered light from the sky which is more in the blue spectrum. As an example if an object or road marking is white shadowing will generally make the object or road marking appear bluer in comparison to other white objects or road markings within an image. By equalizing the blue spectrum across regions of interest such as a road marking region road marking etc. the amount of blue in the shadowed region can be reduced thereby boosting the brightness of the shadowed region closer to a brightness of the non shadowed region. In one or more embodiments shadow boosting is performed on white colored road markings or substantially white road markings.

A matching component such as the matching component as will be discussed in can be configured to match one or more runtime corners with one or more template corners from one or more templates such as templates from a template database. A template from the template database can be feature based or corner based. As an example the matching can include at least one of putative matching or structural matching. Generally putative matching can include matching a runtime corner against one or more template corners from one or more templates based on features descriptors pixel location etc. For example putative matching can include matching according a HOG descriptor from a template corner versus a HOG descriptor from a runtime corner. In one or more embodiments putative matching is based on a threshold. Additionally structural matching can include matching runtime corners and template corners based on at least one of a shape of a set of one or more corners a 2D geometry of a road marking a pattern of a set of one or more corners pixel locations of corners etc.

The matching component can be configured to classify one or more runtime corners based on one or more templates and match one or more runtime corners based on the classification. As an example a runtime corner classified as a railroad crossing corner can be matched against template corners labeled as railroad crossings. Examples of road marking types or road marking classifications can include stop bike lane turn arrows railroad lane markings crosswalks etc. Feature based matching is generally more accurate than other types of matching such as whole shape matching or glyph matching because missing or undetected features or corners can be inferred such as with a snake algorithm. For example if a portion of a glyph is missing or undetected glyph matching may not be feasible. Conversely when one or more corners are not detected the snake algorithm can fill in the missing corners. For example the snake algorithm can iteratively find locations for corners based on minimizing an energy function and locking onto a suitable contour. As an example a contour can be found by a road marking contrasted against an illuminated background provided by image enhancement. The matching component can be configured to determine one or more additional e.g. missing runtime corners based on one or more template corners such as by filling in blanks or inferring corners using corresponding template corners. In one or more embodiments one or more additional runtime corners can be determined based on a snake algorithm. When missing corners are found template corners from a matching or corresponding template can be substituted based on a contour of a road marking.

In one or more scenarios a GPS component can be configured to receive or determine a supplemental location of the vehicle. In these scenarios the matching component can be configured to match corners based on the supplemental location of the vehicle such as within a radius of the supplemental location. For example template corners within a radius of the supplemental location can be used for matching against the corners calculated at runtime runtime corners . By using the supplemental location to facilitate a search or a match localization can be performed more quickly. In one or more embodiments the supplemental location can be determined based on at least one of a GPS location by a camera mono camera stereo camera triangulation etc.

A localization component such as the localization component as will be discussed in can be configured to determine at least one of a location of the vehicle or a pose of the vehicle based on the match. As an example one or more additional runtime corners can be used to facilitate matching for the localization component. In one or more embodiments the localization component can be configured to determine the location or the pose of the vehicle based on a linear transform on a bird s eye view of an image e.g. a rectified image inverse perspective mapped image inverse perspective transform image etc. a corner location e.g. a pixel location of a road marking based on a pixel coordinate system matched between a rectified training image and a rectified runtime image GPS locations of corners from the rectified training image a pixel location of a road marking detection component or a pixel location of a camera from the rectified runtime image. It will be appreciated that because images associated with can be derived from one another that a feature based on one of the images can be based on one or more associated images. Similarly because images associated with can be derived from one another that a feature based on one of the images can be based on one or more associated images. For example a pixel location of a camera can be determined based on at least one of the rectified runtime image of the boosted image of the enhanced rectified runtime image of or the rectified runtime image of etc. Because the pixel location of the camera can be determined or is otherwise known the pose or bearing of the vehicle can be determined. In other words a runtime image and a training image are used to map a first coordinate system e.g. pixel coordinate system to a second coordinate system e.g. GPS coordinate system and solve for a GPS coordinate of a camera.

In one or more embodiments the localization component can be configured to determine the location or the pose of the vehicle based on at least one of triangulation a perspective n point pose of one or more road marking detection components stereo based triangulation local bundle adjustment etc. The perspective n point pose can be calculated from known 3D to 2D point correspondences for example.

In one or more embodiments navigation instructions can be provided to a runtime user based on the location of the vehicle the pose of the vehicle one or more of the road markings detected at runtime etc. For example if a vehicle is travelling the wrong way on a road the image capture component or camera may capture an image including an upside down arrow. Upon detection of the upside down arrow navigation instructions can be provided to the runtime user to move to a correct lane etc. for example. In one or more embodiments navigation instructions are provided to a runtime user based on a shape of a captured road marking. For example when a road marking is associated with a turn only lane navigation instructions can be provided to the runtime user to turn based on the turn only road marking.

It will be appreciated that at least one or more of the components of the system of can be implemented as the same or corresponding component as one or more of the components from the system of according to one or more embodiments. For example the road marking detection component of can be implemented as the same component as the road marking detection component of . In other embodiments respective components can be implemented as separate components. For example the road marking detection component of can be implemented as a different component from the road marking detection component of .

Still another embodiment involves a computer readable medium including processor executable instructions configured to implement one or more embodiments of the techniques presented herein. An embodiment of a computer readable medium or a computer readable device that is devised in these ways is illustrated in wherein an implementation includes a computer readable medium such as a CD R DVD R flash drive a platter of a hard disk drive etc. on which is encoded computer readable data . This computer readable data such as binary data including a plurality of zero s and one s as shown in in turn includes a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable computer instructions is configured to perform a method such as the method of method of or method of . In another embodiment the processor executable instructions are configured to implement a system such as the system of or system of . Many such computer readable media are devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components residing within a process or thread of execution and a component may be localized on one computer or distributed between two or more computers.

Further the claimed subject matter is implemented as a method apparatus or article of manufacture using standard programming or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Generally embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions are distributed via computer readable media as will be discussed below. Computer readable instructions are implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions are combined or distributed as desired in various environments.

In other embodiments device includes additional features or functionality. For example device also includes additional storage such as removable storage or non removable storage including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one or more embodiments computer readable instructions to implement one or more embodiments provided herein are in storage . Storage also stores other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions are loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media is part of device .

The term computer readable media includes communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal includes a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device includes input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices or any other input device. Output device s such as one or more displays speakers printers or any other output device are also included in device . Input device s and output device s are connected to device via a wired connection wireless connection or any combination thereof. In one or more embodiments an input device or an output device from another computing device are used as input device s or output device s for computing device . Device also includes communication connection s to facilitate communications with one or more other devices.

According to one or more aspects a method for vehicle localization is provided including receiving a runtime image of a navigation environment associated with a perspective from a vehicle. The runtime image can include one or more runtime road markings. The method can include transforming the runtime image into a rectified runtime image by reducing perspective distortion associated with the runtime image. The method can include transforming a runtime image of a navigation environment into a rectified runtime image the rectified runtime image comprising a rectified view of one or more runtime road markings the runtime image associated with a perspective from a vehicle. The rectified runtime image can include a rectified view of the one or more runtime road markings.

The method can include enhancing the rectified runtime image by extracting one or more enhanced runtime road marking regions from the rectified runtime image. The method can include calculating one or more runtime corners for one or more runtime road markings based on one or more enhanced runtime road marking regions. The method can include calculating one or more runtime corners for the one or more runtime road markings based on one or more enhanced runtime road marking regions derived from the rectified runtime image. The method can include matching one or more runtime corners with one or more template corners from one or more templates. The method can include determining at least one of a location of the vehicle or a pose of the vehicle based on the matching. The method can include determining at least one of a location of the vehicle or a pose of the vehicle based on matching the one or more runtime corners with one or more template corners from one or more templates.

In one or more embodiments the method can include at least one of performing an inverse perspective transform on the runtime image performing shadow boosting on at least a portion of the rectified runtime image by equalizing a blue spectrum across the rectified view of the one or more runtime road markings within the rectified runtime image extracting one or more enhanced runtime road marking regions based on a maximally stable external region MSER algorithm enhancing the rectified runtime image based on an intensity of the rectified runtime image calculating one or more runtime corners based on features from accelerated segment test FAST corner detection determining a supplemental location of the vehicle matching one or more runtime corners based on the supplemental location of the vehicle classifying one or more runtime corners based on one or more templates matching one or more runtime corners based on the classification putative matching structural matching determining one or more additional runtime corners based on one or more template corners determining at least one of the location of the vehicle or the pose of the vehicle based on one or more additional runtime corners determining one or more additional runtime corners based on a snake algorithm receiving a tilt angle of a ground plane associated with the vehicle or transforming the runtime image into the rectified runtime image based on the tilt angle of the ground plane.

According to one or more aspects a system for vehicle localization is provided including a road marking detection component which can be configured to receive a runtime image of a navigation environment associated with a perspective from a vehicle the runtime image including one or more runtime road markings. The system can include an image processing component configured to transform the runtime image into a rectified runtime image by reducing perspective distortion associated with the runtime image the rectified runtime image including a rectified view of the one or more runtime road markings. The image processing component can be configured to enhance the rectified runtime image by extracting one or more enhanced runtime road marking regions from the rectified runtime image. The system can include a corner component configured to calculate one or more runtime corners for one or more runtime road markings based on one or more enhanced runtime road marking regions. The system can include a matching component configured to match one or more runtime corners with one or more template corners from one or more templates. The system can include a localization component configured to determine at least one of a location of the vehicle or a pose of the vehicle based on the match.

In one or more embodiments the system can include at least one of a shadow component configured to equalize a blue spectrum across the rectified view of the one or more runtime road markings within the rectified runtime image a global positioning system GPS component configured to receive a supplemental location of the vehicle the matching component configured to match based on the supplemental location of the vehicle or a gyroscope component configured to measure a tilt angle of a ground plane associated with the vehicle where the image processing component can be configured to transform the runtime image into the rectified runtime image based on the tilt angle of the ground plane.

Although the subject matter has been described in language specific to structural features or methodological acts it is to be understood that the subject matter of the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example embodiments.

Various operations of embodiments are provided herein. The order in which one or more or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated based on this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

As used in this application or is intended to mean an inclusive or rather than an exclusive or . In addition a and an as used in this application are generally construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Also at least one of A and B and or the like generally means A or B or both A and B. Further to the extent that includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising .

Further unless specified otherwise first second or the like are not intended to imply a temporal aspect a spatial aspect an ordering etc. Rather such terms are merely used as identifiers names etc. for features elements items etc. For example a first channel and a second channel generally correspond to channel A and channel B or two different or two identical channels or the same channel.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur based on a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims.

