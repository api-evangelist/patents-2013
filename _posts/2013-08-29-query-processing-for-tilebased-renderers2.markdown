---

title: Query processing for tile-based renderers
abstract: Systems, methods, and apparatus for performing queries in a graphics processing system are disclosed. These systems, methods, and apparatus may be configured to read a running counter at the start of the query to determine a start value, wherein the running counter counts discrete graphical entities, read the running counter at the end of the query to determine an end value, and subtract the start value from the end value to determine a result.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09589314&OS=09589314&RS=09589314
owner: QUALCOMM Incorporated
number: 09589314
owner_city: San Diego
owner_country: US
publication_date: 20130829
---
This application claims the benefit of U.S. Provisional Application No. 61 817 154 filed Apr. 29 2013 the entire content of which is incorporated herein by reference.

This disclosure relates to graphics processing systems and more particularly to query processing for tile based renderers.

Computing devices often utilize a graphics processing unit GPU to accelerate the rendering of graphics data for display. Such computing devices may include e.g. computer workstations mobile phones e.g. so called smartphones embedded systems personal computers tablet computers and video game consoles. Rendering generally refers to the process of converting a three dimensional 3D graphics scene which may include one or more 3D graphics objects into two dimensional 2D rasterized image data. A graphics scene may be rendered as a sequence of one or more frames where each frame depicts the graphics scene at a particular instance in time.

A GPU may include a 3D rendering pipeline to provide at least partial hardware acceleration for the rendering of a 3D graphics scene. The 3D graphics objects in a scene may be subdivided by a graphics application into one or more 3D graphics primitives e.g. points lines triangles patches etc. and the GPU may convert the 3D graphics primitives of the scene into 2D rasterized image data for each of the frames to be rendered. Therefore in the specific context of GPU rendering rendering may refer to the process of converting 3D graphics primitives that correspond to 3D objects in a graphics scene into 2D rasterized image data.

To render the 3D graphics primitives for a particular frame a graphics application executing on a host central processing unit CPU may place geometry data corresponding to the primitives to be rendered into a GPU accessible memory place one or more GPU state set up commands into the command stream and place one or more draw calls into the command stream that cause the GPU to render the primitives based on the geometry data. The GPU may process the commands contained in the command stream in the order in which the commands were placed in the command stream thereby rendering the scene.

With tile based rendering a query result is output on per tile basis by the GPU and later accumulated by the CPU. Query results may include for example the results from an occlusion query timestamp query pipeline status query pipeline stats etc. An occlusion query is a query in graphics processing that determines if an object to be rendered is occluded by other objects in a graphical scene or tile or not. Accordingly a query result from such a query is data providing an indication if an object to be rendered is occluded by other objects in a graphical scene or tile or not.

In some examples a timestamp is a sequence of characters or encoded information identifying when a certain event occurred. The timestamp may provide for example a date and time that an event occurred. The timestamp may be accurate to a small fraction of a second. A timestamp query may be used to check the timing of certain events in a graphical scene e.g. by comparing time stamps from a start to a stop of such a query. Accordingly a query result from such a query may be the difference of time stamps from a start to a stop of such a query.

A pipeline status query or pipeline stats query may be used to check various statistics and status information of a graphics pipeline. Accordingly a query result from such a query may be data related to various statistics and status information of a graphics pipeline.

The amount of memory needed to store this intermediate per tile results increases linearly with an increase in the number of tiles. In addition when a query result is requested the CPU or other processor may need to accumulate the result in n memory locations to come up with a final value where n is the number of tiles used to render the scene. An increase in the number of tiles also increases the amount of time taken by the CPU to do the accumulation. A more memory and time efficient way to perform such queries may be advantageous.

This disclosure relates to graphics processing systems and more particularly to query processing for tile based renderers. Tile based rendering is a processing technique whereby a frame or other region to be rendered is divided into tiles e.g. rectangular or square regions and each tile is rendered separately. Tile based rendering may be used to exploit local spatial coherence in the scene to facilitate the use of limited hardware rendering resources e.g. fast graphics memory later in the graphics pipeline or both. Generally in tiled based rendering a system apparatus or device such as a computer graphics device may divide a frame into for example a regular grid. The grid forms tiles which are portions of the frame or other region. Each tile may be rendered using the same rendering command stream as the other tiles.

In some examples binning or tile based rendering may provide a way to render a 3D scene in smaller parts called tiles or bins. As discussed above tile based rendering may be used to exploit local spatial coherence in the scene to facilitate the use of limited hardware rendering resources later in the graphics pipeline or both. Generally in tiled based rendering is system apparatus or device such as a computer graphics device may divide a frame into for example a regular grid. The grid forms tiles which are portions of the frame or other region. In an example each tile or bin may be rendered using the same rendering command stream.

For purposes of illustration occlusion queries will be discussed but it will be understood that these techniques of this disclosure may be applied to other types of queries as well. As discussed above in some examples an occlusion query is a query in graphics processing that determines if an object to be rendered is occluded by other objects in a graphical scene or tile or not. Several types of queries which are designed to query different types of information from for example the GPU are possible. Examples include occlusion queries timestamp queries pipeline status queries pipeline stats etc. In some examples a timestamp is a sequence of characters or encoded information identifying when a certain event occurred. The timestamp may provide for example a date and time that an event occurred. The timestamp may be accurate to a small fraction of a second. A timestamp query may be used to check the timing of certain events in a graphical scene e.g. by comparing time stamps from a start to a stop of such a query. A pipeline status query or pipeline stats query may be used to check various statistics and status information of a graphics pipeline. The techniques of this disclosure may also be applied to timestamp queries pipeline status queries pipeline stats and other types of queries.

As discussed above graphics processing systems may use occlusion queries to determine for example if an object to be rendered is occluded by other objects in a graphical scene or tile or not. In other words the graphics processing systems may use occlusion queries to determine if an object to be rendered is blocked by other objects in a graphical scene or tile such that it cannot be viewed or if the object to be rendered is not blocked by other objects in a graphical scene or tile such that it can be viewed. In some examples objects may be blocked partially blocked or visible. The graphics processor may use this information to make rendering more efficient. For example by not rendering objects that are occluded i.e. blocked such that they cannot be seen processing resources may be conserved making rendering of the tile more efficient. Objects that are not occluded may be rendered. In some examples objects that are partially occluded may be rendered. In other examples objects that are partially occluded may not be rendered. Partially occluded objects may be partially rendered or broken into smaller and smaller objects and re tested. It will be understood however that at some point it will generally be more advantageous in terms of use of processing resources to simply render the object or the visible portion of the object rather than spend more processing resources performing further occlusion queries. Rendering of occluded objects may depend for example on how much of the object is occluded.

Graphics processing may be performed by defining a set of primitives polygons e.g. triangles representing an output such as a frame to be displayed or rendered. Each primitive of the render output is usually defined and represented as a set of vertices with each vertex having associated with it a set of data values for the vertex.

Primitives for the output may then be rasterized to generate a plurality of discrete graphical entities that may be further processed to generate a rendered output. These discrete graphical entities may be pixels. The discrete graphical entities may not always correspond exactly to a single pixel in the render output however. This is due to for example down scaling.

Occlusion queries typically count the number of discrete graphical entities e.g. pixels samples etc. for a given object or objects that are visible and using the count to determine if the object or objects formed from the discrete graphical entities is visible if parts of the object or objects are visible or both. Various mechanisms allow for a determination of how many graphical entities such as pixels or samples were rasterized.

A typical occlusion query sequence may include 1 start occlusion query 2 draw one or more objects 3 end occlusion query and 4 obtain results of how many samples were rendered. The amount of memory needed to store an intermediate per tile results in a query such as an occlusion query may increase linearly with an increase in the number of tiles. An increase in the number of tiles also increases the amount of time taken by the CPU to do the accumulation e.g. when the final query result is requested. In one example a more memory efficient way to perform such queries may read a running counter at the start of a query to determine a start value wherein the running counter counts the samples rendered read the running counter at the end of the query to determine an end value and subtracting the start value from the end value to determine a result and perform this operation per bin tile re using the same start counter and end counter memory locations. Examples are discusses herein related to occlusion query processing for tile based renderers. It will be understood however that in other examples other types of queries such as timestamp query pipeline status query pipeline stats and other types of queries may be processed using these techniques.

In some examples e.g. when computing device comprises a personal computer a desktop computer a laptop computer a computer workstation a video game platform or console for example the computing device may perform query processing for a tile based renderer e.g. when processing video data for display on a video display.

If computing device is a wireless communication device or other similar device it may code one or more bit streams of data such as voice communications data video data text messages data files and other forms of data that may be transmitted or received as bit streams of data. A bit stream may be a time series or sequence of bits. Similarly a byte stream may be a series of bytes for example 8 bits each. As used herein a bit stream may include a byte stream. For example a byte stream may be regarded as a special case of a bit stream. A byte stream is a bit stream in which data bits are grouped into units called bytes. 

Computing device may perform query processing for a tile based renderer e.g. when receiving a bit stream of video data and processing such a bit stream for rendering on for example a video display.

As illustrated in the example of computing device includes a user interface a central processing unit CPU a memory controller a memory a graphics processing unit GPU a display interface a display and a bus . User interface CPU memory controller GPU and display interface may communicate with each other using bus . It should be noted that the specific configuration of buses and communication interfaces between the different components shown in is merely exemplary and other configurations of computing devices and or other graphics processing systems with the same or different components may be used to implement the techniques of this disclosure.

In some examples a processor in computing device such as CPU GPU or other processing circuitry may perform queries as part of graphics processing on computing device . For example a processor may read a running counter at the start of the query to determine a start value. The running counter may count discrete graphical entities such as pixels samples polygons etc. The processor may read the running counter at the end of the query to determine an end value. The processor may also subtract the start value from the end value to determine a result.

CPU may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause CPU to execute one or more software applications. The software applications that execute on CPU may include for example a graphics application a word processor application an email application a spread sheet application a media player application a video game application a graphical user interface application an operating system or any other type of program. The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad or another input device that is coupled to computing device via user interface .

The software applications that execute on CPU may include one or more graphics rendering instructions that instruct GPU to render graphics data to a frame buffer for display on display . In some examples the graphics rendering instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API a Direct3D API an X3D API a RenderMan API a WebGL API or any other public or proprietary standard graphics API. In order to process the graphics rendering instructions CPU may issue one or more graphics rendering commands to GPU to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

In some examples CPU may execute software causing it to read a running counter that may count discrete graphical entities at the start of the query to determine a start value. CPU may read the running counter at the end of the query to determine an end value and subtract the start value from the end value to determine a result. In some examples discrete graphical entities may be pixels. In some other examples discrete graphical entities may be polygons.

Memory controller facilitates the transfer of data going into and out of memory . For example memory controller may receive memory read and write commands and service such commands with respect to memory in order to provide memory services for the components in computing device . Memory controller is communicatively coupled to memory . Although memory controller is illustrated in the example computing device of as being a processing module that is separate from both CPU and memory in other examples some or all of the functionality of memory controller may be implemented on one or both of CPU and memory .

Memory may store program modules and or instructions that are accessible for execution by CPU and or data for use by the programs executing on CPU . For example memory may store program code and graphics data associated with the applications executing on CPU . Memory may additionally store information for use by and or generated by other components of computing device . For example memory may act as a device memory for GPU and may store data to be operated on by GPU as well as data resulting from operations performed by GPU . For example memory may store any combination of texture buffers depth buffers stencil buffers vertex buffers frame buffers render targets or the like. In addition memory may store command streams for processing by GPU . Memory may include one or more volatile or non volatile memories or storage devices such as for example random access memory RAM static RAM SRAM dynamic RAM DRAM read only memory ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data medium or an optical storage medium.

GPU may be configured to execute commands that are issued to GPU by CPU . The commands executed by GPU may include graphics commands draw call commands GPU state programming commands timestamp requests memory transfer commands general purpose computing commands kernel execution commands etc.

In some examples GPU may be configured to perform graphics operations to render one or more graphics primitives to display . In such examples when one of the software applications executing on CPU requires graphics processing CPU may provide graphics data to GPU for rendering to display and issue one or more graphics commands to GPU . The graphics commands may include e.g. draw call commands GPU state programming commands memory transfer commands blitting commands etc. The graphics data may include vertex buffers texture data surface data etc. In some examples CPU may provide the commands and graphics data to GPU by writing the commands and graphics data to memory which may be accessed by GPU .

In some examples GPU rather than CPU may execute software causing it to read a running counter that may count discrete graphical entities at the start of the query to determine a start value. GPU may read the running counter at the end of the query to determine an end value and subtract the start value from the end value to determine a result. In another example query result may be output per tile by GPU and later accumulated by CPU .

In further examples GPU may be configured to perform general purpose computing for applications executing on CPU . In such examples when one of the software applications executing on CPU decides to off load a computational task to GPU CPU may provide general purpose computing data to GPU and issue one or more general purpose computing commands to GPU . The general purpose computing commands may include e.g. kernel execution commands memory transfer commands etc. In some examples CPU may provide the commands and general purpose computing data to GPU by writing the commands and graphics data to memory which may be accessed by GPU .

GPU may in some instances be built with a highly parallel structure that provides more efficient processing of vector operations than CPU . For example GPU may include a plurality of processing elements that are configured to operate on multiple vertices control points pixels and or other data in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to render graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than rendering the images using CPU . In addition the highly parallel nature of GPU may allow GPU to process certain types of vector and matrix operations for general purpose computing applications more quickly than CPU .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . In further instances GPU may be located on the same microchip as CPU forming a system on a chip SoC . GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry.

In some examples GPU may include a GPU cache which may provide caching services for all or a portion of memory . In such examples GPU may use the cache to process data locally using a local storage instead of off chip memory. This allows GPU to operate in a more efficient manner by reducing the need for GPU to access memory via bus which may experience heavy bus traffic during each read and write command. In some examples however GPU may not include a separate cache but instead utilize memory via bus . The GPU cache may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM etc.

CPU GPU or both may store rasterized image data in a frame buffer that is allocated within memory . Display interface may retrieve the data from the frame buffer and configure display to display the image represented by the rasterized image data. In some examples display interface may include a digital to analog converter DAC that is configured to convert the digital values retrieved from the frame buffer into an analog signal consumable by display . In other examples display interface may pass the digital values directly to display for processing.

Display may include a monitor a television a projection device a liquid crystal display LCD a plasma display panel a light emitting diode LED array a cathode ray tube CRT display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit. Display may be integrated within computing device . For instance display may be a screen of a mobile telephone handset or a tablet computer. Alternatively display may be a stand alone device coupled to computer device via a wired or wireless communications link. For instance display may be a computer monitor or flat panel display connected to a personal computer via a cable or wireless link.

Bus may be implemented using any combination of bus structures and bus protocols including first second and third generation bus structures and protocols shared bus structures and protocols point to point bus structures and protocols unidirectional bus structures and protocols and bidirectional bus structures and protocols. Examples of different bus structures and protocols that may be used to implement bus include e.g. a HyperTransport bus an InfiniBand bus an Advanced Graphics Port bus a Peripheral Component Interconnect PCI bus a PCI Express bus an Advanced Microcontroller Bus Architecture AMBA Advanced High performance Bus AHB an AMBA Advanced Peripheral Bus APB and an AMBA Advanced eXentisible Interface AXI bus. Other types of bus structures and protocols may also be used.

The techniques described in this disclosure may in some examples be implemented in any of the components in computing device illustrated in including e.g. CPU GPU and system memory . In some examples the occlusion queries techniques of this disclosure may be implemented using GPU and memory . In some examples the techniques of this disclosure may be implemented entirely in GPU . In some examples the techniques described in this disclosure may be implemented using a combination of these components to read a running counter at the start of the query to determine a start value and at the end of the query to determine an end value. One or more of these components may be used to subtract the start value from the end value to determine a result.

CPU may include one or more processors e.g. microprocessors that are configured to execute any of a software application a graphics API a GPU driver and an operating system . In some examples CPU may be configured to execute instructions that cause the one or more processors of CPU to perform all or part of any of the techniques described in this disclosure.

GPU includes a command engine one or more processing units and a tile based rendering buffer . The one or more processing units may be configured to form a 3D graphics rendering pipeline. In some examples one or more of processing units may implement an on chip tessellation enabled graphics rendering pipeline. Command engine and processing units may include any combination of dedicated hardware units firmware software and processors that are configured to perform the functions attributed to such components. In some examples GPU may be configured to execute instructions that cause one or more processors of GPU to perform all or part of any of the techniques described in this disclosure.

Memory may store one or more commands primitive data and timestamp data . In some examples memory may also store instructions that when executed cause one or more processors to perform all or part of any of the techniques described in this disclosure.

In the illustrated example of counter is connected to bus and may thereby be accessed by for example CPU and GPU . In other examples counter may be part of memory or implemented in CPU or GPU . Generally the query counters for all query types are maintained by hardware. Accordingly it is generally necessary to instruct GPU to write the counter values to memory after which CPU can access it. In some examples no software query counters are used. In such examples the counter values for all query types may be maintained in the hardware and hardware commands may be used to cause those counter values to be written to memory. Other examples however may use different counter configurations such as software counters or a combination of hardware and software counters.

It will be understood that other processing resources not shown might be used to implement the techniques of this disclosure by reading counter at the start of the query to determine a start value and at the end of the query to determine an end value and subtracting the start value from the end value to determine a result.

In one specific example of how the techniques described herein might be implemented using the system of GPU may execute software causing it to read counter at the start of the query to determine a start value. This start value may be stored to memory . GPU may then read counter at the end of the query to determine an end value. This end value may be subtracted from the start value stored in memory to determine a result. The end value may be stored in a register within GPU or in memory after it is read. The start value may be read from memory and then subtracted from the end value stored in the register.

In some examples the query counter may be maintained by the GPU. Instructions executed by the GPU may write such counter values to memory where these counter values may then be accessed by CPU . In another specific example of how the techniques described herein might be implemented using the system of CPU may execute software causing it to read counter at the start of the query to determine a start value. This start value may be stored to memory . CPU may then read counter at the end of the query to determine an end value. This end value may be subtracted from the start value stored in memory to determine a result. The end value may be stored in a register within CPU or in memory after it is read however generally a register in CPU will be used. The start value may be read from memory and then subtracted from the end value stored in the register.

In the example illustrated in the processor e.g. CPU or GPU the memory and the counter are each separate logical blocks attached to bus . In other examples not shown one or more of the functions of the processor memory and counter may be performed using a single functional block. For example a processor might instruct a single functional block that may be attached to bus to read a counter at the start of the query to determine a start value store the start value to a memory within the single functional block read counter at the end of the query to determine an end value and subtract the start value from the end value to determine a result. The end value may then be the only thing returned to the processor. In other examples the processor may indicate the start and end of the query to the functional block and the functional lock may return the result.

The apparatus illustrated in may perform various queries in accordance with the systems and methods described herein. For example as is illustrated in more detail with respect to and the memory maps of the apparatus of may perform two queries query ABC and query BC one nested in another. In such a query initially three memory locations may be reset to zero for query ABC.

Software application may be a graphics application that uses GPU to render one or more 3D graphics scenes and or 3D graphics objects into an image to be displayed on a display. Software application may include instructions that cause GPU to rasterize and render a set of 3D graphics primitives. Software application may issue the instructions to GPU driver via graphics API . Graphics API may be a runtime service that translates the instructions received from software application into a format that is consumable by GPU driver .

GPU driver receives the instructions from software application via graphics API and controls the operation of GPU to service the instructions. For example GPU driver may formulate one or more commands place the commands into memory and instruct GPU to execute the commands . In some examples GPU driver may place the commands into memory and communicate with GPU via operating system e.g. via one or more system calls.

Operating system may provide a software platform upon which software application graphics API and GPU driver execute. Operating system may manage the hardware details of communicating and transferring data between CPU memory and GPU .

Commands may include one or more state commands one or more draw call commands and or one or more timestamp requests. A state command may instruct GPU to change one or more of the state variables in GPU such as e.g. the primitive type. A draw call command may instruct GPU to render the geometry defined by a group of one or more vertices e.g. defined in a vertex buffer stored in memory . The geometry defined by the group of one or more vertices may in some examples correspond to a plurality of primitives to be rendered e.g. primitive data . In general a draw call command may invoke GPU to render all of the vertices stored in a defined section e.g. buffer of memory . In other words once GPU receives the draw call command control is passed to GPU for rendering the geometry and primitives represented by the vertices in the defined section e.g. buffer of memory .

Processing units may include one or more processing units each of which may be a programmable processing unit or a fixed function processing unit. A programmable processing unit may include for example a programmable shader unit that is configured to execute one or more shader programs that are downloaded onto GPU from CPU . A shader program in some examples may be a compiled version of a program written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language etc.

A programmable shader unit may in some examples include a plurality of processing units that are configured to operate in parallel e.g. a single instruction multiple data SIMD pipeline. A programmable shader unit may have a program memory that stores shader program instructions and an execution state register e.g. a program counter register that indicates the current instruction in the program memory being executed or the next instruction to be fetched. The programmable shader units in processing units may include for example vertex shader units pixel shader units geometry shader units hull shader units domain shader units compute shader units and or unified shader units.

A fixed function processing unit may include hardware that is hard wired to perform certain functions. Although the fixed function hardware may be configurable via one or more control signals for example to perform different functions the fixed function hardware typically does not include a program memory that is capable of receiving user compiled programs. In some examples the fixed function processing units in processing units may include for example processing units that perform raster operations such as e.g. depth testing scissors testing alpha blending etc.

Tile based rendering buffer may be configured to store rasterized data for a sub region of a render target e.g. a tile or bin . Tile based rendering buffer may act as a temporary render target for particular sub regions of the actual render target during the performance of the rendering pass. Tile based rendering buffer may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM etc. In some examples tile based rendering buffer may be an on chip buffer. An on chip buffer may refer to a buffer that is formed on located on and or disposed on a microchip an integrated circuit and or a die that is the same as the microchip integrated circuit and or die upon which GPU is formed located and or disposed.

In some examples processing units may access tile based rendering buffer via a first communication interface and access the render target e.g. a frame buffer stored in memory via a second communication interface that is different than the first communication interface. In such examples the first communication interface may have in some examples a higher bandwidth than the second communication interface. The second communication interface may in some examples correspond to bus in and the connection between memory controller and memory in . When the tile based rendering buffer is an on chip tile based rendering buffer the first communication interface may be a communication interface that is internal to GPU .

As used herein bandwidth may refer to the rate at which a communication interface is capable of transferring data between two components e.g. a memory component and GPU . The units for bandwidth may in some examples be given as a number of bits per unit of time e.g. gigabits per second Gb s . When a bus having a bus width of multiple bits is used as part of the communication interface the bandwidth may in some examples be equal to the product of the width of the bus multiplied by the rate at which data is transferred along a single bit line. For example if a bus is 16 bits wide and each bit line of the bus is capable of transferring data at a rate of 2 Gb s the bandwidth of the bus may be equal to 32 Gb s. If multiple buses form a communication interface between two components then the bandwidth of the communication interface may be a function of the bandwidth of each of multiple buses e.g. the minimum bandwidth of each of the individual buses.

When tile based rendering buffer is implemented on the same chip as GPU GPU does not necessarily need to access tile based rendering buffer via the system and memory buses e.g. bus in and the connection between memory controller and memory in but rather may access tile based rendering buffer via an internal communication interface e.g. a bus implemented on the same chip as GPU . Because such an interface is on chip it may be capable of operating at a higher bandwidth than the system and memory busses. Although the above described technique is one way of achieving a communication interface for tile based rendering buffer that exceeds the bandwidth of the communication interface used to access memory other techniques are possible and within the scope of this disclosure.

The capacity of tile based rendering buffer may in some examples be limited by the memory available on certain types of computing devices e.g. mobile devices. Rendering buffer may be fast graphics memory. Moreover when tile based rendering buffer is implemented on the same chip as GPU the amount of area available to implement tile based rendering buffer on the same chip may be limited due to the other functionality that is implemented on the chip. In some examples tile based rendering buffer may have a bit density that is lower than the bit density of the render target further limiting the capacity of tile based rendering buffer . Because of these and or other factors the capacity of tile based rendering buffer may in some cases be less than the size of the render target. Consequently the capacity of tile based rendering buffer may in such examples be less than a minimum capacity needed to store pixel data for all of a plurality of destination pixels associated with a graphics image. The capacity of a memory component may refer a maximum amount of data e.g. a maximum number of bits capable of being stored in the memory component. The size of the render target may refer to the amount of data e.g. the number of bits stored in the memory range allocated to the render target. Bit density may refer to the number of bits that can be stored in a particular amount of area.

As discussed above when performing tile based rendering GPU may render each sub region of a render target during a separate iteration of the rendering pass. For example as part of a single rendering pass iteration for a particular sub region of a render target e.g. a particular subset of the destination pixels of the graphics image GPU may render all or a subset of the primitives with respect to the particular sub region of the render target. As discussed above rendering buffer may be fast graphics memory. The capacity of tile based rendering buffer may be configured to be greater than or equal to the size of the sub region of the render target. Accordingly the rendering target may be the size of the fast graphics memory or smaller . Therefore during a single rendering pass iteration all destination pixel data associated with a respective one of the sub regions of the render target may be available in tile based rendering buffer without necessarily needing to access a frame buffer in memory . Consequently during a single rendering pass iteration GPU may be able to read the destination pixel data from tile based rendering buffer via a relatively high bandwidth communication interface rather than having to read such data from memory via a relatively low bandwidth communication interface.

Although some graphics systems that do not perform tile based rendering may be capable of caching part of the frame buffer by using a hardware based on chip cache such caches do not guarantee that the destination pixel values for a given pixel will be available when needed. This is because multiple destination pixels may map to the same address in the hardware based cache. If tile based rendering is not used in this case then the current state of the hardware based cache may not necessarily include the destination pixel values associated with a currently processed primitive but rather include destination pixel values associated with previously processed primitives in other areas of the graphics image.

In contrast to a hardware based cache where multiple destination pixels map to the same cache location the destination pixels stored in tile based rendering buffer for a given rendering pass iteration may in some examples be uniquely addressable. In other words for a given rendering pass iteration a one to one mapping may be defined between the addressable storage slots in tile based rendering buffer and the destination pixels used for that rendering pass iteration. Consequently when performing tile based rendering all destination alpha values for a given tile based rendering pass may in some examples be available from tile based rendering buffer via a relatively low bandwidth communication interface. Moreover unlike the hardware based cache systems because of the uniquely addressable data in tile based rendering buffer cache misses do not occur thereby alleviating the need to resort to bandwidth expensive frame buffer accesses in the event of a cache miss.

A destination pixel may refer to pixel data stored in a render target e.g. either a frame buffer or a corresponding tile based rendering buffer for a particular pixel location. In contrast a source pixel may refer to pixel data that has been generated by a rasterization processing unit in processing units and has not yet been stored to and or merged with a render target. A destination pixel may include composited pixel data from multiple source pixels associated with different primitives.

To perform the tile based rendering software application may in some examples place primitive data into memory that geometrically defines a set of one or more 3D graphics primitives to be rendered and issue one or more draw call commands to GPU driver via graphics API . The draw call commands may cause the primitives defined by primitive data to be rasterized and rendered by GPU into a render target e.g. a frame buffer stored in memory .

In some examples prior to issuing the draw call commands software application may configure GPU to render a particular type of primitive. For example software application may issue a state command to GPU that specifies the particular type of primitive to render during a draw call. In additional examples prior to issuing the draw call commands software application may configure GPU to use one or more tessellation techniques to render a primitive. For example software application may cause one or more shader programs that implement the tessellation techniques to execute on one or more shader units of GPU e.g. a hull shader unit and or a domain shader unit during the draw call instruction.

Primitive data may include data indicative of one or more primitives to be rendered. In some cases primitive data may geometrically define the primitives to be rendered. Geometrically defining a primitive may refer to defining a primitive by a set of vertices or control points and corresponding vertex attributes. In some examples primitive data may take the form of a plurality of vertices a vertex list and or vertex buffer. In further examples primitive data may take the form a vertex buffer in combination with an index buffer. In such examples the vertex buffer may define the vertices and the index buffer may specify which vertices are used to define each of the primitives.

Each of vertices included in primitive data may include one or more attributes such as e.g. positional coordinates normal coordinates texture coordinates etc. The vertices may conceptually correspond to the vertices of a geometric primitive e.g. a point line triangle etc. and or to the control points of a higher order primitive e.g. a higher order surface such as a B zier surface . In some case each of the vertices may be grouped into groups of one or more vertices and each of these groups of vertices may correspond to a single primitive.

The shape of the geometrically defined primitive may be defined in some examples by additional data that is not necessarily included in primitive data . The additional data may include one or more of a specified primitive type from a set of one or more predetermined primitive types one or more mathematical functions and or one or more tessellation techniques.

In some examples the specified primitive type may be stored as a rendering state variable in GPU and may be configurable by software application . The specified primitive type may in some cases define the shape of the resulting rendered primitives e.g. points lines triangles etc. and or the connectivity of the vertices included in primitive data e.g. triangle strip triangle fan etc. . In some examples the different primitive types may correspond to a set of primitive topologies that the graphics pipeline implemented by processing units is capable of processing. In further examples the different primitive types may correspond to the set of primitive topologies that are defined by graphics API and are available for use by software application .

The one or more mathematical functions and or the one or more tessellation techniques may be specified in one or more shader programs that are configured to execute on one or more shader units of GPU e.g. a hull shader unit and or domain shader unit . The mathematical functions may be used to define primitives that have curved lines and or curve surfaces. The one or more tessellation techniques may be used to define a primitive by a plurality of tessellated primitives that approximate the shape and or curvature of an input primitive.

In response to receiving a draw call command from software application GPU driver may cause GPU to perform tile based rendering based on the plurality of primitives to be rendered e.g. primitive data . For example GPU driver may cause GPU to perform a binning pass and rendering pass that includes a plurality of rendering pass iterations. During the binning pass GPU may determine to which of a plurality of sub regions e.g. bins or tiles of a render target each of the primitives contributes image data e.g. pixel data and generate binning data e.g. data from the bins or tiles that indicates to which of the plurality of sub regions of a render target each of the primitives contributes image data e.g. pixel data . Once the binning data has been generated GPU may perform the rendering pass that includes the plurality of rendering pass iterations based on the binning data and the primitive data to generate a composite rasterized version of the primitives.

In some examples in order to perform the binning pass the rasterizer in GPU may be configured to perform low resolution z buffering and or back face culling on the primitives to be rasterized. In such examples the binning data may be generated based on primitives that are visible after z buffering and or back face culling.

In some cases the rendered primitives may be stored as a plurality of pixels. Each of the pixels may be associated with one or more spatial locations of the render target and may include one or more attributes indicative of the color of the respective pixel. In some cases each of the pixels may further include one or more attributes indicative of the transparency of the pixel. In some examples the pixel data may include Red Green Blue and Alpha RGBA attributes for each pixel where the RGB components correspond to color values and the A component corresponds to an alpha value.

The techniques described in this disclosure may be implemented in any of the components shown in including e.g. software application graphics API GPU driver command engine and processing units . For example GPU driver command engine and or processing units may be configured to.

In other examples GPU rather than CPU may execute software causing it to read a running counter that may count discrete graphical entities at the start of the query to determine a start value. GPU may read the running counter at the end of the query to determine an end value and subtract the start value from the end value to determine a result.

In some examples the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a second memory location e.g. in memory . The result may be stored in a third memory location e.g. in memory .

In another example the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a second memory location e.g. in memory . The result may overwrite one of the first or second memory location.

Some examples may further include nesting a second query. Nesting may be done by reading the running counter at the start of the second query to determine a second start value reading the running counter at the end of the second query to determine a second end value and subtracting the second start value from the second end value to determine a result.

In the tile based rendering example of rendering commands for drawing polygons e.g. triangles Tri A Tri B and Tri C may be executed four times e.g. once for every tile. In an example that uses a hardware counter such as an occlusion query counter hardware commands to reset start and stop occlusion query counters may be executed for each tile only if no nesting is used. In some examples if a software counter is used software commands may perform these operations. In some examples in accordance with the techniques of this disclosure nested occlusion queries may be allowed so for example hardware reset of the counter in every tile may not be allowed because this may impact a nested query or queries by resetting the counter in the middle of counting the one or more other queries. For example assume a first query is started and that the counter used for the query is reset at the start of the query. Further assume that a second query is started before the end of the first query. The second query is said to be a nested query because it is started while the first query is still being performed. If a single counter is used for both queries and counter is reset at the start of the second query then the value read from the counter at the end of the first query will likely be incorrect. For example the value read may typically be too small.

In some examples systems methods and devices implementing these techniques may need to store a start and end counter value for each tile. These values may be stored in memory registers or some other storage. For example the start value may be stored in memory a register or some other memory or storage location. The end value may also be stored in memory a register or some other memory or storage location. In another example the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a second memory location e.g. in memory . The result may be stored in a third memory location e.g. in memory . In another example the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a second memory location e.g. in memory . The result may overwrite one of the first or second memory locations. In yet another example the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a register. The result may be stored in the first memory location.

Tile based rendering may in some examples involve subdividing a render target into a plurality of sub regions e.g. bins or tiles and performing a rendering pass that includes a separate rendering pass iteration for each of the sub regions of the render target. To reduce the number of primitives that need to be processed during the rendering pass a binning pass may in some examples be performed prior to the rendering pass. The binning pass may be used to generate binning data that indicates to which of a plurality of sub regions of a render target each of the primitives to be rendered contributes pixel data. The binning data may be used during the rendering pass iterations to selectively render primitives that contribute to sub regions that are active during particular rendering pass iterations thereby reducing the number of primitives that need to be processed during the rendering pass.

Rendering may refer to the process of converting 3D graphics primitives that correspond to 3D objects in a graphics scene into 2D rasterized image data. Rendering typically takes place with respect to a render target e.g. a frame buffer which is usually updated as each of the graphics primitives in the scene is rendered. Therefore not only does the render target store the final 2D rasterized image data for a graphics scene but the render target may also store intermediate data as the graphics scene is rendered. The 2D rasterized image data stored in the render target may include a plurality of pixels where each of the pixels includes color data transparency data and or depth data. As each new primitive is rendered into the render target the 2D rasterized image data of the new primitive is merged with the existing intermediate data that is already stored in the render target for the previously rendered primitives.

To merge the data in the render target the intermediate data typically needs to be read from the render target prior to writing the new data to the render target. Therefore rendering may involve the performance of numerous read and write operations with respect to a memory that contains the render target thereby resulting in high memory bandwidth usage. Because of the high memory bandwidth usage it is desirable to use a dedicated high bandwidth on chip memory for the render target. However in area limited applications such as e.g. mobile applications there may not be enough available area to implement a high bandwidth on chip memory that is able to simultaneously hold all of the data for each of the pixels in the render target.

Tile based rendering may address the above mentioned issues by subdividing a render target into a plurality of sub regions e.g. tiles or bins and performing a rendering pass that includes a separate rendering pass iteration for each of the sub regions. Each of the sub regions may correspond to a subset of the pixels in the render target e.g. a 16 16 tile of pixels . During each of the rendering pass iterations all of the image data associated with the corresponding sub region may be rendered which may include rendering each of the primitives that contributes pixel data to the sub region. A high bandwidth on chip memory that is large enough to store the data for a single sub region of the render target may be used as a local render target for each of the rendering pass iterations and after a rendering pass iteration has completed the contents of the local render target for the rendering pass iteration may be transferred to the general render target stored in a low bandwidth off chip system memory. By performing separate rendering pass iterations on a per tile basis tile based rendering schemes may be able to allow a high bandwidth on chip memory to be used for merging rasterized image data even in area limited applications that do not allow for large on chip memories.

One approach for performing tile based rendering is to perform a rendering pass iteration for each of the sub regions of the render target and during each of the rendering pass iterations render all of the primitives in the scene while using different scissors settings to limit the output to a particular sub region that is currently being rendered. Such an approach however may be inefficient because each of the primitives is rendered in each of the rendering pass iterations regardless of whether or not the primitive is actually visible in the rendered sub region.

In order to improve the efficiency of tile based rendering a binning pass may in some examples be performed prior to the performance of the rendering pass. The binning pass may be used to determine binning data for the primitives. For each of the primitives to be rendered the binning data may indicate with respect to which of the sub regions of the render target each of the primitives contribute pixel data.

At the start of a query the three memory locations for query ABC and the three memory locations for query BC may be reset to zero. A query counter start value for query ABC value SABC may be written to a query counter start value portion of query ABC memory. In some examples this may be by hardware commands.

Query BC may be a nested query in one example. A query counter start value for query BC value SBC may be written to query counter start value of query BC memory. A query end value for query ABC value EABC may be written to query counter end value of query ABC memory. An accumulation may be performed and the result may be written to the accumulate final result memory location of Query ABC memory. Similarly hardware commands may writes a query counter end value for query BC value EBC to the query counter end value memory location of query BC memory. An accumulate may be performed and the result may be written to the accumulate final results memory location of QueryBC memory.

As described above the systems and methods described herein may perform various queries such as occlusion query timestamp query pipeline status query pipeline stats etc. For example these systems and methods may perform two queries query ABC and query BC one nested in another. It will be understood that three or more nested queries are also possible.

In the example of two queries with one nested in another may be performed. In the example three memory locations may be reset to zero for query ABC. For example as illustrated in the memory locations in QueryABC Result Memory for Occlusion Query Counter Start Value Occlusion Query Counter End Value and Accumulated Final Result may be reset to zero for query ABC. Three memory locations may also be reset to zero for query BC. For example as illustrated in the memory locations in QueryBC Result Memory for Occlusion Query Counter Start Value Occlusion Query Counter End Value and Accumulated Final Result may be reset to zero for query BC. When a query for triangles ABC begins a counter start value for query ABC value SABC may be written to a query counter start value portion of query ABC. This may be by writing to memory using hardware commands. For example as illustrated in a start value may be written to QueryABC Result Memory locations Occlusion Query Counter Start Value.

Query BC may be a nested query in one example. A query counter start value for query BC value SBC may be written to query counter start value of query BC memory i.e. Query Counter Start Value of QueryBC Result Memory. In one example QueryABC may end before Query BC. Accordingly a query end value for query ABC value EABC may be written to Occlusion Query Counter End Value of QueryABC Result Memory. An accumulation may be performed e.g. by a processor such as CPU or GPU and the result may be written to the Accumulate Final Result memory location of QueryABC memory. Similarly when query BC is complete hardware commands may writes a query counter end value for query BC value EBC to the Query Counter End Value memory location of QueryBC Result Memory. An accumulate may be performed e.g. by a processor such as CPU or GPU and the result may be written to the Accumulate Final Results memory location of QueryBC Result Memory.

Query BC is a nested query in the illustrated example of . Hardware commands write a query counter start value for query BC value SBC to query counter start value of query BC memory at . Hardware commands write a query end value for query ABC value EABC to query counter end value of query ABC memory at . An accumulation may be performed using e.g. hardware commands and written to the accumulate final result memory location of Query ABC memory at . Similarly hardware commands writes a query counter end value for query BC value EBC to the query counter end value memory location of query BC memory at . An accumulate may be performed and written to the accumulate final results memory location of QueryBC memory at .

As described above other examples might use only one or two memory locations for each query. For example in a two memory location implementation initially two memory locations are reset to zero rather than three for query ABC and two memory locations are also reset to zero for query BC. A query counter start value for query ABC value SABC is written to a query counter start value portion of query ABC memory. This may be by hardware command.

For query BC hardware commands or software in some examples write a query counter start value for query BC value SBC to query counter start value of query BC memory and a query end value for query ABC value EABC to query counter end value of query ABC memory. An accumulation may be performed and written to one or both of the start or stop memory locations for query ABC. Similarly hardware commands write a query counter end value for query BC value EBC to query counter end value of query BC memory. An accumulate may be performed and written to one or both of the start or stop memory locations for query BC. Another example may use two memory locations by saving a start counter value to memory. In such an example an end counter value is not stored in memory but directly subtracted from the start counter value memory location. The accumulated result result of the subtraction may then be stored to memory.

Similarly in some examples a single memory location or a single dedicated memory location might be used for each query. For example a temporary memory or register might be used to store counter end values and results may be written to the same memory location as the corresponding counter start value. In other examples a read of a counter and a difference operation from a value in memory may allow for the use of a single memory location. This may be done by storing a counter start value and then later reading an stop counter value performing a difference operation of the start and stop counter values and over writing the start counter value with the result in a single operation. It will be understood that other configurations are also possible using various dedicated memory locations for a query in combination with temporary memory locations to for example calculate various results.

In some examples a temporary register may hold a counter start value and the end counter value might not be stored to memory either. The start counter register value may be directly subtracted from the end counter value and then only the final accumulated result is stored in a memory location.

In one example some systems methods and devices may include a start memory location but not store an end counter value to memory. The end value may be directly subtracted. For example the start counter value stored in the start memory location may be subtracted from the end counter value and saved to a second memory location. Thus such an example may use two memory locations.

Another example may use one memory location. Such an example may not store the start counter value. Rather a register may be used instead. The end counter value might also not be stored but rather the start value in the register may be subtracted from the end value without saving the end value to memory. The accumulated result may then be stored to memory.

In one example of the disclosure a system method or apparatus may perform a query and obtain an accumulation result using only three memory locations per query irrespective of the number of tiles that comprises the 3D scene. Furthermore accumulation of the per tile result may be done by GPU as it processes each tile. After the last tile is processed by GPU the final accumulated result may already be available.

In another example a system method or apparatus may obtain a query result using only two or fewer memory locations per query irrespective of the number of tiles that comprises the 3D scene. Similarly to the above example accumulation of the per tile result may be done by GPU as it processes each tile. Again after the last tile is processed by GPU the final accumulated result may already be available.

In some examples rendering commands for drawing Tri A Tri B and Tri C of will be executed four times once for every tile. Hardware commands to reset start and stop the occlusion query counters and commands to write out the counter values may be executed for each tile.

In some examples nested occlusion queries may be allowed. Because of this it may not be possible to reset the counter e.g. hardware or software counter in every tile. An example may need to store a start and end counter value per tile.

In an example query processing may be more memory efficient. Some examples may maintain just three two or even one memory locations per query depending on the mathematical processing capabilities of for example a processor implementing the techniques of this disclosure.

For example some systems methods or apparatus may perform occlusion queries in a graphics processing system. This may include reading a running counter at the start of the occlusion query to determine a start value. This start value may be stored in a first memory location. In an example the running counter counts discrete graphical entities. The example systems methods or apparatuses of this disclosure may read the running counter at the end of the occlusion query to determine an end value. This end value may be stored in a second memory location. Additionally these systems methods or apparatus may subtracting the start value from the end value to determine a result. This value may be stored in a third memory location. In another example the start value may be stored in a first memory location. Additionally the end value may be stored in a second memory location and the value determined from the subtraction of the start value from the end value i.e. the result may be stored in one or more of the first and second memory locations thus only requiring two memory locations. In yet another example if a count value may be read and processed in one step the start value may be stored in a first memory location. The end count value may be read and the two values processed in a single step with the result possibly being stored in the first memory location thus only requiring one memory location.

In some examples result accumulation may be performed by GPU instead of CPU as each tile is processed. After all tiles are rendered the final query result is available in e.g. the Accumulated Final Result memory location.

An example method of performing occlusion queries in a graphics processing system may include reading a running counter at the start of the occlusion query to determine a start value. The running counter may count discrete graphical entities. The method may include reading the running counter at the end of the occlusion query to determine an end value and subtracting the start value from the end value to determine a result. The discrete graphical entities may be pixels or polygons.

In an example the start value is stored in a first memory location the end value is stored in a second memory location and the result is stored in a third memory location. In another example the start value is stored in a first memory location the end value is stored in a second memory location and the result is overwrites one of the first or second memory location.

In an example nesting a second occlusion query may be performed by 1 reading the running counter at the start of the second occlusion query to determine a second start value 2 reading the running counter at the end of the second occlusion query to determine a second end value and 3 subtracting the second start value from the second end value to determine a result.

One or more of these example methods may be combined. Additionally various devices systems and apparatus may implement these methods.

As discussed above in various examples the processor e.g. GPU or CPU may use memory to store values read from counter such as the start value. For example the start value may be stored in memory a register or some other memory or storage location. In one example when a query begins a counter start value for the query may be read. This value may then be written to a query counter start value portion of a query memory. For example as illustrated in a start value may be written to QueryABC Result Memory locations Occlusion Query Counter Start Value.

The software may also cause the processor to read counter at the end of the query to determine an end value . Additionally the end value may also be stored in memory a register or some other memory or storage location. For example query end value for query ABC value EABC may be written to Occlusion Query Counter End Value of QueryABC Result Memory of . An accumulation may be performed e.g. by a processor such as CPU or GPU and the result may be written to the Accumulate Final Result memory location of QueryABC memory. Similarly when query BC is complete hardware commands may writes a query counter end value for query BC value EBC to the Query Counter End Value memory location of QueryBC Result Memory. An accumulate may be performed e.g. by a processor such as CPU or GPU and the result may be written to the Accumulate Final Results memory location of QueryBC Result Memory.

Counter may have increased between the start value and the end value by the number of discrete graphical entities that have been processed since the start of the query. The difference between these two values indicates the number of counts that have occurred during the query. Accordingly the software may also cause the processor to subtract the start value from the end value to determine a result . For example the start value may be read from memory and then subtracted from the end value which might be stored in a register. The end value may be stored in memory a register or some other memory or storage location.

In some examples the start value may be stored in a first memory location e.g. in memory . The result may be stored in a third memory location e.g. in memory . In another example the start value may be stored in a first memory location e.g. in memory . The end value may be stored in a second memory location e.g. in memory . The result may overwrite one of the first or second memory locations.

Some examples may further include nesting a second query. Nesting may be done by reading the running counter at the start of the second query to determine a second start value reading the running counter at the end of the second query to determine a second end value and subtracting the second start value from the second end value to determine a result.

The techniques described in this disclosure may be implemented at least in part in hardware software firmware or any combination thereof. For example various aspects of the described techniques may be implemented within one or more processors including one or more microprocessors digital signal processors DSPs application specific integrated circuits ASICs field programmable gate arrays FPGAs or any other equivalent integrated or discrete logic circuitry as well as any combinations of such components. The term processor or processing circuitry may generally refer to any of the foregoing logic circuitry alone or in combination with other logic circuitry or any other equivalent circuitry such as discrete hardware that performs processing.

Such hardware software and firmware may be implemented within the same device or within separate devices to support the various operations and functions described in this disclosure. In addition any of the described units modules or components may be implemented together or separately as discrete but interoperable logic devices. Depiction of different features as modules or units is intended to highlight different functional aspects and does not necessarily imply that such modules or units must be realized by separate hardware or software components. Rather functionality associated with one or more modules or units may be performed by separate hardware firmware and or software components or integrated within common or separate hardware or software components.

The techniques described in this disclosure may also be stored embodied or encoded in a computer readable medium such as a computer readable storage medium that stores instructions. Instructions embedded or encoded in a computer readable medium may cause one or more processors to perform the techniques described herein e.g. when the instructions are executed by the one or more processors. Computer readable storage media may include random access memory RAM read only memory ROM programmable read only memory PROM erasable programmable read only memory EPROM electronically erasable programmable read only memory EEPROM flash memory a hard disk a CD ROM a floppy disk a cassette magnetic media optical media or other computer readable storage media that is tangible.

Computer readable media may include computer readable storage media which corresponds to a tangible storage medium such as those listed above. Computer readable media may also comprise communication media including any medium that facilitates transfer of a computer program from one place to another e.g. according to a communication protocol. In this manner the phrase computer readable media generally may correspond to 1 tangible computer readable storage media which is non transitory and 2 a non tangible computer readable communication medium such as a transitory signal or carrier wave.

Various aspects and examples have been described. However modifications can be made to the structure or techniques of this disclosure without departing from the scope of the following claims.

