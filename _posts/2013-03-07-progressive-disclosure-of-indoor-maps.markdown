---

title: Progressive disclosure of indoor maps
abstract: A digital map of a geographic area is displayed via a user interface, and a 3D representation of a building located in the geographic area is displayed on the digital map. A virtual camera is used to view the digital map, and the location of the virtual camera is changeable in response to user input. The external shell of the 3D representation is made increasingly transparent as a virtual camera approaches the 3D representation of the building to reveal indoor information for the building.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08928657&OS=08928657&RS=08928657
owner: Google Inc.
number: 08928657
owner_city: Mountain View
owner_country: US
publication_date: 20130307
---
The present disclosure relates to interactive digital maps and more particularly to providing an interface for interacting with representations of buildings displayed as part of digital maps on a computing device.

The background description provided herein is for the purpose of generally presenting the context of the disclosure. Work of the presently named inventor to the extent it is described in this background section as well as aspects of the description that may not otherwise qualify as prior art at the time of filing are neither expressly nor impliedly admitted as prior art against the present disclosure.

Today a wide variety of computing devices including many portable devices support software applications that display interactive digital maps mapping applications . For example mapping applications may run on laptop and tablet computers mobile phones car navigation systems hand held global positioning system GPS units etc. Many of these devices are equipped with a touchscreen a touchpad or are otherwise configured to receive input that includes finger gestures. A user may for example pan across a map by swiping her finger in the desired direction zoom in on an area by pinching two fingers together zoom out on an area by spreading two fingers apart etc.

In general a mapping application can display various types of geographic data including topographical data street data urban transit information and traffic data. Further the geographic data may be schematic or based on photography such as satellite imagery. Still further a mapping application can display the information in a two dimensional 2D or three dimensional 3D format.

A user sometimes may operate a mapping application to view a map of an urban area with street names names of landmarks etc. The map may include representations of buildings rendered as a 2.5D representation of the building in which an approximation of the building is rendered by extruding the shape of the building from the surface or 3D representation of the building with or without textures. If map information about the interior of the building is available it may be advantageous for such maps to include information about interior floors of representations of buildings included on the map.

One embodiment of the techniques discussed below is a method providing an intuitive display of a building on a digital map. The digital map is implemented in a computing device having a user interface. The method includes displaying a digital map of a geographic area via a user interface of the computing device from a perspective of a virtual camera changing a position of the virtual camera in response to user input and displaying on the digital map a three dimensional 3D representation of a building located in the geographic area including progressively increasing transparency of an external shell of the 3D representation of the building to reveal indoor information for the building as the virtual camera approaches the 3D representation of the building.

Another embodiment of the techniques described in the present disclosure is a method in a computing device for providing a digital map via a user interface. The method includes displaying a digital map of a geographic area via a user interface of the computing device from a perspective of a virtual camera and displaying on the digital map a three dimensional 3D representation of a building located in the geographic area including not displaying an indoor map when a distance between the virtual camera and the 3D representation of the building is greater than a threshold value and displaying i an indoor map of an internal floor of the building and ii at least a portion of an outer shell of the building disposed between the internal floor of the building and the virtual camera when the distance between the virtual camera and the 3D representation of the building is smaller than a threshold value.

In yet another embodiment a computing device includes a user interface one or more processors and a memory. The memory stores instructions that when executed by the one or more processors cause the computing device to display a digital map of a geographic area via the user interface from a perspective of a virtual camera display on the digital map a three dimensional 3D representation of a building located in the geographic area wherein the 3D representation of the building includes an opaque outer shell that obscures internal features of the building receive a selection of the 3D representation of the building via the user interface and in response to the selection of the 3D representation of the building display the outer shell in an at least partially transparent manner to reveal the internal features of the building.

A mapping software module operating on a computing device displays an interactive digital map of a geographic region in which one or more buildings are located. The mapping software module provides an intuitive space efficient and aesthetically pleasing user interface for inspecting the internal features of the multi story building such as interior floor maps that include floor contours as well as internal wall layout and names of individuals or organizations occupying different floors of the building.

In one example implementation the mapping software module displays a 2D schematic digital map that includes 2.5D and or 3D outlines of buildings which may be displayed to scale with the map. In general the user changes the distance between the virtual camera and the representation of the building via the user interface e.g. by a command to change location of the virtual camera on the x y and or z axes . For example a user inputs a command e.g. a spread gesture to a user interface to cause the mapping software to zoom in on a section of the map i.e. decreasing the height of the camera relative to the map . Zooming may include displaying a section of the map at a higher resolution. Additionally the 3D representations of one or more buildings may increase in size. The mapping software may also alter the 3D representations of one or more buildings by increasing the transparency of the one or more buildings. Further the mapping software may display an interior floor map of the one or more buildings inside the space defined by the 3D representations of the one or more buildings. In effect using the zoom command the user is able to virtually look into a building from the outside to see the layout of the interior of the building. If the building has more than one interior floor the mapping software module may display a default interior floor map. The default floor may depend on the type of building e.g. the ground floor of an office skyscraper the departure and ticketing floor of an airport etc. .

These techniques are discussed in more detail below with reference to . In particular an example system in which a mapping software module may interactively present internal features of buildings is described with reference to example screenshots of the mapping software module are discussed with reference to and example methods which the mapping software module may implement to provide a user interface for inspecting internal features of buildings are discussed with reference to .

Referring first to a system includes a computing device coupled to a map server via a communication network . The computing device can be for example a laptop computer a tablet computer a smartphone etc. In the embodiment illustrated in the computing device includes a central processing unit CPU a graphics processing unit GPU a computer readable memory and a user interface including a touch interface . In various implementations the touch interface can include a touchpad over which the user moves his or her fingers while looking at a separately provided screen a touchscreen where the user places his or her fingers directly over the image being manipulated or over a displayed control being activated e.g. a displayed keyboard etc. The memory is a computer readable non transitory storage device that may include both persistent e.g. a hard disk and non persistent e.g. RAM memory components stores instructions executable on the CPU and or the GPU that make up a mapping software module and map data on which the mapping module operates. The mapping software module includes an internal building feature inspection module that allows users to easily inspect internal features of multi story buildings.

The mapping software module according to various implementations operates as a separately executable software application a plugin that extends the functionality of another software application such as a web browser an application programming interface API invokable by a software application etc. The instructions that make up the mapping software module may be compiled and executable on the CPU and or the GPU directly or not compiled and interpreted by the CPU at runtime. Further the internal building feature inspection module may be provided as an integral part of the mapping software module or as a separately installable and downloadable component.

Depending on the implementation the map data may be in a raster format such as Portable Network Graphics PNG a vector graphics format based on mathematical descriptions of geometric shapes or any other suitable format. The map data in some cases is divided into map tiles or portions of a map image having a certain fixed size such as 256 by 256 pixels. In operation the mapping module receives the map data from the map server renders a map image based on the map data and causes the map image to be displayed via the user interface . When the map data is already rasterized the mapping module renders the map image by selecting and combining the proper rasterized tiles. However if the map data is in a vector graphics format the mapping module interprets the descriptions of various shapes to generate the corresponding raster images. The mapping module also adjusts the displayed image and requests new map data when necessary in response to user input received via the user interface . More specifically the user may change the zoom level pan across the map select a different map type e.g. traffic map terrain map and otherwise interact with the map.

In an example scenario the map server receives a request that specifies the geographic area the zoom level and the map type. The map server in response retrieves outdoor map data and indoor map data from an outdoor map database and an indoor map database respectively. The map server then provides the outdoor map data the indoor map data and appropriate indications of how certain portions of the outdoor map data and the indoor map data are linked to the computing device as part of the map data .

When provided in a vector graphics format outdoor map data may specify individual map elements representing such physical entities as roads parks bodies of water external walls of buildings and other natural and artificial objects visible outside e.g. from above or at a street level . In a raster format map elements typically are embedded into the same image. Outdoor map also may include text based data for displaying various labels such as street names or names of landmarks. In general outdoor map data may be for generating 2D images or 3D images and may include schematic data photographic images or both.

Indoor map data may specify internal features of buildings such as the layout of internal walls or dividers names of people businesses and organizations occupying different portions of a building locations of elevators escalators restrooms etc. For multi story buildings the indoor map data may specify internal features on a per floor basis. Similar to outdoor map data indoor map data may include both graphics content and non graphics e.g. text content and the graphics content may include schematic illustrations photographic images interactive and non interactive icons etc.

Certain portions of the outdoor map data may be logically linked to respective portions of indoor map data. In particular certain map elements displayed on a map may be linked to indoor data that typically is not displayed on the map without an additional user request. In other words certain map elements may be associated with additional map data that is not part of the map image typically displayed for the specified geographic region map type and zoom level. The map server can provide outdoor map data and or indoor map data as a collection of separate data structures each containing a vector based description of a map element text based label data and metadata that further contains a unique identifier of another data structure storing the corresponding indoor map data. If the outdoor map data included in the map data is rasterized the unique identifier of a data structure storing indoor map data can be provided for a particular set of coordinates in the raster image. In either case the mapping software module can display the outdoor map data and provide interactive controls for activating the display of relevant indoor map data.

As a more specific example according to one implementation the map server provides as part of outdoor map data external representations of buildings in the form of low detail 3D outlines. The mapping software module superimposes these 3D outlines over a 2D map. In another implementation the map server provides 3D mesh descriptions of buildings along with photographic imagery for texturing the corresponding 3D meshes. Using this type of map data the mapping software module can generate realistic highly detailed external representations of buildings. In yet another implementation the map server provides merely 2D outlines or footprints of buildings on a 2D map. A user can zoom in on these 3D external representations of buildings to instruct the mapping software module to increase the transparency of the 3D external representations of buildings and to display interior map data within the partially or wholly transparent 3D external representations of buildings. It may be advantageous to create 3D representations of buildings with detailed information about the shape and contours of the building being represented e.g. creating a representation of the Chrysler Building including a detailed modeling the distinctive Art Deco top but it may also be advantageous to create 3D representations of buildings using 2.5D rendering techniques. In 2.5D rendering the shape of the base of the building is extruded from the base of the map to the appropriate altitude above the surface of the map to approximate the shape of the building.

With continued reference to the map server may include a processor and a memory that stores a request handler made up of instructions executable on the processor . The computing device and the map server may communicate in a client server mode where the computing device sends requests for map data to the map server and the map server provides map data in response to these requests. More particularly the request handler in operation receives requests for map data from the computing device identifies and retrieves the requisite map data from the outdoor map database and or the indoor map database formats response messages that contain the map data and causes the response messages to be transmitted to the computing device via the network which may be a wide area network WAN such as the Internet a local area network LAN or any other suitable type of a network.

For simplicity illustrates the map server as only one instance of a server device. However the map server according to some implementations includes in a group of one or more map server devices each equipped with one or more processors and capable of operating independently of the other map server devices. Map server devices operating in such a group can process requests from the computing device individually e.g. based on availability in a distributed manner where one operation associated with processing a request is performed on one map server device while another operation associated with processing the same request is performed on another map server device or according to any other suitable technique. For the purposes of this discussion the term map server may refer to an individual map server device or to a group of two or more map server devices.

Now referring to an example screenshot illustrates a number of 3D representations of buildings overlaying a digital map of a geographic area . In this example the map illustrates several city blocks and includes various outdoor map elements such as railroad tracks roads and representations of buildings and . The map also can include icons and text labels corresponding to outdoor map data such as a mass transit icon for example. A mapping software e.g. the internal building feature inspection module operating in the mapping software module of or a similar module may provide functions for interacting with outdoor map data such as rotate zoom pan etc. as well as functions for inspecting internal features of buildings when indoor map data is available. In the example of the 3D representations of buildings or are 3D shapes displayed according to an isometric projection. In another implementation however these outlines can be illustrated with a two point perspective. More generally and as discussed above buildings and other structures for which indoor map data is available generally can be illustrated using any suitable 2D or 3D shapes rendered with any desired level of detail. The screenshot includes a zoom in button as well as a zoom out button . The hand appearing in is not part of the screenshot but merely indicates that in certain embodiments the user interface presenting the display may accept multi touch inputs such as pinching typically interpreted as a zoom out command or spreading typically interpreted as a zoom in command. The user interface presenting the display may also accept tapping commands to identify a single building to make transparent according to the techniques discussed below. For example the user may tap on or otherwise select the representation of the building or an icon associated with the building to render the building partially transparent and display an interior map as discussed in connection to . Alternatively or additionally all of the buildings in the frustum with interior map information may be made more transparent as a result of a zoom in command or less transparent as a result of a zoom out command as discussed below.

Now referring to another example screenshot illustrates the map of a geographic area of in which the representation of the building is represented as a partially transparent 3D representation of the building after the user has selected the representation of the building to make the representation partially transparent. A representation of the building may be made partially transparent by making any part of the external shell of the building partially transparent. For example the roof and or vertical walls of the representation of the building may be made partially transparent. Indoor and outdoor map data are displayed within a same viewport in this example. An interior floor map may be drawn inside the 3D space defined by the partially transparent 3D representation of the building . As discussed in the present disclosure the interior floor map may be an interior floor map of the default floor. In this instance the default floor is the ground floor of the Mori Tower in Tokyo Japan. Although the map is a 2D map on which most map elements are illustrated with a one point projection the a partially transparent 3D representation of the building and interior floor map in general can overlay any other suitable type of a map such as a 3D map for example. As discussed in the present disclosure the presentation of the partially transparent 3D representation of the building and the interior floor map may be a result of a change in zoom command.

Now referring to another example screenshot illustrates a zoomed in map of the geographic area relative to the map of the geographic area presented in . The zoomed in map may include more details about the geographic area such as side streets etc. The screenshot also includes a more detailed partially transparent 3D representation of the building . As with an interior floor map is drawn inside the 3D space defined by the partially transparent 3D representation of the building . The more detailed partially transparent 3D representation of the building may be more transparent or substantially the same degree transparent than the more detailed than the representation of the building . The screenshot corresponds to the scenario in which the user has zoomed in on a display as shown in or and the mapping software in response generated the zoomed in map of the geographic area .

Now referring to another example screenshot illustrates a more zoomed in map of the geographic area relative to the zoomed in map of the geographic area presented in . The more zoomed in map may include even more details about the surrounding area as well as a highly detailed partially transparent 3D representation of the building . The more detailed interior floor map may include much more detail than the interior floor maps and . The more detailed interior floor map may include text and icons to present more information about what features places of business etc. are located on that particular floor of the building. For example the more detailed interior floor map may include icons representing building features such as elevators and the names of various businesses and an icon to indicate the type of business e.g. the knife and fork icon .

The representation of the buildings and discussed above may be made transparent using any of a number of suitable techniques. For example alpha blending may be used. Additionally or alternatively the map server may generate different raster images with different levels of transparency and send these raster images to the computing device .

It is noted that internal building feature inspection module that implements the techniques discussed with reference to provides an intuitive interface for inspecting indoor map data separately or in conjunction with outdoor map data without requiring that the user operate additional controls and without occluding significant portions of the map.

To further illustrate the techniques for providing an intuitive and efficient interface for inspecting indoor and outdoor map data example methods which the internal building feature inspection module may implement are discussed next with reference to . More generally these methods can be implemented in any suitable computing device and any suitable software application. For example these methods can be implemented as sets of instructions stored on a tangible computer readable medium and executable on a processor.

The flow diagram of illustrates an example method for the progressive disclosure of interior floor maps of a building on a map of a geographic area. At block an interactive digital map of a geographic region is rendered. The rendered digital map may be rendered using outdoor map data and may display map elements such as roads buildings parks bodies of water etc. The rendered digital map may include a substantially opaque 3D representation of a building located in the geographic region. A substantially opaque 3D representation of a building may be completely opaque or may be partially transparent but the overall effect may be that any interior floor maps or other visual information drawn inside the space defined by the 3D representation of a building may be fully or partially obscured. At block a zoom in command may be detected. The zoom in command may correspond to a spread event for example if a multi touch interface is used. The zoom in command may also correspond to a tap event on an on screen button e.g. the button in . A version of the interactive digital map of a geographic region may be rendered with a more transparent 3D representation of a building located in the geographic region at block . The more transparent 3D representation of a building located in the geographic region may have an interior floor map of a default floor of the building drawn inside the space defined by the more transparent 3D representation of a building as described in the present disclosure.

Next at block the map of the geographic area is rendered including a 3D representation of a building in which the building transparency and interior floor map detail are configured using the initial values. At block a command to change zoom level may be detected. The command to change zoom level may be a zoom in command or a zoom out command. A zoom in command may correspond to a spread event for example if a multi touch interface is used. The zoom in command may also correspond to a tap event on an on screen button e.g. the button in . A zoom out command may correspond to a pinch event for example if a multi touch interface is used. The zoom out command may also correspond to a tap event on an on screen button e.g. the button in . At block a software module determines whether the command to change zoom was a zoom in command corresponding to an increase in zoom level or a zoom out command corresponding to a decrease in zoom level.

If the zoom level is to be increased a software module may increment a zoom level counter. At block a software module may increase building transparency as a function of the zoom level. The zoom level may be tied mathematically to a transparency coefficient e.g. a zoom level of 15 may correlate to a transparency level of 15 18 or 83 a zoom level of 16 may correlate to a transparency level of 16 18 or 89 . Alternatively or additionally the zoom level may be associated with one or more transparency thresholds e.g. a zoom level of 14 may be associated with 50 transparency a zoom level of 15 may be associated with 55 transparency etc. . Similarly at block a software module may increase a interior map detail as a function of zoom. As with building transparency interior map detail may be increased using one or more thresholds.

If the zoom level is to be decreased a software module may increment a zoom level counter. At block a software module may decrease building transparency as a function of the zoom level. The zoom level may be tied mathematically to a transparency coefficient e.g. a zoom level of 16 may correlate to a transparency level of 16 18 or 89 a zoom level of 15 may correlate to a transparency level of 15 18 or 83 . Alternatively or additionally the zoom level may be associated with one or more transparency thresholds e.g. a zoom level of 15 may be associated with 55 transparency etc. a zoom level of 14 may be associated with 50 transparency . Similarly at block a software module may decrease a interior map detail as a function of zoom. As with building transparency interior map detail may be decreased using one or more thresholds. After adjusting the zoom level building transparency and interior map detail the method may loop back and render the map according to the new parameters at block and then again detect a command to change zoom level at block .

The following additional considerations apply to the foregoing discussion. Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter of the present disclosure.

Additionally certain embodiments are described in the present disclosure as including logic or a number of components modules or mechanisms. Modules may constitute either software modules e.g. code stored on a machine readable medium or hardware modules. A hardware module is tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more hardware modules of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a hardware module that operates to perform certain operations as described in the present disclosure.

In various embodiments a hardware module may be implemented mechanically or electronically. For example a hardware module may comprise dedicated circuitry or logic that is permanently configured e.g. as a special purpose processor such as a field programmable gate array FPGA or an application specific integrated circuit ASIC to perform certain operations. A hardware module may also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

Accordingly the term hardware should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily configured e.g. programmed to operate in a certain manner or to perform certain operations described in the present disclosure. Considering embodiments in which hardware modules are temporarily configured e.g. programmed each of the hardware modules need not be configured or instantiated at any one instance in time. For example where the hardware modules comprise a general purpose processor configured using software the general purpose processor may be configured as respective different hardware modules at different times. Software may accordingly configure a processor for example to constitute a particular hardware module at one instance of time and to constitute a different hardware module at a different instance of time.

Hardware and software modules can provide information to and receive information from other hardware and or software modules. Accordingly the described hardware modules may be regarded as being communicatively coupled. Where multiple of such hardware or software modules exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses that connect the hardware or software modules. In embodiments in which multiple hardware modules or software are configured or instantiated at different times communications between such hardware or software modules may be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware or software modules have access. For example one hardware or software module may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware or software module may then at a later time access the memory device to retrieve and process the stored output. Hardware and software modules may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The various operations of example methods described in the present disclosure may be performed at least partially by one or more processors that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processors may constitute processor implemented modules that operate to perform one or more operations or functions. The modules referred to in the present disclosure may in some example embodiments comprise processor implemented modules.

Similarly the methods or routines described in the present disclosure may be at least partially processor implemented. For example at least some of the operations of a method may be performed by one or processors or processor implemented hardware modules. The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the processor or processors may be located in a single location e.g. within a home environment an office environment or as a server farm while in other embodiments the processors may be distributed across a number of locations.

The one or more processors may also operate to support performance of the relevant operations in a cloud computing environment or as an SaaS. For example at least some of the operations may be performed by a group of computers as examples of machines including processors these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. application program interfaces APIs . 

The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the one or more processors or processor implemented modules may be located in a single geographic location e.g. within a home environment an office environment or a server farm . In other example embodiments the one or more processors or processor implemented modules may be distributed across a number of geographic locations.

Some portions of this specification are presented in terms of algorithms or symbolic representations of operations on data stored as bits or binary digital signals within a machine memory e.g. a computer memory . These algorithms or symbolic representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. As used in the present disclosure an algorithm or a routine is a self consistent sequence of operations or similar processing leading to a desired result. In this context algorithms routines and operations involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions in the present disclosure using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or a combination thereof registers or other machine components that receive store transmit or display information.

As used in the present disclosure any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. For example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used in the present disclosure the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments in the present disclosure. This is done merely for convenience and to give a general sense of the description. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for providing an interface for inspecting indoor and outdoor map data through the disclosed principles in the present disclosure. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed in the present disclosure. Various modifications changes and variations which will be apparent to those skilled in the art may be made in the arrangement operation and details of the method and apparatus disclosed in the present disclosure without departing from the spirit and scope defined in the appended claims.

