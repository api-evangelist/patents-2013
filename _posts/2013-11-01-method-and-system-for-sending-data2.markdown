---

title: Method and system for sending data
abstract: Embodiments of systems and methods for data transfer disclosed herein. Specifically, embodiments may utilize a protocol module deployed on a computing device, where the protocol module may be configured to receive data from an application and send that data using a particular protocol. The protocol module may, for example, utilize a latency tolerant protocol such as the Mobile Transport Protocol (MTP).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09621473&OS=09621473&RS=09621473
owner: Open Text SA ULC
number: 09621473
owner_city: Halifax
owner_country: CA
publication_date: 20131101
---
This application is a continuation in part of and claims a benefit of priority under 35 U.S.C. 120 of the filing date of U.S. patent application Ser. No. 10 929 029 by inventors Oliver Sturrock and Timothy John Wentford entitled Measuring Latency Over a Network filed on Aug. 27 2004 which claims priority to Great Britain Application No. 0418374.5 by inventors Oliver Sturrock and Timothy John Wentford filed Aug. 18 2004 the entire contents of each are hereby expressly incorporated by reference for all purposes.

This disclosure relates generally to systems and methods for data transfer. Specifically this disclosure relates to systems and methods for sending data in a networked environment and the reduction of the effects of network latency when sending such data.

In today s communication environment the reliance on computing devices is growing ever greater. In particular mobile computing devices or just mobile devices such as cellular phones smart phones laptops PDAs etc. are increasingly the way users conduct a wide variety of their business. Thus users may utilize their computing devices to access a wide variety of data from a wide variety of content providers or sources.

In many cases in particular environments e.g. business environments content management environments etc. applications may be utilized which allow a user to access functionality or content at a location on the network. For example many applications may be deployed on mobile devices where these applications may communicate with a platform e.g. a server or the like which provides functionality or content associated with the application.

With the increase of networked both wired and wireless and distributed computing environments e.g. the Internet mobile or cellular networks office internets or intranets etc. the need to transfer data between computing devices has similarly increased. Commensurate with the increased need to transfer this data the size of the data that it is desired to transfer has also increased. This combination has resulted in undesirable latency issues in the transfer of this data.

Embodiments of systems and methods for data transfer disclosed herein. Specifically embodiments may utilize a protocol module deployed on a computing device where the protocol module may be configured to receive data from an application and send that data using a particular protocol. The protocol module may for example utilize a latency tolerant protocol such as the Mobile Transport Protocol MTP .

The protocol module may send the data to a platform protocol module at a platform e.g. a platform that supports the application on the mobile device or another platform . The platform protocol module may for example form part of a content provisioning or other module at the platform utilized by the application or may be configured to implement the protocol in conjunction with a proxy such that the platform protocol module may communicate with the protocol module on the device according to the protocol to receive the data as sent by the protocol module on the computing device and distribute the received data e.g. to a content provisioning module associated with the application or to another appropriate destination .

In certain embodiments then a protocol module and a platform protocol module may be used to provide a Virtual Private Network VPN between a device and a particular platform. Additionally as network traffic may be sent through and received from the protocol module and the platform protocol module encryption may easily be implemented in conjunction with the protocol module and platform protocol module. As such a VPN network can be implemented using the protocol module and the platform protocol module in a latency tolerant protocol.

As the platform protocol module may form part of a VPN server or TCP or HTTP endpoint and may for example be implemented as a proxy such a platform protocol module may also serve as convenient nexus for the control of network traffic for a device. As such policies e.g. with respect to internet access security content access etc. may be implemented in conjunction with the platform protocol module. For example the platform protocol module may control a user s internet access control authentication or other security related to a user before access to any content in a data store is allowed etc.

In one embodiment a sending computing device may be coupled to a destination computing device over a network. The sending computing device may include an application executing on a processor and a protocol module configured to receive data from the application and send the data to the destination computing device according to the Mobile Transport Protocol MTP .

To send the data some embodiments may create a first packet comprising at least a portion of the data send the first packet to the destination computing device using an unreliable protocol receive control data sent using the unreliable protocol and adjust the sending of the data based on the control data.

In certain embodiments the control data may comprise latency information and the protocol module may be further configured to determine a latency on the network between the computing device and the destination computing device to which the first packet was sent based on the latency information. The protocol module may also be configured to adjust the sending of data to the destination computing device based on the latency by for example determining a data transmission rate corresponding to the destination computing device based on the latency and sending the data according to the data transmission rate.

These and other aspects of the invention will be better appreciated and understood when considered in conjunction with the following description and the accompanying drawings. The following description while indicating various embodiments of the invention and numerous specific details thereof is given by way of illustration and not of limitation. Many substitutions modifications additions or rearrangements may be made within the scope of the invention and the invention includes all such substitutions modifications additions or rearrangements.

Embodiments and the various features and advantageous details thereof are explained more fully with reference to the nonlimiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. Descriptions of well known starting materials processing techniques components and equipment are omitted so as not to unnecessarily obscure embodiments in detail. It should be understood however that the detailed description and the specific examples while indicating preferred embodiments are given by way of illustration only and not by way of limitation. Various substitutions modifications additions and or rearrangements within the spirit and or scope of the underlying inventive concept will become apparent to those skilled in the art from this disclosure. Embodiments discussed herein can be implemented in suitable computer executable instructions that may reside on a computer readable medium e.g. a hard disk HD hardware circuitry or the like or any combination.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

Additionally any examples or illustrations given herein are not to be regarded in any way as restrictions on limits to or express definitions of any term or terms with which they are utilized. Instead these examples or illustrations are to be regarded as being described with respect to one particular embodiment and as illustrative only. Those of ordinary skill in the art will appreciate that any term or terms with which these examples or illustrations are utilized will encompass other embodiments which may or may not be given therewith or elsewhere in the specification and all such embodiments are intended to be included within the scope of that term or terms. Language designating such nonlimiting examples and illustrations includes but is not limited to for example for instance e.g. in one embodiment. 

Embodiments can be implemented in a computer communicatively coupled to a network for example the Internet an intranet an internet a WAN a LAN a SAN etc. another computer or in a standalone computer. As is known to those skilled in the art the computer can include a central processing unit CPU or processor at least one read only memory ROM at least one random access memory RAM at least one hard drive HD and one or more input output I O device s . The I O devices can include a keyboard monitor printer electronic pointing device for example mouse trackball stylus etc. or the like. In embodiments the computer has access to at least one database over the network. In an embodiment the database may be located on the same physical hardware as a platform server and may be accessed locally through protocols such as but not limited to open database connectivity ODBC .

ROM RAM and HD are computer memories for storing computer executable instructions executable by the CPU or capable of being compiled or interpreted to be executable by the CPU. Within this disclosure the term computer readable medium is not limited to ROM RAM and HD and can include any type of data storage medium that can be read by a processor. For example a computer readable medium may refer to a data cartridge a data backup magnetic tape a floppy diskette a flash memory drive an optical data storage drive a CD ROM ROM RAM HD or the like. The processes described herein may be implemented in suitable computer executable instructions that may reside on a computer readable medium for example a disk CD ROM a memory etc. . Alternatively the computer executable instructions may be stored as software code components on a DASD array magnetic tape floppy diskette optical storage device or other appropriate computer readable medium or storage device.

In one exemplary embodiment the computer executable instructions may be lines of C Java JavaScript or any other programming or scripting code. In an embodiment HTML may utilize JavaScript to provide a means of automation and calculation through coding. Other software hardware network architectures may be used. For example the functions of embodiments may be implemented on one computer or shared among two or more computers. In one embodiment the functions may be distributed in the network. Communications between computers implementing embodiments can be accomplished using any electronic optical radio frequency signals or other suitable methods and tools of communication in compliance with known network protocols.

Additionally the functions of the disclosed embodiments may be implemented on one computer or shared distributed among two or more computers in or across a network. Communications between computers implementing embodiments can be accomplished using any electronic optical radio frequency signals or other suitable methods and tools of communication in compliance with known network protocols. It will be understood for purposes of this disclosure that a module is one or more computing devices configured to perform one or more functions for example by executing computer instructions embodied on a non transitory computer readable medium. A module may present one or more interfaces which can be utilized to access these functions. Such interfaces include APIs web services interfaces presented for a web services remote procedure calls remote method invocation etc.

Before delving into more detail regarding the specific embodiments disclosed herein some brief context may be helpful. As discussed above the reliance on computing devices is growing ever greater. With the increase of networked both wired and wireless and distributed computing environments e.g. the Internet mobile or cellular networks office internets or intranets etc. the need to transfer data between computing devices has similarly increased. Commensurate with the increased need to transfer this data the size of the data that it is desired to transfer has also increased. This combination has resulted in undesirable latency issues in the transfer of this data.

More specifically as the distance of over which it is desired to transfer data increases the latency of the file transfer may similarly increase due to increased network latency. This network latency may be due to a number of factors such as an increase in the number of hops required for the data transfer a greater likelihood of network congestion on an intermediary networked varying capacity on intermediary networks or a whole host of other factors.

To exacerbate the problem the latency added by the distance of the transferred may be even more noticeable when large amount of data are transferred. For example a 20 millisecond difference in the transfer speed of a packet may not be particularly noticeable when transferring a 2 MB file however when transferring a 5 GB file such latency may be become quite problematic.

Accordingly it is desired to implement effective reliable and general purpose solutions for reducing the effects of network latency in data transfers. Moreover it is desired to implement such solutions unobtrusively to users.

To that end attention is directed to the embodiments of the systems and methods for data transfer disclosed herein. Specifically embodiments as disclosed may utilize a protocol module deployed on a computing device where the protocol module may be configured to receive data from an application and send that data using a particular protocol. Specifically in one embodiment the protocol module may provide a set of interfaces such as Application Programming Interfaces API or the like and the application may utilize these interfaces to provide the data to be sent to the protocol module. The protocol module may then send the data using a protocol. Alternatively the application may be configured to send the data using a first protocol and the protocol module may receive the data in the first protocol and send the data using a second protocol. The protocol used by the protocol module may be resistant to latency on the network.

For example the data to be sent by the application may be in a particular protocol such a hypertext transfer protocol HTTP Transport Control Protocol TCP or another protocol entirely such that the data received from application in an original protocol may be tunneled over the protocol used by the protocol module. The protocol module may for example utilize the Mobile Transport Protocol MTP as will be discussed below.

Such a protocol module may be for example a protocol plug in module integrated into e.g. as a library or forming a part of the application whereby when such an application is deployed on a computing device the protocol module is likewise deployed on the computing device in conjunction with the application. In other cases a protocol module may form part of a separate protocol application such that it may receive data from one or more applications concurrently executing on a computing device. When these applications send data e.g. in a first protocol the protocol application may receive this data e.g. by intercepting the data emulating an interface of the first protocol etc. . The protocol module can then send this received data using a second protocol e.g. MTP .

Such a protocol module may also for example be integrated at the transport layer the application layer the network layer or another layer of a protocol stack and may emulate one or more interfaces typically provided by protocols that reside at that layer. For example a protocol module may emulate one or more interfaces typically provided by TCP IP UDP HTTP Web Sockets etc.

The protocol module may send the data to a platform protocol module at a platform e.g. a platform that supports the application on the mobile device or another platform . The platform protocol module may for example form part of a content provisioning or other module at the platform utilized by the application or may be configured to implement the protocol in conjunction with a proxy such that the platform protocol module may communicate with the protocol module on the device according to the protocol to receive the data as sent by the protocol module on the computing device and distribute the received data e.g. to a content provisioning module associated with the application or to another appropriate destination . The platform protocol module may also be configured to send data to the device according to the protocol.

In certain embodiments then a protocol module and a platform protocol module may be used to provide a Virtual Private Network VPN between a device and a particular platform. In particular in one embodiment the protocol module may be implemented as a protocol application configured such that all network traffic from any applications executing on a device may be received by the protocol application and sent via the implemented protocol e.g. MTP to the platform protocol module at the platform. Any communication from the platform to the device may similarly be sent via the implemented protocol.

Additionally as all network traffic may be sent through and received from the protocol module and the platform protocol module encryption may easily be implemented in conjunction with the protocol module and platform protocol module. As such a VPN network can be implemented using the protocol module and the platform protocol module in a latency tolerant protocol e.g. MTP .

As the platform protocol module may form part of a VPN server or TCP or HTTP endpoint and may for example be implemented as a proxy such a platform protocol module may also serve as convenient nexus for the control of network traffic for the device. As such policies e.g. with respect to internet access security content access etc. may be implemented in conjunction with the platform protocol module. For example the platform protocol module may control a user s internet access control authentication or other security related to a user before access to any content in a data store is allowed etc.

Accordingly embodiments may be utilized in a wide variety of contexts and in conjunction with a wide variety of computing devices and environments. For example while embodiments may be usefully applied to an environment with users at a mobile or desktop computing device that communicates with a platform other embodiments may also be usefully applied to other environments without loss of generality. In order to better understand embodiments as presented herein embodiments of the MTP protocol which may be utilized in certain embodiments of a protocol module including a platform protocol module will be discussed.

The data is provided over a variety of networks including radio networks such as mobile telephony networks or wireless networks. A Third Generation 3G mobile telephony network connected to the Internet includes a gateway which provides connectivity to a network of base stations. Terminals and are each connected to one of these base stations. A General Packet Radio Service GPRS gateway is connected to the Internet and provides connection to a network of GPRS base stations. Terminals to are each connected to one of these stations. A GMS gateway is connected to the Internet providing connectivity for terminal . A terminal could when possible switch between connections as shown by dotted line .

Internet Service Provider ISP is connected to the Internet and provides internet access for server server and a Wireless Network or Wireless Fidelity WiFi gateway . Terminal has a link to gateway . ISP is connected to the Internet and provides internet access for computer systems and via wire links. Terminal is connected by an ethernet wire link possibly using a docking cradle to computer system . Alternatively server is connected directly to the Internet .

Thus there is a number of ways in which a terminal may link to the Internet in order to receive data from RTDP . There are of course other methods of connection and the rate of technological advance means that in the future there will be further methods. This description should not be construed as limiting connection methods to those described here. However the number of methods makes the task of providing real time data difficult. While it is for example relatively easy to provide data quickly to terminals and terminals to use relatively low bandwidth high latency and high variability connections over which it is very difficult to provide real time data.

Mobile telephony systems such as those provided by gateways to are used to provide data. For example mobile telephone users are able to browse the Internet . However the rate of data supply can be extremely slow. This is merely inconvenient when browsing. However if data on the basis of which decisions are to be made is required for example financial data it must be provided in a timely fashion. This means that the data should arrive at the terminal quickly and preferably it should be possible to indicate to a user how up to date the information is.

This journey across several networks is facilitated by the Internet Protocol IP which provides a header at the start of every packet defining the destination IP address. Other information is also provided in the IP header such as the size of the packet but its primary function is to define an address that gateways and routers can read and decide where the packet should be sent next. Packets are sent separately and may end up taking different routes. It is therefore possible for packets to arrive out of order.

In order to maintain a dialogue between server and terminal an additional protocol must be used. Most commonly this protocol is the Transport Control Protocol TCP . This enables a two way link to be set up between two systems on the Internet . Messages are sent and TCP provides functionality such as acknowledging and resending data if necessary and reordering packets if they arrive in the wrong order. TCP was designed to be used on networks that have a high data capacity and low latency but can suffer from congestion. However mobile telephony networks have different characteristics and TCP handles certain of these characteristics in an ineffective way.

In the communication chain shown in TCP and other protocols achieve effective communication across high capacity parts of the Internet . However the final link to terminal over a low capacity wireless connection is extremely vulnerable. TCP fails to address these vulnerabilities effectively since it was not designed for that purpose.

The IP header defines the destination IP address for the packet. After this there is the transport protocol header which is typically used by the communication client and server to form a connection over which communications can take place. Finally the remainder of the data packet is the data payload. Some packets do not have data and simply consist of signalling in the transport header for example an acknowledgement packet that tells the recipient that some data has been successfully received. Typically though acknowledgements are combined with data to reduce traffic.

An example of a transport protocol is TCP as described with reference to . TCP forms reliable connections and is often combined with higher protocols such as the File Transfer Protocol FTP or Hypertext Transport Protocol HTTP .

TCP s performance is always less than 100 . When there are significant changes in network availability TCP compensates inefficiently because its underlying mechanisms make assumptions about the network that are invalid for a mobile connection. When bandwidth falls off for example at point the amount of data sent using TCP falls much faster because data packets that have been lost need to be resent resulting in a downward spiral of lost bandwidth. TCP cannot anticipate or compensate fast enough to avoid such inefficiencies.

When a disconnection occurs such as at point TCP takes a long time to re establish data flow when the link is reconnected. When using a terminal on a mobile telephony network such disconnections are frequent for example when the user goes through a tunnel.

TCP presents another problem to real time data provision. When a disconnection takes place as at point a wireless service provider will often perform a service known as IP spoofing . This involves a proxy server being used to maintain the TCP connection with a server even though the wireless connection is broken. When the connection is re established data can be sent from where it is cached on the proxy server to the terminal. The telecoms provider does this so that a data transfer can continue rather than being restarted every time the connection is lost.

This operation is helpful for internet browsing and downloading of large files to mobile telephones. However it presents two problems to RTDP . The first is that if the telecoms provider caches a large amount of streamed data and sends it all to a terminal upon reconnection this can overload the connection. This is especially inappropriate given that much of it may be out of date. The second problem is that the RTDP might send transactional data to for example terminal while it is disconnected from 3G gateway . The 3G network spoofing terminal will acknowledge this data. However if terminal does not reconnect which might happen for one of many reasons then the cached transactional data will never be forwarded. This results in RTDP wrongly concluding that terminal has received the data.

A further problem with TCP is that it is a connection oriented protocol. When a client moves between wireless base stations its IP address can change resulting in a requirement to set up a new TCP connection. This can interfere with communications. In particular a secure transaction could be terminated. This also prevents a terminal from using a higher bandwidth lower latency network that may become available without terminating a connection for example when a terminal connected to GPRS gateway comes within range of 3G gateway or moves into the radius of a WiFi gateway .

The application server receives data from a number of data feeds. These are illustrated by two way arrows as data is provided to application server but the server may also send information back for example details of a financial transaction or an information request. Financial transaction services data feed provides communications for making stock market based transactions. Sports transaction services data feed provides communications for making sports based transactions. Financial data feed provides real time updates of for example share prices and exchange rates while sports data feed provides real time updates of sports scores. News data feed provides news headlines and stories. It will be appreciated that the data feeds illustrated in are representative of the type of data that a Real Time Data Server might provide to clients. Other data types and feeds are contemplated and included in this description.

The application server communicates with the real time data server over an outbound initiated TCP based link . The connection between the two systems is made via a high speed Gigabit Ethernet connection. In other embodiments the two servers could use the same processing system. However this provides less security.

The application server is protected by a first firewall so as to resist any security vulnerabilities that may exist in the real time data server which has its own firewall . The real time data server takes data from the application server and supplies it to terminals via the Internet using a custom protocol called the Mobile Transport Protocol MTP . This protocol addresses the needs of real time data services for mobile client terminals.

In the embodiment described herein the terminals are Personal Digital Assistants PDAs such as PDA . These are small portable devices including a display screen control buttons a speaker and a microphone . The display may be touch sensitive allowing the PDA to be controlled using a stylus on the screen instead of buttons . A typical PDA is supplied with software providing the functionality of inter alia a mobile telephone word processing and other office related capabilities a calendar and address book email and internet access games and so on. The skilled reader will appreciate that the PDAs illustrated in this document are not the only terminals that can be used. For example a mobile telephone with enough storage and memory could be used or other devices which can communicate over mobile telephony networks.

PDA may communicate with the real time data server to obtain access to data provided by any of data feeds to or to obtain software downloads for installation. The application server facilitates several different types of service. In particular the efficient provision of multiple types of data having different characteristics is enabled using the custom protocol MTP.

The two main types of data are transactional data and streamed data. For transactional data a two way communication between the PDA and the real time data server facilitates the making of a secure transaction. Data delivery must be guaranteed even if a connection is broken. Such data may be several kilobytes for each message requiring multiple datagrams to be transmitted before a message is complete. These packets or datagrams must be reassembled in the right order before use.

Streamed data comprises updates for example of financial or sporting data. These may be provided at a fixed regular rate or may be provided at an irregular rate as the data becomes available. Each update or message is contained in a single datagram although a datagram may contain more than one message . For this reason it is not necessary for streamed datagrams to be ordered at the terminal.

Because of these different data types each of which has its own issues to be addressed MTP provides two types of data communication transactional communication and streamed communication. It facilitates communication of both types over the same communication link. The data types are differentiated such that the bandwidth utilisation is maximised without compromising transactional communications. It specifically addresses the need for bandwidth efficiency latency measurement multiple data types and continuous updates over a low bandwidth high latency high variability wireless mobile link. Also because by its nature a mobile terminal such as a PDA has low storage and memory capabilities it minimises the computational requirements of the terminal.

Following either of steps or the instructions are installed at step . At this point or if the question asked at step is answered in the negative the instructions are executed at step . At step the real time data server is switched off. In practice this will happen very infrequently for example for maintenance.

Process transmits datagrams from the real time data server to a client . Each packet includes an IP header a UDP header and an MTP header. For convenience each packet is referred to as a datagram. Process comprises two separate processes datagram preparation and output buffer processing . Process prepares data for transmission. Data received from application server can be from several applications having different data characteristics and priorities and it must be processed before it can be sent to terminals such as PDA .

Process receives datagrams from client terminals such as PDA and comprises three separate processes datagram reception transactional datagram processing and streamed datagram processing .

Process which will be described further with reference to performs background processing which includes various processes required to be performed while transmitting and receiving data such as identifying timeout conditions.

Process provides session maintenance which includes operations performed when PDA is temporarily disconnected. This process which will be described further with reference to is the first to start with processes and being performed once the user session is established.

The IP header includes several fields. Version field indicates the version of IP being used for example IPv4 or IPv6. Internet Header Length field indicates the length in 32 bit words of the IP header. Its minimum value is 5. Length field gives the total length in bytes of the datagram including the IP header but not including the local network protocol header . Protocol field is set to a value indicating that UDP is being used. Source IP address field gives the return address of the datagram while destination IP address field gives its destination.

The UDP header has the following fields. Source port field gives the port on the computer sending the datagram while destination port field gives the port number on the computer receiving the datagram. Length field gives the length of the datagram in bytes including the UDP header but not including the previous headers and . Checksum field contains a value computed from the IP header UDP header and the remainder of the datagram enabling data integrity to be confirmed.

Fields to are single bit fields that are considered to be set if their value is one and not set if it is zero. SYN field and KAL field are used for signalling. At the start and end of a session SYN field is used for handshaking but it is also used to perform various connection timing procedures. KAL field is used to send keep alive datagrams that indicate that a connection is open. ACK field indicates that the datagram is being used to acknowledge a received datagram while EACK field indicates an extended acknowledgement. STREAM field is used to differentiate between streamed and transactional data. When set it indicates that the datagram contains streamed data.

START field and END field are used to indicate that a datagram contains data and that it is the first or last of a set. If a datagram is too large to be sent as a single datagram then it may be split and so START field indicates the first datagram and END field indicates the last. A datagram that has not been split has both fields set. An empty datagram does not have these fields set.

RESET field is used for session handshaking when restarting a session and FINISH field is used to close an MTP session.

Session ID field is a number indicating which session the MTP datagram relates to. Sequence number field is a number indicating the datagram sequence. Each datagram that is sent out and that requires acknowledgement is given its own effectively unique number which is then used in an acknowledgement by the client. Since streamed and transactional datagrams are numbered using a different sequence and since the sequence numbering loops at a number that is greater than the number of acknowledgements that will be outstanding at any time the sequence number is not strictly unique but is effectively unique. An acknowledgement is itself a datagram which may contain data and so acknowledgement number field is the sequence number of the datagram being acknowledged in a datagram that has the ACK field set. This datagram is probably otherwise unconnected with the datagram being acknowledged.

Process commences with step at which a question is asked as to whether there is any data for transmission. If this question is answered in the affirmative then a further question is asked at step as to whether the data is transactional data. If this question is answered in the affirmative then at step a datagram is prepared and at step it is placed in the transactional segment buffer . Alternatively if the question asked at step is answered in the negative a datagram of streamed data is prepared at step . The elapsed time value in the datagram is set to zero indicating fresh data at step and at step the datagram is placed in the streamed segment buffer .

Following steps or or if the question asked at step is answered in the affirmative control is returned to step and the question is asked again as to whether there is any data for transmission.

Transmission is facilitated by supplying a datagram to the operating system which facilitates its electronic transmission using the Internet Protocol.

Transactional and streamed datagrams are generated from data stored in prioritised message queues . This data is supplied to message queues by applications running on application server . An application may supply all its outgoing messages to a particular message queue or may pass messages to different queues depending upon the nature of the data.

Transactional data is supplied to prioritised message queues and . Streamed data is supplied to prioritised message queues and . Each message queue may contain a number of messages supplied from applications on application server . These messages are delineated by level one message headers such as header that specify the length of the data and the application from which it was supplied.

The amount of data taken from each message queue and combined into a single datagram depends upon proportions defined for each message queue. For example default proportions of fifty percent thirty percent and twenty percent may be assigned to prioritised message queues to respectively. If message queue has no data then its allocation will be equally reallocated between queues and giving queue thirty five percent and queue sixty five percent. If only one queue contains data then it will have one hundred percent of the allocation.

The way the data is allocated also depends upon the type of message queue. Transactional messages may be broken up over a number of datagrams and so the process only considers the amount of data in the queue. However streamed messages must be wholly contained within one datagram and so only entire messages are taken from these message queues even if this means that the message queue s priority allocation is not used up.

Datagrams are created from the message queues and placed in segment buffers and . These are then sent with the first message being taken from each segment buffer in turn.

The example in shows datagram which is made up from transactional data. The amount of data that can be included in the datagram is calculated and data is taken from each of queues to according to their priority levels. Data from different prioritised message queues is delineated within a datagram by level two message headers such as headers and . These headers include a length field and a message queue field .

Thus the example datagram does not contain a single message but in fact contains portions of five messages since the data from each of queues to includes a message header and thus includes the end of one message and the beginning of another.

The number of prioritised message queues shown here and their proportions are provided as an example only. There could be fewer queues for example only one transactional queue and two streamed queues or any other number. The proportions will vary according to the kinds of real time data provided and the realities of each individual system. Additionally it is not necessary that unused allocation be equally divided between the remaining queues. It could be divided according to their own allocations or in some other way.

At step the variable N is decremented by one and at step the highest message queue is selected. A variable P is set to be the sum of the proportion of the datagram that the data in that queue may use for example 0.3 for queue P1 and variable Y zero on the first iteration and a variable X is set to be the amount of data in bytes in the queue. At step a question is asked as to whether the variable N is equal to zero. If this question is answered in the affirmative then the queue under consideration is the last one containing data and so the following steps need not be carried out control being directed to step .

However if it is answered in the negative then at step a further question is asked as to whether the variable X is less than the product of the variables S and P that is whether the amount of data in the queue is less than the amount of data that may be used. If this question is answered in the affirmative then at step the variable Y is calculated as the variable X subtracted from the product of P and S all divided by the product of S and N all added to the previous value of Y. Thus Y is a proportion that is to be added to the proportions of the remaining queues in order to allocate to them the unused space allocated to the queue under consideration. For example if the available space is 400 bytes and all three queues contained data then P1 is allocated 120 bytes. If it only contained 100 bytes then a further 10 bytes would be allocated to each of the remaining queues. Y would thus be 0.05. Alternatively if the question asked at step is answered in the negative to the effect that the variable X is not less than the product of X and S then at step the variable X is set to be the product of the variables P and S.

Following either step or step or if the question asked at step is answered in the affirmative at step a level two header is created in the temporary buffer and the first X bytes are moved from the queue into the temporary buffer. The question is then asked at step as to whether the variable N is equal to zero. If this question is answered in the negative then control is then returned to step where N is decremented again before the next queue is selected. If it is answered in the affirmative then step is over and a datagram has been prepared. The step at of placing this datagram in the transactional segment buffer consists of moving the data from the temporary buffer to the transactional segment buffer .

At step the available space S is calculated in the same way as at step except that a further two bytes are subtracted which will be used to store the elapsed time. At step the variable N is decremented by one.

At step a level two header is created in the temporary buffer and at step the first message queue is selected and a variable P set to be the sum of the queue s priority proportion and the variable Y. At step the first message in the queue is selected and the variable X is set to be the sum of the message s length in bytes and the previous value of X. At step a question is asked as to whether the variable X is less than the product of the variables P and S.

If this question is answered in the affirmative then at step the message is moved to the temporary buffer and a further question is asked as to whether there is more data in the queue. If the question is answered in the negative then control is returned to step and the next message is selected.

If the question asked at step is answered in the affirmative or the question asked at step is answered in the negative then at step the variable X is reset to zero and the variable Y is updated to be the previous value of the variable X subtracted from the product of P and S all divided by the product of S and N all added to the previous value of Y. A question is then asked at step as to whether N is equal to zero. If this question is answered in the negative then control is returned to step if it is answered in the affirmative then step is concluded.

Thus only entire messages are included in a streamed datagram although more than one message may be contained in a single datagram. A streamed datagram may contain more than one message from a single queue as long as it does not exceed its priority allocation but may not contain a fragment of a datagram.

Additionally in another embodiment not shown this prioritisation and mixing of data does not take place. In that embodiment datagrams only contain data from a single application and the START field and END field are used to indicate the beginning and end of messages instead of the level one headers described with reference to .

Output buffer processing is detailed in . At step a question is asked as to whether both the transactional segment buffer and the streamed segment buffer are empty and if this question is answered in the negative then the next datagram to be sent in either buffer or is marked for transmission the process alternates between the two buffers at step . This may be the next newest datagram or it may be an unacknowledged datagram that has been marked to be resent.

If the question asked at step is answered in the negative then at step a further question is asked as to whether an acknowledgement is required. If this question is answered in the affirmative then at step an empty acknowledgement datagram is created. If the question asked at step is answered in the negative then at step a further question is asked as to whether a heartbeat datagram is required and if this question is answered in the affirmative then a latency measuring datagram is produced at step this will be described more fully with reference to . If the question asked at step is also answered in the negative then control is returned to step and the question is asked again as to whether the buffers are empty.

Following any of steps or the MTP header as described in is set at step . At step the process waits for a transmission time since the rate of datagram transmission is controlled as will be described with reference to . When this transmission time is reached the time of sending is internally recorded for the purposes of delaying the next transmission. It is recorded with the datagram stored in the segment buffer along with an indication of how many times the datagram has already been sent. At step a question is asked as to whether this datagram is being resent and is also a datagram containing streamed data as indicated by the setting of both STREAM field and START field if so the elapsed time is changed at step to reflect the amount of time since the first attempt at sending the datagram as can be calculated from the time of the last sending and any previous value of the elapsed time. This is to facilitate the calculation of resend latency as will be described with reference to . Finally at step the datagram is sent.

If the question asked at step is answered in the affirmative then at step ACK field is set and the sequence number of the datagram being acknowledged is entered in acknowledgement number field . At step a question is asked as to whether this acknowledgement is an extended acknowledgement. If this question is answered in the affirmative then at step the EACK field is also set and any datagrams that have not been received but have lower sequence numbers than the sequence number contained in field are listed as data in part of the datagram. Thus these datagrams are negatively acknowledged. Since the IP header and UDP header both contain length fields indicating the total length of the datagram the recipient of an extended acknowledgement knows implicitly how many datagrams are being negatively acknowledged. At this point and if the question asked at step is answered in the negative step is completed. Note that because transactional datagrams have a separate sequence number from streamed datagrams the extended acknowledgement process does not interfere with the acknowledgement of transactional datagrams. 

However if the question asked at step is answered in the negative to the effect that an acknowledgement is not due at step a further question is asked as to whether a latency measurement or heartbeat should be initiated. If this question is answered in the affirmative then at step SYN field is set to one. A datagram having this field set initiates a latency measurement. When an acknowledging datagram is received from PDA it is used to measure round trip latency further described with reference to . Thus the SYN field cannot be set in an acknowledging datagram. For this reason step is only initiated if the question asked at step is answered in the negative. Alternatively if no data is being sent a datagram having this field set in addition to being used to measure latency provides a heartbeat that confirms that the connection is still open.

This figure highlights one of the few ways in which the server and the client are not symmetrical. While a session is stalled the server will not send heartbeat datagrams but the client will. This is because the receipt of a datagram from the client by the server ends the stall. This is provided by the suspension of background processing process which makes the decision as to whether to send a heartbeat datagram during a stalled session. However process sends the datagram if instructed to in exactly the same way on both the server and the client.

Alternatively if it is answered in the negative then at step a question is asked as to whether the acknowledgement number field is zero. If this question is answered in the affirmative then the ACK field is not set but an acknowledgement number is given. This indicates that the acknowledgement field does not contain a sequence number but indicates a new heartbeat rate measured in milliseconds and thus the heartbeat timing rate contained in the session data is updated at step . This process will be described further with reference to .

Following either of steps or or if either the question asked at step is answered in the negative or that asked at step is answered in the affirmative then control is directed to step at which a question is asked as to whether the datagram contains streamed data as indicated by the setting of STREAM field . If this question is answered in the affirmative then the resend latency is recalculated at step . Resend latency in combination with connection latency is used to estimate the age of data received and is described further with reference to .

Following this or if the question asked at step is answered in the negative acknowledgements and state changes are processed at step as will be further described with reference to .

Finally the data is extracted at step as will be further described with reference to and and the datagram acknowledged at step . The processing steps to relate only to the information contained within the MTP header much of which is not connected with the data in any way.

A latency measurement datagram is sent at regular intervals by setting the SYN field in an outgoing datagram in either transactional segment buffer or streamed segment buffer and noting the time at which it was sent. As an example transactional segment buffer is shown containing several packets and . The question asked at step is answered in the affirmative to the effect that a latency measurement should be initiated and so the SYN field of the next datagram to be sent which is datagram is set.

Datagram takes a number of milliseconds shown by arrow and identified by the variable A to be transmitted to PDA whose receive buffer is shown. A process running on PDA which is substantially identical to process sets the SYN field and the ACK field in its next outgoing datagram . This process takes a time indicated by arrow and identified by the variable B. Finally transmission of datagram back to real time data server takes a time indicated by arrow and identified by the variable C. When datagram is received at real time data server the fact that both the SYN and ACK fields are set triggers latency calculation at step .

The round trip time which is obtained by comparing the receive time of datagram with the transmission time of datagram is equal to the sum of the variables A B and C. Since network conditions are on average symmetric A is assumed to be approximately equal to C. B is very small because it is possible to directly acknowledge packet without waiting for any out of order datagrams that would have to be received if the latency was measured using a cumulative acknowledgement as with TCP. Thus as shown by equation the two way latency is approximately equal to the round trip time and the one way latency or connection latency is half the round trip time.

Having obtained a value for the round trip time it is filtered using equations . K is an adaptive filter coefficient that is varied in order to optimise the ability of the filtered latency to follow quick changes when these are consistently observed. Thus the filtered latency is equal to the sum of the following factors K subtracted from one all multiplied by the measured latency and K multiplied by the previous filtered latency calculation. Other filtering or weighting methods may be used in order to smooth the variability of the latency calculation.

The round trip time is used by both the server and the client to determine the length of time that should be waited for an acknowledgement before a transactional datagram is resent timeout . Since streamed datagrams may be acknowledged using an extended acknowledgement the time that a process waits before sending an extended acknowledgement is added to the latency value to produce the timeout for streamed datagrams. The constant measurement of the latency described above ensures that the timeout settings are as accurate as possible. A fixed timeout setting can be set too high in which case the wait before resend would be too long thus degrading the timeliness of the data or it can be too low resulting in too many resends. This dynamic timeout creates a compromise.

Thus data is transmitted in packets from the real time data server to the PDA and vice versa. A first data packet transmitted from real time data server is modified to measure connection latency. This modified data packet is identified by PDA and a second data packet sent from PDA to real time data server is also modified. Connection latency is determined at the real time data server with reference to the time at which the real time data server transmitted the first modified packet and the time at which the second modified packet was received.

The round trip time may be halved to give a connection latency which indicates the approximate time taken by a datagram to be sent from the server to the client. This value is used by the client to indicate the timeliness of received data and will therefore be described further with reference to . Resend latency measurement which will be described with reference to is also calculated at both the client and the server end but in this embodiment is only used by the client. It will therefore not be discussed at this stage.

If the question asked at step is answered in the negative then at step a question is asked as to whether EACK field is set indicating that the datagram contains an extended acknowledge. If this question is answered in the affirmative then at step the extended acknowledgement is processed. If it is answered in the negative then at step a further question is asked as to whether ACK field is set indicating that the datagram contains an acknowledgement. If this question is answered in the affirmative then at step the acknowledgement is processed by removing the datagram that has the sequence number contained in SEQUENCE NUMBER field from the relevant segment buffer or . If it is answered in the negative or following step the session state variables for PDA are modified if necessary.

Thus at step the first sequence number in this range is selected. At step the streamed datagram corresponding to this sequence number is identified and at step a question is asked as to whether the sequence number identified at step is in the list of negatively acknowledged datagrams contained in data of the datagram. If the question is answered in the negative then the sequence number is being acknowledged and this is processed at step . If the question is answered in the affirmative then since the identified datagram is still stored in its relevant segment buffer or it is marked to be resent at step .

At step a question is asked as to whether the sequence number being considered is the same as the number contained in the acknowledgement number field of the datagram. If this question is answered in the negative then control is returned to step and the next sequence number is selected. If however it is answered in the affirmative then the extended acknowledgement has been fully processed and step is completed.

In the alternative embodiment described with reference to wherein mixing of the data is not used only the transactional data need be ordered in the segment buffer . In this embodiment every streamed message is contained in a single datagram and so need not be ordered. If an old update arrives after a new one then the old one is simply discarded by the relevant application. However transactional data which usually stretches over more than one datagram must be ordered. The START and END fields and are used to indicate when a message is finished and can be transferred to the relevant message queue.

Following step or if the question asked at step is answered in the negative to the effect that the datagram contains no data then a question is asked at step as to whether SYN field is set indicating that the datagram is a latency measurement or heartbeat datagram. If this question is answered in the affirmative or following step the datagram is immediately acknowledged at step . This step involves flagging the sequence number in order that process acknowledges it in the next available outgoing datagram at step as described with reference to . If there is no outgoing datagram then an empty streamed datagram is created. At this point or if the question is answered in the negative step is concluded. Thus transactional and latency measurement datagrams are acknowledged immediately. Streamed datagrams are acknowledged using an extended acknowledgement and empty datagrams that are not tagged for example an acknowledgement containing no data are not themselves acknowledged.

At step the process negotiates a new heartbeat rate if required. This is the maximum interval that should pass without data being sent on either the server or client side. If no data is sent then a heartbeat datagram which is an empty streamed datagram with the SYN field set is sent. The server does not send heartbeats during stalling of a session. This is achieved by the suspension of process when a session is stalled. The negotiation of a heartbeat rate although available to both client and server is in this embodiment predominantly initiated by the client and will therefore be described with reference to .

At step the process flags the necessity for an extended acknowledgement if one is due which leads to the question asked by process at step being answered in the affirmative. At step the process marks for resending any datagrams that have not been acknowledged within a timeout and are thus still within their respective segment buffer or . This is done by flagging the datagram for resending and it also increments the value in resend field by one to indicate the number of times the datagram has been resent.

At step the process updates the timeouts based on connection characteristics. The timeout for a transactional datagram is equal to or slightly larger than the round trip time calculated at step . The timeout for a streamed datagram is equal to or slightly larger than the round trip time calculated at step plus the time that the process will wait before sending an extended acknowledgement.

At step the process recalculates the data transmission rate if necessary. This recalculation is done at specified intervals and thus may not be carried out on every cycle.

At step the process sends an update of network characteristics to the application server for use by the applications. In this embodiment this update includes the amount of data currently being sent per second in datagrams or in bytes the amount of data in the segment buffer that has the most data or alternatively in both segment buffers and the round trip time in other embodiments the update could include more or less information.

Application server part of real time data provider produces transactional messages and and streamed messages and . Process on real time data server sends these messages to a terminal such as PDA in the form of datagrams. Transactional messages to are split and sent as part of datagram and . For example datagram may consist of a part of message a part of message and a part of message . Streamed messages to are not split. Thus datagram consists of the whole of messages and . Datagram consists of message . The whole of message cannot also fit into the datagram and so it is sent even though it is not at the maximum size. Datagram contains message . Thus transactional messages may be split over at least two datagrams while streamed messages must be contained within a datagram.

Another difference in the treatment of transactional and streamed data is the method of acknowledgement. Thus each of transactional datagrams to is individually acknowledged using acknowledgements and . However streamed datagrams to may be acknowledged by PDA using a single extended acknowledgement unless they are control datagrams that have a field such as SYN RESET or FINISH set in which case they are individually acknowledged.

This problem is solved by having a separate transmission rate for each terminal and constantly monitoring each of these rates to keep it optimum. Thus at step a question is asked as to whether the interval since the last update is less than the product of 1.25 and the round trip time calculated at step . If this question is answered in the negative then it is not yet time to perform the calculation and step is concluded. This is because the effect of a previous update to the transmission rate is not felt until at least one round trip time later and thus the calculation interval is a small amount more than the round trip time a quarter of the round trip time in this embodiment.

However if the question is answered in the affirmative then at step the total number of resends in the streamed segment buffer is determined and set as the value of a variable R. The number of resends is a sum of the number of datagrams in the buffer that are tagged to be resent with an indication that a datagram is on its second resend adding two to the total an indication that a datagram is on its third resent adding three to the total and so on.

At step a question is asked as to whether the value of R is zero meaning that there are no datagrams in the buffer that are being resent. This indicates that the rate of transmission can be increased. Thus if this question is answered in the affirmative then a further question is asked at step as to whether the current interval between transmissions is significantly larger than a value saved as the current best interval . If this question is answered in the affirmative then the transmission interval is decreased by a first larger amount at step while if it is answered in the negative then the transmission interval is decreased by a second smaller amount at step . This means that when the transmission interval is much larger than the last known achievable interval the transmission interval is decreased much faster than when it is close to it.

If the question asked at step is answered in the negative to the effect that R is not zero then at step a question is asked as to whether R is less than a certain threshold. If this question is answered in the affirmative then the transmission rate is not changed. If however it is answered in the negative then a further question is asked at step as to whether R is significantly smaller than the previous value of R. If this question is answered in the affirmative then the rate is not altered even though R is above the threshold because this value of R may be an anomaly.

If R is above the threshold and not significantly smaller than the previous R then this indicates that there are too many resends and the interval between datagram transmissions needs to be increased. However first a question is asked at step as to whether the last change in the interval was a decrease. If this question is answered in the affirmative then the current transmission interval is the lowest known achievable interval at the current time and so it is saved as the current best at step . The transmission interval is then increased at step the step size used in this embodiment is larger than both of the step sizes used for decreasing the transmission interval .

The algorithm described herein is a robust method of attempting to increase the rate of datagram transmissions while minimising the number of resends using continual and rapid adjustment. It provides a quick response to decreases in the available network bandwidth and a fast restart when transmission is temporarily cut off or after a congestion spike. Clearly the implementation details of the algorithm such as the number of step sizes and what is meant by significantly large could be changed.

In this embodiment due to the small receive buffer of PDA it is only possible to send one datagram at a time. However in other embodiments the method could be altered by sending more than one datagram at once when the transmission interval reaches a certain low threshold. It can be more efficient to send two packets at once at a larger interval than to continue decreasing the transmission interval.

Additionally in another embodiment it could be the transactional segment buffer or both segment buffers that are considered when summing the resends.

If this question is answered in the negative meaning either that the datagram has no session number or that it contains invalid session details then at step a further question is asked as to whether the datagram is requesting a new session indicated by the lack of a session number and the setting of SYN field . If this question is answered in the affirmative then at step a new session is created for the client that sent the datagram. This includes creating session data and validating the new session i.e. checking whether a valid account number for an active account valid name and correct password have been supplied and is in practice performed by calling a subroutine on application server on which the user details are stored.

An answer in the negative to the question asked at step means that there is a problem of some kind with the datagram for example it relates to a terminated session or the session details do not match and so the session is ended at step by sending a reset datagram a datagram in which the RESET field is set to the originating IP address and removing the session data if there is any.

If the question asked at step is answered in the affirmative to the effect that the session details are valid then a further question is asked at step as to whether the IP address from which the datagram was sent matches the IP address held in the session variables. If this question is answered in the negative then at step the IP address is updated in the session variables. The client could change IP addresses for a number of reasons. The main ones are that a client that has moved between networks or cells thus changing its mobile IP address or that a client deliberately terminated its IP connection in order to fully use bandwidth for another function for example to make a telephone call. In this case the client would probably be assigned a different IP address on reconnection even if it is in the same cell of the same network. However this functionality of MTP allows the client to immediately restore the session without visible delay to the user.

At step a question is asked as to whether the datagram is terminating the session indicated by a setting of FINISH field . If this question is answered in the affirmative then the session is ended at step but if it is answered in the negative then at step a question is asked as to whether another datagram has been received for this session within two timeouts and if is answered in the affirmative then control is returned to step . This timeout is different from the resend timeouts discussed with reference to and is set by the heartbeat rate. The heartbeat rate is the maximum interval which should pass without receiving data from a client.

Thus if the question is answered in the affirmative indicating that since the receipt of the last datagram a period of time equal to two timeouts has passed with no further communication from the client then at step the session is placed in a stalled state. This involves noting in the session variables that the session is stalled which prevents any more datagrams from being sent to the client. In this embodiment this involves suspending datagram reception process and background processing process . A stalled session can occur because the network connection to the client has been broken because the PDA does not currently require the real time data and has therefore stopped communicating because the PDA has been switched off without ending the session and so on.

At step a question is asked as to whether a datagram has been received for this session within ten minutes of the session being placed in a stalled state and if this question is answered in the affirmative then the stall is ended and control is returned to step . Ending a stall involves changing the session state and restarting any suspended processes. This will then have the effect of resending any datagrams that have not been acknowledged. However in an alternative embodiment the streamed data buffer and possibly the streamed message queues to could be flushed on the ending of a stall.

If however the question asked at step is answered in the negative then at step the session is ended. The session is closed after a long stall firstly for security measures because the user may have left his terminal unattended and secondly to prevent memory space being used for an unwanted session for example if the terminal has been switched off.

Stalling as described above solves the problem with spoofing that on reconnection the telecoms gateway sends a large amount of data all at once to the terminal thus negating any value obtained by managing data transmission rate as described with reference to . Instead when the connection is broken and the real time data server stops receiving datagrams from PDA the session is stalled and the real time data server sends no more datagrams. Thus the telecoms gateway builds up a very small amount of data if any to send on when the connection is re established.

The second problem solved here is the maintenance of a session when the PDA moves between cells in a telecoms network or indeed between networks. As soon as an incoming datagram that has the correct session ID and encryption but a different IP address is received the IP address in the session data is immediately updated so that datagrams intended for PDA are sent to that IP address. The user therefore perceives very little if any delay when moving between IP addresses.

The updating of IP addresses described with respect to step is illustrated in . A session is described by its session data stored on application server . It includes a session ID field containing a session ID and an IP address field containing an IP address . The session may be in an active state or may move to a stalled state as shown by arrow when no communication is received from the client within two timeouts as set by the heartbeat rate.

A datagram is received by real time data server . It includes a source IP address field in its IP header and a session ID field in its MTP header . The session ID matches the session ID in field . However the IP address does not match the IP address in the IP header . The session data is therefore updated immediately by replacing the IP address in field with IP address . All datagrams produced are now sent to this new address. Receipt of datagram also ends any stall if one existed and so the session is shown as active.

Following either of steps or the instructions are installed at step . At this point or if the question asked at step is answered in the negative the instructions are executed at step . At step the application server is switched off. In practice this will happen very infrequently for example for maintenance.

At step the application server communicates with the client via real time data server by sending messages. The content of these messages is determined by the user s application requirements and the current level of service.

At step a question is asked as to whether the session is stalled which will be indicated to the application server by real time data server and if this question is answered in the affirmative then at step a question is asked as to whether the stall has ended. If this question is answered in the affirmative then at step a selective update of data is performed and control is returned to step . While the session is stalled the application server does not send any messages to real time data server .

If either of the questions asked at steps or is answered in the negative to the effect that the session is not stalled or that the stall has not ended then at step a further question is asked as to whether the session has ended. If this question is answered in the affirmative then the session ends at step . If however it is answered in the negative then at step any change in application requirements received from the client via real time data server is processed and at step any received network conditions update is processed to change the level of service if necessary. Control is then returned to step .

Although this process is described here in terms of a single client and session the skilled user will appreciate that step involves application server performing these steps for every session.

Thus on a selective update transactional messages are all sent whereas only the newest streamed data is sent in order to avoid overloading the network and the client.

As described with respect to the real time data server periodically supplies to application server updates of certain network condition indicators which in this example comprise the current effective bandwidth given by the amount of data being sent per second the amount of data in one or more buffers and the current round trip time. In this sense network includes the real time data server and the client as well as the Internet mobile telephony network or LAN or any other networks in between. The values of these indicators provide to the application server information regarding the amount of data that can be sent to this client. The applications to then use this information to determine how much information of what type should be sent and at what speed.

Graph shows how a stock prices application could increase the interval between sending messages as the amount of data in the buffers increases. The application can then supersede data that is waiting to be sent with a newer update to the same data and amalgamate messages if necessary. This is an example of how the level of service sets the amount of data sent.

Graph shows how an exchange rate application could stop sending updates altogether if the connection latency is too high send only some exchange rates if the connection latency is about normal and send all the rates that the user is interested in if the latency gets very low. This could be valuable if the user has indicated that he does not want to trade on and is therefore not interested in certain exchange rates if the latency is known to be above a certain threshold. This is an example of how the amount and type of data sent could be set by the level of service.

These graphs are only examples of ways in which network condition indicators could be used to vary the level of service. The exact way in which the level of service varies depends upon the application requirements of the user the particular type of application the data that the application supplies and so on. Also although these graphs indicate thresholds and linear correlations the network conditions could be used so that an increase or decrease in a value triggers an increase or decrease in level of service such that a particular value does not necessarily indicate a particular level of service. The values of two or more network condition indicators could be combined to indicate whether the level of service should increase or decrease. Additionally the application manager could make the necessity to consider network conditions more binding on some applications than others.

Thus MTP provides an additional advantage over other protocols. Because of its management of transmission rate as described with reference to networks with high bandwidth and low latency are used just as effectively as those with low bandwidth and high latency but if network conditions are better then more information is sent. Thus if for example the user of PDA moves into transmission range of WiFi gateway and the PDA detects this and starts using WiFi instead of a telecoms network not only does the session maintenance described with reference to enable the session to be continued seamlessly over the higher capacity network but the user may immediately perceive a higher level of service depending upon the application being used. Thus the protocol makes the best possible use of low bandwidth and high latency connections but also provides high bandwidth low latency users with a high level of service and perceived functionality.

At this point or if the question asked at step is answered in the negative the instructions are executed at step . Instructions for other applications on PDA are executed at step . At step the PDA is switched off.

Web browser instructions and email client instructions are provided. These applications could also use MTP to communicate via the real time application provider . RTDP can forward information from and to a third party using TCP and from and to a terminal using MTP. This emphasises that the protocol described herein for providing real time data could be used for communication of many types.

Session data includes segment buffers priority buffer and state variables as shown for session data in . Real time application data is data used by the application instructions and user account data comprises the user s password name billing details and so on. Other data includes data used by the operating system and other applications.

Since MTP is a substantially symmetrical protocol there is no need to describe in detail much of the real time application instructions executed at step . Datagrams are produced transmitted and received in substantially the same way as the processes described with reference to . Thus as shown in step where the client runs the application instructions comprises the following processes running substantially in parallel. Process transmits datagrams from the client to the real time data server . It comprises two separate processes datagram preparation and output buffer processing . Processes and are substantially identical to processes and respectively.

Process receives datagrams from the real time data server and comprises three separate processes datagram reception transactional datagram processing and streamed datagram processing . These processes are substantially identical to processes and respectively.

Process performs background processing. This is similar to process except that process has no step corresponding to step at which the real time data server informs the application server of the network conditions. The only substantial difference between the client and the server is that the client does not perform a process corresponding to session maintenance .

An additional difference is that in general a session will be requested and terminated by the user of PDA .

Datagram reception process includes step at which a resend latency value is calculated and background processing includes step at which a heartbeat rate is negotiated. These steps correspond to steps and respectively. Although the facility for these steps exists on both the real time data server and PDA in practice in this embodiment it is only PDA that uses them. They are thus described in and respectively.

In the original datagram is transmitted and fails to be delivered. After a time either through a lack of acknowledgement or a negative acknowledge the real time data server will resend the datagram. The resent datagram is also lost. A third attempt is successful.

Each datagram contains an elapsed time field . In datagram this is set to zero. In datagram it is the difference between the transmission time of datagram and the transmission time of datagram similarly for datagram . Thus for example the elapsed time field for datagram is 421 milliseconds.

When a resent datagram is received the resend latency is recalculated using a smoothing filter on the elapsed time. If no datagrams are received at all then the resend latency is gradually increased. This occurs in this embodiment once a heartbeat period has passed with no receipt of datagrams. However receipt of any datagram including transactional datagrams and empty streamed datagrams will at this point decrease the latency since it implies that the reason for non receipt of streamed data may be that there is no data to send and thus the last received updates may still be current.

The resend latency is added to the connection latency to give the application latency. This is the actual time delay of the data displayed to the user on PDA . Thus the timeliness of the data according to a function of the length of time taken to reach the client and the possible number of resends it required is displayed to the user to allow him to make a decision regarding whether or not to use the data. Optionally when the application latency falls below a certain threshold the screen may grey out and transactions may be suspended.

Since latency measurements are sent at the heartbeat rate the latency is more accurate when the heartbeat is faster. This means that when the user is for example trading the heartbeat should be fast whereas when he is browsing news stories the heartbeat should be slow. Thus the heartbeat negotiation is triggered by events that occur when the PDA switches applications minimises or maximised applications or enters a particular state in an application.

At step a new heartbeat rate is requested by sending a datagram that has SYN field set and a number in acknowledgement number field but does not have ACK field set. At step a question is asked as to whether the heartbeat rate has been agreed by receiving an acknowledgement of this datagram. If this question is answered in the negative then the heartbeat rate is not changed. Alternatively if the heartbeat rate is agreed the rate is changed at step .

Associated with this is the possibility that the client may at any time change its application requirements. For example on minimising of the display of stock prices the client may using a transactional datagram change its application requirements to stop the transmission of stock prices. On using the telephone which requires as much bandwidth as possible the client may change its application requirements to cease all transmission of streamed data. When the user returns to the display of stocks then the application requirements can be changed again to indicate that the default requirements apply. However even when no streamed data is being sent the client and server continue to send latency measurements at the agreed heartbeat rate. This indicates not only that the connection is still active but allows an immediate display of latency when the user returns to the display of streamed data.

As may be recalled from the discussion above protocols such as embodiments of the MTP may be useful in the implementation of effective reliable and general purpose solutions for reducing the effects of network latency in data transfers. Embodiments of such systems and methods may utilize a protocol module deployed on a computing device where the protocol module may be configured to receive data from an application and send that data using a particular protocol. Specifically in one embodiment the protocol module may provide a set of interfaces such as Application Programming Interfaces API or the like and the application may utilize these interfaces to provide the data to be sent to the protocol module. The protocol module may then send the data using a protocol. Alternatively the application may be configured to send the data using a first protocol and the protocol module may receive the data in the first protocol and send the data using a second protocol. The protocol used by the protocol module may be resistant to latency on the network.

For example the data to be sent by the application may be in a particular protocol such a hypertext transfer protocol HTTP Transport Control Protocol TCP or another protocol entirely such that the data received from application in an original protocol may be tunneled over the protocol used by the protocol module. The protocol module may for example utilize the Mobile Transport Protocol MTP as discussed above.

Accordingly embodiments may be utilized in a wide variety of contexts and in conjunction with a wide variety of computing devices and environments. For example while embodiments may be usefully applied to an environment with users at a mobile or desktop computing device that communicates with a platform other embodiments may also be usefully applied to other environments without loss of generality.

Platform may include one or more content provisioning modules accessible at one or more locations e.g. IP addresses or domain names or through one or more interfaces. The modules of a particular platform may be deployed on physical computing devices residing at a particular location such as those associated with the provider of a particular mobile application or may be deployed in a cloud. Thus when a platform is deployed in the cloud one or more content provisioning modules may be executing on a virtual machine provided in the cloud where the virtual machine is addressable at a single or more location s .

Regardless of the location of the platform the content provisioning module of a platform may support access from a computing device . In other words users at computing devices may use their computing device to access content provisioning module using for example an application on the computing device . Application may be for example a browser or other application on the computing device a proprietary application on computing device a generic interface etc.

In response to such access content provisioning module may provide data to the accessing computing device or application . This data may include data obtained from a location on the network e.g. over the Internet documents including for example files in a proprietary format e.g. Adobe.pdf Microsoft Word Excel Power Point files in a generic open format e.g. mp3 mpeg jpeg etc. files in a markup language XML HTML etc. or practically any other type of data. Thus for example content provisioning module may provide data to support application being used by a user at computing device a content management application supporting access control and management of documents etc.

As discussed above in many cases it is desired to reduce the effects of network latency e.g. on network in data transfers. Accordingly in certain embodiments computing device may include protocol module and platform may include platform protocol module where protocol module and platform protocol module are configured to communicate according to a protocol that may address such latency issues. Such a protocol may be for example the MTP as described above.

It will be understood here that while application and protocol module have been depicted separately here in some embodiments application and protocol module may form a single module multiple modules may be distributed etc. Similarly with respect to the content provisioning module and the platform protocol module while they have been depicted separately here in some embodiments they may form a single module multiple modules may be distributed etc. It should also be noted that while platform protocol module and protocol module have been depicted differently herein these may the same types of protocol module.

In certain embodiments then protocol module deployed on a computing device may be configured to receive data from application and send that data to the platform protocol module using the protocol e.g. MTP and platform protocol module may be configured to receive such data according to the protocol provide the data to content provisioning module receive data to return to the application and send this data to the protocol module according to the protocol. Protocol module may be configured to receive data according to the protocol and provide the data to application .

Specifically in one embodiment the protocol module may provide a set of interfaces such as Application Programming Interfaces API or the like and the application may utilize these interfaces to provide the data to be sent to the protocol module . The protocol module may then send the data using the protocol. Alternatively the application may be configured to send the data using a first protocol and the protocol module may receive the data in the first protocol and send the data using a second protocol.

Moving now to one embodiment of a topology for sending data according to a protocol where a protocol module is deployed as a plug in to an application is depicted. In the embodiment depicted computing device is connected to platform over network . Platform may include content provisioning module accessible at one or more locations.

Here computing device may include a protocol module and platform may include platform protocol module where the protocol module and platform protocol module are configured to communicate according to a protocol that may address latency issues. Again such a protocol may be for example the MTP.

Specifically in the embodiment depicted the protocol module may be protocol plug in module that has been included as a plug in to application deployed on computing device . For example the protocol plug in module may have been included in the application during development of the application itself or may have been downloaded and installed in conjunction with the application by a user of the computing device during or after installation of application etc.

Accordingly the protocol plug in module may receive data to be sent e.g. to content provisioning module from application . Such data may receive for example through an API provided by the protocol plug in or used by application . Such an API may for example be a proprietary API an open API an API which emulates an interface offered by another type of protocol e.g. a protocol different than the one which protocol plug in module and platform protocol module are configured to utilized to send data etc. Other methods may also be utilized by protocol plug in module to receive data from application to be sent.

Protocol plug in module may send data to platform protocol module at the platform using the protocol . Platform protocol module may receive the data according to the protocol and provide the data to content provisioning module . Similarly then platform protocol module may receive data from content provisioning module to be sent to application at computing device . Platform protocol module may send data to protocol plug in module of application at the computing device using the protocol . Protocol plug in module may receive the data according to the protocol and provide the data to application .

Thus in the embodiment depicted content provisioning module and application may exhibit increased tolerance to latency as data sent between content provisioning module and application may be sent using a latency tolerant protocol implemented by protocol plug in module and platform protocol module . Additionally as all data between content provisioning module and application may be sent by protocol plug in module and platform protocol module all such data may be sent using a VPN implemented by protocol plug in module and platform protocol module . Furthermore such data may easily be encrypted and decrypted by protocol plug in module and platform protocol module providing additional measure of security to the sending of such data .

Looking at one embodiment of a topology for sending data according to a protocol where a protocol module is deployed as an application is depicted. In the embodiment depicted computing device is connected to platform over a network . Platform may include content provisioning module accessible at one or more locations.

Here computing device may include a protocol module and platform may include platform protocol module where the protocol module and platform protocol module are configured to communicate according to a protocol that may address latency issues such as for example the MTP.

Specifically in the embodiment depicted the protocol module may be protocol application that has been deployed on computing device . For example the protocol application may have been installed on the device by a user of the device a provider of the device included with an operating system of the device etc. Protocol application may be configured to receive data to be sent by application on the device when executing. It will be noted that protocol application may be activated automatically when device is started or when any or a particular application is started etc. Protocol application may also be manually executed by a user of the device .

In certain embodiments protocol application may emulate one or more interfaces e.g. APIs calls etc. typically by another type of protocol e.g. TCP IP UDP etc. such that use of those interfaces by application will result in protocol application receiving data to be sent using those interfaces. In certain cases then protocol application may be included as part of a protocol stack e.g. as part of the operating system on device . Other methods may also be utilized by protocol application to receive data from application to be sent.

It will be noted here that as protocol application may emulate interfaces used by various protocols protocol application may receive data to be sent by all applications executing on device regardless of the destination of such data e.g. even if such data is not intended for platform or content provisioning module .

Accordingly the protocol application may receive data to be sent e.g. to content provisioning module or another location from application . Protocol application may send data to platform protocol module at the platform using the protocol . Platform protocol module may receive the data according to the protocol and determine the destination of such data as intended by application . If the data is intended for content provisioning module the platform protocol module may provide the data to content provisioning module . If the data is intended for a location other than content provisioning module the data may be sent to the intended by application location over network where the data may be sent over the network according to the protocol intended by application .

Similarly then platform protocol module may receive data from content provisioning module to be sent to application at computing device . Platform protocol module may send data to protocol application of application at the computing device using the protocol . Protocol application may receive the data according to the protocol and provide the data to application .

As can be seen then in certain embodiments protocol application and platform protocol module may be configured such that substantially all network traffic from applications on device may be sent to platform protocol module according to protocol . As such network latency experienced by a variety of applications on device may be reduced significantly especially in such instances where network latency may be attributable to the position or functioning of device .

Additionally in embodiments such as these as substantially all data from applications on the device may pass through platform protocol module platform protocol module may be a desirable place to implement access controls or other types of security measures. Accordingly in certain embodiments platform protocol module may implement authentication of users restrictions for internet or file access or almost any other type of access controls or security desired with respect to applications on device . Moreover as all network traffic may be sent through and received from the protocol application and the platform protocol module a VPN network can be implemented between the device and the platform using the protocol application and the platform protocol module in a latency tolerant protocol e.g. MTP .

As may be imagined in certain cases a platform protocol module may receive a great deal of network traffic from a large number of devices. Thus in some embodiments it may be desirable to implement a platform protocol module in an efficient manner. depicts one embodiments of a one embodiment of a topology for sending data according to a protocol where a protocol platform protocol module is deployed as a proxy.

In the embodiment depicted computing device is connected to proxy over network . Proxy may be one or more proxy servers deployed at a particular location in the cloud etc. Proxy platform protocol module may be deployed on proxy . Platform may be connected to proxy such that communication to and from platform pass through . Platform may include content provisioning module associated with one or more locations.

Proxy platform protocol module at proxy and protocol application are configured to communicate according to a protocol that may address latency issues e.g. MTP . Specifically protocol application is deployed on computing device . In one embodiment protocol application may receive data to be sent by all applications executing on device regardless of the destination of such data e.g. even if such data is not intended for platform or content provisioning module .

Accordingly the protocol application may receive data to be sent e.g. to content provisioning module or another location from application . Protocol application may send data to proxy platform protocol module at proxy the using the protocol . Proxy platform protocol module at proxy may receive the data according to the protocol and determine the destination of such data as intended by application . If the data is intended for content provisioning module on platform the proxy platform protocol module may provide the data to content provisioning module at platform . If the data is intended for a location other than content provisioning module the data may be sent to the intended by application location over network where the data may be sent over the network according to the protocol intended by application .

Similarly then proxy platform protocol module at proxy may receive data from content provisioning module to be sent to application at computing device . Proxy platform protocol module may send data to protocol application of application at the computing device using the protocol . Protocol application may receive the data according to the protocol and provide the data to application .

As proxy may be separate from platform and can be distributed load balanced etc. such an architecture may efficiently implement proxy platform protocol module and additionally allow implementation of a wide variety of functionality e.g. access controls or other types of security measures in an efficient manner.

Turning now to and referring first to one embodiment of a method for sending data from a computing device according to a protocol is depicted. At step data to be sent is received. As discussed this data may be received at a protocol module on a computing device from an application executing on the computing device. Such a protocol module may be for example a protocol plug in module integrated into e.g. as a library or forming a part of the application whereby when such an application is deployed on a computing device the protocol module is likewise deployed on the computing device in conjunction with the application. In other cases a protocol module may form part of a separate protocol application such that it may receive data from one or more applications concurrently executing on a computing device. When these applications send data e.g. in a first protocol the protocol application may receive this data e.g. by intercepting the data emulating an interface of the first protocol etc. .

Specifically in one embodiment a protocol module may provide a set of interfaces such as an API or the like and the application may utilize these interfaces to provide the data to be sent to the protocol module. Thus data may be received from the application through an interface associated with a protocol different the protocol that will be used by the protocol module to send such data.

The received data may be then formatted according a protocol used by the protocol module at step . Such a protocol may be a latency tolerant protocol. For example in one embodiment the protocol may be the Mobile Transport Protocol MTP as described above. The data may then be sent according this protocol at step . The data may be sent to a destination specified by the application when sending the data or may be sent to a destination associated with the protocol module. Specifically in one embodiment the protocol module may send the data to a platform protocol module at a platform. Such a platform protocol module may be associated with a platform that supports the application and thus may be associated with a destination to which the application intended to send the data or a platform protocol module that is associated with the protocol module and that may not be associated with the destination to which the application intended to send the data.

Moving to one embodiment of a method for receiving data sent from a computing device according to a protocol is depicted. At step data sent by a protocol module on a computing device may be received by a platform protocol module according to a particular protocol utilized by both the platform protocol module and the protocol module e.g. MTP . The platform protocol module may for example form part of a content provisioning or other module at a platform utilized by an application on the computing device or may be configured to implement the protocol in conjunction with a proxy such that the platform protocol module may communicate with the protocol module on the computing device according to the protocol to receive the data as sent by the protocol module on the computing device. At step the data sent via the protocol may be may be determined and provided to a content provisioning module at step .

In the foregoing specification embodiments have been described with reference to specific embodiments. However one of ordinary skill in the art appreciates that various modifications and changes can be made without departing from the scope of embodiments. Accordingly the specification and figures are to be regarded in an illustrative rather than a restrictive sense and all such modifications are intended to be included within the scope of embodiments.

Although embodiments have been described with respect to specific embodiments thereof these embodiments are merely illustrative and not restrictive of the embodiments. The description herein of illustrated embodiments of embodiments is not intended to be exhaustive or to limit embodiments to the precise forms disclosed herein and in particular the inclusion of any particular embodiment feature or function is not intended to limit the scope of embodiments to such embodiment feature or function . Rather the description is intended to describe illustrative embodiments features and functions in order to provide a person of ordinary skill in the art context to understand embodiments without limiting embodiments to any particularly described embodiment feature or function. While specific embodiments of and examples for embodiments are described herein for illustrative purposes only various equivalent modifications are possible within the spirit and scope of embodiments as those skilled in the relevant art will recognize and appreciate. As indicated these modifications may be made to embodiments in light of the foregoing description of illustrated embodiments of embodiments and are to be included within the spirit and scope of the embodiments. Thus while described herein with reference to particular embodiments thereof a latitude of modification various changes and substitutions are intended in the foregoing disclosures and it will be appreciated that in some instances some features of embodiments will be employed without a corresponding use of other features without departing from the scope and spirit as set forth. Therefore many modifications may be made to adapt a particular situation or material to the essential scope and spirit of embodiments.

Reference throughout this specification to one embodiment an embodiment or a specific embodiment or similar terminology means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment and may not necessarily be present in all embodiments. Thus respective appearances of the phrases in one embodiment in an embodiment or in a specific embodiment or similar terminology in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures or characteristics of any particular embodiment may be combined in any suitable manner with one or more other embodiments. It is to be understood that other variations and modifications of the embodiments described and illustrated herein are possible in light of the teachings herein and are to be considered as part of the spirit and scope of embodiments.

In the description herein numerous specific details are provided such as examples of components and or methods to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that an embodiment may be able to be practiced without one or more of the specific details or with other apparatus systems assemblies methods components materials parts and or the like. In other instances well known structures components systems materials or operations are not specifically shown or described in detail to avoid obscuring aspects of embodiments. While embodiments may be illustrated by using a particular embodiment this is not and does not limit the disclosure to any particular embodiment and a person of ordinary skill in the art will recognize that additional embodiments are readily understandable and are a part of this disclosure.

Any suitable programming language can be used to implement the routines methods or programs of embodiments described herein including C C Java assembly language etc. Different programming techniques can be employed such as procedural or object oriented. Any particular routine can execute on a single computer processing device or multiple computer processing devices a single computer processor or multiple computer processors. Data may be stored in a single storage medium or distributed through multiple storage mediums and may reside in a single database or multiple databases or other data storage techniques . Although the steps operations or computations may be presented in a specific order this order may be changed in different embodiments. In some embodiments to the extent multiple steps are shown as sequential in this specification some combination of such steps in alternative embodiments may be performed at the same time. The sequence of operations described herein can be interrupted suspended or otherwise controlled by another process such as an operating system kernel etc. The routines can operate in an operating system environment or as stand alone routines. Functions routines methods steps and operations described herein can be performed in hardware software firmware or any combination thereof.

Embodiments described herein can be implemented in the form of control logic in software or hardware or a combination of both. The control logic may be stored in an information storage medium such as a computer readable medium as a plurality of instructions adapted to direct an information processing device to perform a set of steps disclosed in the various embodiments. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement embodiments.

It is also within the spirit and scope of the embodiments to implement in software programming or of the steps operations methods routines or portions thereof described herein where such software programming or code can be stored in a computer readable medium and can be operated on by a processor to permit a computer to perform any of the steps operations methods routines or portions thereof described herein. The embodiments may be implemented by using software programming or code in one or more general purpose digital computers by using application specific integrated circuits programmable logic devices field programmable gate arrays optical chemical biological quantum or nanoengineered systems components and mechanisms may be used. In general the functions of embodiments can be achieved by any means as is known in the art. For example distributed or networked systems components and circuits can be used. In another example communication or transfer or otherwise moving from one place to another of data may be wired wireless or by any other means.

A computer readable medium may be any medium that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus system or device. The computer readable medium can be by way of example only but not by limitation an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus system device propagation medium or computer memory. Such computer readable medium shall generally be machine readable and include software programming or code that can be human readable e.g. source code or machine readable e.g. object code .

A processor includes any hardware system mechanism or component that processes data signals or other information. A processor can include a system with a general purpose central processing unit multiple processing units dedicated circuitry for achieving functionality or other systems. Processing need not be limited to a geographic location or have temporal limitations. For example a processor can perform its functions in real time offline in a batch mode etc. Portions of processing can be performed at different times and at different locations by different or the same processing systems.

It will also be appreciated that one or more of the elements depicted in the drawings figures can also be implemented in a more separated or integrated manner or even removed or rendered as inoperable in certain cases as is useful in accordance with a particular application. Additionally any signal arrows in the drawings figures should be considered only as exemplary and not limiting unless otherwise specifically noted.

Furthermore the term or as used herein is generally intended to mean and or unless otherwise indicated. As used herein a term preceded by a or an and the when antecedent basis is a or an includes both singular and plural of such term i.e. that the reference a or an clearly indicates only the singular or only the plural . Also as used in the description herein the meaning of in includes in and on unless the context clearly dictates otherwise.

Benefits other advantages and solutions to problems have been described above with regard to specific embodiments. However the benefits advantages solutions to problems and any component s that may cause any benefit advantage or solution to occur or become more pronounced are not to be construed as a critical required or essential feature or component.

