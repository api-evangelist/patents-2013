---

title: System and method for cleaning noisy genetic data from target individuals using genetic data from genetically related individuals
abstract: A system and method for determining the genetic data for one or a small set of cells, or from fragmentary DNA, where a limited quantity of genetic data is available, are disclosed. Genetic data for the target individual is acquired and amplified using known methods, and poorly measured base pairs, missing alleles and missing regions are reconstructed using expected similarities between the target genome and the genome of genetically related subjects. In accordance with one embodiment of the invention, incomplete genetic data is acquired from embryonic cells, fetal cells, or cell-free fetal DNA isolated from the mother's blood, and the incomplete genetic data is reconstructed using the more complete genetic data from a larger sample diploid cells from one or both parents, with or without genetic data from haploid cells from one or both parents, and/or genetic data taken from other related individuals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09424392&OS=09424392&RS=09424392
owner: Natera, Inc.
number: 09424392
owner_city: San Carlos
owner_country: US
publication_date: 20130311
---
This application is a continuation of U.S. Utility application Ser. No. 11 603 406 filed Nov. 22 2006 which claims the benefit under 35 U.S.C. 119 e of the following U.S. Provisional Patent Applications Ser. No. 60 739 882 filed Nov. 26 2005 Ser. No. 60 742 305 filed Dec. 6 2005 Ser. No. 60 754 396 filed Dec. 29 2005 Ser. No. 60 774 976 filed Feb. 21 2006 Ser. No. 60 789 506 filed Apr. 4 2006 Ser. No. 60 817 741 filed Jun. 30 2006 and Ser. No. 60 846 610 filed Sep. 22 2006 the disclosures thereof are each incorporated by reference herein in their entirety.

The invention relates generally to the field of acquiring manipulating and using genetic data for medically predictive purposes and specifically to a system in which imperfectly measured genetic data is made more precise by using known genetic data of genetically related individuals thereby allowing more effective identification of genetic irregularities that could result in various phenotypic outcomes.

Current methods of prenatal diagnosis can alert physicians and parents to abnormalities in growing fetuses. Without prenatal diagnosis one in 50 babies is born with serious physical or mental handicap and as many as one in 30 will have some form of congenital malformation. Unfortunately standard methods require invasive testing and carry a roughly 1 percent risk of miscarriage. These methods include amniocentesis chorion villus biopsy and fetal blood sampling. Of these amniocentesis is the most common procedure in 2003 it was performed in approximately 3 of all pregnancies though its frequency of use has been decreasing over the past decade and a half. A major drawback of prenatal diagnosis is that given the limited courses of action once an abnormality has been detected it is only valuable and ethical to test for very serious defects. As result prenatal diagnosis is typically only attempted in cases of high risk pregnancies where the elevated chance of a defect combined with the seriousness of the potential abnormality outweighs the risks. A need exists for a method of prenatal diagnosis that mitigates these risks.

It has recently been discovered that cell free fetal DNA and intact fetal cells can enter maternal blood circulation. Consequently analysis of these cells can allow early Non Invasive Prenatal Genetic Diagnosis NIPGD . A key challenge in using NIPGD is the task of identifying and extracting fetal cells or nucleic acids from the mother s blood. The fetal cell concentration in maternal blood depends on the stage of pregnancy and the condition of the fetus but estimates range from one to forty fetal cells in every milliliter of maternal blood or less than one fetal cell per 100 000 maternal nucleated cells. Current techniques are able to isolate small quantities of fetal cells from the mother s blood although it is very difficult to enrich the fetal cells to purity in any quantity. The most effective technique in this context involves the use of monoclonal antibodies but other techniques used to isolate fetal cells include density centrifugation selective lysis of adult erythrocytes and FACS. Fetal DNA isolation has been demonstrated using PCR amplification using primers with fetal specific DNA sequences. Since only tens of molecules of each embryonic SNP are available through these techniques the genotyping of the fetal tissue with high fidelity is not currently possible.

Much research has been done towards the use of pre implantation genetic diagnosis PGD as an alternative to classical prenatal diagnosis of inherited disease. Most PGD today focuses on high level chromosomal abnormalities such as aneuploidy and balanced translocations with the primary outcomes being successful implantation and a take home baby. A need exists for a method for more extensive genotyping of embryos at the pre implantation stage. The number of known disease associated genetic alleles is currently at 389 according to OMIM and steadily climbing. Consequently it is becoming increasingly relevant to analyze multiple embryonic SNPs that are associated with disease phenotypes. A clear advantage of pre implantation genetic diagnosis over prenatal diagnosis is that it avoids some of the ethical issues regarding possible choices of action once undesirable phenotypes have been detected.

Many techniques exist for isolating single cells. The FACS machine has a variety of applications one important application is to discriminate between cells based on size shape and overall DNA content. The FACS machine can be set to sort single cells into any desired container. Many different groups have used single cell DNA analysis for a number of applications including prenatal genetic diagnosis recombination studies and analysis of chromosomal imbalances. Single sperm genotyping has been used previously for forensic analysis of sperm samples to decrease problems arising from mixed samples and for single cell recombination studies.

Isolation of single cells from human embryos while highly technical is now routine in in vitro fertilization clinics. To date the vast majority of prenatal diagnoses have used fluorescent in situ hybridization FISH which can determine large chromosomal aberrations such as Down syndrome or trisomy 21 and PCR electrophoresis which can determine a handful of SNPs or other allele calls. Both polar bodies and blastomeres have been isolated with success. It is critical to isolate single blastomeres without compromising embryonic integrity. The most common technique is to remove single blastomeres from day 3 embryos 6 or 8 cell stage . Embryos are transferred to a special cell culture medium standard culture medium lacking calcium and magnesium and a hole is introduced into the zona pellucida using an acidic solution laser or mechanical drilling. The technician then uses a biopsy pipette to remove a single visible nucleus. Clinical studies have demonstrated that this process does not decrease implantation success since at this stage embryonic cells are undifferentiated.

There are three major methods available for whole genome amplification WGA ligation mediated PCR LM PCR degenerate oligonucleotide primer PCR DOP PCR and multiple displacement amplification MDA . In LM PCR short DNA sequences called adapters are ligated to blunt ends of DNA. These adapters contain universal amplification sequences which are used to amplify the DNA by PCR. In DOP PCR random primers that also contain universal amplification sequences are used in a first round of annealing and PCR. Then a second round of PCR is used to amplify the sequences further with the universal primer sequences. Finally MDA uses the phi 29 polymerase which is a highly processive and non specific enzyme that replicates DNA and has been used for single cell analysis. Of the three methods DOP PCR reliably produces large quantities of DNA from small quantities of DNA including single copies of chromosomes. On the other hand MDA is the fastest method producing hundred fold amplification of DNA in a few hours. The major limitations to amplification material from a single cells are 1 necessity of using extremely dilute DNA concentrations or extremely small volume of reaction mixture and 2 difficulty of reliably dissociating DNA from proteins across the whole genome. Regardless single cell whole genome amplification has been used successfully for a variety of applications for a number of years.

There are numerous difficulties in using DNA amplification in these contexts. Amplification of single cell DNA or DNA from a small number of cells or from smaller amounts of DNA by PCR can fail completely as reported in 5 10 of the cases. This is often due to contamination of the DNA the loss of the cell its DNA or accessibility of the DNA during the PCR reaction. Other sources of error that may arise in measuring the embryonic DNA by amplification and microarray analysis include transcription errors introduced by the DNA polymerase where a particular nucleotide is incorrectly copied during PCR and microarray reading errors due to imperfect hybridization on the array. The biggest problem however remains allele drop out ADO defined as the failure to amplify one of the two alleles in a heterozygous cell. ADO can affect up to more than 40 of amplifications and has already caused PGD misdiagnoses. ADO becomes a health issue especially in the case of a dominant disease where the failure to amplify can lead to implantation of an affected embryo. The need for more than one set of primers per each marker in heterozygotes complicate the PCR process. Therefore more reliable PCR assays are being developed based on understanding the ADO origin. Reaction conditions for single cell amplifications are under study. The amplicon size the amount of DNA degradation freezing and thawing and the PCR program and conditions can each influence the rate of ADO.

All those techniques however depend on the minute DNA amount available for amplification in the single cell. This process is often accompanied by contamination. Proper sterile conditions and microsatellite sizing can exclude the chance of contaminant DNA as microsatellite analysis detected only in parental alleles exclude contamination. Studies to reliably transfer molecular diagnostic protocols to the single cell level have been recently pursued using first round multiplex PCR of microsatellite markers followed by real time PCR and microsatellite sizing to exclude chance contamination. Multiplex PCR allows for the amplification of multiple fragments in a single reaction a crucial requirement in the single cell DNA analysis. Although conventional PCR was the first method used in PGD fluorescence in situ hybridization FISH is now common. It is a delicate visual assay that allows the detection of nucleic acid within undisturbed cellular and tissue architecture. It relies firstly on the fixation of the cells to be analyzed. Consequently optimization of the fixation and storage condition of the sample is needed especially for single cell suspensions.

Advanced technologies that enable the diagnosis of a number of diseases at the single cell level include interphase chromosome conversion comparative genomic hybridization CGH fluorescent PCR and whole genome amplification. The reliability of the data generated by all of these techniques rely on the quality of the DNA preparation. PGD is also costly consequently there is a need for less expensive approaches such as mini sequencing. Unlike most mutation detection techniques mini sequencing permits analysis of very small DNA fragments with low ADO rate. Better methods for the preparation of single cell DNA for amplification and PGD are therefore needed and are under study. The more novel microarrays and comparative genomic hybridization techniques still ultimately rely on the quality of the DNA under analysis.

Several techniques are in development to measure multiple SNPs on the DNA of a small number of cells a single cell for example a blastomere a small number of chromosomes or from fragments of DNA. There are techniques that use Polymerase Chain Reaction PCR followed by microarray genotyping analysis. Some PCR based techniques include whole genome amplification WGA techniques such as multiple displacement amplification MDA and MOLECULAR INVERSION PROBES MIPs that perform genotyping using multiple tagged oligonucleotides that may then be amplified using PCR with a singe pair of primers. An example of a non PCR based technique is fluorescence in situ hybridization FISH . It is apparent that the techniques will be severely error prone due to the limited amount of genetic material which will exacerbate the impact of effects such as allele drop outs imperfect hybridization and contamination.

Many techniques exist which provide genotyping data. TAQMAN is a unique genotyping technology produced and distributed by Applied Biosystems. TAQMAN uses polymerase chain reaction PCR to amplify sequences of interest. During PCR cycling an allele specific minor groove binder MGB probe hybridizes to amplified sequences. Strand synthesis by the polymerase enzymes releases reporter dyes linked to the MGB probes and then the TAQMAN optical readers detect the dyes. In this manner TAQMAN achieves quantitative allelic discrimination. Compared with array based genotyping technologies TAQMAN is quite expensive per reaction 0.40 reaction and throughput is relatively low 384 genotypes per run . While only 1 ng of DNA per reaction is necessary thousands of genotypes by TAQMAN requires microgram quantities of DNA so TAQMAN does not necessarily use less DNA than microarrays. However with respect to the IVF genotyping workflow TAQMAN is the most readily applicable technology. This is due to the high reliability of the assays and most importantly the speed and ease of the assay 3 hours per run and minimal molecular biological steps . Also unlike many array technologies such as 500 k AFFMETRIX arrays TAQMAN is highly customizable which is important for the IVF market. Further TAQMAN is highly quantitative so anueploidies could be detected with this technology alone.

ILLUMINA has recently emerged as a leader in high throughput genotyping. Unlike AFFMETRIX ILLUMINA genotyping arrays do not rely exclusively on hybridization. Instead ILLUMINA technology uses an allele specific DNA extension step which is much more sensitive and specific than hybridization alone for the original sequence detection. Then all of these alleles are amplified in multiplex by PCR and then these products hybridized to bead arrays. The beads on these arrays contain unique address tags not native sequence so this hybridization is highly specific and sensitive. Alleles are then called by quantitative scanning of the bead arrays. The Illlumina GOLDEN GATE assay system genotypes up to 1536 loci concurrently so the throughput is better than TAQMAN but not as high as AFFMETRIX 500 k arrays. The cost of ILLUMINA genotypes is lower than TAQMAN but higher than AFFMETRIX arrays. Also the ILLUMINA platform takes as long to complete as the 500 k AFFMETRIX arrays up to 72 hours which is problematic for IVF genotyping. However ILLUMINA has a much better call rate and the assay is quantitative so anueploidies are detectable with this technology. ILLUMINA technology is much more flexible in choice of SNPs than 500 k AFFMETRIX arrays.

One of the highest throughput techniques which allows for the measurement of up to 250 000 SNPs at a time is the AFFMETRIX GeneChip 500K genotyping array. This technique also uses PCR followed by analysis by hybridization and detection of the amplified DNA sequences to DNA probes chemically synthesized at different locations on a quartz surface. A disadvantage of these arrays are the low flexibility and the lower sensitivity. There are modified approaches that can increase selectivity such as the perfect match and mismatch probe approaches but these do so at the cost of the number of SNPs calls per array.

Pyrosequencing or sequencing by synthesis can also be used for genotyping and SNP analysis. The main advantages to pyrosequencing include an extremely fast turnaround and unambiguous SNP calls however the assay is not currently conducive to high throughput parallel analysis. PCR followed by gel electrophoresis is an exceedingly simple technique that has met the most success in preimplantation diagnosis. In this technique researchers use nested PCR to amplify short sequences of interest. Then they run these DNA samples on a special gel to visualize the PCR products. Different bases have different molecular weights so one can determine base content based on how fast the product runs in the gel. This technique is low throughput and requires subjective analyses by scientists using current technologies but has the advantage of speed 1 2 hours of PCR 1 hour of gel electrophoresis . For this reason it has been used previously for prenatal genotyping for a myriad of diseases including thalassaemia neurofibromatosis type 2 leukocyte adhesion deficiency type I Hallopeau Siemens disease sickle cell anemia retinoblastoma Pelizaeus Merzbacher disease Duchenne muscular dystrophy and Currarino syndrome.

Another promising technique that has been developed for genotyping small quantities of genetic material with very high fidelity is MOLECULAR INVERSION PROBES MIPs such as AFFMETRIX s GENFLEX Arrays. This technique has the capability to measure multiple SNPs in parallel more than 10 000 SNPS measured in parallel have been verified. For small quantities of genetic material call rates for this technique have been established at roughly 95 and accuracy of the calls made has been established to be above 99 . So far the technique has been implemented for quantities of genomic data as small as 150 molecules for a given SNP. However the technique has not been verified for genomic data from a single cell or a single strand of DNA as would be required for pre implantation genetic diagnosis.

The MIP technique makes use of padlock probes which are linear oligonucleotides whose two ends can be joined by ligation when they hybridize to immediately adjacent target sequences of DNA. After the probes have hybridized to the genomic DNA a gap fill enzyme is added to the assay which can add one of the four nucleotides to the gap. If the added nucleotide A C T G is complementary to the SNP under measurement then it will hybridize to the DNA and join the ends of the padlock probe by ligation. The circular products or closed padlock probes are then differentiated from linear probes by exonucleolysis. The exonuclease by breaking down the linear probes and leaving the circular probes will change the relative concentrations of the closed vs. the unclosed probes by a factor of 1000 or more. The probes that remain are then opened at a cleavage site by another enzyme removed from the DNA and amplified by PCR. Each probe is tagged with a different tag sequence consisting of 20 base tags 16 000 have been generated and can be detected for example by the AFFMETRIX GENFLEX Tag Array. The presence of the tagged probe from a reaction in which a particular gap fill enzyme was added indicates the presence of the complimentary amino acid on the relevant SNP.

The molecular biological advantages of MIPS include 1 multiplexed genotyping in a single reaction 2 the genotype call occurs by gap fill and ligation not hybridization and 3 hybridization to an array of universal tags decreases false positives inherent to most array hybridizations. In traditional 500K TAQMAN and other genotyping arrays the entire genomic sample is hybridized to the array which contains a variety of perfect match and mismatch probes and an algorithm calls likely genotypes based on the intensities of the mismatch and perfect match probes. Hybridization however is inherently noisy because of the complexities of the DNA sample and the huge number of probes on the arrays. MIPs on the other hand uses multiplex probes i.e. not on an array that are longer and therefore more specific and then uses a robust ligation step to circularize the probe. Background is exceedingly low in this assay due to specificity though allele dropout may be high due to poor performing probes .

When this technique is used on genomic data from a single cell or small numbers of cells it will like PCR based approaches suffer from integrity issues. For example the inability of the padlock probe to hybridize to the genomic DNA will cause allele dropouts. This will be exacerbated in the context of in vitro fertilization since the efficiency of the hybridization reaction is low and it needs to proceed relatively quickly in order to genotype the embryo in a limited time period. Note that the hybridization reaction can be reduced well below vendor recommended levels and micro fluidic techniques may also be used to accelerate the hybridization reaction. These approaches to reducing the time for the hybridization reaction will result in reduced data quality.

Once the genetic data has been measured the next step is to use the data for predictive purposes. Much research has been done in predictive genomics which tries to understand the precise functions of proteins RNA and DNA so that phenotypic predictions can be made based on genotype. Canonical techniques focus on the function of Single Nucleotide Polymorphisms SNP but more advanced methods are being brought to bear on multi factorial phenotypic features. These methods include techniques such as linear regression and nonlinear neural networks which attempt to determine a mathematical relationship between a set of genetic and phenotypic predictors and a set of measured outcomes. There is also a set of regression analysis techniques such as Ridge regression log regression and stepwise selection that are designed to accommodate sparse data sets where there are many potential predictors relative to the number of outcomes as is typical of genetic data and which apply additional constraints on the regression parameters so that a meaningful set of parameters can be resolved even when the data is underdetermined. Other techniques apply principal component analysis to extract information from undetermined data sets. Other techniques such as decision trees and contingency tables use strategies for subdividing subjects based on their independent variables in order to place subjects in categories or bins for which the phenotypic outcomes are similar. A recent technique termed logical regression describes a method to search for different logical interrelationships between categorical independent variables in order to model a variable that depends on interactions between multiple independent variables related to genetic data. Regardless of the method used the quality of the prediction is naturally highly dependant on the quality of the genetic data used to make the prediction.

Normal humans have two sets of 23 chromosomes in every diploid cell with one copy coming from each parent. Aneuploidy a cell with an extra or missing chromosomes and uniparental disomy a cell with two of a given chromosome that originate from one parent are believed to be responsible for a large percentage of failed implantations miscarriages and genetic diseases. When only certain cells in an individual are aneuploid the individual is said to exhibit mosaicism. Detection of chromosomal abnormalities can identify individuals or embryos with conditions such as Down syndrome Klinefelters syndrome and Turner syndrome among others in addition to increasing the chances of a successful pregnancy. Testing for chromosomal abnormalities is especially important as mothers age between the ages of 35 and 40 it is estimated that between 40 and 50 of the embryos are abnormal and above the age of 40 more than half of the embryos are abnormal.

Karyotyping the traditional method used for the prediction of aneuploides and mosaicism is giving way to other more high throughput more cost effective methods. One method that has attracted much attention recently is Flow cytometry FC and fluorescence in situ hybridization FISH which can be used to detect aneuploidy in any phase of the cell cycle. One advantage of this method is that it is less expensive than karyotyping but the cost is significant enough that generally a small selection of chromosomes are tested usually chromosomes 13 18 21 X Y also sometimes 8 9 15 16 17 22 in addition FISH has a low level of specificity. Using FISH to analyze 15 cells one can detect mosaicism of 19 with 95 confidence. The reliability of the test becomes much lower as the level of mosaicism gets lower and as the number of cells to analyze decreases. The test is estimated to have a false negative rate as high as 15 when a single cell is analysed. There is a great demand for a method that has a higher throughput lower cost and greater accuracy.

Listed here is a set of prior art which is related to the field of the current invention. None of this prior art contains or in any way refers to the novel elements of the current invention. In U.S. Pat. No. 6 720 140 Hartley et al describe a recombinational cloning method for moving or exchanging segments of DNA molecules using engineered recombination sites and recombination proteins. In U.S. Pat. No. 6 489 135 Parrott et al. provide methods for determining various biological characteristics of in vitro fertilized embryos including overall embryo health implantability and increased likelihood of developing successfully to term by analyzing media specimens of in vitro fertilization cultures for levels of bioactive lipids in order to determine these characteristics. In US Patent Application 20040033596 Threadgill et al. describe a method for preparing homozygous cellular libraries useful for in vitro phenotyping and gene mapping involving site specific mitotic recombination in a plurality of isolated parent cells. In U.S. Pat. No. 5 994 148 Stewart et al. describe a method of determining the probability of an in vitro fertilization IVF being successful by measuring Relaxin directly in the serum or indirectly by culturing granulosa lutein cells extracted from the patient as part of an IVF ET procedure. In U.S. Pat. No. 5 635 366 Cooke et al. provide a method for predicting the outcome of IVF by determining the level of 11 hydroxysteroid dehydrogenase 11 HSD in a biological sample from a female patient. In U.S. Pat. No. 7 058 616 Larder et al. describe a method for using a neural network to predict the resistance of a disease to a therapeutic agent. In U.S. Pat. No. 6 958 211 Vingerhoets et al. describe a method wherein the integrase genotype of a given HIV strain is simply compared to a known database of HIV integrase genotype with associated phenotypes to find a matching genotype. In U.S. Pat. No. 7 058 517 Denton et al. describe a method wherein an individual s haplotypes are compared to a known database of haplotypes in the general population to predict clinical response to a treatment. In U.S. Pat. No. 7 035 739 Schadt at al. describe a method is described wherein a genetic marker map is constructed and the individual genes and traits are analyzed to give a gene trait locus data which are then clustered as a way to identify genetically interacting pathways which are validated using multivariate analysis. In U.S. Pat. No. 6 025 128 Veltri et al. describe a method involving the use of a neural network utilizing a collection of biomarkers as parameters to evaluate risk of prostate cancer recurrence.

The cost of DNA sequencing is dropping rapidly and in the near future individual genomic sequencing for personal benefit will become more common. Knowledge of personal genetic data will allow for extensive phenotypic predictions to be made for the individual. In order to make accurate phenotypic predictions high quality genetic data is critical whatever the context. In the case of prenatal or pre implantation genetic diagnoses a complicating factor is the relative paucity of genetic material available. Given the inherently noisy nature of the measured genetic data in cases where limited genetic material is used for genotyping there is a great need for a method which can increase the fidelity of or clean the primary data.

The system disclosed enables the cleaning of incomplete or noisy genetic data using secondary genetic data as a source of information. While the disclosure focuses on genetic data from human subjects and more specifically on as yet not implanted embryos or implanted fetuses it should be noted that the methods disclosed apply to the genetic data of a range of organisms in a range of contexts. The techniques described for cleaning genetic data are most relevant in the context of pre implantation diagnosis during in vitro fertilization prenatal diagnosis in conjunction with amniocentesis chorion villus biopsy and fetal blood sampling and non invasive prenatal diagnosis where a small quantity of fetal genetic material is isolated from maternal blood. The diagnoses may focus on inheritable diseases increased likelihoods of defects or abnormalities as well as making phenotype predictions for individuals to enhance clinical and lifestyle decisions. The invention addresses the shortcomings of prior art that are discussed above.

In one aspect of the invention methods make use of imperfect knowledge of the genetic data of the mother and the father together with the knowledge of the mechanism of meiosis and the imperfect measurement of the embryonic DNA in order to reconstruct in silico the embryonic DNA at the location of key SNPs with a high degree of confidence. It is important to note that the parental data allows the reconstruction not only of SNPs that were measured poorly but also of insertions deletions and of SNPs or whole regions of DNA that were not measured at all.

The disclosed method is applicable in the context of in vitro fertilization where a very small number of blastomeres are available for genotyping from each embryo being considered for implantation. The disclosed method is equally applicable to the context of Non Invasive Prenatal Diagnosis NIPD where only a small number of fetal cells or fragments of fetal DNA have been isolated from the mother s blood. The disclosed method is more generally applicable in any case where a limited amount of genetic data is available from the target genome and additional genetic data is available from individuals who are genetically related to the target.

In one aspect of the invention the fetal or embryonic genomic data which has been reconstructed can be used to detect if the cell is aneuploid that is if fewer or more than two of a particular chromosome is present in a cell. A common example of this condition is trisomy 21 which gives rise to Down syndrome. The reconstructed data can also be used to detect for uniparental disomy a condition in which two of a given chromosome are present both of which originate from one parent. This is done by creating a set of hypotheses about the potential states of the DNA and testing to see which one has the highest probability of being true given the measured data. Note that the use of high throughput genotyping data for screening for aneuploidy enables a single blastomere from each embryo to be used both to measure multiple disease linked loci as well as screen for aneuploidy.

In another aspect of the invention the direct measurements of the amount of genetic material amplified or unamplified present at a plurality of loci can be used to detect for aneuploides or uniparental disomy. The idea behind this method is simply that the amount of genetic material present during amplification is proportional to the amount of genetic information in the initial sample and measuring these levels at multiple loci will give a statistically significant result.

In another aspect of the invention the disclosed method can clean genetic material of the individual which has been contaminated by foreign DNA or RNA by identifying the data generated by extraneous genetic materials. The spurious signals generated by the contaminating DNA can be recognized in a manner similar to that way that chromosome wide anomalous signals generated by aneuploides can be detected.

In another aspect of the invention target cells are isolated the genetic data contained in those cells are amplified and measurements of multiple SNPs are made using a combination of one or more of the following techniques PCR based amplification techniques PCR based measurement techniques or detection techniques based on MOLECULAR INVERSION PROBES or microarrays such as the GENECHIP or TAQMAN systems. This genetic data is then used in the system described herein.

In another aspect of the invention the genetic data of an individual can be cleaned using diploid and haploid data from both parents. Alternately haploid data from a parent can be simulated if diploid and haploid data of the parent s parent can be measured. In another aspect genetic data from any person of a known genetic relation to the individual can be used to clean the data of the individual including parents siblings grandparents offspring cousins uncles aunts etc.

In another aspect of the invention the target and or related individual s genetic data may be partly or wholly known in silico obviating the need for some direct measurements. Portions of the genetic data can be generated in silico by means of an informatics approach utilizing a hidden Markov model.

In another aspect of the invention it is possible to estimate the confidence one has in the determination of those SNPs.

Note that the techniques described herein are relevant both to measurements of genetic material in one or a small number of cells as well as to measurements on smaller amounts of DNA such as that which can be isolated from the mother s blood in the context of Non invasive Prenatal Diagnosis NIPD . Also note that this method can be equally applied to genomic data in silico i.e. not directly measured from genetic material.

It will be recognized by a person of ordinary skill in the art given the benefit of this disclosure aspects and embodiments that may implement one or more of the systems methods and features disclosed herein.

The goal of the disclosed system is to provide highly accurate genomic data for the purpose of genetic diagnoses. In cases where the genetic data of an individual contains a significant amount of noise or errors the disclosed system makes use of the similarities between genetic data of related individuals and the information contained in that secondary genetic data to clean the noise in the target genome. This is done by determining which segments of chromosomes were involved in gamete formation and where crossovers occurred during meiosis and therefore which segments of the secondary genomes are expected to be nearly identical to sections of the target genome. In certain situations this method can be used to clean noisy base pair measurements but it also can be used to infer the identity of individual base pairs or whole regions of DNA that were not measured. In addition a confidence can be computed for each reconstruction call made. A highly simplified explanation is presented first making unrealistic assumptions in order to illustrate the concept of the invention. A detailed statistical approach that can be applied to the technology of today is presented afterward.

Another goal of the system is to detect abnormal numbers of chromosomes sections of chromosomes and origins of chromosomes. In genetic samples that are aneuploid have unbalanced translocations uniparental disomy or other gross chromosomal abnormalities the amount of genetic material present at a plurality of loci can be used to determine the chromosomal state of the sample. There are multiple approaches to this method and several of them are described here. In some approaches the amount of genetic material present in a sample is sufficient to directly detect aneuploides. In other approaches the method for cleaning the genetic material can be used to enhance the efficiency of detection of chromosomal imbalances. A confidence can be computed for each chromosomal call made.

Attention must be paid to the points of potential crossing over in between the SNPs of interest. The set of alleles of the three maternal genes may be described as a a a corresponding to SNPs SNP SNP SNP . The set of alleles of the three paternal genes may be described as a a a . Consider the recombination nodules formed in and assume that there is just one recombination for each pair of recombining chromatids. The set of gametes that are formed in this process will have gene alleles a a a a a a a a a a a a . In the case with no crossing over of chromatids the gametes will have alleles a a a a a a . In the case with two points of crossing over in the relevant regions the gametes will have alleles a a a a a a . These eight different combinations of alleles will be referred to as the hypothesis set of alleles for that particular parent.

The measurement of the alleles from the embryonic DNA will be noisy. For the purpose of this discussion take a single chromosome from the embryonic DNA and assume that it came from the parent whose meiosis is illustrated in . The measurements of the alleles on this chromosome can be described in terms of a vector of indicator variables A AAA where A 1 if the measured allele in the embryonic chromosome is a A 1 if the measured allele in the embryonic chromosome is a and A 0 if the measured allele is neither aor a. Based on the hypothesis set of alleles for the assumed parent a set of eight vectors may be created which correspond to all the possible gametes describe above. For the alleles described above these vectors would be a 1 1 1 a 1 1 1 a 1 1 1 a 1 1 1 a 1 1 1 a 1 1 1 1 1 1 a 1 1 1 . In this highly simplified application of the system the likely alleles of the embryo can be determined by performing a simple correlation analysis between the hypothesis set and the measured vectors argmax1 . . . 8 1 

Once i is found the hypothesis ais selected as the most likely set of alleles in the embryonic DNA. This process is then repeated twice with two different assumptions namely that the embryonic chromosome came from the mother or the father. That assumption which yields the largest correlation Aawould be assumed to be correct. In each case a hypothesis set of alleles is used based on the measurements of the respective DNA of the mother or the father. Note that in a typical embodiment of the disclosed method one measures a large number of SNPs between those SNPs that are important due to their association with particular disease phenotypes these will be referred to these as Phenotype associated SNPs or PSNPs. The Non phenotype associated SNPs NSNPs between the PSNPs may be chosen a priori for example for developing a specialized genotyping array by selecting from the NCBI dbSNP database those RefSNPs that tend to differ substantially between individuals. Alternatively the NSNPs between the PSNPs may be chosen for a particular pair of parents because they differ between the parents. The use of the additional SNPs between the PSNPs enables one to determine with a higher level of confidence whether crossover occurs between the PSNPs. It is important to note that while different alleles are referred to in this notation this is merely a convenience the SNPs may not be associated with genes that encode proteins.

In another more complex embodiment the a posteriori probability of a set of alleles is computed given a particular measurement taking into account the probability of particular crossovers. In addition the scenario typical of microarrays and other genotyping technologies is addressed where SNPs are measured for pairs of chromosomes rather than for a single chromosome at a time. The measurements of the genotype at the locus i for the embryonic paternal and maternal chromosomes may be characterized respectively by random variables representing the pairs of SNP measurements e e p p and m m . Since one cannot determine the presence of crossovers in the maternal and paternal chromosomes if all measurements are made as pairs the method is modified in addition to genotyping the fertilized embryos and paternal and maternal diploid tissue one haploid cell from each parent namely a sperm cell and an egg cell is also genotyped. The measured alleles of the sperm cell are represented by p i 1 . . . N and the complementary alleles measured from the paternal diploid tissue by p. Similarly the measured alleles of the egg cell are represented by mand their complement in the mother s diploid cell by m. These measurements provide no information on where the parental chromosomes crossed over in generating the measured sperm and egg cells. However one can assume that the sequence of N alleles on the egg or sperm was created from the parental chromosomes by a small number of or no crossovers. This is sufficient information to apply the disclosed algorithm. A certain error probability is associated with calling the paternal and maternal SNPs. The estimation of this error probability will vary based on the measurements made p p and m m and the signal to noise ratio for the technology used. Although these error probabilities can be uniquely computed for each locus without affecting the disclosed method the algebra is simplified here by assuming that the probabilities of correctly calling the paternal and maternal SNPs are constant at pand prespectively.

Assume that a measurement is performed on the embryonic DNA which is termed measurement M. In addition the notation is slightly modified so that A is now a set and not a vector A refers to a particular hypothesis about the combination or set of alleles derived from each parent. The set of all possible combinations of alleles A from both parents is denoted as S. The goal is to determine the combination of alleles or that hypothesis A Swith the highest a posteriori probability given the measurement M argmax 2 Using the law of conditional probabilities P A M P M A P A P M . Since P M is common for all different A s the optimizing search can be recast as argmax 3 

Now consider the computation of P M A . Begin with a single locus i and let the hypothesis be that this locus on the embryo is derived from the parental SNPs pand m where the underscoreis used to denote the true value of these Parental SNPs as opposed to the measurements performed pand m which may or may not be correct. The true value of the embryonic SNPs is denoted as e e . If hypothesis A is true then e e p m or m p . Since one cannot differentiate which of the measurements e e comes from which parent both orders must be considered so the hypothesis set A p m m p . The probability of a particular measurement M depends on the true values or the underlying states of the parental SNPs namely p p and m m . Since there are four SNPs p p m m and each of these can assume the value of four nucleotide bases A C T G there are 4or 256 possible states. The algorithm is illustrated for one state sfor which it is assumed that p p m m. From this explanation it will be clear how to apply the method to all 256 possible states s k 1 . . . 256. Assume a measurement M of embryonic SNPs e e is performed and the result e p e mis obtained. The a priori probability for this measurement given that hypothesis A and state sare true is computed 4 Consider the first expressions in the first term and second term P e p e m A s P e m e p A s 0.5 since the hypothesis A p m m p makes two orderings for the embryonic SNPs equally likely. Now consider the second expression of the first term P e p e p the probability of measuring e pgiven the assumption that embryonic SNP eactually is derived from paternal SNP p. The probabilities for correctly measuring the paternal SNPs maternal SNPs and embryonic SNPs are p p and p. Given the assumption e p the measurement e p requires either that both embryonic and paternal SNPs are correctly measured or that both are incorrectly measured and they happen to be incorrectly measured as the same nucleotide A C T or G . So P e p e p pp 1 p 1 p 3 where it is assumed for simplicity that the probability of incorrectly calling all of the four nucleotides is equally likely the algorithm can be easily modified to accommodate different probabilities of calling a particular nucleotide A C T G given a measurement on another particular nucleotide. The same approach may be applied to the third expression in the first term to obtain P e m e m pp 1 p 1 p 3. Now consider the second expression of the second term. P e p e m m p requires either that eor pbe an incorrect measurement or that both be incorrect measurements so that the measured values happen to be equal P e p e m m p p 1 p 3 1 p p 3 1 p 1 p 2 9. The same argument can be applied to the last expression of the second term to yield P e m e p m p p 1 p 3 1 p p 3 1 p 1 p 2 9. Now combining all of these terms and making the assumption merely to simplify the algebra that p p p p one can compute 

Although the computation will vary a similar conceptual approach to that described here would be used for all 256 possible states s k 1 . . . 256. Computing P e p e m A s for all 256 states sand summing over the probability of each sone obtains P e p e m A . In other words 

In order to compute the probabilities of each state s P s one must treat all the separate alleles making up a state as separate events since they are on separate chromosomes in other words P s P p p m m P p P p P m P m . Bayesian techniques may be applied to estimate the probability distribution for the individual measurements. Every measurement of an allele on the maternal or paternal chromosomes at locus i may be treated as a coin toss experiment to measure the probability of this allele being a particular value A C T or G . These measurements are made on the adult tissue samples and may be treated as being totally reliable even though pairs of alleles are measured for each SNP and it is not possible to determine which allele comes from which chromosome. Let w P p corresponding to the probability of the SNP i on the father s chromosome being value p. In the following explanation w is used instead of w. Let the measurements performed on SNP i of the father s chromosome be characterized as collecting data D. One can create a probability distribution for w p w and update this after the data is measurement according to Bayes Theorem p w D p w p D w p D . Assume n alleles of SNP i are observed and that the particular allele corresponding to w comes up h times in other words heads is observed h times. The probability of this observation can be characterized by the binomial distribution

Since there is the a probability distribution for each w one can also compute conservative estimates of the values P s to any specified confidence level by integrating over the probability distribution rather than simply using the MAP estimates. It is possible to do this for example to conservatively estimate P M A to within some confidence level. Whether a conservative estimate or a MAP estimate is used the estimate of P s is continually refined for the computation of P M A . In what follows reference to the assumed state will be eliminated to simplify the notation and state sis assumed for all explanations of detailed computation. Bear in mind that in actuality these calculations would be performed for each of 256 states and be summed over the probability of each.

The method of computing P M A is now extended to multiple SNP loci assuming that M represents the set of measurements of N pairs of SNPs on the embryo M M . . . M . Assume also that A represents the set of hypotheses for each SNP about which parental chromosomes contributed to that SNP A A . . . A . Let S represent the set of all other possible hypotheses that are different from A or are in the set A . P M A and P M A may be computed 

Let the probability of a crossover in each region between SNPs be denoted P r 1 . . . N 1. To first order the probability of a recombination node in a region r between two SNPs is proportional to the genetic distance between those SNPs measured in cMorgans . However much recent research has enabled a precise modeling of the probability of recombination between two SNP loci. Observations from sperm studies and patterns of genetic variation show that recombination rates vary extensively over kilobase scales and that much recombination occurs in recombination hotspots and causes linkage disequilibrium to display a block like structure. The NCBI data about recombination rates on the Human Genome is publicly available through the UCSC Genome Annotation Database.

Various data sets can be used singly or in combination. Two of the most common data sets are from the Hapmap Project and from the Perlegen Human Haplotype Project. The latter is higher density the former is higher quality. See for the regional recombination rates from positions 1 038 423 to 4 467 775 of chromosome 1 based on the HapMap Phase I data release 16a. These rates were estimated using the reversible jump Markov Chain Monte Carlo MCMC method which is available in the package LDHat. The state space considered is the distribution of piece wise constant recombination rate maps. The Markov chain explores the distribution of the number and location of rate change points in addition to the rates for each segment . These results may be used to generate an estimate of Pby integrating over the recombination rates times by the length of each constant segment between the SNPS. The cumulative recombination rate over the nucleotides is shown in in red.

Let C be a set of indicator variables csuch that c 1 if a crossover occurred in region r and 0 otherwise. c 1 if no crossovers occurred and 0 otherwise. Since it is assumed that only one crossover can occur in a region of N SNPs only one element of the set C is non zero. Hence the probability of crossover represented by set C is found to be 

Now with the equations for determining P A and P M A all the elements necessary to compute A per Equation 3 above have been defined. Hence it is possible to determine from the highly error prone measurements of the embryonic SNPs where crossovers occurred and to consequently clean the embryonic measurements with a high degree of confidence. It remains to determine the degree of confidence in the best hypothesis A . To determine this it is necessary to find the odds ratio P A M P A M . The tools have all been described above for this computation 

The confidence in A is then given as P A M OR 1 OR . This computation indicates the confidence in a particular hypothesis A but it does not indicate a confidence in a particular determination of a SNP. In order to compute the confidence in a determination of embryonic PSNP n it is necessary to create the set of all hypotheses A that don t change the value of this SNP. This set will be denoted as S which corresponds to all hypothesis that result in PSNP n on the embryo having the same value as is predicted by hypothesis A . Similarly create a set Swhich corresponds to all hypothesis that result in PSNP n having a different value to that predicted by hypothesis A . Now it is possible to compute the odds ratio of the probability that the SNP is correctly called versus the probability that the SNP is incorrectly called 

Note that this technique could also be used to detect such defects as uniparental disomy UPD wherein two of the same chromosomes are from the same parent while none of that chromosomes from the other parent is present. Upon attempting to deduce the crossovers in the parent chromosomes there will be no hypothesis which adequately explains the data with a high confidence and if alternate hypotheses are allowed that include the possibility of UPD they will found to be more likely.

The disclosed method depends on assumptions about the probability of recombination between particular SNPs assumptions about the probability of the correct measurement of each SNP on the embryonic sperm egg paternal and maternal chromosomes and assumptions about the likelihood of certain alleles within different population groups. Consider each of these assumptions the mechanism of recombination is not perfectly understood and modeled and the crossover probability has been established to vary based on an individual s genotype. Furthermore the techniques by which the recombination rates are measured show substantial variability. For example the package LDHat which implements the reversible jump Markov Chain Monte Carlo MCMC method makes a set of assumptions and requires a set of user inputs about the mechanism and characterization of recombination. These assumptions can affect predicted recombination rates between SNPs as is evinced by the different results obtained by various studies.

It is anticipated that the assumptions about recombination rates out of all assumptions listed above will have the most impact on Equation 15. The computations described above should be based on the best estimates of the probability for crossover between SNPS P. Thereafter conservative estimates may be used for Pusing values at for example the 95 confidence bounds for the recombination rates in the direction that reduces the confidence measure P correctly called SNP n . The 95 confidence bounds may be derived from confidence data produced by various studies of recombination rates and this may be corroborated by looking at the level of discordance between published data from different groups using different methods.

Similarly the 95 confidence bounds may be used for the estimates of the probability that each SNP is correctly called p p p. These numbers can be computed based on the actual measured array intensities included in the genotyping assay output files combined with empirical data on the reliability of the measurement technique. Note that those NSNPs for which these parameters p pand pare not well established may be ignored. For example since the diploid parental data is reliably measured one may ignore NSNP measurements of the parents haploid cells and on the embryo that do not correspond to any of the alleles on the relevant SNPs of the parent s diploid tissue.

Lastly consider the assumptions about the likelihood of certain alleles within different population groups which give rise to the computation P s . These assumptions also will not have a large impact on the disclosed method since the measurement of the parental diploid data is reliable i.e. direct measurement of the state sfrom the parental samples typically result in data with high confidence. Nonetheless it is possible to use the probability distribution for each w as described in Equation 8 in order to compute a confidence bound for the probability of each state P s . As above one may compute the 95 confidence bound for each P s in the conservative direction that reduces confidence measure P correctly called SNP n .

The determination of P correctly called SNP n will inform the decision about how many NSNPs need to be measured around each PSNP in order to achieve the desired level of confidence.

Note that there are different approaches to implementing the concept of the disclosed method namely combining the measurement of the parent s DNA the measurement of the DNA of one or more embryos and the a priori knowledge of the process of meiosis in order to obtain a better estimate of the embryonic SNPs. It will be clear to one skilled in the art how similar methods can be applied when different subsets of the a priori knowledge are known or not known or known to a greater or lesser degree of certainty. For example one can use the measurements of multiple embryos to improve the certainty with which one can call the SNPs of a particular embryo or to accommodate missing data from the parents. Note also that one does not need a PSNP of interest to be measured by the measurement technique. Even if that PSNPs is not determined by the measurement system it can still be reconstructed with a high degree of confidence by the disclosed method.

Also note that once the points of crossover that occurred during meiosis have been determined and the regions of the target genome have been mapped to the pertinent regions of the parental DNA it is possible to infer not only the identity of individual SNPs of interest but also whole regions of DNA that may be missing in the measured target genome due to allele drop out or other errors in measurement. It is also possible to measure insertions and deletions in the parental DNA and use the disclosed method to infer that they exist in the target DNA.

Various techniques may be used to improve the computational complexity of the disclosed algorithm described above. For example one may only or predominantly select those NSNPs that differ between the mother and the father. Another consideration would be to only use NSNPs that are spaced nearby the PSNPs to minimize the chance of crossovers occurring between the NSNPs and PSNPs of interest. One could also use NSNPs that were spaced along the chromosome so as to maximize coverage of multiple PSNPs. Another consideration will be to initially use only a small number of NSNPs to determine roughly where crossovers occurred and with only a limited degree of certainty. Additional NSNPs can then be used to refine the crossover model and increase the probability of correctly calling the PSNPs. The number of crossover combinations to consider scales roughly as Nwhere N is the number of SNPs and C is the maximum number of crossovers. Consequently for C 4 it is possible to accommodate roughly N 100 for each PSNP while remaining computationally tractable on a Pentium IV processor. Using the approaches described above and other approaches for increased computational efficiency N 100 C 4 can be easily accommodated. One such approach is described below.

Note that there are many other approaches to make a call on a PSNP and generate an estimate of the probability that a PSNPs has been correctly determined based on a particular set of embryonic data parent data and algorithm used without changing the underlying concept. This probability can be used for individual decision making and for implementing a reliable service in the context of IVF or NIPGD.

Another embodiment of the invention involving an algorithm that scales linearly is described here. Given the limited nature of computation power the length of the computation may be a significant factor in the use of the disclosed method. When running computations any algorithm that must compute certain values where the number of computations needed rises exponentially with the number of SNPs can become unwieldy. A solution that involves a number of calculations that increase linearly with the number of SNPs will always be preferred from a time standpoint as the number of SNPs gets large. Below this approach is described.

A simple approach which is to consider all possible hypotheses must contend with the running time being an exponential function in number of SNPs. Suppose as before that measured data are a collection of measured embryo father and mother chromosome measurements on k SNPs i.e. M M . . . M where M e e p p m m . As before the hypotheses space is S H . . . H set of all the hypotheses where each hypothesis is of the format H H . . . H where His the mini hypothesis for snip i of the format H p m where p p p and m m m. There are 4 different mini hypotheses H in particular 

There are 4different hypotheses in the space S. By trying to find the best hypothesis by exhaustively exploring the entire space S the necessary algorithm would be of exponential order in k O exp k where k is the number of SNPs involved. For large k even k 5 this is immensely slow and unpractical. Therefore it is more practical to resort to a recursive solution which solves the problem of size k as a function of the problem of size k 1 in constant time. The solution shown here is of the linear order in k O k .

Begin with F M H P H M P M H P H P M . Then argmaxF M H argmaxP M H P H and the goal is to solve P M H P H in linear time. Suppose that M measurement on SNPs s to k H hypothesis on SNPs s to k and to simplify notation M M H H measurement and hypothesis on SNP k. As shown before 

It is not necessary to solve for P M to get the best hypothesis since it is constant for all H. But in order to get the actual meaningful number for the conditional probability P H M P M H P H P M it is also necessary to derive P M . As above we can write 

At each level there are only four different hypotheses H so the algorithm is again linear in the number of SNPs k.

Once we the best hypothesis H H . . . H has been computed it is now may be desired to derive the confidence in the final answer for each SNP namely P H M for i 1 . . . k. As before P H M P M H P H P M W H M P M where P M is already known.

Again a case of size k has been reduced to two pieces of smaller size albeit a bit more complicated than before. Each of the pieces can be calculated as

In one embodiment of the system it is only necessary to make use of diploid data from one parent presumably the mother with or without haploid data from either or both of the parents and when that data is known to a greater or lesser degree of certainty. For example it is expected that given the grueling nature of egg donation there will be occasions when maternal haploid data is not readily available. It will be clear to one skilled in the art after reading this description how the statistical methods for computing the likelihood of a particular SNP can be modified given a limited data set.

An alternative approach uses data from more distant relatives to make up for missing diploid or haploid data of one or both parents. For example since it is known that one set of an individual s chromosomes come from each of his or her parents diploid data from the maternal grandparents could be used to partially reconstruct missing or poorly measured maternal haploid data.

Note the recursive nature of this method given the naturally noisy measurement of single cell parental haploid data along with the diploid and or haploid data of the appropriate grandparents the disclosed method could be used to clean the parental haploid data which in turn will provide more accurate genotyping of the embryo. It should be obvious to one skilled in the arts how to modify the method for use in these cases.

It is preferable to use more information rather than less as this can increase the chances of making the right call at a given SNP and can increase the confidence in those calls. This must be balanced with the increasing complexity of the system as additional techniques and sources of data are used. There are many sources of additional information as well as techniques available to use the information to augment the data. For example there are informatics based approaches which take advantage of correlations which can be found in Hapmap data or other repositories of genomic data. In addition there are biological approaches which can allow for the direct measurement of genetic data that otherwise would need to be recreated in silico. For example haploid data otherwise unavailable may be measurable by extracting individual chromosomes from diploid cells using flow cytometry techniques to isolate fluorescently tagged chromosomes. Alternately one may use cell fusion to create monoallelic hybrid cells to effect diploid to haploid conversion.

In one embodiment the system can be used to determine the likelihood of an embryo to implant in the mother and develop into a baby. To the extent that the likelihood of the embryo implanting is determined by SNPs of the embryo and or their relation to SNPs of the mother the disclosed method will be important in helping the selection of embryos based on making a reliable prediction of which will successfully implant based on the clean SNP data. To best predict the likelihood it will be necessary to take into account the determined genotype of the embryo possibly combined with the levels of gene expression in the embryo the levels of gene expression in the mother and or the determined genotype of the mother.

In addition it is well known that aneuploid embryos are less likely to implant less likely to result in a successful pregnancy and less likely to result in a healthy child. Consequently screening for aneuploides is an important facet to selecting the embryo that is most likely to result in a successful outcome. More detail on this approach is given below.

In one embodiment of the method it may be necessary to deduce parental haplotypes given detailed knowledge of the diploid data of a parent. There are multiple ways this can be done. In the simplest case haplotypes have already been inferred by molecular assay of single haploid cells of a direct relation mother father son or daughter . In this case it is a trivial matter to one skilled in the art to deduce the sister haplotype by subtracting the known haplotype from the diploid genotype measured by molecular assay. For example if a particular locus is heterozygous an unknown parental haplotype is the opposite allele from the known parental haplotype.

In another case the noisy haploid data of the parent may be known from molecular biological haplotyping of individual parental haploid cells such as a sperm cell or from individual chromosomes which may be isolated by various methods including magnetic beads and flow cytometry. In this case the same procedure can be used as above except that the determined haplotype will be as noisy as the measured haplotype.

There are also methods for deducing haploid data sets directly from diploid data using statistical methods that utilize known haplotype blocks in the general population such as those created for the public Hapmap project . A haplotype block is essentially a series of correlated alleles that occur repeatedly in a variety of populations. Since these haplotype blocks are often ancient and common they may be used to predict haplotypes from diploid genotypes. The parents inferred haplotype blocks can then be used as input for the method described herein to clean the noisy data from the embryos. Publicly available algorithms that would accomplish this task include an imperfect phylogeny approach Bayesian approaches based on conjugate priors and priors from population genetics. Some of these algorithms use hidden Markov models. One study used public trio and unrelated individual data to demonstrate that these algorithms perform with error rates as low as 0.05 across 1 MB of sequence. However as expected accuracy is lower for individuals with rare haplotype blocks. In one estimate computational methods failed to phase as many as 5.1 of loci with minor allele frequency of 20 .

In one embodiment of the invention genetic data from multiple blastomeres taken from different embryos during an IVF cycle is used to infer the haplotype blocks of the parents with greater reliability.

In one embodiment of the system the measured genetic data can be used to detect for the presence of aneuploides and or mosaicism in an individual. Disclosed herein are several methods of using medium or high throughput genotyping to detect the number of chromosomes or DNA segment copy number from amplified or unamplified DNA from tissue samples. The goal is to estimate the reliability that can be achieved in detecting certain types of aneuploidy and levels of mosaicism using different quantitative and or qualitative genotyping platforms such as ABI TAQMAN MIPS or Microarrays from ILLUMINA AGILENT and AFFMETRIX. In many of these cases the genetic material is amplified by PCR before hybridization to probes on the genotyping array to detect the presence of particular alleles. How these assays are used for genotyping is described elsewhere in this disclosure.

Described below are several methods for screening for abnormal numbers of DNA segments whether arising from deletions aneuploides and or mosaicism. The methods are grouped as follows i quantitative techniques without making allele calls ii qualitative techniques that leverage allele calls iii quantitative techniques that leverage allele calls iv techniques that use a probability distribution function for the amplification of genetic data at each locus. All methods involve the measurement of multiple loci on a given segment of a given chromosome to determine the number of instances of the given segment in the genome of the target individual. In addition the methods involve creating a set of one or more hypotheses about the number of instances of the given segment measuring the amount of genetic data at multiple loci on the given segment determining the relative probability of each of the hypotheses given the measurements of the target individual s genetic data and using the relative probabilities associated with each hypothesis to determine the number of instances of the given segment. Furthermore the methods all involve creating a combined measurement M that is a computed function of the measurements of the amounts of genetic data at multiple loci. In all the methods thresholds are determined for the selection of each hypothesis Hbased on the measurement M and the number of loci to be measured is estimated in order to have a particular level of false detections of each of the hypotheses.

The probability of each hypothesis given the measurement M is P H M P M H P H P M . Since P M is independent of H we can determine the relative probability of the hypothesis given M by considering only P M H P H . In what follows in order to simplify the analysis and the comparison of different techniques we assume that P H is the same for all H so that we can compute the relative probability of all the P H M by considering only P M H . Consequently our determination of thresholds and the number of loci to be measured is based on having particular probabilities of selecting false hypotheses under the assumption that P H is the same for all H. It will be clear to one skilled in the art after reading this disclosure how the approach would be modified to accommodate the fact that P H varies for different hypotheses in the set H. In some embodiments the thresholds are set so that hypothesis His selected which maximizes P H M over all i. However thresholds need not necessarily be set to maximize P H M but rather to achieve a particular ratio of the probability of false detections between the different hypotheses in the set H.

It is important to note that the techniques referred to herein for detecting aneuploides can be equally well used to detect for uniparental disomy unbalanced translocations and for the sexing of the chromosome male or female XY or XX . All of the concepts concern detecting the identity and number of chromosomes or segments of chromosomes present in a given sample and thus are all addressed by the methods described in this document. It should be obvious to one skilled in the art how to extend any of the methods described herein to detect for any of these abnormalities.

The methods applied here are similar to those applied in optimal detection of digital signals. It can be shown using the Schwartz inequality that the optimal approach to maximizing Signal to Noise Ratio SNR in the presence of normally distributed noise is to build an idealized matching signal or matched filter corresponding to each of the possible noise free signals and to correlate this matched signal with the received noisy signal. This approach requires that the set of possible signals are known as well as the statistical distribution mean and Standard Deviation SD of the noise. Herein is described the general approach to detecting whether chromosomes or segments of DNA are present or absent in a sample. No differentiation will be made between looking for whole chromosomes or looking for chromosome segments that have been inserted or deleted. Both will be referred to as DNA segments. It should be clear after reading this description how the techniques may be extended to many scenarios of aneuploidy and sex determination or detecting insertions and deletions in the chromosomes of embryos fetuses or born children. This approach can be applied to a wide range of quantitative and qualitative genotyping platforms including TAQMAN qPCR ILLUMINA Arrays AFFMETRIX Arrays AGILENT Arrays the MIPS kit etc.

Assume that there are probes at SNPs where two allelic variations occur x and y. At each locus i i 1 . . . N data is collected corresponding to the amount of genetic material from the two alleles. In the TAQMAN assay these measures would be for example the cycle time C at which the level of each allele specific dye crosses a threshold. It will be clear how this approach can be extended to different measurements of the amount of genetic material at each locus or corresponding to each allele at a locus. Quantitative measurements of the amount of genetic material may be nonlinear in which case the change in the measurement of a particular locus caused by the presence of the segment of interest will depend on how many other copies of that locus exist in the sample from other DNA segments. In some cases a technique may require linear measurements such that the change in the measurement of a particular locus caused by the presence of the segment of interest will not depend on how many other copies of that locus exist in the sample from other DNA segments. An approach is described for how the measurements from the TAQMAN or qPCR assays may be linearized but there are many other techniques for linearizing nonlinear measurements that may be applied for different assays.

The measurements of the amount of genetic material of allele x at loci 1 . . . N is given by data d d. . . d . Similarly for allele y d d. . . d . Assume that each segment j has alleles a a. . . a where each element ais either x or y. Describe the measurement data of the amount of genetic material of allele x as d s where sis the signal and is a disturbance. The signal s f a . . . a . . . f a . . . a where fis the mapping from the set of alleles to the measurement and J is the number of DNA segment copies. The disturbance vector is caused by measurement error and in the case of nonlinear measurements the presence of other genetic material besides the DNA segment of interest. Assume that measurement errors are normally distributed and that they are large relative to disturbances caused by nonlinearity see section on linearizing measurements so that nwhere nhas variance and vector nis normally distributed N 0 R R E nn . Now assume some filter h is applied to this data to perform the measurement m hd hs h . In order to maximize the ratio of signal to noise hs hn it can be shown that h is given by the matched filter h Rswhere is a scaling constant. The discussion for allele x can be repeated for allele y.

Method 1a Measuring Aneuploidy or Sex by Quantitative Techniques that do not Make Allele Calls when the Mean and Standard Deviation for Each Locus is Known

Assume for this section that the data relates to the amount of genetic material at a locus irrespective of allele value e.g. using qPCR or the data is only for alleles that have 100 penetrance in the population or that data is combined on multiple alleles at each locus see section on linearizing measurements to measure the amount of genetic material at that locus. Consequently in this section one may refer to data dand ignore d. Assume also that there are two hypotheses hthat there are two copies of the DNA segment these are typically not identical copies and hthat there is only 1 copy. For each hypothesis the data may be described as d h s h nand d h s h nrespectively where s h is the expected measurement of the genetic material at locus i the expected signal when two DNA segments are present and s h is the expected data for one segment. Construct the measurement for each locus by differencing out the expected signal for hypothesis h m d s h . If his true then the expected value of the measurement is E m s h s h . Using the matched filter concept discussed above set h 1 N R s h s h . The measurement is described as m hd 1 N s h s h m.

If his true the expected value of E m h m 1 N s h s h and the standard deviation of m is 1 N s h s h 1 N s h s h .

If his true the expected value of m is E m h m 0 and the standard deviation of m is again 1 N E s h s h .

This approach was applied to data measured with the TAQMAN Assay from Applied BioSystems using 48 SNPs on the X chromosome. The measurement for each locus is the time C that it takes the die released in the well corresponding to this locus to exceed a threshold. Sample 0 consists of roughly 0.3 ng 50 cells of total DNA per well of mixed female origin where subjects had two X chromosomes sample 1 consisted of roughly 0.3 ng of DNA per well of mixed male origin where subject had one X chromosome. and show the histograms of measurements for samples 1 and 0. The distributions for these samples are characterized by m 29.97 SD 1.32 m 31.44 SD 1.592. Since this data is derived from mixed male and female samples some of the observed SD is due to the different allele frequencies at each SNP in the mixed samples. In addition some of the observed SD will be due to the varying efficiency of the different assays at each SNP and the differing amount of dye pipetted into each well. provides a histogram of the difference in the measurements at each locus for the male and female sample. The mean difference between the male and female samples is 1.47 and the SD of the difference is 0.99. While this SD will still be subject to the different allele frequencies in the mixed male and female samples it will no longer be affected the different efficiencies of each assay at each locus. Since the goal is to differentiate two measurements each with a roughly similar SD the adjusted SD may be approximated for each measurement for all loci as 0.99 sqrt 2 0.70. Two runs were conducted for every locus in order to estimate for the assay at that locus so that a matched filter could be applied. A lower limit of was set at 0.2 in order to avoid statistical anomalies resulting from only two runs to compute . Only those loci numbering 37 for which there were no allele dropouts over both alleles over both experiment runs and over both male and female samples were used in the plots and calculations. Applying the approach above to this data it was found that MSNR 2.26 hence N 25 2.26 2 17 loci.

Method 1b Measuring Aneuploidy or Sex by Quantitative Techniques that do not Make Allele Calls when the Mean and Std. Deviation is not Known or is Uniform

When the characteristics of each locus are not known well the simplifying assumptions that all the assays at each locus will behave similarly can be made namely that E m and are constant across all loci i so that it is possible to refer instead only to E m and . In this case the matched filtering approach m hdreduces to finding the mean of the distribution of d. This approach will be referred to as comparison of means and it will be used to estimate the number of loci required for different kinds of detection using real data.

As above consider the scenario when there are two chromosomes present in the sample hypothesis h or one chromosome present h . For h the distribution is N and for hthe distribution is N . Measure each of the distributions using Nand Nsamples respectively with measured sample means and SDs m m s and s. The means can be modeled as random variables M Mthat are normally distributed as M N N and M N N . Assume Nand Nare large enough 30 so that one can assume that M N m s N and M N m s N . In order to test whether the distributions are different the difference of the means test may be used where d m m. The variance of the random variable D is N Nwhich may be approximated as s N s N. Given h E d 0 given h E d . Different techniques for making the call between hfor hwill now be discussed.

Data measured with a different run of the TAQMAN Assay using 48 SNPs on the X chromosome was used to calibrate performance. Sample 1 consists of roughly 0.3 ng of DNA per well of mixed male origin containing one X chromosome sample 0 consisted of roughly 0.3 ng of DNA per well of mixed female origin containing two X chromosomes. N 42 and N 45. and show the histograms for samples 1 and 0. The distributions for these samples are characterized by m 32.259 s 1.460 s sqrt N 0.225 m 30.75 s 1.202 s sqrt N 0.179. For these samples d 1.509 and 0.2879.

Since this data is derived from mixed male and female samples much of the standard deviation is due to the different allele frequencies at each SNP in the mixed samples. SD is estimated by considering the variations in Cfor one SNP at a time over multiple runs. This data is shown in . The histogram is symmetric around 0 since Cfor each SNP is measured in two runs or experiments and the mean value of Ct for each SNP is subtracted out. The average std. dev. across 20 SNPs in the mixed male sample using two runs is s 0.597. This SD will be conservatively used for both male and female samples since SD for the female sample will be smaller than for the male sample. In addition note that the measurement from only one dye is being used since the mixed samples are assumed to be heterozygous for all SNPs. The use of both dyes requires the measurements of each allele at a locus to be combined which is more complicated see section on linearizing measurements . Combining measurements on both dyes would double signal amplitude and increase noise amplitude by roughly sqrt 2 resulting in an SNR improvement of roughly sqrt 2 or 3 dB.

Assume that mis known perfectly from many experiments and every experiment runs only one sample to compute mto compare with m. Nis the number of assays and assume that each assay is a different SNP locus. A threshold t can be set half way between mand mto make the likelihood of false positives equal the number of false negatives and a sample is labeled abnormal if it is above the threshold. Assume s s s 0.597 and use the 5 sigma approach so that the probability of false negatives or positives is 1 normcdf 5 0 1 2.87e 7. The goal is for 5s sqrt N 

Assume the same situation as above except that the goal is to detect mosaicism with a probability of 97.7 i.e. 2 sigma approach . This is better than the standard approach to amniocentesis which extracts roughly 20 cells and photographs them. If one assumes that 1 in 20 cells is aneuploid and this is detected with 100 reliability the probability of having at least one of the group being aneuploid using the standard approach is 1 0.95 64 . If 0.05 of the cells are aneuploid call this sample 3 then m 0.95 m 0.05 mand var m 0.95s 0.05s N. Thus std m 2sqrt 0.95s 0.05s sqrt N N 16 0.95s 0.05s 0.05 m m 1001. Note that using the goal of 1 sigma statistics which is still better than can be achieved using the conventional approach i.e. detection with 84.1 probability it can be shown in a similar manner that N 250.

Although this approach may not be necessary assume that every experiment runs two samples in order to compare mwith truth sample m. Assume that N N N. Compute d m mand assuming set a threshold t m m 2 so that the probability of false positives and false negatives is equal. To make the probability of false negatives 2.87e 7 it must be the case that m1 m2 2 5sqrt s N s N N 100 s s m1 m2 32.

As above assume the probability of false negatives is 2.3 i.e. 2 sigma approach . If 0.05 of the cells are aneuploid call this sample 3 then m 0.95m 0.05mand var m 0.95s 0.05s N. d m mand 1.95s 0.05s N. It must be that std m 2sqrt 1.95s 0.05s sqrt N N 16 1.95s 0.05s 0.05 m m 2002. Again using 1 sigma approach it can be shown in a similar manner that N 500.

Consider the case if the goal is only to detect 5 mosaicism with a probability of 64 as is the current state of the art. Then the probability of false negative would be 36 . In other words it would be necessary to find x such that 1 normcdf x 0 1 36 . Thus N 4 0.36 2 1.95s 0.05s 0.05 m m 65 for the 2 sigma approach or N 33 for the 1 sigma approach. Note that this would result in a very high level of false positives which needs to be addressed since such a level of false positives is not currently a viable alternative.

Also note that if N is limited to 384 i.e. one 384 well TAQMAN plate per chromosome and the goal is to detect mosaicism with a probability of 97.72 then it will be possible to detect mosaicism of 8.1 using the 1 sigma approach. In order to detect mosaicism with a probability of 84.1 or with a 15.9 false negative rate then it will be possible to detect mosaicism of 5.8 using the 1 sigma approach. To detect mosaicism of 19 with a confidence of 97.72 it would require roughly 70 loci. Thus one could screen for 5 chromosomes on a single plate.

The summary of each of these different scenarios is provided in . Also included in this table are the results generated from qPCR and the SYBR assays. The methods described above were used and the simplifying assumption was made that the performance of the qPCR assay for each locus is the same. and show the histograms for samples 1 and 0 as described above. N N 47. The distributions of the measurements for these samples are characterized by m 27.65 s 1.40 s sqrt N 0.204 m 26.64 s 1.146 S sqrt N 0.167. For these samples d 1.01 and 0.2636. shows the difference between Cfor the male and female samples for each locus with a standard deviation of the difference over all loci of 0.75. The SD was approximated for each measurement of each locus on the male or female sample as 0.75 sqrt 2 0.53.

In this section no assumption is made that the assay is quantitative. Instead the assumption is that the allele calls are qualitative and that there is no meaningful quantitative data coming from the assays. This approach is suitable for any assay that makes an allele call. describes how different haploid gametes form during meiosis and will be used to describe the different kinds of aneuploidy that are relevant for this section. The best algorithm depends on the type of aneuploidy that is being detected.

Consider a situation where aneuploidy is caused by a third segment that has no section that is a copy of either of the other two segments. From the situation would arise for example if pand p or pand p both arose in the child cell in addition to one segment from the other parent. This is very common given the mechanism which causes aneuploidy. One approach is to start off with a hypothesis hthat there are two segments in the cell and what these two segments are. Assume for the purpose of illustration that his for pand mfrom . In a preferred embodiment this hypothesis comes from algorithms described elsewhere in this document. Hypothesis his that there is an additional segment that has no sections that are a copy of the other segments. This would arise for example if por mwas also present. It is possible to identify all loci that are homozygous in pand m. Aneuploidy can be detected by searching for heterozygous genotype calls at loci that are expected to be homozygous.

Assume every locus has two possible alleles x and y. Let the probability of alleles x and y in general be pand prespectively and p p 1. If his true then for each locus i for which pand mare homozygous then the probability of a non homozygous call is por p depending on whether the locus is homozygous in x or y respectively. Note based on knowledge of the parent data i.e. p p pand m m m it is possible to further refine the probabilities for having non homozygous alleles x or y at each locus. This will enable more reliable measurements for each hypothesis with the same number of SNPs but complicates notation so this extension will not be explicitly dealt with. It should be clear to someone skilled in the art how to use this information to increase the reliability of the hypothesis.

The probability of allele dropouts is p. The probability of finding a heterozygous genotype at locus i is pgiven hypothesis hand pgiven hypothesis h.

Create a measurement m 1 N Iwhere Iis an indicator variable and is 1 if a heterozygous call is made and 0 otherwise. Nis the number of homozygous loci. One can simplify the explanation by assuming that p pand p pfor all loci are the same two values pand p. Given h E m p 0 and p 1 p N. Given h E m pand p 1 p N. Using 5 sigma statistics and making the probability of false positives equal the probability of false negatives it can be shown that p p 2 5 hence N 100 p 1 p p 1 p p p . For 2 sigma confidence instead of 5 sigma confidence it can be shown that N 4.2 p 1 p p 1 p p p .

It is necessary to sample enough loci N that there will be sufficient available homozygous loci Nsuch that the confidence is at least 97.7 2 sigma . Characterize N Jwhere Jis an indicator variable of value 1 if the locus is homozygous and 0 otherwise. The probability of the locus being homozygous is p p. Consequently E N N p p and N p p 1 p p . To guarantee N is large enough with 97.7 confidence it must be that E N 2 Nwhere Nis found from above.

For example if one assumes p 0.3 p p 0.5 one can find N 186 and N 391 for 5 sigma confidence. Similarly it is possible to show that N 30 and N 68 for 2 sigma confidence i.e. 97.7 confidence in false negatives and false positives.

Note that a similar approach can be applied to looking for deletions of a segment when his the hypothesis that two known chromosome segment are present and his the hypothesis that one of the chromosome segments is missing. For example it is possible to look for all of those loci that should be heterozygous but are homozygous factoring in the effects of allele dropouts as has been done above.

Also note that even though the assay is qualitative allele dropout rates may be used to provide a type of quantitative measure on the number of DNA segments present.

Here it is assumed that the alleles of the normal or expected set of segments are known. In order to check for three chromosomes the first step is to clean the data assuming two of each chromosome. In a preferred embodiment of the invention the data cleaning in the first step is done using methods described elsewhere in this document. Then the signal associated with the expected two segments is subtracted from the measured data. One can then look for an additional segment in the remaining signal. A matched filtering approach is used and the signal characterizing the additional segment is based on each of the segments that are believed to be present as well as their complementary chromosomes. For example considering if the results of PS indicate that segments p2 and m1 are present the technique described here may be used to check for the presence of p2 p3 m1 and m4 on the additional chromosome. If there is an additional segment present it is guaranteed to have more than 50 of the alleles in common with at least one of these test signals. Note that another approach not described in detail here is to use an algorithm described elsewhere in the document to clean the data assuming an abnormal number of chromosomes namely 1 3 4 and 5 chromosomes and then to apply the method discussed here. The details of this approach should be clear to someone skilled in the art after having read this document.

Hypothesis his that there are two chromosomes with allele vectors a a. Hypothesis his that there is a third chromosome with allele vector a. Using a method described in this document to clean the genetic data or another technique it is possible to determine the alleles of the two segments expected by h a a. . . a and a a. . . a where each element ais either x or y. The expected signal is created for hypothesis h s f a a . . . f a a s f a a . . . f a a where f fdescribe the mapping from the set of alleles to the measurements of each allele. Given h the data may be described as d s n n N 0 d s n n N 0 . Create a measurement by differencing the data and the reference signal m d s m d s. The full measurement vector is m mm .

Now create the signal for the segment of interest the segment whose presence is suspected and will be sought in the residual based on the assumed alleles of this segment a a. . . a . Describe the signal for the residual as s sS where s f a . . . f a s f a . . . f a where f a if a x and 0 otherwise f a if a y and 0 otherwise. This analysis assumes that the measurements have been linearized see section below so that the presence of one copy of allele x at locus i generates data nand the presence of copies of the allele x at locus i generates data n. Note however that this assumption is not necessary for the general approach described here. Given h if allele a x then m n m nand if a y then m n m n. Consequently a matched filter h 1 N Rscan be created where R diag . . . . . . . The measurement is m hd. 1 1 In order to estimate the number of SNPs required make the simplifying assumptions that all assays for all alleles and all loci have similar characteristics namely that and for i 1 . . . N. Then the mean and standard deviation may be found as follows 0 1 2 1 2 1 Now compute a signal to noise ratio SNR for this test of hversus h. The signal is m m and the noise variance of this measurement is 2 N . Consequently the SNR for this test is 2 N N 2 .

Compare this SNR to the scenario where the genetic information is simply summed at each locus without performing a matched filtering based on the allele calls. Assume that h 1 N where is the vector of N ones and make the simplifying assumptions as above that and for i 1 . . . N. For this scenario it is straightforward to show that if m hd 0 2 1 22 1 2 Consequently the SNR for this test is N 4 . In other words by using a matched filter that only sums the allele measurements that are expected for segment a the number of SNPs required is reduced by a factor of 2. This ignores the SNR gain achieved by using matched filtering to account for the different efficiencies of the assays at each locus.

Note that if we do not correctly characterize the reference signals s and sthen the SD of the noise or disturbance on the resulting measurement signals mand mwill be increased. This will be insignificant if 

We now describe another quantitative technique that makes use of allele calls. The method involves comparing the relative amount of signal at each of the four registers for a given allele. One can imagine that in the idealized case involving a single normal cell where homogenous amplification occurs or the relative amounts of amplification are normalized four possible situations can occur i in the case of a heterozygous allele the relative intensities of the four registers will be approximately 1 1 0 0 and the absolute intensity of the signal will correspond to one base pair ii in the case of a homozygous allele the relative intensities will be approximately 1 0 0 0 and the absolute intensity of the signal will correspond to two base pairs iii in the case of an allele where ADO occurs for one of the alleles the relative intensities will be approximately 1 0 0 0 and the absolute intensity of the signal will correspond to one base pair and iv in the case of an allele where ADO occurs for both of the alleles the relative intensities will be approximately 0 0 0 0 and the absolute intensity of the signal will correspond to no base pairs.

In the case of aneuploides however different situations will be observed. For example in the case of trisomy and there is no ADO one of three situations will occur i in the case of a triply heterozygous allele the relative intensities of the four registers will be approximately 1 1 1 0 and the absolute intensity of the signal will correspond to one base pair ii in the case where two of the alleles are homozygous the relative intensities will be approximately 2 1 0 0 and the absolute intensity of the signal will correspond to two and one base pairs respectively iii in the case where are alleles are homozygous the relative intensities will be approximately 1 0 0 0 and the absolute intensity of the signal will correspond to three base pairs. If allele dropout occurs in the case of an allele in a cell with trisomy one of the situations expected for a normal cell will be observed. In the case of monosomy the relative intensities of the four registers will be approximately 1 0 0 0 and the absolute intensity of the signal will correspond to one base pair. This situation corresponds to the case of a normal cell where ADO of one of the alleles has occurred however in the case of the normal cell this will only be observed at a small percentage of the alleles. In the case of uniparental disomy where two identical chromosomes are present the relative intensities of the four registers will be approximately 1 0 0 0 and the absolute intensity of the signal will correspond to two base pairs. In the case of UPD where two different chromosomes from one parent are present this method will indicate that the cell is normal although further analysis of the data using other methods described in this patent will uncover this.

In all of these cases either in cells that are normal have aneuploides or UPD the data from one SNP will not be adequate to make a decision about the state of the cell. However if the probabilities of each of the above hypothesis are calculated and those probabilities are combined for a sufficient number of SNPs on a given chromosome one hypothesis will predominate it will be possible to determine the state of the chromosome with high confidence.

Many approaches may be taken to linearize measurements of the amount of genetic material at a specific locus so that data from different alleles can be easily summed or differenced. We first discuss a generic approach and then discuss an approach that is designed for a particular type of assay.

Assume data drefers to a nonlinear measurement of the amount of genetic material of allele x at locus i. Create a training set of data using N measurements where for each measurement it is estimated or known that the amount of genetic material corresponding to data dis . The training set i 1 . . . N is chosen to span all the different amounts of genetic material that might be encountered in practice. Standard regression techniques can be used to train a function that maps from the nonlinear measurement dto the expectation of the linear measurement E . For example a linear regression can be used to train a polynomial function of order P such that E 1 dd. . . d c where c is the vector of coefficients c cc. . . c . To train this linearizing function we create a vector of the amount of genetic material for N measurements . . . and a matrix of the measured data raised to powers 0 . . . P D 1 dd. . . d 1 dd. . . d . . . 1 dd. . . d . The coefficients can then be found using a least squares fit c DD D .

Rather than depend on generic functions such as fitted polynomials we may also create specialized functions for the characteristics of a particular assay. We consider for example the TAQMAN assay or a qPCR assay. The amount of die for allele x and some locus i as a function of time up to the point where it crosses some threshold may be described as an exponential curve with a bias offset g t exp t where is the bias offset is the exponential growth rate and corresponds to the amount of genetic material. To cast the measurements in terms of compute the parameter by looking at the asymptotic limit of the curve g and then may find and by taking the log of the curve to obtain log g t log t and performing a standard linear regression. Once we have values for and another approach is to compute from the time t at which the threshold gis exceeded. g exp t . This will be a noisy measurement of the true amount of genetic data of a particular allele.

Whatever techniques is used we may model the linearized measurement as nwhere is the number of copies of allele x is a constant for allele x and locus i and n N 0 where can be measured empirically.

Method 4 Using a Probability Distribution Function for the Amplification of Genetic Data at Each Locus

The quantity of material for a particular SNP will depend on the number of initial segments in the cell on which that SNP is present. However due to the random nature of the amplification and hybridization process the quantity of genetic material from a particular SNP will not be directly proportional to the starting number of segments. Let q q q qrepresent the amplified quantity of genetic material for a particular SNP s for each of the four nucleic acids A C T G constituting the alleles. Note that these quantities may be exactly zero depending on the technique used for amplification. Also note that these quantities are typically measured from the intensity of signals from particular hybridization probes. This intensity measurement can be used instead of a measurement of quantity or can be converted into a quantity estimate using standard techniques without changing the nature of the invention. Let qbe the sum of all the genetic material generated from all alleles of a particular SNP q q q q q. Let N be the number of segments in a cell containing the SNP s. N is typically 2 but may be 0 1 or 3 or more. For any high or medium throughput genotyping method discussed the resulting quantity of genetic material can be represented as q A A N where A is the total amplification that is either estimated a priori or easily measured empirically Ais the error in the estimate of A for the SNP s and is additive noise introduced in the amplification hybridization and other process for that SNP. The noise terms Aand are typically large enough that qwill not be a reliable measurement of N. However the effects of these noise terms can be mitigated by measuring multiple SNPs on the chromosome. Let S be the number of SNPs that are measured on a particular chromosome such as chromosome 21. It is possible to generate the average quantity of genetic material over all SNPs on a particular chromosome as follows 

In another embodiment assume that the amplification is according to a model where the signal level from one SNP is s a where a has a distribution that looks like the picture in left. The delta function at 0 models the rates of allele dropouts of roughly 30 the mean is a and if there is no allele dropout the amplification has uniform distribution from 0 to a. In terms of the mean of this distribution ais found to be a 2.86a. Now model the probability density function of a using the picture in right. Let sbe the signal arising from c loci let n be the number of segments let be a random variable distributed according to that contributes to the signal from locus i and let be the standard deviation for all . s anc mean s anc std s sqrt nc . If is computed according to the distribution in right it is found to be 0.907a. We can find the number of segments from n s ac and for 5 sigma statistics we require std n 0.95a sqrt nc ac 0.1 so c 0.95n 0.1 181.

Another model to estimate the confidence in the call and how many loci or SNPs must be measured to ensure a given degree of confidence incorporates the random variable as a multiplier of amplification instead of as an additive noise source namely s a 1 . Taking logs log s log a log 1 . Now create a new random variable log 1 and this variable may be assumed to be normally distributed N 0 . In this model amplification can range from very small to very large depending on but never negative. Therefore e 1 and s a 1 . For notation mean s and expectation value E s are used interchangeably 1 To find E the probability density function pdf must be found for a which is possible since is a function of which has a known Gaussian pdf. p p d d . So 

In one embodiment of the system the genetic data can be used to determine the sex of the target individual. After the method disclosed herein is used to determine which segments of which chromosomes from the parents have contributed to the genetic material of the target the sex of the target can be determined by checking to see which of the sex chromosomes have been inherited from the father X indicates a female and Y indicates a make. It should be obvious to one skilled in the art how to use this method to determine the sex of the target.

In some embodiments of the system one drawback is that in order to make a prediction of the correct genetic state with the highest possible confidence it is necessary to make hypotheses about every possible states. However as the possible number of genetic states are exceptionally large and computational time is limited it may not be reasonable to test every hypothesis. In these cases an alternative approach is to use the concept of hypothesis validation. This involves estimating limits on certain values sets of values properties or patterns that one might expect to observe in the measured data if a certain hypothesis or class of hypotheses are true. Then the measured values can tested to see if they fall within those expected limits and or certain expected properties or patterns can be tested for and if the expectations are not met then the algorithm can flag those measurements for further investigation.

For example in a case where the end of one arm of a chromosome is broken off in the target DNA the most likely hypothesis may be calculated to be normal as opposed for example to aneuploid . This is because the particular hypotheses that corresponds to the true state of the genetic material namely that one end of the chromosome has broken off has not been tested since the likelihood of that state is very low. If the concept of validation is used then the algorithm will note that a high number of values those that correspond to the alleles that lie on the broken off section of the chromosome lay outside the expected limits of the measurements. A flag will be raised inviting further investigation for this case increasing the likelihood that the true state of the genetic material is uncovered.

It should be obvious to one skilled in the art how to modify the disclosed method to include the validation technique. Note that one anomaly that is expected to be very difficult to detect using the disclosed method is balanced translocations.

In one embodiment of the system genetic data from target DNA which has been definitely or possibly contaminated with foreign DNA can also be cleaned using the disclosed method. The concept outlined above that of hypothesis validation can be used to identify genetic samples that fall outside of expected limits in the case of contaminated samples it is expected that this validation will cause a flag to be raised and the sample can be identified as contaminated.

Since large segments of the target DNA will be known from the parental genetic data and provided the degree of contamination is sufficiently low and sufficient SNPs are measured the spurious data due to the foreign genetic material can be identified. The method disclosed herein should still allow for the reconstruction of the target genome albeit with lower confidence levels. Provided that the level of contamination is sufficiently low the hypothesis that is calculated to be most likely is still expected to correspond to the true state of the genetic material in the target DNA sample.

It should be obvious to one skilled in the art how to optimize these methods for the purpose cleaning genetic data contaminated with spurious signals due to foreign DNA.

In one embodiment of the system the method described above can be implemented using a set of algorithms which will calculate the most likely identity of each SNP in a list of relevant SNPs as well as a confidence level for each SNP call. Described here is one possible way to implement the method disclosed in this patent. and visually represent the breakdown of this implementation of the disclosed method the input requirements and the format of the output. Note that the implementations discussed here were done using the computer program Matlab and a familiarity with this product will facilitate the understanding of the examples.

The population frequency data FD contains the allele frequency for each of the values A C T G for each of the SNPs available. These data can be previously known or measured and can be updated with newly collected data as described elsewhere in this document.

Measurement bias data BD captures the bias of the measurement process towards certain values. For example assuming the true value of the allele is X A and probability of the correct measurement is p the distribution of the measured value x is 

Crossover data CD consists of a database of genetic distances and crossover probabilities between pairs of snips collected from HAPMAP data.

Together MD FD BD CD make up the necessary input to the disclosed method termed Parental Support algorithm. This algorithm then operates on the input data to generate the output data which describes the most likely true value of the target s genetic data given the measured values as well as the most likely origin of each SNP in terms of the parental alleles.

P t is the frequency of a particular value t for paternal and maternal alleles and is derived from population frequency data FD . P M H t is the probability of correctly measuring the allele values of the embryo the father and the mother assuming a particular true value t. The measurement data and accuracy entered by the user MD and the measurement bias database BD are the inputs required to calculate P M H t .

A more detailed description of the method is given forthwith. Begin with SNPs R r . . . rk a set of k SNPs and the corresponding measured identities of parents and embryo M e e p p m m for k SNPs identified with id s s . . . s where 

e e e . . . e is the measurement on one of the chromosomes of the embryo they don t all have to come from the same parental chromosome for all the SNPs

p p p . . . p is the measurement on the FIRST chromosome of the father all coming from the same chromosome

p p p . . . p is the measurement on the SECOND chromosome of the father all coming from the same chromosome 

m m m . . . m is the measurement on the FIRST chromosome of the mother all coming from the same chromosome 

m m m . . . m is the measurement on the SECOND chromosome of the mother all coming from the same chromosome 

The goal of the method is to determine the true embryo valueT E1 E2 i.e. the most likely case given the measurement M where 

E E E . . . E is the measurement on the FIRST chromosome of the embryo corresponding to the PATERNAL chromosome E p p

E E E . . . E is the measurement on the SECOND chromosome of the embryo corresponding to the MATERNAL value E m m

Effectively the parental chromosome values p p m m are being used as support to check validate and correct measured values of e e hence the term Parental Support Algorithm .

To achieve this goal all the possible hypotheses for the origin of embryo values are developed and the most likely one is chosen given the measurement M. The hypotheses space is S H . . . M set of all the hypotheses where each hypothesis is of the format H H . . . H where His the mini hypothesis for SNP i of the format H p m where p p p and m m m. There are 4 different mini hypotheses H in particular 

In theory Scan have q 4different members to pick from though later this space will be limited with a maximal number of crossovers of paternal and maternal chromosomes.

Since measurements on each SNP are independent for M M . . . M and the particular hypothesis H H . . . H on all k SNPs then . . . For the particular SNP r derive P M H . For A C T GXA C T GX A C T GXA C T G the space of all the possible values for true parent values P P M M by Bayes formula is 

T E E P P M M is the supposed true value for t P P M M and E E fixed from T by hypothesis. Eis one of P P Eis one of M M Given 

For Suppose there are n samples of P P M M all paternal and maternal values are assumed to be independent and t t t t t for tin A C T G

To get a particular p P P t for t A assume that in absence of any data this probability could be anything between 0 and 1 so it is assigned a value of U 0 1 . With the acquisition of data this is updated with the new values and the distribution of this parameter becomes a beta distribution. Suppose that out of n observations of P 1 there are h values P1 A and w event P A and D data given . It is described in a prior section the form of the beta distribution B with h 1 n h 1 for p w Data see equation 8 . The expected value and variance of X B distribution are 

The probability of the hypothesis H H . . . H with H p m depends on the amount of chromosome crossover. For example 

with P crossover 0 then P H and H p m if p in p11 p21 . . . ps1 p12 p22 . . . ps2 m in m11 m21 . . . ms1 m12 m22 . . . ms2 0 otherwise

Hypothesis H consists of the hypothesis for paternal and maternal chromosomes for each SNP p p p and m m m i.e. H H H where H p . . . p and H m . . . m which are independent.

Given SNPs a b at base locations l l given in bases the probability of crossover is approximated as P l l 0.5 1 exp 2G l l where G l l genetic distance in Morgans between locations l l. There is no precise closed form function for G but it is loosely estimated as G l l l l 1e. A better approximation can be used by taking advantage of the HapMap database of base locations s and distances G s s for i spanning over all locations. In particular 

Given the limitation of computer time and the exponential scaling of complexity of the above method as the number of SNPs increases in some cases it may be necessary to use more expedient methods to determine the hypothesis of maximal probability and thus make the relevant SNP calls. A more rapid way to accomplish this follows 

From before P H M P M H P H P M argmaxP H M argmaxand P M H P H argmaxF M H and the object is to find H maximizing F M H .

Suppose M measurement on snips s to k H hypothesis on snips s to k and for shorts M M H H measurement and hypothesis on snip k. As shown before 

Since there are only four hypotheses to remember at any time and a constant number of operations the algorithm is linear.

The algorithm is similar to the case above where i 2 n and in each step a new set of W i are generated until the final step yields the optimized W.

For the purpose of explanation this section will focus on the paternal diploid and haploid data but it is important to note that maternal data can be treated similarly. Let 

The term correspond is used since it can mean either be equal or originate with higher probability from depending on different measurement outcomes and population frequency.

The goal of the algorithm is to calculate probabilities of true allele values hidden beyond results of raw measurement h d d p p pand population frequencies.

 i determine whether h corresponds to dor dbased on h d d p p pvalues and the population frequency data

The task is to calculate probabilities of these two hypotheses given the measurement M and To simplify the text these will be referred to as P H M and P H M hereafter.

In order to calculate P M H and P M H one must consider the set of all possible values of diploid outcomes dand d AA AC . . . GG i.e. any combination of A C T G so called underlying states. When the hypotheses are applied to the underlying states i.e. accompany the assumed value of h based on hypothesis Hor H to values dand d the following tables of all possible combinations states S s s . . . s of true values H Dand Dfor h dand d can be generated respectively. These are listed here 

The calculation of the probability of correct allele call hitting the true allele value is based on measurement of outcome x given the true value of allele X. If the measured value x and the true value X are equal that probability is p the probability of correct measurement . If x and X are different that probability is 1 p 3. For example calculate the probability that the true value C is found under the conditions that X C and the measured value is x A. The probability of getting A is p. The probability of getting C T or G is 1 p . So the probability of hitting C is 1 p 3 since one can assume that C T and G are equally likely.

If the indicator variable Iis included in the calculation where I 1 if x X and I 0 if x X the probabilities are as follows 1 1 in Now consider the last two terms in P M H . P D and P D are population frequencies of alleles A C T and G that may be known from prior knowledge.

Consider the expression shown above for a particular state s given the particular measurement M h A d G d C 

Similarly calculate 1 given the particular measurement in this case M h A d G d C for remaining 15 states and sum over the set .

Since the origin of pis unknown it is derived from dwith probability of P H M and from dwith probability P H M one must consider both cases that pallele originates from dor d. For Hypothesis H applying Bayes rule give 

Here is an elaboration of H. In the true case case pwill be equal to A only if the haploid and the corresponding diploid cell are equal to A. Therefore in order to calculate pand pone must consider situations where haploid and corresponding diploid cell are equal. So the hypothesis H the true value of pis A and becomes H the true value of the haploid cell and corresponding diploid cell is A.

Since the origin of h is unknown it is derived from dwith probability of P H M and from dwith probability P H M one must consider both cases that h allele originates from dor d and implement that in determination of p. That means using Bayes rule 

P H M P H H M P H H M and now we have calculated the probability that pis equal to A. Repeat the calculation for C T and G. The highest value will give the answer of pallele call and corresponding probability.

Two input examples are shown. The first example is of a set of SNPs with a low tendency to cosegregate that is SNPs spread throughout a chromosome and the input data is shown in . The second example is of a set of SNPs with a high tendency to cosegregate that is SNPs clustered on a chromosome and the input data is shown in . Both sets of data include an individual s measured SNP data the individual s parents SNP data and the corresponding confidence values. Note that this data is actual data measured from actual people. Each row represent measurements for one particular SNP location. The columns contain the data denoted by the column header. The key to the abbreviations in the column headers is as follows 

The two examples of output data are shown in and and correspond to the output data from the data given in and respectively. Both tables show an individual s measured SNP data the individual s parents SNP data the most likely true value of the individual s SNP data and the corresponding confidences. Each row represents the data corresponding to one particular SNP. The columns contain the data denoted by the column header. The key to the abbreviations in the column headers is as follows 

Note that this algorithm can be implemented manually or by a computer. and show examples of input data for a computer implemented version of the method. shows the output data for the input data shown in . shows the output data for the input data shown in .

Below is a second simulation which was done to ensure the integrity of the system and to assess the actual efficacy of the algorithm in a wider variety of situations. In order to do this 10 000 full system simulations were run. This involves randomly creating parental genetic data emulating meiosis in silico to generate embryonic data simulating incomplete measurement of the embryonic data and then running the method disclosed herein to clean the simulated measured embryonic data and then comparing the simulated cleaned data with the simulated real data. A more detailed explanation of the simulation is given below and the visual representation of the flow of events is given in . Two different implementations of the theory were tested. A fuller explanation is given below.

These values should be fixed based on the results from empirical data population frequency on relevant SNPs and from measuring instrumentation performance ph pd pe . The simulation was run for several scenarios such as most likely informed uniform uninformed and very unlikely extreme case .

Once the above static parameters are fixed crossover probabilities given the particular SNPs are the same for all the simulations and will be derived ahead of the time given the databases for snip location SNIPLOC NAME MAT and genetic distance HAPLOC NAME MAT .

The preliminary simulation loop is to demonstrate that the genetic data that will be used for the full simulation is realistic. Steps 1 through 5 were repeated 10 000 times. Note that this simulation can be run for either or both parents the steps are identical. In this case the simulation will be run for the paternal case for the purposes of illustration and the references to will also include the corresponding maternal entry in in parentheses. This simulation was also run using Matlab.

Generate original paternal cells depending on the population frequency for each SNP for father cells.

Simulate crossover of the parental chromosomes to give two sets of chromosomes crossed over P1C1 P2C1 and P1C2 P2C2 . Pick one of the father alleles after the crossover from the first set for haploid allele HP in this case P1 since there is no difference which one and mix up the order in the diploid alleles to get D1P D2P .

DHAlgo takes alleles from haploid cell and an unordered alleles from diploid cell and returns the most likely ordered diploid alleles that gave rise to these. DHAlgo attempts to rebuild P1 P2 also returns estimation error for father pp1 pp2 . For comparison the empirical algorithm that does simple allele matching is also used. The goal is to compare how much better is the disclosed algorithm compared to the simple empirical algorithm.

Note P1S P2S P1P P2P P1A P2A I I pp p1 p2 where I is binary indicator array for estimation of DH algorithm accuracy for all the SNPs similarly for I. p pare probabilities of a correct allele call derived from the algorithm and p1 mean I i.e. average accuracy for this run for p1 similar for p2.

Ten thousand simulations were used to estimate the algorithm accuracy DHAccuracy.P1 mean P1A DHAccuracy.P2 mean P2A which shows the overall accuracy of the DH algorithm from P1 P2. On an individual SNP basis the average accuracy on each SNP SNPAcc.P1 mean P1S should agree with the average of the estimated probability of correctly measuring that SNP SNPProb.P1 mean P2P i.e. if the algorithm works correctly the value for SNPAcc.P1 should correspond closely to SNPProb.P1. The relationship between these two is reflected by their correlation.

STAlgorithm in order to assess the performance of the disclosed algorithm. The results of all these runs are summarized in .

The disclosed algorithm is performs better than the existing empirical algorithm in these simulations especially for the realistic cases of non uniform population frequency and unbalanced or reduced probabilities of correct measurements. It has also been confirmed that our estimates of the algorithm accuracy for individual SNPs are very good in these cases since the correlation between the estimated accuracy of correct allele call and simulation average accuracy is around 99 with average ratio of 1.

In the most realistic case for data population frequency and ph pd 0.6 0.8 the average percent of correctly retrieved SNPs for P1 P2 is 0.852 0.816 in implementation 1 and 0.601 0.673 in implementation 2.

Note that for and the rows beginning with data use population frequency data was taken from empirical results while the rows beginning with uniform assume uniform populations.

It is important to note that in and the accuracy is defined as the average percent of SNPs where the correct SNP call was made and the correct chromosome of origin was identified. It is also important to note that these simulations reflect two possible implementations of the algorithm. There may be other ways to implement the algorithm that may give better results. This simulation is only meant to demonstrate that the method can be reduced to practice.

Steps 1 8 were repeated 10000 times. This is the simulation to test the full disclosed method to clean measured genetic data for a target individual using genetic data measured from related individuals in this case the parents. This simulation was run using Matlab.

Generate original parental cells depending on the population frequency for each SNP for mother and father cells.

Generate two sets of paternal cells with crossovers first to get P1C1 P2C1 used in DHAlgo and second time to get P1C2 P2C2 used in PSAlgo. 

Generate two sets of maternal cells with crossovers first to get M1C1 M2C1 used in DHAlgo and M1C2 M2C2 used in PSAlgo. 

Pick one of the sets of paternal cells first set for haploid cell HP and mix up the order in the diploid cell to get D1P D2P . Do the same for mother cells first set to get MH D1M D2M . .

Pick one of the paternal cells second set and one of the maternal cells second set for embryo cell. Mix up the order for measurement purposes.

Based on given measurement error ph haploid cells pd unordered diploid cells pe embryo cells introduce error into the measurements.

DHAlgo takes a haploid cell and an unordered diploid cell and returns the most likely ordered diploid cell that gave rise to these. DHAlgo attempts to rebuild P1C1 P2C1 for father and M1C1 M2C1 for mother chromosomes also returns estimation error for father pp1 pp2 and mother pm1 pm2 cells.

PSAlgo takes rebuilt parent cells p1 p2 m1 m2 and unordered measured embryo cell e1 e2 to return most likely ordered true embryo cell DE1 DE2 . PS Algo attempts to rebuild E1 E2 .

 DE1 DE2 alldata PSAlgo snips e1 e2 p1 p2 m1 m2 pe pp1 pp2 pm1 pm2 parameters crossprob popfreqlistPP popreqlistMM 

Ten thousand simulations were run and the final estimates for the algorithm accuracy PSAccuracy.E1 mean E1A PSAccuracy.E2 mean E2A which tells us the overall accuracy of the PS algorithm from E1 E2 were calculated. On an individual SNP basis the average accuracy on each SNP SNPAcc.E1 mean E1S should agree with the average of the estimated probability of correctly measuring that SNP SNPProb.E1 mean E2P i.e. if the algorithm is written correctly then SNPAcc.E1 should be observed to correlate to SNPProb.E1. The relationship between these two is reflected by their correlation.

STPSAlgorithm in order to assess the performance of the disclosed algortihm. The results of these runs are summarized in the .

The disclosed algorithm is performs better than the existing empirical algorithm in these simulations especially for the realistic cases of non uniform population frequency and unbalanced or reduced probabilities of correct measurements. It has also been shown that the estimates of the algorithm accuracy for individual SNPs are very good in these cases since the correlation between the estimated accuracy of correct allele call and simulation average accuracy is around 99 with average ratio of 1.

In the most realistic case for data population frequency and ph pd pe 0.6 0.8 0.8 the average percent of correctly retrieved SNPs for E1 E2 is 0.777 0.788 in implementation 1 and 0.835 0.828 in implementation 2. As mentioned above the number denoting the average accuracy of algorithm refers not only to the correct SNP call but also the identification of correct parental origin of the SNP. To be effective an algorithm must return better results than the algorithm that simply accepts the data as it is measured. One might be surprised to see that in some cases the accuracy of the algorithm is lower than the listed accuracy of measurement. It is important to remember that for the purposes of this simulation a SNP call is considered accurate only if it is both called correctly and also its parent and chromosome of origin is correctly identified. The chance of getting this correct by chance is considerably lower than the measurement accuracy.

There are many techniques available allowing the isolation of cells and DNA fragments for genotyping. The system and method described here can be applied to any of these techniques specifically those involving the isolation of fetal cells or DNA fragments from maternal blood or blastocysts from embryos in the context of IVF. It can be equally applied to genomic data in silico i.e. not directly measured from genetic material.

Adult diploid cells can be obtained from bulk tissue or blood samples. Adult diploid single cells can be obtained from whole blood samples using FACS or fluorescence activated cell sorting. Adult haploid single sperm cells can also be isolated from sperm sample using FACS. Adult haploid single egg cells can be isolated in the context of egg harvesting during IVF procedures.

Isolation of the target single blastocysts from human embryos can be done following techniques common in in vitro fertilization clinics. Isolation of target fetal cells in maternal blood can be accomplished using monoclonal antibodies or other techniques such as FACS or density gradient centrifugation.

DNA extraction also might entail non standard methods for this application. Literature reports comparing various methods for DNA extraction have found that in some cases novel protocols such as the using the addition of N lauroylsarcosine were found to be more efficient and produce the fewest false positives.

Amplification of the genome can be accomplished by multiple methods including ligation mediated PCR LM PCR degenerate oligonucleotide primer PCR DOP PCR and multiple displacement amplification MDA . Of the three methods DOP PCR reliably produces large quantities of DNA from small quantities of DNA including single copies of chromosomes this method may be most appropriate for genotyping the parental diploid data where data fidelity is critical. MDA is the fastest method producing hundred fold amplification of DNA in a few hours this method may be most appropriate for genotyping embryonic cells or in other situations where time is of the essence.

Background amplification is a problem for each of these methods since each method would potentially amplify contaminating DNA. Very tiny quantities of contamination can irreversibly poison the assay and give false data. Therefore it is critical to use clean laboratory conditions wherein pre and post amplification workflows are completely physically separated. Clean contamination free workflows for DNA amplification are now routine in industrial molecular biology and simply require careful attention to detail.

The genotyping of the amplified DNA can be done by many methods including MOLECULAR INVERSION PROBES MIPs such as AFFMETRIX s GENFLEX Tag Array microarrays such as AFFMETRIX s 500K array or the ILLUMINA Bead Arrays or SNP genotyping assays such as APPLIED BIOSYSTEMS s TAQMAN assay. The AFFMETRIX 500K array MIPs GENFLEX TAQMAN and ILLUMINA assay all require microgram quantities of DNA so genotyping a single cell with either workflow would require some kind of amplification. Each of these techniques has various tradeoffs in terms of cost quality of data quantitative vs. qualitative data customizability time to complete the assay and the number of measurable SNPs among others. An advantage of the 500K and ILLUMINA arrays are the large number of SNPs on which it can gather data roughly 250 000 as opposed to MIPs which can detect on the order of 10 000 SNPs and the TAQMAN assay which can detect even fewer. An advantage of the MIPs TAQMAN and ILLUMINA assay over the 500K arrays is that they are inherently customizable allowing the user to choose SNPs whereas the 500K arrays do not permit such customization.

In the context of pre implantation diagnosis during IVF the inherent time limitations are significant in this case it may be advantageous to sacrifice data quality for turn around time. Although it has other clear advantages the standard MIPs assay protocol is a relatively time intensive process that typically takes 2.5 to three days to complete. In MIPs annealing of probes to target DNA and post amplification hybridization are particularly time intensive and any deviation from these times results in degradation in data quality. Probes anneal overnight 12 16 hours to DNA sample. Post amplification hybridization anneals to the arrays overnight 12 16 hours . A number of other steps before and after both annealing and amplification bring the total standard timeline of the protocol to 2.5 days. Optimization of the MIPs assay for speed could potentially reduce the process to fewer than 36 hours. Both the 500K arrays and the ILLUMINA assays have a faster turnaround approximately 1.5 to two days to generate highly reliable data in the standard protocol. Both of these methods are optimizable and it is estimated that the turn around time for the genotyping assay for the 500 k array and or the ILLUMINA assay could be reduced to less than 24 hours. Even faster is the TAQMAN assay which can be run in three hours. For all of these methods the reduction in assay time will result in a reduction in data quality however that is exactly what the disclosed invention is designed to address. Some available techniques that are faster are not particularly high throughput and therefore are not feasible for highly parallel prenatal genetic diagnosis at this time.

Naturally in situations where the timing is critical such as genotyping a blastocyst during IVF the faster assays have a clear advantage over the slower assays whereas in cases that do not have such time pressure such as when genotyping the parental DNA before IVF has been initiated other factors will predominate in choosing the appropriate method. For example another tradeoff that exists from one technique to another is one of price versus data quality. It may make sense to use more expensive techniques that give high quality data for measurements that are more important and less expensive techniques that give lower quality data for measurements where the fidelity is not critical. Any techniques which are developed to the point of allowing sufficiently rapid high throughput genotyping could be used to genotype genetic material for use with this method.

As noted previously given the benefit of this disclosure there are more aspects and embodiments that may implement one or more of the systems methods and features disclosed herein. Below is a short list of examples illustrating situations in which the various aspects of the disclosed invention can be combined in a plurality of ways. It is important to note that this list is not meant to be comprehensive many other combinations of the aspects methods features and embodiments of this invention are possible.

One example is the system which may operate in an IVF laboratory see that would allow full genotyping of all viable embryos within the time constraints of the IVF procedure. This would require a turn around time from egg fertilization to embryo implantation of under three days. This system may consist of parental genetic samples from IVF user mother and IVF user father being analyzed at IVF lab using a genotyping system. It may involve multiple eggs that are harvested from the mother and fertilized with sperm from the father to create multiple fertilized embryos . It may involve a laboratory technician extracting a blastocyst for each embryo amplifying the DNA of each blastocyst and analyzing them using a high throughput genotyping system . It may involve sending the genetic data from the parents and from the blastocyst to a secure data processing system which validates and cleans the embryonic genetic data. It may involve the cleaned embryonic data being operated on by a phenotyping algorithm to predict phenotype susceptibilities of each embryo. It may involve these predictions along with relevant confidence levels being sent to the physician who helps the IVF users and to select embryos for implantation in the mother .

Another example could utilize a variety of genotyping measurement techniques in a way that would optimize the value of each. For example a lab could use an technique that is expensive but can give high quality data in cases with low signal such as APPLIED BIOSYSTEMS s TAQMAN assay to measure the target DNA and use a technique that is less expensive but requires a greater amount of genetic material to give good quality data such as AFFMETRIX s 500K Genechip or MIPs to measure the parental DNA.

Another example could be a situation in which a couple undergoing IVF treatment have eggs harvested from the woman and fertilized with sperm from the man producing eight viable embryos. A blastocyst is harvested from each embryo and the genomic data from the blastocysts are measured using TAQMAN Genotyping Assay. Meanwhile the diploid data is measured from tissue taken from both parents using MOLECULAR INVERSION PROBES. Haploid data from one of the man s sperm and one of the woman s eggs is also measured using MIPs. The genetic data of the parents is used to clean the SNP data of the eight blastocysts. The cleaned genetic data is then used to allow predictions to be made concerning the potential phenotypes of the embryos. Two embryos are selected which have the most promising profile and allowed to implant in the woman s uterus.

Another example could be a situation where a pregnant woman whose husband has a family history of Tay Sachs disease wants to know if the fetus she is carrying is genetically susceptible but she does not want to undergo amniocentesis as it carries a significant risk of miscarriage. She has her blood drawn some fetal DNA is isolated from her blood and that DNA is analyzed using MIPs. She and her husband had already had their full genomic data analyzed previously and it is available in silico. The doctor is able to use the in silico knowledge of the parental genomes and the method disclosed herein to clean the fetal DNA data and check if the critical gene that is responsible for Tay Sachs disease is present in the genome of the fetus.

Another example could be a situation where a 44 year old pregnant woman is concerned that the fetus she is carrying may have Downs Syndrome. She is wary of having an intrusive technique used for pre natal diagnosis given a personal history of miscarriages so she chooses to have her blood analyzed. The health care practitioner is able to find fetal cells in the maternal blood sample and using the method disclosed herein together with the knowledge of the woman s own genetic data is able to diagnose for aneuploidy.

Another example could be a situation where a couple are undergoing IVF treatment they have eggs harvested from the woman and fertilized with sperm from the man producing nine viable embryos. A blastocyst is harvested from each embryo and the genomic data from the blastocysts are measured using an ILLUMINA BEAD ARRAY. Meanwhile the diploid data is measured from tissue taken from both parents using MOLECULAR INVERSION PROBES. Haploid data from the father s sperm is measured using the same method. There were no extra eggs available from the mother so bulk diploid tissue samples are taken from her own father and mother and a sperm sample from her father. They are all analyzed using MIPs and the method disclosed herein is used to provide a genetic analysis for the mother s genome. That data is then used along with the father s diploid and haploid data to allow a highly accurate analysis of the genetic data of each of the blastocysts. Based on the phenotypic predictions the couple chooses three embryos to implant.

Another example could be a situation where a racehorse breeder wants to increase the likelihood that the foals sired by his champion racehorse become champions themselves. He arranges for the desired mare to be impregnated by IVF and uses genetic data from the stallion and the mare to clean the genetic data measured from the viable embryos. The cleaned embryonic genetic data allows the breeder to find relevant genotypic phenotypic correlations and select the embryos for implantation that are most likely to produce a desirable racehorse.

Another example could be a situation where a pregnant woman wants to know whether the fetus she is carrying is predisposed towards any serious illness. The father has since passed away and so the haploid and diploid data generated from the father s brother and the father s father are used to help clean the genetic data of the fetus measured from fetal cells gathered during fetal blood sampling. A company contracted by the health care practitioner uses the cleaned fetal genetic data to provide a list of phenotypes that the fetus is likely to exhibit along with the confidence of each prediction.

Another example could be an amniocentesis lab that must occasionally contend with contaminated fetal genetic data due to poor laboratory techniques. The disclosed method could be used to clean the contaminated fetal genetic data using maternal and paternal genetic data. One could imagine a situation where a laboratory is able to cut costs by relaxing sterility procedures knowing that the disclosed method would be able to compensate for an increased rate of contaminating DNA.

Another example could be a situation in which a woman in her forties is undergoing IVF to get pregnant. She wants to screen the embryos to select the one s that are least likely to have a genetic illness and are most likely to implant and carry to term. The IVF clinic she is using harvests a blastocyst from each of the viable embryos and uses standard procedures to amplify the DNA and measure key SNPs. The technician then uses the methods disclosed herein to screen for chromosomal imbalances and also to find and clean the genetic data of the embryos to make predictions about the phenotypic predispositions of each embryo.

Another example could be a situation where a pregnant woman has amniocentesis and the genetic material in the fetal cells in the blood sample are used along with the methods described herein to screen for aneuploidy and other chromosomal abnormalities.

It is important to note that the method described herein concerns the cleaning of genetic data and as all living creatures contain genetic data the methods are equally applicable to any human animal or plant that inherits chromosomes from parents. The list of animals and plants could include but is not limited to gorillas chimpanzees bonobos cats dogs pandas horses cows sheep goats pigs cheetahs tigers lions salmon sharks whales camels bison manatees elk swordfish dolphins armadillos wasps cockroaches worms condors eagles sparrows butterflies sequoia corn wheat rice petunias cow s vetch sun flowers ragweed oak trees chestnut trees and head lice.

The measurement of genetic data is not a perfect process especially when the sample of genetic material is small. The measurements often contain incorrect measurements unclear measurements spurious measurements and missing measurements. The purpose of the method described herein is to detect and correct some or all of these errors. Using this method can improve the confidence with which the genetic data is known to a great extent. For example using current techniques uncleaned measured genetic data from DNA amplified from a single cell may contain between 20 and 50 unmeasured regions or allele dropouts. In some cases the genetic data could contain between 1 and 99 unmeasured regions or allel dropouts. In addition the confidence of a given measured SNP is subject to errors as well.

In a case where the uncleaned data has an allele dropout rate of approximately 50 it is expected that after applying the method disclosed herein the cleaned data will have correct allele calls in at least 90 of the cases and under ideal circumstances this could rise to 99 or even higher. In a case where the uncleaned data has an allele dropout rate of approximately 80 it is expected that after applying the method disclosed herein the cleaned data will have correct allele calls in at least 95 of the cases and under ideal circumstances this could rise to 99.9 or even higher. In a case where the uncleaned data has an allele dropout rate of approximately 90 it is expected that after applying the method disclosed herein the cleaned data will have correct allele calls in at least 99 of the cases and under ideal circumstances this could rise to 99.99 or even higher. In cases where a particular SNP measurement is made with a confidence rate close to 90 the cleaned data is expected to have SNP calls with confidence rate of over 95 and in ideal cases over 99 or even higher. In cases where a particular SNP measurement is made with a confidence rate close to 99 the cleaned data is expected to have SNP calls with confidence rate of over 99.9 and in ideal cases over 99.99 or even higher.

It is also important to note that the embryonic genetic data that can be generated by measuring the amplified DNA from one blastomere can be used for multiple purposes. For example it can be used for detecting aneuploides uniparental disomy sexing the individual as well as for making a plurality of phenotypic predictions. Currently in IVF laboratories due to the techniques used it is often the case that one blastomere can only provide enough genetic material to test for one disorder such as aneuploidy or a particular monogenic disease. Since the method disclosed herein has the common first step of measuring a large set of SNPs from a blastomere regardless of the type of prediction to be made a physician or parent is not forced to choose a limited number of disorders for which to screen. Instead the option exists to screen for as many genes and or phenotypes as the state of medical knowledge will allow. With the disclosed method the only advantage to identifying particular conditions to screen for prior to genotyping the blastomere is that if it is decided that certain PSNPs are especially relevant then a more appropriate set of NSNPs which are more likely to cosegregate with the PSNPs of interest can be selected thus increasing the confidence of the allele calls of interest. Note that even in the case where SNPs are not personalized ahead of time the confidences are expected to be more than adequate for the various purposes described herein.

