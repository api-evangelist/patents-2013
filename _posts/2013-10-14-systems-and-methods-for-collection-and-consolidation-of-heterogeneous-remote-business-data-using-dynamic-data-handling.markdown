---

title: Systems and methods for collection and consolidation of heterogeneous remote business data using dynamic data handling
abstract: Remote data collection systems and methods retrieve data including financial, sales, marketing, operational and the like data from a plurality of databases and database types remotely over a network in an automated, platform-agnostic manner. An Extract Transform and Load (ETL) data replication method for Chart of Account (COA) standardization includes receiving a request for remote data collection to extract data from a data source; extracting data in a non-intrusive manner from the data source, wherein the data comprises non-standard COA data; and transforming one of an entire set or a subset of the extracted data based on the request based on a template or a standardized form desired for comparisons.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09411864&OS=09411864&RS=09411864
owner: Zeewise, Inc.
number: 09411864
owner_city: Atlanta
owner_country: US
publication_date: 20131014
---
The present non provisional patent application is a continuation in part of U.S. patent application Ser. No. 13 540 415 filed Jul. 2 2012 and entitled REMOTE DATA COLLECTION SYSTEMS AND METHODS USING READ ONLY DATA EXTRACTION AND DYNAMIC DATA HANDLING now U.S. Pat. No. 8 560 568 issued on Oct. 15 2013 which is a continuation in part of U.S. Pat. No. 8 214 329 filed Aug. 26 2009 issued on Jul. 3 2012 and entitled REMOTE DATA COLLECTION SYSTEMS AND METHODS which claims priority to U.S. Provisional Patent Application Ser. No. 61 136 291 filed Aug. 26 2008 entitled REMOTE DATA COLLECTION SYSTEM each of which is incorporated in full by reference herein.

The present invention relates generally to collection consolidation and processing of multiple remote data sets using a dynamic and adaptive Extract Transform and Load ETL data replication system. More particularly the present invention provides remote data collection systems and methods for retrieving and processing data from one or more databases such as financial data from accounting systems such as QuickBooks by Intuit sales or marketing lead generation data from various Point of Sale POS systems and in general any type of Line of Business LOB data using a plurality of database types at a plurality of remote locations over a network in an automated platform agnostic manner to facilitate the operation of a comparative Business Intelligence BI process which provides Key Performance Indicators KPIs business scorecards and visualized business reports such as Visual Cash Flow by ZeeWise to various independent business users with normative comparisons within user defined business peer groups .

The collection consolidation and general centralized data processing of business data is a necessary pre condition to the operation of modern data warehouse systems also known as Business Intelligence BI systems and or Big Data BD systems. In order to analyze and or visualize the data calculate statistics compare values identify or generate key data elements and in general provide modern business reports on business data a centralized database system must incorporate take in or consume and process data from one or more remote or external business systems. This general data input process is known as an Extract Transform and Load ETL process which various database or other software vendors may provide as part of their core SQL database or data warehouse or BI systems. However some of the key problems in building data warehouses or BI systems in general is identifying and describing which types of data are required to be collected identifying where the required data is located in various foreign or remote business systems and most importantly extracting and processing the required data from multiple heterogeneous remote data sources while performing these steps on a recurring and ideally automated basis. Typically ETL processes are fed from well known or standardized enterprise type business systems such as ERP CRM or CMS systems using well known bulk data extraction procedures or even more modern web services type interfaces which are provided by the external enterprise data source system. This type of architecture works well for large companies and or enterprise type data sources as there is sufficient personnel technology infrastructure and documented system interfaces or Application Programming Interfaces APIs to identify and extract this data which is then fed into the ETL process built by the enterprise IT personnel or vendor supplied systems. Most commonly these data sources are located within or operate internal to an organization e.g. within their own private network or behind an Internet firewall on a common shared network and or transfer data from Internet based SaaS systems over the public Internet using Service Oriented Architectures SOA web services with published well known or even privately negotiated interfaces or APIs to extract data and send it into an ETL system. In the simplest case an ETL system may use simple methods such as a SQL query for data extraction to a flat file combined with a FTP file transfer to a secure landing site operated by the existing ETL process. These types of systems designs are well known to those with a general level of IT knowledge or those who work for large corporations and or consult or support data warehouse or BI systems and or work for BI or data warehousing or ETL type vendors. This type of data processing is in common practice at an enterprise level where sophisticated and custom systems integration tools data modeling and software development skills are in abundance along with the resources to create manage and support such systems including storing vast quantities of data or Big Data BD in a system.

However this well known ETL design does not work for the majority of businesses today that is the millions of small and medium SMB sized businesses who have neither the enterprise IT skills personnel or infrastructure or even budget to operate such a complex ETL and or BI system. What is needed therefore and embodied within the present invention is the ability to operate a similar enterprise like ETL process in order to create an SMB BI or BD system which works across and adapts to a variety of non enterprise software and data sources including at thousands or even millions of remote sites in a lights out automated manner while still allowing the various SMB members to benefit from the business insight gained from BI reports dashboards scorecards tools and or metrics. The general purpose of the SMB BI system is to help business owners operators managers and even employees to understand how their specific or local business is performing using a wide range of key business measurements statistics computed or qualitative scoring ranking and identified data values in a variety of reporting formats or types including enhanced visual reports especially on an individual and or peer group basis.

The difficulty of designing let alone operating this type of system is significant when one considers that these SMB business owners may own or operate one or more SMB locations but generally do not have detailed database data warehouse BI or even general IT skills at their location let alone multiple remote locations. While they may have selected their LOB systems from commercial off the shelf COTS software vendors or customized it extensively by a VAR or other vendor or even had them custom built by programmers hired for the project they usually do not broadly understand the internal operations of these LOB systems. This includes how to get at define extract and select specific data sets from a specific system and integrate that data subset into other systems. Thus operating a general purpose ETL system which can dynamically adapt to the wide variety types and conditions found within various SMB locations requires the specific abilities of the present invention. Without the embodiments of this system design the successful collection and consolidation of the required remote SMB data can t be provided by the average small or medium business owner manager or employee nor can the SMB BI system be utilized to improve their business with having access to all of the data in a consolidated comparative form.

In order to participate in an enterprise type BI system SMB businesses face a variety of difficulties if not outright obstacles or barriers to success. First each remote SMB business must provide business data on a frequent if not regular basis which can be time consuming if not prohibitive if it cannot be made available to them in an automated manner without expensive software customization programming and or consulting labor. Second the data provided must be processed from the internal format used by the desired LOB POS or financial and or accounting systems and transformed into a standardized or normalized form which may be required by the SMB BI system to make an apples to apples type comparison across various members. Most likely the SMB business participant does not understand how to generate this type of reformatted or transformed data from their individual LOB systems let alone have the ability to produce it on a frequent basis and in a rigorous and consistent manner. More significant to the overall system design each SMB owner may not be utilizing the same database design schema or database elements particularly if they utilize different version levels of the same system from the same vendor. This challenge is made even worse if multiple SMB sites use different types of LOB systems i.e. inventory sales ordering and the like or systems from different vendors. Thus the ETL process is generally unmanageable if not outright impossible for individual SMB participants.

Among the millions of SMB businesses in the US many are based on the franchised business model. Franchising is an approach to doing business whereby the owner of a business concept i.e. a Franchisor licenses the business model to an independent business entity i.e. a Franchisee to operate under the terms of a well defined franchise agreement. The Franchisor authorizes the usage of proven trade dress operating methods and systems as well as business practices within the guidelines set forth in the agreement. The Franchisor provides various support services that may include advertising marketing public relations training operating physical facility design assistance product menu specifications material sourcing support design and production of business operating systems or methods including specification or design of specific Line of Business LOB applications Point of Sales POS systems and or other business support. Such support is generally provided to the Franchisee for a royalty fee typically calculated as a percentage of gross monthly sales which the Franchisee typically faxes or emails to the Franchisor on a monthly basis. In the US as of 2005 the franchising business model was utilized in over 70 different industry segments by 2 500 Franchisors with over 900 000 individual franchisee locations generating more than 1 trillion in revenues. Each business utilizes one or more LOB applications which are a set of critical computer applications that are vital to running various aspects of the business such as production operations sales and marketing accounting supply chain management resource planning applications and the like. LOB applications are usually specialized programs that contain a number of integrated capabilities which tie into and depend upon the features of databases and database management systems to store retrieve and manage critical transaction and business data. Even with this vast level of support most individual franchise owners struggle to understand the health of their business let alone have the ability to compare their performance to those of similar peers within a franchise system while further comparisons to competitors or operators of frequently non franchised independent businesses e.g. dry cleaners and the like may be totally unavailable. Additionally even small or medium sized Franchisors desire to operate at an enterprise level by viewing a comprehensive rolled up or consolidated view of their entire business while still maintaining the ability to drill down to the individual unit or peer group levels to understand the details of any specific unit operation or item. Thus most SMB business owners struggle to identify compute or visualize their own business data let alone find or understand effective business metrics or measurements that are generated for comparative or BI purposes. These SMB users are even further behind when seeking to compare themselves to other businesses as part of an effective SMB BI community using peer groups or other BD techniques.

Franchisors have a fiduciary legal obligation to support the franchisees in their efforts to successfully operate the concept. Unfortunately Franchisors typically struggle to know how their Franchisees are performing as it is very difficult to collect consolidate and report on the key operational and financial indicators for each of the Franchisees. At least one known reason for this difficulty is because many of these individual Franchisees utilize different operational and financial reporting systems that cannot be easily collected from consolidated or reported upon due to their different data storage formats different product versions or non standardized product deployments. As a result Franchisors are often left to advise Franchisees on how to improve their business and operational performance with very limited data and they lack the ability to compare them to peer groups and or regional norms within the concept or industry. Additionally while most businesses and business consultants desire to identify operational Key Performance Indicators KPI having limited data makes it difficult to identify and monitor these businesses on a consistent basis.

While Franchising is one example of an industry that can utilize a remote data collection system with a dynamic and adaptive ETL capability there are many other industries or business models which can benefit from such a system. Other examples include trade associations co operatives or distributors and the like but can also include branch or field offices of large corporate enterprises. Another example is a bank or credit provider who desires to monitor the financial health of one or more businesses to which they make loans or to whom they extend lines of credit. This enables a new type of loan and lines processing and lines of credit tracking which may be tied to financial measurements such as accounts receivable AR cash flow or profitability. Typically businesses who desire to remotely monitor the financial and or operational parameters of a business depend on emailed or faxed copies of monthly quarterly or year end reports which are often lost ignored or obsolete by the time they are received or reviewed. Worse yet comparison among and between businesses is difficult if not impossible without normalizing the financial data into consistent sets using a standardized Chart of Accounts COA to consistently quantify accounting and financial data. In addition these reports are inadequate to monitor dynamic business conditions and certainly cannot provide monitoring in a near real time and consolidated manner which may reduce business or lending risks without extensive customized Information Technology IT systems and support personnel. In general the problem and challenges of remote data collection and ETL processing can be seen to apply to any and all businesses with multiple locations where financial accounting POS or LOB applications operate and where the need to monitor rank or compare these businesses requires access to the data from each location in a consolidated or rolled up and optionally a standardized or normalized fashion. Finally for purposes of definition readability and clarity the use of the terms cloud system Big Data BD system SaaS system or enterprise websites or portals and the like whenever used in the application should be seen to refer to similar if not operationally or functionally identical concepts or usages or be interchangeable when viewed from the point of view of the invention.

In an exemplary embodiment an Extract Transform and Load ETL data replication method for Chart of Account COA standardization includes receiving a request for remote data collection to extract data from a data source extracting data in a non intrusive manner from the data source wherein the data comprises non standard COA data and transforming one of an entire set or a subset of the extracted data based on the request based on a template or a standardized form desired for comparisons.

In another exemplary embodiment a remote data collection system includes a network interface a connection to a data source a processor communicatively coupled to the network interface and the connection and memory storing instructions for remote data collection that when executed cause the processor to receive a request for remote data collection to extract data from the data source extract data in a non intrusive manner from the data source wherein the data comprises non standard COA data and transform one of an entire set or a subset of the extracted data based on the request based on a template or a standardized form desired for comparisons.

The remote data consolidation process of the present invention is flexible yet comprehensive and complete while allowing for variability complexity and individual requirements of a variety of LOB applications running in a variety of situations at remote sites. The unique and novel design features and attributes provided by the definition abstraction model of the invention allow these capabilities to be adapted to the variety of LOB applications without executable program code being introduced into the LOB or database applications. Additional benefits of this design allow a central administrator to schedule data collection from a variety of remote LOB applications and database formats across many sites without local IT help while yielding a central consolidated view of the entire business operation. Additional flexibility is shown through the use of optional LOB add in components local UI components to alert remote site personnel and allow them to be part of the automated process along with an optional deployment of the consolidation database server at a customer s site. As a result the remote data collection system provides a database from which management reports dashboards and monitoring can be performed to increase the efficiency effectiveness and overall profitability of these remote sites while also allowing for increased visibility into the underperforming sites and enabling proactive support to be provided before it is too late. This is accomplished by the client agent and server design the use of definitions and updates along with a central management approach without the need for expensive and scarce remote IT people.

The flexibility of the present invention is derived from a foundation built on top of an abstract message passing architecture plus the use metadata messages to control and configure the agent along with a layered code design which allows for the replacement of code layers without disruption or reinstallation of the entire system. The key to the lights out remote control and operation of the system is due to the use of an automated installation package plus a set of system metadata messages which define and control what to do at the remote agent once it is installed. This architecture allows the entire system to be centrally managed and monitored over the same message communication infrastructure which is used to collect remote data. The metadata messages are built from a configuration database which defines both the system definition rules and the client agent update versions . The system also uses messages to provide for a centralized log of all remote agent state or status. Definitions are records which store the collection rules which tell the remote client agent what to do how to do it and when to do it. Using the existing data replication message transport system definitions and update files can be sent out to the remote sites to update the existing agent code and reconfigure the collection process. Thus the overall system characteristics including the flexibility adaptability and performance with low IT overhead is due to many unique factors including but not limited to the combination of the system architecture remote agent and server design along with the metadata control and management system. This flexibility is required in order to easily adapt the system across the wide range of business conditions various LOB applications and databases as part of an automated remote data collection system which does not require remote personnel support.

In various exemplary embodiments the present invention provides remote data collection consolidation and enterprise transformation and loading ETL systems and methods suitable to enable an enterprise like BI system to operate on SMB business data such as financial sales marketing operational and the like data from a plurality of database types remotely over a network in an automated platform agnostic manner utilized in remote environments including independent SMB business operators franchisors franchisees or members of a co op business club or industry trade group or common association among other business organization types. The present invention is designed to work across LOB applications across database vendors and across business models or businesses as well as business infrastructure various computing platforms appliances mobile devices and POS devices and the like and business processes while still providing the ability to automatically collect data from multiple remote business sites. The present invention includes one or more central servers communicating with a plurality of remote data collection agents. The remote data collection agent is designed to overcome existing requirements or limitations as it is able to automatically attach to and collect remote data from a wide range of businesses as well as multiple LOB applications while connecting to multiple databases vendors and formats over a manageable configurable transport mechanism included in the present invention. Finally the remote data collection and processing system enables the central BI system to federate and consolidate data and generate standardized data sets from complex data including financial and accounting data. This process enables comparison between individual independent or non related businesses using user defined peer groups and also to generate unique visual business charts reports or graphs such as Visual Cash Flow by ZeeWise. These new visual reports simplify complex business analysis models or reports and the like that are traditionally or commonly generated using standard business data such as Income Statements Balance Sheet as well as general executive scorecards dashboards and KPI measurement systems. In addition to unique visual styles these new reports enable an apple to apple type of comparison between two or more independent businesses using the reliable and relevant data sets produced by the SMB BI system enabled by the current invention.

SMB type businesses desire to utilize BI techniques approaches systems and methods which are similar to those used by large enterprise like businesses in order to benefit from the BI systems ability to measure evaluate and compare their operational business data and then understand how each element of their business is performing. Additionally and critically each participant in an SMB BI community system wishes to benefit by understanding their data through the operational capabilities of the BI system yet they are commonly not able to provide the required data. Thus most SMB businesses may not participate in or benefit from the self examination nor the external business consulting support benefits or advice such an SMB BI community system could provide without first providing the data sets required and then put them into normalized or standardized form required to generate business reports with unique or visual formats or utilize peer comparison reports by selecting which group they want to see compared to their own results.

One of the most important aspects of a SMB BI system is the ability for a small business operator or owner to compare their operation to similar businesses or peers who would also be providing similar data as members of the general purpose SMB BI community. Noticeably each SMB community member who participates could volunteer to provide their data via a secure process and generally in an anonymized or de identified form using the present invention in order to participate in and benefit from membership in the BI community. Importantly the value of the overall system grows dramatically as more SMB members participate and provide their unique data sets. This is known as the Network Effort in business systems where the value of the group or community network grows in proportion to the square of the number of participants or N this value equation may also be known as Metcalf s Law. A similar idea is behind the value created by Big Data architectures that seek to understand patterns in large and seemingly unrelated data sets where the obvious insight is hidden in the complexity volume or collection of all the data.

Thus the key to building a valuable SMB BI community or network requires broad participation in contribution of data sets yet individual members do not have any control over the participation level of the other members in their BI peer ranking or evaluation group and thus may not be in a position to acquire various sets of remote data to compare to their own business let alone compare themselves to a set of friendly franchisees in a peer group or even a set of competitors from similar businesses within the millions of independent SMB businesses in the US and or around the world. What is required to drive participation and overall system value of the desired SMB BI community or network is the operation of an enterprise like ETL system which utilizes and provides an automated adaptable and dynamic remote data collection system to its members which is capable of working with various and multiple remote data sources in a consistent automated and frequent or recurring basis with the ability to standardized the data extracted from various remote heterogeneous LOB SMB data sources.

It should be seen by those with ordinary skill in the art that the various existing Big Data BD SaaS and or cloud based systems applications services or architectures have not addressed this need nor have they defined an automated way to connect multiple sets of remote heterogeneous data sets from the millions of remote small businesses across multiple software vendors LOB systems and data formats. Thus using the present invention both the desired goal of building an SMB BI or BD community as well as supporting data synchronization with multiple external cloud or SaaS systems can be achieved with everyone benefiting from the collection of SMB data from many remote sites. Using one aspect of the current inventions ETL process standardized data can be produced based on multiple sets of SMB operational and financial remote data which is then made available for traditional enterprise type BI procedures including reporting and visualization as well as other application data integration processes and or data sharing goals.

Additionally the operation of the ETL process may enable the creation of new types of services which extend the ETL concept into additional business services. For example the ETL system may operate in a manner of a metacloud like application system or service where various existing cloud services can be connected in a virtual connected cloud which provides a new type of Big Data system. This new form of BD system or BizWeb demonstrates that it is now possible to build a service which utilizes all of the relevant SMB data because it is now generated by the consistent extraction and ETL processing of remote SMB data. The BizWeb ETL process may occur on a frequent or scheduled basis using a flexible and adaptable data replication service which may work in a two way replication manner i.e. in either direction a from the remote client to the cloud or from the cloud down to the remote client . In addition the system integrates with one or more legacy LOB data sources at multiple remote sites as well as one or more cloud services or systems and creates a single homogeneous data source upon which BI processing may be performed at a single metacloud or BD data service layer.

Another new service is the Universal Translation cloud service where LOB data is extracted by the remote agent from one or more LOB systems and then transported with optional conversion attributes into a different LOB system either within the same category i.e. one accounting system to a different vendor s system or across categories where for example accounting data is extracted processed and inserted with or without synchronization attributes into a foreign LOB system i.e. non accounting system . A similar but different capability is the ability to extract data from a Legacy or older LOB system and then process that data for migration integration or exchange with a newer version of the same LOB system and or a foreign vendor s version of a similar system. This scenario helps SMB owners migrate their data from older LOB systems to newer LOB systems with similar but upgraded features while maintaining consistency of data data validation and or business rules among other critical aspects of business services migration efforts. Next a two way data synchronization service may be offered to connect LOB systems with each other on a periodic and managed basis whereby flexible business rules determine what to extract when to do it how to do it and what to do with extracted data and where to put the processed data into one or more second LOB systems. Finally for existing or Legacy LOB applications that cannot or do not want to create a new cloud data replication service from their local Legacy LOB data source to a new cloud platform of either their own a competitor or 3party cloud or SaaS site and the like the enterprise ETL features of the present invention enables these isolated or orphaned or ignored systems to become virtually connected or actually connected to these outside systems via an enterprise data bridge or application integration service supported by monitored by controlled by and operated by the SMB ETL service on behalf of end users SMB owners trade associations informal groups industry groups Legacy software vendors new software vendors or other 3parties.

One of the weaknesses of present cloud SaaS or even enterprise ETL systems or Big Data systems is their inability to provide their SMB users with an automated ETL process which works across the various data sources which individual sites or members could provide to them. General IT practitioners know that single LOB systems may replicate data from databases which are under the control of their own software systems which must be installed at remote client sites. These systems tend to provide limited one way data transfers data subsets or fixed data sets etc systems to send their own data up to a remote or central site SaaS platform or cloud site and the like e.g. as it is designed today Intuit s QuickBooks can replicate some data from its local database to a cloud platform under the control of Intuit i.e. IPP but the local QB software can t send data automatically to a different non Intuit controlled cloud platform . Note that typically these systems cannot extract and copy data from multiple sets of their own data sources at the remote site using the same data collection system nor can they extract multiple sets of data from the variety of the other local LOB systems operating at a remote SMB site and send it to their cloud platform let alone a different vendor s site. This situation prevents existing systems or vendors from performing more advanced BI techniques which depend on two or more different sets of business data such as financial and operational data in order to calculate KPIs such as revenue per square foot profit margin contribution per item or service sold and the like or other advanced calculations where for example some of the data comes from the accounting systems and other required data is located in separate and unrelated LOB operational systems. It should be noted that these types of advanced calculations or similar capabilities are commonly found at the enterprise level or in large company LOB systems such as ERP systems given their inherent centralized data structure and designs however SMB businesses typically operate with non integrated ERP or independent LOB systems and therefore they must collect consolidate and transform or standardize data from multiple systems typically by hand or manually to generate similar types of statistics if at all possible.

An additional problem with single purpose data replication systems is that while they may provide their users with the ability to share collected data sent to their own single SaaS or cloud site or with another cloud system or even other local LOB systems connected to their cloud via published APIs they typically do not provide all of the data that is available at a remote SMB site nor do they collect multiple types or sets of data from foreign LOB systems. Instead these local LOB software systems typically prefer to simplify or limit the set of extracted data for either security reasons or to reduce system complexity or more likely because the operators of the single SMB community or cloud site cannot envision wider uses of or new methods to apply to all of the available data sets given their limited business models inexperience creativity or lack of vision or even capacity to extract all of their own data at the remote site. Next individual SMB owners may not know how to utilize published SDK s or documented APIs by LOB or cloud systems to extract data and or send it to remote LOB SaaS or cloud platforms or desire to not spend the time and money to pay someone to program a complex one off ETL system process without the guarantee that other similar SMB business owners will do the same level of ETL systems effort and provide similar data. Finally the existing cloud based BI systems i.e. Domo.com Tableau and the like or ETL toolkits either open source packages or pre packaged software vendors such as Talend.com and the like are typically targeted at either enterprise IT type personnel not SMB owners or they depend on the existing LOB systems inherent ability to export its data in simple limited or standardized formats data formats or they depend on SQL query access to the Legacy LOB data source which SMB owners do not know how to define setup expose to another product and or operate. Examples of some well known SMB LOB systems or platforms include Intuit Inc. s QuickBooks for accounting Micros for Point of Sale POS and Salesforce.com CRM systems among various and many 3party Line of Business LOB software packages.

Typically these SaaS services cloud sites toolkits or data aggregation procedures operate via requesting the remote SMB member to manually operate the ETL process locally on their LOB data source and then they either require the member to manually upload or send data to the central site without a secure or guaranteed delivery data transfer service. Or they may provide for some type of local agent to upload extracted data to their site but without additional data transformation normalization or standardization services being applied to the manually extracted data sets. These types of manual processes enable errors to occur through inconsistent manual data extraction procedures incorrect or incomplete data extraction of requested data or simple human error of uploading or FTPing data files manually which may cause non delivery of data or incomplete data sets. Finally when these existing data connection methods work they typically cover simple scenarios such as exporting from a single LOB system a simple list of customers contacts invoices or single purpose data subsets and the like to a simple CSV XML or text file without additional transformation normalization or standardization methods being applied to the extracted data. The extracted data file is then manually uploaded sent or communicated to a single remote site. These existing or known methods may also not provide data filters selection criteria or dynamic methods to determine what state the local data is in what is new old deleted and or changed what data to extract when to extract it nor are these methods delivered on a consistent or scheduled recurring basis. The existing website SaaS or cloud data aggregators typically do not provide a method to transform normalize or standardize the user supplied data and they typically require the SMB user to repeat the process for each LOB system that contains. Finally even if a user were to manually extract and upload separate data sets these existing systems do not provide ETL functionality to transform normalize or standardize their separate sets of user supplied data into a single master consolidated data view nor do they provide a way to make normalized data sets for comparison to user defined peer groups .

Most often the collected SMB data from one remote site is not normalized therefore it is not capable of being compared to another SMB data set from one or more other remote sites in an apples to apples manner given the incomplete or inaccurate data sets produced by their existing systems methods or procedures. This problem is made more complex when trying to make operational business comparisons across peers similar but independent or unrelated SMB businesses or business segments or types of business or age of business operation or consistent time periods of business operation and or sized businesses based on revenue number of employees operating format store type and the like . Thus the existing system models greatly limit the scope and or breadth of BI insight they may provide to their members. Finally even these manual one off ETL systems or cloud platform data replication methods must still overcome the problems and challenges of data standardization by providing a way to normalize or standardize any user provided data in order to provide users with relevant comparison metrics. Typically these comparisons are made using known standards such as NAICS i.e. formerly SIC industry categories yet existing systems have no way to group individual SMB members into many of the other needed types of categories size age etc. for peer comparison mentioned previously.

One of the most important standardization techniques for building an SMB BI community is normalizing financial data from thousands of individual businesses which may have data elements which were categorized differently by various or different accounting systems under similar but differently named numbered or identified accounting codes or categories. This problem is generally known as standardizing the Chart of Accounts COA in accounting terms and is a prerequisite to a centralized SMB BI site which intends to compare financial results between two businesses based on similar but different ways to categorize the basic elements of revenue and expenses among other accounting items or categories. Generally accounting systems enable their users to generate standard business reports and perform standard accounting techniques by following a set of agreed up principals procedures or forms known as the Generally Accepted Accounting Principles GAAP incorporated fully herein by reference . GAAP encourages a somewhat standard classification system and account process or procedures for entering recording and categorization of various business activities into primarily two main areas of revenue or expenses using a set of categories or COA structure from which reports or status can be measured. However problems for consolidation and comparative systems are created even when users follow GAAP procedures within their accounting system. These problems and challenges are introduced for example when one business owner creates and utilizes an expense category called Payroll under a category number of while another owner may use number for Payroll expenses. Similarly additional problems occur when owners label their categories as Rent and another as Rents plural or even worse categorize payroll as Labor Labour Payroll Salary and Wages etc such that any transformational or normalization procedure would easily fail to conclude these items are the same fundamental GAAP item under treatment of expenses. This failure is due to the limited nature in which existing systems attempt to match text labels or even numerical codes between files even when the collected data set is from a single LOB system or vendor s data files or sources. This aspect is made more complicated when collecting and consolidating multiple sets from different versions of the same vendors data source let alone from different LOB vendors within the same type of software e.g. accounting systems and then finally between types of LOB systems POS versus accounting vs supply chain or logistics etc . Finally GAAP procedures may produce standard business reports on a single data set but they do not provide an automatic way to consolidate two or more sets of financial data for comparative purposes without first putting them individually into a normalized or standardized form and then make these data sets available to an accounting system to incorporate into the standardized reporting system offered by the accounting vendor. Additionally following GAAP does not automatically generate business reports with clear visualization treatments in comparative form or enable peer group level comparative visual reports without the consistent adoption of an ETL like procedures across all peer level user data.

Beyond standardizing accounting data additional data standardization challenges exist when comparing key LOB data items in categories such as sales in common currency terms in common time periods and with or without taxes and the like inventory items via UPC codes SKUs or quantities and the like operational metrics hours of effort per category square footage number of customers and the like as well as specific business metrics such as number of sales leads per closed sale among various unique KPIs or metrics. Therefore it should be seen by those with ordinary skill in the art that beyond collecting remote data there is an enormous challenge facing any vendor who desires to build a meaningful and reliable SMB BI or BD system for comparison of business data between members of a related group let alone industry peers or similar sized aged or types of business as peers without an extensive and dynamic ETL system described in the present invention. The key features utilized by the ETL system to create this capability are that it supports an extensive standardization transformation and or normalization procedures via the flexible and dynamic command set to be performed per data source per site on all data in order to generate peer group comparison level data.

In order to provide the central SMB BI system with consistent sets of data it is desirable to schedule the automatic collection of remote data sets via a centralized command and control system which manages the activities of a remote data collection agent. Without the benefit of an automated system controlled from the central BI or BD system the errors inherent in a manual data extraction system may exist and prevent meaningful comparisons of normalized data sets. It is preferred that the consolidation process utilize a single yet flexible remote data collection agent which is capable of attaching to multiple types of data sources at each remote site while being able to be controlled from the central data warehouse system. The primary function of the remote data agent is to attach to each requested data source define a set of connection and extraction logic for the requested type and set of data extract the data from the remote operational system without interference or impact on the existing operational system perform one or more optional data normalization steps and then safely and securely send the requested data sets to the central BI system where additional processing and reporting may take place. All of this capability should be done on a frequent periodic basis as defined by the needs of the business users of the BI system typically on a nightly weekly or perhaps monthly basis for infrequently updated or changed data.

In at least some known techniques of collecting operational or business data collection features embedded into a single LOB application such as a POS system are generally standardized across all remote sites. That is if a Franchisor wishes to collect each day s sales and transaction detail information from all of the remote stores operating in their franchise system they must first standardize every store on the exact same POS system vendor if not the exact same version of that POS application . This standardization is required to enable the system to roll up and consolidate the data from identical copies of the application database along with identical transaction detail format which is stored in the same type and version level of the database. Additionally many of these single version collection systems depend on data consolidation systems that are built into the database engine which is used to store electronically read write to a disk the data at the remote sites. Database vendors such as Microsoft Oracle and Sybase and the like have provided many types of proprietary data replication techniques embedded into their products to allow Independent Software Vendors ISVs to develop rich LOB applications e.g. POS that can copy and replicate identical databases to a central location via their built in techniques or Application Programming Interfaces API . The fact that a business must standardize their POS system on a single POS vendor and version to enable remote data consolidation is a limitation which is often driven by the fact that the POS system was built on top of a database vendor s replication technology which only talks to itself. This problem is further compounded when an entire industry category or segment desires to participate in the data collection consolidation and standardization process of an SMB community BI system but there is no common denominator upon which the data collection and ETL process may be based upon given the huge variety in age type and capacity of the thousands of existing or legacy LOB systems which are utilized to run existing SMB businesses. Even if all SMBs utilized modern cloud or SaaS systems the problems of data extraction synchronization and normalization across various cloud systems still exists. Additionally these challenges would still be faced by those existing businesses who wish to migrate their existing data from legacy LOB systems up to any new cloud system. Thus given the existing islands of SMB data contained in 1000 s of legacy systems at millions of locations it can be seen that there is a considerable and unique opportunity in creating an ETL system for processing SMB data that will be present far into the future regardless of technology architectures.

Alternative techniques to replicate data depend on a common definition of the data and or a common data file format. While there are many industry standards for data interoperability such as XML standards CSV text files or other formats these standards only enable a common data description and data format to be used when exporting data from within the original LOB system they do not solve the data normalization or comparison problem nor do they enable automated data transport or delivery to a central site. One of the challenges for existing cloud based systems when using these data export import techniques is how to create a centralized and automated remote data consolidation system without requiring that remote sites utilize custom software to adapt their cloud connector to each LOB product and version as well as require extensive IT personnel to support the communication infrastructure to send extracted data to the cloud on a consistent basis. In addition these methods depend on having every LOB application support the same common file format as a data export option. An additional requirement may be present when data from different LOB applications is collected into a central data warehouse or repository which then requires that extensive data transformation techniques be used to normalize the data into a common format. These conditions or requirements cannot be easily supported by small or mid size businesses ex. Franchisors or these conditions do not exist uniformly across various remote businesses. This fact is particularly true for remote sites where the local personnel may not be employees of the business which seeks to centralize the data ex. Franchisees and thus they are unfamiliar with untrained on or unwilling to follow detailed operational guidelines and procedures to extract LOB data from their local system into a common data file and send it across a sophisticated communication infrastructure.

An additional challenge to automated collection consolidation and standardization or transformation of remote LOB data is the problem of systems administration and management. For any system to work it must have a process to uniquely identify a remote site or location and the specific rules required by the local system agent to operate autonomously at the location. This identification and control scheme must handle variations and changes in business operating rules naming conventions organizational structure regions attributes reporting rules etc and other collection consolidation and ETL rule requirements such as versioning of business rules or definition sets code and databases. Additionally the systems management model must provide for flexibility in targeting controlling monitoring and reporting on the state of the remote sites while the data collection process dynamically operates on a 24 7 365 manner. Beyond the technical barriers many remote data collection systems fail due to the overhead and complexity of simply managing remote software agents at hundreds or even thousands of remote physical locations. Finally the communication method utilized to connect the remote sites to a central consolidation point must be comprehensive yet easy and operate in a lights out manner in order to efficiently scale the management monitoring and system control while providing for fault tolerance reliability and guaranteed delivery of remote data to the central site.

Thus any service which desires to apply BI techniques to a consolidated view of LOB data across many remote sites must either provide IT support personnel or create a custom software program that is so simple that anyone can operate it without extensive training on consistent procedures. What is desired by various businesses is a generic remote data consolidation and ETL system which can be quickly and easily adapted to their LOB system without extensive and costly custom programming. This generic system must then work across any type of remote location and work across various LOB application and database vendors as well as multiple databases or LOB applications at a single remote site. Such a system would then need to be quickly deployed and installed at many remote sites without remote IT personnel work flexibly and yet dynamically reliably and automatically collect and process data from one or more various LOB applications and send the data across a common communication infrastructure such as TCP IP and the Internet.

The remote data consolidation and ETL process of the present invention is flexible yet comprehensive and complete while allowing for variability complexity and individual requirements of a variety of LOB applications running in a variety of situations at remote sites. The unique and novel design features and attributes provide these capabilities and allow a central administrator to dynamically define what data to collect and how to collect and process or normalize it from a variety of remote LOB applications and database formats across many sites without developing custom program code and without local IT help while yielding a central consolidated view of the entire business operation. Additional flexibility is shown through the use of optional LOB add in components or local UI components to alert remote site personnel and allow them to be part of the automated process to customize the collection or normalization or standardization process with user driven mapping of local data elements into a general or standardized form or generally allow them to understand and verify what is happening or what did happen. As a result the remote data collection system provides a centralized database from which unique visual management or comparative reports can be generated along with executive dashboards. Additionally ongoing monitoring can be performed to increase the efficiency effectiveness and overall profitability of these remote sites while also allowing for increased visibility into the underperforming sites and enabling proactive support to be provided to them before the business suffers further negative conditions or financial impact. This is accomplished by the client agent and server design the use of definitions and updates for collection and ETL processing along with some form of centralized control over the data extraction and processing system combined with a centralized management approach that eliminates the need for expensive and scarce IT people or custom software at remote sites.

The flexibility of the present invention is derived from a foundation built on top of an abstract message passing architecture plus the use of metadata messages to dynamically control and configure the agent and the agent s ETL processing or the server side agent ETL processing along with a layered code design which allows for the replacement of code layers without disruption or reinstallation of the entire system. The key to the lights out remote control and operation of the system is due to the use of an automated installation package a flexible command and control system with dynamic and adaptive scheduled commands via a set of system metadata messages which define and control what to do at the remote agent once it is installed along with a centralized logging error handling and alerting system via the same message infrastructure as the data collection. This architecture allows the entire system to be centrally managed and monitored using the same message communication infrastructure which is used to collect and process remote data. The metadata messages are built from a configuration database which defines both the system data definition extraction and or transformation rules and the client agent code update versions . The system also uses messages to provide for a centralized log of all remote agent state or status. Definitions are metadata commands which are typically stored as database records. These records store the collection rules and or commands which tell the remote client agent what to do how to do it and when to do it for one or more LOB applications operating at the remote site or groups of sites. Optionally the ETL type definition files may configure control or operate as a server side process versus remote client agent to transform collected data before consolidation or other data warehouse operations are performed. Using the existing data replication system system definitions and update files can be sent out to the remote sites to update the existing agent code and reconfigure the collection process. Thus the overall unique and novel system characteristics of quick adaptability flexibility and performance is due to many unique factors including but not limited to the combination of the system architecture remote agent and server design along with the metadata control and management system. This flexibility is required in order to easily adapt the system across the wide range of business conditions various LOB applications and databases as part of an automated remote data collection system which does not require remote personnel support to operationally scale across thousands of remote sites.

In an exemplary embodiment a remote data collection system includes a network interface a connection to a data source a processor communicatively coupled to the network interface and the connection and memory storing instructions for remote data collection that when executed cause the processor to receive a request to extract data from the data source extract the data in a non intrusive manner from the data source using a two phase process comprising a reconciliation phase and a collection phase and transmit one of an entire set and a subset of the extracted data and or optionally perform ETL processes on the extracted data based on the definition commands and requested processing. The non intrusive manner can include the data source being read only to the processor during the remote data collection. The instructions when executed further cause the processor to copy the data from the data source to a shadow database and process the data in the shadow database to provide the entire set and the subset of the extracted data and perform ETL processing. The processor connects to the original local data source in read only mode during the remote data collection connection. The shadow database is separate from the original data source and wherein the non intrusive manner utilizes the shadow database for any insertions updates or deletions thereby preventing any interference corruption or modification of the data source by the processor during the remote data collection. The instructions when executed further cause the processor to mark data stored in the shadow database with metadata to distinguish between existing data modified data deleted data new data or requested data processed appropriately in order to facilitate the remote data collection and ETL process. The instructions when executed further cause the processor to create the shadow database based on database schema tables and columns defined by the current collection and or ETL object for the data source wherein the shadow database is adapted to a type associated with the data source thereby enabling the remote data collection to operate on a plurality of software systems and data files for obtaining extractable data therefrom and or requested ETL processing. The data source can include one of a text file a spreadsheet a structured query language database an Indexed Sequential Access Method file a flat file mobile device data stores or caches or new noSQL or non structured data storage architectures such as BigData systems based on Hadoop and the like. The instructions when executed further cause the processor to perform peer to peer ad hoc dynamic data replication and synchronization with a remote data system and utilize a dynamic command language with the remote data system to determine what data sets to retrieve how to extract the data sets including dynamic binding to one or more of the local APIs or access methods or connection interfaces of data source and compare extracted data to targeted or requested data and process transform or manipulate it as defined by the ETL definition message or command. The instructions when executed further cause the processor to perform the reconciliation phase to determine what data to extract from the data source to determine how to extract the data from the data source and to define a current collection object for extracting the data set from the data source and perform the collection phase to synchronize data between the data source and the shadow database to process the data in the shadow database and or on the server side and to send the processed data and optionally to provide ETL processes via standardization rules or normalization procedures to ensure consistent data sets are being stored into a common SMB BI system for each type of data set collected.

In another exemplary embodiment a remote data collection method includes receiving a request for remote data collection to extract data from a data source extracting the data in a non intrusive manner from the data source using a two phase process comprising a reconciliation phase and a collection phase and transmitting one of an entire set and a subset of the extracted data based on the request. The remote data collection method can further include copying the data from the data source to a shadow database and processing the data in the shadow database to provide the entire set and the subset of the extracted data wherein the data source is read only during the remote data collection. The shadow database can be separate from the data source and wherein the non intrusive manner utilizes the shadow database for any insertions updates or deletions thereby preventing any interference corruption or modification of the data source by the processor during the remote data collection. The remote data collection method can further include marking data stored in the shadow database with metadata to distinguish between existing data modified data deleted data or new data in order to facilitate the remote data collection process. The remote data collection method can further include creating the shadow database based on database schema tables and columns defined by the current collection object for the data source wherein the shadow database is adapted to a type associated with the data source thereby enabling the remote data collection to operate on a plurality of software systems and data files for obtaining extractable data therefrom. The data source can include one of a text file a spreadsheet a structured query language database an Indexed Sequential Access Method file a flat file tablet and or mobile device data stores or caches cloud data stores or new noSQL type or non structured data storage architectures such as BigData systems based on Hadoop and the like. The remote data collection method can further include performing peer to peer ad hoc dynamic data replication and synchronization with a remote data system and utilizing a dynamic command language with the remote data system to determine what data sets to retrieve how to extract the data sets and compare extracted data to targeted or requested data. The remote data collection method can further include performing the reconciliation phase to determine what data to extract from the data source to determine how to extract the data from the data source and to define a current collection object for extracting the data from the data source and performing the collection phase to synchronize data between the data source and the shadow database to process the data in the shadow database to send the processed data and finally to provide ETL processes via standardization rules or normalization procedures to ensure consistent data sets are being stored into a common SMB BI system for each type of data set collected.

In yet another exemplary embodiment software stored in a non transitory computer readable medium and including instructions executable by a system and in response to such execution causes the system to perform operations including receiving a request for remote data collection to extract data from a data source interfacing to the data source in a read only manner performing a reconciliation phase to determine what data to extract from the data source to determine how to extract the data from the data source and to define a current collection object for extracting the data from the data source performing a collection phase to synchronize data between the data source and a shadow database to process the data in the shadow database and to send the processed data and transmitting one of an entire set and a subset of the extracted data based on the request.

In yet another exemplary embodiment a remote data collection system includes one or more servers coupled to one or more data sources a plurality of remote clients communicatively coupled to the one or more servers each of the plurality of remote clients comprise a remote client agent communicatively coupled to one or more client data sources and a metadata message transport mechanism configured to coordinate control and replicate data between the plurality of remote clients and the one or more data sources and wherein the metadata message transport mechanism is further configured to provide communication and control between the one or more servers and the plurality of remote clients the control includes the one or more servers being configured to remotely control the replication of data from one of the one or more client data sources through the one of the plurality of remote clients. The remote data collection system can further include a definition server communicatively coupled to each of the plurality of remote clients wherein the definition server is configured to provide a plurality of definitions for each remote client agent and wherein the plurality of definitions define collection rules for data in the client data source the collection rules comprising dynamically generated extraction rules for data and subsets thereof with the extraction rules determining operation of the plurality of remote clients for the replication and optional transformation of data from one of the one or more client data sources. The remote data collection system can further include an update server communicatively coupled to each of the plurality of remote clients wherein the update server is configured to provide updates to the plurality of remote client agents wherein the updates are configured to modify the metadata message transport mechanism and associated control for the replication of data. The one or more client data sources can include data from one of a financial accounting application a line of business application or point of sale application or other LOB application and wherein the remote client agent can include an abstract implementation configured to operate on a plurality of database types with the one or more client data sources including at least two different database types of the plurality of database types and wherein the normalization or standardization process is specific to each type of data collected from the one or more database collected from a plurality of databases and data sets requested.

The metadata message transport mechanism can include a plurality of message types exchanged between the plurality of remote clients and the one or more servers to remotely control the replication of data from one of the one or more client data sources and wherein the metadata message transport mechanism contains formatted data that is abstracted by a remote data collection system using message handlers thereby enabling future upgrades to the message handlers to add new messages types or extend existing message types. The plurality of message types can include data messages log messages exception messages update ready messages update server online messages update complete messages update interrupted messages update file messages update configuration messages definition request messages definition messages and transformation messages or data processing commands. The remote data collection system can further include one or more shadow databases utilized in a data collection task wherein in response to the control from the metadata message transport mechanism the data collection task copies data from one of the one or more client data sources to one of the one or more shadow databases and processes and or transforms the copied data in accordance with a requested collection definition object for sending via the metadata message transport mechanism the one or more shadow databases are used for operations in the data collection task to reconcile and collect the data. The data collection task can include a comparison function verifying copied data in the one or more shadow databases responsive to the requested collection definition object and may include an optional step of local processing of data to generate normalized or standardized form if requested and a sending function to the one or more data sources from the one or more shadow databases.

In yet another exemplary embodiment a computer includes a network interface a connection to a data source and a processor communicatively coupled to the network interface and the connection wherein the processor is configured to execute a remote data collection agent wherein the remote data collection agent is configured to coordinate control and replicate data between the data source and a server and wherein the remote data collection agent utilizes a metadata message transport mechanism to communicate to the server through the network interface the metadata message transport mechanism is further configured to provide communication and control between the server and the computer wherein the control includes the server being configured to remotely control the replication of data from the data source through the remote data collection agent and wherein the server is configured to automatically and remotely replicate and receive the data from the data source through the remote data collection agent. The remote data collection agent can be configured to receive a plurality of definitions defining collection rules for data in the data source from the server the collection rules comprising dynamically generated extraction rules for data and subsets thereof in the data source and wherein the remote data collection agent using the collection rules to automatically replicate and transmit the data from the data source to the server. The remote data collection agent can be configured to operate in a reconciliation phase and a collection phase in the reconciliation phase the remote data collection agent is configured to determine what data to extract and how to extract it from the data source using a shadow database and in the collection phase the remote data collection agent is configured to synchronize and optionally transform the data and to send the data using the shadow database. The data source can include data from one of a line of business application and point of sale application and wherein the remote data collection agent comprises an abstract implementation configured to operate on a plurality of database types such that the remote data collection agent operates on the data source independent of a type of database of the data source. The metadata message transport mechanism may utilize a Java Message Service for secure transmission over the Internet wherein the metadata message transport mechanism can include a plurality of message types exchanged between the remote data collection agent and the server to remotely control the replication of data from the data source and wherein the metadata message transport mechanism contains formatted data using message handlers thereby enabling future upgrades to the message handlers to add new messages types or extend existing message types.

The computer can further include a shadow database utilized in a data collection task wherein the shadow database is communicatively coupled to the processor wherein in response to the control from the metadata message transport mechanism the data collection task copies data from one of the data source to one of the shadow database and processes the copied data in accordance with a requested collection definition object from the metadata message transport mechanism the shadow database is used to perform operations on the data as defined in the requested collection definition object. The data collection task can include a comparison function verifying copied data in the shadow database responsive to the requested collection definition object and a sending function to the database from the shadow database.

In yet another exemplary embodiment a method of remote data collection includes receiving an agent installation package at a remote client initiating the agent installation package installing a service process that facilitates automatically starting a launcher process loading the launcher process thereby installing a plurality of components of a remote client agent communicating through a plurality of metadata messages with a server or a second level ETL processing service to provide defined data from a data source at the remote client to the server wherein the plurality of metadata messages enable the server to automatically and remotely replicate the defined data using a data collection process with a reconciliation and a collection step each using a local shadow database to collect operate on and verify the defined data and using the plurality of metadata messages to control operation at the remote client and to determine subsets of the defined data to control extract and transport to the server. The method can further include receiving collection definitions from the server extracting data from the data source responsive to the collection definitions writing the extracted data to the local shadow database processing the extracted data in the local shadow database based on the collection definitions comparing and optionally transforming the extracted data to data in the local shadow database and sending data messages comprising the extracted data to the server. The method can further include extracting a table and a column definition from the collection definitions matching a requested table and column definition with a table and column of at least one of the data source the local shadow database and a server data source. The method can further include sending an update number to the server receiving an update package from the server and installing the update package on the remote client to support new messages different database types or modify existing messages. The data source can include data from one of a financial accounting application a line of business application and point of sale application and or other LOB application or system.

In yet another exemplary embodiment a remote data collection system includes one or more network communication endpoints dynamically created to connect a plurality of remote agents to one or more central servers including a network namespace of endpoints which are dynamically monitored managed and which provide a near real time linkage between remote agent and central database wherein the plurality of remote agents and the one or more central servers are connected in a bi directional fashion whereby the real time linkage is provide by a plurality of metadata messages and the real time linkage includes communication and control wherein the plurality of remote agents are communicatively coupled to a plurality of data sources wherein the one or more central servers are configured to replicate collect data and process data from the plurality of data sources using the plurality of remote agents using the one or more network communication endpoints and wherein the plurality of remote agents and the one or more central servers are configured to operate in a database independent manner relative to the plurality of data sources using abstraction layers to hide implementation details for various database types and provide an ETL like process per collected data set per remote site based on configurable business rules for each consolidated dataset.

The various remote locations Zee Zee . . . Zee may each be associated with one another and constitute the notion of one or more Zors or franchise systems Zor Zor . . . Zor but may also represent associations or trade groups and the like with individual business members loosely affiliated. Each of the remote businesses locations includes network connectivity such as through the Internet . Each Zee location can include one or more local or virtual or remote database s that includes data elements either the entire set or a subset of the data that the associated Zor organization or SMB BI system would like to consolidate into a single database i.e. a consolidated database . The consolidated database can be located in a central data center that is configured to operate a server side data consolidation and management process to consolidate data from the various databases at the various remote business locations . The consolidated database additionally may include ETL processes to normalize and or standardize the data and may include system reports visual business reports and or dashboards configured to provide various user interface UI screens and graphs along with numerical charts and tables and KPI reports based on the normalized and consolidated data.

The remote agent metadata command and control definitions are defined as objects that store data collection rules which tell the remote client agent what to do how to do it when to do it and which version or update of agent code components to use to perform the requested action for each LOB data source. These definition objects are serialized and stored as database records in the configuration database and are retrieved by a definition server . The update configuration metadata commands are defined by records that contain pointers or references to code component files that are stored in directories on the server s file system which contain new client code versions . The update metadata commands are stored in the configuration database and retrieved by an update server . The definition and update objects can be sent automatically from the data center to the remote site to update the existing code and collection process rules at the remote client agent . The system can also include updated code files which in one embodiment are Java jar packages and configuration text files which encapsulate the updates available to the remote agent as defined by the update metadata. The combination of the system architecture remote agent and server design along with the metadata command and control along with the central management system allows the system to have great remote flexibility. This flexibility is required in order to quickly and easily adapt the remote data collection system across a wide range of business conditions LOB applications and databases to automate remote data collection and ETL processing without remote IT personnel.

The architecture of the remote data collection system allows the creation of a unique data consolidation process which can work across Zees or remote business sites as well as a diverse set of Zors or any other type of business which desires to automatically collect and process data from a remote personal computer PC mobile device embedded computing device SaaS service cloud service and or a local or virtual POS device. At each remote site a business can have different LOB or POS applications running and these can each use different database engines . These businesses can also have a diverse set of installed PCs mobile devices software and data collection needs for different business processes. The remote data consolidation process of the present invention can be easily adapted from a central location to work across this variety of remote target sites and infrastructures via the metadata command and control definition objects . Further this flexibility is automatically managed across both the Zee s within a Zor and across all Zors who subscribe to the remote data collection service. This design results in a centrally managed and consolidated set of LOB data stored in a consolidated LOB database and retrieved from the remote site through a data consolidation server that can be used by subscribers to improve their business performance at the Zee or Zor level by identifying key business trends and operational statistics as well as provide rolled up financial performance and other types of management or comparative reports such as key performance indicator KPI reports or peer group reports or Visual Cash Flow . Note that while the terms Zor and Zee are used throughout this document any set of remote businesses can be collection clients and the business method is not limited to Franchising or any specific industry or LOB application type.

The remote data collection system facilitates providing a single system solution to a variety of problems which face many industries and companies where they do not own or control the remote sites or where there is no local IT staff to manage the process. When these businesses attempt to consolidate data from remote or independent business locations in order to monitor business activity they quickly discover the complexity of this process. Yet there are no existing shrink wrapped tools or solutions for these types of scenarios which can be purchased and easily deployed. The system can be quickly and easily adapted to a wide range of industries and business applications to provide a remote data consolidation system and may be designed with but not limited to the following attributes 1 Database independence the system can work with SQL Server Oracle Sybase Paradox Access proprietary formats text files XML files etc. 2 computer application independence the system may collect data from various types of LOB applications 3 Site independence the system enables automated remote data collection without the need of onsite IT support 4 Business model independence works across range of industries ex. Franchising etc. 5 Easy system agent rollout via email notification instant message service or webpages via embedded URI links and or a self extracting setup program 6 User interaction or diagnostics via optional LOB application add ins and or a system tray tool 7 Ability to consolidate data at an alternative location while the management is still centralized and 8 Ability to provide aggregated statistics analysis and reporting on consolidated data i.e. through system wide reports based on data in consolidated database .

The system can be quickly adapted to a variety of LOB application situations while being successfully deployed to hundreds or thousands of remote sites which are operated in a remote lights out automated manner providing consolidated LOB data. Moreover the system can use a flexible message passing layered LOB data access architecture which allows it to be centrally controlled and operated while implementing a simple remote agent that responds to these messages which are passed back and forth over a secure and reliable communication transport channel .

It is important to note that for many years database or other software tool vendors have provided many similar sounding features such as publish and subscribe but the implementation of these data replication products is limited to being incorporated into a single LOB system that is built with that vendor s database replication technique. The problem solved by the present invention is much broader than that faced by a single LOB application e.g. a CRM system because those are dedicated or single purpose data collection systems deployed on a single database vendors platform and only collect data from themselves. The system includes a generic process which works across any type of LOB applications and across database vendors in an automated and lights out manner. Similarly while traditional middleware message bus or message queue architectures have been used by enterprise businesses to link remote sites or to link two independent LOB systems together these implementations required a consistent set of managed IT infrastructure such as shared security models private networks and dedicated IT staff to develop custom software and manage these systems in order to support a data collection system which could work across LOB applications or across database vendor platforms. Thus the remote data collection system is unique in its ability to work across all types of LOB applications across database vendors and across business models or businesses as well as across different types of business infrastructure various computer and POS devices and with no IT support processes while providing the ability to centralize and automate data collection from multiple remote business sites.

During the collection of remote data the remote agent is controlled and centrally managed using a combination of system Definition and Update messages as well as a plurality of status reports on the remote agent s activity received from the remote agent by a meta log server and stored in an agent status database . A definition can be a set of business rules or commands for one or more remote agents that describe what to do how to do it as well as other settings that are stored as a set of metadata records called a Data Collection Definition object. These definitions can be centrally managed in the configuration database using a set of administration applications or web pages that allow a single admin to easily change the collection process for one many or all remote agents across one or more Zors. For each LOB that the system is adapted to support the definitions can be serialized business objects stored as records that define the business operation rules such as which LOB data to collect at the remote site which method or way or command statement or API to use to collect the data where to find the data optional transformation commands as well as client side configuration info what time to collect it which client update version to use where to send it etc . The remote client agent periodically checks for new definitions on a configurable periodic basis which when needed are sent down to the client using the Definition server . Updates are tracked by an Update Number UN that defines the specific version of code to use to perform a requested action by the remote agent . The updates are stored and organized in the Update database using business specific metadata examples include but are not limited to organizing updates by business or category type by LOB application company ID or ZorID a specific store location or client ID geographic region or grouping code etc. that allows a single administrator to automatically target a set of remote agents with a specific version of the agent code. The update metadata references the server s file system directories which organize and store both binary Java code files e.g. JAR files as well as text based configuration files e.g. .conf . The updates can be managed and configured system wide e.g. all Zors per business concept ZorID per groups of remote clients or per individual remote client via its specific ClientID. Note the targeting of versions can also support groups or subsets of Zees within or across Zors such as by a region or territory or by common LOB application. The update files contain new remote agent code files that are pulled down by the remote agents when they send update request messages to the Update server . These updated files can add new system features or provide patches bug fixes to the current remote client code via the automatic update process. Note that the entire flow of control and management information definitions and updates can be initiated from the client side . The client agents can use a message passing model to initiate a conversation with the DC servers that enables remote clients to either push collection data up or pull definitions or updates down in a reliable and predictable manner. Additionally the flow of messages and data can be sent in both directions for centralized data distribution.

The remotely collected information can be transported across the Internet in a secure and reliable manner utilizing an extensible and flexible message passing architecture established over a communication transport channel . The actual transport of information between clients and servers has been abstracted so that the system can use a combination of delivery methods or replace them as needed in the future. In an exemplary embodiment the system can use extensible messages which are passed over the Internet via managed communication transport channels . The managed channels can be established over a secure and reliable transport layer such as but not limited to the Java Message Service JMS and are used to send and receive both data and system control messages in an asynchronous or synchronous manner. In an exemplary embodiment the remote data collection system includes but is not limited to eleven unique types of messages that can flow in the channels created between the clients and the data center such as the message packets over the Internet . These messages may include but not limited to data message log messages exception messages update ready messages update server online messages update complete messages update interrupted messages update file messages update configuration messages definition request messages and definition messages and optional data transformation commands.

Each message can contain formatted data that is abstracted from the system using message handlers in order to allow for future upgrades to handlers that can add new messages or extend existing message capabilities in the system . The remote agent sends LOB collection data to the DC using the messages that are created by this message handler architecture. The remote agent uses the definition rules to extract data and hand it off to message sending nodes that utilize the handlers to both create and send the messages. The messages are handed over to the JMS layer for actual reliable transport and delivery to the DC . In addition to data all other client state or status log information are sent to the central DC site using this same message passing architecture via additional unique message types.

The data messages can be structured in multiple formats by a message handler which may produce multiple message formats including an XML based representation of client data from a particular LOB database table at the remote site. These messages can contain one or more rows from the table. Total message size in bytes is a configurable setting and is used to tune transport level performance and reliability. In an exemplary embodiment the data messages can be sent from the client side to the server side data consolidation servers at the DC servers. In another exemplary embodiment the data messages can flow in both directions.

Log messages can include remote agent log messages structured as a text string that originates from remote clients that are then logged into the server side agent status database by the Meta Log server . Log messages can include the progress or state of client applications such as a timestamp of when a collection run was started when data elements of a particular table have been changed or updated the number of rows that a table has and if there were any problems with or changes to the LOB database etc. Exception messages can wrap any Java Virtual Machine JVM or java code exceptions that occur. The exception messages facilitate delivering exception data from remote agents to the central server logs.

The update ready messages can be used by the clients to tell the DC update server that the client is ready to receive updates and provide the server with the client s current update number version. This message initiates the update conversation between server and client. They are also used by the server to search the configuration database to determine what update number is available in the event the update number is the same as the client s current update number there is no update available and the client will continue to use its current version . Update server online messages can be used by the update server when it comes online. The update server can broadcast this message to any clients that are connected at that moment to let them know that the update server has completed a restart. This broadcasted message invalidates any current update conversations since the client is essentially notified that any previous messages were forgotten since the server was recently restarted. This process facilitates preventing stalled remote clients from waiting indefinitely i.e. when remote clients are waiting for Update Complete Messages which won t be sent due to the server side interruption and restart. . The clients can restart the update process and check for updates again to initiate a new conversation. Update complete messages can be used by the update server to tell the remote client that it has completed sending all update messages. This message ends the update conversation from the server end point of view and the client may close the message communication channel and load the new client code before a new collection run is started.

Update interrupted messages can be used by clients to tell the update server that an interruption occurred on the client side. In the event servers are interrupted the servers can send an update server online messages telling the clients that the servers have been interrupted and to ask for an update again. For example interruptions can occur because but not limited to a java thread threw a java exception due to an unhandled exception such as a write attempt to a local client storage medium which was full. Update file messages can be binary messages that include a JAR file that can be written to the client side storage medium. For example there can be but not limited to one message per file and one file per message. Update configuration messages can be messages that contain the current settings and values that are used to update the client configuration files. For example there can be but not limited to one message per client configuration file. Alternatively the messages can include at least one setting in the configuration file. Definition request messages can be used by clients to request that the definition server send the current definition version they should use. For example the clients can wait to receive a definition message response from the server before proceeding to obtain their current rules. Definition messages can wrap or encapsulate the collection definition business rule object that can be sent from the definition server to the client to control its operation.

In an exemplary embodiment the node senders and node listeners on any specific machine client or server can work together and can share a common set of state information or NodeState that allows them to synchronize the threads that perform the node abstraction level message transmitting work. The system destinations are managed objects which contain messages to deliver information to a specific location agent server or service . The system uses JMS destinations as concrete implementations of communication channel destinations and the set of all destinations forms the transport space . That is nodes connect to a specific JMS destination and message traffic is contained within that destination. JMS destinations are defined by server hostname port number and destination name and type. These attributes are stored within a configuration file sent down to the remote agent as part of the definition configuration information which defines where the nodes used by the remote agent should send their messages and this remote site node configuration can be updated by update messages. The JMS destinations are managed using JMS tools that allow an administrator of the system to create or destroy the destination objects manually. Note that the JMS objects can instead be managed automatically by using the JMS feature of client initiated destinations. That is no user management of the server side JMS services is needed to manage new destinations because they are automatically created using the JMS client initiated auto creation method. Once a destination is created the node processes are immediately able to utilize them by name to identify where to send their messages.

The JMS implementation which can be running on a DC server enables the system to create a high level destination or communication channel management model that can be used to easily visualize and manage the communication transport channels. This management model view of destinations is referred herein as a transport layer space which is an additional system abstraction layer. It is the overall transport layer space utilized by the remote data collection process which provides for the reliable transmission of message packets in an abstract manner which allows the system to be adapted to other data transport systems. This same communication channel infrastructure is also used to provide updated code as well as definitions to the remote agents .

The JMS destination names can be organized by business concept e.g. ZorID to provide a coherent and convenient management organization model. Alternatively the destinations can be named and utilized in a shared manner to instead maximize efficiency instead of administrative name clarity. In the JMS architecture transport destinations are defined to be either topics or queues depending on the type of communication channel needed. In the exemplary embodiment topics can provide a many to many communication channel between one or more node senders and one or more node listeners . Moreover alternative implementations may use queues to provide a many to one communication channel between one or more node senders and a single node listener which empties the queue. In the exemplary embodiment a data consolidation server retrieves data from a JMS queue populated by a single remote agent while the definition and update servers instead utilize JMS topics for bi directional communication to and from many remote agents . Moreover in the exemplary embodiment data can be sent from remote sites to the data consolidation server . Specifically the data consolidation server at the DC includes a node listener object . Alternatively the data consolidation server at the DC can include a node listener object and or a node sender object . In another exemplary embodiment the system can distribute and send LOB data including but not limited to new business rules for the LOB database back down to remote sites as well as collect it up to the DC .

Note that using the auto client create method the administrator does not need to perform any proactive administration to create the JMS transport space . Instead the remote clients send messages to a JMS destination by name this destination can be automatically created as a server side JMS object topic or queue if it does not already exist. Additionally management tools can monitor the transport space to identify new endpoints that do not have corresponding listener node threads. That is while JMS handles the automatic creation of the endpoints on the server side and stores messages bound for it in a persistent and durable manner these new endpoints may not be serviced if this is the first time the remote client has run the collection process. Thus a server side self monitoring process is used to watch for auto created endpoints that need to have a new server side thread process created in order to service the new collection endpoint. Optionally an exception report can be generated to notify the administrator that a new collection client has been detected.

The node topic or queue objects can run in the JMS service. Moreover the system utilizes these JMS objects and services in this transport space to abstract reliable sending and receiving of data packets over the network between the clients and the data center. Alternatively the system can utilize and or substitute additional transport layer technologies in place of the JMS layer by implementing this same transport space in the new transport layer. Also the system can be used with any type of transport or message layer that enables the system to function as described herein. The remote data collection process which moves data from many remote sites into a central datacenter can be reversed such that data is sent back to the remote clients when and if it is necessary.

The specific client agent and server design is described below. Note that the client and servers are represented or modeled in independent diagrams because they are loosely coupled via the message passing architecture . However the client and server processes can be viewed to be part of a single system design that accommodates the flexibility and adaptability needed to work autonomously across a variety of systems. For example a specific client is not aware of the remote server or message transportation specifics and vice versa however the central DC does track the remote client status and configurations. The message passing nodes connect each side with their corresponding counterpart and allow for the passing of both control and configuration messages as well as LOB data to occur reliably and automatically.

At the remote client site a service wrapper process component can be used to auto start the remote data collection process as a service on a local business device PC or POS as well as configure the JVM to load and run the other remote data collection components. The service wrapper process monitors the JVM for restart messages and if detected automatically re loads a launcher process . The service wrapper process ensures that the launcher process is started and running at both power up boot time and throughout the operation of the local business device PC or POS . Finally the service wrapper process can configure the JVM to initially load current remote data collection JAR files via file path settings memory requirements etc.

The launcher process is a singleton Java process that can load and launch other remote data collection processes. The remote data collection system is a layered service where each layer is responsible for a small isolated feature set that allows the system to interact with the other layers using Java calls messages .conf settings and the JMS. The launcher process can be viewed abstractly as a supervisor process that ensures that other remote data collection processes are running properly. Specifically the launcher is utilized as a synchronization root to allow loosely coupled sub features or processes on separate threads to abstractly interact with one another. Additionally it provides access to global configuration information. Alternatively the launcher process can set an exit condition and shutdown the JVM. The exit condition set by the launcher process can be monitored or read by the service wrapper process layer upon exiting the JVM and can be used to signal to the service wrapper process that the JVM and its processes should be restarted. This monitored watchdog process provides for simplified and predictable reliability at remote sites.

When the JVM is started the launcher process is auto started and it reads the local configuration files to determine what other processes should be stored in memory. Then the launcher process loads those other Java classes inside the JVM. Also the launcher process serves as an interface for all Input Output I O to the local text configuration files e.g. .conf . The launcher process redirects the JVM Standard Error output port to use a log process to ensure all Java errors are written into the client side central log . In one exemplary embodiment the launcher process is configurable via the metadata messages. The launcher process also holds the agent state information such as data values for is Collecting is Updating UpdaterStarted that enables the various remote agent sub processes to have abstract access to global agent state information. Both updater and collector processes can query the launcher process for the current system state to determine what actions they should or should not take. Additionally the launcher process constructs and launches the updater and collector Java classes via a custom Versioned File System Class Loader VFSCL that allows more control of the Java file loading process than the standard built in JVM class loading mechanism. Class loading is managed by the VFSCL without using file locks which provides for another unique feature of the present invention as it ensures that code update changes do not conflict with each other are not blocked by current remote agent operation and are able to be rolled back. Finally the launcher process is also responsible for killing the update and the collector processes whenever needed and if needed the entire JVM. In such an event the launcher signal is noticed by the Service wrapper which kills and restarts the JVM if needed.

The update process is responsible for keeping the local installation up to date with the current version of the remote data collection code as defined in the master update database table stored at the data center . During operation the update process posts an update request message into the destination transport space which is received by the Update Server . The purpose of the update request message is to check for any updated code or configuration files based on the client s currently running version which is defined by its update number. Generally the update process is asking the DC if it has a newer version of the remote data collection system available at the DC. This abstraction allows the update process to maintain the correct current code version and configuration settings at the local site as defined by the remote data collection system administrator. Furthermore the client only needs to know its current version while all update availability decision making and delivery are handled by the Update Server at the DC. When the client update process receives a response it either begins receiving file update messages or an update complete message if it is already up to date. The update process then determines if it is necessary to restart the service wrapper process and JVM to repeat the process if needed. The updates are packaged and sent as messages by the Update Server and processed by the client to create new remote data collection code or configuration files stored in the local storage medium .

The collector process connects to one or more of the configuration defined local LOB database s extracts the required information and may send the data to a destination or write the information to a local shadow database and then prepares data messages to send to the DC via the message channel transport space . The collector process includes many sub processes and threads that are synchronized across its operation. The collector process can also create log entries stored in a local state database in order to identify which stage or process it is or was last running and what values or actions it has taken. Additionally collector state can be packaged as messages and sent via the channel transport space to the MetaLog Server which allows the central administer to produce reports which show the state and status of this complex process across multiple sites with minimal effort.

A tray tool process can be a local system agent process that interacts with the local user of the PC or POS device and notifies the user of important status or diagnostic messages and allows the user to take actions to change or correct the status of the remote agent . The purpose of the tray tool process is to provide an optional user interface UI to the normally automated and hands off operations of the remote agent . For example whenever the system identifies a problem the tray tool process can notify the user. Moreover the user can request the current status of their remote agent of the system using the tray tool UI. The tray tool process runs as a system object in a manner consistent with other operating system utilities and tools. In an exemplary embodiment the tray tool process can include an icon that changes state red green or creates a pop up message to warn the user that the system needs their attention. Examples can include when the collection process did not run during the scheduled time due to a power failure or if the Internet connection went down. The tray tool icon allows the user to click on it to display a menu which contains additional state information e.g. last collected time version number etc. as well as run additional diagnostic tests e.g. connectivity tests via pinging the DC or to attempt to start the collection process immediately using the manual Run Now command. Thus the system can run in a lights out automated process or the tray tool can provide the local user with the ability to interact with the automated remote data collection process and diagnose local problems such as local LOB connectivity problems.

A per LOB add in process is an optional component of the system that extends the tray tool process features directly into each of the local LOB application s from which the agent is performing data collection. This feature allows the local user to perform the Run Now command and other remote data collection management features from within the LOB application menu system. During operation a local user can be working within the LOB application and decide to send the current data to the DC using the LOB add in process . For example in one exemplary embodiment of the invention the local user can select the File menu in the LOB application then selecting the add in menu called Run Collection Now they can manually trigger the data collection process to run immediately. Alternatively the command location text and function can be a configurable component defined by the definition files and is compatible with the LOB add in extension method for that particular LOB product. This add in model allows the user to control when data is collected by directing the system much the same as the tray tool is used.

Finally the entire remote agent can be packaged in a platform specific manner for installation and loading onto the remote client PC POS or embedded device using an appropriate setup process that can be activated by a mouse click or other types of actions automated by software deployment tools. This setup process can be started via a variety of mechanisms including but not limited to an email message sent to the users at each location targeted by the administrator for remote automated collection. In such an embodiment the email may contain text explaining the purpose of the remote data collection rollout program as well as a URL pointing to the HTTP or FTP location of the specific download installation package. The remote agent installation package can be customized to the specific collection needs and remote data collection code for the local device. A business user at the remote site can be directed by the email to click on the link to facilitate copying the installation package to the local device from over the Internet via HTTP or FTP download. Once the installation package is copied locally the installation package code can be run automatically to extract the remote data collection files copy them to the predefined location and configure them to operate according to the configuration files embedded into the installation package. The setup process can also copy the JVM code if needed to the remote PC and configure it for operation. Additionally the setup process can install the local service wrapper process which then both loads the JVM and automatically launches the collection process components whenever the remote device is started. As described earlier when the remote data collection process first loads the service process causes the launcher process to be loaded. It is the function of the launcher process to launch the update process the first time it is loaded. The first time the update process is run the update service sends an update request message to check for newer versions of code files. This auto checking ensures that the local client is running the correct version of the code and definition files even when the installation package has older or stale code versions. The system can instruct the local client to ask for the current system definition each time it is run. This auto bootstrapping facilitates auto installation of current versions of the code and definitions onto remote PC or POS devices without the need for extensive local human intervention or actions. After the installation and the first update process has run normal remote data collection operation procedures take over allowing the collector process to run as scheduled. Once the current and correct set of files is installed the collector process occurs on regularly scheduled intervals that can be defined by the definition object. Note that while the collector process typically occurs on regular scheduled intervals defined by the definition it can also be launched for immediate operation using the Run Now command via the optional tray tool or the LOB add in tool or other methods.

The nodes used by the client agent processes can be the definition node pair e.g. a local sender and a listener the main collection data node sender plus a metadata or log node sender e.g. a local sender . As described above these nodes are classes that encapsulate the communication process provided by the chosen transport layer here JMS and are utilized to abstract the data collection process from the physical transport layer implementation. The collector scheduler process can also include the code required to determine what the collection schedule should be what the current time is and to check the collection definition for new information. The collection scheduler process can launch the Data Collection Task DCT and the Definition Checking Task at the appropriate time using a set of timers which launch timer tasks. In the exemplary embodiment the timers can be objects upon which tasks can be scheduled to run at a desired time and or at a desired interval. During operation the collection scheduler first retrieves the latest collection definition object from a definition message sent by the Definition Server and determines if the definition is configured to run immediately or if the tray tool has set the Run Now flag. If either case is true the collection scheduler schedules the DCT to run immediately. Otherwise the schedule definition is extracted from the full system definition object. This schedule definition can contain the defined collection launch time and interval which can be used to schedule the DCT on the data timer . Next the definition checker task is scheduled to run on the definition timer at a repeated interval. This interval value can be stored as a configuration setting. The definition checker task is a small background process that is run on an interval with the intention of keeping the client synchronized with the latest collection definition and corresponding schedule. As the definition checker task periodically runs it retrieves the current definition from the full definition object which was sent by the Definition Server using a definition message processed by a node pair and then compares the retrieved and current in memory definition launch times and reschedules collection if needed.

A unique ability of the collection process and the other processes described herein is to not interfere or corrupt or modify the requested collected information from any of the specified data sources. That is the collection processes can be operated in a non intrusive manner with respect to the source DB so as to prevent interference corruption or modification of data with the source DB . Specifically the remote data collection agent works in a read only mode that copies requested data to extract it and process it for comparison and transport. This read only capability is enhanced without the need to modify the existing LOB or software application or data source. Thus the simplicity safety and reliability of the system enhance the unique value of the remote data collection system and methods.

Further another unique capability of the remote collection systems and methods includes the ability to treat almost any type of software system or data file as an extractable data source . For example a wide range of supported data sources includes text files spreadsheets traditional SQL databases Indexed Sequential Access Method ISAM files or flat files and the like. An additional unique attribute is the ability to wrap a standard Internet Web Service WS and treat it like any other data source that is supported or consumed by the remote data collection agent. Thus the system flexibility and support for a wide range of heterogeneous data sources.

The flexibility provided by the reconciliation phase of the Data Collection Task DCT process is one of the unique features of the present invention. The DCT can be viewed as containing two primary components or abstraction layers which are labeled the Reconciliation and Collection phases but this is an abstract design model which may be implemented in various ways by system agent depending on the nature of the LOB application or database or API used to retrieve data. In general the Reconciliation phase of the DCT process performs the unique and novel functions of the process steps labeled and . The data collection process can begin with the extraction of collection rules data from the full collection definition object to learn what data is requested by the central administrator from the local LOB database and how to extract the data and optionally transform the data. In the exemplary embodiment the DCT facilitates extracting data from the local LOB by first testing to see if it can extract the local LOB database table and column names defined by the collection definition object as indicated by the first step in the reconciliation phase . This step is used to verify that the local LOB database has no local data access issues which may have been caused by changes to the LOB database schema caused by upgrades patches and manual editing and the like. If the data access step is successful the DCT process reconciles the state of the local database with the state of the shadow database selecting as much data as was requested and available given the current state of the local database . The comparison step of the Reconciliation phase performs any processing or comparison of rules or selection statements in order to select only those data values which match the current collection object . The Reconciliation phase of the DCT process can also use the local shadow database to prevent the resending of redundant or previously collected data. This de duplication process can be performed on either the server or the client . Alternatively the de duplication process is performed at each remote site rather than the central DC to facilitate parallelizing the process performed at the client and not the central server . An additional alternative implementation is to utilize the local LOB API eg. QuickBooks XML API to perform a similar data filtering function provided in steps and .

In an exemplary embodiment the DCT can enable the system to extract data from the LOB database copy it to a local shadow database extract the required data and package it for handoff to the message transport layer . The DCT may connect to the local LOB database via a Java Database Connectivity JDBC connection or some other LOB proprietary application programming interface API such as QBXML for QuickBooks. The DCT can be scheduled to run via the timer created by the collection scheduler process which was auto started by the JVM and launcher process . Thus the DCT can be activated when needed or requested. Once the DCT is activated the DCT can retrieve the current and latest schedule definition each time it runs to receive the most current definition of what actions to perform step . Each time the DCT runs it can extract the requested data from the local LOB database and prepare the shadow database while comparing it to previously collected data in order to determine which data values are new changed or deleted since the last collection time. The decision of what to collect such as but not limited to new new plus changed data all data including new changed or deleted etc. is accomplished using rules defined by the definition object . The comparison step facilitates indentifying the changes in the local LOB database since the last collection process was run and therefore makes the process efficient by only extracting and sending the specifically requested set of new information. The DCT can also log status information both locally and remotely to the server as it processes or inserts the data into the shadow database . To log status data the DCT can send a log message which can be retrieved by a listener node servicing the MetaLog Server which inserts them into the central log database . A log entry allows the central administer to generate reports and set alerts for any remotely generated errors and provide proactive management to solve any potential problems. Additionally the DCT sends any client side java exception messages to the MetaLog listener node for logging in the event that any problem occurred e.g. the local database is missing moved corrupted or locked etc. . Note that the local log entries are also sent as part of the remote data collection process which provides a hands off or lights out remote data collection process. The log files can be centrally managed and reported on to identify any problems which can be fixed with definition or update changes.

The DCT process can run using a variety of implementations to make it abstracted from and run independent of any specific LOB database engine such as but not limited to SQL Server Oracle MS Jet Paradox Dbase etc. This database DB abstraction layer may be implemented in the reconciliation steps to wrap deficiencies in the native LOB data access layer or the shadow database storage mechanism. For example a LOB data access layer may provide non standard names for columns or tables or truncate these names as well as return incorrect column properties such as NULL for non NULL columns. The DCT data access wrapper layer handles and corrects for these conditions using a dynamic SQL statement generation object which objectively represent an abstracted view of either the local LOB database or the shadow database. For example a Paradox JDBC driver may lack specific JDBC features but it may still be supported by the DCT process because the DCT DB abstraction layer implements the source and destination collection databases as objects. This data object representation is used by the DCT process to drive the proper generation of SQL statements to ensure that it can work correctly with both the local and shadow database to provide unique database independence capabilities. Moreover the DB object abstraction layer is used to extract the current LOB data and compare it to the local data in the shadow database i.e. the last collected data using the rules in the collection definition object without depending on the local database engine feature set. The comparison can be performed by a separate database stored within the existing local LOB database or in a separately installed shadow database engine that is transparent to the local PC or user. The database abstraction layer also supports creating or re creating the entire local LOB database in a separate shadow database on a per table basis. In one embodiment the database abstraction layer flushes the current temporary local shadow database with a complete new copy of the current LOB data via steps . The database abstraction layer also supports resending data from the local data store on a timestamp basis in the event of communication loss packet corruption or DC operational loss. Thus the DCT process has a robust set of data connection abstraction comparison re transmitting resending and error handling features required by a true automated remote and lights out remote LOB data collection process.

In the exemplary embodiment the implementation of the comparison function via steps handles a variety of traditional comparison functions as well as a large set of special edge cases which occur due to the variance of many LOB applications and how they are implemented in various databases and data schema versions or variations. The ability to extract existing LOB data and compare it to rules defined by the central configuration server via the definition object allows for easy and non DBA or IT administration of the remote data collection process. The comparison process can use the key design concepts of separate comparison metadata tables and destination or data store tables. The structure of these data tables enables the comparison process to perform quickly and efficiently on the client side and these table structures i.e. schema are reconciled or updated to the current collection definition on each collection run. Note that the DCT collection process can use the comparison function to perform reconciliation between the table column in the definition file and the existing or local table s column in both the source and shadow databases. This technique allows the DCT process to safely capture newly requested data such as but not limited to new columns or values and to notify the central server when the local database has changed its schema definitions. For example the comparison and reconciliation process can notify the central administrator that a specific local LOB application was upgraded and that it now stores additional data previously not collected. This table definition comparison allows the DCT process to dynamically adapt to either missing or added columns and reconcile the current local schema to the collection definition request without interrupting the current collection run. The comparison function facilitates the reconciliation phase process which prevents minor database schema changes from causing an error loop that results in continuous cycle of data retrieval and error reporting which would overwhelm the DC servers. As a result customers can be safely provided with data while providing peace of mind and confidence that minor application or database patches will not stop the flow of data collection. Additional error and exception handling code allows the collection process to adapt to local database conditions such as the corruption of individual rows within the source database or to prevent corruption of the shadow and remote datacenter databases in the event of changes to the local LOB database primary keys or other schema elements. Thus the comparison function can retrieve the current database column definitions that exist in the local database e.g. the current local LOB database schema source tables each time the DCT process runs to ensure that local changes are reconciled with the shadow data and the collection rules . This feature enables data collection reliability and prevents errors due to variations in local LOB database schemas and data content across a wide range of independent remote sites.

Once the reconciliation process is done the end result is a pared down representation of the collection definition s table and column objects. Another unique feature is the use of these objects to dynamically generate the local SQL scripts that perform the source data retrieval and the shadow database insert comparison function without depending on triggers stored procedures or other database software logic contained within the local LOB database . The DCT process can also utilize a dynamic source and or shadow database driver that may be embedded in the definition to aid in the SQL script generation. This feature allows for flexibility and cross database implementations to handle changes or inconsistencies with data types keywords or other database attributes which can occur between vendors. Note that the DCT database abstraction process does not allow for arbitrary SQL statements to be executed on the source database. The DCT script generation and execution engine only performs SELECT type SQL statements thus ensuring the collection is a read only process that can not damage the existing LOB database . Also note that script generation is automatic because it is driven by parameters defined in the collection definition object . Finally this layered and abstracted design allows the DCT process to collect from multiple clients or databases simultaneously. This is useful in hosted environments where a single server may host multiple implementations of a LOB process or where a single LOB application may use multiple databases or where a remote site may use multiple LOB applications and wish to collect from all of the LOB data sources. The DCT process is abstracted from the implementation specifics of the local LOB database or machine thus allowing a single local agent to perform the entire set of data collection tasks. Finally it should be noted that by using JDBC or native LOB APIs the collection process may work independently with multiple source databases that are both local on the machine or at remote machines that may use the Operating System O S file system network sockets layer or other APIs including Internet webservice calls to retrieve data stored within the LOB database.

The Data Message Sender DMS process can use a message controller object to package the collected data into data messages which can fit into the packet size specified by the collection definition object which may be tuned to match the current transport layer and node sender operating environment. The DMS handles the internals of receiving the source data determining the current data byte size and utilizing the message controller to package the data into data messages which are sent to the DC . The DMS may also notify the correct classes to turn encryption of the data message on or off using the optional data encryption process . Once the DMS has a data message of the configured size it passes the message over to the collection node sender which then utilizes the transport space to reach the data consolidator node listener at the central DC . Again note that all the data nodes at both the client and DC simply know of the existence of the data message as an object without knowing any of the internal details due to the use of the message controller abstraction layer. This type of abstraction implementation allows the actual message formatting to be independent of the underlying communication transport layer . In an exemplary embodiment the system can be adapted to use many other transport layer technologies including other object broker or middleware products. The actual message passing and transmission may be handled by the transport layers including acknowledgement message persistence automatic queuing serialization and retry processing in the event of a communication failure. Any appropriate transport errors are also logged into the local log for later collection into a centralized error log for further analysis and reporting.

An additional exemplary embodiment of the invention is the creation of a peer to peer ad hoc dynamic data replication and synchronization system. Since the remote data collection systems and methods have the ability to treat any system as a data source a corollary to this design means that any two remote systems may send or receive data to each other. This dynamic data replication and synchronization service is created via the creation of a dynamic command language to determine what data sets to retrieve how to extract them and compare extracted data to targeted or requested data and send that data to the data transport system. Another aspect of the dynamic peer to peer system is the ability of the invention to dynamically create system end points or receiving data listeners as needed or specified without administration overhead. Additionally another dynamic aspect of the invention is the ability to dynamically create new or custom data fields as needed in the master or consolidated database. This feature is useful when the various remote system data source structures and metadata schema data fields column names tables and the like vary between and among the many remote sites. Using dynamically created consolidated data tables allows the system to handle the wide variability and unpredictable nature of remote systems where various versions of LOB systems are installed i.e. inconsistent or different versions are installed across the system and or when customizations or local modifications have been made to local data sets. Existing systems generally require a common or identical data set model and or they drop the additional or customized data values. The dynamic data source creation is generated by robust information contained within a data message used by the dynamic command language that controls the system s operation to both create a new column and generate the dynamic database language statements on the fly to insert the new dynamic data.

An additional aspect of this invention is the ability to support data collection and or display on modern mobile digital devices such as smart phones tablets or personal digital assistants PDAs and the like. The ability to collect flat files or structured storage across device types in a two way data replication and synchronization scenario enables mobile users to stay up to date with both centralized data sources as well as other remote systems such as cloud or BD services and or other mobile users. The dynamic ad hoc nature of the system allows even homogenous devices which have dissimilar data sets stored within supported data sources to make a comparison that identifies the commonality the differences and exchange requested information between them anytime. This includes support from synchronizing mobile devices with existing LOB systems or devices and allowing the mobile device to become remote terminals to interact with the legacy systems data including configuration settings and or evaluating operating results with dynamic charts graphs and measurements indicating the current state of the legacy system on the mobile users device. Examples of this include differences in two users phone number lists and having the system compare these data sets and synchronize the differences between them including user override or approval of additional data.

A significant aspect of the invention is the ability to replicate data between systems including new cloud or Software as a Service SaaS systems including data forwarding from existing legacy devices by integrating them with cloud based data consolidation systems. Of particular note is the ability for the invention to include other cloud based systems as data sources via the support of a WebService as potential LOB data source. Thus a hybrid cloud architecture can be supported between legacy LOB systems by replicating or sending their data to new cloud systems and or collect from multiple cloud systems into a single cloud system.

Yet another aspect of the invention includes the idea of a database repeater or a dynamic ETL to move data from one LOB system to another of the same or different type using a combination of the unique features. This improves upon existing Extract Transform and Load ETL systems that have a fixed taxonomy and fixed understanding of what data inputs come in and how they are mapped or transformed into a combined data source typically a data warehouse. The system s ability to use a dynamic command language to work on dynamic data sets and extract compare and replicate them including handling different data source schema variances at the source and dynamically creating compatible destination consolidation sources. Examples include variations in accounting systems chart of accounts to categorize similar if not identical items under different labels or identifies or codes and the like. This can be extended to any type of tagged or identifiers including Extensible Markup Language XML labels or described data sets such as financial reporting under the Extensible Business Reporting Language XBRL standard.

The system updates may be version controlled in the update database using the update number. The UN versioning enables specific versions of the agent code to be loaded at the client side using a custom java class loader called the Versioned FileSystem Class Loader VFCL . This process enables the launcher to load the correct update number version of the code file into memory and execute the code file. Moreover the VFCL may load java classes without maintaining a file system lock on the .jar files which facilitates updating the client while it is still running in the remote client machine s Java Virtual Machine JVM . This allows the old client files to be in use but not locked by the file system allowing them to be overwritten by the new update versions. The VFCL enables the system to run in an automated and unattended manner at the remote site and be maintained by a centralized configuration site using the UN. The VFCL also searches for classes in a pre defined order or manner rather than a default java system class loader search method. Moreover the VFCL may ignore the CLASSPATH local environment variable settings opting instead to load jar files in a predefined manner such as from the highest available version of a java class to the lowest available versions. This allows the client to store and use multiple versions of the code files for example loading the current version specified by the .conf file and additionally falling back to an earlier version of the file if the current version is missing or corrupt.

The processor is a hardware device for executing software instructions. The processor can be any custom made or commercially available processor a central processing unit CPU an auxiliary processor among several processors associated with the computer a semiconductor based microprocessor in the form of a microchip or chip set or generally any device for executing software instructions. When the computer is in operation the processor is configured to execute software stored within the memory to communicate data to and from the memory and to generally control operations of the computer pursuant to the software instructions.

The I O interfaces can be used to receive user input from and or for providing system output to one or more devices or components. User input can be provided via for example a keyboard and or a mouse. System output can be provided via a display device and a printer not shown . I O interfaces can include for example a serial port a parallel port a small computer system interface SCSI an infrared IR interface a radio frequency RF interface and or a universal serial bus USB interface.

The network interfaces can be used to enable the computer to communicate on a network such as to a client or the like. The network interfaces can include for example an Ethernet card e.g. 10BaseT Fast Ethernet Gigabit Ethernet or a wireless local area network WLAN card e.g. 802.11a b g n . The network interfaces can include address control and or data connections to enable appropriate communications on the network.

A data store can be used to store data such as configuration data and the like. The data store can include any of volatile memory elements e.g. random access memory RAM such as DRAM SRAM SDRAM and the like nonvolatile memory elements e.g. ROM hard drive tape CDROM and the like and combinations thereof. Moreover the data store can incorporate electronic magnetic optical and or other types of storage media. In one example the data store can be located internal to the computer such as for example an internal hard drive connected to the local interface in the computer .

The memory can include any of volatile memory elements e.g. random access memory RAM such as DRAM SRAM SDRAM etc. nonvolatile memory elements e.g. ROM hard drive tape CDROM etc. and combinations thereof. Moreover the memory may incorporate electronic magnetic optical and or other types of storage media. Note that the memory can have a distributed architecture where various components are situated remotely from one another but can be accessed by the processor .

The software in memory can include one or more software programs each of which includes an ordered listing of executable instructions for implementing logical functions. In the example of the software in the memory system includes a suitable operating system O S and one or more programs . The operating system essentially controls the execution of other computer programs and provides scheduling input output control file and data management memory management and communication control and related services. The operating system can be any of Windows NT Windows 2000 Windows XP Windows Vista Windows Server all available from Microsoft Corp. of Redmond Wash. Solaris available from Sun Microsystems Inc. of Palo Alto Calif. LINUX or another UNIX variant available from Red Hat of Raleigh N.C. or the like.

Further many embodiments are described in terms of sequences of actions to be performed by for example elements of a computing device. It will be recognized that various actions described herein can be performed by specific circuits e.g. application specific integrated circuits ASICs by program instructions being executed by one or more processors or by a combination of both. Additionally these sequence of actions described herein can be considered to be embodied entirely within any form of computer readable storage medium having stored therein a corresponding set of computer instructions that upon execution would cause an associated processor to perform the functionality described herein. Thus the various aspects of the invention may be embodied in a number of different forms all of which have been contemplated to be within the scope of the claimed subject matter. In addition for each of the embodiments described herein the corresponding form of any such embodiments may be described herein as for example logic configured to perform the described action.

The computer system also includes a main memory such as a random access memory RAM or other dynamic storage device e.g. dynamic RAM DRAM static RAM SRAM and synchronous DRAM SDRAM coupled to the bus for storing information and instructions to be executed by processor. In addition the main memory may be used for storing temporary variables or other intermediate information during the execution of instructions by the processor. The computer system further includes a read only memory ROM or other static storage device e.g. programmable ROM PROM erasable PROM EPROM and electrically erasable PROM EEPROM coupled to the bus for storing static information and instructions for the processor.

The computer system also includes a disk controller coupled to the bus to control one or more storage devices for storing information and instructions such as a magnetic hard disk and a removable media drive e.g. floppy disk drive read only compact disc drive read write compact disc drive compact disc jukebox tape drive and removable magneto optical drive . The storage devices may be added to the computer system using an appropriate device interface e.g. small computer system interface SCSI integrated device electronics IDE enhanced IDE E IDE direct memory access DMA or ultra DMA .

The computer system may also include special purpose logic devices e.g. application specific integrated circuits ASICs or configurable logic devices e.g. simple programmable logic devices SPLDs complex programmable logic devices CPLDs and field programmable gate arrays FPGAs .

The computer system may also include a display controller coupled to the bus to control a display such as a cathode ray tube CRT liquid crystal display LCD or any other type of display for displaying information to a computer user. The computer system includes input devices such as a keyboard and a pointing device for interacting with a computer user and providing information to the processor. Additionally a touch screen could be employed in conjunction with display. The pointing device for example may be a mouse a trackball or a pointing stick for communicating direction information and command selections to the processor and for controlling cursor movement on the display. In addition a printer may provide printed listings of data stored and or generated by the computer system.

The computer system performs a portion or all of the processing steps of the invention in response to the processor executing one or more sequences of one or more instructions contained in a memory such as the main memory. Such instructions may be read into the main memory from another computer readable medium such as a hard disk or a removable media drive. One or more processors in a multi processing arrangement may also be employed to execute the sequences of instructions contained in main memory. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions. Thus embodiments are not limited to any specific combination of hardware circuitry and software.

As stated above the computer system includes at least one computer readable medium or memory for holding instructions programmed according to the teachings of the invention and for containing data structures tables records or other data described herein. Examples of computer readable media are compact discs hard disks floppy disks tape magneto optical disks PROMs EPROM EEPROM flash EPROM DRAM SRAM SDRAM or any other magnetic medium compact discs e.g. CD ROM or any other optical medium punch cards paper tape or other physical medium with patterns of holes a carrier wave described below or any other medium from which a computer can read.

Stored on any one or on a combination of computer readable media the present invention includes software for controlling the computer system for driving a device or devices for implementing the invention and for enabling the computer system to interact with a human user. Such software may include but is not limited to device drivers operating systems development tools and applications software. Such computer readable media further includes the computer program product of the present invention for performing all or a portion if processing is distributed of the processing performed in implementing the invention.

The computer code devices of the present invention may be any interpretable or executable code mechanism including but not limited to scripts interpretable programs dynamic link libraries DLLs Java classes and complete executable programs. Moreover parts of the processing of the present invention may be distributed for better performance reliability and or cost.

The term computer readable medium as used herein refers to any medium that participates in providing instructions to the processor for execution. A computer readable medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example optical magnetic disks and magneto optical disks such as the hard disk or the removable media drive. Volatile media includes dynamic memory such as the main memory. Transmission media includes coaxial cables copper wire and fiber optics including the wires that make up the bus. Transmission media also may also take the form of acoustic or light waves such as those generated during radio wave and infrared data communications.

Various forms of computer readable media may be involved in carrying out one or more sequences of one or more instructions to processor for execution. For example the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions for implementing all or a portion of the present invention remotely into a dynamic memory and send the instructions over a telephone line using a modem. A modem local to the computer system may receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector coupled to the bus can receive the data carried in the infrared signal and place the data on the bus. The bus carries the data to the main memory from which the processor retrieves and executes the instructions. The instructions received by the main memory may optionally be stored on storage device or either before or after execution by processor.

The computer system also includes a communication interface coupled to the bus. The communication interface provides a two way data communication coupling to a network link that is connected to for example a local area network LAN or to another communications network such as the Internet. For example the communication interface may be a network interface card to attach to any packet switched LAN. As another example the communication interface may be an asymmetrical digital subscriber line ADSL card an integrated services digital network ISDN card or a modem to provide a data communication connection to a corresponding type of communications line. Wireless links may also be implemented. In any such implementation the communication interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

The network link typically provides data communication through one or more networks to other data devices. For example the network link may provide a connection to another computer or remotely located presentation device through a local network e.g. a LAN or through equipment operated by a service provider which provides communication services through a communications network. In preferred embodiments the local network and the communications network preferably use electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on the network link and through the communication interface which carry the digital data to and from the computer system are exemplary forms of carrier waves transporting the information. The computer system can transmit and receive data including program code through the network s and the network link and the communication interface. Moreover the network link may provide a connection through a LAN to a mobile device such as a personal digital assistant PDA laptop computer or cellular telephone. The LAN communications network and the communications network both use electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on the network link and through the communication interface which carry the digital data to and from the system are exemplary forms of carrier waves transporting the information. The processor system can transmit notifications and receive data including program code through the network s the network link and the communication interface.

One of the unique elements of the visual reporting system of the present invention is the ability to create comparative visual graphs or charts such as Visual Cash Flow charts . These unique business reports enable a novice user to more quickly and easily understand the impact of their financial LOB or operational decisions on their business by graphing their data from the point of view of a center line or 0 value axis to show either a positive impact or a negative impact on any item category KPI or any calculated or defined values which may be collected consolidated and or normalized or standardized by the SMB BI system. This graphical charting of values utilizes the key idea to display business data values including averages or other calculated values as deviations from a zero or neutral point or line. This visual treatment enables users of the SMB BI system to visualize their data either within their own individual operation their individual store results in the first column of numbers in and or vis vis selected peer group or national averages and the like e.g. a national average column as graphed in . This unique and novel format enables a clear comparative picture using the visual treatment format of red and green bars displaying the magnitude of their data value per measured item or category from the perspective of a zero or neutral axis. This concept utilizes a unique normative or standardizing visual treatment which enables complex accounting or other business concepts to be both easily understood as to their impact on the item i.e. good or bad and on a relative basis i.e. to peers or averages regardless of the type or manner of measuring the operational business data value. This visual treatment is based on the idea of graphing actual calculated or other business data values as both a color green for positive or good impact or results red for negative or bad impact or results as well as a magnitude of the data value using the length size width and the like of the visual item such as in a bar chart . This normalized visual treatment works relative to either their individual SMB members own data values and or a set of comparative values such as peer group averages and or national averages and the like. For example the visual treatment would display a favorable data value either in dollars or as a percentage as a green graphical bar pointing to the right of the zero axis while a negative data value is shown as red bar pointing to the left of the zero axis for any measured identified or calculated quantity.

For example most business owners managers or anyone reviewing an individual business operating results struggle to understand the complex items that are used to produce or incorporated within a standard accounting cash flow type of report. These reports are typically displayed as static columns of numbers listed by accounting categories in a single table format without charts graphs or visual treatments. Even when these values are graphed they typically only use the absolute magnitude of the data value or number but they have not been used to show the impact of the data value. Small business owners struggle to understand let alone know the meaning behind a change to an individual accounting category therefore seeing the table of numbers is less insightful than seeing why the results ended up at the position they are shown. For example is an increase in liabilities a good thing or a bad thing from the point of view of the small business owner Most owners who are not CPAs or who do not have extensive accounting education would not know how to understand that question let alone know what that result means to their business and how to take action to correct it if needed. Another example is the scenario where cash was increased within a business for a defined period of time thus did the end of period net cash increase due to aggressive collection of invoices and thus a decrease to AR or due to a delay in paying invoices and thus an increase in AP Utilizing the visual treatment this can be more readily discovered and used to guide the business owner operator manager or advisor to make better or different decisions going forward. Thus the unique and novel comparative nature of the present inventions Visual Cash Flow helps anyone understand their individual business results directly as well as by comparing their business results against other comparative data sets.

To further aid guide and help the user understand their business or operating results the unique comparative visual treatment utilizes the exact nomenclature and composition of accounting items for each account and account grouping i.e. C. Investing Activities Other Assets Other Liabilities as that found in the most common small business financial accounting software e.g. QuickBooks by Intuit . Additional flexibility is provided by the SMB BI system in that this visual treatment may be modified or adapted to any type of LOB software reporting style and or similar accounting software such as Peachtree Accounting by Sage . Calculations resulting in values displaying the financial impact within each account or grouping positive or negative are based on Generally Accepted Accounting Principles GAAP . For example Increases in Non Cash Assets result in Decreases in Cash Flow while conversely Decreases in Non Cash Assets result in Increases in Cash Flow. Additionally Increases in Liabilities result in Increases in Cash Flow while conversely Decreases in Liabilities result in Decreases in Cash Flow. The bars directly adjacent to each account or account grouping are in direct synchronization with such accounts and are drawn to scale reflecting the numerical variation dollars or percent either positive green or negative red versus the peer group average by pivoting off of a vertical axis which is at the neutral position. This process enables the creation of simple visual comparisons versus an unlimited number of peer group averages which are enabled by the SMB BI systems dynamic ETL collection consolidation and reporting capabilities.

Note that the Income Statement utilizes the exact same formatting as the visual cash flow charts while the Balance Sheet utilizes simple side by side bar comparisons to explain changes to categories for either an individual business or versus averages. This novel and unique formatting allows those without expert level accounting business or operational skills to quickly and easily understand the net results of their individual or consolidated business operations. Finally those of ordinary skill in the art will recognize that the screen shots and can be adapted to other business and to other types of collected data i.e. demonstrating the positive or negative financial impact versus pre established goals budgets or of variances of actual results to goals budgets and or changes within each element of a financial statement income statement cash flow balance sheet .

Specifically the SMB BI System is able to generate unique and enhanced reports with greater business intelligence value or insight by combining in one report data from both a financial accounting package plus operational data from an LOB system. These types of unique reports may only be generated when both financial and operational data are consolidated normalized and or provided with additional data processing on items from two or more businesses as they enable members to make comparisons under equal terms to unique measures generally known as operational dollar efficiency measurements or metrics yielding key performance indicators KPIs unique to their own or similar business operations. These unique KPI results require more than one set of data in order to demonstrate the financial efficiency of various operational processes in the business i.e. Labor costs per Service provided . Similar metrics may be applied to product based businesses as well. Color coding of the comparative numerical results enhances readability and comparative insight for example a peer average utilizing Green shows better than average results Yellow showing somewhat less than average and Red showing results which are well below average . Utilizing these unique KPI charts or dashboards significantly enhances a Franchisor s ability to efficiently pinpoint target areas for improvement for the individual Franchisees.

Additional enhanced business reports with greater insight may be created by the present invention in the specific case of accounting reports. For example additional but underutilized data may be present in collected and consolidated data files if SMB BI members utilize the unique QuickBooks accounting feature where the creator of an invoice has the ability to designate both a Class category grouping and an Item a type of service or product to be shown or assigned within each invoice. When present the present invention utilizes this additional data by combing the revenue dollar breakdown from this accounting data with additional specific Labor Cost or Operational data from an LOB system which has tracked specific Invoices. Using the combined collected data set from these two independent data sources it is possible to create a Margin Dollars Margin Percent by Class Category Grouping Item Service Type report which provides great insight into actual business results see which shows the results of a service oriented business. Similar metrics and visual treatment may be applied to a product based businesses as well. Likewise as noted above color coding of the comparative numerical results which may vary per type of business or concept can be used to display comparisons versus a peer average using a model of Green for better than average results Yellow for somewhat less than average and Red for results which are well below average . Again these types of unique KPI charts significantly enhance a Franchisor s or any business manager s ability to efficiently pinpoint target areas for improvement for the individual Franchisees or independent business. In order to generate these exemplary results it is required to consolidate and integrate remote data that can be collected from both the financial accounting and the LOB system thus a single system which can utilize the same agent or code is preferred method and an exemplary attribute of this invention.

Each of the screen shots and include a plurality of icons enabling the user to navigate between the screen shots and and to a home page or summary page. The screen shots and further include a report date illustrating the range of dates from which the information is displayed a title and a last completed collection date. Note the user can modify the date ranges and the type of information to display such as through the home page. Additionally each screen shot and includes icons at the bottom to change the view to year to date last full year last month and the like.

The method provides a COA standardization procedure here for apples to apples either as an agent side process and or as a server side process or as an automated client side process to fix up the existing data from a non standard COA to a template or standardized form desired for comparisons. Additionally the method may optionally reform the local COA so that existing data conforms to a new standard and or new data being entered is encoded under the new COA. Finally the ETL system may enable unique read only mapped views to be generated on existing data using a standard COA but without actually modifying the underlying data source but support continuing operation under the old or existing COA while supporting future reports analysis or comparison under a virtual COA either at the local and or at the central or remote site.

For example the data source can include QuickBooks QB . Next once QB data is consolidated the method can produce an apples to apples type of comparison between any two members or peers using pre categorized and normalized data under the Visual Cash Flow model using a unique Visual Format and include comparison in absolute terms or terms and allow drill down via a Zero axis puts and takes graphical analysis. By combining both QB and LOB type of data in a central collection and consolidation normalization process the method can provide the ability to produce unique efficiency reports and margin contribution reports.

Optionally the method can include accessing data from a plurality of accounting system files comprising heterogeneous data sets across different accounting applications performing sorting calculating and normalizing of the data for each of the plurality of accounting system files to provide a first set of processed data performing sorting calculating and normalizing of the data for each of the heterogeneous data sets in the first set of processed data to provide a second set of processed data performing sorting calculating and normalizing of the data for a plurality of peer groups on the second set of processed data to provide a third set of processed data and providing a consolidated data set from the third set of processed data. The method can also include defining definition files for each of the heterogeneous data sets that comprise specific collection commands defined to collect all collect deltas between the data recollect find specific items transform data locally or transform data on the server side.

The method defines and describes how data from multiple QB files or multiple other Accounting system data files heterogeneous data sets across Accounting Apps is handled or addressed via a two pass or multi pass ETL operations i.e. sorting calculating and normalizing data per file or within a local site file then per app i.e. all QB then all Peachtree then all Dynamics data files then per category all accounting data QB PeachTree Dynamics then process this data on a per peer group basis then for the entire consolidated DB file set Acct LOB . . . etc. .

The present invention Zpipe utilizes agent definition files which can be created or defined for each LOB database with specific collection and ETL commands which are defined to collect all collect delta s recollect find specific items transform data locally or transform data on the server side etc. The systems Definitions provide unique flexibility. Using a metaphor for how Zpipe works when attaching to multiple LOB systems the comparison would be describe as follows the Zpipe invention speaks multiple data languages and using one translation system ETL the system can 1 identify the local language 2 translate from a local to a central language and 3 issue commands to act in local language and optionally add commands at central language.

Using the methods and the present invention a Cloud to Cloud data collection and consolidation produces a meta cloud system.

Franchising is a leading category or type of SMB business where Franchisors primary revenue source is paid by Franchisees as a royalty or percentage of sales generated by the Franchisee under the local operation of the licensed business. Thus royalties are the life blood of any franchise system. There is a specific need in Franchising to have accurate royalties on a daily weekly or monthly basis across the diverse and dynamic business conditions under which a franchise may operate. Utilizing the unique properties of the data replication and ETL system a unique and automated Automatic Royalty Generation system with built in auditing can be operated. The current invention creates a software platform or system which enables Franchisors to fully automate the process of collecting consolidating reporting and administering highly complex concept wide royalties which are often structured with numerous rule sets which go far beyond simple percentage calculations of revenues only. In effect it provides streamlined and accurate generation of royalties and automated accounting of them which benefits both Franchisors and Franchisees and automated auditing of royalty accounting data when compared to operational data. With the exemplary embodiments of the present invention Franchisors Zors no longer have to rely on inaccurate incomplete or inconsistent sets of self reported sales results and or other types of accounting data from Franchisees Zees which are prone to errors in the best case and willful under reporting in the worst. In addition to creating efficiency in data collection and reporting the present system enables the automation of time consuming administrative responsibilities such as parsing through Franchise Agreements and keeping track of the rules that govern each remote and independent franchisee s royalty calculations such as revenue tiering and monthly minimums and the like. Additionally prior to the current invention modifications to royalty data for extenuating circumstances required multiple iterations reviews ongoing revisions and numerous approvals by a variety of individuals within the franchise system. The invention has removed these bottlenecks and produced a reliable repeatable and trustworthy process to automate and audit royalties. See for example of Automated Royalty Report utilizing this new system.

Importantly the ability to capture multiple revenue sources from separate Accounting and Point of Sale and or LOB operational software systems provide for real time automated auditing within the system and dramatically reduces the royalty shortfalls for many Franchisors. See for an Automated Royalty Audit Report which compares the Revenue Submitted and automatically collected from accounting systems from the Franchise systems typical source the Franchisees Line of Business software system to that automatically collected from the Franchisees QuickBooks Accounting system. Both sets of Revenue numbers should match however there is a 19.7 difference in the third week of the reporting period. Finally the audit process can be further enhanced by the utilization of historical norms and parameters which can be applied to the Franchisees submissions from any and all sources to indicate any outliers outside of normal projected boundaries.

This automated platform process and accompanying technology can also be utilized in any business system in addition to franchising that has numerous autonomous remote locations that rely on accurate reporting of results to determine fees commissions due to a parent entity for example licensees cooperative members marketing cooperative participants dealerships distributors bottlers wholesalers associations etc.

An Additional Unique Aspect of the Present Inventions is the Ability to Generate Automated Franchise Item 19 FPRs Reports.

US law defines rules for the sale of franchised units by a Franchisor under an officially filed plan or set of documents called a Franchise Disclosure Document FDD filed with the US Government. Typically the FDD allows the Franchisor to define their concept the rules under which a Franchise location is offered for sale the business rules for operating the location or unit along with various other items listed in the various FDD sections by number. Of importance to a prospective Franchisee when reviewing various FDDs particularly for units offered for sale by different Franchisors who have similar concepts products or services is the optional section known as Financial Performance Representations FPR declared in Item 19 of the FDD. The FPR must be based on real operational and financial results of existing Franchisee locations using the historical data or records of those existing systems. The use of Item 19 FPRs is a rapidly growing trend in the franchise industry with franchise experts estimating growth in adoption from 25 to 50 of established Franchisors in a recent 3 year period. The presence of an Item 19 section allows a Franchisor to showcase either their ability to collect historical records manually or preferably the sophisticated support systems that a concept utilizes to manage their business and make their FPR claims which helps inform their future Zee partners. Many potential franchise prospects consider it a red flag if a franchisor does not provide an Item 19 section in their FDD. Prospects look for hard numbers to gain deeper insight into the concept. The willingness of a franchisor to share this information provides instant credibility and also dramatically expedites the decision making process for the prospect.

For the first time in franchising the present invention allows the creation and operation of an Item 19 Enabler reporting system that enables Franchisors to automate the process of collecting consolidating and reporting on Item 19 FPRs in FDDs. Prior to the present invention s reporting system abilities Item 19s presented a particularly difficult choice for franchisors as there are legal risks if their Item 19 claims are un substantiated. Franchisors hesitated to make FPR claims because these claims require a reasonable basis based on facts or details which if based on assumptions or without documentation and or back up data could reveal inconsistent LOB operating values results or financial gains. Thus utilizing the present inventions automated data collection consolidated and ETL system capabilities the required data evidence and operational performance documents with backup data can now be generated quickly easily and in a comprehensive and consistent manner across a Franchisors system. The present invention s Item 19 Enabler reporting system solves the requirement for evidence by automatically collecting on each individual franchisees financial and operational results consolidating that data and then providing the ability to report on it in multiple relevant peer groups identified by the franchisor. The fully automated system provides full data visibility that is timely reliable and accurate yielding business insight for all parties.

Although the present invention has been illustrated and described herein with reference to preferred embodiments and specific examples thereof it will be readily apparent to those of ordinary skill in the art that other embodiments and examples may perform similar functions and or achieve like results. All such equivalent embodiments and examples are within the spirit and scope of the present invention and are intended to be covered by the following claims.

