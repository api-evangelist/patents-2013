---

title: Method for wirelessly transmitting content from a source device to a sink device
abstract: Methods and devices for wirelessly transmitting content from a source device to a sink device are disclosed. The method comprises: identifying one or more data types associated with a display frame displayed on the source device; selecting a transmission format for the display frame in accordance with the one or more identified data types, wherein the transmission format is selected from the group consisting of screencasting, graphics processing unit (GPU) processing, or GPU processing with media streaming; and sending visual information representing the display frame in the transmission selected transmission format to the sink device. One or a combination of latency, image/video quality, and power consumption associated with the wireless transmission may be used to adapt the wireless transmission.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09412332&OS=09412332&RS=09412332
owner: BlackBerry Limited
number: 09412332
owner_city: Waterloo
owner_country: CA
publication_date: 20131220
---
The present disclosure relates generally to techniques in wireless communication devices which are configured for wireless transmission of display frames for example by using a wireless transmission channel configured for Wi Fi peer to peer P2P communication.

A wireless communication device such as a portable battery powered wireless communication device may be configured to communicate via access points APs of wireless local area networks WLANs in accordance with IEEE 802.11 standards or the like. Such a device may additionally communicate using peer to peer communication techniques for example over a wireless transmission channel configured in accordance with the Wi Fi Direct technical specification also known as Wi Fi Peer To Peer Wi Fi P2P technical specification . Such a device may be certified as a Wi Fi Direct device.

There is a need for efficiently facilitating transmission of a stream of display frames over the wireless transmission channel to enable wireless communication devices to transmit and or receive display frames to a second communication device such as a television for display at the second communication device. This is useful for example when one portable wireless communication device has a smaller sized display screen than the second communication device.

Transmission of a stream of display frames from a first device to a second device over a wireless transmission channel for display at the second device enables many applications. For example an Internet connected portable wireless communication device may stream a video from a video sharing Internet site and wirelessly transmit the video to a television having a larger display screen. In another example a presentation video or other media stored in the memory of a portable wireless communication device may be wirelessly transmitted to a projector for presentation to an audience. However as such applications require real time or near real time processing and transmission of the display frames more efficient encoding of the media is necessary to allow for reduced latency of transmission and to occupy the wireless channel more efficiently thus reducing the bandwidth for transmission.

The present disclosure provides methods and devices for wirelessly transmitting content from a source device to a sink device are disclosed. The method comprises determining one or more data types associated with display content of the source device selecting a format for transmitting the display frame in accordance with the one or more determined data types wherein the format is selected from the group consisting of screencasting graphics processing unit GPU encoding or a GPU encoding with media streaming preparing the content in the selecting format and sending the prepared content to the sink device. One or a combination of latency image video quality and power consumption associated with the wireless transmission may be used to adapt the wireless transmission.

In accordance with one embodiment of a first aspect of the present disclosure there is provided a method for wirelessly transmitting content from a source device to a sink device comprising identifying one or more data types associated with a display frame displayed on the source device selecting a transmission format for the display frame in accordance with the one or more identified data types wherein the transmission format is selected from the group consisting of screencasting graphics processing unit GPU processing or GPU processing with media streaming and sending visual information representing the display frame in the transmission selected transmission format to the sink device.

In accordance with one embodiment of a another aspect of the present disclosure there is provided a method for wirelessly receiving content on a sink device from a source device comprising receiving a set of one or more GPU display commands and encoded media from the source device performing the set of one or more GPU display commands on one or more graphics resources to generate programmatically generated graphics decoding the encoded media and displaying the decoded media together with the programmatically generated graphics on a display of the sink device. In some embodiments the programmatically generated graphics overlay the displayed decoded media when displayed on the display of the sink device. In some embodiments the encoded media comprises images video or a combination of images and video. In some embodiments the graphics resources are stored in memory on the sink device.

In accordance with further aspects of the present disclosure there are provided wireless communication devices comprising a processor and a memory coupled to the processor and storing instructions which configure the processor for performing the methods described in the present disclosure.

In accordance with yet further aspects of the present disclosure there are provided non transitory computer readable mediums which store instructions for execution by a processor to implement methods described in the present disclosure.

To illustrate one environment within which the techniques of the present disclosure may be practiced illustrates a wireless communication device hereinafter wireless device for convenience which may communicate with wireless communication devices and collectively and an access point AP . Certain adaptations and modifications of the described embodiments can be made. Therefore the above described embodiments are considered to be illustrative and not restrictive. The wireless device may communicate with one or more wireless communication networks. For example wireless device may communicate with a wireless local area network WLAN 110 operating in accordance with IEEE 802.11 standards or other WLAN standards and the Internet via AP .

The wireless device additionally or alternatively communicates using wireless peer to peer communication techniques for example in accordance with the Wi Fi Direct technical specification also known as Wi Fi Peer To Peer Wi Fi P2P technical specification and or be certified as a Wi Fi Direct device. The wireless device may establish a Wi Fi P2P wireless connection with a display device or monitor which includes a wireless transceiver. Such a Wi Fi P2P wireless network connection may be suitable for applications such as for example a streaming media application or a display or presentation application. The wireless device may additionally or alternatively establish a Wi Fi P2P wireless network connection with a printer which includes a wireless transceiver. Such a Wi Fi P2P wireless network connection may be suitable for applications such as for example a print application or a facsimile application. Even further the wireless device may additionally or alternatively establish a Wi Fi P2P wireless network connection with a speaker which includes a wireless transceiver. When the wireless device is connected as such using one or more Wi Fi P2P wireless network connections data may be communicated directly between the wireless device and the other devices i.e. without the data traversing any fixed wireless network infrastructure .

Wi Fi P2P wireless networks may include a P2P wireless device which is designated as a group owner GO to serve some functions of an AP such as broadcasting beacon frames and allocating wireless channel resources. The GO may maintain multiple concurrent network connections in an active state for example with multiple devices including the wireless devices and the AP . In the wireless device acts as a group owner.

The wireless device may be additionally configured to access communication services via a Public Land Wireless Network PLWN not shown such as a cellular telecommunications network. For communication with PLWNs the wireless device may be configured in accordance with one or more cellular telecommunication standards such as Global Systems for Mobile GSM General Packet Radio Service GPRS Enhanced Data rates for GSM Evolution EDGE or Enhanced GPRS EGPRS Universal Mobile Telecommunications System UMTS Long Term Evolution LTE or EVolution Data Only EV DO for CDMA technologies as a few examples.

Reference is next made to which shows in block diagram form an example of the display device suitable for displaying real time streaming media such as video and presentations in accordance with example embodiments of the present disclosure. The display device may be any one of a television a projector a computer monitor an adaptor coupled to a display or other device suited for displaying information on a display screen.

The display device includes a rigid case not shown housing the electronic components of the display device . The electronic components of the display device are mounted on a printed circuit board not shown . The display device includes a processor which controls the overall operation of the display device and a communication interface for communicating with other devices via a communication network . The communication network may be the network shown in or other suitable communication network.

The processor interacts with other components such as one or more input devices such as a keypad buttons or touch sensitive bezel Random Access Memory RAM Read Only Memory ROM a graphics processing unit GPU a display screen via the GPU persistent non volatile memory which may be flash erasable programmable read only memory EPROM memory flash memory or any other suitable form of memory auxiliary input output I O subsystems one or more data ports such as a serial data port e.g. Universal Serial Bus USB data port and High Definition Multimedia Interface HDMI data port a speaker and other device subsystems generally designated as . The components of the display device are coupled via a communications bus not shown which provides a communication path between the various components.

The processor operates under stored program control and executes software modules stored in memory for example in the persistent memory . The persistent memory stores data such as user data. As illustrated in the software modules comprise operating system software and software applications . The software applications include a P2P streaming application . The software modules or parts thereof may be temporarily loaded into volatile memory such as the RAM . The RAM is used for storing runtime data variables and other types of data or information. Although specific functions are described for various types of memory this is merely one example and a different assignment of functions to types of memory could be used.

The GPU provides specialized processing of GPU drawing commands. The GPU interfaces with the processor to receive GPU drawing commands from the processor as the processor off loads processing of GPU drawing commands to the GPU for enhanced efficiency. The processor may send GPU drawing commands to the GPU directly or using a graphics application programming interface API such as without limitation OpenGL or DirectX . The API provides for more efficiency by allowing an application e.g. P2P streaming application requesting a GPU drawing command to request only a high level command to achieve the same function of numerous low level commands. For example the OpenGL command rotateX angle rotates an object around the X axis by the specified angle. The OpenGL API translates the command into instructions for the GPU to process. Furthermore the OpenGL API and other graphics APIs allow for the application to be written only once for multiple GPUs as the API provides a different translation in dependence on the GPU. The GPU once processing of the GPU drawing command is complete defines pixel information which is used by the screen to produce an image on the screen . When numerous GPU drawing commands are processed in sequence by a GPU such as GPU highly visual graphics are displayed on the screen .

The GPU may either be a separate unit or may be combined with the processor into the same unit. For example the GPU may be implemented on an individual integrated circuit IC or may be implemented using a system on chip SoC architecture whereby both the GPU and the processor are implemented on the same IC. Additionally in some embodiment the processor performs the functions of the GPU in addition to other processing functions.

The display screen may be provided as part of a touchscreen which provides an input device . The display screen which together with a touch sensitive overlay not shown operably coupled to an electronic controller not shown comprise the touchscreen. User interaction with a GUI graphical user interface is performed through the input devices . Information such as text characters symbols images icons and other items are rendered and displayed on the display screen via the processor .

The communication interface may include a short range wireless communication subsystem not shown which provides a short range wireless communication interface. The short range wireless communication interface may be configured in accordance with one or more cellular telecommunication standards including any one of a Bluetooth standard an IEEE 802.11 standard an IEEE 802.15.3a standard also referred to as UltraWideband UWB a Z Wave standard a ZigBee standard or other suitable short range wireless communication standard. The communication interface may provide an infrared IR interface such as an Infrared Data Association IrDA interface to receive communication from a remote control unit not shown for controlling operation of the display device

The P2P streaming application configures the display device to display information received via the communication interface over a P2P wireless network such as a Wi Fi P2P wireless network on the display screen . The information may be processed in real time or near real time and may include video audio pictures text any combination of audio pictures and text or other media or multimedia. In some embodiments the P2P streaming application enables the display device to act as an external display device or monitor for a connected computing device such as the wireless device including cloning another display device such as the display screen of the wireless device or acting as a primary display device or monitor for the connected computing device. The P2P streaming application may additionally or alternatively receive audio from the wireless device as part of the real time or near real time information which may be reproduced using the speaker of the display device or an external speaker not shown coupled directly or indirectly to the display device

The P2P streaming application may run in the background concurrently with another application such as a TV application not shown . Accordingly the P2P streaming application may be triggered upon detecting a new P2P connection has been established with a device supporting P2P streaming such as the wireless device .

Reference is next made to which illustrates a mobile wireless device suitable for communicating with the display device in accordance with example embodiments of the present disclosure. Examples of the wireless device include but are not limited to a mobile phone smartphone or superphone tablet computer notebook computer also known as a laptop netbook or ultrabook computer depending on the device capabilities wireless organizer personal digital assistant PDA mobile gaming device special purpose digital camera or wearable computer such as a smartwatch or head mounted display HMD such as Google Glass from Google Inc.

The wireless device includes a rigid case not shown housing the electronic components of the wireless device . The electronic components of the wireless device are mounted on a printed circuit board not shown . The wireless device includes a processor which controls the overall operation of the wireless device . Communication functions including data and voice communication are performed through a communication interface . The communication interface receives messages from and sends messages via the communication network . The communication interface typically includes a WWAN interface for communication over cellular networks and a WLAN interface for communication over Wi Fi networks.

The processor interacts with other components including one or more input devices such as a keyboard and or touchscreen RAM ROM a graphics processing unit GPU a display screen via the GPU persistent non volatile memory which may be flash memory or any other suitable form of memory auxiliary I O subsystems one or more data port such as serial data port e.g. USB data port a camera such as video and or still camera a speaker a microphone a motion sensor which enables to processor to determine whether the wireless device is in motion and the nature of any sensed motion at any appropriate time an orientation sensor which enables the processor to determine which direction the wireless device is pointed at any appropriate time a global positioning system GPS device which enables the processor to determine GPS coordinates i.e. location of the wireless device at any appropriate time proximity sensor which enables the processor to determine the distance between the wireless device and an object at any appropriate time and other device subsystems generally designated as . The components of the wireless device are coupled via a communications bus not shown which provides a communication path between the various components.

The processor operates under stored program control and executes software modules stored in memory for example in the persistent memory . The persistent memory stores data such as user data user information and information regarding the components and technical capabilities of the wireless device . As illustrated in the software modules comprise operating system software and software applications . The software applications may include a P2P streaming application . The software modules or parts thereof may be temporarily loaded into volatile memory such as the RAM . The RAM is used for storing runtime data variables and other types of data or information. Although specific functions are described for various types of memory this is merely one example and a different assignment of functions to types of memory could be used.

The processor off loads processing of GPU drawing commands to the GPU . The GPU is coupled to the processor thereby receives GPU drawing commands from the processor and is also coupled to the display screen thereby outputting the result of the GPU drawing commands to the display screen . The GPU may either be a separate unit or may be combined with the processor into the same unit. For example the GPU may be implemented on an individual integrated circuit IC or may be implemented using a system on chip SoC architecture whereby both the GPU and the processor are implemented on the same IC. Additionally in some embodiment the processor performs the functions of the GPU in addition to other processing functions.

The display screen may be provided as part of a touchscreen which provides an input device . The display screen which together with a touch sensitive overlay not shown operably coupled to an electronic controller not shown comprise the touchscreen. User interaction with a GUI is performed through the input devices . Information such as text characters symbols images icons and other items are rendered and displayed on the display screen via the processor . The processor may interact with the orientation sensor to detect direction of gravitational forces or gravity induced reaction forces so as to determine for example the orientation of the wireless device in order to determine a screen orientation for the GUI.

The input devices may include a keyboard control buttons not shown such as a power toggle on off button volume buttons camera buttons general purpose or context specific buttons back or home buttons phone function buttons and or a navigation device. When the display screen is provided as part of a touchscreen the various buttons or controls may be provided by onscreen user interface elements displayed on the display screen instead of or in addition to physical interface components. The keyboard may be provided instead of or in addition to a touchscreen depending on the embodiment. At least some of the control buttons may be multi purpose buttons rather than special purpose or dedicated buttons.

The wireless device may include a memory card interface for receiving a removable memory card comprising persistent memory such as flash memory. A removable memory card can be inserted in or coupled to the memory card interface for storing and reading data by the processor including but not limited to still images and optionally video images. Other types of user data may be stored on the removable memory card . Other types of removable digital image storage media such as magnetic hard drives magnetic tape or optical disks may be used in addition to or instead of the removable memory card .

The communication interface may include a short range wireless communication subsystem not shown which provides a short range wireless communication interface. The short range wireless communication interface may be configured in accordance with one or more cellular telecommunication standards including any of a Bluetooth standard an IEEE 802.11 standard an IEEE 802.15.3a standard also referred to as UWB a Z Wave standard a ZigBee standard or other suitable short range wireless communication standard.

A received signal such as a text message an e mail message or web page download is processed by the communication subsystem and input to the processor . The processor processes the received signal for output to the display screen and or to the auxiliary I O subsystem . A subscriber may generate data items for example e mail messages which may be transmitted over the communication network through the communication subsystem for example.

The motion sensor may comprise an accelerometer such as a three axis accelerometer or other suitable motion sensor. The orientation sensor may comprise an accelerometer such as a three axis accelerometer electronic compass gyroscope or a combination thereof. Other suitable orientation sensors could be used instead of or in addition to the accelerometer electronic compass and gyroscope. The motion sensor and orientation sensor or parts thereof may be combined or shared for example within an integrated component. The processor or controller not shown of a three axis accelerometer can convert acceleration measurements into device orientations.

The proximity sensor may comprise a sensor that transmits a field or signals such as electromagnetic to detect the presence of nearby objects i.e. the sensor s target . The maximum distance that the proximity sensor can detect is may be predetermined or adjustable. The processor can utilize this information to determine the distance between the wireless device and the target object to be captured in an image.

The wireless device includes a battery as a power source which is typically one or more rechargeable batteries that may be charged for example through charging circuitry coupled to a battery interface such as the serial data port . The battery provides electrical power to at least some of the electrical circuitry in the wireless device and the battery interface provides a mechanical and electrical connection for the battery . The battery interface is coupled to a regulator not shown which provides power V to the circuitry of the wireless device .

The P2P streaming application configures the wireless device to initiate communication with an external wirelessly coupled display such as display device . The display device is coupled using an established wireless P2P communication session. Data representative of encoded display frames is sent to the display over the wireless P2P network via the communication interface . The display device then decodes and or processes the received encoded display frames to produces images on the screen of the display device . The images produced on the screen may include with any limitations any one of or any combination of video pictures text and computer graphics. The images produced may correspond to data files stored in the memory of the wireless device for example as persistent data or on a removable memory card or to data retrieved from the Internet by the wireless device in real time or near real time or may be generated by the processor or the GPU . The encoded display frames may be decoded and or processed at the display device in real time or near real time.

The P2P streaming application operates in any one of at least two modes without limitation as selected by a user via a user interface. The first mode is an extended screen mode whereby the images displayed on the screen of the display device are different from the images displayed on the screen of the wireless device . The second mode is a screen cloning mode whereby the images displayed on the screen are reproduced identically or almost identically on the screen . In both modes the P2P streaming application may additionally or alternatively transmit audio from the wireless device .

The P2P streaming application may run in the background concurrently with another application such as an Internet video streaming application e.g. YouTube . Accordingly the P2P streaming application may be triggered upon detecting launch of the video streaming application.

Prior to wireless transmission of display frames a P2P communication session is typically established between the wireless device and the display device . illustrates an example flow diagram of communication between the wireless device and the display device to establish a P2P communication session for wireless transmission of display frames between the two devices. The flow diagram of provides only a high level illustration of steps and messages that may be communicated to establish a session. Various other steps may be implemented and various other messages may be communicated. Additionally the order of the steps and messages is only illustrative and is non restrictive.

The wireless device and the display device may be configured to scan for other P2P available devices at . The wireless device and the display device may receive an instruction to scan from a user via input received via a user interface of the wireless device or the display device or may be programmed to perform a scan when a pre determined condition is detected. The pre determined condition may be the launch of a particular application such as a video application. The scanning procedure allows the devices to discover each other at and negotiate parameters for selection of a wireless channel such as a channel number.

After the devices have discovered each other the devices may enter into a group owner GO negotiation phase at . The GO negotiation allows for the selection of one of the devices acting as a GO to perform functions similar to that of an AP in a traditional Wi Fi network. The selection of the GO may be based on many factors including factors related to IT policy the available services interference with other wireless devices and the ability to access other networks. Typically when only one device of device is a battery constrained device the battery constrained device is selected as the GO. The GO may select and establish a Notice of Absence NoA schedule defining absence periods during which the GO may enter an inactive state such as a low power state in which wireless communication functions are suspended. The NoA schedule may be broadcast in a beacon frame by the GO at regular intervals. The NoA schedule defines a time allocation for each device to transmit over the wireless channel using four parameters 1 a time duration parameter specifying the length of each absence period 2 a time interval parameter specifying the time between consecutive absence periods 3 a start time specifying the starting time of the first absence period after the current beacon frame and 4 a count of the number of absence periods in the current schedule. At the end of each absence period the GO returns to an active state from the inactive state for example when changing from the low power state to a higher power state such as a normal operating state. The GO may adjust the NoA schedule at any time. In some embodiments a particular NoA schedule is chosen to minimize latency while satisfying throughput and power consumption requirements.

After the devices have discovered each other the devices may enter into a device capability negotiation phase at . The device capability negotiation may include exchanging messages providing details of supported encoding schemes and standards and or other device capability information.

During the device capability negotiation phase the devices identify a maximum average throughput which the devices can both support due to hardware limitations associated with the wireless device and or the display . The hardware limitations may directly affect the ability of the wireless device to process and output real time or near real time media and for the display to process and display the display frames without interruptions. The hardware limitations add latency to the system which may delay the display of one or more display frame on the screen of the display device . This may be considered to be unacceptable as each frame has a specific time at which it should be displayed to ensure continuity of the display frames.

A session may be established between the wireless device and the display device after completing the negotiation at . The devices may in some embodiments use a Real Time Transport Protocol RTP over Transmission Control Protocol TCP or User Datagram Protocol UDP as the communication protocol for sending and receiving data packets during the session. Accordingly the wireless device may prepare the display frames for transmission by encapsulating the display frames into data packets using the negotiated compression parameters and encapsulate the encoded data packets into a data frame as described with reference to .

Reference is now made to showing a functional block diagram of the GPU of the wireless device . In some embodiments the GPU is used in preparing the display frames for transmission. The GPU provides specialized processing of GPU drawing commands and is similar to GPU of the display device

When the processor of the wireless device executes an application such as the P2P streaming application the processor off loads processing of the GPU drawing commands to the GPU for enhanced efficiency. The GPU drawing commands are typically generated using a graphics API as previously described.

The processor places the GPU drawing command into a GPU drawing command buffer for processing by the GPU . The buffer is typically implemented using a First In First Out FIFO architecture. The first GPU command is processed by a GPU drawing command processor to generate pixel information. The pixel information defines a display frame suitable for display on the screen of the wireless device by defining pixels for display on the screen for a single moment in time. The pixel information is placed on a frame buffer which interfaces with the screen . The pixel information is updated regularly to ensure the image displayed on the screen is representative of the processing performed by the processor .

In some embodiments the frame buffer also interfaces with the P2P streaming application to allow for the screen cloning mode. For example the OpenGL API command glReadPixels returns pixel data from the screen buffer . Additionally the same command may return only the pixel data within a specified location on the screen .

When the GPU drawing commands correspond to a graphics API any GPU drawing commands generated by an application running on the wireless device can also be processed by the GPU of the display device . Accordingly the P2P streaming application may send GPU drawing commands from the wireless device to the display device . When the GPU drawing commands are received at the display device the GPU processes the commands and generates the pixel information that the GPU would generate. Accordingly the P2P streaming application may send display frames to the display device by either sending the pixel information as processed by the GPU at the wireless device or by sending the GPU drawing commands for processing by the GPU at the display device . As described in greater detail in the present disclosure the pixel information is typically compressed using a video encoding scheme prior to sending to the display device . Additionally for some display frames as described in greater detail in this disclosure the P2P streaming application may be limited from sending the pixel information to the display device using the GPU drawing commands.

When operating in the extended screen mode the P2P streaming application may send either the GPU drawing commands or the pixel information for example as compressed in accordance with the present disclosure to the display device . When the GPU drawing commands are sent to the display device only the GPU of the display device processes the GPU drawing commands as the images displayed on each of the screens and are different. Alternatively only the GPU of the device processes the GPU drawing commands however the pixel information produced by the GPU is not displayed on the screen of the device . Instead the pixel information is sent to the display device and displayed only on the screen . In another embodiment the pixel information produced by the GPU includes partial information suited for display on both the screen and the screen . Such partial information may represent a limited area of the screen and or . For example in a presentation application an additional menu can be displayed on the screen that is displayed on the screen .

When operating in the screen cloning mode the P2P streaming application may also send either the GPU drawing commands or the pixel information to the display device . When the GPU drawing commands are sent to the display device both the GPU and the GPU process the same GPU drawing commands. Thus the same image is displayed on the screen of the display device and the screen of the wireless device .

Alternatively only the GPU processes the GPU drawing commands and generates pixel information corresponding to the GPU drawing commands. The pixel information as generated by the GPU of the device is then sent to the display device for display on the screen and to the screen .

Accordingly in some embodiments a single display frame may be encoded either using pixel information or GPU drawing commands for sending to an external wirelessly coupled display such as display device . Additionally in some embodiments as will be described a single display frame may be encoded using a combination of both the pixel information and the GPU drawing commands. In other words a single display frame may be split into two or more portions and each portion defined using a different encoding scheme.

Many factors are considered when determining which encoding scheme to use for each display frame. The encoding scheme is selected such that the display device is operable to decode the encoded display frame for display on the screen on the basis of information exchanged in the device capability negotiation phase at of . Additionally the encoding scheme may also be selected on the basis of the data type of the information encoded in the display frame. GPU drawing commands provide relative high efficiency in encoding of programmatically generated graphics including without limitation user interfaces computer games and images created using vector graphics. However the GPU drawing commands cannot be used to represent encoded media including without limitation images and videos. Accordingly when display frames include portions of both programmatically generated graphics and encoded media each portion may be encoded in different encoding schemes.

Additionally in a stream of display frames successive frames may employ different encoding schemes. In one example a user utilizes a user interface menu to play a video and then enlarges the video to occupy the complete area of the screen. A first display frame showing the user interface menu is encoded using GPU drawing commands . A subsequent second display frame including both the user interface menu and the video is then encoded using a combination of both pixel information and GPU drawing commands . A subsequent third display frame including only the video is encoded using only pixel information .

The wireless device accordingly acts as a source of display frames for the display device whereas the display device acts as a sink for the display frames received from the wireless device . The wireless device may be referred to as a source and the display device may be referred to as a sink . Other types of devices may function as a sink . For example a speaker may receive audio content. Accordingly the display device may be replaced with the speaker in some embodiments. The P2P streaming application or other similar application may control various aspects of transmission of the display frames such as controlling which content to transmit.

As illustrated in the wireless device encodes and transmits a display frame to the display device . A stream of display frames may also be transmitted from the wireless device to the display device . Each display frame can visually represent any number of data files stored on the wireless devices or any programmatically generated graphics. Additionally each display frame has a deadline for displaying the display frame on the display device . When the deadline of most display frames is met then the transmission is said to occur in in real time or near real time. When the deadline of most display frames is not met then the user experience is typically negatively affected as the images displayed on the display device are delayed.

Each display frame may be encoded using any one of screencasting e.g. video compression scheme providing compression of the pixel information GPU processing using graphics resources and a set of GPU drawing commands and GPU processing with media streaming such as DLNA. At the device capability negotiation phase step of the wireless device and the display device exchange information to determine which display frame encoding schemes are supported by both devices. Only encoding schemes supported by both devices are later considered and used to transmit the display frames.

When a display frame is encoded using a video encoding scheme the processor sends pixel information to the encoder for compression and or encoding. The encoding and or compression is are generally based on a protocol suitable for sending to the display device over a wireless communication channel. The display device includes a decoder that is operable to decode the encoded frame for display on the screen of the display device . The encoder compresses the pixel information using a video encoding scheme to reduce the throughput to transmit the display frames in real time or near real time in accordance with the available bandwidth over the wireless communication channel.

Typically only the compressed pixel information is transmitted wirelessly. The pixel information as produced in the frame buffer is routinely used to send display frames to local screens i.e. screens coupled to the frame buffer via a wired communication bus e.g. on a PCB or through a cable . However sending pixel information as produced in the frame buffer over a wireless communication channel is taxing since the wireless communication channel may not provide sufficient throughput. Additionally a wireless communication channel is more error prone than a wired communication bus for example due to interference and reduced signal to noise ratio. Accordingly the pixel information is encoded using a video encoding scheme as will be described on the wireless device . The encoded pixel information i.e. using the video encoding scheme is then sent. The use of the video encoding scheme helps ensure the deadline associated with each display frame is satisfied. Additionally the video encoding scheme may be adapted in correspondence with the available wireless bandwidth. In other words the wireless device may monitor the wireless communication channel and if a reduced throughput is detected the video encoding scheme is adapted accordingly by utilizing more compression.

The compression scheme employed by the encoder may be in accordance with the H.264 video encoding standard. The pixel information is encoded into a plurality of Groups of Pictures GOPs where each GOP has a set of frames. The GOP structure allows for compression of display frames by using different types of video frames each providing different levels of compression. Each display frame is thus comprised of multiple video frames. Each GOP includes only one key frame providing a full representation of an image associated with the frame. Redundancy in the video stream is removed by including predicted frames in the GOP which only include difference information from reference frames such as the key frame. Accordingly for a given GOP the more predicted frames present the greater the compression. However using too many predicted frames may reduce the quality of the display frames as received at the display device as less scene information is included in the compressed stream. For example when a scene of video changes i.e. the entire background is changed a new key frame may be included.

When the H.264 video encoding standard is used information exchanged during the device capability negotiation phase at step of is used to determine the parameters of the compression. For example the devices may exchange information regarding supported profiles and or levels. Each profile defines a particular set of features to be supported and each profile is tailored to a specific class of applications. For example the Constrained Baseline Profile CBP defines a low cost set of features suitable for videoconferencing and mobile applications. In another example the High Profile HiP supports high definition television applications. Example features that are supported by HiP but not CBP include 10 bit sampling interlaced coding and quantization scaling matrices. Additionally each level may include definitions of maximum decoding speed maximum frame size maximum video bit rate for coding and maximum resolution. Accordingly to support a particular profile and level a particular set of hardware and software performance requirements may be needed.

A profile may be selected based on the type of media being transmitted. For example when transmitting a movie for display on the display the HiP may be selected. However the level may be selected based on hardware limitations associated with either of the devices . In one embodiment the level selected may be the level providing the maximum image and or video quality given the hardware performance constraints of the devices. In another embodiment the level selected may be the level providing the maximum battery life for the devices 

In one embodiment the hardware limitation is a buffer limitation of the display for storing received data from the wireless device or a decoder limitation of a decoder of display for decoding received data from the wireless device . In another embodiment the hardware limitation is a buffer limitation of a buffer of the wireless device for storing data for sending to the display or an encoder limitation of an encoder of the wireless device for encoding data for sending to the display . In another embodiment the decoder and or the buffer limitations may be dependent on the software implementation of the decoder and buffer respectively. For example if a more efficient algorithm is used by the decoder the hardware limitations associated with the decoder may be reduced.

The wireless transmission may be implemented using the Miracast standard a peer to peer wireless screencast standard formed via Wi Fi Direct connections. Miracast enables wireless delivery of compressed standard or high definition video to or from electronic devices. Typically both the sending and receiving devices should be Miracast certified. However Miracast adapters which plug into an expansion port such as an HDMI port are available which allow streaming to a non certified device. Miracast allows a portable device or computer to securely send up to 1080p HD video and 5.1 surround sound AAC and AC3 are optional codecs mandated codec is LPCM 16 bits 48 kHz 2 channels .

Within a GOP a first frame type of the different types the Intra Frame I Frame or I for short includes full image information and may be used as a reference frame. Accordingly the I Frame is the key frame and is the largest frame in terms of data size. Thus the I Frame requires the longest transmission time. A second frame type is the Predicted Frame P Frame or P for short and is based on the closest preceding I Frame or P Frame and may be used as a reference frame. A P Frame typically requires much less disk space than an I Frame of the same GOP and thus requires less transmission time than an I Frame.

Examples of various GOP structures and are represented in . GOP structures and GOP represent the same length of video in time as each other. However each structure has a different number of frames of each type. Structure represents one GOP having one I Frame and seven P Frames. Structure represents two GOPs each having one I Frame and three P Frames. Since the I Frames typically offer less compression than the P Frames the GOP structure may offer less compression than that of GOP structure . GOP structure requires two I Frames and six P Frames to represent the same length of video as GOP structure which instead requires one I Frame and seven P Frames.

Structure represents four GOPs having one I Frame and one P Frame each. However four GOPs are needed to represent the same length of video as that of GOP structures and . Accordingly the GOP structure offers the least compression of all the representations shown.

Each GOP may be characterized by a GOP size i.e. the number of frames in the GOP and by a GOP structure i.e. the number of each type of frame in the GOP and the arrangement thereof. Increasing the GOP size increases the compression of the stream of display frames reducing the time and bandwidth needed to transmit and process the stream of display frames because the time period between two successive key frames i.e. I Frames is increased. Thus less key frames are used. Adjusting the GOP structure may affect the compression of the stream of display frames as described previously thus affecting the time and bandwidth needed to transmit and process the stream of display frames. Accordingly the throughput of the stream of display frames outputted by the encoder may be directly correlated with both the GOP size and GOP structure amongst other factors.

The encoder may encapsulate one or more frames into packets formatted according to an MPEG transport stream MPEG TS format. An example structure of an MPEG TS formatted packet is shown in . Each MPEG TS packet includes header information and a number of Frames I or P Frames . The header information provides additional data relating to the Frames such as data for synchronization and for maintaining transmission integrity when the transmission signal is degraded. The MPEG TS packet may be of a fixed data size such as 188 Bytes. Accordingly the number of Frames encapsulated therein may depend on the type of frames encapsulated and their corresponding data sizes.

The encoder may output to the source buffer a series of MPEG TS packets similar to the MPEG TS formatted packet . The source buffer may be implemented as a First In First Out FIFO structure stored in the RAM of the wireless device . The source buffer may be allocated only a limited space in the RAM sufficient to only store a pre determined number of GOPs or Frames. The memory space allocated to the source buffer may be based on limitations associated with the sink buffer or other limitations.

The wireless device may also send display frames encoded using GPU drawing commands if the display device supports the graphical API used by the wireless device . This may be determined by exchanging a list of supported graphical APIs at the device capability negotiation phase of which may include without limitation any of DirectX and OpenGL . Additional information such as the size of the sink buffer available for receiving GPU drawing commands and the number of operations per second the GPU of the display device is capable of can be used by the wireless device to ensure that no buffer overrun events occur.

When a display frame is encoded using GPU drawing commands the processor sends GPU drawing commands to the source buffer . The processor bypasses the encoder as the encoding of the GPU drawing commands do not usually need to be changed for wireless transmission. Additional information needed by the GPU to complete processing of the GPU drawing commands may also be placed on the source buffer . The GPU may require data objects upon which to execute the GPU drawing commands associated with the display frame. In some embodiments the WLAN transceiver of the wireless device operating under control of the processor sends one or more data objects associated with the display frame to the WLAN transceiver . In one example a GPU drawing command to draw a graphic is sent to the GPU . Accordingly the graphic file representing the graphic is also sent to the GPU . However if at a later time a GPU drawing command to resize the graphic is sent to the GPU the same graphic file need does not need to be sent again. In some embodiments the data objects are sent to the encoder for encoding and or compression to reduce the data size of the data objects prior to the wireless transmission.

The data objects are encoded by the encoder based on the encoding scheme or schemes supported by both the encoder of the wireless device and the decoder of display device as determined in the device capability negotiation phase in . For image files this may include any one of without limitation JPEG GIF TIFF and PNG encoding. For video this may include without limitation H.264 and MPEG2 encoding. In some embodiments the transfer of the data objects is enabled by the use of the Digital Living Network Alliance DLNA standard which helps ensure interoperability between devices. When the encoded data objects are received at the display device they may be decoded by the decoder .

The wireless device may also send more or more display frames such that each display frame is encoded using GPU processing and media streaming using a video encoding scheme such as DLNA. Both the wireless device and the display device should support screencasting GPU processing and GPU processing and media streaming. The information regarding supported encoding schemes is exchanged during the device capability negotiation phase of . Specific limitations pertaining to the use of GPU processing and media streaming may also be exchanged including without limitation any limitations specific to the number of portions each display frame may be split into or the number of times per unit time the encoding scheme may be switched for a particular area. Any other limitation due to hardware or software on either the wireless device or the display device is also exchanged.

When a display frame is encoded using both a video encoding scheme and GPU drawing commands the processor sends GPU drawing commands to the source buffer and sends pixel information to the encoder for compression and or encoding as previously described . The GPU drawing commands represent the portion or portions of the display frame that are encoded using GPU drawing commands and the pixel information represent the portion or portions of the display frame that are encoded using the video encoding scheme. The processor may also send to the source buffer relative position and size information to identify the position and size of each portion in the display frame to allow the display device to recreate the correct display frame.

The processor of the wireless device in some embodiments provides a user interface to allow the user to rearrange the position of each of the portions of the display frame when displaying the display frame at the display device . Additionally some portions may not be displayed on the display device and some portions may be scaled in size differently at the display device . That is the content display on the wireless device and display device may differ somewhat in size aspect ratio or arrangement for example to accommodate differ screen shapes and sizes. In response to user input received via the user interface the processor controls the GPU and or the video encoder to generate an altered display frame for display at the display device

The source buffer outputs the display frames stored therein to the WLAN transceiver which includes transmitter and receiver capability for further processing and transmission. The WLAN transceiver may encapsulate several MPEG TS packets into one Wi Fi Direct WFD packet and may send a number of WFD packets in a real time stream. An example structure of a WFD packet is shown in . Other WFD packet structures are also possible. In the shown example the WFD packet includes 1 an IP header for example providing the IP address of the display device 2 a UDP header for example identifying the audio or video stream 3 an RTP header providing time stamp information to synchronize media playback sequence number information to indicate the position in WFD packet in relation to other WFD packets and other information and 4 payload information for example a number of MPEG TS packets as previously described. The WFD packet may have a fixed data size such as 1356 Bytes. The header information may occupy only 40 Bytes. Accordingly 1316 Bytes are allocated for pay load information. Accordingly one WFD packet may include up to 7 MPEG TS packets as described in the example packet structures and .

In the example shown in WFD packet utilizes a user datagram protocol UDP for transmission. The UDP transmission protocol provides minimal transmission overhead but does not offer reliability in transmission as no acknowledgement of receipt ACK of the packet is sent from the display device . The wireless device thus does not know if a packet is lost in transmission. This is acceptable when the display frames are encoded using the video encoding scheme as any display frames in the lost packets are simply ignored. However when the display frames include any GPU drawing commands reliable transmission is more important. The display device may not be able to reproduce the correct images for one display frame if the GPU drawing commands for the preceding display frame are not received. This is illustrated by the following example. If a first command is sent to draw a circle is not received a subsequent command to resize the circle would not be possible to complete. Accordingly a transmission protocol which includes acknowledgement of receipt may be preferred when GPU drawing commands are encapsulated in the WDP packet. Once such protocol is the transmission control protocol TCP .

An example protocol providing acknowledgement of receipt ACK of a packet is shown in . Such a protocol is particularly useful when a display frame is encoded completely or partially using GPU drawing commands as previously described. At the wireless device sends one or more GPU drawing commands encapsulated in a packet similar to the WFD packet . A string may be provided in the header of the packet indicating to the WLAN transceiver that the packet contains GPU drawing commands. Upon receiving the packet and determining that the packet contains GPU drawing commands the display device sends an ACK to the wireless device at . An ACK may be sent in response to receipt of the entire packet or receipt of a single GPU drawing command or receipt of a set of GPU drawing commands and or video frames corresponding to a single display frame depending on the protocol used. The ACK also provides an indication to the wireless device of the time the packet or the single GPU drawing command or set of the GPU drawing commands and or video frames corresponding to a single display frame is are received at the display device . By using a synchronized clock between the display device and the wireless device to indicate the time of receipt the wireless device is able to determine the latency in transmitting a display frame from the wireless device to the display device

Upon receipt of the packet from the wireless device the display device also starts processing of the GPU drawing command s using GPU . Additionally and optionally once processing is complete an indication of this is sent to the wireless device at . Such a processing complete message may optionally include an indication of either the time used by the GPU to complete processing of each GPU drawing command or an indication of the time used by the GPU to complete processing of all the GPU drawing commands in the packet or an indication of the time used by the GPU to complete processing and or decoding of the set of GPU drawing commands and or video frames corresponding to a display frame. The display device may compute and send the time information to the wireless device or alternatively the display device may send timestamp information to the wireless device thereby allowing the wireless device to compute the time. This time is indicative of the latency in processing the GPU drawing commands at the display device

The WLAN transceiver may transmit each WFD packet as soon as the packet is ready for transmission to be received at the WLAN transceiver of the display device . The WLAN transceiver may then extract the encapsulated MPEG TS packets and send them to the sink buffer to await processing by the decoder for pixel information or the GPU for GPU drawing commands . The display device then displays on the display screen the decoded display frame.

Reference is now made to which illustrates a flowchart of a method for wirelessly transmitting content from a source device such as the wireless device to a sink device such as the display device over a wireless transmission channel. The method may be implemented by the wireless device or other source device. The method may be carried out by software executed for example by a processor. Coding of software for carrying out such a method is within the scope of a person of ordinary skill in the art provided the present disclosure. The method may contain additional or fewer processes than shown and or described and may be performed in a different order. Computer readable code executable by the processor to perform the method may be stored in a computer readable medium such as a memory of a host device.

To provide display mirroring the source device may send the sink device screencast encoded data when the displayed content includes an image or video or device may send the sink device GPU encoded data when the displayed content is programmatically generated graphics. While arbitrating between screencast encoding and GPU encoding schemes may be adequate in cases of pure video and pure graphics transmission this approach has limits. Firstly modern user interfaces are typically not limited to one type of content and often display a blend of programmatically generated graphics and images and or video. Secondly the wireless transmission channel capacity for transfer between the source device and sink device can differ over time and should be regularly monitored for best performance. This has an impact on the optimal type of encoding scheme. Lastly the hardware of the sink device is often integrated into the infrastructure e.g. embedded into TVs or monitors or available as an HDMI stick and remains there for a longer time. At the same time source devices e.g. smartphones are rapidly evolving and the hardware capabilities of the source device can exceed the hardware capabilities of the sink device in many cases. This has a further impact on the optimal type of encoding scheme.

When a screencast format such as Miracast is used the source device performs a local overlay of graphics image and video information generates an encoded and typically also compressed version of the content of its display memory buffer which is output as video the Miracast format is a variant of H.264 and sent to the sink device. The sink device decodes and displays the video thereby providing an emulated version of the display the buffer content of the source device on the display of the sink device. When the display content on the source device includes encoded media objects the encoded media objects are transcoded decoding and subsequent encoding by the source device for example in accordance with Miracast to create an encoded media object in and display frames in the transcoded format are sent to the sink device. Screencast typically provides the highest quality when image and or video needs to be transmitted but may be limited by the available wireless transmission channel capacity transmission data rate . Screencast may be advantageous if the hardware of the sink device does not support efficient rendering of complex graphics or the data rate of the wireless transmission channel is lower than the rate for the multiplexed stream.

When GPU encoding is used all visual information displayed on the source device is transmitted to the sink device as compressed graphics. Graphics resources such as pixel maps and textures are indexed so that the graphics resources can be cached in memory on the sink device. A set of GPU drawing commands are used to modify the graphics resources cached on the sink device. The necessary graphics resources and GPU drawing commands are obtained from a GPU on the source device and sent to the sink device. GPU encoding is typically the highest quality path for programmatically generated graphics however GPU encoding does not work when portions of the display content on the source device include encoded media such as image or video information i.e. natural or native video rather than only simulated video . GPU encoding offloads the processing burden to render the display content to the GPU of the sink device. When the visual content is limited to programmatically generated graphics GPU encoding may be advantageous because it is very bandwidth efficient and exhibits very low latency since only the GPU drawing commands get transmitted over the wireless transmission channel once the graphics resources are cached on the sink device. However the hardware of the sink device could be overloaded if the programmatically generated graphics complexity is too high resulting in longer processing time for the graphics rendering and lower frame rates. Additionally with increased graphics performance of the source device local rendering on the source device may be superior in quality to remote rendering on the sink device due to the remote GPU on the sink device having less performance in which case screencast may be advantageous.

When a combination of GPU encoding with media streaming is used a multiplexed stream of programmatically generated graphics and image video information is sent to the sink device. The streams are kept separate and are overlayed by the sink device. The separation of the streams seeks to provide the highest overall quality. The image video information may comprise encoded media objects which are available to the sink device in encoded format e.g. JPEG image file an H.264 or MPEG2 MPEG4 video file . In such cases display frames for the encoded media objects may be transferred from the source device to the sink device without transcoding using media streaming for example in accordance with DLNA UPnP.

The method assumes that the source device such as the wireless device and the sink device such as the display device are both enabled for screencast GPU encoding decoding and GPU encoding decoding with media streaming. In other embodiments as a preliminary step the processor of the wireless device determines the technical capabilities of the sink device for receiving displaying and decoding display frames. The technical capabilities may include the codecs encoding and decoding schemes supported GPU support etc. With reference to step of this information is usually exchanged during the device capability negotiation phase. If the sink devices does not have decoders for encoded media objects in the display frames or does not support GPU encoding of the frames is performed using Miracast or other screencast encoding scheme in which the screen content of the source device is encoded as video and sent to the sink device. If the sink device does not support Miracast or other screencast encoding scheme the method ends.

At a P2P session is established between the source device the wireless device and the sink device the display device . This may be performed in accordance with the steps outlined in as previously described.

At the processor of the wireless device identifies one or more data types in or associated with the content being displayed on the display of the wireless device to be transmitted from the source device to the sink device. The content is typically examined on the basis of each display frame. The data types describe the visual information displayed by the wireless device . In some embodiments the data types are programmatically generated graphics and encoded media. Different data types may be used in other embodiments. In some embodiments the encoded media may include but is not limited to digital still image s and digital video and audio. Other encoded media may be included in other embodiments for example the encoded media may also include audio. In other embodiments the data types may be a list of encoded media object formats e.g. images video and audio . The list of encoded media object formats may be those supported i.e. having the necessary codecs by the source device and sink device.

The data types may be identified using one or more of a variety of approaches including the active application s on the source device i.e. wireless device during the P2P session. For example applications on the wireless device may have preset associations with one or more data types For example a video playback application may be associated with encoded media i.e. video whereas a video game may be associated with programmatically generated graphics.

At a transmission format for transmitting the display content of the wireless device is selected. The transmission format is selected based on the identified data type s of the display frame such as programmatically generated graphics PGG encoded media or a combination thereof. The transmission format is selected from screencasting e.g. Miracast GPU encoding e.g. OpenGL or DirectX or a combination of GPU encoding with media streaming. It is believe that each transmission format may provide a relatively higher efficiency when used in association with particular data types as described previously. The processor of the wireless device controls the encoding of display frames on the basis of the data type s associated with the display frames to ensure capability and efficiency. The efficiency in association with a particular data type may be defined by the amount of compression achieved i.e. lower bandwidth faster transmission rates lower processing times or by other means. As previously described GPU encoding provides relative high efficiency when the data type associated with the display frame is programmatically generated graphics. On the other hand screencasting provides relative high efficiency when the data type associated with the display frame is encoded media such as video or images.

At the content of the display frame is prepared using GPU encoding when the display frame includes only programmatically generated graphics. The display frame is already encoded using the GPU of the wireless device . The graphics resources and a set of one or more GPU drawing commands representing the display frame can be sent to by the processor on an as is basis or may be modified for the display device and re encoded before sending. For example the display frame may be modified for the technical capabilities of the display device . Example steps for encoding and preparing the display frame for transmission are described with reference to .

At the content of the display frame is prepared using screencasting when the display frame includes only encoded media such as video. The preparing comprises encoding the display frame as video for example in the Miracast format.

When more than one data type is associated with the display frame i.e. when the display frame includes programmatically generated graphics and encoded media GPU processing plus media streaming e.g. DLNA media streaming is used to provide the display content of the source device to the sink device. The source device uses graphics or GPU processing for sending the programmatically generated graphics e.g. via OpenGL and uses DLNA or similar techniques for sending encoded media objects e.g. audio images videos . GPU processing uses graphics resources and GPU display comments to send programmatically generated graphics similar to how programmatically generated graphics are displayed by the GPU on the source device. DLNA media transfer streaming works by sending the encoded media object already encoded in one of a number of source codecs . The encoded media objects are sent separately from the GPU display commands and graphics resources if any need to be sent . The sink device which has the necessary codecs decodes and reproduces the encoded media objects. This can be contrasted to screencasting using Miracast where one codec a variant of the H.264 codec has been standardized for both source device and sink device.

At the processor identifies the portions of the display frame associated with each data type. More than one data type may be associated with the display frame in many examples such as when the display frame is representative of a video being played in a browser window.

The identification in is performed at the application layer in some embodiments. Each running application outputs an application window for display at the display screen the display screen or both. Each application window is characterized by a boundary which may be characterized by horizontal and vertical pixel values in a two dimensional space representing the display frame. The application window may in its entirety define a portion of the display frame. However in some embodiments each application is split into multiple portions such as in the browser window example previously described. The video displayed within the boundary of the browser window is in itself identified as a different portion than the region of the browser window displaying the video. Thus one portion is identified as the rectangular area of the browser window excluding the rectangular region of the video.

In more complex scenarios more than two different portions may be identified. In one example a display frame represents multiple application windows displayed side by side in addition to user interface elements generated by the operating system . For example a browser window in which a video is being played a photo application window having user interface elements and in which an image is being displayed are displayed side by side. The region of the video and the region of the photo within the respective application windows may be associated with encoded media such as images and video. However the remaining region of the browser window and the user interface elements of the photo application and the user interface elements of the operating system may be associated with programmatically generated graphics. Thus several regions are identified and each region is associated with a particular data type.

At the processor prepares the content of each portion of the display frame based on the data type associated therewith namely programmatically generated graphics is prepared using GPU encoding as described above in connection with and encoded media is prepared using media streaming such as DLNA streaming. That is similar to and the portions of the display frame which includes programmatically generated graphics are prepared using GPU encoding while the portions of the display frame which includes encoded media are prepared using media streaming such as DLNA streaming.

Example steps for encoding and preparing the display frame for transmission are described with reference to . The processor also determines the relative position of the portions relative to one another. This position information may be included in the data packet in which the encoded display frame is sent from the source device to the sink device to allow the sink device to recompile the different portions in the correct location relative to each other. The position information may be characterized for example by horizontal and vertical pixel values in a two dimensional space representing the display frame.

The processor then controls the WLAN transceiver of the wireless device to encapsulate the display frame into a packet for sending to the WLAN transceiver of the display device as previously described. At the processor sends visual information representing the display frame in the transmission selected transmission format to the sink device. That is the prepared content is sent to the sink device i.e. the display device . In at least some embodiments a packet encapsulating the display frame is then sent to the display device . As previously described with reference to upon receiving the packet the display device may send an ACK to the wireless device and may additionally send a message indicating that processing of the display frame is complete. The message comprises information which includes an indication of the transmission latency and the processing latency at the display device which is indicative of the overall performance of the system and is useful in adapting the encoding scheme at the wireless device for encoding and sending subsequent display frames to the display device . Typically a stream of display frames is sent to the display device such that an average of 15 to 30 display frames are displayed each second until the wireless device stops transmitting display frames.

At the processor determines if a subsequent display frame is available. When no subsequent display frame is available the method ends and in at least some embodiments the P2P session established at is also ended.

When a subsequent display frame is available processing returns to in which the processor of the wireless device determines one or more data types in or associated with the content being displayed on the display of the wireless device to be transmitted from the source device to the sink device. The transmission format is then selected at as above. However when the display content is i programmatically generated graphics or ii a mix of programmatically generated graphics and encoded media the processor may at optionally evaluate the performance of the wireless transmission using predetermined performance criteria. In other embodiments the operations at may be omitted.

The predetermined performance criteria are evaluated when performance data is available for example after one or a number of display frames have been prepared and transmitted to the sink device i.e. display device . In some embodiments the evaluation may be performed before each subsequent display frame is processed. In other embodiments the evaluation may be performed at regular intervals such as for example the processing of a predetermined number of display frames since the last evaluation e.g. every 10 25 or 100 frames or a predetermined duration since the last evaluation e.g. every 1 2 or 5 seconds .

Alternatively the predetermined performance criteria may be evaluated based on historical performance data and therefore could be performed at any time. The historical performance data may be based on the data type s active application s during the P2P session the particular source device or particular type of source device the particular sink device or particular type of sink device or any combination thereof.

The predetermined performance criteria may be user or application defined or possibly a combination thereof and may vary between embodiments. In some embodiments the predetermined performance criteria include latency for data transfer and presentation on the remote screen and quality of image video reproduction. The time information received as shown in from the display device in response to receiving the display frame is useful in evaluating latency.

When the wireless transmission performance meets predetermined performance criteria operations proceed to or as described above.

When the wireless transmission performance does not meet predetermined performance criteria operations proceed to in which screencasting is used and optionally the transmission of subsequent display frames is adapted.

When a stream of display frames is sent each display frame received at the display device should be processed and displayed at the display device at a given deadline to ensure continuity of the stream. Otherwise the display frame may be skipped i.e. dropped . Dropped frames create a sluggish or choppy reproduction.

A first measure of latency is whether the processing time for graphics rendering on the sink device i.e. display device T is greater than the time interval between consecutive display frames T . The processor determines whether the processing time for graphics rendering on the sink device is greater than the time interval between consecutive display frames. When Tis greater than T the wireless device determines that the display device is unable to process the display frames in real time or near real time. This suggests that the hardware of the sink device may not be sufficient.

When the first measure of latency is not satisfied and processing other than screencasting is in use e.g. GPU processing or GPU DLNA processing and media streaming the processor of the wireless device changes the processing to screencasting. Though not shown in addition to changing the processing to screencasting for example when changing the processing to screencasting does not cause the first measure of latency to be satisfied the processor of the wireless device may reduce the frame rate of the screencasting. This could be an interactive process in that the frame rate may be reduced until Tis equal to or less than T. The screencasting may be adapted by varying the compression setting to achieve the desired number of frames per second by increasing the compression and reducing the quality.

When the first measure of latency is not satisfied and screencasting is in use the processor of the wireless device may reduce the frame rate of the screencasting not shown . This could be an interactive process in that the frame rate may be reduced until Tis equal to or less than T.

A second measure of latency is the overall latency associated with display of the display frame at the display device . The processor determines whether the overall latency is greater than maximum allowed latency value for the current use case. The overall latency in at least some embodiments is the sum of the processing time for graphics rendering on the sink device T and the time for sending the complete data of one frame T . Tis the maximum allowed latency between source and sink signal.

When the second measure of latency is not satisfied and processing other than screencasting is in use the processor of the wireless device changes the processing to screencasting. Though not shown in addition to changing the processing to screencasting for example when changing the processing to screencasting does not cause the first measure of latency to be satisfied the processor of the wireless device may reduce the frame rate of the screencasting. This could be an interactive process in that the frame rate may be reduced until T T is less than or equal to T.

When the second measure of latency is not satisfied and screencasting is in use the processor of the wireless device may reduce the frame rate of the screencasting not shown . This could be an interactive process in that the frame rate may be reduced until T T is less than or equal to T.

The maximum allowed overall latency may differ between applications and or data type in dependence on the use case. In specific use cases when latency has a high impact on overall performance the maximum allowed latency is set to a relatively low value. For example low latency is particularly desired when a user is running a video game application on the wireless device and using the screen of the display device . A low latency helps ensure a minimum delay from initiating a game control and seeing the effect of the game control on the screen . In such a use case the maximum allowed latency may be set to 50 milliseconds ms . In another use case a user is typing a document using a word processing application running of the wireless device and using the screen of the display device . A delay between hitting a key on the keyboard and viewing the associated character on the screen is undesirable. However a higher latency may be considered acceptable than in the video game use case. In such a use case the maximum allowed latency may be set to 100 ms. In another use case a user is playing a video on the wireless device and using the screen of the display device . A high latency is typically acceptable. In such a use case the maximum allowed latency may be set to 250 ms.

While specific values have been described above for the maximum allowed latency for particular use cases it is understood that such values are only exemplary. Additionally it is understood that the maximum allowed latency will vary greatly in dependence on the system being used. For example for a high end system the maximum allowed latency values may be lowered whereas for a low end system the maximum allowed latency values may be increased.

As noted above quality of image video reproduction may be one of the predetermined performance criteria. The processor may also in some embodiments monitor the quality associated with the encoded display frame at the wireless device and or the display device . The quality of the encoded display frame at the wireless device can be characterized relative to the original display frame for example in some embodiments the original display frame is the pixel information in the frame buffer .

The processing associated with processing the display frame as described in method may result in a compressed display frame. The effect of the processing is to reduce the data size of the display frame which may result in a loss of relevant information. The signal quality can be characterized by the processor using several techniques. In one embodiment the processor determines a peak signal to noise ratio PSNR associated with the processed display frame relative to the original display frame. This in effect compares the ideal sequence of high resolution images on the source device with the reproduced images on the sink device. In another embodiment the processor determines the spatial frequency of both the original display frame and processed display frame. A loss in the spatial frequency indicates a reduction is the image quality. In another embodiment the presence of block artifacts in the processed image compared to the original image is detected by the processor which may include artificial edges color and brightness changes.

Using similar techniques the processor at the display device can characterize the quality of the processed display frame at the display device relative to the original display frame or the processed display frame at the wireless device . The wireless device and display device exchange relevant information to enable the comparison of the display quality frame quality characteristics. For example the wireless device may send a value corresponding to the spatial frequency of the original display frame and processed display frame at the wireless device . After decoding the display frame at the display device the processor can also compare the spatial frequency of the processed display frame at the display device to both the original and the processed display frames at the wireless device . The display device may also send a value corresponding to the spatial frequency of the decoded display frame at the display device to the wireless device for comparison by the processor . An additional measure of quality may also be determined by the processors and when a stream of display frames is considered the rate at which display frames are processed and displayed on the respective display frames.

In some embodiments when a relative loss of quality between the display frame as decoded on the display device and the original display frame is determined to exist the processor examines the relative loss of quality to determine whether it is an acceptable level of loss. For each use case as previously described a different amount of loss of quality is permitted by defining a threshold level of accepted loss of quality.

If the loss of quality is below the predefined threshold the processor attempts to configure the processing of future display frames to mitigate the loss of quality. In one embodiment when processing other than screencasting is in use the processor of the wireless device changes the processing to screencasting. Though not shown in addition to changing the processing to screencasting for example when changing the processing to screencasting does not cause the first measure of latency to be satisfied the processor of the wireless device may reduce the frame rate of the screencasting. This could be an interactive process in that the frame rate may be reduced until the loss of quality is equal to or above the predefined threshold. The video encoding scheme may be adapted by varying the compression setting to achieve the desired number of frames per second by increasing the compression and reducing the quality.

When the loss of quality is below the predefined threshold and screencasting in use the processor of the wireless device may reduce the frame rate of the screencasting not shown . This could be an interactive process in that the frame rate may be reduced until the loss of quality is equal to or above the predefined threshold.

Alternatively in other embodiments the processing method may be selected using a cost function which assesses the power consumption of each processing scheme under the constraints that the above noted latency and quality performance criteria are met namely equality is above the minimum acceptable quality the latency is below the overall use case dependent maximum latency limit and the processing time is below the limit defined by the frame rate. The processing option which provides the minimum value for the cost function i.e. the most power efficient processing scheme is selected. If all of the constraints are not fulfilled the display frames are processed using method described. This embodiment assumes that the highest visual quality could be achieved even with lower performance hardware on the sink device if there is enough time. This embodiment may increase latency and so may be not be preferred when the programmatically generated graphics content is too complex. We also think that we have to take link usage data rate and power consumption into consideration since we want long operation time and also operation in congested channels with low data rate .

Power consumption is a useful consideration since the source device i.e. wireless device is typically battery powered and may enter a low power mode when the remaining battery life falls below a predefined threshold among other reasons. Rather than determining a power consumption of each processing scheme in real time or near real time each of the processing schemes may have a power consumption rating based on power consumption history data stored in memory from processing similar display frames. Display frames may be considered to be similar if the same processing type and characteristics are used. For example in the case of screencasting the selected GOP structure and the selected profile may be used to compare the similarity of two display frames. In the case of the GPU processing the number of graphics resources and the number of GPU commands to represent a display frame may be considered along with the power consumption rating since some GPU drawing commands may require more processing power to complete. Similar considerations can also be made when the display frame is processing using GPU DLNA processing.

Thus described in the present disclosure are methods and devices for wirelessly transmitting content from a source device to a sink device such as a real time stream of display frames. Each display frame is processing using screencasting GPU processing or GPU DLNA processing based on the data type s associated with the display frame. Additionally latency image video quality and or power consumption associated with the wireless transmission may be used to adapt the processing of the display frames.

The above described embodiments of the present disclosure are intended to be examples only. Those of skill in the art may affect alterations modifications and variations to the particular embodiments without departing from the scope of the application. Although the description relates to specific examples for illustration where the WLAN is an IEEE 802.11 based network for example different environments may be applicable as well. As a few other examples the wireless networking may be based on a WiMAX network i.e. IEEE 802.16 or an UWB network i.e. IEEE 802.15 . The teachings of the present disclosure are intended to cover and embrace all suitable changes in technology.

The steps and or operations in the flowcharts and drawings described herein are for purposes of example only. There may be many variations to these steps and or operations without departing from the teachings of the present disclosure. For instance the steps may be performed in a differing order or steps may be added deleted or modified.

While the present disclosure is described at least in part in terms of methods a person of ordinary skill in the art will understand that the present disclosure is also directed to the various components for performing at least some of the aspects and features of the described methods be it by way of hardware components software or any combination of the two or in any other manner. Moreover the present disclosure is also directed to a pre recorded storage device or other similar computer readable medium including program instructions stored thereon for performing the methods described herein.

The present disclosure may be embodied in other specific forms without departing from the subject matter of the claims. The described example embodiments are to be considered in all respects as being only illustrative and not restrictive. The present disclosure intends to cover and embrace all suitable changes in technology. The scope of the present disclosure is therefore described by the appended claims rather than by the foregoing description. The scope of the claims should not be limited by the embodiments set forth in the examples but should be given the broadest interpretation consistent with the description as a whole.

