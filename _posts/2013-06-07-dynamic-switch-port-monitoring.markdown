---

title: Dynamic switch port monitoring
abstract: Disclosed are methods and system to dynamically monitor a number of switching ports of a networking device. In one embodiment, a system is disclosed to monitor network traffic comprising a switch port monitoring device comprising a real-time processor, a packet data processor, a packet queue and a storage device. The system also comprises one or more switches coupled to the switch port monitoring device, where at least one of the switches comprising a switch processor, a switch fabric, one or more ingress/egress ports coupled to the switch fabric, and one or more uplink ports coupling the switch packet to the packet queue of the switch port monitoring device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08614946&OS=08614946&RS=08614946
owner: Sideband Networks Inc.
number: 08614946
owner_city: Sunnyvale
owner_country: US
publication_date: 20130607
---
This application incorporates by reference U.S. Pat. No. 8 441 961 titled METADATA DRIVEN SWITCH NETWORK CONTROL filed on Dec. 24 2012 U.S. Pat. No. 8 448 238 titled NETWORK SECURITY AS A SERVICE USING VIRTUAL SECURE CHANNELS filed on Jan. 23 2013 U.S. Pat. No. 8 438 631 titled SECURITY ENCLAVE DEVICE TO EXTEND A VIRTUAL SECURE PROCESSING ENVIRONMENT TO A CLIENT DEVICE filed on Jan. 24 2013 and U.S. patent application Ser. No. 13 861 365 titled DYNAMIC ALLOCATION OF RESOURCES AND DISTRIBUTION OF CONFIGURATIONS OVER A NETWORK filed on Apr. 11 2013 in their entirety.

This disclosure relates generally to networking technology in one example embodiment to methods apparatus and systems to dynamically monitor a number of switching ports of a networking device.

A data intensive organization in today s information rich technological environment may transfer upwards of several TBs of traffic per second over its network. In order to ward against forwarding potentially harmful traffic network device manufacturers have developed certain tools to monitor the ingress and egress of data packets making their way through such devices. Common tools include user configurable port tapping or monitoring. Oftentimes each active network port is mirrored to one tap port. While such a 1 1 mirroring relationship may be easier to maintain when the flow of network traffic is low the inefficiency of this particular system is quickly exposed when the flow of network traffic increases. In the case where the amount of ingress traffic at the active ports exceeds the bandwidth of the monitoring ports one or more data packets may be dropped before they are examined. This is especially troublesome if a threat agent for example a computer virus can only be detected if a protracted series of packets must all be present for the network device to realize that an attack is in progress. In such a case the inadvertent dropping of one or two critical packets may leave the network vulnerable.

Moreover even if the amount of traffic arriving at the active ports does not exceed the bandwidth of the monitoring ports the deployment of a static 1 1 minoring scheme may be inefficient as no monitoring or tap ports would be operating at near line rate. In addition most network monitoring solutions do not base their monitoring decisions on historical network traffic data or account for future spikes in network traffic.

Therefore a networking monitoring solution is needed that can handle the fluctuations of today s unpredictable network traffic by utilizing both historical and real time knowledge of ingress network traffic patterns and the capacity constraints of all monitoring tools available.

Disclosed are methods apparatus and systems to dynamically monitor a number of switching ports of a networking device. As disclosed herein a machine implemented method to dynamically monitor network traffic is disclosed comprising queuing one or more packets received from one or more uplink ports of a switch fabric in a packet queue querying by a real time processor the packet queue for a queuing status of the packet queue and querying the monitoring load of a packet data processor analyzing the one or more packets received from the packet queue determining by the real time processor an objective specific model that optimizes the number of packets forwarded to the packet queue or the rate of packet data forwarded to the packet queue as a result of the queries and commanding a switch processor and the switch fabric through a control engine of the real time processor to deploy the objective specific model.

In this aspect the method may further comprise commanding through the control engine of the real time processor the switch processor to tag a packet flow if one or more packets in the packet flow have been analyzed by the packet data processor and commanding through the control engine of the real time processor the switch fabric to exclude the packet flow or the one or more packets of the packet flow tagged by the switch processor from being forwarded to the packet queue. The method may also comprise storing the objective specific model in a storage device communicatively coupled to the real time processor as a cached objective specific model. In certain instances the cached objective specific model may be deployed to optimize the number of packets forwarded to the packet queue or the rate of packet data forwarded to the packet queue.

In this aspect the switch fabric may comprise one switch fabric or one switch fabric coupled to another switch fabric. Additionally the queuing status of the packet queue may comprise data relating to the number of packets in the packet queue and or the rate of packet data added to the packet queue. The method may further comprise querying the monitoring load of the packet data processor by receiving from the packet data processor feedback data comprising the bits per second analyzed by the packet data processor and or the packets per second analyzed by the packet data processor.

In this aspect commanding the switch processor of the switch fabric to deploy the objective specific model may comprise updating one or more entries in a switch forwarding table. Moreover the objective specific model deployed may comprise a networking model that forwards packets from two or more ingress ports of the switch fabric to one uplink port. Finally the one or more packets received from the one or more uplink ports of the switch fabric may be copies of packets received at one or more ingress ports of the switch fabric.

Another aspect of the disclosure may include a system to dynamically monitor network traffic. In this aspect the system comprises a switch port monitoring device comprising a real time processor a packet data processor a packet queue and a storage device one or more switches coupled to the switch port monitoring device with at least one of the aforementioned switches comprising a switch processor a switch fabric one or more ingress egress ports coupled to the switch fabric and one or more uplink ports coupling the switch fabric to the packet queue of the switch port monitoring device and a plurality of programs stored in a plurality of memory devices and executable by at least one of the aforementioned processors.

In this aspect such programs may comprise instructions to implement the methods described heretofore.

The methods and systems disclosed herein may be implemented in any means for achieving various aspects. Other features will be apparent from the accompanying drawings and from the detailed description that follows.

Other features of the present embodiments will be apparent from the accompanying drawings and from the detailed description that follows.

Disclosed are methods apparatus and systems to dynamically monitor network traffic in a fast and efficient manner. Although the present embodiments have been described with reference to specific example embodiments it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the various embodiments. It should be understood by one of ordinary skill in the art that the terms application s program s software software code sub program s module s and block s are industry terms that refer to computing instructions stored in memory and executable by one or more processors. In addition the components shown in the figures their connections couples and relationships and their functions are meant to be exemplary only and are not meant to limit the embodiments described herein.

In one embodiment a machine implemented method is disclosed to dynamically monitor network traffic in a fast and efficient manner. In this embodiment the method comprises queuing one or more packets received from one or more uplink ports A N of a switch fabric in a packet queue querying by a real time processor the packet queue for a queuing status of the packet queue and the monitoring load of a packet data processor configured to analyze the one or more packets received from the packet queue determining by the real time processor an objective specific model that optimizes at least one of the number of packets forwarded to the packet queue and the rate of packet data forwarded to the packet queue as a result of the queries and commanding through a control engine of the real time processor a switch processor and the switch fabric to deploy the objective specific model .

In one or more embodiments the method may further comprise commanding through the control engine of the real time processor the switch processor to tag a packet flow if one or more packets in the packet flow have been analyzed by the packet data processor and commanding through the control engine of the real time processor the switch fabric to exclude at least one of the packet flow and the one or more packets of the packet flow tagged by the switch processor from being forwarded to the packet queue .

In one or more embodiments the method may further comprise storing the objective specific model in a storage device communicatively coupled to the real time processor as a cached objective specific model. In this or other embodiments the method may further comprise deploying the cached objective specific model to optimize at least one of the number of packets forwarded to the packet queue and the rate of packet data forwarded to the packet queue .

In this or other embodiments the switch fabric may be one switch fabric of a single switch for example switch A or may be comprised of one switch fabric coupled to another switch fabric of another switch for example switch B . In addition the queuing status of the packet queue may comprise data relating to the number of packets in the packet queue and the rate of packet data added to the packet queue . Moreover the method may comprise querying the monitoring load of the packet data processor by receiving from the packet data processor feedback data comprising at least one of the bits per second analyzed by the packet data processor and the packets per second analyzed by the packet data processor .

In one or more embodiments the method may further comprise commanding the switch processor and the switch fabric to deploy the objective specific model by updating one or more entries in a forwarding table . In this or other embodiments the objective specific model deployed may comprise a networking model that forwards packets from at least two ingress ports for example ingress egress ports A and B of the switch fabric to one uplink port for example uplink port A . Finally the one or more packets received from the one or more uplink ports A N of the switch fabric may be copies of the packets received at one or more ingress ports for example any of the indicated ingress egress ports A N of the switch fabric .

Reference is now made to which is a schematic diagram illustrating an example system that may be used to implement the methods disclosed herein. In one embodiment the system comprises a switch port monitoring device comprising a real time processor a non real time processor a storage device communicatively coupled to the real time processor and the non real time processor a packet data processor and a packet queue . As shown in the example embodiment in the packet queue may be coupled to a switch fabric of a networking device or a network switch device for example switch A through one or more uplink ports A N. In one embodiment the one or more uplink ports A N may be Ethernet ports capable of transmitting multiple gigabits of network traffic per second e.g. 10 Gigabits per second Gbps XAUI ports or lanes of such Ethernet ports. In another embodiment the uplink ports A N may comprise SGMI ports multiplexed with XAUI ports. In one or more embodiments the uplink ports A N may be designed according to applicable IEEE networking standards for example IEEE 1588v2 on precision timing or IEEE 802.1Qbb on priority flow control . In this or another embodiment the uplink ports A N may be coupled to one another the packet queue and the switch fabric through techniques and resources defined in IEEE 802.3 on 10 Gigabit Media Independent Interfaces XGMII .

In one or more embodiments each of the real time processor the packet data processor and the non real time processor may comprise of one or more processor cores operating at 1.0 to 1.2 Gigahertz GHz . In one embodiment each such processor core may be designed according to a 64 bit architecture and may comprise L1 L2 and or L3 caching capabilities. In particular each core may comprise up to 32 kilobytes KB of L1 cache 256 KB of L2 cache and 18 MB of L3 cache. In one embodiment each of the cores may comprise a memory that may be implemented as either volatile memory for example dynamic random access memory DRAM or static random access memory SRAM or non volatile memory for example non volatile random access memory . In a further embodiment the cores may share one or more memory devices. In this or another embodiment the memory in such cores may comprise any form of computer readable medium configured to store one or more computer programs in the form of instructions executable by the aforementioned processors. In this or another embodiment the real time processor the packet data processor the packet queue and the non real time processor may be interconnected by high speed buses.

In one or more embodiments the packet queue may be an application specific integrated circuit ASIC comprising one or more processor cores and on chip memory for example SRAM DRAM etc. coupled to such processor cores. In this or another embodiment the packet queue may be C programmable and may provide checksum and redundancy check functions for packet headers and payloads. In addition the packet queue may provide load balancing and buffer management functionalities. In a further embodiment the packet queue may comprise one or more processing cores of the switch port monitoring device and may share memory with the other processors embedded in the switch port monitoring device . In yet a further embodiment the packet queue may be a packet queue program stored in a memory or storage device of the switch port monitoring device and executable by one or more processors of the switch port monitoring device .

In one embodiment the entire switch port monitoring device may be implemented as an ASIC comprising multiple processor cores storage devices and memory devices. In another embodiment the switch port monitoring device may be or may be integrated into networking device a switch router etc. . In yet another embodiment the switch port monitoring device may be or may be integrated into a data processing device e.g. laptop desktop workstation server etc. .

As shown in the example embodiment illustrated in the switch port monitoring device may be coupled to the switch A through a high speed expansion bus. In one embodiment the switch port monitoring device may be coupled to the switch A through a Peripheral Component Interconnect Express PCIe interface. The PCIe interface used may be a version 2.0 3.0 or 4.0 interface. In one or more embodiments the PCIe interface may couple a motherboard comprising the real time processor to another motherboard comprising the switch processor . As indicated in the example embodiment shown in the switch A may be one switch coupled or communicatively coupled to a network of switches comprising switches B N. In other embodiments not shown in the switch port monitoring device may be coupled to more than one switch for example switch A and switch B through PCIe interfaces and uplink ports.

In one embodiment the switch A may be an Open Systems Interconnection OSI layer L2 or layer L3 networking device. In another embodiment the switch A may be a metadata driven switch. In yet another embodiment the switch A may be a foreign switch as the term is defined in U.S. Pat. No. 8 448 238.

In one or more embodiments the switch processor may be a host processor coupled to the switch fabric of the switch A. In this or another embodiment the switch processor may be any processor configured to execute floating point instructions. In the case where the switch A is a metadata driven switch the switch processor A may be a server grade processor. It is understood by one of ordinary skill in the art that the switch processor depicted in may be implemented as one or more processor cores of an ASIC embedded in the switch A.

As shown in the example embodiment depicted in the switch processor the switch fabric and the forwarding table may be communicatively coupled via high speed buses. In one or more embodiments the switch fabric may be coupled to one or more ingress egress ports A N. In this or another embodiment the one or more ingress egress ports A N may be communicatively coupled to one or more data processing devices computing devices or networking devices through a network . In one embodiment the network may be a wide area network WAN such as the Internet. In another embodiment the network may be a local area network LAN such as an enterprise s intranet. Also in one embodiment the ingress egress ports A N may be wired Ethernet ports with a minimum line rate of multiple Gbps. In another embodiment the ingress egress ports A N may be wireless Ethernet ports. As shown in the example embodiment depicted in network traffic data or network packets represented by the packets may enter the switch fabric at one of the ingress egress ports A N and may also exit the switch fabric at one of the ingress egress ports A N. In one or more embodiments the packets may be network packets comprising one or more headers and payloads.

In one or more embodiments the switch fabric may refer to a switch silicon or an ASIC configured to route or forward network traffic. In this or other embodiments the switch silicon may be any switch ASIC with multiple ports for example 64 ports and the bandwidth to switch multiple Gigabits of traffic per second for example 640 Gbps . In one or more embodiments the forwarding table may be a forwarding information base FIB a routing information base RIB or routing table or a media access control MAC forwarding table. The forwarding table may be stored in a memory of the switch A where the memory is communicatively coupled to one or more processors of the switch A for example the switch processor . In one embodiment the forwarding table may be stored in a ternary content addressable memory T CAM of the switch A.

Although the present embodiments have been described with reference to a single switch switch A it will be evident that various modifications and changes may be made to these embodiments and references to the switch A may encompass multiple switches for example a switch network comprising multiple switches where switch A is part of the switch network . In one embodiment the switch fabric may refer to one switch fabric coupled to another switch fabric for example the switch fabric of switch A coupled to the switch fabric of switch B .

Reference is made to which is a block diagram of the switch port monitoring device according to one or more embodiments. As illustrated in the example embodiment in the packet queue may comprise a memory that stores instructions for a packet manager application. In addition the packet data processor may comprise a memory that stores instructions for one or more applications and instructions for an application recognition engine . Furthermore the real time processor may comprise a memory that stores instructions for a feedback engine and a control engine . Moreover the non real time processor may comprise a memory that stores instructions for a dashboard engine .

In one embodiment a plurality of programs may be stored in the plurality of memory devices described herein and shown in which may then be executed by the plurality of processors described herein and shown in . In one example embodiment the programs may comprise instructions for the packet manager of the packet queue to queue one or more packets received from the one or more uplink ports A N of the switch fabric . In this or other embodiments the one or more packets received from the one or more uplink ports A N of the switch fabric may be copies of the packets received at one or more ingress ports for example any of the indicated ingress egress ports A N of the switch fabric .

The packets residing in the packet queue may be taken off the packet queue and inspected by one or more applications of the packet data processor . In one embodiment the one or more applications may comprise of deep packet inspection applications. In another embodiment the application recognition engine may direct packets to specific applications of the packet data processor based on information contained in the header of the packet. In a further embodiment each of the applications may maintain their own application specific packet queues and the packets may be delivered to such an application specific packet queue before being delivered to the applications .

Moreover the feedback engine of the real time processor may query the packet manager of the packet queue for a queuing status of the packet queue . In one embodiment the queuing status of the packet queue may comprise data relating to the number of packets currently in the packet queue and the rate of packet data added to the packet queue from the one or more uplink ports A N. In addition the feedback engine may also query the monitoring or inspection load of the packet data processor by querying one or more applications or applications specific packet queues of the packet data processor . Furthermore the feedback engine may query the monitoring load of the packet data processor by receiving feedback data from the packet data processor comprising the bits per second analyzed by the packet data processor or the packets per second analyzed by the packet data processor .

In one or more embodiments if the feedback engine of the real time processor receives feedback data indicating that the maximum monitoring or inspection bandwidth of the packet data processor has been reached or is close to being reached the real time processor may determine an objective specific model that optimizes at least one of the number of packets forwarded to the packet queue and the rate of packet data forwarded to the packet queue . In one example embodiment the real time processor may determine an objective specific model that forwards packets from at least two ingress ports for example ingress egress port A and ingress egress port B of the switch fabric to one uplink port for example uplink port A . It should be apparent to one of ordinary skill in the art of networking that such objective specific models may comprise forwarding schemes that include any combination of ingress ports and uplink ports.

In addition the real time processor may store the objective specific model in a storage device communicatively coupled to the real time processor as a cached objective specific model. In one embodiment an objective specific model may be stored in the storage device as a cached objective specific model even if not deployed by the control engine of the real time processor . Furthermore the control engine of the real time processor may command the switch processor and the switch fabric of the switch A to deploy the objective specific model . In addition the control engine may also command the switch processor and the switch fabric to deploy a cached objective specific model if the situation warrants. In one or more embodiments the control engine of the real time processor may command the switch processor and the switch fabric to deploy the objective specific model by updating one or more entries in the forwarding table of the switch A. In one embodiment such entries in the forwarding table may be updated continuously and at a fast pace.

In a further embodiment the control engine of the real time processor may command the switch processor to tag a packet flow if one or more packets in the packet flow have been analyzed by the packet data processor . Once a packet has been tagged by the switch processor the switch processor may instruct the real time processor to store the tagged packet in the storage device . In one or more embodiments the tagged packets may be an actual copy of the packet tagged by the switch processor or data concerning the tagged packet so that the switch processor the switch fabric the packet queue the real time processor and or the packet data processor can more easily identify either the packet or the packet flow comprising the tagged packet once again.

In one or more embodiments the control engine of the real time processor may command the switch processor and the switch fabric to exclude any packets tagged by the switch processor or any packet flows containing a packet previously tagged by the switch processor from being forwarded to the packet queue . By storing such tagged packets in the storage and or memory devices of the switch port monitoring device the switch port monitoring device can reduce the amount of network traffic in the form of packets that will need to be examined by the switch port monitoring device . By continuously adding to the cache of tagged packets and by continuously tagging new packets inspected by the packet data processor at a fast pace the switch port monitoring device may be able to gradually reduce the amount of network traffic that will need to be inspected or examined to only the delta traffic i.e. only the incoming traffic or packets that have not been previously examined . By doing so the switch port monitoring device may ensure full scanning of all network traffic flowing through the switch or switches coupled to the switch port monitoring device .

As indicated in the example embodiment in the storage device may store one or more objective specific models and packets tagged by the switch processor shown in as tagged packets . In one or more embodiments the objective specific models stored in the storage device may be referred to as cached objective specific models. In one embodiment the storage device may be comprised of a hard disk device an optical disk device a flash memory and or other similar solid state memory device. In another embodiment the storage device may be an array of the devices in a computer readable medium. In other embodiments not shown in the objective specific models and the tagged packets stored in the storage device may be retrieved and stored temporarily in one or more of the memory devices mentioned heretofore for easy access by the one or more processors depicted in .

In a further embodiment not shown in the figures the objective specific models and tagged packets may be stored in a storage device that is external to the switch port monitoring device . The storage device external to the switch port monitoring device may be a physical device within the local network or a cloud based device. In one embodiment the storage device may be comprised of at least one of a hard disk device an optical disk device a tape device a flash memory and or other similar solid state memory device. In another embodiment the external storage device may be an array of the devices in a computer readable medium.

In one or more embodiments the real time processor may be configured to generate the objective specific model . In one example embodiment the objective specific model may be metadata models that simulate port configurations including but not limited to ingress egress ports A N and uplink ports A N of the switch A. Such metadata models may be constructed of metadata commands or instructions that simulate possible switch port configurations.

In another embodiment the objective specific models may comprise of switch port configurations that take into account historical and real time information related to the status of the network. Such status information may include data concerning current and historical network traffic flows data concerning users applications and or devices and or data concerning the monitoring load or capacity of the packet data processor . To obtain such information the real time processor may query a network monitor such as Nagios or HP OpenView for information regarding the status of the network. In addition to Nagios or HP OpenView it may be understood that any software for IT infrastructure monitoring known by those skilled in the art may be used to monitor the network for changes. Moreover the real time processor may also retrieve cached objective specific models stored in the storage device to construct new objective specific models.

In a further embodiment the objective specific models may be the same type of objective models as those described in U.S. patent application Ser. No. 13 861 365. In the broadest sense of the term an objective specific model may in one or more embodiments be any computer generated model that achieves a specific networking objective.

Furthermore an objective specific model may be determined based on the resources available on a network. For example if a new switch is added to a switch network and the switch fabric comprises switch fabrics from all such switches the real time processor may take into account the additional incoming traffic from the ingress egress ports of the new switch into its determination. The objective specific models may also be displayed as a single object to a network administrator using a dashboard engine such as the dashboard engine . The objective specific model may be presented to the network administrator through an interface of the dashboard for example a HTML page or an interface modal window.

One simplified example of an objective specific model albeit on a much smaller scale may be the port configuration tables shown in .

Reference is now made to which are simplified port configuration tables that represent calculations made by the real time processor when arriving at an objective specific model that optimizes the number of packets forwarded to the packet queue and or the rate of packet data forwarded to the packet queue in one or more embodiments. In one or more embodiments the tables illustrated in may represent simplified objective specific models . Tables and represent port configurations of a fictional switch and switch port monitoring device system. In such a system the switch comprises nine ingress egress ports for example ingress egress ports A I and four uplink ports for example uplink ports A N . In all such tables the maximum uplink rate is the maximum uplink bandwidth of the uplink port s . In the example embodiment shown in all four uplink ports have the same uplink bandwidth for example 10 Gbps . However in one or more other embodiments each of the uplink ports may have a different maximum uplink bandwidth or line rate.

As indicated in the example embodiment depicted in table represents the traffic rates of all nine ingress egress ports as a percentage of the uniform line rate of the uplink ports for example 10 Gbps . As indicated in table of uplink port C may be passing traffic at a rate of 91 its uplink line rate. In this example a spike in traffic through one of the ingress egress ports may cause the real time processor to instruct the packet queue to drop all packets coming in from ingress egress port H as indicated in table since including such traffic would put the traffic rate of the uplink port at above its line rate. In one or embodiments the uplink port may be instructed to drop all or a portion of the data packets coming from its least active ingress egress port. The real time processor may be instructing the packet queue to drop packets coming in from certain ingress ports at a high rate of repetition.

As indicated in the example embodiment depicted in table represents a different set of traffic rates for the nine ingress egress ports as a percentage of the uniform uplink line rate. As shown in table the real time processor may instruct the switch fabric via the switch processor to distribute the traffic rates evenly amongst all of the uplink ports so as to prevent any one uplink port from being over utilized or under utilized at any one time. In addition the real time processor may instruct the switch fabric to distribute such traffic amongst the various uplink ports at a high rate of repetition.

In one or more embodiments port configurations or forwarding instructions may also be deployed to other switch devise on a switch network through a variety of interfaces such as application programming interfaces APIs file transfer protocols FTPs or command line interfaces CLIs as is known by those skilled in the art.

Reference is now made to which is a simplified process flow diagram illustrating a method to dynamically monitor one or more ingress egress ports A N of a networking device according to one or more embodiments. Specifically operation may involve queuing the one or more packets received from the one or more uplink ports A N of the switch fabric in the packet queue . Operation may involve querying by the real time processor the packet queue and querying the monitoring load of the packet data processor responsible for analyzing the one or more packets received from the packet queue . Operation may involve determining by the real time processor an objective specific model that optimizes the number of packets forwarded to the packet queue and or the rate of packet data forwarded to the packet queue as a result of the queries. Finally operation may involve commanding through the control engine of the real time processor the switch processor and the switch fabric to deploy the objective specific model .

Reference is now made to which is a simplified process flow diagram illustrating an additional method to dynamically monitor one or more switching ports of a networking device for example switch A according to one or more embodiments. Specifically operation may involve queuing the one or more packets received from the one or more uplink ports A N of the switch fabric in the packet queue . Operation may involve querying by the real time processor the packet queue and querying the monitoring load of the packet data processor responsible for analyzing the one or more packets received from the packet queue . Operation may involve determining by the real time processor an objective specific model that optimizes the number of packets forwarded to the packet queue and or the rate of packet data forwarded to the packet queue as a result of the queries. Operation may involve storing the objective specific model in the storage device communicatively coupled to the real time processor as a cached objective specific model. Finally operation may involve commanding through the control engine of the real time processor the switch processor and the switch fabric to deploy the objective specific model and or the cached objective specific model.

Reference is now made to which is a flowchart illustrating certain decisions made by the switch port monitoring device when dynamically monitoring one or more switching ports of a networking device according to one or more embodiments. In one embodiment operation involves the real time processor querying the switch processor to see if a packet flow received at any of the ingress ports for example ingress egress port A comprises a packet which has been tagged by the switch processor in the past. If the answer to this inquiry is yes then the control engine of the real time processor may send a command to the switch processor and or the switch fabric to forward the packet flow to its intended destination pursuant to operation . In another embodiment not shown in the real time processor may send a command to the packet queue for example through the packet manager to drop the packet from the packet queue . Additionally the control engine of the real time processor may also send a command to the switch fabric via the switch processor to not forward either the tagged packet or packet flow comprising the tagged packet or copies of such packets to the packet queue . If the answer to this inquiry is no then as shown in operation the packet manager may instruct the packet queue to queue the packet received through any of the uplink ports for example uplink port A .

Operation involves the feedback engine of the real time processor querying the packet manager to determine if the packet queue is nearing capacity. If the answer to this inquiry is yes then as shown in operation the real time processor may determine and deploy by the switch processor and the switch fabric an objective specific model that optimizes the number of packets forwarded to the packet queue and or the rate of packet data forwarded to the packet queue . Moreover as depicted in operation the real time processor may store the objective specific model in a storage device such as storage device . As shown in the example flowchart in once the objective specific model has been cached in the storage device the real time processor may once again undertake operation and query the packet queue for a status update. By doing so the real time processor executes a dynamic loop where the packet queue and the packet data processor are continuously being monitored. In one embodiment this operations loop may be undertaken at a high rate of repetition. If the answer to the inquiry of operation is no then as shown in operation the feedback engine of the real time processor may query the packet data processor to determine whether the monitoring bandwidth of the packet data processor has been exceeded. If the answer to this inquiry is yes then the real time processor may once again implement operation and operation .

If the answer to this inquiry is no the packet data processor may inspect the packet picked up from the packet queue . Once the packet has been examined by the packet data processor the packet data processor may send feedback data to the feedback engine of the real time processor . The control engine of the real time processor may then instruct the switch processor to tag the packet or to save a copy of the tagged packet in the storage device . Finally operation may involve the control engine of the real time processor instructing the switch fabric via the switch processor to forward the packet to its intended destination.

A number of embodiments have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the claimed invention. In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other embodiments are within the scope of the following claims.

It may be appreciated that the various systems methods and apparatus disclosed herein may be embodied in a machine readable medium and or a machine accessible medium compatible with a data processing system e.g. a computer system and or may be performed in any order.

The structures and modules in the figures may be shown as distinct and communicating with only a few specific structures and not others. The structures may be merged with each other may perform overlapping functions and may communicate with other structures not shown to be connected in the figures. Accordingly the specification and or drawings may be regarded in an illustrative rather than a restrictive sense.

