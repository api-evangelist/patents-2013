---

title: Efficient priority-aware thread scheduling
abstract: A priority-based scheduling and execution of threads may enable the completion of higher-priority tasks above lower-priority tasks. Occasionally, a high-priority thread may request a resource that has already been reserved by a lower-priority thread, and the higher-priority thread may be blocked until the lower-priority thread relinquishes the reservation. Such prioritization may be acceptable if the lower-priority thread is able to execute comparatively unimpeded, but in some scenarios, the lower-priority thread may execute at a lower priority than a third thread that also has a lower priority than the high-priority thread. In this scenario, the third thread is effectively but incorrectly prioritized above the high-priority thread. Instead, upon detecting this scenario, the device may temporarily elevate the priority of the lower-priority thread over the priority of the third thread until the lower-priority thread relinquishes the resource, thereby reducing the waiting period of the high-priority thread for the requested resource.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09569260&OS=09569260&RS=09569260
owner: Microsoft Technology Licensing, LLC
number: 09569260
owner_city: Redmond
owner_country: US
publication_date: 20130531
---
Within the field of computing many scenarios involve a set of threads executing on a processor where respective threads share a set of computing resources. For example the time available by the processor may be shared among the set of threads and network capacity may be divided among the threads that are endeavoring to send or receive data. Some resources may be reserved by a thread e.g. a thread may lock a file or a section of memory in order to restrict access by other threads during a sensitive operation such as writing data in a manner that reduces unintended overwriting by other threads. However difficulties may arise if a first thread requests access to a resource that has already been reserved by a second thread. In such scenarios the computing environment may block the execution of the first thread until the second thread relinquishes the reservation of the resource.

Additionally in such scenarios respective threads may include a priority that facilitates the sharing of computing resources. Such priorities may be utilized e.g. to determine that a processor is to allocate a higher and earlier share of processing time to a higher priority thread than a lower priority thread and or that a request for access to a resource such as network capacity or the use of a communications bus is to be allocated to satisfy the tasks of a higher priority thread before allocation to satisfy the tasks of a lower priority thread.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A particular problem that may occur within thread scheduling and reservation of resources involves a first thread having a comparatively high priority and a second thread having a lower priority where the second thread acquires a reservation of a resource that is also requested by the first thread. In such scenarios the first higher priority thread is often blocked until the second lower priority thread relinquishes the reservation of the resource and the higher priority thread is then awarded a reservation of the resource. In order to reduce the waiting period of the higher priority thread for the resources it may be desirable to expedite the processing of the second thread. In many such scenarios this sequence of events is acceptable because the blocking of the first thread enables the second thread to be executed unimpeded thereby allocating a larger share of computational resources to the second thread until its task is completed. However in other scenarios the second thread may have a lower priority not just of the first thread but also of a third thread that is also executing within the computing environment. The computing environment may prioritize the execution of the third thread above the execution of the second thread due to the comparative priorities of the threads. However if the third thread also has a lower priority than the first thread then the prioritization may result in the third thread consuming a larger share of resources than the second thread during the reservation of the resource on which the first thread is waiting resulting in an effective and incorrect prioritization of the third thread over the first thread.

Presented herein are techniques for scheduling threads for execution on a processor of a device in view of the resource reservations of such threads. In accordance with these techniques for respective threads the device may identify at least one resource reserved by the thread. Upon detecting that a first thread is awaiting a selected resource that is reserved by a second thread and also that a third thread has a priority that is below the priority of the first thread and above the priority of the second thread the device may elevate the priority of the second thread above the third thread and then schedule the execution of the threads according to the respective thread priorities. This scheduling may reduce the incidence of higher priority threads that are awaiting access to resources that are in use by lower priority threads which in turn are scheduled at a lower priority than other threads that also have a lower priority than the blocked higher priority thread in accordance with the techniques presented herein.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Within such scenarios it may be possible to execute one or more threads concurrently e.g. the device may comprise more than one processor and or respective processors may comprise multiple cores . Additionally it may be desirable to enable a first thread to have priority over a second thread e.g. while concurrently executing a first process providing a user task such as editing a text document and a kernel process completing a time sensitive task such as streaming media to a media device it may be desirable to shift processor time memory and other computing resources from the user process to the kernel process because a brief processing delay in streaming media may be more noticeable or problematic than a brief processing delay in a text editing user interface.

In order to enable resource sharing the device may assign to each thread a priority indicating the priority of the thread to consume resources relative to other threads that may also be executing on the device . The priorities may be assigned e.g. as numeric scores or as ordinal identifiers of the priority rank of the thread with respect to other threads . A thread scheduler may then generate a thread schedule indicating for respective blocks of time which thread is executed by the processor wherein threads having a higher priority are allocated a larger share of time on the processor than other threads . When the block of time on the processor allocated to one thread is completed the processor may perform a context switch e.g. storing the values of registers used by the previous thread and the call stack of the thread selecting a second thread and loading into the registers the values and the call stack at the completion of a previous block of processor time for the second thread . In this manner the thread scheduler may enable the threads to share the processor in a manner that prioritizes higher priority threads over lower priority threads and without causing any threads to starve e.g. allocating at least a small share of time on the processor for even the lowest priority threads .

Additionally within the exemplary scenario of the resources of the device optionally including the processor may be subject to one or more reservations requested by the threads . As a first example a thread may request a lock on a particular file stored in a storage device such that the thread may exclusively access the resource while writing to the file in order to restrict other threads from overwriting the same file and causing a loss of data. As a second example a thread may request exclusive use of a communications bus or a share of network bandwidth in order to complete an operation having tight constraints such as a Voice over IP VoIP session achieved over a network where inadequate resource availability may result in a noticeable reduction of the quality of service QoS of the session. Accordingly when one or more threads requests a reservation for a resource the device may record the reservation and grant access to the resource only in accordance with the reservation . If a second thread requests access to a resources that is unavailable due to one or more reservations by other threads the device may temporarily suspend or block the execution of the second thread until one or more of the other threads relinquishes its reservation of the resource . A detected relinquishment may enable a fulfillment of the reservation for the second thread which is unsuspended and permitted to continue executing with the reservation of the resource .

In such scenarios the reservation of resources may result in a variance from a strict prioritization and scheduling of threads according to priority . For example a first thread and a second thread may be executing on the device where the first thread has a higher priority than the second thread and the device may ordinarily scheduling of the execution of the first thread to occur more often than the execution of the second thread . However the second thread may acquire a first reservation of a resource and the first thread may subsequently request a second reservation of the same resource . Moreover interrupting the operation of the second thread may not be possible e.g. many such reservations involve atomic operations that result in data loss or corruption if interrupted. Instead the device may suspend or block the first thread until the second thread has completed its access of the resource and relinquished its reservation of the resource .

In many instances scheduling the execution of the second thread over the execution of the higher priority thread may occasionally be desirable and acceptable. For example if the lower priority thread is permitted to utilize the reserved resource in a comparatively unimpeded manner then the lower priority thread may complete its operation rapidly and the delay of the higher priority thread may be negligible. However in some instances such scheduling of threads due to may result in an inefficient utilization of the resources of the device and avoidable delays in the execution of the threads . For example while the second thread is utilizing the resource and the first thread is suspended a third thread may also be executed by the device that has a priority that is lower than the priority of the first thread but that is higher than the priority of the second thread . Accordingly the thread scheduler may refrain from executing the first thread while awaiting the relinquishment of the reservation of the resource by the second thread but may also prioritize the execution of the third thread over the second thread due to its higher priority . Accordingly the operation of the third thread may delay the completion of the task of the second thread its relinquishment of the reservation of the resource and the resumption of the first thread . This interaction results in an effective prioritization of the third thread over the first thread despite the first thread having a higher priority than the third thread .

Many techniques may be devised to reduce these and similar scheduling problems. However many such techniques may be computationally expensive. For example a scrupulous reservation tracking system may utilize some complex logic in order to fulfill any request for a reservation of a resource by a thread . However tradeoffs may exist in the efficiency gains of scrupulous tracking techniques as compared with the computational expenses involved. For example maintaining a global record of every reservation of every resource may also involve a reservation process for updating the global record e.g. in order to award a reservation of a resource to a thread the device may first have to acquire a reservation of the global reservations record in order to record the reservation and may have to lock the global reservations record again when the reservation is relinquished. Updating the global reservation record therefore impose a cost in computational resources that reduces or even exceeds the efficiency gains of such reservation aware thread scheduling. Accordingly the particular technique selected for prioritizing the threads may significantly affect the efficiency of the device .

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. Such computer readable media may include e.g. computer readable storage media involving a tangible device such as a memory semiconductor e.g. a semiconductor utilizing static random access memory SRAM dynamic random access memory DRAM and or synchronous dynamic random access memory SDRAM technologies a platter of a hard disk drive a flash memory device or a magnetic or optical disc such as a CD R DVD R or floppy disc encoding a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein. Such computer readable media may also include as a class of technologies that are distinct from computer readable storage media various types of communications media such as a signal that may be propagated through various physical phenomena e.g. an electromagnetic signal a sound wave signal or an optical signal and in various wired scenarios e.g. via an Ethernet or fiber optic cable and or wireless scenarios e.g. a wireless local area network WLAN such as WiFi a personal area network PAN such as Bluetooth or a cellular or radio network and which encodes a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein.

An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method of prioritizing the execution of threads on a device in view of the reservations of the resources of the device by such threads such as the exemplary method of . In another such embodiment the processor executable instructions may be configured to implement a set of components that together provide a system for prioritizing the execution of threads on a device in view of the reservations of the resources of the device by such threads such as the exemplary system of . Some embodiments of this computer readable medium may comprise a computer readable storage medium e.g. a hard disk drive an optical disc or a flash memory device that is configured to store processor executable instructions configured in this manner. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary method of and or the exemplary system of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized.

As a first variation of this first aspect the techniques presented herein may be utilized with many types of devices such as servers server farms workstations laptops tablets mobile phones game consoles and network appliances. Such devices may also provide a variety of computing components such as wired or wireless communications devices human input devices such as keyboards mice touchpads touch sensitive displays microphones and gesture based input components automated input devices such as still or motion cameras global positioning service GPS devices and other sensors output devices such as displays and speakers and communication devices such as wired and or wireless network components.

As a second variation of this first aspect the techniques presented herein may involve the monitoring of many types of reservations of many types of resources . As a first example the resources may comprise e.g. execution time on one or more processors a requested or detected affinity of a thread for a particular processor or processor core an allocation of memory in a volatile memory circuit such as system RAM or a nonvolatile storage device such as a hard disk drive an allocation of bandwidth in a communication bus or network connection and or access to one or more hardware or software components of the device . As a second example the reservations of the resources may comprise e.g. a reserved allocation of a portion of the capacity of the resource e.g. a reservation of a block of memory or a share of network bandwidth exclusive access to the resource and or participation in a limited shared access of the resource such as through a semaphore. As a third example the resources may comprise a particular task or operation performed by the second thread on which the first thread is awaiting completion before performing subsequent processing.

As a third variation of this first aspect the priorities of respective threads may be identified and assigned in various ways. As a first example the priorities may comprise relative numerical scores where a higher priority score of a first thread denotes a higher priority than a lower priority score of a second thread . As a second example the priorities may have semantic significance such as an identification of the role of the thread e.g. kernel threads may be assigned a first priority device driver threads may be assigned a second priority and user threads may be assigned a third priority and or the significance of the task performed by the thread e.g. threads performing a time sensitive task may request and receive comparatively higher priority than threads performing time insensitive tasks . As a third example the device may select the priorities of the threads based on roles or activities e.g. adjusting the priorities of the threads while monitoring the performance of the device . Alternatively the priorities may be specified by the threads and or selected by a user of the device .

As a fourth variation of this first aspect the priorities of the threads adjusted in accordance with the techniques presented herein may be usable by the device in many ways. As a first example the device may choose a thread schedule for the threads executing on the device in view of the priorities of the threads . As a second example the device may award reservations based on the priorities of the threads e.g. if two threads concurrently request a reservation of a resource the device may award the reservation first to the thread having a higher priority . As a third example the device may manage the allocated resources of the threads in accordance with the priority e.g. if a memory shortage prompts a deferral or termination of one or more threads the threads having lower priority may be selected for deferral or termination before threads having a higher priority . These and other scenarios may be suitable for implementations of the techniques presented herein.

A second aspect that may vary among embodiments of these techniques relates to the tracking of resources and reservations thereof.

As a first variation of this second aspect the reservations of resources may be detected in an ad hoc manner e.g. by examining and or querying the threads to determine the reservations held by each thread or by monitoring the interactions of the threads and resources .

As a second variation of this second aspect the device may include a reservation record where the reservations of resources by threads are recorded. Additionally the reservation record may be generated as a data structure facilitating lookup of reservations and or associated threads . A forest of binary trees may be feasible for this role as each binary tree may be rebalanced upon detecting an imbalance in the binary tree comprising the reservation record particularly if the binary tree is amenable to consistent lookup time and or rapid rebalancing such as a partitioned red black tree . In an embodiment a first binary tree identifies the threads that have reservations for a particular resource and a second binary tree identifies the threads that are awaiting a reservation for the resource . As a second example the set of threads that have reserved and or are awaiting reservations for the respective resources may be stored in a data structure such as a linked list which may present greater lookup efficiency and consistency in the reservation mechanism than techniques that utilize recursion to inspect the graph of reservations which may consume a significant portion of the call stack in scenarios involving complex interrelated graphs of references.

In variations involving a reservation record the manner of recording the reservations in the reservation record may significantly affect the performance of the device . For example a scrupulous and comprehensive recording process may involve recording each reservation in the reservation record promptly upon awarding the reservation to a thread . However scrupulous and comprehensive recording may be inefficient in several respects. As a first example mechanisms for recording every thread interaction in a centralized reservation record may have significant difficulties with concurrency in the updating of the reservation record e.g. devices featuring an abundance of executing threads devices featuring a high degree of concurrently executing threads such as devices with large numbers of processing and or processing cores and computing environments where reservations are frequently requested and released . The concurrency of accessing the reservation record may consume a significant amount of computational resources including the complexity and delay in requesting receiving and or relinquishing a reservation and may occasionally create additional processing bottlenecks that reduce or exceed the potential efficiency gains of the reservation tracking mechanism. As a second example scrupulous and comprehensive recording may result in computational work for many reservations that are unlikely to present opportunities for adjustments that yield higher efficiency or performance. Examples of such scenarios include the reservation of a resource only by one thread the acquisition and relinquishing of a reservation in a short period of time such as within the same processing cycle and reservations for resources that are held by a lower priority thread and awaited by a higher priority thread with no other threads having priority that may preempt the lower priority thread wherein the resource conflict is resolvable simply by allowing the lower priority thread to run to completion and relinquish the reservation.

In view of these observations a set of second variations of this second aspect involve reservation recording techniques relating to the usage of the reservation record. Rather than providing a scrupulous comprehensive documenting of reservations the device may conservatively utilize the reservation record to focus on the reservations are likely to provide opportunities for adjustments resulting in greater efficiency.

As a first example of this second variation of this second aspect the recording of reservations may occur outside of the actual reservation of the resource in order to reduce the duration of the reservation e.g. the recording of an awarded reservation in the reservation record may be performed before providing the reservation to the second thread and or the relinquishing of the awarded reservation may be performed after the reservation has been relinquished.

As a second example of this second variation of this second aspect the reservation record may be utilized only for scenarios where the selected resource has been and or is soon likely to be requested by a second thread and optionally more particularly detecting that the subsequent request is received from a first thread having a higher priority than the second thread .

As a third example of this second variation of this second aspect incidents wherein lower priority threads reserve selected resources that are not awaited by a higher priority thread may be recorded in an internal reservation record owned by the thread and may be transferred to a centralized reservation record only upon detecting that a higher priority thread is awaiting the selected resource .

As a fourth example of this second variation of this second aspect the recording of reservations by a second thread may be deferred until the run cycle of the thread is complete e.g. when the device is about to perform a context switch away from the second thread . This deferral may reduce the recording of reservations that are acquired and relinquished so promptly that it is unlikely that higher priority threads may be significantly delayed by the reservation by the lower priority thread . Using these and other techniques the device may access the reservation record conservatively e.g. avoiding the recording of reservations that are unlikely to provide opportunities for priority adjustments that result in higher efficiency in order to reduce the computational resources involved in the recording. Those of ordinary skill in the art may devise many techniques for efficiently tracking reservations of resources in embodiments of the techniques presented herein.

A third aspect that may vary among embodiments of these techniques relates to the elevation of priorities of threads in order to alleviate resource conflicts involving reservations of resources .

As a first variation of this third aspect the elevation of priority of one or more threads may be reserved for scenarios potentially enabling in greater efficiency. For example when a lower priority thread is detected to have a reservation of a resource that is awaited by a higher priority thread it may be determined that the elevation of priority only results in greater efficiency if a third thread is scheduled for execution that may delay the completion of the second thread and the resulting relinquishing of the reservation and the resumption of the higher priority thread and additionally the third thread has a higher priority than the second lower priority thread and a lower priority than the first higher priority thread .

As a second variation of this third aspect the elevation of priority of one or more threads may be performed during a context switch For example upon context switching away from the first thread and in an embodiment upon context switching away from the first thread that is blocked and awaiting a reservation of a resource the device may identify the resources awaited by the first thread and one or more second threads that have a reservation for the selected resources and at least one third thread having a priority that is above the priority of the first thread and below the priority of the second thread . The context switch away from the first thread may present a convenient opportunity for performing this extensive evaluation and elevating the priority of the second thread above the third thread e.g. because the interruption of the first thread due to the blocking request for a reservation of the selected resource entails a delay in the operation of the first thread and performing this evaluation may provide a small increase in computational evaluation in exchange for a potentially significant expedition of the second thread through the elevation of priority and a potentially significant gain in efficiency. Additionally the elevation of priority may reflect the priority of the first thread at various times e.g. the elevation of the priority of the second thread may reflect the priority of the first thread even if the priority of the first thread changes. For example if the priority of the second thread is elevated at a first time to the priority of the second thread and subsequently the priority of the first thread is later increased e.g. if the first thread comprises a memory reclaiming process such as a garbage collector and the device later encounters a significant shortage of memory the priority of the second thread may be further elevated to reflect the elevation of priority of the first thread .

As a third variation of this third aspect the elevation of priority of the second thread may be achieved in various ways. As a first such example the priority of the second thread may be set at least as high as the priority of the first thread or just above the priority of the third thread . As a second such example the priority of the second thread may be elevated only briefly e.g. only for one run cycle as a temporary adjustment of priority in case the second thread is capable of completing the task and promptly relinquishing the reservation of the resource and or may be maintained through at least one subsequent context switch e.g. potentially expediting the completion of the second thread by a significant extent in the case of long running tasks . As a third such example the elevation of priority of the second thread may be reduced promptly after detecting that the second thread has relinquished the reservation of the resource or may be maintained for a brief or extended duration e.g. in case the second thread promptly reacquires the reservation of the resource or in case the second thread performs tasks on at least one related resource that has been or may promptly be requested by the first thread . As another alternative the priority may be briefly reduced even below the initial priority of the second thread e.g. in order to provide a comparatively consistent amount of priority to the second thread over time.

As a fourth variation of this third aspect in some scenarios respective threads may have different types of priority for different types of resource access to different types of resource . For example a thread may have a first priority identifying the priority of the thread to lock one or more files of a file system a second priority identifying the priority of the thread to execute on the processor and a third priority identifying the priority of the thread to communicate over and or reserve bandwidth for a communications bus or network. As a first example of this fourth variation of this third aspect while elevating the priority of a thread in order to expedite the relinquishing of a reservation on a selected resource having a selected resource type e.g. write access to a file memory interaction with a component such as a display adapter or communication over a communications bus or network the device may specifically elevate the resource access type priority for the access type of the selected resource e.g. elevating only the priority of the thread for accessing the network for which the thread has a reservation and that is awaited by a higher priority thread . Alternatively the device may elevate the priority of the thread for one or more other resource access type priorities e.g. so that the thread may utilize any resources involved in the completion of the task on the selected resource and the relinquishing of the reservation . For example the first thread may be awaiting access to a file that is exclusively locked by the second thread for transmission over a network. Because the completion of the transmission may be affected both by the priority of the second thread in accessing the file determined according to a file access type priority as well as the priority of the second thread in transmitting data over the network determined according to a network access type priority the device may elevate both the file access type priority and the network access type priority of the second thread even though only the reservation of the file directly relates to the suspension of the first thread .

As a fifth variation of this third aspect the elevation of priority may be applied selectively to the second thread e.g. by elevating the priority with respect to operations of the second thread involving the selected resource and refraining from elevating the priority of other operations of the second thread that does not involve the selected resource . Such selective elevation of priority may also be applied retroactively e.g. by elevating the priority of an operation of the second thread that was initiated prior to the detection of the first higher priority thread awaiting the selected resource and or the third thread having a higher priority than the second thread .

As a sixth variation of this third aspect in some scenarios the completion of the second thread and the relinquishing of the reservation of the resource that the first thread is awaiting may be further contingent on the completion of yet another thread having reserved a second resource that the second thread is awaiting. In such scenarios the elevation of priority of the second thread may be inadequate for expediting the relinquishing of the reservation of the resource because the second thread is also suspended pending completion of the other thread. Accordingly in an embodiment elevating the priority of the second thread may further involve detecting that the second thread is awaiting a second resource that is reserved by a fourth thread having a priority below the priority of the third thread and therefore elevating the priority of the fourth thread above the priority of the third thread in order to facilitate its completion and relinquishing of the reservation of the second resource . In a further embodiment the device may first elevate the priority of the fourth thread and upon detecting a relinquishing of the reservation of the second selected resource by the fourth thread may reduce the priority of the fourth thread and also elevate the priority of the second thread . In this manner the prioritization of the threads may involve an evaluation of a dependency chain involving a set of threads and the sequential elevation of priority of each thread at the end of the dependency chain in order to expedite its completion and the resumption of a preceding thread of the dependency chain for which the priority is next elevated etc. In this manner the device may resolve a chain of reservation requests involving a set of resources in a manner that expedites the completion of the tasks of the threads higher up the dependency chain.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB Firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

