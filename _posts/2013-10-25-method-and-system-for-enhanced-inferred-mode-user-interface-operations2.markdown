---

title: Method and system for enhanced inferred mode user interface operations
abstract: A method and system is provided for the input of user interface commands. Particularly, command initiation events including at least one of: (i) a mouse press event on mouse pointer hardware, and (ii) at least one of a pen touch event, a stylus touch event, and a finger touch event on touch pointer hardware, are accepted. Then gesture stroke input events including at least one of: (i) a mouse drag event on the mouse pointer hardware, and (ii) at least one of a pen drag event, a stylus drag event and a finger drag event on the touch pointer hardware, are accepted. Additionally, command termination events including at least one of (i) a mouse release event on the mouse pointer hardware, and (ii) at least one of a pen lift event, a stylus lift event and a finger lift event on the touch pointer hardware, are accepted. The events are then interpreted as at least one of object selection or digital ink input operations without prior selection of a user input mode.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09659279&OS=09659279&RS=09659279
owner: PALO ALTO RESEARCH CENTER INCORPORATED
number: 09659279
owner_city: Palo Alto
owner_country: US
publication_date: 20131025
---
This application is related to the following copending applications all of which are hereby incorporated by reference as if fully set forth herein 

U.S. application Ser. No. 14 062 934 filed herewith and entitled SYSTEM AND METHOD FOR CREATING GRAPHICALLY RICH MESSAGES INCORPORATING SHARED DOCUMENTS by Eric Saund et al. 

U.S. application Ser. No. 14 062 942 filed herewith and entitled SYSTEM AND METHOD FOR TRANSMITTING MIXED CONTENT TYPE MESSAGES by Eric Saund et al. 

U.S. application Ser. No. 14 062 954 filed herewith and entitled SYSTEM AND METHOD FOR GENERATING UNIFORM FORMAT PAGES FOR A SYSTEM FOR COMPOSING MESSAGES by Eric Saund et al. and

U.S. application Ser. No. 14 062 971 filed herewith and entitled SYSTEM AND METHOD FOR REFLOW OF TEXT IN MIXED CONTENT DOCUMENTS by Eric Saund et al.

The present application relates to electronic messages and documents and more particularly to improving the process of message and document generation and communication.

Presently a great deal of work between individuals is performed through written electronic discussion about shared documents. For example it is common for electronic messages such as email messages to contain attachments or references to documents in shared repositories and for the content of the email messages to refer to matter contained in these documents. A problem arises when the email correspondent wishes to directly include portions of these documents in their email message in order to refer to them annotate them or indicate modifications. Particularly email is a text based medium that does not readily support graphic markup or inclusive references to non textual matter found in referenced documents.

To currently address these shortcomings emails can include attachments. Email attachments are separated from the body of email message text which means that viewing both the body of an email and material contained in attachments requires different applications and view windows on a display screen of an electronic computing device e.g. a computer laptop tablet smartphone etc. .

Emails can include inline images meaning that images can be interspersed with typed email text. It is possible in some email clients to author messages containing inline images derived from attachment documents shared documents or private documents. To generate such a message is currently a cumbersome multistep process involving opening a document in a viewer different from the viewer in which the email is displayed taking a screen snapshot copying and pasting the image to another program which provides markup capabilities performing markup on the document image copying and then pasting the resulting marked up image into their email then sizing and positioning the marked up image among their email text.

The following patents applications and Articles are incorporated herein by reference in their entireties U.S. Pat. No. 7 177 483 System And Method For Enhancement Of Document Images by Saund U.S. Pat. No. 7 086 013 Method And System For Overloading Loop Selection Commands In A System For Selecting And Arranging Visible Material In Document Images by Saund et al. U.S. Pat. No. 6 903 751 System And Method For Editing Electronic Images by Saund et al. U.S. Pat. No. 7 036 077 Method For Gestural Interpretation In A System For Selecting And Arranging Visible Material In Document Images by Saund et al. Saund et al. Perceptually Supported Image Editing of Text and Graphics Proc. UIST 2003 ACM Symposium on User Interface Software and Technology pp. 183 192 lyad Abu Doush et al. Detecting And Recognizing Tables In Spreadsheets DAS 10 Proceedings of the 9th IAPR International Workshop on Document Analysis Systems Pages 471 478 ACM New York N.Y. Eric Saund and Edward Lank Minimizing Modes for Smart Selection in Sketching Drawing Interfaces in J. Jorge and F. Samavati eds. Sketch based Interfaces and Modeling Springer 2011 pp. 55 80 and Rubine D. 1991 Specifying gestures by example Proc. SIGGRAPH 1991 New York ACM Press 329 337.

A method and system is provided for the input of user interface commands. Particularly command initiation events including at least one of i a mouse press event on mouse pointer hardware and ii at least one of a pen touch event a stylus touch event and a finger touch event on touch pointer hardware are accepted. Then gesture stroke input events including at least one of i a mouse drag event on the mouse pointer hardware and ii at least one of a pen drag event a stylus drag event and a finger drag event on the touch pointer hardware are accepted. Additionally command termination events including at least one of i a mouse release event on the mouse pointer hardware and ii at least one of a pen lift event a stylus lift event and a finger lift event on the touch pointer hardware are accepted. The events are then interpreted as at least one of object selection or digital ink input operations without prior selection of a user input mode.

As will be set out in detail in the following the teachings of the present patent application simplify and streamline the process of referring to and including document material in the body of an electronically generated message such as an email message. The disclosed systems and methods support the integrated inclusion of referenced document material in the body of an electronic message which allows for composing and or generating and the assembling of mixed content type electronic messages that have graphically rich layouts including at least some of text images digital ink graphic objects annotations voice audio clips and or video clips. Documents are understood herein to include a single page as well as multiple pages.

It is to be understood that in the following disclosure the use of the words generating and or composing and variations thereof include the concept of a user interacting with the methods and systems described herein to produce or author content of an electronic message on an electronic display of an electronic computing device being operated by a user. Further the use of the word assembling and variations thereof include the concept of putting the content created by the generating and or composing operations into a format and or form that is configured to be electronically transmitted across a communication network networked service via email protocols and that will display on email client programs operating on other electronic computing devices such that the content of the email including at least some of text or text objects images or image objects digital ink graphics or graphic objects annotations voice audio clips and audio clips remains intact and with fidelity to its appearance as generated and or composed by the user.

The described systems and methods allow a user to generate and or compose the enhanced electronic message and to have the message assembled by use of a single application. Where application refers to an application in the form of computer code that is configured to operate on electronic computing devices and in certain particular embodiments computer code that allows for the generation of electronic messages e.g. email . Calling the present application a single application is explained as follows. In existing email applications a user can place an image in line with an email message. However this requires the user to take multiple steps employing more than a single application. As an example the user will need to open a document in a viewer different from the viewer in which the email is displayed take a screen snapshot copy and paste the image to another program which provides markup capabilities perform markup on the document image copy and then paste the resulting marked up image into the email then the user must further size and position the marked up image among the email text. On the other hand the present methods and systems permit for an enhanced mixed content type electronic message through the use of a single email application which does not require the use of the aforementioned separate distinct applications.

It is further to be understood the concept of a single application includes situations where portions of the single application are found on more than a single electronic computing device. It is appreciated in this situation the application is still a single application where there is no need for the user to open another separate application rather aspects of the single application are simply distributed over more than a single electronic computing device.

The present systems and methods are also configured to present a single view to the user while the user generates and or composes the mixed content. Particularly in one embodiment the user is presented with a single display window of an electronic computing device where the single display window includes multiple regions or panes. It is to be understood this concept of a single view also includes when the single view is distributed over more than a single electronic display. For example it is known that an electronic computing device may operate two or more electronic displays. Therefore a user could move some of the regions or panes of the single view from a first electronic display to another electronic display being viewed by a user. Under the present teachings this splitting of the regions and or panes among electronic displays is still understood to be a single view of a single display window.

In the following description representative embodiments of the system and method of the present application are referred to herein as a VMail Arrangement which in general includes but is not limited to a VMail Application and in certain embodiments an optional VMail Cloud Service. It being understood the services of the VMail Cloud Service normally done remotely over a network but such services could also be done locally on the same electronic computing device operating the VMail Application.

Turning to illustrated is a system architecture and environment for one embodiment of the VMail Arrangement . Herein VMail Application is configured as computer code in the form of a computer program e.g. email client installed on a user s electronic computing or computational device . In this embodiment the electronic computing device also includes the user s normal existing email program e.g. Outlook from Microsoft Corporation etc.

Electronic computing device represents and includes but is not limited to a desktop computer laptop computer tablet computer smartphone mobile device or other electronic device with an electronic display and other hardware and software appropriate to operate as known in the art including support for a user interface and network connectivity. Hardware and software of such electronic computing devices include but are not limited to electronic processor arrangement s e.g. electronic processor s video graphic processor s where for example the electronic processor arrangement s include a controller memory component s e.g. Random Access Memory RAM Read Only Memory ROM among other memory configurations user interface components e.g. keyboard voice input control an electronic mouse i.e. both a mouse not physically integrated into an electronic computing device and an integrated mouse also called a touchpad or similarly understood designation electronic pen stylus and finger for use with touch screens or other known selection transfer capable device capable of for example operating as a data entry and or object selection device or mechanism. The memory components are configured to hold and allow the operation of software both for operation of the computing device e.g. including but not limited to controllers operating system software and software which permits the electronic computing devices to perform tasks e.g. application type software . Such elements or components are understood to be represented by the electronic computing device . It is also to be understood that electronic computing devices discussed in this embodiment are equally applicable to other embodiments of the present application.

VMail Application is configured to have the capability to interact with plug in API Application Programming Interface of the user s normal email program if such plug in API exists. The normal existing email program e.g. Outlook sends and receives email messages e.g. outgoing and incoming messages through an email service e.g. networked service via an appropriate electronic communication network e.g. Internet Intranet private network etc. . The email messages being sent and received by others having electronic computing devices appropriately configured with email applications configured to be able to interact with the system architecture and environment of .

The VMail Application program communicates with optional VMail Cloud Service which includes a VMail Page Rendering Service and optionally a VMail Email Service e.g. networked service for communication with the other electronic computing devices . Additionally a local cache is established for offline use. It is to be appreciated that the VMail Page Rendering Service may in some embodiments be located on the electronic computing device . The embodiment of also depicts an electronic processor arrangement memory component s and user interface component s .

The VMail Application Client Tab or Window as previously discussed is deployed on an electronic computing or computational device including but not limited to a desktop workstation laptop computer tablet computer smartphone or other electronic device presenting a user interface and network connectivity. The embodiment of also depicts an electronic processor arrangement memory component s and user interface component s .

Turning now to illustrated is a user interface configuration display window of an electronic display e.g. of electronic computing devices of for the VMail Application of the present disclosure. Provided in this embodiment are two main components each of which is a region or pane contained within a display window or screen window on an electronic display of an electronic computing device. One component is referred to as the Email Authoring Region . This in turn includes an Email Address Block and a Message Composition Region . In the example shown the Message Composition Region includes text of a message and enhanced content such as but not limited to images digital ink e.g. the hand drawn loop and graphic objects e.g. the lined arrow . The second component is a Document Viewing Region or Document Display Region which displays document image pages of reference documents e.g. attachments as well as documents stored in repositories including those shared by others . This in turn includes a Document Chooser and a Page Viewing Region or Page Display Region . In other configurations and or embodiments more than one Message Composition Region and more than one Page Viewing Region may be present. It should be appreciated that alternative configurations of user interface regions and widgets fall under the scope of this patent application.

An exemplary operation of the VMail Arrangement is illustrated in which presents a representative sequence of user activities interspersed with activities performed by the VMail Arrangement that result in the user s authorship and sending of a message. The VMail Application is deployed to the user s electronic computing device through a variety of arrangements as described above and it may be invoked through a variety operations. Among these the sequence shown in illustrates operation in connection with a configuration corresponding to wherein the VMail Application is installed on the user s electronic computing device and is linked to the user s existing email client application e.g. Outlook through a plug in architecture.

In the sequence shown in the VMail Application is started by the user invoking a special Reply In VMail command from their existing email client. This may be included as a button on the interface of the existing email client.

With continuing reference to the sequence commences at with the user s email client e.g. Outlook already running and showing a listing of received messages. At step the user performs an action in the normal existing email client to open a message and in step the normal email client application brings up a window or view in which the message is displayed. In this representative sequence it is assumed the message contains one or more attachments. At step the user invokes the Reply in VMail command. This causes the VMail Application itself to be started on electronic computing device step . Through the well established use of plug in architectures the Reply in VMail command is invoked within the context of the normal email client.

At step attachment documents of the replied to message are automatically transferred to the VMail Page Rendering Service. In one embodiment the VMail Page Rendering Service runs on the client s electronic computing device. In another embodiment as represented in the VMail Page Rendering Service runs on a remote server system that the VMail Application communicates with over a communication network.

The attachment documents from the email message being replied to will in general be encoded in a variety of native document formats including Microsoft Word Microsoft PowerPoint Microsoft Excel Adobe PDF Microsoft Visio plain text Rich Text Format .jpg .png and any number of additional native document formats.

At step the VMail Page Rendering Service performs computations to render the uploaded document s into a uniform format. In one embodiment the uniform format is any document communication format that preserves the visual appearance of the document. Examples of such formats include but are not limited to bitmap image formats such as .png format .jpg format and .tif format each of which are capable of various types of image compression as well as pdf format and proprietary formats. In another embodiment the uniform format includes an augmented data format. The augmented data format gives access to symbolic data contained in the documents including ascii text rich text format and graphics. The augmented data format also gives access to metadata about the document including author date version number and additional information about the source document.

In a situation where the uniform format includes augmented data another embodiment of the VMail Application arrangement includes providing access to different versions of a same document. For example for an edited document such as a Word document with track changes used . This arrangement provides a user with access to a layered number of versions of the same document. For example if a document has been revised though a number of versions with each version having additional changes the layered number of versions include the various revised versions of the document.

At step the fields of the Address Block e.g. are automatically populated with recipient information To field and CC field Sender information From field and Subject field in accordance with the Address field of the message being replied to. In one embodiment this information is obtained through the plug in mechanism of the normal email client. In another embodiment this information is obtained through a standard service interface to the address book function and email services accessible through their computer.

At step the user edits the text and enhanced content of their reply email message in a Message Composition Region . It is to be understood that editing activities in the Message Composition Region can take place at any time during the sequence not only in the order shown in the representative scenario .

After some period of time the VMail Page Rendering Service completes rendering of at least one page image of the first attachment document which is then automatically downloaded step to the VMail Application where it is provided to the VMail Document Viewing Region . After a period of time the page images of the attachment documents have been rendered and automatically downloaded. The names or titles of the attachment documents are added to a list of documents for which page images are available in the Document Chooser .

While not shown as a separate step in it is understood the steps allow the user to use the Document Chooser to select among multiple documents to display page images of in the Page Viewing Region . In one embodiment the Page Viewing Region displaying page images of a document is in the form of a scroll region.

Upon viewing one or more document page images step the user performs a selection operation step on a page image displayed in Page Viewing Region . By use of a selection transfer mechanism or device such as a mouse finger stylus elements or other known selection transfer device a convenient set of mouse operations or finger stylus gestures are used to select an entire page or a region portion or material of a page of a rendered document. For example in one embodiment a double click selects an entire page image while a mouse press drag release operation selects a rectangular region of a page image.

At step the user copies the selected page image region to the Message Composition Region . In one embodiment this is accomplished by a standard drag and drop gesture.

At step the VMail Arrangement optionally performs automatic image processing on the selected image region. This image processing is designed to render background regions of the image transparent for reasons that will become apparent later. The method of U.S. Pat. No. 7 177 483 System and method for enhancement of document images is used in one embodiment to perform this image processing.

At step the image region is optionally re sized to fit appropriately with the span of text and other material being generated in Message Composition Region .

At step the position of the image region in Message Composition Region is optionally adjusted to align it with margins and or other image material.

Optionally during drag and drop step if the user drags an image region in such a manner that it overlaps existing text graphics or other material in Message Composition Region the locations and layout parameters of this other material is readjusted to make room for the new image region. In particular text may optionally be caused to reflow or reformatted around the dragged image region and material may be moved down to extend the vertical extent of the contents in the Message Composition Region. This reflow or reformatting will be described in more detail in connection with .

At step the user selects one or more documents to be rendered and provided to Document Viewing Region so that pages of such documents may be viewed as page images in Page Viewing Region . These documents are other than and in addition to the email attachment documents already there by virtue of steps and . These additional documents may be selected from among a number of sources including but not limited to the user s electronic computing device a clipboard a file system cloud storage or from the attachments of other emails in their normal email client. In one embodiment icons for these additional documents are dragged and dropped into the Page Viewing Region which causes the VMail Application to automatically upload them and send them to the VMail Page Rendering Service .

In steps and the Page Rendering Service commences rendering the documents and downloading page images to the VMail Application as described above analogously to steps and .

In steps and the user performs additional edit operations incorporating at least some of text images freeform digital ink voice audio clips video clips structured graphic objects and annotations.

At step the user edits the Subject To and From fields of the Address Block . In one embodiment the VMail Application provides semi automatic text completion by exchanging data with the user s email client via the normal email application s plug in API .

In response at the VMail Application performs steps such as described in or to assemble the contents of the Message Composition Region into a form that can be transmitted via email protocols and that will display on email recipient s email client programs with at least some of text images digital freeform ink voice audio clips video clips and annotations intact and with fidelity to its appearance in a Message Composition Region .

It will be appreciated that analogous and corresponding workflow steps apply to alternative embodiments of the application such as those described in . In the previous representative scenario described in the VMail Application was launched by the user by pressing a Reply in VMail button on their normal existing email client. Alternative means are provided to launch the program and include but are not limited to pressing a New Message in VMail or equivalent button on the normal existing email client starting the program from scratch with no other email client running replying to an email message in a browser based email client and navigating a browser to the URL Uniform Resource Locator of the Mail Application Host .

Optionally access to the VMail Cloud Services may be gated by a user log in process. Under the system architecture of of this would apply to the VMail Application Host service as well.

The VMail Page Rendering Service is optionally designed to store page images for previously uploaded documents which enables faster return of page images to the VMail Application program. The stored document page images are optionally indexed by User ID user groups user organizations and by other metadata for purposes of collaborative sharing. Furthermore the VMail Cloud Service in some embodiments is configured to perform additional data analysis on the uploaded documents including keyword extraction text analysis and image analysis in order to support added value services including document version tracking similar document and related document search and targeted advertising.

In an embodiment of the present disclosure the VMail Email Service e.g. performs all email handling and storage functions and can therefore substitute for and replace the user s existing email service e.g. . In certain embodiments VMail Email Service incorporates the VMail Page Rendering Service function of rendering document page images and enhanced page images such as e.g. of the foregoing description.

In an embodiment where the user employs the VMail Email Service e.g. when an email is received e.g. from or the VMail Email Service e.g. will directly provide attached documents that are to be rendered to the VMail Page Rendering Service e.g. . Then when rendered such documents are provided to the VMail application such that when the user is viewing the email the rendered documents are available. This is in contrast to the situation when the existing or normal email service e.g. is used. In those situations the received email is first provided to the VMail application and then the documents to be rendered are sent to the Page Rendering Service. This results in a possible delay for the user to view the rendered documents.

The VMail Email Service e.g. of the present application is also configured to provide logging caching of documents as well as tracking of email threads.

Turning to the VMail Application incorporates various tools and or processes to facilitate the user s ability to generate and or compose messages containing a mixture of content including but not limited to plain text formatted text desired text layout images freeform digital ink and structured graphics .

Message Composition Region of provides a canvas architecture on which editing tools e.g. mechanisms and processes are used on textual and graphic objects to place rearrange copy paste select and or modify the text and graphic objects.

In addition to the above editing tools e.g. mechanisms and processes the present concepts provide additional document editing tools and processes including the following Where various ones of the tools and processes are further described in connection with and 

 i A select and crop tool and process configured to select and crop image objects using rectangle drag or lasso drag without prior selection of mode as described in more detail for example in U.S. Pat. No. 7 086 013 Method and system for overloading loop selection commands in a system for selecting and arranging visible material in document images. See for example herein .

 ii A select primitive object tool and process configured to select among multiple overlapping groups of primitive objects as described in more detail for example in U.S. Pat. No. 6 903 751 System and method for editing electronic images. It is understood that in the art a primitive object is also understood to be identified or called a primary object as well as an atomic object and in U.S. Pat. No. 6 903 751 the primary object is understood to include a bitmap object See for example herein .

 iii A gesture interpretation tool and process configured to interpret mouse stylus finger gestures as either a lasso e.g. also identified as a closed or nearly closed freeform path selection gesture or a stroke of digital ink as described in more detailed in for example U.S. Pat. No. 7 036 077 Method for gestural interpretation in a system for selecting and arranging visible material in document images. See for example herein .

 iv A gesture interpretation tool and process configured to interpret mouse stylus finger gestures as either a lasso selection gesture a rectangle selection gesture or a stroke of digital ink as described in more detail for example in connection with .

 v An automatic subdividing e.g. fragmenting or decomposition tool configured to provide automatic subdividing e.g. fragmenting or decomposition of image regions into smaller image objects on the basis of user selection operations as described in more detail for example in U.S. Pat. No. 6 903 751 System and method for editing electronic images. See for example herein .

 vi A placement and object location modifier e.g. adjustment tool and process configured to place and adjust locations of predefined graphic objects by selection from a menu or toolbar.

 vii A hand drawn gesture recognition tool and process configured to recognize hand drawn gestures as indicators of graphic objects according to stroke and sketch recognition methods known in the art and placement of corresponding graphic objects on the canvas.

 viii A automatic adjustment tool and process wherein for graphic objects attached to text and or locations on image objects the tool and process automatically adjusts position of the graphic objects as the text or image objects to which they are attached are rearranged.

 ix Image editing tools and processes that include the operations of translation rotation and scaling of selected objects including text digital ink images and graphic objects.

 x A proximity sensitive tool and process for positioning a text entry location. Referring for example to user interface configuration of in general computer based document editing user interfaces employ a text cursor or text caret as a visual indicator for where text entered by keystrokes will appear on a screen. Oftentimes the text cursor is displayed as a blinking vertical line although other visual indicators are common. Text on the screen is associated with blocks of text which may be lines paragraphs lists or other structures. Text entry locations are locations where text will be placed through keystrokes selection of text from menus voice commands or other mechanism to enter text. Commonly text entry locations include the beginning of a block of text the end of a block of text or insertion between characters of a block of text . Additionally a text entry location can be associated with a new block of text that does not yet contain any characters Conventionally in the art a new text block is established via a menu or toolbar operation that places the user interface in a mode wherein a subsequent mouse press or touch gesture determines the location of the new text block text entry location.

VMail Message Composition Region See also of is intended to support placement of text at arbitrary locations on a canvas according to the expressive desires of the user. Accordingly enhanced tools are provided to allow the user to assert text entry locations and associated text cursor with a minimum of effort. Specifically the VMail Application includes a process for placement of a text entry location either in association with an existing text block or to establish a new text block without prior specification of mode and thereby without a requirement to first choose any menu item press any toolbar button or otherwise place the user interface into a special mode for text entry.

Referring to regions of the canvas are established according to proximity to existing text blocks. Rectangular regions represent locations wherein a user mouse click or touch gesture will snap the text entry location in association with the enclosed text block. These locations include before the first character of the text block or insertion between existing characters of the text block. Pie shaped regions indicate locations wherein a user mouse click or touch gesture will snap the text entry location after the last character of the associated text block. The radius of the pie region is a predetermined distance designed to permit the user be imprecise in their text location positioning click or gesture. Finally a user mouse click or touch at an arbitrary location over the canvas outside these regions proximal to existing text blocks causes a new text block to be established and subsequent character keystrokes will add text to this new text block.

It is to be appreciated that mouse press or touch gestures may also take into account existing image digital ink and graphic objects on the canvas in which case instead of positioning a text entry location selection operations on existing objects may instead take place. In general a new text block will be created if the mouse click or touch occurs either over a background region of the canvas or over an anchored image object as described for example in the publication E. Saund D. Fleet D. Lamer and J. Mahoney Perceptually Supported Image Editing of Text and Graphics Proc. UIST 03 ACM Symposium on User Interface Software and Technology pp. 183 192.

In some cases information copied to the Message Composition Region is better understood if it is accompanied by additional contextual information. The VMail Application provides a process for contextual image material to be automatically or semi automatically transferred to Message Composition Region e.g. of from Page Viewing Region e.g. of in conjunction with targeted image material manually selected and transferred by the user.

Referring to the VMail Application user interface displays a partially composed message in a Message Composition Region and pages from a reference document image in a Page Viewing Region . A user selects a region of a page image by a convenient operation such as dragging out a rectangle with a mouse or by other known processes.

Referring to the user transfers the page image region of interest to the Message Composition Region by a convenient operation such as drag and drop.

Referring to another example is given. Here the VMail Application places into the Message Composition Region additional contextual information. In this illustration the contextual information consists of a reduced size image of the entire page from which the selected region was extracted along with dashed lines indicating the location of the selected region within the entire page . Additionally the page number of the source page is represented as a text object . In one embodiment of the present patent application additional contextual information is carried in the form of metadata which may be accessed via a right button click menu selection or other well known interface command. The metadata may include the document title author date version number and additional information about the source document.

In one embodiment of the present patent application the selection and placement of additional contextual information is programmed to be fully automatic. In another embodiment the selection and placement is semi automatic and is invoked by convenient operations available to the user such as menu selection keystrokes or toolbar buttons.

Referring to certain cells of a referenced spreadsheet document image have been selected by the user through a convenient operation such as mouse rectangle drag operation.

Referring to an enlargement of a portion of the spreadsheet image is shown. Accordingly the user selected cells are shown enlarged. Additionally shown are row header cells and column header cells that indicate the semantic index or address of the selected cells in the spreadsheet.

Referring to the user has dragged the selected cells to Message Composition Region see also of . But also appearing are excerpts of the source image corresponding to the row headers and column headers . Additionally the page number of the source image is added as a text object .

Focusing on the first sub workflow the user selects a region of page image . At step automatic document recognition processing is applied to determine whether the page image contains tabular organized data such as a spreadsheet. Processes for performing such document recognition are available in the art such as described in lyad Abu Doush and Enrico Pontelli Detecting and recognizing tables in spreadsheets DAS 10 Proceedings of the 9th IAPR International Workshop on Document Analysis Systems Pages 471 478 ACM New York N.Y.

If the decision point in step returns YES processing proceeds to step . If the decision point returns NO an exit point is encountered and the sub workflow is ended. In step it is determined whether the image region selected by the user contains one or more cells of the spreadsheet. This determination is made by intersecting the region of the page image containing data cells with the region selected by the user. Upon returning YES processing proceeds to step . If the decision point returns NO an exit point is encountered and the sub workflow is ended. In step the bounds of the row header corresponding to the selected cell s is determined and then the process moves to step where the region identified in step is excerpted copied from the page image. Similarly at steps and the region of the column header s corresponding to the selected cell s is determined and excerpted copied . The determination of row and column header regions of the page is accomplished through tabular document image recognition methods as mentioned above.

Focusing on the second sub workflow the user places their selected cell image region in Message Composition Region e.g. of by drag and drop or a similar convenient operation . At steps and the row header and column header context for the cell s meaning in the spreadsheet are automatically placed to the left and above respectively of the cell s location in the Message Composition Region .

Subsequent repositioning of the cell image region automatically causes the row header region and column header region to maintain their respective alignments to each other and the cell image region. However manual direct repositioning or adjustment by the user of the row header region or column header region does not affect other regions so the user is capable of achieving whatever configuration of image regions they may ultimately desire.

It is to be appreciated that the feature of automatic selection and copying of contextual information such as can be achieved by automatic document recognition processes are available in the art and are applicable to document material other than spreadsheets.

Returning to at step the VMail Application component of the present application performs steps that assemble the mixed type contents of the Message Composition Region e.g. of of of of into a form that is configured to be transmitted via email protocols and that will display on the email client programs of the recipient of the email with text and images intact and with fidelity to its appearance in the Message Composition Region. For the purposes of this application this form of email message is referred to generically as a composed mixed content email message. Where such a message includes a coded format preserving separable structure of the content such as but not limited to text image objects digital ink graphic objects voice audio clips and video clips.

In one embodiment of the present application a composed mixed content email message employs HTML CSS tags as illustrated in . presents an example mixed content type message that could be composed in a Message Composition Region of the present disclosure. This message of includes text and digital ink in the form of the encircling of some text an image in the form of a torso in a t shirt and structured graphics in the form of an arrow .

HTML HyperText Markup Language with CSS Cascading Style Sheets enhancements is a standard representation for communicating document content over the internet for display in web browsers. Under some circumstances email clients are capable of rendering mixed content type messages encoded in terms of standard HTML CSS tags. It is well known in the art how to convert different standard content element types to corresponding HTML CSS tags. In the case of the corresponding HTML CSS representation is shown in . Specifically text and is converted to tags and and . Any freeform digital ink path is converted to an tag . As illustrated in in one embodiment of the present application the page image data itself is encoded in Base64 as the src attribute of the tag. In an alternative embodiment the image data is stored on the VMail Cloud Service and a URL Uniform Resource Locator for the image data is placed as the src attribute of the tag. Any image object of the mixed content type message is converted to an tag . Any graphic object is converted to an tag . Typically CSS attribute positioning attributes are used to assign locations to the various content objects.

It is noted that certain figures include a statement that parts of Base64 code has been omitted for brevity. This omitted material does not affect the intended teaching of the present concepts.

In another embodiment of the present application a composed mixed content email message employs SVG tags as illustrated by reference to .

SVG Scalable Vector Graphics is a standard representation for communicating document content over the internet for display in web browsers. Under some circumstances email clients are capable of rendering mixed content type messages encoded in terms of SVG tags. It is well known in the art how to convert different standard content element types to corresponding SVG tags. It is to be appreciated that multiple ways of mapping from mixed content type objects to SVG tags are possible. are used to illustrate one embodiment. In the case of the corresponding SVG representation is shown in . Specifically text and is converted to SVG tags and . Alternative image renderings of text are also encoded. These take form as tags and which are grouped with their corresponding tags through the use of group tags and respectively. Digital ink is converted to an svg tag . Any image object is converted to an SVG tag . Some graphic objects can be converted to corresponding SVG tags while in other cases graphic objects such as the arrow of are converted to more generic tags .

In another embodiment of the present patent application a composed mixed content email message employs a sequence of text and image elements in the multipart MIME email transmission format. MIME is a standard representation for email messages that can include different types of content including plain text rich text and images.

For the example of the mixed content type message of illustrates a MIME encoding that standard email clients are capable of rendering such that the visual appearance of is substantially preserved in the screen image presented to email message recipients. The email message includes a multipart related section . This in turn refers to a multipart alternative section and one or more image jpeg sections . The multipart alternative section in turn refers to a text plain section and a text html section . In general the email recipient controls whether plain text or html text is displayed. Both the plain text section and html section intersperse text and image objects. In the terminology of the art images are displayed inline . In the embodiment shown in the image data is encoded as part of the message in Base64 format in the image jpeg sections and . In an alternative embodiment the image data is stored on the VMail Cloud Service and URLs are provided. For the purpose of inline intermixing of text and image content image data is given ID names and . These are referred to in the plain text and html text sections e.g. and .

It is to be appreciated the forgoing describes only one exemplary configuration of a MIME based message and other configurations of multipart MIME types are possible.

In an embodiment employing multipart MIME encoding individual text image digital ink and graphic objects from the original mixed content type message are not give different sections of the MIME message. Instead the message is converted to strips or bands of alternating text and image content stacked vertically. shows how the example of is decomposed into bands. Any horizontal strip of the mixed content type message that includes any image digital ink or graphic content anything other than text will be rendered as image format. Thus a line of text in the message that has a non text marking for example the encircling of a word will be transmitted as image content type of . Image and graphic objects are also transmitted as image content type of . Sections of the original message whose horizontal projections contain only textual material are transmitted as text of . Alternative embodiments are possible wherein textual message content that is eligible to be transmitted as text is nonetheless converted to image format. In the extreme under one embodiment of this application the entire message content is converted and transmitted as one or more image sections of a MIME encoded email message.

At step all non textual objects are considered and by a well known method of projection profiles it is determined whether any non text object intersects the current text object in horizontal projection. If so processing proceeds to step . If on the other hand the object consists purely of text that does not intersect any non text object in projection profile processing proceeds to step . At step plain text and html text versions of the textual matter are created. These are referred to as text blocks .

If the process on the other hand moves from steps or to step objects are rendered into bitmap objects and then at step these are converted to jpeg image format png format or any other format that may be accepted by email clients for inclusion in the multipart MIME message. These are referred to as image blocks. 

When all objects have been considered the iterator step passes processing to step . At step the list of text blocks and image blocks is sorted vertically by their topmost location. At step it is determined if the first block in the list is an image block. If yes processing proceeds to step . If not processing proceeds to step .

At step a text block is created that contains a reference to the image block following the example shown by and of . Step is an iterator that considers the remaining sorted blocks one at a time. At step the next block is popped. Step determines whether this is a text block. If so this text block is stored in a register at step and processing returns to the iterator . If at step the block is an image block and not a text block then the process moves to step to determine whether the register is empty. If the register is empty then processing returns to the iterator . If it is not empty then at step a reference to this image block is created for the text block in the register and at the register is cleared whereupon processing returns to the iterator . In this manner it is ensured that the image sections of the multipart MIME message created are all referred to by a preceding text block. Thereby the recipient s email client will render text sections and image sections in correct order preserving the layout of the sender s mixed content type message.

While it is understood that even others that are using an email service that is not a VMail Arrangement will obtain the VMail generated message with the content created by a VMail based system i.e. a third party does not need to employ the VMail Application to receive enhanced mixed content VMail emails . In one embodiment of the present teachings the VMail generated message further exploits the multipart MIME email format standard to provide enhanced functionality to email recipients who possess VMail enabled email client programs. In this embodiment an additional text plain section is added to the multipart MIME message. The section is given a special Content Type which by example is referred to here as VMail SVG . The text content of this section consists of the SVG encoding of the mixed content type message as exemplified in .

The VMail SVG section of the multipart MIME email message is generated by the VMail Application to gain access to the mixed content type objects the VMail message sender created and manipulated including plain text formatted text bitmap images digital ink and graphic objects. A recipient possessing a suitably enabled and authorized VMail Application or equivalent that is capable of parsing and rendering the SVG representation then presents these objects in the Message Composition Region in lieu of the sequential text sections and inline image sections of a standard multipart MIME rendering. It is to be appreciated that in some embodiments of the present application access to VMail SVG content is provided as an added value service or product.

In one embodiment of the present application the additional text plain section incorporates metadata about authorship and other attributes of text and enhanced content. Each text object image object digital ink object and graphic object is tagged with the user ID of the person who created or edited it. Then a document viewer such as the VMail Application exploits this metadata in order to support filtering selective viewing and selective re editing of the VMail message. This functionality enhances users ability to understand what comments or remarks were made by the various parties to an email thread built up in layers by multiple people modifying VMail generated messages.

A number of editing tools and processes have been previously introduced such as in the paragraphs related to and the paragraphs immediately preceding those paragraphs. The following discussion includes additional discussion regarding various ones of those tools and processes.

The previously introduced select and crop tool and process which is configured to select and crop image objects using rectangle drag or lasso drag without prior selection of mode is illustrated in one embodiment by reference to . This figure shows a flow chart illustrating the steps in rectangle drag and freeform path e.g. lasso selection methods of object selection. At step a mouse drag event is initiated. The user determines whether to utilize a polygon input mode at step . If the polygon input mode is selected the processor adjusts the current polygon vertex at step . If the polygon input mode is not selected a decision is made at step as to whether to select the path rectangle input mode. When the path rectangle input mode is not selected the processor at step determines whether an object has been selected. If an object has been selected it is moved at step . If an object has not been selected no action is taken. Returning to step if the path rectangle input mode is selected then an evaluation of the path is initiated at step . If a clear rectangle selection gesture is provided the processor displays the drag rectangle at step . If the selection gesture is a clear freeform path then the drag path is displayed at step . In those cases in which the selection gesture is ambiguous both the drag rectangle and drag path are displayed at step .

Freeform path selection gestures and enclosing rectangle selection gestures are both initiated by the same event a single mouse press not occurring over a selectable object. In this state the spatial characteristics of the gesture are analyzed to determine whether it has the characteristics of a freeform path a rectangle or either both. Depending on this analysis the path the rectangle or both are displayed.

Turning now to an embodiment of the select primitive object tool and process which is configured to select among multiple overlapping groups of primitive or primary objects is set forth.

The flow diagram of teaches a method for maintaining established group structure even while the user replaces source image material with typed text. The Primary Image Object e.g. Bitmap Objects which are to be replaced by typed text may in many cases participate in groups which are represented by Composite Objects. These groups should be preserved if possible even if the selected Bitmap Objects are removed and replaced with typed text. In this example typed text is entered into a display of an electronic computing device using a special kind of Bitmap Object called a Text String Bitmap Object. This is a Bitmap Object which is associated with a set of ascii characters plus typography information such as font family font size font color etc. The textual characters and typography information permit this Bitmap Object to be modified by the user in terms of its formatted textual appearance.

At step the input to the system may include Bitmap Objects with a group structure represented by a lattice of Composite Objects a Text String Bitmap Object TSBO and a listing of Selected Bitmap Objects the TSBO is to replace in the image display. At step a determination is made as to whether the selected image objects are comprised of a single Bitmap Object. If the selected image objects are not comprised of a single Bitmap Object then at step a Composite Object corresponding to the collection of selected Bitmap Objects is identified.

At step an Alternative Formality Relation is generated between the Composite Object and a new TSBO. At step the processor identifies those Composite Objects whose supporting Bitmap Objects include the entire set of selected Bitmap Objects as well as additional Bitmap Objects. The additional Bitmap Objects supporting each such Composite Object are identified as the non selected supporting Bitmap Objects. At step the processor removes the links from the non selected supporting Bitmap Objects and identifies these as historical links. The processor then creates a counterpart Composite Object whose support is the non selected supporting Bitmap Objects plus the new TSBO. At step the processor identifies Composite Objects whose support does not include the entire set of selected Bitmap Objects and removes the links to the non selected Bitmap Objects supporting these Composite Objects. These are stored as historical links to be restored in the event that the replacing typed text in the display is itself replaced by the original informal Bitmap Objects it replaced. At step the selected Bitmap Objects are removed from the display and the new TSBO is added to the display. If the selected image objects are comprised of a single Bitmap Object at step the processor creates an Alternative Formality Relation between the selected Bitmap Object and a new TSBO. At step the processor identifies each Composite Object supported by the selected Bitmap Object and replaces the support link to the Bitmap Object with a support link to the new TSBO. At step the processor removes the selected Bitmap Object from the display and replaces it with the new TSBO.

The result of the procedure described above is a reconfigured structure lattice whereby the TSBO replaces the selected Bitmap Objects in the list of displayed image objects visible in a display while groups involving the selected Bitmap Objects now become associated with the TSBO. This structure leaves historical links which preserve the information about the original groupings. This permits the TSBO to be exchanged and the original Bitmap Objects it replaced to be restored with all of their prior grouping structure. It will be noted that although the foregoing has been described with regard to replacing Bitmap Objects representing textual material with typed text represented in a Text String Bitmap Object this procedure applies as well to purely graphical or line art data thus enabling groups of image primitives to be replaced with Formal Graphic Objects while maintaining prior grouping relationships.

Attention is now directed to the previously introduced gesture interpretation tool and process configured to interpret mouse stylus finger gestures as either a lasso selection gesture or a stroke of digital ink. shows a flow diagram illustrating steps in a user interaction cycle of this tool and process.

Initially the user interaction cycle begins with the user initiating a gesture which could be either drawn digital ink content or a command selection gesture by pressing or touching the stylus pen or mouse. This occurrence is indicated by the processor passing a stylus down event or equivalent at Step . At Step a determination is made as to whether the system is in choice presented state by consulting a CHOICE PRESENTED STATE internal state variable. At the outset of user interaction this variable is initialized to the value FALSE. If at Step the CHOICE PRESENTED STATE is FALSE then the user s input is gathered until the stylus is lifted or mouse button is released. This input may be a stroke consisting of a series of mouse stylus locations or it may be a tap if the pointing device is lifted released at the same location where it was set down or the button was pressed. In the event that a stroke is being drawn at step this gesture may be rendered on the display as a tentative path such as a dotted line. When the gesture is completed various tests are then employed at step to determine whether a user gesture can be interpreted as an unambiguous draw operation an unambiguous selection operation or an ambiguous operation.

If the gesture is a tap located on top of or immediately beside an image object then it is interpreted as a selection gesture and that object is selected and processing proceeds to step . Repeated tapping at approximately the same location may be used to cycle through groups that this object belongs to. Servicing the selection at step involves highlighting or otherwise indicating which object s are selected and entering a state whereby further input gestures may be interpreted as move delete or other operations on the selected objects as is standard in the art. For example a pop up menu of operations may be presented for the user to select among including Move Delete Rotate Duplicate etc. Furthermore the selected object s may be highlighted and Move operations may be executed by pressing the mouse stylus on a selected object and dragging it. If the gesture is a tap not located on top of or immediately beside an image object then the gesture is interpreted as a drawn dot of digital ink and at step is rendered as such on the display and recorded as such in the displayed objects data structure.

If the gesture is a closed or nearly closed path that encloses or partially encloses at least one existing object then it is ambiguously a selection operation or a draw operation. Also if the gesture is a nearly straight line that approximately underlines textual image material or falls besides several lines of text then it is ambiguously a selection operation or a draw operation. It will be clear to skilled practitioners that other comparisons of the user s stroke with displayed image material can be devised for which the gesture can be interpreted either as selecting certain image material or else existing simply as hand drawn digital ink image content. In such a case processing proceeds to step . The internal CHOICE PRESENTED STATE state variable is set to TRUE and a choice is presented to the user as to whether to interpret the gesture as a selection operation or not. This may take the form of a pop up menu choose box in close proximity to the gesture.

If at step the processor determines that the gesture input at step is clearly a draw operation for example closed path strokes that do not enclose anything or open strokes occurring not in proximity to textual image material the program proceeds to step where the gesture is added as a new marking. Consider next the processing of user input gestures when the CHOICE PRESENTED STATE flag is TRUE at step and the display consequently contains a pop up menu choose box. At step the system makes a determination as to whether the gesture is a tap click inside the pop up choice box. If the gesture is a tap click inside the choice box then the gesture is interpreted as a selection operation the tentative path is erased and the program services the selection at step . If on the other hand the mouse stylus press is outside the choice box then the prior gesture is interpreted as drawn material. It is immediately rendered as such and entered into the displayed object data structure at step and the system continues to gather the path of the currently input gesture at step . From step when the pen is lifted the current gesture is evaluated at step as described above.

Thus the described tool and process provides the user with the ability to execute unimpeded sequential input of freeform strokes of many types rapidly and without making explicit choices about user interface modes or interpretations. The user can perform selection operations without first entering a selection mode. Instead a selection choice is presented but only after the gesture has been drawn and it is found to be ambiguous in intent. Although the present invention has been described in terms of draw gestures it will be noted that the present invention is not limited to draw gestures only. Additional commands can be recognized by their intrinsic characteristics and context for example a cross out erase command indicated by a scratch out gesture. This would cause an Erase menu button to pop up which could be pressed to erase crossed out material or ignored if the intent was to draw and leave on the canvas a cross out marking. Numerous other such examples will occur to those skilled in the art.

It is noted that within this discussion reference has been made to tapping clicking or otherwise selecting an object. The term tapping is generally used in reference to the physical act of touching a stylus pen or finger of a touch based computing system to the screen or tablet and shortly thereafter lifting the stylus pen or finger from the screen i.e. within a predetermined period of time without moving the stylus pen or finger any significant amount i.e. less than a predetermined amount as for example two pixels . This is a typical method of selecting objects in a touch based computing system. The term clicking is intended to be broader in scope and is intended to cover not only tapping but also the action of selecting an object using a button associated with a mouse track ball or touchpad as well as the selection of an object using any other pointer device.

Attention is now directed to the previously introduced automatic subdividing e.g. fragmentation or decomposition tool configured to provide automatic subdividing e.g. fragmentation or decomposition of image regions into smaller image objects on the basis of user selection operations. is a flow diagram illustrating one possible user interaction procedure in which Primary Objects may be split or fragmented through user selection. At step image material is selected by inputting a closed path selection to enclose the desired material from the Primary Objects. Although for the purposes of this example material is selected through use of a freeform path it is noted that multiple other means may be used such as rectangle dragging polygon selection selection of established primitive image objects with a single mouse click selection of established groups of image objects with multiple mouse clicks and editing of group structure by depressing a single pre specified key for example the shift key while performing selection operations.

The desired material may contain one or more objects such as text characters and words or other shapes. At step the processor detects the Primary Objects intersected or enclosed by the selection path and identifies them as the affected Primary Objects. The affected Primary Objects bitmaps are broken into fragments according to the selection path at step. The bounding box size of each of the fragmented Primary Objects is reduced to the minimal bounding box size of the foreground material for each fragmented Primary Object at step and fragments containing no foreground pixels are eliminated. At step the processor gathers the fragmented Primary Objects and non fragmented affected Primary Objects enclosed by the selection path to form enclosed Primary Objects.

The use of bitmap type Primary Objects is improved by the step of of performing automatic image processing to render background regions of the image transparent. Typically the background in a document image is the color of paper or a blank canvas which is normally white or nearly white. In selecting and re arranging bitmap type Primary Objects on the canvas the user will find that background pixels can occlude the foreground markings of interest. Therefore it is beneficial to apply image processing to detect background pixels and render them transparent in the electronic bitmap image. This way foreground objects can be put in close proximity and remain fully visible without occlusion by surrounding background pixels. In one embodiment at step of a machine learning classifier well known in the art is applied. The classifier is trained to distinguish between document type images which contain foreground graphic markings against a uniform or near uniform background versus photographic images. Automatic image processing to set background pixels transparent is applied only to those images that are classified as document images not to photographic images e.g. bitmap images of document pages versus bitmap images of photographic scans .

The processor then creates a new provisional Composite Object representing the group of enclosed Primary Objects at step . At this point the user has performed a selection operation and the system completes its tasks and at step pauses for receipt of a next command. At step a determination is made as to whether the next command establishes a group. If a group is not to be established the processor discards the fragmented Primary Objects and the provisional Composite Object at step . If a group is to be established the fragmentation is accepted. The processor then removes the affected Primary Objects from the original Primary Object List and adds the fragmented Primary Objects to the Primary Object List at step . At step the processor locates Composite Objects supported by the affected Primary Objects. For each such Composite Object the processor replaces its support by the affected Primary Objects with support links to enclosed Primary Objects.

Attention is now directed to text reflow concepts incorporated into the disclosed VMail Arrangement. It is understood however that the following concepts may also be implemented in environments other than the presently disclosed VMail Arrangement such as but not limited to other electronic document forming and editing environments.

The issues to which the present concepts are directed involve the creation and editing of mixed content type documents containing both running text and graphical objects which includes but is not limited to images drawings structured graphics digital ink and text. Graphical objects thus encompass what are conventionally known as figures in documents. Document authors desire to achieve document layout which is both logically meaningful and visually pleasing. Figures need to be placed in correct juxtaposition to the running text that refers to them. Running text requires text to reflow to maintain column width and avoid overlap with figures. To be easily readable and visually pleasing text lines must have a minimum width. Graphical objects require that text which is part of the graphical objects stay where the user entered them relative to other elements of a graphical object or figure and thus not be subject to reflow. These behaviors can be at odds with one another. The following presents teachings in connection with which reconcile these conflicts.

With attention to illustrated is a document authoring and editing tool or process . The tool or process employs an Automatic Hybrid Reflow Routine which presents a user interaction design that among other aspects encompasses the following features i Distinctive Treatment of Narrative Versus Annotative Text Routine ii Localized Application of Text Reflow Routine and iii Automatic Determination of Vertical Jumps Routine . Any one or a combination of these features may be applicable to any given document depending on the document s content. It is to be appreciated that in some embodiments the fully automatic aspects of the Automatic Hybrid Reflow Routine may be modified to include deliberate user intervention to set conditions and parameters of the method manually and thus become semi automatic. B and the associated discussion expand upon the document authoring tool having aspects summarized by .

A specific aspect of the present teachings is a feature known as Distinctive Treatment of Narrative Versus Annotative Text Routine . Narrative text is subject to automatic reflow while annotative text stays where the user placed such text relative to local coordinate systems where the local coordinate systems of graphical objects can be translated with respect to the global system of the entire document. It is to be understood that narrative text and annotative text refers to what a user intends to put in an electronic message and what is instantiated by a program configured according to present teachings.

Providing some background it is known that WYSIWYG What You See Is What You Get User interfaces for document editing follow one of two models for placement of text and figures flow formatting and absolute positioning . A standard WYSIWYG text editor such as Microsoft Word uses flow formatting to cause text layout to conform to a predetermined design. Text is laid out in one or more columns that extend through one or more pages. Text may be inserted or deleted anywhere but at each such operation the locations of other text elements i.e. words are repositioned to adhere to the layout format. In enhanced versions of flow formatting text editors images and figures may be placed within the body of the text and text will be positioned automatically to flow around the images and figures.

A standard graphics editing tool such as Microsoft PowerPoint or Adobe Illustrator use absolute positioning whereby text and image objects remain where they are placed by the user. In some cases an absolute positioning editor may incorporate a limited amount of flow formatting for text objects. But the placement of the text object itself is fixed wherever the text object is placed by the user. For example in PowerPoint a user can create a text object and place it on a canvas of an electronic display. Then for example the user can grab a right side of the text graphic and change the width and the text will reflow in a limited amount. However the text object would remain fixed i.e. the left side edge or location of the text object would not be moved. Thus in contrast to a full narrative text editor in a structured graphics editor such as PowerPoint the reflow is constrained to the text object affected and does not propagate to other objects on the canvas.

Under existing practice if a user wishes to author a document containing text interspersed with graphical objects they use a structured graphics editing tool or a photo editing tool to create individual graphical objects or figures and a separate WYSIWYG text editing tool to position such graphical objects within the text document. In some cases it is possible to invoke a structured graphics editing tool or photo editing tool from within the text editing tool but any textual or graphic objects are constrained to the page region defined by the structured graphics editing tool or photo editing tool.

This situation is less than ideal for anyone wishing to place graphical objects at arbitrary locations within the running text of a document and have the running text flow around not overlap such graphical objects where the graphical objects include but are not limited to images structured graphics digital ink and text. An example situation where this more flexible type of authoring would be preferred is in the presently disclosed Visual Email e.g. VMail . As has been described with VMail a user is allowed to compose a narrative text message that incorporates excerpts from email attachments or other shared documents including drag and drop of graphical objects into the body of the VMail email message and including entry of text as annotations or captions to these graphical objects.

Attention is now directed to a more detailed discussion of the present methods and systems for distinctive treatment of narrative versus annotative text in text reflow.

It is understood from the foregoing that in the presently described VMail Application includes at least the following elements 

 iii A caret or other visible cursor indicating a reference location for various operations including text placement and paste location for document objects.

 iv A controller which responds to user interface commands and causes changes to the content of the canvas changes to layout of objects on the canvas and changes to the internal structure of document objects.

The controller manages receipt of mouse and keyboard events whereby the user conducts these operations. Methods for performing the above mentioned operations are well known in the art and are embodied by many available applications.

In an image object rectangle with X is adjacent to two paragraphs of text . An arrow indicates a small translational re positioning of the image object caused by a user action such as a mouse drag. shows the desirable behavior wherein after the repositioning the text has reflowed around the image object .

In an image object rectangle with X is adjacent to two paragraphs of text . An arrow indicates a large translational re positioning of the image object caused by a user action such as a mouse drag. shows the desirable behavior that after the repositioning text has reflowed to create a vertical gap to create space for the image object . Consequently some text has moved downward.

In an image object rectangle with X has been placed within a spatial gap amongst paragraphs of text and a textual annotation has been placed on top of the image object. An arrow indicates a small translational re positioning of the image object caused by a user action such as a mouse drag. shows undesirable behavior which would occur if text is always caused to reflow whenever it would otherwise overlap or collide with an image object. The annotation text has been repositioned below the image object . This is undesirable because it is no longer positioned where the user originally placed it with respect to the image object and the user s layout intent has been violated.

In an image object rectangle with X has been placed within a spatial gap amongst paragraphs of text and a textual annotation has been placed on top of the image object . An arrow indicates a small translational re positioning of the image object caused by a user action such as a mouse drag. shows desirable behavior. The annotation text remains in place and has not been automatically repositioned to a more distant location in order to avoid overlap with the image object . The user s layout intent is therefore maintained.

The classification of text as narrative or annotative can be done under user control while interacting with a computing device or automatically. In one embodiment of the present disclosure a text object is automatically classified as narrative text if its left edge is placed within a predetermined distance from the left edge or margin of the canvas. Otherwise it is classified as annotative text.

In one embodiment of the present disclosure as shown in visual indicators are added to canvas of an electronic user interface display to aid the user in appreciating the text object s classification. In this embodiment text indicators are shown as vertical lines positioned at the left margin alongside the vertical extent of text objects . It is to be understood in other embodiments the visual indicators can take other forms. Further the visual indicators can be added to identify narrative text annotative text or both.

The reflow system and method being disclosed is concerned with text reflow namely when and how the controller causes text to reflow or adjust position on the canvas in response to various user commands. It is desirable for text to reflow automatically to avoid overlap with figural elements yet also for text annotations and captions for figural elements to maintain a relatively fixed layout with respect to those elements and hence not to be subject to reflow. illustrates the relevant behavior. We herein disclose a feature known as Localized Application of Text Reflow.

Because of the reflow feature narrative text objects become taller or shorter and move up and down subject to user operations of insertion and deletion of text and figural objects. It is necessary for elements of the document to move in synchrony and maintain correct vertical spacing. The foregoing will be described in more detail in connection with .

In all document objects maintain an internal parameter called herein y space to datum . The y space to datum parameter indicates the vertical distance to the bottom of the vertically closest narrative paragraph. The bottom vertical location of each paragraph is considered a datum or reference vertical position for objects lying below the paragraph. In two narrative text objects are shown. The bottom of each one defines a y datum . All document objects maintain a y space to datum value which is the vertical distance to the nearest y datum reference above.

Whenever text is reflowed document objects adjust their vertical position so as to maintain the distance y space to datum with respect to the narrative paragraph object immediately above it. By this strategy the various document objects comprising figures are able to maintain their relative vertical positioning and hence maintain the layout intent of the author.

Flow diagrams and illustrations related to the flow diagrams for carrying out the present processes are shown by .

At Step it is determined whether one or more document objects acted on modified by the user command is a Text Object. If so i.e. YES the location and optionally other properties of the Text Object are assessed to assign the text a status of being Narrative Text or else Annotative Text . In one embodiment the distance of the leftmost edge of the Text Object to the left margin of the canvas is compared with a predetermined threshold to determine if the text is narrative or annotative e.g. if meeting the threshold the text is annotative and if outside of the threshold the text is annotative .

At step a routine Recalculate Layout which recalculates the page or document layout is applied to the document taking into account a status of the modified text object as being one of a narrative text object or an annotative text object. Thereafter control returns to step where additional user commands are received.

If at step it is determined the modification does not include a text object i.e. NO the process moves directly to the Recalculate Layout routine of step and thereafter control returns to step .

At step document objects are sorted in a list ordered by vertical position of the top of the object s bounding box. The topmost or highest object in the document is placed first in the list and bottommost object is last where the top of a document and the bottom of a document is used here as is commonly understood . At step it is determined whether to recalculate datum distances of document objects. Under most user operations datum locations are re assigned but under some operations they are not. For example under a cut or paste operation some embodiments may determine not to reassign datum locations. In this way in accordance with the subsequent steps in particular reposition all document objects below current narrative text object objects will be repositioned to fill or expand vertical spacing for the cut or pasted document objects.

If it is determined to recalculate datum distances YES then at step the document objects assign their internal parameter i.e. y space to datum and as shown in .

At step a list of obstacle document objects is created. This list is transient and exists only for the remaining duration of the Recalculate Layout routine. The obstacle list contains objects that narrative text type Text Objects must flow around. Each document object that is of type Image Object or Annotative Text is added to the obstacle list.

At steps and document objects are considered sequentially from top to bottom as they were vertically sorted at step until no more document objects are in the sorted list and the routine is exited at step . In step a determination is made if the document object is a narrative text object such that only Narrative Text Objects are considered at step . At step the Narrative Text Object is reflowed around obstacles in the obstacle list according to a routine identified as Reflow Narrative Text Object e.g. see . The result of this reflow operation may cause the narrative text object to grow or shrink in height.

Therefore at step all objects falling below the current narrative text object are adjusted in vertical position to maintain their distance y space to datum with respect to a reference vertical position. In this embodiment we define and assign the reference vertical position for each object falling below the current narrative text object to be the bottom text line of the closest narrative text object above itself e.g. see reference vertical position shown as y datum in the figure .

By this means when reflow takes place with regard to document objects acted upon modified by the user certain obstacle document objects will have narrative text reflow around them while obstacle document objects lower on the page will be translated vertically in synchrony with the surrounding narrative text.

In another embodiment this same goal is achieved with the use of a single narrative text object containing all narrative text in the document. In this case reflow of the narrative text object occurs with respect to the document objects acted upon modified by the user as described above. But at some vertical location in the document a reference vertical position is established and assigned to all document objects falling below this location. Typically this reference vertical position occurs at a paragraph break but it can be set at the vertical location of any text line below the document objects being acted upon whose character content does not change due to reflow of the narrative text object around the obstacle document objects.

Turning to the routine Reflow Narrative Text Object is set forth. The purpose of this routine is to place the characters comprising a text object into a sequence of text lines so as to avoid overlap with obstacles. The input to the routine is the sequence of characters of the narrative text object. Normally the characters will be organized as a sequence of words separated by spaces.

It is desirable that under some conditions narrative text flow around graphical objects such that text lines are of shortened width placed in horizontal juxtaposition to graphical objects yet under other conditions successive text lines maintain full width and jump vertically to create a full width gap to make room for one or more graphical objects. For example often a small image is placed toward the left side or right side margin of text in which case the text would be intended to flow around the figure. While in another case a figure is positioned near the centerline of the text in which case the intent is to have the text jump to below the figure s location. Further it is desirable for a user to achieve these effects without having to manually set a reflow mode in the interface. To accommodate this user intent we herein disclose a feature known as Automatic Determination of Vertical Jumps.

At step the routine Find Next Viable Text Line Position is called. This routine examines the target location of the first and on subsequent calls subsequent text line s . A viable text line position is defined in some embodiments as a bounding box or rectangle that does not overlap any obstacles and that meets predetermined minimum width and centering conditions as described below. At this step a location for the current text line is established.

At steps and characters are considered sequentially to build the textual content of the current text line. At step it is determined if by adding the current character the text line s width would fall within or outside the limits of the current line s bounding box as determined at step . If by the addition the character does not extend outside the bounding box then the character is added step and control proceeds from step to step where the next character is considered. If the addition of the character would cause the text line to extend outside the bounding box then control proceeds from step to step where a bounding box is found for the next text line in the sequence. If at step all characters have been considered then processing exits at step .

It is to be understood that alternative versions of the Reflow Narrative Text Object may also be implemented. Specifically groups of characters comprising words will be considered at step . If any part of the word would fall outside the bounding box of the current text line then a new next line is started.

Obstacle document objects obstacles may have been placed by previous user actions in locations that intersect bounding box representing the target text line position and width . In however it is apparent that the obstacles do not intersect the placement of the bounding box and in the next viable text line position stippled region is determined to be in congruence with the target text line position.

Therefore the viable text line position represented by bounding box may be established at this vertical location but inset from the left margin. This is shown in where a predefined inset distance from the obstacle establishes the leftmost side of the next viable text line stippled position .

By this arrangement the user is able to achieve two kinds of reflow automatically without having to specify manually or a priori which one they intend. One kind of reflow has narrative text wrap around obstacle document objects such that narrative text and obstacle document objects are horizontally juxtaposed. The other kind of reflow creates full width gaps in the placement of narrative text with obstacle document objects inserted between. The determination of which kind of reflow will take place is made by virtue of the user s positioning of obstacle document objects i.e. image objects graphic objects annotative text . When the obstacle is placed nearer the right or left margin of a paragraph of narrative text wrap around reflow occurs. When the obstacle is placed nearer the vertical centerline of the paragraph narrative text reflow automatically switches to creating a full width gap.

The VMail application provides a user with a system and method to compose a mixed content message which will in general include multiple types of operations and which may be accomplished via a keyboard a mouse a stylus pen a finger and or a voice input system.

Most of these operations can be accomplished with a pointing device or pointer i.e. a computer mouse touchpad electronic pen stylus or finger on the touchscreen of a tablet computer. A problem arises in that the same primitive operations of pressing touching dragging the pointer across the screen and releasing raising must be interpreted in different ways at different times in order to execute the detailed commands of each task operation.

The prevailing method for handling this problem is to introduce user interface modes. Typically a menu item selection or button on a toolbar is used to place the system into an operation specific mode. For example when in DRAW mode pressing touching and dragging the pointing device will cause a stroke of digital ink to be placed on the canvas. When in REGION SELECT mode the identical gesture of pressing touching and dragging the pointing device will define a rectangular region and objects within the region will become selected. When in LASSO SELECT mode the same identical gesture of pressing touching and dragging the pointing device will define a freeform boundary region and objects within the region will become selected.

There are at least three disadvantages of multiple mode or modal user interfaces. First they require an extra step for users. Second users have to remember to enter the correct mode before performing an operation and this incurs distraction and cognitive load. Third when users forget to enter the intended mode their pointer actions end up performing undesired actions that disrupt the workflow and must be un done or otherwise corrected. Further discussion of this topic can be found in Eric Saund and Edward Lank Minimizing Modes for Smart Selection in Sketching Drawing Interfaces in J. Jorge and F. Samavati eds. Sketch based Interfaces and Modeling Springer 2011 pp. 55 80.

Previous work has shown that certain user interface design features can alleviate many of these difficulties. One such method called Overloaded Loop Selection is taught in U.S. Pat. No. 7 086 013 Method and system for overloading loop selection commands in a system for selecting and arranging visible material in document images. Under this method either a rectangular selection region or a lasso closed or nearly closed path selection region can be entered without the user having to specify a priori which they intend to use. The method works by analyzing the shape of the gesture path. Aspects of these concepts have for example been previously discussed in connection with .

Another such method called the Inferred Mode Protocol is taught in U.S. Pat. No. 7 036 077 Method for gestural interpretation in a system for selecting and arranging visible material in document images. Under this method either a digital ink stroke or a selection lasso may be drawn by a pen stylus gesture without the user having to take steps to cause the system to enter a user interface mode in advance to indicate which they intend to do. Instead after completion of the gesture the system conducts processing steps to consider the existence of selected objects and the geometric properties of the gesture in relation to objects on the canvas. If these factors indicate that the user s intent is unambiguous then that action is taken. If the user s intent to draw ink versus select objects is ambiguous then a pop up Choice button is presented which the user may elect to press or not. If they press the button the canvas content enclosed by the gesture is selected. Otherwise the gesture is converted to a digital ink object which is added to the canvas. Aspects of these concepts have for example previously been discussed in connection with .

It is desired to enhance the user interface design so as to further increase the ability of the user to perform a variety of operations without prior specification of a user interface mode. Furthermore it is desirable for the same user interface actions to apply uniformly across pointer device types. In particular the Overloaded Loop Selection method is favored for mouse pointer and touchpad pointer devices desktop and laptop computers while the Inferred Mode Protocol is favored for pen stylus finger pointer devices mobile phones and tablets .

The following discloses an Enhanced Inferred Mode Protocol that enables the input of digital ink selection rectangle or selection lasso without prior specification of mode on a mouse pointer device an electronic pen stylus pointer device or other appropriate pointer device. The Enhanced Inferred Mode Protocol relies on improved methods for inferring user intent and expansion of a post action user Choice button. It is understood the enhanced inferred mode protocol is applicable to environments beyond the present VMail implementation such as other electronic document generating and editing environments.

The disclosure of the Enhanced Inferred Mode Protocol is presented in concert with . The computer program that implements the method has entry points corresponding to mouse touchscreen or other appropriate command entry device events including PRESS or TOUCH DRAG RELEASE and MOVE.

As shown by illustration of common to similar user interfaces operating system software enables a low level state machine that cycles between a POINTER UP state and POINTER DOWN state . In POINTER UP state pointer events indicating movement of the pointer may be detected and transmitted by the operating system in the form of MOVE events . Also in POINTER UP state the pointer may be pressed mouse press or pen stylus finger touch triggering a PRESS event in which case the system enters POINTER DOWN state . In POINTER DOWN state the pointer may be moved which triggers DRAG events but leaves the system in POINTER DOWN state . Or the pointer may be lifted stylus pen finger or released i.e. mouse triggering a RELEASE event and transition to the POINTER UP state. The Enhanced Inferred Mode Protocol amplifies the task level consequences of these primitive events by taking into account additional information.

Considering flow diagram of when in POINTER UP state and a PRESS or TOUCH event has been received the system determines whether a Choice option has been presented to the user. If YES and the location of the PRESS event occurs at one of the Choice option locations for example on a popup context menu button then the action indicated by the selected choice option is performed and the process enters a state of operation as determined by the chosen action . The actions may include but are not limited to interpreting the just completed stroke drag gesture as digital ink interpreting the just completed stroke drag gesture as a lasso selection region interpreting the just completed stroke drag gesture as a rectangle drag selection region.

If the location of the PRESS event is not on a Choice option location NO then the location of the press event is considered in relation to objects on the canvas of the electronic display .

If the PRESS event is over a selectable object or set of objects YES then the selected object and or sets of objects may be modified i.e. object s may be caused to be selected to be deselected or to cause other objects to become selected or deselected according to group membership as described in U.S. Pat. No. 6 903 751 System and method for editing electronic images. Accordingly the system may enter an OBJECTS SELECTED state .

Turning attention to flow diagram of and where the pointer is in a POINTER DOWN state a DRAG event is processed according to the steps of the flow diagram .

If the system is in an OBJECTS SELECTED state YES then the drag event causes selected objects to be translated i.e. moved across the canvas .

If the system is in DRAW GESTURE state i.e. objects have not been selected NO at step then steps are taken to ascertain user intent. The characteristics of the drag gesture are considered in relation to other objects on the canvas i.e. score gesture interpretations are undertaken. In particular in one embodiment a score or probability is assigned to each of three cases whether the gesture thus far is likely in user intent to be a rectangle selection a lasso selection or entry of digital ink. Multiple factors known in the art can be used to assess likelihood of user intent including length of the gesture wiggliness of the gesture calculated for example by sum square curvature aspect ratio of the gesture whether the gesture encloses any objects on the canvas expected size of hand drawn text on the canvas. These factors are in at least one embodiment combined in a machine learning classifier trained by training samples as is well established in the art. Please refer to Rubine D. 1991 Specifying gestures by example Proc. SIGGRAPH 1991 New York ACM Press 329 337.

For each of the gesture interpretation possibilities rectangle select lasso select digital ink if the assigned score is above or otherwise meets a predetermined threshold then a visual indicator of that intent is presented on the electronic display .

Considering flow diagram of a Pointer RELEASE Event is processed in a manner initially similar to a DRAG event. The completed gesture stroke is evaluated in relation to objects on the canvas of the electronic display. If the process is in a state of the selected objects YES then the process is exited . If the process is not in a state of the selected objects NO the process moves to a score gesture interpretation step . In this step scores are assigned to identify the likelihood the user intent is that the gesture is rectangle selection lasso selection or a drawing of visual ink. Based on these scores an ambiguity test is undertaken . If the best scoring candidate under an ambiguity test NO i.e. no ambiguity out scores other candidates by a predetermined threshold amount then the process moves to step . At step it is determined whether the gesture that has the unambiguous intent is a selection operation or not. If YES then the enclosed objects are selected at . If not NO then the gesture stroke is accepted as a digital ink object at .

If however the ambiguity test is not conclusive YES then a post gesture Choice option is presented to the user so that the user may unambiguously indicate their intent. By default one of the options will be chosen if the user presses the pointer in the background.

In this manner a user interface protocol is made available that is common to mouse touchpad pen stylus and finger or other pointer interface devices that enables semi automatic disambiguation of rectangle selection lasso selection and digital ink entry operations without prior selection of mode.

In another embodiment of the present application upon the RELEASE event and determination of ambiguous user intent for the just completed gesture stroke the candidate selection is shown with a background highlight region along with the candidate digital ink stroke.

Subsequently if at Step of the user presses in a highlighted background region the selection is accepted and selected object translation is enabled by virtue of entering the Objects Selected state as at step . Alternatively if at Step of the user presses elsewhere on the canvas a digital ink stroke is created and placed on the canvas corresponding to the just completed gesture stroke.

As a further embodiment of the present disclosure presents a method for semi automated entry of structured graphic objects .

More specifically after a digital ink entry is accepted e.g. or step of the gesture stroke is further evaluated e.g. scored to determine whether the stroke matches a shape model for one of a predetermined class of graphic objects . These shapes may include but are not limited to Rectangle Square Circle Ellipse Diamond Arrow. Techniques for scoring matches of digital ink strokes according to such categories are known in the art. If the score for any graphic object category does not meet a predetermined threshold i.e. clear match NO then the stroke is kept as digital ink . If the score meets a predetermined threshold YES then an overlay image of the structured graphic object is presented on the electronic display and a Choice option is presented to the user. If the user selects to confirm the choice option then the digital ink stroke is replaced by the structured graphic object. The choice is selected or discarded at a PRESS event at Step of .

It will be appreciated that variants of the above disclosed and other features and functions or alternatives thereof may be combined into many other different systems or applications. Various presently unforeseen or unanticipated alternatives modifications variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims.

