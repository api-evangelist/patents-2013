---

title: Increased parallelism performance of batch requests
abstract: A system selectively dequeues journal requests instead of dequeuing on a first come, first served basis. A database system detects that a request for access from a client is a journal batch, which includes multiple journal requests. The system queues the journal batch in a queue with other journal batches for processing. The system selectively dequeues journal requests from the journal batch queue, including selecting at least one journal request from multiple different journal batches. Thus, the journal requests do not conflict for shared resources, and the system can improve parallelism in processing the journal batches.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495411&OS=09495411&RS=09495411
owner: salesforce.com, inc.
number: 09495411
owner_city: San Francisco
owner_country: US
publication_date: 20130920
---
This application is a nonprovisional application based on U.S. Provisional Patent Application No. 61 704 788 filed Sep. 24 2012 and claims the benefit of priority of that provisional application. Provisional Application No. 61 704 788 is hereby incorporated by reference.

Embodiments described are related generally to database requests and embodiments described are more particularly related to increasing parallelism of processing batch requests.

Portions of the disclosure of this patent document may contain material that is subject to copyright protection. The copyright owner has no objection to the reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever. The copyright notice applies to all data as described below and in the accompanying drawings hereto as well as to any software described below Copyright 2013 Salesforce.com Inc. All Rights Reserved.

User s store data in database systems to organize large amounts of data. There are many commercially available database systems that have tools to help users to store organize and retrieve data of interest. In a database system users access the database by making requests to access the database. The requests can be to read write or modify data in the database. In certain database implementations a user can generate requests in batches. A batch is a group or set of requests. Batch requests allow a user to submit a single request transaction and cause the database to access multiple different records. Thus batches allow for much greater access efficiency for the user.

In certain applications with database systems a user generates multiple batch requests for a database system to process and the requests are queued and processed one at a time. The database system architecture may allow for multiple different processing managers to operate in parallel by receiving and processing different requests. However when the managers access jobs from the same batch collisions can occur. A collision refers to a scenario when multiple managers attempt to lock the same resource when processing a job. The collisions traditionally require one manager to wait for the resource to become available before another manager can access it. Thus even when a database system architecture allows for parallel processing managers to operate in parallel on batch jobs the fact that the jobs are in batches can prevent actual parallel operations. The lack of parallelism can exist even when there are hardware processing resources available to perform the operations.

Descriptions of certain details and implementations follow including a description of the figures which may depict some or all of the embodiments described below as well as discussing other potential embodiments or implementations of the inventive concepts presented herein. An overview is provided below followed by a more detailed description with reference to the drawings.

As described herein a system selectively dequeues journal requests instead of dequeuing on a first come first served basis. A database system detects that a request for access from a client is a batch request which includes multiple separate requests. The system queues the batch in a queue with other batches for processing. The system selectively dequeues individual requests from the batch queue including selecting at least one request from multiple different batch jobs. Thus the requests do not conflict for system resources and the system can improve parallelism in processing the batches.

In one embodiment the batch requests are associated with a journal application of a database. For example Oracle General Ledger GL is a module within Oracle Applications. It will be understood that all trademarks used herein are the property of their owners and are used herein solely for purposes of identification of an example and do not imply any rights on the part of the applicant. Oracle GL and Oracle Applications are trademarks of Oracle Corporation Redwood Shores Calif. The users of an Oracle GL module create journal entries to record various transactions. The journal entries can be grouped into batches called Journal Batches. Each batch in a journal batch includes three information components batch header and lines. In a typically GL implementation the three information components are stored in three separate tables the batch information in a table GL JE BATCHES the header information in a table GL JE HEADERS and the line information in a table GL JE LINES. Users can also reverse the journal entries to reverse previously entered transactions. In addition to reversing the individual journal entries the users can reverse an entire journal batch.

When a user reverses a journal batch Oracle GL submits multiple concurrent Reverse Journal requests for reversing a single journal batch. All the requests are submitted to a concurrent job processing queue. The queue can have multiple managers that can be run concurrently e.g. 100 managers . In one embodiment each batch has a separate row in the table GL JE BATCHES. However it will be understood that during execution of each separate request of the batch all managers executing requests from the same batch will try to capture a lock on the same row. In a default implementation the requests are executed on a first come first served FCFS basis. In the example where 100 managers execute concurrently or in parallel the FCFS implementation can easily result in all 100 managers concurrently executing requests from the same batch for relatively long periods of time. Each manager would need to wait for the manager that currently owns the lock on the table row or other shared resource or system resource to release the lock. Thus a 100th running request would have to wait for all previous 99 requests to be executed by managers that that owned the lock or requested the lock prior to the 100th manager. Such a wait time can significantly affect performance time and efficiency.

A job queue manager can include a dequeue agent that allows the processing managers to dequeue and process requests from multiple batches in a batch queue in a way that improves parallelism. In one embodiment the queue allows the system to apply a hold and an unhold referring to removing a hold from a request previously put on hold to individual requests within the batches. In one embodiment the system selectively holds and unholds requests to cause the processing managers to dequeue requests from different batches. By selecting requests from different batches the system can reduce the number of processing managers executing requests with resource collisions.

In one embodiment the database system that receives and processes the requests is a multitenant database. The multitenant database provides a cloud architecture that allows a user to query for data in a modern database system. As referred to herein a multitenant database stores data for multiple client organizations which are each identified by a tenant ID. One or more users can be associated with each tenant ID. The one or more users of each client organization access data identified by the tenant ID associated with the respective client organization. The multitenant database is typically a database stored and hosted remote from the client organization. Typically the multitenant database is hosted by an entity e.g. company separate from the client organization. A multitenant database system MTS as described herein can be said to provide on demand database services. An MTS is typically a hosted system that provides as much database storage and service as required by each tenant.

In an MTS implementation each tenant ID may have a set of data associations and relationships. Thus a query on the MTS for one tenant ID may produce different results than the identical query on the MTS for a different tenant ID. In one embodiment the architecture of each tenant ID develops separately with custom configuration for each tenant such as custom objects and custom indexes. For example a UDD user defined database may be implemented for each tenant to store relationships and categorization data. It will be understood that typical database technologies will not necessarily apply to operations in an MTS.

User device represents any type of client device that may access a server system for example a desktop or laptop computer a tablet smartphone server or other computing device. Network includes any type of network access that allows user device to access database system . Network may be or include any one or more networks such as local or wide area networks wireless or wired encrypted e.g. virtual private network VPN or open on any of a variety of know or proprietary protocols or other network. Network is understood to include hardware and software components to enable remote connection of one device to another.

In one embodiment database system is or is part of an on demand database environment. As an on demand environment database system can provide to user device the quantity of database resources needed and when they are needed. As such database system can appear as a scalable database resource to user device . In one embodiment database system has at least one aspect of its configuration that is configurable and scalable for different tenants. It will be understood that fundamentally data stored is simply data. A database such as database is a framework of how that data is stored structured and interpreted when stored and accessed. Thus a database may be considered in one embodiment as a set of rules and procedures for storing accessing and manipulating data.

Each batch request generated by a user device can be identified e.g. via a header or identifier or other information as a batch request. Server can place batch requests for access to database into job queue by default based on the type of the batch request. In one embodiment database includes a journal and requests can be for reverse journals. A journal refers to a ledger or other set of structured data. Data can be entered into a ledger by journal requests and or journal batches a collection of journal requests . Entries in a ledger can be removed e.g. to eliminate data and or to move it from one ledger to another using reverse journals which are reverse operations or operations that reverse journal request transaction or journal batch transactions.

Journal requests and or other database requests can be queued in job queue . In one embodiment job queue is technically part of the implementation of database rather than part of the implementation of database system . Thus database system can include a database implementation that includes job queue . In one embodiment database is an Oracle GL database which includes a default queue e.g. a Standard Manager Queue to store batch requests. In one embodiment job queue is or includes the default queue. Database can include multiple parallel processing managers not shown in system to process the requests from job queue . In one embodiment database and job queue are implemented as separate instances for each tenant of database system .

In a typical implementation each batch is submitted to job queue one at a time as received from server s . Each later submitted batch waits for previously submitted batches to be processed before being processed by database . In one embodiment database system includes job queue manager which is an agent or module or other executable that can alter the way job queue is executed on by database . In one embodiment manager includes PL SQL code executing on the database level of applications associated with database e.g. implemented on the Oracle Applications under APPS user account . In one embodiment database system invokes manager when server detects a specific type of request e.g. a reverse journal batch . In one embodiment manager exits when there are no more reverse journal batch requests to be controlled and released from job queue or a concurrent job queue system.

Manager can change the way jobs or requests are dequeued from job queue . Thus in one embodiment manager can operate in addition to or in conjunction with a default dequeuing mechanism of database . In one embodiment manager can replace a default dequeuing mechanism of database . Manager causes the system to dequeue requests from different batches instead of the default behavior of finishing an entire batch before beginning to pull requests from a subsequently received batch. Thus the different requests executed by the processing managers come from different batches which can reduce or eliminate contention for shared resources such as rows of a table. Each processing manager can then lock different resources and operate in a more parallel fashion.

System includes queue which can be one example of job queue of system . Queue includes multiple batch jobs . It will be understood that an actual implementation could include dozens or hundreds of batch jobs queued for processing. For simplicity in illustration only a small portion of queue is illustrated. Queue holds pending requests waiting to be picked up by a manager . Queue includes an indication of the timing of receipt of the jobs where job was queued at some arbitrary time t relative to the other queues and time increases to the left i.e. job was received subsequently to job and prior to job which in turn is received subsequently to job and prior to job .

Each job includes multiple individual requests where each request represents an access operation to execute on database . Table stores data that managers use to access data in database . Table is shown having rows . . . . There can be any number of rows and columns in table . The rows in table can provide information to identify specific data in database . In one embodiment table or the rows of table are shared or common resources that managers lock to maintain synchronization of data of database . However the locking by one manager can cause other manager s to have to wait until a particular row is unlocked to access the same row.

Managers represent processing managers of system . Assume for the sake of discussion that manager is a first available manager is a next available manager down to N which is the last manager that is or will be available to process requests currently queued in queue . Manager N is illustrated as currently being busy processing a request that accesses row in table . N can be any number depending on available hardware resources e.g. hardware processing resources memory network bandwidth or other resources . Managers are typically executed in an implementation where they share hardware resources. The number of managers N can vary dynamically over time depending on a workload coming from queue a priority of work in queue relative to other work in the database system and or an amount of hardware resources allocated to managers .

Managers receive requests dequeued by dequeue engine and process the requests. In one embodiment managers acquire locks on rows of table or on other shared resources in system other shared resources are not explicitly shown . Shared resources can be elements of another table an access channel or other resource. Managers access database based on rules associated with the database.

Dequeue engine represents a dequeue mechanism that dequeues requests from the jobs queued in queue . As illustrated dequeue engine operates on a FCFS basis by sending the first dequeued request to the first available manager the second dequeued request to the next available manager and so forth. It will be understood that managers in system are illustrated as being organized in accordance with their availability and the labels designating the managers are not necessarily indicative of any identifier or handle used to access the managers in practice. Managers can take varying amounts of time to process particular requests. Thus for example manager could take a shorter amount of time to process its request than manager and would thus be available for processing a subsequent request prior to manager .

In one embodiment system includes agent to change how dequeue engine receives requests from queue . More specifically in one embodiment agent work in conjunction with the FCFS operation of dequeue engine by providing requests to dequeue engine in a different order than they were received in queue . In one embodiment agent selectively holds and unholds requests in queue . In one embodiment agent places all received requests on hold in conjunction with the requests being placed in the queue. Agent can then unhold selective requests from selected batch jobs to cause dequeue engine to take requests from different batches. If the only requests not on hold are requests across multiple batches dequeue agent can operate without modification and dequeue the requests in an order different from how the requests were received into queue . While parallelism is improved by using requests from different batches it will be understood that multiple requests can still be dequeued from the same batch as illustrated with respect to job . In one embodiment agent provides feedback to manager pool to cause the system to increase or decrease the number of managers in the pool.

Consider an example in which database is implemented as an Oracle GL database instance. The instance can be specific to a particular tenant or client of a database system of which database is a part. In such an example queue can be implemented as a Standard Manager Queue under Oracle Applications. Manager pool can be implemented as a collection of Standard Managers. Standard Managers execute by picking up requests from queue that are not on hold. In one embodiment managers pick up requests from queue based on a time interval. In an Oracle implementation the interval can be defined by a sleep second setting at a Concurrent Manager definition. For example a 30 second sleep interval indicates that the Standard Manager would pick up the pending requests every 30 seconds. The Standard Manager can pick up only as many pending requests as there are idle managers that the Standard Manager has at the end of the sleep cycle moment. Thus in one embodiment the requests are held in the queue until processing resources become available a manager becomes idle . If there are 100 managers and 80 managers are currently processing requests 20 managers can receive requests at the end of the sleep cycle.

In the Oracle GL example implementation a user can submit a large number of Reverse Journal Batch requests. In one embodiment the queue places and or keeps all submitted requests on hold. Agent can release a certain number of requests from each Reverse Journal Batch to the pending queue. The number of requests is less than a total number of requests in the batch and could be one or more. Thus the pending queue would include requests from multiple different batches which the Standard Manager would pick up for processing.

In one embodiment agent could be understood as cherry picking logic which picks journal requests from different batches. In one embodiment the system can monitor how long each journal request of each batch takes and use that information to estimate how long it will take to process subsequent requests from the same batch. The system can monitor historical information and use the historical information to determine how to cherry pick. For example agent can choose one request from one batch over another request from a different batch based on an expectation that the selected one will complete faster than the other.

Agent includes queue interface which represents any process or mechanism through which agent can interface with a batch queue. In one embodiment queue interface includes one or more APIs application programming interfaces or other program calls that enable agent to access a batch queue. Similarly agent includes dequeue engine interface which represents any process or mechanism through which agent can interface with a dequeue agent that removes requests from a batch queue. In one embodiment agent does not need an interface per se with a dequeue engine. For example a dequeue engine could be configured to simply dequeue requests that are not on hold in which case agent can simply unhold specific requests and allow the dequeue engine to operate normally.

In one embodiment agent includes one or more function modules that enable agent to monitor or collect various metrics. Agent can use one or more metrics to determine how to manage the dequeuing of requests from a batch queue. In one embodiment agent includes batch module manager module history module and load module . In an alternative embodiment agent includes more or fewer modules or includes other modules in place of those illustrated. Each module can include software and or hardware logic to provide various functions and or perform various operations. Certain functionality is described below which should be understood as non limiting examples of functionality.

Batch module enables agent to drive queue interface . Thus batch module can include all logic routines and processes needed to invoke the batch queue interface. In one embodiment batch module enables agent to identify separate batches within the batch queue. Batch module can associate specific metrics with specific batches for monitoring. Thus batch module can include or have access to a data structure or other data store to associate metric information with particular batches to be used in determining how to dequeue the requests from the batch queue.

Manager module represents logic routines and or processes by which agent can access a processing manager pool. Thus manager module can invoke an interface to access the processing manager s . Manager module can enable agent to collect statistical information about the operation of the managers to use in determining how to dequeue requests from the batch queue. In one embodiment for example based on monitoring information from batch module manager module can indicate a need for more or fewer managers to perform processing on the queue. In one embodiment manager module includes thresholds of processing time or wait time in the queue which if reached trigger agent to request more processing managers.

History module enables agent to monitor and use historical information to determine how to dequeue requests. Load module enables agent to monitor and use load information about the processing managers e.g. via manager module to determine how to dequeue requests. Historical information can include any information related to how long on average it takes to process a request or a maximum or minimum amount of time to process a request. Other historical information can include a number of requests processed or how many are currently in process. Load information can include information about the number of managers or what resources are available to the managers.

It will be understood that there can be different algorithms implemented by agent to determine how to dequeue requests. One example embodiment follows. In one embodiment agent monitors the batch queue for various conditions and metrics such as the number of requests currently in progress the batch queue idle bandwidth the number of pending requests in the queue the number of requests currently on hold within the queue and or other information. In one embodiment agent determines an appropriate number of requests to be released based on collected metrics. In one embodiment agent calculates a number of requests to release for each batch individually. It will be understood that agent can release or unhold more total requests than the processing managers have bandwidth to process immediately. Thus agent can unhold requests that may still sit in the queue awaiting processing resources after being released.

In one embodiment agent computes a number of request to be released from a batch in accordance with the formula 

In the formula ceil denotes a mathematical ceiling function mgris the total number of managers available to process requests from the batch queue batchis the total number of batches submitted to the queue and waiting to be processed and batch running reg is the total number of requests currently running in the concurrent job queue or being executed by processing managers for the particular batch. The first ceiling portion can be understood to take into account metrics related to a current state or load on the queue and or load on the processing managers. Thus agent can dequeue requests based at least in part on a load of the computing resources in the system.

The second portion of the equation can be considered a seed factor. The seed factor adjustment can be used to compensate for an implementation where the processing managers pick up running requests at the end of a sleep cycle instead of immediately. In an implementation where the processing managers pick up requests immediately after the processing resources become available the agent may be able to eliminate the historical component from the calculation of how many requests to release for dequeue. It will be understood that when processing managers pick up requests at the end of a sleep cycle there will be extra bandwidth available due to the time gap between the time the calculations were made and the time the managers actually pick up the requests. Even though the time gap would be in the order of seconds for processing rates having a high number of requests per second the delay would result in a large enough bandwidth to accommodate more requests.

For the historical portion or seed factor portion of the equation ceil again denotes a mathematical ceiling function reg per sec is the total number of batch requests processed per second current batch size is the number of requests pending in the current batch for which the calculation is being computed and average batch size is an average of a number of requests per batch among the submitted batches in the queue. Thus agent can calculate a determination of how to dequeue the requests from the batch queue based on historical information. Among the historical data that agent can use the agent can base dequeuing on an estimate of how long jobs from a particular batch take to process.

If the request is not a journal request NO branch the system processes the request based on the type of the request . If the request is a journal request YES branch the system can queue the batch request in a journal batch queue . The batch request will wait in the queue until processing resources are available to process the request. In one embodiment the system places a hold on queued batch jobs including each request in each batch . The system can then selectively release or unhold the requests to allow processing resources to process them. The database system includes an agent or a module that monitors the queue and affects how requests are dequeued from the queue for processing. Thus the system monitors the journal batches in the queue .

The system can determine if there are processing resources available to process more journal requests . In one embodiment the system makes the determination by monitoring the activity of the processing managers. In one embodiment the system triggers a sleep period and at the end of the period any processing manager that are idle are available resources for processing the batch requests. If there are no resources available NO branch or if it is not time to acquire requests from the queue the system continues to monitor the journal batches in the queue .

If there are resources available YES branch the system can continue to monitor the journal batches in the queue for metrics that allow the system to determine how many and which requests to dequeue. The agent also makes a determination of which requests to dequeue based on metrics monitored by the agent . The agent increases parallelism of the processing by selecting requests from multiple different batch jobs. In one embodiment the agent directs an unhold or release from selected requests in the queue . The system dequeues the selected requests for example by having the processing managers acquire requests from among requests that are waiting and released. Multiple requests can be released from the same batch if the agent determines it is likely they will all be processed before the system checks again for available resources. The dequeued requests are sent to the processing managers and executed on parallel or concurrently executing resources .

MTS provides on demand database services for environment . An on demand database service such provided by MTS is a database system that is made available to an outside user as needed by the user e.g. on the demand of the user . Thus a user does not necessarily need to be concerned with building and or maintaining the database system and rather can simply store and access data as needed from a remotely operated database system.

In one embodiment MTS stores information from one or more tenants into tables of a common database image or multitenant database MTDB . Accordingly MTS provides on demand database service. A database image may include one or more database objects. A multitenant database stores data for various different tenants or organizations in a single database instance. Resources such as memory processing space processing hardware and other resources of the database system are shared or allocated among the different tenants.

Multitenant database includes tenant data . . . . The tenant data may be divided into different storage areas which can be a physical and or a logical arrangement of data. In one embodiment multitenant database is accessed via a relational database management system RDBMS or the equivalent which executes storage and retrieval of information against the database object s . In one embodiment multitenant database is accessed via an object oriented database management system OODBMS or the equivalent. In one embodiment multitenant database is accessed via an object relational database management system ORDBMS or the equivalent. It will be understood that an RDBMS manages data stored in the database based on a relational model where data and data relationships are stored in tables. An OODBMS includes at least some integration of a database with an object oriented programming language and data is stored in the database in the same mode of representation as is provided in the programming language. An ORDBMS implements both a relational model and an object oriented model storing data in tables and allowing representation of data consistent with a programming language.

Application platform represents a framework that allows applications of MTS to execute. Thus application platform includes the software components such as an operating system to allow execution of the applications. Hardware platform provides hardware resources to enable the applications to execute on application platform as well as enabling execution of management or control logic for MTS . In one embodiment application platform of MTS enables creation managing and executing one or more applications developed by the provider of the on demand database service users accessing the on demand database service via network or third party application developers accessing the on demand database service via network .

MTS represents any type of system that may provide on demand database service. In addition to application platform and hardware platform which includes processor resources and memory resources MTS may include other components. MTS includes network interface to enable user devices to access MTS over network . In one embodiment MTS includes system data program code and process space . System data represents data specific to the running of MTS rather than being tenant data. It is logically separated from the tenant storage and may be physically separated e.g. by designating storage areas or address ranges for system data . Program code represents code to implement various functions of MTS which enable the system to provide on demand database service. Process space represents a framework for executing MTS processes and tenant specific processes such as running applications as part of an application hosting service. It will be understood that MTS may include more or fewer components than what is illustrated.

As mentioned above environment includes organizations and which represent tenants of MTS . Each organization may include one or more individual and may be an individual or small company up to a large corporation or organization. Thus it will be understood that the number of user devices associated with each organization could potentially be hundreds or even thousands. Each organization is assigned a tenant identifier ID within MTS . Each tenant ID could have certain associated properties for use depending on how the organization is configured. User device is associated with organization and access MTS under the tenant ID of organization . Similarly user devices and are associated with organization and access MTS under the tenants ID assigned to organization .

User devices and may be any machine or system that is used by a user to access a database user system. For example any of the user devices can be a handheld computing device a mobile phone a laptop computer a work station and or a network of computing devices. Each user device can be provided with an on demand database service from MTS via network .

Within an organization users may be further given access privileges and or restrictions as illustrated by data filter . As illustrated user device may access MTS in accordance with whatever access is available to organization while user device has additional restrictions applied by data filter . In one embodiment data filter may additionally or alternatively provide specific user interface features for user in accessing data from MTS .

The users of user devices and may differ in their respective capacities and the capacity of a particular user device might be entirely determined by permissions permission levels for the current user. For example where a salesperson is using a particular user device to interact with MTS that user device has the capacities assigned to that salesperson. However an administrator using the same user device may have different capacities assigned to that administrator. In systems with a hierarchical role model users at one permission level may have access to applications data and database information accessible by a lower permission level user but may not have access to certain applications database information and data accessible by a user at a higher permission level. Thus different users will have different capabilities with regard to accessing and modifying application and database information depending on a user s security or permission level. Such enforcement could occur based on data filter which can filter per device and or could filter for the entire organization e.g. a central filter as opposed to distributed filtering .

Network represents any network or combination of networks. A network is generically an interconnection of devices that communicate with each other. Network can be or include any combination of a LAN local area network WAN wide area network telephone network wireless network point to point network star network token ring network hub network or other appropriate configuration. TCP IP Transfer Control Protocol and Internet Protocol networks are commonly used such as the global internetwork of networks often referred to as the Internet. Reference to specific networks in certain examples herein is meant only to provide examples and is not limiting.

In one embodiment user devices and other user devices not shown communicate with MTS over network using TCP IP and at a higher network level use other common protocols to communicate such as HTTP HyperText Transfer Protocol FTP File Transfer Protocol AFS Andrew File System a distributed network filesystem using trusted servers WAP Wireless Access Protocol . In an example where HTTP is used user device might include an HTTP client commonly referred to as a browser for sending and receiving HTTP messages to and from an HTTP server at MTS not specifically shown but which could be executed on hardware platform . Such an HTTP server might be implemented as the sole network interface between MTS and network but other techniques might be used as well or instead. In one embodiment the interface between MTS and network includes load sharing functionality such as round robin HTTP request distributors to balance loads and distribute incoming HTTP requests evenly over a plurality of servers. At least as for the users that are accessing that server each of the plurality of servers has access to data in MTS however other alternative configurations may be used instead.

In one embodiment MTS implements a web based customer relationship management CRM system. For example in one embodiment MTS includes application servers configured to implement and execute CRM software applications as well as provide related data code forms webpages and other information to and from user devices e.g. and to store to and retrieve from a database system related data objects and webpage content. With a multitenant system data for multiple tenants may be stored in the same physical database object however tenant data is typically arranged so that data of one tenant is kept logically separate from that of other tenants. The logical separation prevents one tenant from having access to another tenant s data. An express sharing of data among tenants is possible which removes the logical separation. In one embodiment MTS implements applications other than or in addition to a CRM application. For example MTS may provide tenant access to multiple hosted standard and custom applications including a CRM application. User or third party developer applications which may or may not include CRM may be supported by application platform which manages creation storage of the applications into one or more database objects and executing of the applications in a virtual machine in process space of MTS .

In one embodiment MTS is configured to provide webpages forms applications data and media content to user client device to support the access by user devices as tenants of MTS . In one embodiment MTS provides security mechanisms to keep each tenant s data separate unless the data is shared. More than one MTS may be used. If more than one MTS is used the multiple systems may be located in close proximity to one another e.g. in a server farm located in a single building or campus or they may be distributed at locations remote from one another e.g. one or more servers located in city A and one or more servers located in city B .

As used herein each MTS could include one or more logically and or physically connected servers distributed locally or across one or more geographic locations. Additionally the term server refers to a computer system including processing hardware and process space s and an associated storage system and database application e.g. OODBMS RDBMS ORDBMS as is known in the art. It will be understood that server system and server are often used interchangeably herein. Similarly a database object described herein can be implemented as single databases a distributed database a collection of distributed databases a database with redundant online or offline backups or other redundancies and might include a distributed database or storage network and associated processing intelligence or logic.

A database of MTS can be a database that one or more user devices access with batch jobs. One or more resources such as tables of MTDB can be common resources that are locked by processing managers that execute in process space . In one embodiment an agent executes in process space to determine how to dequeue batch requests from queued batch jobs submitted by the user devices. An agent can dequeue the request or prepare the requests for dequeuing in accordance with any embodiment described herein.

Environment may include conventional well known elements that are explained only briefly here. For example user device and any other user devices through which users access MTS could include a desktop personal computer workstation laptop handheld device cell phone or smart phone or any wireless access protocol WAP enabled device or any other computing device capable of interfacing directly or indirectly to the Internet or other network connection.

User device includes processor which represents one or more processor devices and may be any combination of one or more processors. Processor provides hardware means to execute programs and applications on user device . Memory represents a memory system for user device and may be any combination of one or more memory devices short term and or long term memory. I O input output represents any type of input and output devices such as keyboards pointers and controllers touchscreens buttons microphones or other input mechanisms and monitors screens printers interfaces to networks and or other output devices.

User device includes network interface which represents hardware interconnections and control logic and circuitry to enable user device to connect to network . Network interface also has associated drivers and possibly other software components to allow user programs to interface with the interconnection hardware. User device includes client which represents a program that allows a user of user device to access information from network such as accessing MTS . UI represents a user interface component of client or a user interface in which information from client is presented on user device . Thus UI may be integrated with client or it may be separate from client but display data related to the execution of client . UI is rendered on display or user interface hardware or device which can be understood to be represented by UI .

In one embodiment user device runs an HTTP client as client . An HTTP client may be for example a browsing program or a browser which may include a WAP enabled browser in the case of a cell phone PDA or other wireless device. The HTTP client allows a user e.g. subscriber of MTS of user device to access process and view information pages and applications available from MTS over network based on permissions and privileges. The user interface device of user device can be used to access data and applications hosted by MTS and to perform searches on stored data and otherwise allow a user to interact with various GUI graphical user interface pages that may be presented to a user.

Similar to what is discussed above with reference to network of environment network represents any network or group of networks over which access can be provided to MTS . Network may include switching and or routing elements cables connectors and other components. In one embodiment at least part of network is the Internet referring to a specific global internetwork of networks. However it should be understood that other networks can be used in addition to or instead of the Internet such as an intranet an extranet a virtual private network VPN a non TCP IP based network any LAN or WAN or other network.

In one embodiment user devices such as user device which may be client systems communicate with application server to request and update system level and tenant level data from MTS that may require sending one or more queries to tenant data storage in database instance and or system data in system database . In one embodiment MTS e.g. application server automatically generates one or more SQL statements e.g. one or more SQL queries designed to access the desired information. System data storage in system database may generate query plans to access the requested data from database instance .

In one embodiment MTS includes one or more application servers . From one perspective application server can be considered a network interface of MTS to connect to network . Application server exchanges i.e. receives and or transmits data with network such as receiving requests and sending replies or sending data. Application servers may share hardware resources for interfacing with network or they may be assigned separate resources. In one embodiment one or more of application servers can be implemented as an HTTP application server.

In one embodiment each application server is configured to handle requests for any user associated with any organization that is a tenant. Thus a request from user device could be received and processed at any application server . There may be advantages to avoiding affinity for a user and or an organization or tenant to a specific application server such as the ability to add and remove application servers from a server pool at any time for any reason as well as for workload balancing among the servers. In an implementation where user and or tenant affinity is used an application server could not be removed without completing its jobs and or handing off users to another server.

In one embodiment an interface system implementing a load balancing function e.g. an F5 Big IP load balancer is communicably coupled between application servers and the user devices to distribute requests to the application servers . In one embodiment the load balancer uses a least connections algorithm to route user requests to the application servers . Other examples of load balancing algorithms such as round robin and observed response time also can be used. For example in certain embodiments three consecutive requests from the same user could hit three different application servers and three requests from different users could hit the same application server . In this manner MTS is multitenant wherein MTS handles storage of and access to different objects data and applications across disparate users and organizations. In one embodiment 

Each application server includes elements to provide database access service and request processing. Application server includes API application programming interface and UI . UI represents server side components that provide user interface elements that are provided to user device for display. API provides an interface for users and or developers to access resident processes of MTS .

In one embodiment application server includes application appl platform which provides a sub environment on which applications hosted by application server can be executed. Application platform may include an operating system or other control logic as well as business logic and common routines for use by the applications. As illustrated application platform includes application setup mechanism that supports creation and management of applications including configuration by application developers which may be saved as metadata into tenant data storage of database db instance . Save routines represent the mechanisms used to store data in database instance such as storing the application setup metadata. Such applications can be executed by subscriber users for example in process space .

In one embodiment invocations to or related to such applications may be coded using PL SOQL Procedural Language Salesforce Object Query Language that provides a programming language style interface extension to API . Thus PL SOQL is capable of serving as a procedural extension to an on demand database centric service API that allows flow control and transaction control to execute on a server in conjunction with database APIs e.g. SOQL data manipulation language DML or others . PL SOQL can enable the capability to thread together multiple SOQL DML statements as a single unit of work on the server. PL SOQL need not necessarily be considered a general purpose programming language seeing that it may be implemented as heavily data focused but is not necessarily implemented that way. In one embodiment PL SOQL can be used by developers to interlace with an on demand database system in contrast to traditional application developers conventional tools such as PL SQL Structured Query Language of ORACLE Inc. of Redwood Shores Calif. and others.

In one embodiment PL SOQL includes variable and expression syntax block and conditional syntax loop syntax object and array notation pass by reference and other syntax known to other programming languages. Thus full control over syntax and the ability to reference dynamic schema elements is provided with a new language and runtime for database services. Where embedded concepts that interface with on demand database applications are provided syntax and semantics that are easy to understand and which encourage efficient use of database APIs may also be employed. In one embodiment PL SOQL is implemented as a strong typed language with direct non quoted references to schema objects such as Object and Field names both standard and custom .

More details about PL SOQL language embodiments is discussed in commonly owned U.S. Provisional Patent Application 60 828 192 entitled PROGRAMMING LANGUAGE METHOD AND SYSTEM FOR EXTENDING APIs TO EXECUTE IN CONJUNCTION WITH DATABASE APIs by Craig Weissman filed Oct. 4 2006 now expired which is incorporated in its entirety.

In one embodiment invocations to applications may be detected by one or more system processes which manage retrieving application metadata for the subscriber making the invocation and executing the metadata as an application in a virtual machine. Metadata provides data related to access and or use of data stored in database instance . In one embodiment metadata is stored in a separate table within database instance and in an alternative embodiment metadata is stored with other data elements of user storage such as with user storage of table .

In one embodiment application server includes process space which may include tenant process spaces through N for some integer number N of process spaces configured in application server tenant management process space and system process space . It will be understood that process space is an abstraction to illustrate the resources allocated for execution of processes e.g. programs or applications within application server . The skilled reader recognizes that memory and processor and other hardware resources may need to be allocated as well as software resources to support the execution of a process. The processes may be executed as separate threads or may share a thread. In one embodiment the number N of tenant processes is equal to a number of subscriber tenants. In another embodiment the number N of tenant processes may be higher than the number of subscriber tenants. Tenant management process provides management of the other processes including determining when certain processes execute. System process executes operations related to functions of MTS .

Each application server may be configured to tenant data storage in database instance and the tenant data stored therein and to system data storage of system database and the system data stored therein to serve requests of user devices. As mentioned above in one embodiment tenant data is separated logically and stored in the same multitenant database. In one embodiment database instance stores data in tables through M where M is some integer number of tables. In one embodiment different tables store data of different types. Application metadata may be implemented as a separate table. Alternatively one of the tables through M could be a table that stores varying types of objects which are defined through metadata stored in the table.

In one embodiment database instance is further implemented with user storage space distinct e.g. identifiable from its associated tenant. Thus for example user data may include the tenant ID as well as an identifier specific to a user. Thus storage may represent either or both of tenant storage or user storage. For example a copy of a user s most recently used MRU items might be stored to in user storage within database instance . Similarly a copy of MRU items for an entire organization that is a tenant might be stored to a tenant storage area of database instance . In one embodiment the tenant data and the system data as illustrated by system database are stored in separate databases.

Application servers may be communicably coupled to database systems e.g. having access to system database and tenant database instance via a different network connection. For example one application server may be coupled via a network e.g. the Internet another application server might be coupled via a direct network link and another application server might be coupled by yet a different network connection. The application servers may connect to the database systems via TCP IP or another transport protocol at least partially depending on the network interconnect used.

Regarding storage in database instance one tenant might be a company that employs a sales force where each salesperson uses MTS to manage their sales process. Thus a user might maintain contact data leads data customer follow up data performance data goals and progress data and other data all applicable to that user s personal sales process e.g. storage which may be tenant storage . Thus all of the data and the applications to access view modify report transmit calculate or perform other operations can be maintained and accessed via a user device having nothing more than network access. In an example of an MTS arrangement the user can manage his or her sales efforts and cycles from any of many different user devices. For example if a salesperson is visiting a customer and the customer has a lobby with Internet access the salesperson can obtain critical updates as to that customer while waiting for the customer to arrive in the lobby.

While each user s data might be separate from other users data regardless of the employers of each user some data might be organization wide data shared or accessible by a plurality of users or all of the users for a given organization that is a tenant. Thus there might be some data structures managed by MTS that are allocated at the tenant level while other data structures might be managed at the user level. Because MTS may support multiple tenants including possible competitors MTS should have security protocols that keep data applications and application use separate. Additionally because many tenants may opt for access to an MTS rather than maintain their own system redundancy up time and backup are additional functions that may be implemented in MTS . In addition to user specific data and tenant specific data MTS may also maintain system level data usable by multiple tenants or other data. Such system level data might include industry reports news postings and the like that are sharable among tenants.

In one embodiment each database instance can be viewed as a collection of objects such as a set of logical tables containing data fitted into predefined categories. A table is one representation of a data object and may be used herein to simplify the conceptual description of objects and custom objects according to what is described herein. It should be understood that table and object type may be used interchangeably herein. Each table generally contains one or more data categories logically arranged as columns or fields in a viewable schema. Each row or record of a table contains an instance of data for each category defined by the fields.

For example a CRM database may include a table that describes a customer with fields for basic contact information such as name address phone number fax number or other information. Another table might describe a purchase order including fields for information such as customer product sale price date or other fields. In one embodiment a multitenant database has standard entity tables for use by all tenants. For CRM database applications such standard entities might include tables for Account Contact Lead and Opportunity data each containing pre defined fields. Thus tables through M may include standard defined tables.

In one embodiment tenants may be allowed to create and store custom objects or they may be allowed to customize standard entities or objects for example by creating custom fields for standard objects including custom index fields. U.S. patent application Ser. No. 10 817 161 filed Apr. 2 2004 entitled Custom Entities and Fields in a Multi Tenant Database System teaches systems and methods for creating custom objects as well as customizing standard objects in a multitenant database system. In one embodiment for example all custom entity data rows are stored in a single multitenant physical table which may contain multiple logical tables per organization. It is transparent to customers that their multiple tables are in fact stored in one large table or that their data may be stored in the same table as the data of other customers.

A database instance of MTS can be a database that one or more user devices access with batch jobs. One or more resources such as tables can be common resources that are locked by processing managers that execute in process space . In one embodiment an agent executes in process space to determine how to dequeue batch requests from queued batch jobs submitted by the user devices. The agent makes the determination based on monitored performance or statistical information. An agent can dequeue the request or prepare the requests for dequeuing in accordance with any embodiment described herein.

Flow diagrams as illustrated herein provide examples of sequences of various process actions. Although shown in a particular sequence or order unless otherwise specified the order of the actions can be modified. Thus the illustrated implementations should be understood only as an example and the process can be performed in a different order and some actions may be performed in parallel. Additionally one or more actions can be omitted in various embodiments thus not all actions are required in every implementation. Other process flows are possible.

Various operations or functions are described herein which may be described or defined as software code instructions configuration and or data. The content may be directly executable object or executable form source code or difference code delta or patch code . The software content of the embodiments described herein may be provided via an article of manufacture with the content stored thereon or via a method of operating a communications interface to send data via the communications interface. A machine readable medium or computer readable medium may cause a machine to perform the functions or operations described and includes any mechanism that provides i.e. stores and or transmits information in a form accessible by a machine e.g. computing device electronic system or other device such as via recordable non recordable storage media e.g. read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices or other storage media or via transmission media e.g. optical digital electrical acoustic signals or other propagated signal . A communication interface includes any mechanism that interfaces to any of a hardwired wireless optical or other medium to communicate to another device such as a memory bus interface a processor bus interface an Internet connection a disk controller. The communication interface can be configured by providing configuration parameters and or sending signals to prepare the communication interface to provide a data signal describing the software content.

Various components described herein may be a means for performing the operations or functions described. Each component described herein includes software hardware or a combination of these. The components can be implemented as software modules hardware modules special purpose hardware e.g. application specific hardware application specific integrated circuits ASICs digital signal processors DSPs etc. embedded controllers hardwired circuitry etc.

Besides what is described herein various modifications may be made to the disclosed embodiments and implementations without departing from their scope. Therefore the illustrations and examples herein should be construed in an illustrative and not a restrictive sense.

