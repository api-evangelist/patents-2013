---

title: Inverse request aggregation
abstract: A system and method for efficiently scheduling memory access requests from a display controller pipeline. The display controller monitors the amount of data in the line buffers in the internal pixel-processing pipelines. The display controller waits until the amount of data in a given line buffer has fallen below an amount equal to the pixel width of the region being rendered by the internal pixel-processing pipeline before issuing memory requests to the memory controller. When the memory controller is not processing received memory requests, the memory controller transitions to a low-power state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09117299&OS=09117299&RS=09117299
owner: Apple Inc.
number: 09117299
owner_city: Cupertino
owner_country: US
publication_date: 20130508
---
This invention is related to the field of digital systems and more particularly to low power mechanisms for managing displays in digital systems.

As the power and complexity of computer systems increase graphics operations are increasingly being performed using dedicated graphics rendering hardware. Accordingly a graphics processing unit GPU may include various built in and configurable structures within a display pipe for rendering images of pixel data to be presented via a display. These structures may implement various pipeline stages corresponding to for example rasterisation overlaying blending clipping dithering color space conversion frame rotation frame buffering etc.

In one embodiment a video subsystem in a computing system may include multiple sources for video data. The design of a smartphone or computer tablet may include user interface layers cameras and video sources such as media players. Each of these sources may utilize video data stored in memory. A corresponding display controller may include multiple internal pixel processing pipelines for these sources. Each memory request sent from the video subsystem includes both overhead processing and information retrieval processing. A large number of requests may create a bottleneck in the memory subsystem and the repeated overhead processing may reduce the subsystem performance.

In order to minimize power consumption of the overall system the system should attempt to enter a low power mode whenever traffic is not being sent over the communication fabric to the memory controller. However the memory subsystem may be unable to enter a low power mode as one or more display pipelines continuously access the memory. The memory may be off die synchronous dynamic random access memory SDRAM used to store frame data in frame buffers. The accesses of the SDRAM consume an appreciable amount of power in addition to preventing the memory subsystem from entering a low power mode.

In view of the above methods and mechanisms for minimizing the power consumption of a display pipeline are desired.

In one embodiment a display controller includes circuitry configured to process image data e.g. still frames and or video sequences for visual display. The display controller may include one or more internal pixel processing pipelines. Each of the internal pixel processing pipelines may be able to process the frame data received from memory via the memory controller for a respective video source. The display controller may be configured to blend one or more still frames and or sequences to produce output frames. The output frames may be conveyed to and presented on a respective display screen.

The display controller may be configured to transmit read requests to memory via a memory controller in order to retrieve the image data from memory for processing. In one embodiment after sending a burst of memory requests to the memory controller each pixel processing pipeline of the display controller may wait to issue read requests until a programmable number of pixels are left in the line buffer. The programmable number of pixels may be based on a size of the region being rendered by the pixel processing pipeline.

The display controller may aggregate memory requests for each pixel processing pipeline to the memory controller while waiting for the number of pixels in the corresponding line buffer to fall below the programmable number of pixels. In response to not receiving memory access requests from the display controller or any other functional blocks the memory controller may transition to a low power mode.

In one embodiment the display controller may receive an indication that one or more of the programmable numbers of pixels has been updated. The update may be generated based on a change in the size of the region being rendered by a given pixel processing pipeline. For example the width of the frame may change from a first width to a second width. Initially after sending a burst of memory requests the display controller may be configured to wait until there are a first number of pixels equal to the first width left in the line buffer of the given pixel processing pipeline prior to issuing the next set of read requests to the memory controller. After the display controller receives the indication that the programmable number has been updated to the second number of pixels the display controller may then wait for the amount of data in the line buffer to fall below the second number of pixels before issuing additional read requests to the memory controller.

These and other embodiments will be further appreciated upon reference to the following description and drawings.

While the invention is susceptible to various modifications and alternative forms specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood however that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.

This specification includes references to one embodiment . The appearance of the phrase in one embodiment in different contexts does not necessarily refer to the same embodiment. Particular features structures or characteristics may be combined in any suitable manner consistent with this disclosure. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Various units circuits or other components may be described or claimed as configured to perform a task or tasks. In such contexts configured to is a broad recitation of structure generally meaning having circuitry that performs the task or tasks during operation. As such the unit circuit component can be configured to perform the task even when the unit circuit component is not currently on. In general the circuitry that forms the structure corresponding to configured to may include hardware circuits. Similarly various units circuits components may be described as performing a task or tasks for convenience in the description. Such descriptions should be interpreted as including the phrase configured to. Reciting a unit circuit component that is configured to perform one or more tasks is expressly intended not to invoke 35 U.S.C. 112 paragraph six interpretation for that unit circuit component. Additionally configured to can include generic structure e.g. generic circuitry that is manipulated by software and or firmware e.g. an FPGA or a general purpose processor executing software to operate in a manner that is capable of performing the task s at issue. Configured to may also include adapting a manufacturing process e.g. a semiconductor fabrication facility to fabricate devices e.g. integrated circuits that are adapted to implement or perform one or more tasks.

In the following description numerous specific details are set forth to provide a thorough understanding of the present invention. However one having ordinary skill in the art should recognize that the invention might be practiced without these specific details. In some instances well known circuits structures and techniques have not been shown in detail to avoid obscuring the present invention. It will be appreciated that for simplicity and clarity of illustration elements shown in the figures have not necessarily been drawn to scale. For example the dimensions of some of the elements may be exaggerated relative to other elements.

Terminology. The following paragraphs provide definitions and or context for terms found in this disclosure including the appended claims 

 Comprising. This term is open ended. As used in the appended claims this term does not foreclose additional structure or steps. Consider a claim that recites An apparatus comprising a display controller . . . . Such a claim does not foreclose the apparatus from including additional components e.g. a CPU complex a communication fabric .

 First Second etc. As used herein these terms are used as labels for nouns that they precede and do not imply any type of ordering e.g. spatial temporal logical etc. . For example in a display controller with a plurality of pixel processing pipelines the terms first and second pixel processing pipelines can be used to refer to any two of the plurality of pixel processing pipelines.

 Based On. As used herein this term is used to describe one or more factors that affect a determination. This term does not foreclose additional factors that may affect a determination. That is a determination may be solely based on those factors or based at least in part on those factors. Consider the phrase determine A based on B. While B may be a factor that affects the determination of A such a phrase does not foreclose the determination of A from also being based on C. In other instances A may be determined based solely on B.

Turning now to a block diagram of one embodiment of a system on chip SOC is shown coupled to a memory and one or more display devices . A display device may be more briefly referred to herein as a display. As implied by the name the components of the SOC may be integrated onto a single semiconductor substrate as an integrated circuit chip. In some embodiments the components may be implemented on two or more discrete chips in a system. However the SOC will be used as an example herein. In the illustrated embodiment the components of the SOC include a central processing unit CPU complex a display pipe peripheral components A B more briefly peripherals a memory controller and a communication fabric . The components A B and may all be coupled to the communication fabric . The memory controller may be coupled to the memory during use. Similarly the display pipe may be coupled to the displays during use. In the illustrated embodiment the CPU complex includes one or more processors and a level two L2 cache .

The display pipe may include hardware to process one or more still images and or one or more video sequences for display on the displays . Generally for each source still image or video sequence the display pipe may be configured to generate read memory operations to read the data representing the frame video sequence from the memory through the memory controller . In one embodiment each read operation may include a quality of service QoS parameter that specifies the requested QoS level for the operation. The QoS level may be managed to ensure that the display pipe is provided with data in time to continue displaying images without visual artifacts e.g. incorrect pixels being displayed skipping or other visually identifiable incorrect operation .

The display pipe may be configured to perform any type of processing on the image data still images video sequences etc. . In one embodiment the display pipe may be configured to scale still images and to dither scale and or perform color space conversion on the frames of a video sequence. The display pipe may be configured to blend the still image frames and the video sequence frames to produce output frames for display. The display pipe may also be more generally referred to as a display controller. A display controller may generally be any hardware configured to prepare a frame for display from one or more sources such as still images and or video sequences.

The displays may be any sort of visual display devices. The displays may include for example touch screen style displays for mobile devices such as smart phones tablets etc. Various displays may include liquid crystal display LCD light emitting diode LED plasma cathode ray tube CRT etc. The displays may be integrated into a system including the SOC e.g. a smart phone or tablet and or may be a separately housed device such as a computer monitor television or other device. The displays may also include displays coupled to the SOC over a network wired or wireless .

In some embodiments the displays may be directly connected to the SOC and may be controlled by the display pipe . That is the display pipe may include hardware a backend that may provide various control data signals to the display including timing signals such as one or more clocks and or the vertical blanking interval and horizontal blanking interval controls. The clocks may include the pixel clock indicating that a pixel is being transmitted. The data signals may include color signals such as red green and blue for example. The display pipe may control the displays in real time providing the data indicating the pixels to be displayed as the display is displaying the image indicated by the frame. The interface to such displays may be for example VGA HDMI digital video interface DVI a liquid crystal display LCD interface a plasma interface a cathode ray tube CRT interface any proprietary display interface etc.

The CPU complex may include one or more CPU processors that serve as the CPU of the SOC . The CPU of the system includes the processor s that execute the main control software of the system such as an operating system. Generally software executed by the CPU during use may control the other components of the system to realize the desired functionality of the system. The CPU processors may also execute other software such as application programs. The application programs may provide user functionality and may rely on the operating system for lower level device control. Accordingly the CPU processors may also be referred to as application processors. The CPU complex may further include other hardware such as the L2 cache and or an interface to the other components of the system e.g. an interface to the communication fabric .

The peripherals A B may be any set of additional hardware functionality included in the SOC . For example the peripherals A B may include video peripherals such as video encoder decoders image signal processors for image sensor data such as camera scalers rotators blenders graphics processing units etc. The peripherals may include audio peripherals such as microphones speakers interfaces to microphones and speakers audio processors digital signal processors mixers etc. The peripherals may include interface controllers for various interfaces external to the SOC e.g. the peripheral B including interfaces such as Universal Serial Bus USB peripheral component interconnect PCI including PCI Express PCIe serial and parallel ports etc. The peripherals may include networking peripherals such as media access controllers MACs . Any set of hardware may be included.

The memory controller may generally include the circuitry for receiving memory operations from the other components of the SOC and for accessing the memory to complete the memory operations. The memory controller may be configured to access any type of memory . For example the memory may be static random access memory SRAM dynamic RAM DRAM such as synchronous DRAM SDRAM including double data rate DDR DDR2 DDR3 etc. DRAM. Low power mobile versions of the DDR DRAM may be supported e.g. LPDDR mDDR etc. . The memory controller may include various queues for buffering memory operations data for the operations etc. and the circuitry to sequence the operations and access the memory according to the interface defined for the memory .

The communication fabric may be any communication interconnect and protocol for communicating among the components of the SOC . The communication fabric may be bus based including shared bus configurations cross bar configurations and hierarchical buses with bridges. The communication fabric may also be packet based and may be hierarchical with bridges cross bar point to point or other interconnects.

It is noted that the number of components of the SOC and the number of subcomponents for those shown in such as within the CPU complex may vary from embodiment to embodiment. There may be more or fewer of each component subcomponent than the number shown in .

Turning now to a block diagram of one embodiment of a portion of the display pipe is shown. There may be additional circuitry e.g. the display backend referenced in to directly interface to the display to display pixels generated by the display pipe . In some embodiments there may be multiple instances of the display pipe for coupling to multiple displays .

As shown in the display pipe may include one or more user interface UI units two shown as UI A and UI B in this case. One or more video units such as video unit may also be included along with a blend unit . It is noted that in other embodiments generic pipeline units may be utilized rather than UI and video units as shown in . Each generic pipeline unit may perform the functions of a UI or video unit as required by the overall display pipe. In some embodiments the generic pipeline may be configured by software and may be programmed as a UI unit and then later reprogrammed as a video unit or vice versa . A host interface unit host I F may also be included within display pipe . An output pixel buffer or a pixel first in first out buffer FIFO and control unit are also shown. In various embodiments control unit may include various circuitry e.g. QoS control circuit clock gate control circuit not shown in to avoid obscuring the figure.

In the illustrated embodiment the host interface unit may be coupled to the user interface units A B the video unit and control unit . The user interface units A B and the video unit may further be coupled to the blend unit . The blend unit may be coupled to the pixel FIFO . Control unit may be coupled to receive buffer occupancy indications from the user interface units A B and the video unit . In one embodiment control unit may include a clock gate control circuit configured to control clock gating in a portion of the display pipe . Particularly the portion above the dashed line in may be able to be clock gated. Control unit may also be coupled to receive a pixel FIFO count from the pixel FIFO .

The pixel FIFO may be the interface to the display backend which may control the display to display the pixels generated by the display pipe . The display backend may read pixels at a regular rate from the pixel FIFO according to a pixel clock. The rate may depend on the resolution of the display as well as the refresh rate of the display. For example a display having a resolution of N M and a refresh rate of R frames per second may have a pixel clock frequency based on N M R. On the other hand the pixel FIFO may be written by the blend unit as pixels are generated by the blend unit . In some instances the rate at which the display pipe generates pixels may be faster than the rate at which the pixels are read assuming that data is provided to the display pipe from the memory quickly enough.

The pixels in the pixel FIFO may thus be a measure of a margin of safety for the display pipe before erroneous operation may be observed on the display . Control unit may be configured to generate QoS levels based on the number of pixels in the pixel FIFO . Control unit may provide the generated QoS level to the host interface unit which may transmit the QoS level with each memory read operation to the memory controller . Control unit may also determine when to clock gate the display pipe based on the comparison of the number of pixels in the pixel FIFO to a threshold. Additionally in some embodiments the amount of data that is available within the display pipe to generate additional pixels for the pixel FIFO may be viewed as additional margin of safety.

Each user interface unit A B may include instances of a buffer a scaler and a fetch unit . The buffer may be coupled to receive image data from the host interface unit and to provide the data to the scaler . The scaler may be configured to output pixels to the blend unit with an alpha value for blending. The fetch unit may be coupled to provide memory operations to the host interface unit for transmission to the memory controller . The video unit may include a video pipe a video output buffer and one or more fetch units . For example the video unit may include a fetch unit for each image plane in the video sequence. The various image planes may describe the video image. For example the image planes may be color planes e.g. red green blue or Y Cr Cb . The fetch unit s in the video unit may be coupled to provide memory operations to the host interface unit . The video pipe may be coupled to receive video image data from the host interface unit .

The buffers may be input line buffers. That is the buffers may store lines of data corresponding to lines of the input frame. For vertical downscaling data from adjacent lines of the input frame may be needed to generate each output pixel and thus the line buffers may provide space to store data for processing. The data may be the color data for each pixel as well as an alpha value for blending. The buffer may be an output buffer of video frame pixels. The pixels in the buffer may already have been scaled if applicable and may be ready for blend unit to produce output pixels for the output pixel FIFO .

Generally the image data input to each of the units A B and may describe the source image to be displayed. In an embodiment the image data for a user interface image input to the units A and B may include pixel data and an alpha value for blending. The pixel data may describe a color for each pixel. The scaled pixels may be provided as output pixels from the user interface units A and B to the blend unit along with the alpha values. In an embodiment the user interface units A B may support programmable active regions in the source image. The active regions may define the only portions of the source image to be displayed. In an embodiment the user interface units A B may be configured to only fetch data within the active regions. Outside of the active regions dummy data with an alpha value of zero may be passed as the pixel data.

In one embodiment the video pipe may receive fetched image data describing a sequence of frames to be displayed at a frame rate specified for the video sequence. In an embodiment the video sequence data may be in YCbCr format and the video unit may be configured to color space cover the frames to RGB for blend with the frames from the user interface units A B. The video pipe may insert random noise dither into the data and may optionally scale the data in one or both of vertical and horizontal directions.

The blend unit may receive frames of pixels from the user interface units A B and the video unit and may be configured to blend them together layer by layer. The final resultant pixels may be queued in the output pixel FIFO . The lowest level layer in the blend unit may be defined as the background color. Layer may blend with layer . The next layer layer may blend with the blended layers and and so on until all the layers are blended.

Each of the units A B and may include pipelined hardware that performs the operations assigned to that unit. Accordingly each of the units A B and may be referred to as a pipeline or pipe. Thus the user interface units A B may be user interface pipes static frame image pipes or user interface pixel processing pipelines. The video unit may be referred to as a video pipe video sequence pipe or video interface pixel processing pipeline.

In the illustrated embodiment the control unit includes register configured to store thresholds corresponding to the line buffers of the pixel processing pipelines. The value of each threshold may be calculated based on the active region being rendered by the corresponding pixel processing pipeline. Control unit may also be coupled to receive buffer occupancy indications for each of the pixel processing pipelines. Control unit may compare a buffer occupancy indication to a corresponding threshold to determine whether to issue read requests to the memory controller for a given pixel processing pipeline.

It may be advantageous in some systems to generate memory requests in bursts rather than generating memory requests that are spread out evenly over time. In some cases a reduction in power consumption may be achieved by operating in burst modes where large amounts of memory requests are sent out rapidly over a short period of time followed by a long period of time of inactivity. During the inactivity the memory controller and communication fabric may be able to enter a low power state that reduces the power consumption of the electronic device. The inverse request aggregation techniques disclosed herein offer many advantages over the prior art. For example one advantage of inverse request aggregation is that it allows the display pipeline to aggregate the maximum number of requests possible with no risk of under run. Additionally setting an occupancy threshold guarantees a fixed latency tolerance regardless of whether a full screen worth or only a portion of pixels are being fetched. In one embodiment the latency tolerance may be a function of the display resolution and the scaling factor if any . Therefore the threshold may be set based on those two factors. In some embodiments the display resolution may be fixed for a specific screen and the screen s physical characteristics may not change dynamically. In these embodiments the aggregation threshold may effectively be a function of the scaling factor.

Turning now to a generalized block diagram of one embodiment of user interface UI pixel processing pipelines within the display pipeline is shown. The example shown in with the user interface pipelines and rendering regions and respectively is for illustrative purposes only. As shown in user interface pipeline is rendering user interface region with a size of N pixels wide by M pixels tall. The values N and M may vary according to the particular region being rendered. In one embodiment the value of N may determine the location of threshold in buffer . Additionally in some embodiments the size of region may change at any time and so the user interface pipeline may also adjust its operation to match the region being rendered. Similarly user interface pipeline is rendering user interface region with a size of P pixels wide by Q pixels tall. The value P may determine the location of threshold in buffer .

After receiving a first burst of pixels fetch unit may be configured to wait until there are N pixels left before issuing memory requests to host interface I F unit for additional pixels. In one embodiment fetch unit may be configured to monitor buffer and determine when there are N pixels remaining. Alternatively a control unit not shown may monitor buffer and fetch unit may receive an indication from the control unit to start issuing memory requests. The above description of fetch unit may also apply to fetch unit .

In the embodiment shown in the regions and are of different sizes with N not equal to P and M not equal to Q. However this is for illustrative purposes only. In another embodiment region and may be the same size. Alternatively in another embodiment N and P may be equal while M is different than Q. Or in a further embodiment M and Q may be equal while N is different than P.

In one embodiment user interface pipelines and may not perform any scaling of the received pixel data. In other embodiments either of user interface pipelines or may utilize scaling in which case the threshold used in the corresponding line buffer will be scaled accordingly. For example if a given pipeline were upscaling by a factor of two and the width of the region being rendered is N pixels then the threshold for the line buffer may be N 2 pixels. In this way each threshold may reflect the quantity of output equivalent pixels in the buffer that is equal to a single line in the region being rendered.

Turning now to a block diagram of one embodiment of a video pixel processing pipeline is shown. In one embodiment video pipeline may be included within a display pipeline that also includes user interface pipelines and of . Video pipeline may be coupled to host interface I F unit and to a blend unit not shown . Video pipeline may receive frame data from a memory controller via host I F unit . Video pipeline may process the frame data and send the processed frame data to the blend unit to be blended with one or more user interface pipelines.

As shown in video pipeline may be rendering region of size R pixels wide by T pixels tall. Video pipe may include a line buffer not shown and additional logic including dither unit scaler etc. Threshold of video pipe may be set based on the width of R pixels. For example if R is equal to 20 pixels and there are 4 bytes per pixel then threshold may be set for 80 bytes for the line buffer of video pipe . These values of R and the number of bytes per pixel are for illustrative purposes only. Other values of R and other numbers of bytes per pixel may be utilized in other embodiments. When the size of region changes threshold may be updated to reflect the new width of region . Also if the type of scaling used by video pipe changes threshold may be updated to match the amount of scaling being utilized.

A control unit not shown may monitor the amount of data stored in video pipe and detect when the amount of data is less than threshold . While the amount of data stored in buffer video pipe is above the threshold fetch unit may aggregate memory requests for frame data. When the control unit detects that the amount of data has fallen below threshold then the control unit may signal fetch unit to begin issuing memory requests.

Turning now to a generalized flow diagram of one embodiment of a method for implementing an inverse request aggregation technique within a display pipeline is shown. For purposes of discussion the steps in this embodiment are shown in sequential order. However in other embodiments some steps may occur in a different order than shown some steps may be performed concurrently some steps may be combined with other steps and some steps may be omitted.

In one embodiment the control unit of a given internal pixel processing pipeline may monitor the amount of data stored in the line buffer as data is forwarded from the line buffer to the next stage of the given pixel processing pipeline block . If the amount of data stored in the line buffer is less than the threshold conditional block yes leg then the fetch unit of the given pixel processing pipeline may issue memory requests for additional pixel data block . In one embodiment the fetch unit may send memory requests to the interface unit of the display pipe and the interface unit may arbitrate among requests for forwarding to the memory controller. In one embodiment the control unit may set the threshold of the line buffer of the given internal pixel processing pipeline based on the width of the line of the region being rendered. The width of the line may be calculated in terms of the amount of data per line of the region based on the number of pixels in the line and the number of bits per pixel. The value of the threshold may also be based on the type of scaling that is being performed by the given internal pixel processing pipeline.

If the amount of data stored in the line buffer is above the threshold conditional block no leg then the fetch unit may aggregate memory requests and prevent the memory requests from being issued block . After block method may return to block and monitor the amount of pixel data in the line buffer.

After block the control unit may monitor the line buffer and determine if the line buffer is full conditional block . Alternatively the fetch unit or another logical unit may monitor the line buffer and determine if the line buffer is full. The line buffer may be considered full if all of the line buffer entries are either filled with pixel data or are reserved for pixel data that has been fetched but not yet returned. If the line buffer is full conditional block yes leg then the fetch unit may stop issuing memory requests block . After block method may return to block and monitor the amount of pixel data in the line buffer. If the line buffer is not full conditional block no leg then method may return to block and the fetch unit may continue issuing memory requests. It is noted that method may be performed in parallel for multiple internal pixel processing pipelines user interface and video interface of the display pipeline.

Referring next to a block diagram of one embodiment of a system is shown. As shown system may represent chip circuitry components etc. of a desktop computer laptop computer tablet computer cell phone television or set top box configured to be coupled to a television or otherwise. Other devices are possible and are contemplated. In the illustrated embodiment the system includes at least one instance of SoC of coupled to an external memory .

SoC is coupled to one or more peripherals and the external memory . A power supply is also provided which supplies the supply voltages to SoC as well as one or more supply voltages to the memory and or the peripherals . In various embodiments power supply may represent a battery e.g. a rechargeable battery in a smart phone laptop or tablet computer . In some embodiments more than one instance of SoC may be included and more than one external memory may be included as well .

The memory may be any type of memory such as dynamic random access memory DRAM synchronous DRAM SDRAM double data rate DDR DDR2 DDR3 etc. SDRAM including mobile versions of the SDRAMs such as mDDR3 etc. and or low power versions of the SDRAMs such as LPDDR2 etc. RAMBUS DRAM RDRAM static RAM SRAM etc. One or more memory devices may be coupled onto a circuit board to form memory modules such as single inline memory modules SIMMs dual inline memory modules DIMMs etc. Alternatively the devices may be mounted with SoC in a chip on chip configuration a package on package configuration or a multi chip module configuration.

The peripherals may include any desired circuitry depending on the type of system . For example in one embodiment peripherals may include devices for various types of wireless communication such as wifi Bluetooth cellular global positioning system etc. The peripherals may also include additional storage including RAM storage solid state storage or disk storage. The peripherals may include user interface devices such as a display screen including touch display screens or multitouch display screens keyboard or other input devices microphones speakers etc.

The device driver for the display controller may include both user mode components and kernel mode components. A graphics hardware vendor may supply the user mode graphics driver and the kernel mode graphics driver. The operation system OS may load a separate copy of the user mode driver for each application. The user mode graphics driver may be a dynamic link library DLL that is loaded by corresponding application programming interfaces APIs in the OS graphics APIs. Alternatively runtime code may be used to install the user mode graphics driver.

In various embodiments corresponding graphics libraries and drivers may determine and pass the aggregate threshold from the software application to the computing system such as to a programmable configuration register within the display controller. In some cases the user mode graphics driver may be an extension to the Direct3D and OpenGL software development kits SDKs . Accordingly the determination and passing of the aggregate threshold may be made available through a standard interface.

In some embodiments one or more counters may be used to measure the time duration between separate requestors being selected by arbitration logic and sending an initial memory read request. Additionally the time duration between a same requestor being selected by arbitration logic during a requestor aggregate mode and sending an initial memory read request may be measured. The recorded times may be compared to given values such as expected signatures in order to debug the system and make adjustments to the programmable aggregate threshold and the number of requests to send within a burst mode.

In various embodiments program instructions of a software application may be used to implement the methods and or mechanisms previously described. The program instructions may describe the behavior of hardware in a high level programming language such as C. Alternatively a hardware design language HDL may be used such as Verilog. The program instructions may be stored on a computer readable storage medium. Numerous types of storage media are available. The storage medium may be accessible by a computer during use to provide the program instructions and accompanying data to the computer for program execution. In some embodiments a synthesis tool reads the program instructions in order to produce a netlist comprising a list of gates from a synthesis library.

Although the embodiments above have been described in considerable detail numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

