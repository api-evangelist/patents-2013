---

title: System and method for allocating resources for heterogeneous service requests
abstract: A system for allocating constrained resources (e.g., downstream services, execution threads, database connections, input/output channels, computational resources, and/or memory) to requested services that are dependent on those resources may include multiple resource queues, each of which maintains a queue of requests for a respective constrained resource, and multiple service request queues, from which requests may be subsequently serviced. As each request reaches the head of a resource queue, it may receive a resource token for a respective constrained resource. Once the request has collected resource tokens for each of the constrained resources on which it depends, the request may be passed to a service request queue that maintains a queue of requests of a particular type. Requests in the multiple service request queues may be serviced on a round-robin or weighted round-robin basis. The number of tokens available for each constrained resource may be modified based on observed system performance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09385963&OS=09385963&RS=09385963
owner: Amazon Technologies, Inc.
number: 09385963
owner_city: Reno
owner_country: US
publication_date: 20130805
---
This application is a continuation of U.S. application Ser. No. 12 981 263 filed Dec. 29 2010 now U.S. Pat. No. 8 504 691 which is hereby incorporated by reference herein in its entirety.

In a typical Web service or remote procedure call RPC service a pool of worker threads services a queue of incoming requests performing the work that is required for the request and responding to the requester when the work is complete. When services of this kind are deployed in a service architecture it is typical for such service threads to be blocked while waiting on calls to downstream services requests for database connections access to input output mechanisms e.g. I O channels and or on other constrained resources on which they depend e.g. computational resources or memory . When these constrained resources become unavailable or slow to respond service requests that require them tend to cause all of the available service threads in the system to become blocked while waiting for these resources.

Typical approaches to solving this problem include the use of asynchronous input output mechanisms timeouts for in flight requests and timeouts around calls that may become slow or block other services. While these approaches are typically effective they are difficult to add to existing services add complexity to the service implementation increase the difficulty of predicting system performance and significantly reduce throughput. Another common approach is the use of admission control for requests which prevents too many requests from being accepted e.g. by throttling.

While the technology described herein is susceptible to various modifications and alternative forms specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood however that the drawings and detailed description thereto are not intended to limit the disclosure to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present disclosure as defined by the appended claims.

Systems and methods for allocating constrained resources e.g. downstream services execution threads database connections input output channels computational resources or a portion of system memory disk memory or another persistent storage resource to requested services that are dependent on those constrained resources are described herein according to various embodiments. In some embodiments the system may include multiple resource queues each of which may maintain a queue of requests for a respective constrained resource. As each request reaches the head of a resource queue it may receive a resource token for the respective constrained resource from a resource token bucket associated with the resource queue. In some embodiments the number of tokens available for each constrained resource i.e. allocated for each resource token bucket may be modified based on observed system performance.

In some embodiments once a request has collected resource tokens for each of the constrained resources on which it depends the request may be passed to a service request queue from which the request may be subsequently serviced e.g. on a first in first out basis . In some embodiments the system may include multiple service request queues each of which maintains a queue of requests of a particular type for a particular service or for particular clients. Requests in the multiple service request queues may be serviced on a round robin or weighted round robin basis in various embodiments.

In some embodiments having two queuing stages e.g. one stage including resource queues in an admission control subsystem and a second stage including separate service request queues as described herein may help the system absorb surges or spikes in the number of service requests received. Therefore the systems described herein may achieve higher performance e.g. throughput than systems in which requests are blocked by other requests at a single queuing stage.

As noted above a typical Web service or RPC service may employ a pool of worker threads to service a queue of incoming requests performing the work that is required for the request and responding to the requester when the work is complete. However in services of this kind service threads may be blocked while waiting on calls to downstream services requests for database connections access to input output mechanisms and or on other constrained resources on which they depend e.g. computational resources or memory .

The systems and methods described herein may in various embodiments employ an approach to admission control that is based on explicit identification of service dependencies and prioritization of service requests based on observed system performance. In some embodiments these systems and methods may be suitable for use in heterogeneous Web services or RPC services which may provide multiple services e.g. multiple service calls or service call types each of which may have different dependencies and exhibit different behaviors. In some embodiments the queuing techniques described herein may be well suited for Web services that must offer both high throughput and high availability during traffic spikes. For example rather than simply dropping requests at times of high traffic as with typical admission control approaches the systems described herein may perform a reprioritization of constrained resources under such conditions.

Various techniques described herein may be employed in local or remote systems including systems that provide services to users e.g. subscribers over the Internet or over other public or private networks such as virtual private networks and connections to services in a virtual private cloud VPC environment. illustrates a block diagram of a system that provides various Web based services to clients according to one embodiment. In this example system includes one or more clients . In this example the clients may be configured to interact with a Web server via a communication network .

As illustrated in this example the Web server may be configured to process requests from clients for various services such as Web service A Web service B and Web service C and to return results to the clients . In various embodiments some or all of these Web services may be dependent on one or more downstream services and or other constrained resources and Web server may be configured to allocate those downstream services and or other constrained resources to individual client requests in order to provide the requested services. Various components of a Web server or other computer system configured to allocate constrained resources to service requests are illustrated in and described in detail below.

In the example illustrated in the clients may encompass any type of clients configured to submit service requests to Web server via network on behalf of a user or a requesting application. For example a given client may include a suitable version of a Web browser or a plugin module or other type of code module configured to execute as an extension to or within an execution environment provided by a Web browser. Alternatively a client may encompass an application such as a database application media application office application or any other application that may make use of the services provided by Web server . In some embodiments such an application may include sufficient protocol support e.g. for a suitable version of Hypertext Transfer Protocol HTTP for generating and processing Web service requests without necessarily implementing full browser support for all types of Web based data. That is client may be an application configured to interact directly with Web server . In various embodiments client may be configured to generate requests for Web services according to a Representational State Transfer REST style Web services architecture a document or message based Web services architecture or another suitable Web services architecture. In some embodiments client may be configured to provide access to Web based service to other applications in a manner that is transparent to those applications. For example a client may be configured to integrate with an operating system to provide services in accordance with a suitable variant of the service model described herein. However the operating system may present a different service request interface to applications than that described herein.

In various embodiments the communication network may encompass any suitable combination of networking hardware and protocols necessary to establish Web based communications between clients and Web server . For example the communication network may generally encompass the various telecommunications networks and service providers that collectively implement the Internet. The communication network may also include private networks such as local area networks LANs or wide area networks WANs as well as public or private wireless networks. For example both a given client and the Web server may be respectively provisioned within enterprises having their own internal networks. In such an embodiment the communication network may include the hardware e.g. modems routers switches load balancers proxy servers etc. and software e.g. protocol stacks accounting software firewall security software etc. necessary to establish a networking link between the given client and the Internet as well as between the Internet and Web server . Note that in some embodiments clients may communicate with Web server using a private network rather than the public Internet. For example in some embodiments clients may be provisioned within the same enterprise as the resources that provide various services to those clients. In such a case clients may communicate with a server entirely through a private communication network not shown .

In this example Web services interface may be configured to receive requests for services from various clients and to communicate with admission control subsystem to facilitate the performance of those services on behalf of the clients. For example in some embodiments admission control subsystem may be configured to communicate with a service request subsystem to admit one or more service requests into a service request queue and service request subsystem may in turn be configured to allocate or initiate allocation of one or more constrained resources needed to perform the requested services to those requests from resource pool s . In some embodiments Web service interface may utilize predefined instructions or communications such as via defined application protocol interfaces APIs to communicate with admission control subsystem and or other components of computing system on behalf of a client.

As illustrated in this example in some embodiments admission control subsystem may include multiple resource queues shown as resource queues each of which queues requests for a given downstream service or other constrained resource. As illustrated in this example each of these resources queues may be associated with a respective resource token bucket shown as token buckets . The operation of an admission control subsystem is described in more detail below according to various embodiments.

As illustrated in this example in some embodiments service request subsystem may include multiple service request queues shown as service request queues each of which queues requests for a particular subset of the service requests provided by computing system . For example in some embodiments requests may be placed in a particular one of service request queues according to the type of service request e.g. according to the Web service API called to make the request . In other embodiments requests may be placed in a particular one of the service request queues that maintains a queue for a particular web based service for a particular client of the computing system or for a particular group of clients of the computing system e.g. for clients having a particular priority or service level . In some embodiments the system may apply a stochastic fair queuing algorithm as part of its process for determining the particular one of a plurality of service request queues in which to place a given request. For example in some embodiments a request may be placed in a particular service request queue dependent on a hashing of a portion of the information included in the request e.g. information identifying the client from which the request was received a client group or classification the request type a service level or any other information included in the request . In such embodiments the hashing applied to the requests may be keyed with a periodically changing key in order to avoid or prevent starvation of the service threads or other constrained resources being managed in the system. The operation of a service request subsystem is described in more detail below according to various embodiments.

Note that in various embodiments the components illustrated in may be implemented directly within computer hardware as instructions directly or indirectly executable by computer hardware e.g. a microprocessor or computer system or as a combination of these techniques. For example the components of the computing system may be implemented by a distributed system including any number of computing nodes or simply nodes . In various embodiments the functionality of a given component may be implemented by a particular node or distributed across several nodes. In some embodiments a given node may implement the functionality of more than one of the component illustrated in and or .

As illustrated in a first stage of the admission control strategy described herein may employ a set of resource queues one per constrained resource on which various services may be dependent and each of those resource queues may be associated with a resource token bucket for that constrained resource. In some embodiments a fixed e.g. a pre determined or default number of resource tokens may be placed into each resource token bucket at launch time or during configuration of the system. In some embodiments the initial number of resource tokens allocated to each resource queues and corresponding constrained resources may be dependent on the available resources in the system. For example in some embodiments a resource token bucket associated with a resource queue for a downstream service may be allocated a number of resource tokens that is equal to or dependent on the number of available service threads and or the maximum number of service threads that may be allocated to calls for each downstream service on which a service is dependent. In various embodiments the total number of service thread tokens allocated for all downstream services may be less than equal to or greater than the total number of service threads available in the system. Various service requests may collect resource tokens for constrained resources on which they depend and may cause them to be returned to the same or other token buckets following the completion of the requested service. In some embodiments the number of resource tokens allocated to a given resource token bucket may be subsequently modified as described in more detail below.

In some embodiments when a service call sometimes referred to herein as a service request is received by a system that provides one or more services it may be categorized according to the dependencies it requires e.g. according to the constrained resources on which it depends and may be placed into a respective queue for each of these dependencies. Each of these resource queues may be continuously serviced with work items requests being removed from the resource queue and assigned resource tokens as the token bucket for that resource queue is continuously refilled. When a request has been removed from all its dependency queues i.e. when it has collected resource tokens for all of the constrained resources on which it is dependent the request may be available for queuing in the second stage e.g. in a service request queue. As noted above once the request has been processed to completion all of the resource tokens allocated to it may be placed back in the relevant token buckets for each of these constrained resources unless they are placed into a different token bucket as a result of a re allocation exercise. Note that in some embodiments if a request times out before collecting resource tokens for all of the constrained resources on which it is dependent e.g. if it remains in one or more resource queues longer than a pre determined timeout period the entire request may fail and any resource tokens that had been collected up to that point may be returned to the resource token buckets from which they were obtained and or to other resource token buckets. Note also that if one or more queues in the system into which a request is to be placed e.g. one or more relevant resource queues or an applicable service request queue has reached a pre determined length limit the request may be rejected outright in some embodiments.

A method for allocating constrained resources to heterogeneous service requests is illustrated by the flow diagram in according to one embodiment. As illustrated in this example the method may include a computing system configured to provide various services to clients receiving a request for a service e.g. a Web based service as in . The method may include determining that the requested service is dependent on one or more constrained resources e.g. downstream services database connections input output channels computational resources execution threads system memory disk memory or other persistent storage resources or any other constrained resources as in . In some embodiments the computing system may place the request in a resource queue for one of the constrained resources on which the requested service is dependent as in . For example placing a request in a queue e.g. in one of the resource queues and or service request queues described herein may in some embodiments involve adding an identifier of the request to the queue. If the request is dependent on other constrained resources shown as the positive exit from the method may include adding an identifier of the request to a resource queue for each of the other constrained resources on which the requested service is dependent. This is illustrated in by the feedback from to .

As illustrated in this example in response to the request reaching the head of a resource queue the computing system may dispense a resource token for the corresponding constrained resource to the request from a resource token bucket associated with the resource queue as in . If the request is dependent on other constrained resources shown as the positive exit from the method may include the request collecting resource tokens for each of the other constrained resources on which the requested service is dependent as the request reaches the head of the respective resource queue for each of those constrained resources. This is illustrated in by the feedback from to . In one embodiment each resource token in the system may include a unique identifier and each request may be associated with a data structure that includes an identifier of the request and an array in which such unique token identifiers may be stored when a resource token for each dependent resource is dispensed to the request. In this example each token bucket may be implemented as a data structure e.g. an array storing the unique identifiers of the resource tokens in the bucket. In this example when a resource token is dispensed from a token bucket one of the unique token identifiers may be removed from the token bucket data structure and written in the request data structure. In this example when a service request is completed the unique token identifiers dispensed to that request may be deleted from the request data structure and written into one or more token bucket data structures.

In some embodiments once the resource has collected a resource token for each of the constrained resources on which the requested service is dependent the method may include granting the one or more constrained resources to the request to perform the requested service as in .

In this example Web service B is also dependent on two downstream services or other constrained resources resource R and resource R . When the admission control subsystem receives a request for Web service B an identifier of the request shown in as B is added to the resource queues for resource R and R . In this example Web service C is dependent on only one downstream service or other constrained resource resource R . When the admission control subsystem receives a request for Web service C an identifier of the request shown in as C is added to the resource queue for resource R . In this example Web service D is dependent on three downstream services or other constrained resources resource R resource R and resource R . When the admission control subsystem receives a request for Web service D an identifier of the request shown in as D is added to the resource queues for resource R R and R . In this example none of the four illustrated Web services are dependent on resource R and there are no pending requests for resource R in its queue .

As illustrated in once the request has collected a resource token for each of the constrained resources on which it depends the method may include the admission control subsystem passing the request to a service request subsystem as in . In some embodiments the service request subsystem may place the request in a service request queue as in . In this example in response to the request reaching the head of the service request queue the request may be granted each of the constrained resources on which it depends from a corresponding resource pool as in and the computing system may perform the requested service. Once the requested service has been performed the resource tokens that were collected by the resource may be returned to the token buckets from which they were obtained as in . Note that in some embodiments and in some cases not all of the resource tokens collected by the request may be returned to the same resource token bucket from which they were obtained. For example in some embodiments the number of resource tokens allocated to a given resource token bucket may be dynamically adapted e.g. based on the observed performance of the system. A method for dynamically re allocating resource tokens to resource token buckets for a respective constrained resource queue is illustrated in and described in detail below.

In some embodiments service requests that are dependent on one or a small number of constrained resources may be processed ahead of service requests that were issued or received earlier but that are dependent on a larger number of constrained resources or on one or more resources that are more tightly constrained than others i.e. less frequently available . is a flow diagram illustrating a method for processing a service request that depends on a single constrained resource according to one embodiment. In this example an admission control component e.g. the admission control subsystem illustrated in may receive a given request for a service e.g. a Web based service that is dependent on a single constrained resource as shown in . As illustrated in the admission control component may add an identifier of the given request to a queue for the constrained resource as in . In this example another request i.e. a request already in the queue for the same constrained resource is dependent on one or more other constrained resources in addition to being dependent on the single constrained resource on which the given request is dependent.

In this example the other request reaches the head of the resource queue receives a resource token from the corresponding resource token bucket and then waits to reach the head of one or more other resource queues those associated with the other constrained resources on which it depends as in . While the other request waits to reach the head of the one or more other resource queues the given request reaches the head of the resource queue as in and receives a resource token from the corresponding resource token bucket as in . As illustrated at in this example once the given request receives a resource token for the only constrained resource on which it depends the admission control component may pass the given request to a service request component such as the service request subsystem illustrated in in order to queue the service for execution even though the given request was issued and or received by the admission control component after the other request was issued and or received by the admission control component.

Note that in various embodiments out of order processing of service requests such as described above may be applied for any number of resource requests that wait on different ones of and or different numbers of constrained resources. In other words any given request that collects resource tokens for all of its dependencies may be passed to the service request subsystem even if the given request was issued received after other requests that are dependent on some of the same constrained resources but that are still waiting to receive one or more resource tokens for other constrained resources on which the given request does not depend.

Out of order processing of received service requests may be further illustrated by way of the example data flow diagram in . Specifically illustrates the processing of two service requests by various subsystems of a computing system that provides Web based services according to one embodiment. In this example a request D shown as in is passed from Web service interface e.g. on behalf of a client to admission control subsystem . This request is for a service D which is dependent on constrained resources R R and R in this example. As described above admission control subsystem may place an identifier of request D in the resource queues for resources R R and R. At some point after request D is passed to admission control subsystem a request C shown as in is passed from Web service interface to admission control subsystem . This request is for a service C which is also dependent on constrained resource R in this example. Therefore admission control subsystem may place an identifier of request C in the resource queue for resource R.

In this example since request D was placed in the resource queue for resource R prior to request C it may reach the head of that resource queue and collect one of the resource tokens for resource R before request D reaches the head of that resource queue. However since request D is also dependent on resources R and R this request may need to wait to reach the head of the request queues for these additional resources before it can be passed to service request subsystem . In the meantime request C may reach the head of the resource queue for resource R and may collect one of the resource tokens for resource R. Since resource R is the only resource on which request C depends it may be passed from admission control subsystem to service request subsystem as soon as it receives the resource token for resource R. This is illustrated in as request C being passed from admission control subsystem to service request subsystem shown as prior to request D being passed from admission control subsystem to service request subsystem shown as . As described above when requests C and D are received by service request subsystem they may be placed in a service request queue e.g. the same service request queue or two different service request queues for subsequent servicing.

In the example illustrated in request C reaches the head of the service request queue in which it was placed prior to request D reaching the head of the service request queue in which it was placed and or the queue in which request C was placed is serviced prior to the queue in which request D was placed e.g. according to a round robin or weighted round robin scheme . Therefore request C may be passed to one of resource pools shown as granted the resource on which it is dependent resource R and dispatched for execution prior to request D being passed to one or more of resource pools shown as granted the resources on which it is dependent resources R R and R and dispatched for execution.

In some embodiments the second stage of the admission control approach described herein i.e. the portion of the admission control approach employing one or more service request queues in a service request subsystem may ensure fairness of queuing across heterogeneous requests. In some embodiments requests of different types e.g. calls to different Web service APIs may be placed in separate queues and each queue may be serviced based on a dispatch rate weighted round robin scheme. For example a Web service containing two APIs DescribeThing and CreateThing may include two service request queues one containing DescribeThing requests and one containing CreateThing requests. If both requests are dispatched at approximately the same per thread rate the service request queues may be serviced equally. However if CreateThing runs for twice as long as DescribeThing on average then the DescribeThing queue may be serviced twice as often as the CreateThing queue. Note that in other embodiments the requests in different service request queues may be serviced according to a round robin approach that is weighted by criteria other than dispatch rates or that is unweighted. In other embodiments the system may employ any other suitable method for selecting requests to be serviced from among the requests in two or more service request queues.

In the example above if there are execution threads and or other constrained resources on which pending requests are dependent available the dispatch rate weighted round robin strategy described above may have no effect on the execution time or order of processing of different requests. However as the system saturation point is reached the rate of the dispatch of cheaper calls may increase relative to the rate of the dispatch of more expensive calls. This is most interesting during short load peaks which may be common due to the Poisson process nature of traffic loads on typical large scale Web services when throughput on cheap calls may be preserved in favor of more expensive calls. Therefore in some embodiments request queue priorities may be calculated dynamically which may preserve overall system throughput.

The operation of a service request subsystem is illustrated by the flow diagram in according to one embodiment. Specifically illustrates one embodiment of a method for processing service requests of different types. As illustrated at in this example the method may include a service request subsystem receiving one or more requests for services e.g. Web based services from an admission control subsystem such as that described herein. In this example each of the requests for services is dependent on one or more constrained resources. In some embodiments the service request subsystem may place an identifier of each service request in one of a plurality of service request queues as in . For example in some embodiments the service request subsystem may route requests to a particular one of the service request queues dependent on the type of service that was requested and or on the specific service that was requested e.g. the API called to submit the request . In other embodiments other criteria may be used to partition requests for services received by a service request subsystem into two or more service request queues. In still other embodiments the service request subsystem may include only a single service request queue and all requests passed from the admission control subsystem are placed in this queue in response to having been granted a resource token for each of the constrained resources on which it is dependent.

As illustrated in this example one of the requests may reach the head of the service request queue in which it was placed as in . As described above in some embodiments the service request subsystem may service the service request queue in which the request was placed according to a round robin or weighted round robin scheme as in . In other words the service request subsystem may select a request to service next from among the requests that have reached the head of each of the plurality of service request queues using a round robin or weighted round robin approach. When the request is serviced it may be granted the one or more constrained resources for performing the requested service from respective resource pool s and dispatched for execution as in . If there are more service requests in the service request queues of the service request subcomponent shown as the positive exit from the method may include continuing to select and dispatch requests and allocating to them the constrained resources on which they depend for any remaining requests in the service request queues according to the scheme in place for selecting requests to dispatch from among the service request queues. This is shown in by the feedback from to . If there are no more service requests in the service request queues to be processed shown as the negative exit from the method may include the service request subsystem waiting to receive one or more additional requests for services and then processing those additional requests in the manner illustrated in . This is shown in by the feedback from to . Note that the operations illustrated in may be performed continuously as individual service requests and or collections of service requests are received by and processed in the service request subsystem.

As previously noted in some embodiments one or more resource token buckets may be dynamically resized based on the measured performance of downstream services and or the measured performance of various resource queues . For example when a downstream service speeds up leading to higher rates of dispensing its resource tokens additional tokens may be placed in or allocated for its token bucket to increase throughput for calls depending on that downstream service. Alternatively if a downstream service slows down leading to lower rates of dispensing its resource tokens tokens may be removed from or deallocated from its token bucket to preserve throughput for other calls. In some embodiments the system may support explicit timeouts for service calls in flight to prevent sudden failures causing starvation.

A method for dynamically allocating and or re allocating resource tokens to resource token buckets associated with different constrained resource queues is illustrated by the flow diagram in according to one embodiment. As illustrated at in this example each resource token bucket corresponding to a respective one of a plurality of constrained resource queues may receive an initial number of resource tokens. For example an admission control subsystem may allocate a particular number of resource tokens to each of the constrained resources for which it includes a resource queue based on a default value the number of available resources in the system previously observed performance or other criteria. In some embodiments each resource token bucket may initially be allocated the same number of resource tokens while in other embodiments the number of resource tokens initially allocated to different resource token buckets may be different. As described herein resource tokens may in general be returned to the resource token buckets from which they were obtained after their use unless there has been a reallocation of resource tokens in the system since they were obtained. As illustrated in this example once an initial allocation of resource tokens to resource token buckets has been made or at any other time such as at the launch or configuration of the admission control subsystem the system may begin monitoring performance of each of the constrained resource queues as in . For example in various embodiments the system may periodically or continuously measure one or more of token dispensing rates average token dispensing rates latency or average latency for service requests times or average times that requests remain in various queues service request failure rates time to failure or average time to failure system response times average response times or any other suitable performance measurements in the system and or for any of the queues therein.

As illustrated in this example if one or more of the resource queues is performing well e.g. if their throughput exceeds an expected performance level and or the performance of one or more other resource queues shown as the positive exit from these faster queues may receive additional resource tokens as in . For example in some embodiments as a result of such a re allocation exercise resource tokens may be added to a resource token bucket immediately. In other embodiments as tokens obtained for one or more other constrained resources are returned to the admission control subsystem they may added to the token buckets of one of these faster resource queues instead of to the token buckets from which they were obtained. Alternatively if one or more of the resource queues is not performing well e.g. if their throughput is less than expected and or than that of one or more other resource queues shown as the positive exit from the number of resource tokens may be reduced for these slower queues as in . For example in some embodiments as a result of such a re allocation exercise resource tokens may be removed from a resource token bucket immediately. In other embodiments as tokens obtained for the corresponding constrained resources are returned to the admission control subsystem they may added to the token buckets of other resource queues instead of to the token buckets from which they were obtained. As illustrated in this example the system may in some embodiments continue monitoring the performance of some or all of the constrained resource queues as in and adaptively re allocating resource tokens to resource token buckets in response to observed performance as long as the admission control subsystem is in operation. This is illustrated in by the feedback from to .

In some embodiments the system and methods described herein for allocating constrained resources to service requests may be employed in a system through which various services are provided to subscribers as part of a virtualized computing service. In various embodiments such virtualized computing may be offered as an on demand paid service to clients. For example an enterprise may assemble and maintain the various hardware and software components used to implement virtualized computing and may offer clients access to these resources according to various pricing models e.g. usage based pricing subscription pricing etc. . Thus clients may have access to a range of virtual computing resources without having to incur the costs of provisioning and maintaining the infrastructure needed to implement those resources.

It is contemplated that in some embodiments any of the methods techniques or components described herein may be implemented as instructions and data capable of being stored or conveyed via a computer accessible medium. Such methods or techniques may include for example and without limitation various methods for allocating constrained resources to service requests as described herein. Such instructions may be executed to perform specific computational functions tailored to specific purposes e.g. processing requests received via a web services interface determining whether requests are dependent on constrained resources placing requests in queues for those constrained resources dispensing resource tokens for constrained resources and or servicing requests from one or more service request queues after they have collected resource tokens for each of the constrained resources on which they depend as described herein as well as higher order functions such as operating system functionality virtualization functionality network communications functionality application functionality storage system functionality and or any other suitable functions.

One example embodiment of a computer system that includes computer accessible media and that allocates constrained resources to service requests using the mechanisms described herein is illustrated in . In various embodiments the functionality of any of the various modules or methods described herein may be implemented by one or several instances of computer system . In particular it is noted that different elements of the system described herein may be implemented by different computer systems . For example a computer system that supports the functionality described herein for allocating constrained resources to service requests may be implemented on the same computer system on which a client through which a user requester accesses the system executes or on another computer system in different embodiments. In another example different subsystems e.g. an admission control subsystem and a service request subsystem different resource queues and or different service request queues may be implemented on or across multiple ones of the computing nodes and each of the computing nodes may be similar to computer system .

In the illustrated embodiment computer system includes one or more processors coupled to a system memory via an input output I O interface . Computer system further includes a network interface coupled to I O interface . In various embodiments computer system may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processor capable of executing instructions. For example in various embodiments processors may be a general purpose or embedded processor implementing any of a variety of instruction set architectures ISAs such as the 86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store instructions e.g. code and data e.g. in data store accessible by processor . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment instructions and data implementing desired functions methods or techniques such as functionality for supporting the allocation of constrained resources to service requests according to the APIs and other mechanisms described herein are shown stored within system memory as code . It is noted that in some embodiments code may include instructions and data implementing desired functions that are not directly executable by processor but are represented or encoded in an abstract form that is translatable to instructions that are directly executable by processor . For example code may include instructions specified in an ISA that may be emulated by processor or by other code executable on processor . Alternatively code may include instructions procedures or statements implemented in an abstract programming language that may be compiled or interpreted in the course of execution. As non limiting examples code may include code specified in a procedural or object oriented programming language such as C or C a scripting language such as perl a markup language such as HTML or XML or any other suitable language.

In some embodiments data store within system memory may store data in one or more request queues resource queues resource request data structures resource token bucket data structures or other data structures suitable for implementing the techniques described herein.

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computer system and other devices attached to a network such as other computer systems for example. In various embodiments network interface may support communication via wired or wireless general data networks such as any suitable type of Ethernet network for example via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may include a non transitory computer accessible storage medium configured to store instructions and data as described above. However in other embodiments instructions and or data may be received sent or stored upon different types of computer accessible storage media. Generally speaking a computer accessible storage medium may include storage media or memory media such as magnetic or optical media e.g. disk or CD DVD ROM coupled to computer system via I O interface . A computer accessible storage medium may also include any volatile or non volatile storage media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computer system as system memory or another type of memory. A computer accessible storage medium may generally be accessible via transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface .

Although the embodiments above have been described in considerable detail numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

