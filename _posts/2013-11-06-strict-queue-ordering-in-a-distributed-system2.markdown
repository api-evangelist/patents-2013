---

title: Strict queue ordering in a distributed system
abstract: Methods and systems for implementing strict queue ordering in a distributed system are disclosed. A plurality of messages are distributed to a plurality of queue servers based on strict order parameters for the messages. Messages that share a strict order parameter are distributed to a respective one of the queue servers. Sequence identifiers are assigned to the plurality of messages at the queue servers. Each sequence identifier indicates a respective position in a message sequence for a corresponding one of the strict order parameters. The respective position is based on a time of receipt at the queue server. The plurality of messages are enqueued based on the sequence identifiers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09654408&OS=09654408&RS=09654408
owner: Amazon Technologies, Inc.
number: 09654408
owner_city: Reno
owner_country: US
publication_date: 20131106
---
Many companies and other organizations operate distributed systems that interconnect numerous computing systems and other computing resources to support their operations such as with the computing systems being co located e.g. as part of a local network or instead located in multiple distinct geographical locations e.g. connected via one or more private or public intermediate networks . For example data centers housing significant numbers of interconnected computing systems have become commonplace such as private data centers that are operated by and on behalf of a single organization and public data centers that are operated by entities as businesses to provide computing resources to customers. As the scale and scope of typical distributed systems has increased the tasks of provisioning administering and managing the computing resources have become increasingly complicated.

For example a queuing service may be implemented using a distributed system in a manner that prioritizes high availability and redundancy. However prior approaches for implementing a distributed queuing service may present messages out of their intended order. Additionally prior approaches for implementing a distributed queuing service may present a message more than the number of intended times e.g. once . The presentation of messages out of their intended order and the presentation of messages more than once may pose problems for applications that require strict queue behavior.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to. 

Various embodiments of methods and systems for implementing strict queue ordering in a distributed system are described. In a distributed strict queue system with multiple queue servers each queue server may be assigned a portion of a range of values for a strict order parameter. Based on the value of its strict order parameter an incoming message may be forwarded to the appropriate queue server for the value of the strict order parameter and the queue server may assign a sequence identifier to the message. The message may then be presented in the intended order with respect to other messages with the same value for the strict order parameter. Additionally each message may be delivered to a queue consumer once and only once in the distributed strict queue system.

Various embodiments of methods and systems for implementing a pre processing and processing pipeline for a queue client are described. For any given message in a queue a queue client may obtain an estimated time to pre process the message and an estimated time to process the message. Based on these estimated times for consecutive messages in the queue the client may perform pre processing operations for a later message e.g. fetching data required for processing while continuing to process an earlier message. In this manner the queue client may perform all or part of the pre processing for a particular message by the time the client is ready to process the message. In one embodiment the processing and pre processing may be performed simultaneously for consecutive messages with different strict order parameters or when the pre processing stage does not have a strictness guarantee.

In one embodiment the strict queue s may include messages associated with different values for a strict order identifier. Messages with the same value for the strict order identifier may be enqueued in the correct order relative to each other. However for messages with different values for the strict order identifier the queue service may use a best effort ordering technique that is not guaranteed to present messages with different values for the strict order identifier in the correct order. The best effort ordering may result in some messages with different values for the strict order identifier being processed by queue clients in a different order than the messages were received by the queue service . Accordingly the strict queue s may be strict for messages with the same value for the strict order identifier and non strict for messages with different values for the strict order identifier.

It is contemplated that the distributed strict queue system may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although three queue producers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue producers may be used. Additionally although three queue servers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue servers may be used. Furthermore although three queue consumers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue consumers may be used.

The distributed strict queue system may comprise one or more computing devices any of which may be implemented by the example computing device illustrated in . In various embodiments portions of the functionality of the distributed strict queue system including the queue producers A N queue servers A N and or queue consumers A N may be provided by the same computing device or by any suitable number of different computing devices. If any of the components of the distributed strict queue system are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

In some embodiments the queue servers A N and queue consumers A N may be implemented as virtual compute instances or as physical compute instances. The virtual compute instances and or physical compute instances may be offered to clients provisioned and maintained by a provider network that manages computational resources memory resources storage resources and network resources. A virtual compute instance may comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . One or more virtual compute instances may be implemented by the example computing device illustrated in .

In one embodiment a suitable component of the distributed strict queue system may select and or provision the queue servers A N and or queue consumers A N. For example the queue servers A N and or queue consumers A N may be provisioned from a suitable pool of available computing instances. In one embodiment additional computing instances may be added to the queue servers A N and or queue consumers A N as needed. In one embodiment computing instances may be returned to the pool of available computing instances from the queue servers A N and or queue consumers A N if the computing instances are not needed at a particular point in time.

In one embodiment the functionality of the distributed strict queue system may be provided to clients using a provider network. For example the functionality of the distributed strict queue system may be presented to clients as a web accessible service. A network set up by an entity such as a company or a public sector organization to provide one or more services such as various types of cloud based computing or storage accessible via the Internet and or other networks to a distributed set of clients may be termed a provider network. A provider network may include numerous data centers hosting various resource pools such as collections of physical and or virtualized computer servers storage devices networking equipment and the like that are used to implement and distribute the infrastructure and services offered by the provider. The resources may in some embodiments be offered to clients in units called instances such as virtual or physical compute instances or storage instances. A virtual compute instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . A number of different types of computing devices may be used singly or in combination to implement the resources of the provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like.

In one embodiment operators of provider networks may implement a flexible set of resource reservation control and access interfaces for their clients. For example a provider network may implement a programmatic resource reservation interface e.g. via a web site or a set of web pages that allows clients to learn about select purchase access to and or reserve resources. In one embodiment queue resources may be reserved on behalf of clients using a client accessible service that implements the distributed strict queue system . According to one such embodiment a distributed strict queue system in such an environment may receive specifications for the various messages to be enqueued e.g. a description of one or more tasks and an indication of a source of input data to be used by the task s . In response the distributed strict queue system may enqueue and execute the task s using one or more resources of a selected resource pool of the provider network. In one embodiment the resource pool may be automatically selected based on the anticipated computational needs of the various tasks. In one embodiment the resource pool may be selected based on a specific resource request or reservation submitted by the client.

In one embodiment the client may use one or more suitable interfaces such as one or more web pages an application programming interface API or a command line interface CLI to provide the various messages to be enqueued and otherwise configure the distributed strict queue system . In one embodiment the client may be able to view the current status of the messages using the interface s . In one embodiment additional information about messages in the distributed strict queue system may be available via the interface s such as program output error logs exception logs and so on.

In one embodiment the messages A N may be received by one or more designated instances of the queue servers A N. As shown in for example the messages A N may be received by substantially any of the queue servers such as queue server A and queue server B for example. Based on the value of the strict order parameter associated with a message the queue server that initially receives the message from the corresponding queue producer may forward the message to a particular queue server that is associated with that value of the strict order parameter.

In one embodiment a range of values for the strict order parameter may be divided among the queue servers A N such that a particular one of the queue servers may be responsible for handling messages identified by each value of the strict order parameter. The range of values may include any collection of values and the values may include integers alphanumeric values binary values etc. In one embodiment each value of the strict order parameter may be assigned to one and only one of the queue servers A N. In one embodiment any of the queue servers A N may be responsible for one or more values of the strict order parameters.

The value of the strict order parameter for a message may be generated by the corresponding queue producer. For example the value of the strict order parameter may be a string a binary value or an integer. In one embodiment a stable hash function may be applied by the initial recipient queue servers to the values of the strict order parameter as expressed in incoming messages. In this manner the various initial values for the strict order parameter may be standardized to a particular length and or data type within a known range for more efficient handling by the queue service . As used herein the term strict order parameter may refer to the original strict order parameter or the value thereof associated with a message or to the result of a hash function that uses the original strict order parameter as input. In one embodiment a message may be forwarded to an appropriate queue server i.e. a destination server based on the hash value.

In one embodiment each of the queue servers A N that is configured to receive incoming messages from the queue producers A N may include functionality for destination server determination. For example the queue server A may include a module A that implements the destination server determination functionality and the queue server B may include a module B that implements the destination server determination functionality. Using the destination server determination module A or B the corresponding queue server may compare the value of the strict order parameter of an incoming message to the range of values assigned to the various queue servers. The destination server determination module A or B may implement the destination server determination functionality using any suitable technique such as the use of a lookup function that maps an input value representing a strict order parameter to an output value representing a queue server. The destination server determination module A or B may determine the identity of the queue server to which the message should be forwarded i.e. the destination queue server based on the value of the strict order parameter for the message. The queue server A may forward one or more messages B to the queue server B based on one or more values of the strict order parameter and the queue server B may forward one or more messages A to the queue server A based on one or more values of the strict order parameter.

The value of the strict order parameter for the message may be within the range of values assigned to the destination queue server. The output of the destination server determination functionality may be stored for later reference using a module for storage of the destination server state. For example the queue server A may include a module A that implements the destination server state functionality and the queue server B may include a module B that implements the destination server state functionality. In one embodiment the destination server state A or B may represent a whole or partial list of active servers within the queue service .

In one embodiment the destination server determination modules A and B and or the states A and B may change if one or more new queue servers become active in the distributed strict queue system if one or more queue servers stop being active or are removed from the distributed strict queue system or if the range of values of the strict order parameter is otherwise reassigned to the queue servers. For example the range of strict order parameters may be rebalanced if a set of messages with a particular value for the strict order parameter begins placing excessive demands on the resources of the particular queue server assigned to that value of the strict order parameter. In such circumstances the load for the particular queue server may be reduced by reassigning one or more values of the strict order parameter to another queue server. As another example if the load provided by a set of messages with a particular value for the strict order parameter decreases sufficiently the responsible queue server may be assigned additional values of the strict order parameter so that it may optimize its resource usage. In one embodiment queue servers may be added to the distributed strict queue system or removed from the distributed strict queue system as needed to handle the current load and or anticipated load.

As shown in one or more components may be configured to serve as an interface between the queue producers A N and the queue servers A N. Each of the component s may be referred to as a forwarding server. Although one forwarding server is shown for purposes of example and illustration it is contemplated that different quantities and combinations of forwarding servers may be used. The forwarding server s may be implemented by the example computing device illustrated in . In one embodiment each forwarding server may be provisioned from among the queue servers A N. The one or more forwarding servers may be used to receive messages from the queue producers A N and forward each message to the appropriate queue server based on the value of the strict order parameter for the message. For example the one or more forwarding servers may forward one or more messages A to the queue server A based on one or more values of the strict order parameter one or more messages B to the queue server B based on one or more values of the strict order parameter and one or more messages N to the queue server N based on one or more values of the strict order parameter. As discussed above with reference to each forwarding server may include a module C for destination server determination and a module C for destination server state storage. The forwarding server s may be used with the distributed strict queue system on any suitable basis e.g. a queue by queue or account by account basis.

If the queue producer for a message does not supply a value for the strict order parameter then a value may be generated by another entity within the distributed strict queue system such as the queue server or forwarding server that initially receives the message from the queue producer. The value for the strict order parameter may be generated using any suitable technique including uniform random selection from a range of possible values e.g. within the same range of values assigned to the various queue servers A N or round robin selection from a range of possible values. The ranges of values may be a parameter of the distributed strict queue system or configurable per strict queue.

The queue server A may include a sequence identification functionality A. In one embodiment each incoming message within the range of strict order parameters assigned to the queue server A may undergo sequence identification using the sequence identification functionality A. The sequence identification functionality A may employ any suitable technique to assign each incoming message a place in a message sequence for the corresponding value of the strict order parameter. For example the sequence identification functionality A may generate a message sequence for the first value based on the messages received over time. The message sequence may indicate an ordering of the messages based on the time of receipt at the queue server A. The time of receipt may be based on the time of receipt of the first byte received the time of receipt of the last byte received or any time in between. Accordingly the message sequence for the first value may place the earlier message A before the later message N.

The sequence identification functionality A may assign a sequence identifier to each message. Each sequence identifier may indicate a respective position in the message sequence for the message where the respective position is based on the time of receipt e.g. the time of receipt of the first byte received the time of receipt of the last byte received or any time in between . In one embodiment the sequence identifier may include a timestamp e.g. indicating the time of receipt and or an ordinal number indicating the relative position of the message in a sequence associated with a particular value of the strict order identifier. In one embodiment the sequence identification functionality A may remember the last sequence identifier for a particular value of the strict order parameter as long as the particular value is active in the distributed strict queue system and associated with new messages provided to the queue server A. If the particular value of the strict order parameter has not been associated with a new message since the last message was delivered to a queue customer then the message sequence for that particular value may be discarded. The message sequence may be restarted e.g. from the beginning if the one or more queue providers resume sending messages with the particular value of the strict order parameter to the queue server A.

After the sequence identifier has been added to an incoming message the queue server A may enqueue the message in a logical queue A. In one embodiment a logical queue may be managed by a single queue server e.g. server A and may contain only those messages associated with a particular value for the strict order parameter. The logical queue A may be strictly ordered for messages with a particular value of the strict order parameter. By referencing the sequence identifiers for messages having a particular value of the strict order parameter the messages may be added to the logical queue A in the order in which the messages were received by the queue server A that is designated to handle the particular value. As a result the logical queue A may include the messages for a particular value of the strict order parameter in a strict order relative to each other. For example the earlier message with a sequence identifier with the first value A and the later message with a sequence identifier with the first value N may be enqueued in the correct order relative to each other.

As shown in the queue server A may receive messages having different values for the strict order parameter. Although the queue server functionality is illustrated with reference to queue server A it is contemplated that the same or similar functionality may be implemented by any of the queue servers A N in the distributed strict queue system . At least two of the values of the strict order parameter may be assigned to the queue server A e.g. within a range of values assigned to the queue server A. Accordingly the queue server A may receive a set of messages from one or more of the queue producers A N where the set of messages includes both messages with a first value for the strict order parameter and messages with a second value for the strict order parameter. The messages may be received at different points in time. For example the messages may include an earlier message A and a later message N with the first value and the messages may also include an earlier message A and a later message N with the second value. Any suitable number of messages may be received by the queue server A. As discussed above the messages may be forwarded to the queue server A from another one of the queue servers or from a forwarding server based on the strict order parameters within the messages.

The queue server A may include a sequence identification functionality A. In one embodiment each incoming message within the range of strict order parameters assigned to the queue server A may undergo sequence identification using the sequence identification functionality A. The sequence identification functionality A may employ any suitable technique to assign each incoming message a place in a message sequence for the corresponding value for the strict order parameter. For example the sequence identification functionality A may generate a message sequence for the first value based on the messages A N with the first value received over time and the sequence identification functionality A may generate a message sequence for the second value based on the messages with the second value A N received over time. Each message sequence and may indicate an ordering of the messages based on the time of receipt at the queue server A. The time of receipt may be based on the receipt of the first byte of the message or the receipt of the last byte of the message. Accordingly the message sequence for the first value may place the earlier message A before the later message N and the message sequence for the second value may place the earlier message A before the later message N.

As discussed above the sequence identification functionality A may assign a sequence identifier to each message. Each sequence identifier may indicate a respective position in the message sequence for the message where the respective position is based on the time of receipt e.g. of the first byte or last byte . In one embodiment the sequence identifier may include a timestamp e.g. indicating the time of receipt and or an ordinal number indicating the relative position of the message in a sequence associated with a particular value of the strict order identifier.

After the sequence identifier has been added to an incoming message the queue server A may enqueue the message in a logical queue A for the first value of the strict order parameter or in a logical queue A for the second value of the strict order parameter. In one embodiment each logical queue A and A may be managed by a single queue server e.g. server A and may contain only those messages associated with a particular value for the strict order parameter. The logical queue A may be strictly ordered for messages with the first value of the strict order parameter and the logical queue A may be strictly ordered for messages with the second value of the strict order parameter. By referencing the sequence identifiers for messages having particular values of the strict order parameter the messages may be added to the appropriate logical queue A or A in the order in which the messages were received by the queue server A that is designated to handle the particular values. As a result the logical queue A may include the messages for the first value of the strict order parameter in a strict order relative to each other and the logical queue A may include the messages for the second value of the strict order parameter in a strict order relative to each other. For example the earlier message with a sequence identifier with the first value A and the later message with a sequence identifier with the first value N may be enqueued in the correct order relative to each other. Additionally the earlier message with a sequence identifier with the second value A and the later message with a sequence identifier with the second value N may be enqueued in the correct order relative to each other

In one embodiment the strict queue s may include a plurality of logical queues such as logical queues A and A. Each of the logical queues may be managed by a single queue server and may correspond to a particular value for the strict order parameter. Messages with the same value for the strict order identifier may be enqueued in the correct order relative to each other. However for messages with different values for the strict order identifier the queue service may use a best effort ordering technique that is not guaranteed to present messages with different values for the strict order identifier in the correct order. The best effort ordering may result in some messages with different values for the strict order identifier being placed in the queue s in a different order than the messages were received by the queue service . Accordingly the strict queue s may be strict for messages with the same value for the strict order identifier and non strict for messages with different values for the strict order identifier.

When a message is received by the primary server A and stamped with a sequence identifier the stamped message may be forwarded to the one or more backup servers e.g. secondary server B and tertiary server N . The replicated message A may be sent from the primary server A to the secondary server B and the replicated message B may be sent from the secondary server B to the tertiary server N. The tertiary server N may then send a confirmation of receipt N to the secondary server B and the secondary server B may then send a confirmation of receipt B to the primary server A. In one embodiment the primary server A may place the message in the logical queue A and or confirm the enqueuing of the message to the message source only after receiving the confirmation of receipt B from the secondary server B.

Similarly as shown in the example of when preparing to deliver a message to a consumer the primary server A may send updates A and B to the secondary server B and tertiary server N before delivering the message. The updates A and B may indicate that the primary server A is preparing to deliver the message. In one embodiment the message may be delivered to the consumer only after the one or more backup servers have confirmed receipt of the update s sent by the primary server e.g. with confirmations of receipt B and N. In one embodiment the delivery of a message to a consumer may include a preparation step in which the one or more backup servers are notified of the impending delivery a locking step to flag the message in the queue as locked after the message has been delivered and a deletion step to delete the message from the queue after the consumer has confirmed successful processing of the message. Updates A and B may be sent from the primary server to the one or more backup servers before each step and the step may be completed only after the one or more backup servers have confirmed receipt of the updates with receipt confirmations B and N. For example the primary server A may delete the message from the queue A only after receiving confirmation of processing from the consumer sending updates A and B to the secondary server B and tertiary server N and receiving confirmations B and N of receipt of the updates. In this manner the distributed strict queue system may provide guaranteed once delivery for messages i.e. a guarantee that each message is delivered once and only once using one or more backup servers in case the primary server A fails at some point during the delivery process.

In one embodiment in a similar manner as discussed above with reference to a queue consumer may be directed to an appropriate queue server based on one or more values of the strict order parameter assigned to the queue consumer. As shown in one or more components may be configured to serve as an interface between the queue consumers A N and the queue servers A N. Each of the component s may be referred to as a forwarding server. Although one forwarding server is shown for purposes of example and illustration it is contemplated that different quantities and combinations of forwarding servers may be used. The forwarding server s may be implemented by the example computing device illustrated in . The one or more forwarding servers may be used to receive requests from the queue consumers A N and forward each request to the appropriate queue server based on the one or more values of the strict order parameter associated with the requesting queue consumer. After a forwarding server determines a corresponding queue server for a particular queue consumer the queue server may push messages to the queue consumer or the queue consumer may pull messages from the queue server.

Each forwarding server may include a module for performing server determination a module for storing queue server state information and a module for storing queue consumer state information. In one embodiment one or more values of the strict order parameter may be assigned to each of the queue consumers using any suitable technique including uniform random selection from a range of possible values e.g. within the same range of values assigned to the various queue servers A N or round robin selection from a range of possible values. The value s of the strict order parameter associated with a particular queue consumer may be stored in the queue consumer state information . Using the server determination module the forwarding server s may compare the value s of the strict order parameter associated with a queue consumer to the ranges of values assigned to the various queue servers. The server determination module may implement the server determination functionality using any suitable technique such as the use of a lookup function that maps a value or range of values of the strict order parameter to a queue server. The server determination module may determine the identity of a queue server that should provide messages to a queue consumer based on one or more values or range of values of the strict order parameter associated with the queue consumer. The output of the server determination functionality may be stored for later reference using a module for storage of queue server state information.

After performing the server lookup process to determine the queue server responsible for a particular value or range of values of the strict order parameter the server determination module or any other suitable component of the forwarding server may forward a request e.g. a request from a queue consumer for messages to that queue server. If the logical queue corresponding to the value of the strict order parameter contains any messages that are available to the queue consumer then the queue server may return the next message in the logical queue to the queue consumer. If the logical queue corresponding to the value of the strict order parameter is empty then the association between the queue consumer and the value of the strict order parameter may be removed and the server determination module or any other suitable component of the forwarding server may restart the server lookup process.

If no queue server has messages among the queue servers that are responsible for the value s of the strict order parameter assigned to the queue consumer then the forwarding server may assign one or more new values or a range of values of the strict order parameter to the queue consumer and restart the lookup process. Alternatively the forwarding server may send a message to the queue consumer indicating that the queue consumer is not currently responsible for processing any messages. In response to such a message from the forwarding server the queue consumer may enter a sleep state in which its interaction with the distributed strict queue system is reduced.

By allowing queue servers to give preferential treatment to particular queue consumers based on the strict order parameter the efficiency and reliability of failover operations may be enhanced. Additionally the performance characteristics of a consumer may be enhanced by allowing the consumer to process messages for particular values of the strict order parameter particularly if the messages tend to require the same input data or other resources. The range of values of the strict order parameter assigned to various consumers may be rebalanced to optimize resource usage e.g. using load balancing techniques.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in a sequence identifier may be assigned to the message at the queue server responsible for all of the messages with the strict order parameter. The sequence identifier may indicate a respective position in a message sequence for the strict order parameter. The respective position may be based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server.

As shown in the message may be enqueued based on the sequence identifier. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message.

The queue client may comprise one or more computing devices any of which may be implemented by the example computing device illustrated in . In various embodiments portions of the functionality of the queue client may be provided by the same computing device or by any suitable number of different computing devices. If any of the components of the queue client are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions. In some embodiments the queue client may be implemented as one or more virtual compute instances and or physical compute instances. It is contemplated that the queue client may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown.

The queue service may maintain one or more logical queues such as logical queue A and logical queue B. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store message A and message B through message N having one value for the strict order parameter and the logical queue B may store message A and message B through message N having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations.

In one embodiment the queue service may include functionality to estimate a time i.e. a duration of time to process one of the messages. Processing a message may include performing or implementing the one or more tasks described in the message. For messages with the same value for the strict order parameter the processing stage may have a strictness guarantee such that the queue service is expected to perform the processing of the messages in a particular predetermined order. The queue service may also include functionality to estimate a time i.e. a duration of time to pre process one of the messages. Pre processing a message may include any part of the message computation for which strict ordering between different messages is not required. For example pre processing a message may sometimes include performing one or more tasks to prepare the message for processing such as fetching or otherwise loading the data described in the message as input for the processing stage. When pre processing a message includes fetching data the elements of input data may be acquired from any appropriate source s such as local storage locations remote storage locations and or other servers in a distributed system.

In one embodiment the pre processing and processing time estimates may be configured at the queue level such that the same estimates may generally be applied to all the messages in the queue by default but the queue level estimates may be overridden for particular messages in a queue. In one embodiment each message may have its own respective time estimates. Therefore the queue service may store the pre processing and processing time estimates per queue A and or per message B. Any suitable techniques may be used to determine the estimates. In one embodiment the time estimates may be determined based on a user specified configuration per message and or per queue. In one embodiment information usable to determine the estimates may be supplied by the queue producer using any suitable interface presented by the queue service . For example a message size parameter may be supplied by the queue producer on a message by message basis. The message size parameter may be an integer for which smaller values tend to indicate a shorter processing time and for which larger values tend to indicate a longer processing time. In one embodiment the queue service may be configured to programmatically estimate the pre processing and or processing times based on analysis of performance of the queue client over time. For example the queue service may programmatically determine a relationship between the message size parameter and processing time for various processed messages and the queue service may programmatically determine a relationship between the message size parameter and pre processing time for various processed messages. In this manner the queue service may generate better estimates for the pre processing and or processing times of subsequent messages based on the determined relationships between the message size parameter and the pre processing and or processing times for prior messages.

The queue client may receive a sequence of messages from the queue service and process the messages. In one embodiment the queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A and B by sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to the queue client . Messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service . The queue client may send to the queue service an indication of the client s health at appropriate points in time. For example the queue client may send a health indication upon receipt of a message from the queue service . In general the health indication for a queue client may comprise any data usable by the queue service to determine whether to send additional messages to the queue client how many messages to send to the queue client and or how many logical queues to assign to the queue client. For example the health indication may tend to indicate the load at the client. Based on one or more of the health indications received over time the queue service may perform a rebalancing of the assignment of logical queues to the queue client and one or more additional queue clients. The queue service may also determine that a particular queue client is unnecessary if the other queue clients are able to handle the strict queue load consequently the queue service may reassign any logical queues to the other clients and may instruct the queue client considered unnecessary to enter a sleep state thereby reducing the queue client s traffic with the queue service

The queue client may also receive the time estimates for pre processing and processing each message. The time estimates for each message may be received along with the message on a message by message basis i.e. in a bundle along with the body of the message. In one embodiment relevant per queue time estimates A or relevant per message time estimates B may be sent by the queue service for each individual message.

Based on the pre processing and processing time estimates the queue client may implement a pipeline for pre processing and processing the messages . Using the pipeline the queue client may begin pre processing one message while continuing to process an earlier message. In other words the queue client may concurrently process one message and pre process another message. In one embodiment the queue client may include functionality for message pre processing and functionality for message processing . The message processor may be configured to perform the tasks described in the message e.g. by executing or interpreting instructions and or invoking functions or services included in the body of the message. In one embodiment the message pre processor may be configured to perform any tasks that may be used to prepare a message for processing such as fetching or otherwise loading the data described in the message as input for the processing stage. In general however the pre processing stage may include any computation for which a strict order guarantee is not required. For consecutive messages with different values for the strict order identifier both pre processing and processing may be performed concurrently. For consecutive messages with the same value for the strict order identifier the pre processing of the second message may sometimes be performed concurrently with the processing of the first message.

The queue client may include a scheduler component . In one embodiment the scheduler may schedule the receipt and or pre processing of the next message based on the estimated time to process the current message and estimated time to pre process the next message. For example if the estimated time to process the current message is 2.0 seconds and the estimated time to pre process the next message is 0.3 seconds then the scheduler may cause the queue client to begin pre processing the next message after the current message has been processing for 1.7 seconds. As a result the next message may be fully pre processed and ready for processing near the time when the processing of the current message is complete. Using the pipeline in this manner the queue client may perform all or part of the pre processing for a particular message by the time the client is ready to initiate the processing of the message. In one embodiment however the pre processing of the next message may be initiated at substantially any point in time during the processing of the current message even if the pre processing is likely to finish before the processing of the current message or after the processing of the current message.

When a message is first received by the queue client from the queue service the scheduler may receive and analyze the message. At different stages during the pre processing and processing of the message the queue service may use different flags to indicate the status of the message. For example the message may be flagged as prepared when sent to the queue client and as locked when processing begins. The message may be deleted from the queue or flagged for deletion when the queue service is informed by the queue client that processing is complete.

In one embodiment the queue client may include a heartbeat indicator functionality . Using the heartbeat indicator functionality the queue client may send one or more heartbeat indications at appropriate intervals. In one embodiment the health indications discussed above may be communicated using the same or similar modules. In one embodiment the heartbeat indication s may include data usable by the queue service to determine the load at the queue client . Using the heartbeat indication s for multiple queue clients the queue service may decide to put one or more of the clients to sleep if the heartbeats indicate that there are too many active clients for the current load represented by the queue s .

As shown in the queue client may initiate pre processing of the second message during the processing of the first message. The pre processing may comprise fetching data described in the second message or any other computation associated with the second message that is not required to be performed in a strict order with respect to the processing of the first message. The pre processing of the second message may be scheduled to begin based on the estimated time to process the first message and the estimated time to pre process the second message. In one embodiment the pre processing of the second message may be scheduled to be completed by the end of the processing of the first message based on the estimated time to process the first message and the estimated time to pre process the second message. In one embodiment the operation shown in may be performed during the processing of the first message based on analysis of the strict order parameters for the first and second messages.

As shown in the queue client may initiate processing of the second message. In one embodiment the processing of the second message may use any of the results generated from the pre processing of the second message. The processing of the second message may be initiated after the processing of the first message is completed. In this manner the queue client may implement a pipeline for pre processing and processing consecutive messages in a queue. The queue client may also send a status of the processing of any of the messages to the queue service e.g. after the processing of the message is complete.

In at least some embodiments a computer system that implements a portion or all of one or more of the technologies described herein may include a general purpose computer system that includes or is configured to access one or more computer readable media. illustrates such a general purpose computing device . In the illustrated embodiment computing device includes one or more processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may include any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store program instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code i.e. program instructions and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other devices attached to a network or networks such as other computer systems or devices as illustrated in for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer readable i.e. computer accessible medium configured to store program instructions and data as described above for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer readable media. Generally speaking a computer readable medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer readable storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer readable medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface . Portions or all of multiple computing devices such as that illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer readable medium. Generally speaking a computer readable medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc. In some embodiments a computer readable medium may also include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. In various of the methods the order of the steps may be changed and various elements may be added reordered combined omitted modified etc. Various of the steps may be performed automatically e.g. without being directly prompted by user input and or programmatically e.g. according to program instructions .

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description is to be regarded in an illustrative rather than a restrictive sense.

