---

title: Systems and methods for predictive text entry for small-screen devices with touch-based two-stage text input
abstract: Embodiments relate to systems and methods for predictive text entry for small touch-screen devices. A two-state input interface () of a device () can include a seek area (), which displays a subset of letters representing the full range of available letters. The user can select a first letter in that subset. A prediction engine () can generate a next most-likely letter () based on the currently inputted letter, using look-up tables or other techniques based on letter sequence probabilities. The user can respond with a right or left-swipe gesture, causing the prediction engine () to seek the most-likely next letter upstream or downstream in the alphabet. The user can also respond by touching the seek area causing the prediction engine () to seek the next predicted letter closest to the touch point. The prediction engine () can also generate a predicted completed word, for convenient user selection.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09274685&OS=09274685&RS=09274685
owner: Google Technology Holdings LLC
number: 09274685
owner_city: Mountain View
owner_country: US
publication_date: 20130315
---
The present disclosure relate to systems and methods for predictive text entry for small touch screen devices. The predicted text may include alphanumeric characters such as letters numbers punctuation or other symbols.

In the field of portable communication services manufacturers have built ever more capable wireless devices into increasingly compact form factors. Some wireless devices include a liquid crystal display LCD touch screen or other interactive display components that occupy a comparatively small area. For example the MOTOACTV fitness tracker has a touch screen size of 1.6 inches 40.64 mm with a resolution of 176 220 pixels. One of the challenges in bringing a high function small screen electronic device such as a watch or other wearable electronic device to market is the fact that the limited screen area makes it difficult to display a full range of data entry characters in the available touch screen space.

Instead of using a touch screen some devices use up down buttons to scroll through an alphabet and select characters for text entry. When a desired letter is displayed an enter button can be used to select that letter. Of course a touch screen can be used to implement virtual scroll and select buttons in a similar fashion. This type of text entry mechanism however may be cumbersome and frustrating to the user because it can potentially require very long scrolling actions to arrive at a letter or other symbol the user wishes to enter into a messaging dialing or other program.

Skilled artisans will appreciate that elements in the figures are illustrated for simplicity and clarity and have not necessarily been drawn to scale. For example the dimensions of many of the elements in the figures may be exaggerated relative to other elements to help to improve understanding of embodiments.

Embodiments of the present disclosure relate to systems and methods for predictive text entry for small touch screen devices. These concepts were originally developed for a compact mobile electronic device having a touch screen size of 1.6 inches 40.64 mm with a resolution of 176 220 pixels but it will be appreciated that these ideas can be implemented in electronic devices of other sizes including those with both larger and smaller touch screens. More particularly embodiments relate to platforms and techniques including a two stage interface for receiving user input on a touch screen device in which the user can be presented with a seek bar or area which represents the entire range of letters characters numbers and or other symbolic information in a compressed format.

For example in a seek bar that presents the entire range of the letters of the English alphabet the seek bar may present every other letter for a total of 13 displayed letters or can present other subsets of the full range of available letters. The user can touch the display at a first point in the seek bar near the area of a letter the user desires to select and touch a point for example at or near the letter m in the seek bar. In some implementations a selection bar or area as a second graphical interface element can then be generated and or updated based on the user s touch at the first point. The selection bar is configured to display the letters surrounding the first point touched on the seek bar. Thus in the case of the user touching a first point at or near the letter m on the seek bar the selection bar or area can present the user with the individual letters k l m n o or shorter or longer sets of the letters surrounding the letter m in the alphabet assuming a linear representation of the alphabet . The user can then slide the finger from the first point to touch a second point for example the letter n displayed in the selection bar if that is the letter the user wishes to select as input. Upon lifting off that second point and or by other user actions the selected letter n can then be inputted to a text editing box or other dialogue.

The user can then repeat the process of targeting a range for and then selecting individual letters or other symbolic elements until the user completes a desired input string. The user can select or activate a done button or other control when the message is composed or completed to send the text string to an application and or other software or service such as a messaging or dialing application. In various aspects the activity of entering text character numeric and or other types of symbolic information can be facilitated for a user operating an electronic device having a comparatively small touch screen including those that do not easily support the display of full or unabbreviated character sets in the available screen area and selection of one character from the full character set in a single stage manner.

In addition according to implementations herein the host device can incorporate a prediction engine and other logic and associated resources to generate the most likely next letter or letters to follow text selections the user has already made on the two stage input interface. By snapping or locating the target range of the alphabet to sections that include the most likely next letter s identified by the prediction engine ease of navigation can be further increased and efficiency of input operations can be enhanced.

Reference will now be made in detail to exemplary embodiments of the present disclosure which are illustrated in the accompanying drawings. Where possible the same reference numbers will be used throughout the drawings to refer to the same or like parts.

The electronic device can have a small form factor such as a watch style device an arm band device a belt style device or a head set device. As shown the electronic device can host or incorporate a number of hardware software and or other resources including a display and an operating system .

The display can be or include a light emitting diode LED organic light emitting diode OLED or liquid crystal display LCD and or displays having other types of panels or illumination elements. In some implementations the display can incorporate hardware based input components such as for example a capacitive or resistive touch sensitive panel allowing the user to enter data based on touch points or other actions on the screen. As noted the electronic device can be configured in a comparatively small form factor but the touch screen or display screen may be larger for low vision applications or other use cases. It may be noted that the electronic device can incorporate other input and output devices such as for example audio output via a speaker and or audio input via a microphone and or control input via mechanical buttons or switches.

As shown the electronic device can host or incorporate further hardware software and or other services or resources to provide an overall framework for operating the electronic device and conducting input communications and or other activity. The resources of the electronic device can include for example an operating system installed on the electronic device and controlling the data storage processing communications and or other resources of the electronic device and or accessed via the electronic device . As shown the electronic device can host a set of applications running through the operating system . The set of applications can be or include one or more applications and or other software services and or routines such as telephony applications messaging applications including texting instant messaging and or email applications word processing applications spreadsheet applications database applications social networking applications digital audio video player applications and or others.

The set of applications can access any one or more of a set of system resources hosted by or incorporated in the electronic device via an application programming interface API and or other interface channel bus and or connection. The set of system resources can include various hardware software and or other services logic or resources such as electronic memory local storage such as disk based optical and or electronic storage communications resources such as ports transmission hardware and or a set of antennas to permit wireless network operations such as connection to the Internet and or other public or private networks such as by cellular telephone wireless data packets WiFi connections or sessions and or others.

The set of antennas can be or include a single antenna or a set of multiple antennas for diversity and or other purposes. The set of antennas can be mounted externally to the electronic device as shown and or can be mounted internally within the electronic device and or can be mounted in other configurations. The set of system resources can include an interface manager which can be a set of routines logic services and or other resources executing and or supporting the processing of input to and or output from the electronic device including a two stage text input interface generated and presented on the display . According to some implementations the interface manager and or associated logic can be implemented as a self running system application service and or other resource that handles text input and editing operations and or operations on other symbolic elements.

In some implementations the interface manager may not report every entered letter or other symbolic element back to the calling application upon completion of the entry of each individual symbolic element. Instead the interface manager may only report a completed string after a user indicates that the complete string has been entered by touching a done virtual button on the touch screen. The two stage text input interface can incorporate a number of dialogues selection buttons or boxes and or other interface features to permit the user of device to enter textual and or other symbolic information into the electronic device despite a comparatively limited viewing area on display . Those interface objects can for instance include a cancel button . While the done virtual button and cancel button are illustrated as virtual buttons in implementations those buttons and any other of the buttons keys objects or switches may be mechanical or virtual.

As shown the two stage text input interface can include a view and or display area on the display with a selection component such as a capacitive or resistive touch panel in which the user of electronic device can input various data and perform other operations. In various aspects the user can operate the two stage text input interface to control a seek area from which the user can access or enter a selection area to view and enter elements from a subset of a set of symbolic elements shown e.g. in . The seek area can be configured in a linear or bar format in a two dimensional format and or in other formats or arrangements. The set of symbolic elements can include any type of symbolic data characters and or elements such as for example an alphabet in English and or other languages a set of numbers and or other numeric information a set of symbols such as for example commas periods parenthesis and or other typing or grammatical symbols mathematical symbols icons or other graphical information keyboard or telephone keypad symbols and or other characters data or information.

In certain implementations the set of symbolic elements and or other characters figures marks and or information is too long and or occupies too much screen area to fit into the seek area of the display while in other implementations the set of symbolic elements and or other characters figures marks and or information may be represented in full form on the display . The set of symbolic elements can be displayed in abbreviated format by for example showing only every Nth letter of the set where N 2 or by showing only representative elements of the set e.g. one happy face for a range of positive expression icons and one sad face for a range of negative expression icons .

As shown the two stage text input interface can include a set of controls to operate the two stage text input interface and to select various input processing or other actions such as to select navigate underline and or delete letters or other symbolic information among others according to platforms and techniques described herein. The set of controls shown include a number of virtual buttons with icons to activate various controls or actions. Of course the controls could be implemented as mechanical buttons voice control instructions gesture based motions of the electronic device e.g. as supported by a gyroscope or accelerometer or a combination of virtual button mechanical button voice control or motion based inputs.

For example the set of controls includes a selection virtual button that can be activated to switch between different sets of symbolic elements such as letter sets character sets symbol sets icon sets and or others. An upper lower case or shift virtual button can be activated to switch between lowercase and uppercase formats for the symbolic elements. A space virtual button can be activated to insert a blank space in the text editing box and or other dialogue entry area. A delete virtual button can be activated to delete or remove a selected symbolic element or elements from the text editing box and or other dialogue entry area. It will again be appreciated that while four specific virtual buttons are shown in the illustrated set of controls other amounts types layouts and configurations of buttons switches keys and or other icons or controls can be used including mechanical versions of those elements.

During operation the two stage text input interface can generate and or display the seek area to present a comparatively compact abbreviated filtered truncated and or otherwise reduced representation of the set of symbolic elements . For example the seek area can display a set of sampled letters taken from the complete English alphabet such as a . . . e . . . l . . . n . . . r . . . v . . . z as shown although it will be appreciated that other selections or samplings of letters or other symbolic elements can be used. In some implementations the reduced and or otherwise modified representation of the full set of symbolic elements and or other characters figures marks and or information shown in the seek area can be regularly separated sampled and or spaced within the ordinal or ordered list or arrangement of the set of symbolic elements . Thus the reduced and or modified representation of the set of symbolic elements can present every other symbolic element every third symbolic element every sixth symbolic element and or other ordered arrangements that are spaced apart using other spacing or sampling rules or techniques. As further examples the reduced representation of the set of symbolic elements and or other characters figures marks and or information can be generated using irregular and or variable spacing ordering or separation between the symbolic elements of the set of symbolic elements . The reduced or modified representation of the full set of symbolic elements and or other characters figures marks and or information presented in the seek area can permit the user to view a depiction of the entire range of the set of symbolic elements available for selection without necessarily showing every element in the set of symbolic elements .

According to various implementations and as shown in the user can view the reduced or modified representation of the set of symbolic elements in the seek area and touch a first point on a surface of the display on or around a desired letter or other element to cause a target range of the set of symbolic elements and or other characters figures marks and or information to appear in the selection area . The target range is a selection or subset from the full set of symbolic elements so that for example as shown five letters that might be covered by the touch point on the seek bar can be displayed. Other ranges of symbols surrounding a selected symbol can be used. For example if representative happy sad and neutral emoticons were displayed in the seek area touching the happy emoticon may result in a target range of five different types of happy emoticons to be displayed in the selection area .

The target range is a limited subset of the entire set of symbols available for text entry. In some implementations the selection area can likewise be configured in a linear or bar format in a two dimensional or matrix format and or in other formats or arrangements. The selection area can include touch screen input elements so that the user can touch a first point on the seek bar view in the selection area the target range symbols related to the first touch point then drag and or otherwise reposition the finger or a pointing instrument on one element in the target range on the selection bar that the user wishes to select.

For example as shown in after the user has identified and or selected the letter and or other symbol the user wishes to input the selected letter or other symbolic elements can appear in a text editing box and or other dialogue of the two stage character input interface . The text editing box can in various implementations be configured to display a done virtual button and or a cancel virtual button as shown as well as other buttons and associated operations. Of course the virtual buttons may be replaced by mechanical buttons that perform the same functions. The done virtual button can allow the user to indicate the completion of a textual string and or other input and for example initiate the transmission of a message contained in the text editing box to a messaging application in the set of applications dial a telephone number indicated by a string contained in the text editing box search for a song title with a phrase indicated by a string contained in the text editing box or to perform other actions. The cancel virtual button can allow the user to cancel and back out of the entry of a textual string and or other input for example to start another message or to take other actions.

The input operation of selecting a character e.g. letter number symbol icon etc. by touching a first touch point in the seek area followed by touching a second touch point in the selection area can be accomplished using one continuous and or uninterrupted motion by the user who may touch and drag a finger and or pointing instrument from a first touch point on the touch screen display to a second touch point on the touch screen display without lifting the finger or instrument off the surface of display . Alternately the two touches may be separate with a lifting of the finger off the surface of the display between the two touches.

Additionally the first touch point may be a sequence of touch points within the seek area with the final touch point operating to finalize the target range available for selection in the selection area . For example the user touches a first point in the seek area with a finger or pointing instrument and moves the finger continuously along the seek area to cause continuous updating of the target range shown in the selection area . If the target range is updated in a smooth continuous manner the letters and or other symbolic elements displayed in the target area may seem to scroll left right and or otherwise following the moving touch point on the seek area in a real time or near real time manner. Continuing the example if the user slides the finger off the seek area the target range displayed at the time the finger leaves the seek area is the target range available for selection of a character. The user then may continue the glide motion and touch a second point in the selection area . As feedback to the user a character related to the second point may be highlighted by enlarging that character or changing its color. This may assist the user to select a desired character. When the desired character is touched a lift off of the finger from a second point in the selection area adds the symbolic element to the text editing box .

In those regards and others the entry of letters or other symbolic elements via the two stage character input interface can therefore be performed with a single action using one finger or instrument although the two stage character input interface can also be configured to accept pauses and or discontinuities in the user s input contact with the display . For example the user may touch a first point in the seek area lift the finger from the seek area to select a target range touch a second point in the selection area and lift the finger from the selection area to select a character to be entered in the text editing box .

According to various implementations the two stage character input interface can likewise be configured so that if the user moves a finger and or pointing instrument all the way to either end of the selection area the target range shown in the selection area can enter a slow scrolling action or mode in which one symbolic element emerges at a time. When the desired element appears in this end of range slow scrolling mode the user can then lift the finger and or pointing instrument off the desired letter and or other symbolic element to select that element. Other techniques can be used to present the set of symbolic elements beyond the ends or boundaries of the available target range as initially shown in the selection area . Again the character under the second touch point may be highlighted to indicate the character that will be selected if the finger lifts off from that touch point.

In another example if the user touches a first point in the seek area to select a target range and lifts the finger and or pointing instrument directly off from the seek area the two stage character input interface can be configured to present the corresponding target range in the selection area for a predetermined amount of time in a hanging display fashion. If the user resumes by touching a second touch point in the selection area the letter and or other symbolic element selected can be highlighted such as by becoming enlarged and or changing color. Upon lift off of the finger from the selection area the highlighted symbolic element is entered into the text editing box . Alternately the user may touch another first point in the seek area to select another target range and continue text entry as previously described.

Further as another example when a user s finger or pointing instrument does not contact the display for a predetermined time such as for example 5 seconds the two stage character input interface can be configured to return to an initial or default condition and or position of the set of symbolic elements . In some implementations a default condition in those scenarios presents a target range positioned at or from the middle or center of the set of symbolic elements available from the selection area positioned at or from the first symbol and or other beginning of the set of symbolic elements positioned at or from the last symbol and or other end of the symbolic elements and or positioned at or from a set of most likely next characters based on any existing text in the text editing box . Additional features of the two stage character input interface can be incorporated in the device including those described in co pending U.S. application Ser. No. 13 584 966 entitled Systems and Methods for Touch Based Two Stage Text Input filed Aug. 14 2012 assigned or under obligation of assignment to the same entity as this application and which application is incorporated by reference in its entirety herein.

According to implementations the device can additionally incorporate a prediction engine and associated logic and resources to assist the user with on the fly suggestions for selection of a most likely next letter or letters based on the text input the user has supplied. In general the user can supply combinations of input actions including the selection of touch points on the seek area and the performance of touch or swipe gestures on the selection area to traverse the alphabet in desired directions while seeking or including predicted letters or words. As shown in a user can start by inputting an initial letter in the text editing box . In implementations as shown that first or initial letter can be inputted by making a first touch point on the lower bar of the seek area to pull up a target range of letters M through Q in the selection area . With that target range displayed the user can tap or otherwise select Q by creating a second touch point on the selection area as shown.

After the user has lifted off the second touch point as shown in B the letter Q can be displayed in the text editing box . At or around the same time the prediction engine can detect the entry of the letter Q and generate the letter u as the predicted next most likely letter . In implementations as shown the next most likely letter can be displayed in the center of the selection area for instance with a highlight mark to indicate to the user that letter is the most likely letter to follow the entered Q. The user can then select the most likely next letter u by touching a third touch point on that letter in the selection area .

After that action as shown in the text editing box can display the letters Qu. In implementations as shown the text editing box can also display a completed whole word prediction in the illustrated example the word Quote can be generated by the prediction engine . In implementations the two stage input interface can be configured to accept a touch point entry or other input on the whole word prediction to allow the user to proceed directly to entering the predicted whole word if desired. It will be appreciated however that in implementations a whole word prediction can be omitted or not be used. In addition to the possible display of the whole word prediction as shown in the prediction engine can generate a further next most likely letter in this case the letter o which is also displayed in the center of the selection area with a highlight mark . In the event the user does not wish to enter the next most likely letter that is the letter o the user can as shown in enter a right swipe gesture on the selection area .

Entry of the right swipe gesture can cause the prediction engine to determine the next most likely letter according to the direction of the swipe. In the illustrated example that letter can be determined to be the letter l which as shown in is then displayed as the next most likely letter on the selection area . In addition in implementations the prediction engine can also generate a new whole word prediction which now becomes the word Quiet which is displayed in the text editing box . The user can again choose to select and enter that word by touching a touch point on that word or taking other action when a whole word prediction is presented. In cases as shown the user can select the next most likely letter l by touching a first touch point on that letter in the selection area accepting the predicted letter.

Following that action as shown in the prediction engine can generate an updated or new next most likely letter which now becomes the letter e. Again in implementations the whole word prediction can be updated to display the word Quiet when that feature is used. In cases as shown the user may choose not to select the next most likely letter e and instead input a left swipe gesture on the selection area indicating a desire to locate the next most likely letter in a downstream direction toward z in the alphabet.

In implementations as shown this action can result as shown in in the prediction engine generating a new next most likely letter as the letter t which can again be centered in the selection area and highlighted with a highlight mark . The whole word prediction can if used likewise be updated to show the word Quit. The user can then as shown in select the letter t by touching a touch point on that letter after which the user can touch a touch point on the done button as shown in to accept and enter the word Quit. In cases the user can alternatively select the whole word prediction to enter the word Quit directly.

Alternatively after selection of the letter i the user can touch the letter grouping in the seek area denoted with the letter r. In this case the prediction engine can likewise cause the letter t to be highlighted or marked for selection as the still most likely next letter . As a further alternative the user can provide a quick swipe gesture left or right to snap to the letters r or v respectively since those letters could be identified in words that remain a less likely possibility such as quirk or quiver respectively.

In implementations for instance as shown in further types of predictive processing can be performed in which manual user input is combined with predictive letter generation. As shown in the user can start by entering an initial touch point between e and i in the seek area . The prediction engine in response can as shown in cause the letters e f g h i to be displayed in the selection area . The user as shown in can then select the letter g by touching a touch point on that letter in the selection area .

As shown in that action can cause the letter G optionally capitalized as the first letter of the new word in the text editing box . Upon detection of that letter the prediction engine can generate or identify the letter o as the next most likely letter . The prediction engine can likewise cause the display of the letter o as the next most likely letter in the selection area . The next most likely letter can again be marked or highlighted with a highlight mark such as the illustrated opposing arrows or detents or other marks. The prediction engine can likewise again optionally generate and display the word Good as the whole word prediction . After viewing the displayed next most likely letter as shown in the user may choose not to enter the letter o and can instead enter a right swipe gesture indicating a desire to seek a next most likely letter in an upstream direction toward a of the alphabet.

After receipt of the right swipe gesture as shown in the prediction engine can generate or identify the next most likely letter according to the direction of the gesture in this case in an upstream direction of the alphabet. That letter can be identified as e which is then displayed in the selection area with a highlight mark . The prediction engine can also generate and cause to be displayed a whole word prediction in the text editing box which in the illustrated case based on selection of the letter e can be the word Get. 

In the event the user chooses not to select the letter e the user can as shown in enter a right swipe gesture on the selection area indicating a desire to travel upstream from that point in the alphabet. As shown in the result of that action can be that the prediction engine causes the letters a b c d e to be displayed in the selection area . In this case the user has entered a right swipe gesture while the currently displayed target range is near the beginning of the alphabet causing the prediction engine to pin the display of letters in the selection area at the beginning of the alphabet starting with the letter a. In implementations as shown the prediction engine can temporarily suspend the display of a next most likely letter and instead display the letters in sequence at the start of the alphabet beginning with a. In aspects as also shown in the prediction engine can cause a whole word prediction to be displayed in the text editing box in this case the word Gable. This can represent the most likely completed whole word based on the letters displayed in the selection area .

The user can view the selection area and as shown in choose to enter a left swipe gesture on the selection area to indicate a desire to travel downstream in the alphabet rather than to make a selection of any currently displayed letters. As shown in the prediction engine can as a result of that input cause the selection area to display the letters h i j k l with a highlight mark on the letter h at the beginning of that letter grouping. In this case the prediction engine can determine that the letter h represents the next most likely letter after excluding letters which were previous presented to the user as possible selections after the current letter but which were declined. As shown the letters f and g had already been presented to the user but were not selected causing the prediction engine to exclude those letters from the group of letters displayed in the selection area . In this scenario the prediction engine can as shown highlight the first letter shown in the five letter target range rather than on the center letter j which does not represent a likely next letter based on prediction algorithms. The prediction engine can also as shown generate a whole word completion represented by Ghost based on the letter h as the next most likely letter .

The user can then as shown in choose not to select any of the letters displayed in the selection area and instead input a left swipe gesture in the selection area indicating a desire to travel downstream in the alphabet from the present point. In this scenario as shown in the prediction engine identifies the letters r s t u v for display in the selection area with the letter u selected for presentation as the next most likely letter marked by a highlight mark at the fourth position in the group of five letters. In this scenario the prediction engine adjusts its prediction and display logic to locate the letter u as the next most likely letter located in the downstream direction of the alphabet. Here however the prediction engine locates a grouping of five letters containing u as the most likely next letter while also presenting other letters which have not yet been displayed to the user after the currently entered letter G . That is since the letter q was previously displayed to the user but not selected E the prediction engine begins the five letter grouping containing u next most likely letter at the letters r s t which have not yet been displayed to the user followed by the letter v which has likewise not yet been displayed to the user. In implementations the prediction engine can update the whole word prediction to the word Gulch if that feature is used.

As illustrated in the user may then choose not to select the letter u as the highlighted next most likely letter and instead enter a left swipe gesture indicating a desire to travel downstream in the alphabet. In this case because the display has neared the end of the alphabet the prediction engine can cause the letters v w x y z to be displayed in the selection area in the next screenshot not shown because the remaining letters in that direction have pinned the display to the end of the alphabet. The user can then select one of the displayed letters v w x y z touch a touch point in the seek area or take other actions or supply other inputs.

In implementations for instance as shown in further types of predictive processing can be performed in which manual user input is combined with predictive letter generation. As shown in a user can begin input processing by selecting the letter g by inputting a touch point in the selection area . In response to that action and as shown in the prediction engine can cause the letter G again optionally capitalized as the first letter of a word to be displayed in the text editing box . As also shown the prediction engine can also cause the word Good to be displayed as a whole word prediction in the text editing box for instance in greyed out or otherwise highlighted format.

As also shown in after the user has selected the letter G using a touch point selection the prediction engine can cause the selection area to display the letters m n o p q as the five letter grouping centered on the letter o as the next most likely letter . As in other illustrated implementations the letter o can be marked or highlighted by a highlight mark to indicate to the user that o is the most likely next letter and to make selection of that letter easier or more convenient. In case the user may as shown choose not to select the next most likely letter and instead enter a touch point on the seek area between the letters r and v .

As a result of that action as shown in the prediction engine can cause further updates to the display including to cause the selection area to display the letters s t u v w with the letter u highlighted by a highlight mark indicating that letter as the next most likely letter . The prediction engine can also update the whole word prediction to display the word Gulch for convenient selection if that word reflects the user s desired input. After viewing that display the user may choose as shown in to enter a touch point on the seek area between the letters m and r. In response to that action as shown in the prediction engine can cause the selection area to display the letters m n o p q including the letter o highlighted by highlight mark as the next most likely letter within the selected range. Here the prediction engine provides the highlight mark to set off the letter o in the selection area as the next most likely letter even though the preceding user input action has taken place on the seek area using a touch point . The prediction engine can also in implementations cause the word Good to be displayed at this stage in the text editing box as the whole word prediction 

In cases and as shown in the user at this stage may choose to touch a touch point to the left of the letter m in the seek area rather than accept or select the next most likely letter . As shown in the prediction engine can as a result display the letters k l m n o and the letter o may remain the next most likely letter which can be marked off by a highlight mark in the selection area . The prediction engine in such cases can effectively shift the five letter grouping presented in the selection area to include the next most likely letter at the center point or in other positions.

It will be appreciated that while certain user input sequences and letter displays are shown in and other inputs gestures sequences and displays can be used or produced by the prediction engine and associated logic.

In a determination can be made whether the prediction engine can find a prediction result based on the letters received. If the determination is no processing can proceed to in which the prediction engine and or other logic can process the user event or input without using the prediction engine to predict further letters or words until the current letter input is completed. After processing can return to . It may be noted that a special case can be processed for instances where the user may delete a previous letter in which processing can optionally return to in view of the fact that the prediction engine can be used again with fewer previous letters in the input history.

If the determination in is yes processing can proceed to in which the prediction engine can optionally generate and or display a whole word prediction or similar in the text editing box based on the current letter or letters selected by the user and displayed in the text editing box . The completed whole word prediction can be based on dictionaries heuristics look up tables self learning networks and or other rules to generate a most likely completed word based on the letter s already selected or inputted by the user.

In the prediction engine can find or generate a most likely next letter or letters based on the current letter and or other input history to that current point. The most likely next letter can be based on dictionaries heuristics look up tables self learning networks and or other rules. In the prediction engine can identify a target range of the alphabet containing the most likely next letter s and display that target area in the selection area or similar. The target area generated can for instance consist of five consecutive letters of the alphabet with at least one of those displayed five letters consisting of the letter determined by the prediction engine to be the next most likely next letter based on the current letter and or inputted text string to that point. In implementations as described herein the next most likely letter can be set off or highlighted with a highlight mark or similar and or can be placed in the center of the target range and or selection area or similar and or can be presented highlighted and or positioned in other ways.

In a user input or inputs can be received via the two stage input interface . The user input can include or consist of for example a touch on a touch sensitive screen a swipe gesture a selection or confirmation of the entry of a highlighted letter a spoken or verbal input and or other input action or event. In a determination can be made whether the user input is a selection of a completed whole word prediction or similar. If the determination of is yes processing can proceed to where the whole word prediction or similar is entered via the text editing box . After processing can return to . If the determination of is no processing can proceed to . In a determination can be made whether the user input is a selection in a displaced target range . If the determination of is yes processing can proceed to in which the selected letter can be inserted in the text editing box . After processing can return to . If the determination of is no processing can proceed to .

In a determination can be made whether the user input is a gesture to navigate the alphabet or other symbols upstream or downstream. If the determination of is yes processing can proceed to in which the next most likely letter can be identified or found based on the navigation direction. After processing can return to .

If the determination of is no processing can proceed to . In a determination can be made whether the user input is at or received from the seek area or similar. If the determination of is yes processing can proceed to in which the next most likely letter can be found or identified based on a touch point or similar. After processing can return to . If the determination of is no processing can proceed to .

In a determination can be made whether the user input is a space to end a word. If the determination of is yes processing can return to . If the determination of is no processing can proceed to . In a determination can be made whether the user input is a slow scroll action on the selection area or seek area or similar. If the determination of is yes processing can proceed to in which the user event or input can be processed without using the prediction engine or other logic until completing the current letter input. After processing can return to .

If the determination of is no processing can proceed to . In a determination can be made whether the user input is an option selected to discontinue text entry. If the determination of is no processing can return to . If the determination of is yes processing can proceed to in which the text input activity can be completed along with a transfer or transaction of the inputted text to one or more applications or destinations and then the process can be terminated at .

It will be appreciated that while various processing activity logical decisions and or other operations illustrated in or elsewhere have been described as taking place in steps that two or more of various of those operations or activities can be combined into one operation or activity and that any one or more of those operations or activities can be divided into two or more operations or activities. Moreover while those various operations or activities have been illustrated and described as occurring in a certain order it will be appreciated that in implementations those same and or other operations or activities can take place in a different order or orders. It will likewise be understood that indicated reference numbers in connection with the various illustrated steps are intended for reference only and are not meant to necessarily imply dependencies precedence and or orders between steps or that steps can not be rearranged or reordered. Further while various operations or activities have been described as being carried out by certain hardware software service and or other resources it will be appreciated that in implementations the same activities and or operations can be carried out by other hardware software service and or other resources and or combinations of the same.

It will likewise be appreciated that the foregoing description is illustrative and variations in configuration and implementation may occur to persons skilled in the art. For example while embodiments have been described that incorporate a two stage character input interface in implementations three or more input stages can be used. Similarly while implementations have been described in which the electronic device can be or include a portable wireless communications device in implementations the operative device can be or include other types or classes of devices or hardware such as for example a data device or hardware incorporated in an automobile having a dashboard or other display screen or area. Further while embodiments have been described in which the prediction engine generates the most likely next letter in implementations the prediction engine can also or instead generate the most likely pair of next letters the most likely three next letters the most likely completed word as noted a most likely entire sentence and or other units sections increments or other textual strings or objects. Even further while embodiments have been described which operate on the English alphabet in implementations the prediction engine can operate on the alphabets or symbol sets. Conversely while implementations have been described which operate solely on the English alphabet in implementations prediction processing can be carried using words or letters from two or more languages. Other resources described as singular or integrated can in embodiments be plural or distributed and resources described as multiple or distributed can in embodiments be combined. The scope of the present disclosure is accordingly intended to be limited only by the following claims.

