---

title: Systems and methods for responding to human spoken audio
abstract: Systems and methods for responding to human spoken are provided herein. Exemplary methods may include continuously listening, via an intelligent assistant device, for an initiating command. Additionally, the method may include upon receiving the initiating command, continuously listening, via the intelligent assistant device, for an audio command and transmitting the audio command from the intelligent assistant device to a command processing server. The method may also include transmitting the audio command to at least one information source, the audio command having been converted from speech-to-text, receiving at the command processing server, a response from the at least one information source, and transmitting the response from the command processing server to the intelligent assistant device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09542956&OS=09542956&RS=09542956
owner: Interactive Voice, Inc.
number: 09542956
owner_city: San Francisco
owner_country: US
publication_date: 20130104
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61 584 752 filed on Jan. 9 2012 and entitled SYSTEMS AND METHODS FOR RESPONDING TO HUMAN SPOKEN AUDIO USING A NATURAL LANGUAGE PROCESSOR which is hereby incorporated herein by reference in its entirety including all references cited therein.

The present invention relates generally to systems and methods of responding to human spoken audio and more specifically to systems and methods that interpret human spoken audio and then generate a response based on the interpretation of the human spoken audio.

According to some embodiments the present technology may be directed to methods that comprise a continuously listening via an intelligent assistant device for an initiating command b upon receiving the initiating command continuously listening via the intelligent assistant device for an audio command c transmitting the audio command from the intelligent assistant device to a command processing server d transmitting the audio command to at least one information source the audio command having been converted from speech to text e determining context and intent of the converted text f receiving at the command processing server a response from the at least one information source and g transmitting the response from the command processing server to the intelligent assistant device.

According to some embodiments the present technology may be directed to a device that comprises a a display screen b a first microphone c a speaker d a processor that executes logic stored in memory to perform operations comprising i continuously listening via the first microphone for an initiating command ii upon receiving the initiating command continuously listening via the first microphone for an audio command iii transmitting the audio command from to a command processing server iv receiving a response from the command processing server and v outputting the response via any of the display screen and the speaker.

According to some embodiments the present technology may be directed to a system that comprises a an intelligent assistant device comprising a processor which executes logic to perform operations comprising i continuously listening via a microphone for an initiating command and ii upon receiving the initiating command continuously listening via the microphone for an audio command and b a command processing server communicatively coupled with the intelligent assistant device the command processing server comprising a processor that executes logic to perform operations comprising i receiving the audio command from the intelligent assistant device ii transmitting the audio command to at least one information source the audio command having been converted from speech to text iii receiving at the command processing server a response from the at least one information source and iv transmitting the response from the command processing server to the intelligent assistant device.

While this technology is susceptible of embodiment in many different forms there is shown in the drawings and will herein be described in detail several specific embodiments with the understanding that the present disclosure is to be considered as an exemplification of the principles of the technology and is not intended to limit the technology to the embodiments illustrated.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

It will be understood that like or analogous elements and or components referred to herein may be identified throughout the drawings with like reference characters. It will be further understood that several of the figures are merely schematic representations of the present technology. As such some of the components may have been distorted from their actual scale for pictorial clarity.

The present technology provides hardware and software components that interact interpret and respond to human spoken audio. In some embodiments the hardware components include a microphone that receives audio comprising human spoken audio. The audio that comprises human spoken audio may in some instances be transmitted to a cloud computing cluster e.g. cloud based computing environment for processing. In general a cloud based computing environment is a resource that typically combines the computational power of a large grouping of processors and or that combines the storage capacity of a large grouping of computer memories or storage devices. For example systems that provide a cloud resource may be utilized exclusively by their owners or such systems may be accessible to outside users who deploy applications within the computing infrastructure to obtain the benefit of large computational or storage resources.

The cloud may be formed for example by a network of web servers with each web server or at least a plurality thereof providing processor and or storage resources. These servers may manage workloads provided by multiple users e.g. cloud resource customers or other users . Typically each user places workload demands upon the cloud that vary in real time sometimes dramatically. The nature and extent of these variations typically depend on the type of business associated with the user.

With respect to the present technology the audio commands that comprise human spoken audio may be processed to clarify the human spoken audio components from other audio aspects that may have also been recorded such as background noise. In some instances the present technology may utilize digital signal process beam forming microphone assembly which is included in an end user device. In other embodiments various DSP processes may be utilized at the cloud level to remove background noise or other audio artifacts. The processed human spoken audio may then be transmitted to a text processor. The text processor uses speech to text software such as from Nuance and converts the human spoken audio into a string of text that represents the human spoken audio hereinafter string of text .

Once the human spoken audio has been processed into a string of text the text processor may then return the string of text to a processing server which then transmits the string of text to a natural language processor. The terms natural language processor may include but is not limited to any system process or combination of systems and methods that evaluate process parse convert translate or otherwise analyze and or transform natural language commands. For example an exemplary natural language processor may convert natural language content from an audio format into a text format e.g. speech to text and may also evaluate the content for sentiment mood context e.g. domain and so forth. Again these natural language commands may include audio format and or text format natural language content as well as other content formats that would be known to one of ordinary skill in the art.

At the natural language processor the string of text may be broken down into formal representations such as first order logic structures that contain contextual clues or keyword targets. These contextual clues and or keyword targets are then used by a computer system to understand and manipulate the string of text. The natural language processor may identify the most likely semantics of the string of text based on an assessment of the multiple possible semantics which could be derived from the string of text.

It will be understood that in some embodiments one or more of the features described herein such as noise reduction natural language processing speech to text services and vice versa text parsing and other features described herein may be executed at the device level e.g. on the intelligent assistant device . In other instances many or all of the aforementioned features may be executed at the cloud level such that the intelligent assistant device receives audio commands and returns responses. Thus most or all of the processing of the audio commands may occur at the cloud level. In some instances the intelligent assistant device and the cloud may share processing duties such that the intelligent assistant device executes some of the features of the present technology and the cloud executes other processes. This cooperative content processing relationship between the intelligent assistant device and the cloud may function to load balance the duties required to process audio commands and return responses to the end user.

Based on the computer system s understanding of the semantics of the string of text data from the string of text will be prepared for delivery to an appropriate application program interface API . For example a string of text comprising the query What s the weather look like today in Los Angeles Calif. may be processed by the computer system and distributed to a weather API. Further the weather API may process the data from the string of text to access a weather forecast for Los Angeles Calif. associated with the day that the query was asked.

Since APIs may have different data structure requirements for processing queries one aspect of the natural language processor may be formatting the data from the string of text to correspond to the data structure format of an API that has been determined to be appropriate.

Once an API has processed the query data derived from human spoken audio an API response may be generated. This API response may then be converted into an appropriate pre spoken text string also referred to as a fulfillment. Further the API response may be recorded in a database and then converted to a speech response. Once the API response has been converted to a speech response the speech response may be distributed to a hardware component to playback the API speech response. The API response may also be saved and or paired with the query data and saved in a cache for efficient lookup. That is rather than processing the same query data multiple times the present technology may obtain previously generated responses to identical or substantially identical query data from the cache. Temporal limitations may be placed upon the responses stored in the cache. For example responses for queries regarding weather may be obtained from the cache only for relevant periods of time such as an hour.

In some embodiments a hardware unit e.g. intelligent assistant device may act as a base station that is connected over a Wi Fi network to both the natural language processor as well as other enabled devices. For instance other enabled devices may act as a microphone transmitting human spoken audio via the base station to the natural language processor or transmitting human spoken audio directly to the intelligent assistant device and then to the natural language processor. Additionally enabled devices may also receive commands from a general server based on interpretation of the human spoken data using the natural language processor. For instance a Wi Fi enabled thermostat may receive a command from the base station when the natural language processor has interpreted human spoken audio to request an increase in temperature within a room controlled by the user device that received the human spoken audio data. In some instances the intelligent assistant device may utilize other communication media including but not limited to Bluetooth near field communications RFID infrared or other communicative media that would be known to one of ordinary skill in the art with the present disclosure before them.

In accordance with the discussion above is a system for processing human spoken audio in accordance with embodiments of the present invention. In particular a user spoken question or command is received at microphone . The user spoken question or command is within audio data. As such the audio data comprises human spoken audio. The audio data may then be transmitted to hardware device such as an intelligent assistant device or connected hardware device such as a cellular phone or digital music player. If the audio data is transmitted to connected hardware device the audio data may then be further transmitted to hardware device after being received at connected hardware device . Alternatively hardware device may comprise microphone such that hardware device is able to record user commands and distribute recorded user commands to a speech and text system for initial processing.

From hardware device audio and user identification information is transmitted to a server also referred to a command processing server. The audio may be cleaned at the server . In particular a combination of a microphone array e.g. using audio captured by multiple microphones beam forming noise reduction and or echo cancellation system may be used to clean up the audio received to remove audio characteristics that are not human spoken audio. Once audio is received at the server the audio is provided to a speech to text service .

At the speech to text service the audio is converted to a string of text that represents human spoken audio. In embodiments the string of text may be stored in a database . In particular database may be used for storage of user data and for the storage of processed queries. Further database may be used to manage learned behaviors based on unique hardware identification.

The string of text may then be transmitted to a natural language processor . Natural language processor may parse unstructured text documents and extract key concepts such as context category meaning and keywords. Additionally the natural language processor may comprise artificial intelligence AI logic to process the string of text into a discernible query. Further natural language processor may utilize machine learning and or a neural network to analyze the string of text. For example natural language processor may utilize a method of interpreting and learning from patterns and behaviors of the users and attributing data to such behaviors.

Further natural language processor may be run using a server system used to run natural language processor and a neural network. Additionally the natural language processor may determine which query API is most appropriate to receive the query associated with the string of text. Further once a query API is determined the natural language processor may modify the query to comply with the structure of queries appropriate to the determined query API .

The query generated at the natural language processor is then provided to a query API . An exemplary API may comprise a variety of open source or licensed APIs that are used to take natural language processor output and retrieve the necessary data. The query API processes the query and provides a query response to server . Once the query response is received at server the query response may be transmitted to a format response component . The format response component may comprise for example a text to speech translator. In particular a text to speech translator may comprise a system used to take the national language processor output in text format and output in spoken audio. The answer may then be provided to hardware device such as via a device interface comprising a process of returning the spoken audio from the text to speech component to hardware device . From hardware device the answer may be transmitted through a speaker to a system spoken audio response .

In another embodiment a customer speaks a second trigger command also referred to as an audio command such as Weather Los Angeles at . In some instances the audio command may comprise a natural language or spoken word command such as the audio command at . The second trigger command is captured at by a microphone and transmitted to device . Device is coupled with a private API via WiFi connection . Further device provides an audio query to private API . In particular audio query is derived from an audio command.

Audio query may then be provided to a speech text processor which translates the audio query into text query Weather Los Angeles . Text query Weather Los Angeles is then provided to private API which directs text query Weather Los Angeles to an AI Logic component . AI Logic component then provides text query Weather Los Angeles to a third party API . For example for the text query Weather Los Angeles an appropriate third party API may be a weather API. Third party API then generates text answer 76 Degrees .

Text answer 76 Degrees may then be provided to AI Logic component . Further text answer 76 Degrees may then be transmitted from AI Logic component to private API . Further text answer 76 Degrees is provided to a speech text processor where text answer 76 Degrees is translated to audio answer . Audio answer may then be provided to private API and then provided to device . From device audio answer is output as an audio 76 Degrees . In particular audio response 76 Degrees is in response to audio command Weather Los Angeles . Further audio Command Please is in response to the initiating command Hello ivee .

Additionally device command interpreter is also communicatively coupled with language interpreter . In particular device command interpreter may provide a sentence with scenario information to language interpreter . Further the language interpreter may generate analyzed sentence information and send the analyzed sentence information with scenario information to a decision making engine . The decision making engine may select a most appropriate action. Further the decision making engine may utilize user accent references from a voice database . Based on the analyzed sentence information and the scenario information the decision making engine may generate a selected most appropriate action from scenarios and further may provide the selected most appropriate action to the device command interpreter .

The device command interpreter may also send a request to build sentence information to a sentence generator component . In response the sentence generator component may provide a built sentence string to device command interpreter . Additionally the device command interpreter may request service on servers by providing a service request to an add on service interface . The add on service interface may provide the service request to a voice database web server . Further a response generated by voice database web server may be provided to the device command interpreter via the add on service interface .

Further device command interpreter may interact with a user database via a user information database . In particular device command interpreter may provide user information and device authentication to the user database via an interface of the user information database . Additionally device command interpreter may interact with a streaming interface of a device via communications module . In particular device command interpreter may provide a file for download and or text to speech voice data to file downloader. Communications module may include any data communications module that is capable of providing control of data streaming processes to the streaming interface of the device. In response the streaming interface of the device may provide a data stream to communications module . The communications module may provide a voice streaming up of device command interpreter .

Processor also exchanges information with a Fast Super Twisted Nematic Display FSTN Liquid Crystal Display LCD display module with driver as well as a WiFi module . Further processor is communicatively coupled with an Erasable Programmable Read Only Memory EEPROM for user information and or settings. Processor is also communicatively coupled with radio module and audio mux . Audio mux is an audio amplifier chip. Audio mux also receives data from aux audio input . Further sensory natural language processor also provides data to audio mux . Additionally audio mux provides data to audio amp and stereo speaker . also comprises for example a USB Jack or other similar communicative interface for recharging that provides rechargeable battery .

In addition to the embodiments described above another exemplary embodiment may utilize a plurality of microphones of a smartphone base to implement a natural language processor in accordance with embodiments of the present invention. In particular audio is received at the plurality of microphones at a smartphone base. The audio is received at an application running a natural language processor such as natural language processor . Further the application comprises a clean up component that utilizes a combination of a microphone array beam forming noise reduction and or echo cancellation system to clean up the audio received. In particular the clean up component may remove non human spoken audio and or may remove garbled human spoken audio e.g. background conversations that do not comprise primary human spoken audio e.g. the human spoken audio of the primary user . By using this process a user can interact with a smartphone application from approximately ten feet away and closer. As such by using audio clean up processes such as beamforming audio received from microphones of auxiliary hardware devices such as a dock for smartphone devices may be used to interact with an application that comprises a natural language processor such as natural language processor .

A frames scheduler may be utilized to schedule and correlate responses with other objects such as advertisements.

The intelligent assistant device may also communicatively couple with a notifications server as shown in . The notifications server may cooperate with the frames scheduler and an advertisements engine to query relevant advertisements and integrate the same into a response which is returned to the intelligent assistant device .

As shown in the system may utilize a command fulfiller that creates API requests and processes responses to those requests. Additionally the command fulfiller may also generate return response objects. The command fulfiller may communicatively couple with the speech processor of as well as various sub classes of command fulfillers . These sub classes of command fulfillers may query third party information sources such as an external knowledge engine . The sub classes of command fulfillers may be domain specific such as news weather and so forth.

Additionally a user management system may allow for end user setup of the intelligent assistant device via an end user. The end user may utilize a web based portal that allow for the end user to setup and manage their device via a device management API .

The components shown in are depicted as being connected via a single bus . The components may be connected through one or more data transport means. Processor unit and main memory may be connected via a local microprocessor bus and the mass storage device peripheral device s portable storage device and display system may be connected via one or more input output I O buses.

Mass storage device which may be implemented with a magnetic disk drive or an optical disk drive is a non volatile storage device for storing data and instructions for use by processor unit . Mass storage device may store the system software for implementing embodiments of the present invention for purposes of loading that software into main memory .

Portable storage device operates in conjunction with a portable nonvolatile storage medium such as a floppy disk compact disk digital video disc or USB storage device to input and output data and code to and from the computing system of . The system software for implementing embodiments of the present invention may be stored on such a portable medium and input to the computing system via the portable storage device .

User input devices provide a portion of a user interface. User input devices may include an alphanumeric keypad such as a keyboard for inputting alpha numeric and other information or a pointing device such as a mouse a trackball stylus or cursor direction keys. Additional user input devices may comprise but are not limited to devices such as speech recognition systems facial recognition systems motion based input systems gesture based systems and so forth. For example user input devices may include a touchscreen. Additionally the system as shown in includes output devices . Suitable output devices include speakers printers network interfaces and monitors.

Display system may include a liquid crystal display LCD or other suitable display device. Display system receives textual and graphical information and processes the information for output to the display device.

Peripherals device s may include any type of computer support device to add additional functionality to the computer system. Peripheral device s may include a modem or a router.

The components provided in the computing system of are those typically found in computer systems that may be suitable for use with embodiments of the present invention and are intended to represent a broad category of such computer components that are well known in the art. Thus the computing system of may be a personal computer hand held computing system telephone mobile computing system workstation server minicomputer mainframe computer or any other computing system. The computer may also include different bus configurations networked platforms multi processor platforms etc. Various operating systems may be used including Unix Linux Windows Mac OS Palm OS Android iOS known as iPhone OS before June 2010 QNX and other suitable operating systems.

It is noteworthy that any hardware platform suitable for performing the processing described herein is suitable for use with the systems and methods provided herein. Computer readable storage media refer to any medium or media that participate in providing instructions to a central processing unit CPU a processor a microcontroller or the like. Such media may take forms including but not limited to non volatile and volatile media such as optical or magnetic disks and dynamic memory respectively. Common forms of computer readable storage media include a floppy disk a flexible disk a hard disk magnetic tape and any other magnetic storage medium a CD ROM disk digital video disk DVD any other optical storage medium RAM PROM EPROM a FLASHEPROM any other memory chip or cartridge.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be coupled with the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. Exemplary embodiments were chosen and described in order to best explain the principles of the present technology and its practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

Aspects of the present invention are described above with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. The descriptions are not intended to limit the scope of the technology to the particular forms set forth herein. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments. It should be understood that the above description is illustrative and not restrictive. To the contrary the present descriptions are intended to cover such alternatives modifications and equivalents as may be included within the spirit and scope of the technology as defined by the appended claims and otherwise appreciated by one of ordinary skill in the art. The scope of the technology should therefore be determined not with reference to the above description but instead should be determined with reference to the appended claims along with their full scope of equivalents.

