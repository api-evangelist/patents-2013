---

title: Automated software composition
abstract: A method for automated composition of an application including: receiving a customizable template for application composition and a composition goal, wherein the goal comprises a plurality of tags and the goal is incomplete such that more than one possible composition matches the goal; refining the goal by automatically adding refinement tags to the goal; and generating an application flow that matches the customizable template and the refined goal, wherein the application flow comprises data sources, data processing operators, and outputs of the application flow.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09286032&OS=09286032&RS=09286032
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09286032
owner_city: Armonk
owner_country: US
publication_date: 20130315
---
This invention was made with U.S. Government support under Contract No. H98230 11 C 0276 awarded by the Department of Defense. The U.S. Government has certain rights in this invention.

The application is related to U.S. patent application Ser. No. 11 872 385 filed Oct. 15 2007 U.S. patent application Ser. No. 12 608 689 filed Oct. 29 2009 and U.S. patent application Ser. No. 12 626 745 filed Nov. 27 2009 the disclosures of which are incorporated by reference herein in their entireties.

The present invention relates to the composition of software applications and more particularly to automated composition of flow based applications.

Automated planning can be used to create composite applications in compositional architectures such as web services and stream processing. The applications may be processing graphs composed of smaller modular components such as service invocations data processing operators or other smaller processing graphs.

According to an exemplary embodiment of the present invention a method for automated composition of an application includes receiving a customizable template for application composition and a composition goal wherein the goal comprises a plurality of tags and the goal is incomplete such that more than one possible composition matches the goal refining the goal by automatically adding refinement tags to the goal and generating an application flow that matches the customizable template and the refined goal wherein the application flow comprises data sources data processing operators and outputs of the application flow.

An information processing flow obtains data from different sources aggregates or integrates them in different manners applies different kinds of analyses on the data and visualizes or handles the end results in different ways for example. An information processing flow may be viewed as a directed acyclic graph of black box components which include data sources and processing components connected by data flow links. Flows are used to describe information processing applications in different platforms including service oriented systems event driven systems data mashups stream processing systems extract transform load systems and the grid for example.

Challenges exist in the assembly and deployment of information processing flows. For example assembly is complex since there may be a very large number of components available and users may not be aware of the syntactic and semantic constraints in assembling different components into complex flows. Deployment is complex since the users may not know how best to distribute and schedule the flow graph on a distributed system.

In this disclosure described are exemplary embodiments for automated software composition with situational goal refinement.

According to an exemplary embodiment of the present invention a customizable template may be implemented to direct and aid automated software composition. The customizable template may dictate the ways in which different components of software can be composed and may have sufficient flexibility so that the template is reusable by different users.

There are a variety of different ways a composition template can be specified. One way to represent the composition template is based on Hierarchical Task Networks HTNs .

HTN planning is a popular and widely used planning paradigm and many domain independent HTN planners exist. In HTN planning the planner is provided with a set of tasks constraints on these tasks and a set of methods that control decomposition of these tasks. A plan may be formulated by repeatedly decomposing tasks into smaller and smaller subtasks until primitive executable tasks are reached.

Another way to specify a composition template is to specify patterns for example using the Cascade language. This technique is used in MARIO Mashup Automation with Runtime Invocation and Orchestration a tool for assisted composition of flow based applications to allow domain experts to explore the space of possible flows and help them construct parameterize and deploy compositions mashups of data or code. A description of this can be found in Eric Bouillet Mark Feblowitz Hanhua Feng Zhen Liu Anand Ranganathan and Anton Riabov. A Tag Based Approach for the Design and Composition of Information Processing Applications OOPSLA 2008 Oct. 19 23 2008 Nashville Tenn. the disclosure of which is incorporated by reference herein in its entirety.

It is often the case in practice that users of automated composition software are unable to provide an unambiguous e.g. complete processing goal to such a system since by design they do not have to be aware of all the data sources and software components available for automated composition. As a result methods to automatically refine incomplete goals are desirable.

According to an exemplary embodiment of the present invention a method for automated software composition includes situational goal refinement.

A system may use tag clouds to guide a user in the assembly and configuration of new compositional applications automatically based on user selected output properties.

Feedback may be provided by showing a preview of the resulting output and updates may be made to the tag cloud based on selected tags. According to an exemplary embodiment of the present invention a tag cloud is a weighted list of tags. Weights reflect the popularity of tags. Clicking on any tag in the tag cloud adds the tag to a planning goal and to the list of selected tags. This also leads to a new processing graph being composed and a new tag cloud. The new tag cloud is created in the context of currently selected tags. In particular the new tag cloud does not include the selected tags or any other tags that never appear on the same feed description where all selected tags appear. When the new processing graph is constructed it is deployed and an output feed is shown in a preview window.

Implied tags are tags that always appear together with the selected tags. Guessed tags are tags assigned to the output of the graph and as such they do not appear in implied or selected tags.

Users interact with the system by specifying processing goals as a set of tags via a user interface. The system responds by generating a processing graph that outputs information that satisfies this goal. The system also updates the user interface elements.

According to an exemplary embodiment of the present invention incomplete goals may be completed automatically. Automatic completion of incomplete goals may allow additional semantics based decisions to take place before an optimization method finds the best plans or flows for the specified goal.

According to an exemplary embodiment of the present invention tag semantics can be leveraged and cross correlated with other available information during goal refinement. This information may include semantic information describing context project phase in the project lifecycle team mission knowledge of temporal patterns and other business level and semantic considerations relevant to conditions under which goals are submitted. How this additional information is received is not limited. It may be given by experts other systems or inferred automatically from historical data.

Referring to interactive goal refinement may be performed according to user preferences and selections. User refined goals are taken as input at block . In other words a customizable template for application composition and a composition goal are received. The composition goal may include a plurality of tags and be incomplete such that more than one possible composition matches the goal. Automatic goal refinement is performed at block . For example refinement tags are added to the goal. An optimal flow is generated based on the goals and a user may select a flow for deployment at block . The generated flow may be an application flow that matches the customizable template and the refined goal. The application flow may include components such as data sources data processing operators outputs of the application flow etc. The selected flow may then be deployed .

Referring to the interactively refined goals may be received with an associated set of possible refinement tags . An ordered list of refinements may be generated from available information about any the following relevant context. For example a project that the user submitting the goal is working on a mission of the team that the user belongs to current objectives of the team and of the user time dependent context derived from knowledge of temporal patterns potentially specific to user team or project or general patterns and time of goal submission and other information derived from available sources. Refinements determined automatically may be applied in order . For example in order of their rank. The application of refinements is depicted in .

Referring to given a first tag from an order refinement list a goal may be modified by adding a tag and invoking the planner . If the tag is plannable additional refinements may be considered at block . For a tag that is not plannable the tag is removed from the goal at block . The method continues through the ordered refinements list until all refinements have been considered.

One useful way of refining incomplete goals is through user preferences for example users may prefer a certain type of machine learning algorithm over another or data from one source that is more trusted than another similar source.

Goal specification is an iterative process. The user specifies a goal as a set of tags for example specifying an average stock price. The system after analyzing available data sources and analytics notifies the user that refinements are possible. For example exponential average or window average live data or historical data etc. The user can refine the goal creating a new goal such as average stock price for live data. The system may respond that exponential average or window average refinement is possible. Note that not all refinements of the previous step will be available. The user is not required to refine the goal until no additional refinements are possible. The system may then auto complete the ambiguous goal in a way that does not contradict end user s preferences.

According to an exemplary embodiment of the present invention user preferences may be inferred. The preferences may be inferred from records of a user s previous goals. By inferring user preferences over time obsolete records may be discarded in view of changes to usage patterns. Association rule based mining may be used on historically submitted goals to infer the associations. Consider the following examples 

In this way inferred associations may be represented as preferences for an HTN problem. An HTN planner may support preferences to find a plan that satisfies the goal and preferences. Such as described in Sohrabi S. Baier J. A. and McIlraith S. A. 2009 HTN planning with preferences. In Proceedings of the 21International Joint Conference on Artificial Intelligence IJCAI pp. 1790 1797 Sohrabi et al. 2009 the disclosure of which is incorporated by reference herein in its entirety.

As previously mentioned one useful way to automatically refine incomplete goals is through inferred user preferences. To achieve this we may express software composition domains for information processing flows such as those described above into a paradigm that supports planning with user preferences such as HTNs. Such preferences may be inferred as described above.

As description of HTN planning and Cascade follows. This will serve as the basis for a further exemplary embodiment of the present invention in which the customizable template and the refined goal of are translated into HTN solved with an HTN planner and then translated back into the originally determined application flow.

HTN planning is a widely used planning paradigm and many domain independent HTN planners exist. The HTN planner is given the HTN planning problem the initial state s the initial task network w and the planning domain D a set of operators and methods . HTN planning is performed by repeatedly decomposing tasks by the application of methods into smaller and smaller subtasks until a primitive decomposition of the initial task network is found. More formally oo. . . ois a plan for HTN planning problem P s w D if there is a primitive decomposition w of wof which is an instance. A task network is a pair U C where U is a set of tasks and C is a set of constraints. A task is primitive if its name matches with an operator otherwise it is non primitive. An operator is a regular planning action described by its name precondition and effects. It can be applied to accomplish a primitive task. A method is described by its name the task it can be applied to task m and its task network subtask m . A method m can accomplish a task t if there is a substitution such that t task m . Several methods can accomplish a particular non primitive task leading to different decompositions thereof.

HTNP P is a preference based HTN planner built on top of a Lisp implementation of SHOP2. SHOP2 is described in Nau D. S. Au T. C Ilghami O. Kuter U. Murdock J. W. Wu D. and Yaman F. 2003. SHOP2 An HTN planning system. Journal of Artificial Intelligence Research 20 379 404 the disclosure of which is incorporated by reference herein in its entirety. An example of HTNP P is described in Sohrabi et al. 2009. HTNP P takes as input an HTN planning problem specified in the SHOP2 s specification language not in planning domain definition language PDDL . HTNP P performs incremental search and uses a variety of different heuristics including the Lookahead Heuristic LA . HTNP P is modified to implement a heuristic according to an exemplary embodiment of the present invention hereinafter referred to as the Enhanced Lookahead Heuristic ELA . HTNP P is also used to evaluate this approach.

Cascade e.g. flow patterns for stream processing will now be discussed. The Cascade language describes data flow patterns that can guide automated software composition. Cascade is an alternative to the lower level planning domain languages like PDDL that are difficult to use as part of a software development cycle. Cascade has a programming language syntax that is friendly to software developers includes integrated development tools and can be used with different execution environments. An example of such a programming language is described in E. Bouillet M. Feblowitz H. Feng A. Ranganathan A. Riabov O. Udrea and Z. Liu. MARIO middleware for assembly and deployment of multi platform flow based applications Proceedings of the 10ACM IFIP USENIX International Conference on Middleware No. 26 Springer Verlag New York Inc. 2009 the disclosure of which is incorporated by reference herein in its entirety.

An example of an execution environment is stream processing middleware for example IBM InfoSphere Streams which facilitates the development of distributed applications that must process high volumes of data in memory. Stream processing applications are constructed as data flow graphs composed of modular software components that communicate via data streams and described in a programming language e.g. Stream Processing Language SPL . The middleware deploys the components of the application across multiple hardware nodes within a dedicated stream processing cluster manages them and provides efficient data transport. Cascade flow patterns define the space of valid composed flows which are then mapped to stream processing data flow graphs in SPL.

A single flow pattern defines a number of actual flows. In other words a Cascade flow pattern describes a set of flows by specifying different possible structures of flow graphs and possible components that can be part of the graph. As an example assume there are five different descendants for each of the abstract components. Then the number of possible flows defined by StockBargainIndexComputation is 2 3 5 5 3 or 450 flows.

A flow pattern in Cascade is a tuple F V E M where is a directed acyclic graph and M is a main composite. Each vertex v V can be the invocation of one or more of the following 1 a primitive component 2 a composite component 3 a choice of components 4 an abstract component with descendants 5 a component optionally. Each directed edge e E in the graph represents the transfer of data from an output port on one component to the input port of another component. Throughout this disclosure edges are referred to as streams outgoing edges are referred to as output streams and ingoing edges are referred to as input streams. The main composite M defines the set of allowable flows. For example if StockBargainIndexComputation is the main composite in then any of the 450 flows that it defines can potentially be deployed on the underlying platform.

Components in Cascade can have zero or more input ports and one or more output ports. A component can be either primitive or composite. A primitive component is an atomic element of the pattern graph and is usually associated with a code fragment which is used in code generation during flow graph deployment. A composite component internally defines a flow of other components. In the TableView and BIComputationCore are examples of primitive and composite components respectively. Similarly an abstract component includes the declaration of inputs and outputs but without a code fragment or graph. Instead separately defined concrete components can be declared to implement an abstract component. Note a concrete component can be primitive or composite. Including an abstract component within a graph pattern e.g. a composite defined as a point of variability of the graph allowing any implementation of the abstract to be used in place of the abstract.

Cascade includes two more constructs for describing graph variability. The choice invocation can be used to enumerate several alternatives to be used within the same location in the graph. For example the pattern in defines a choice between TCP source and file source. The alternatives must have the same number of inputs and the same number of outputs. Any component contained within the optional invocation becomes optional. This requires the contained component to have the same number of inputs and outputs. For example in the choice between filtering trades ByTickers and ByIndustry is made optional allowing graphs that include no filters at all to be valid instantiations of this pattern.

In Cascade output ports of components can be annotated with user defined tags to describe the properties of the produced data. Tags can be any keywords related to terms of the business domain. Tags are used by the end user to specify the composition goals referred to as Cascade goals. For each graph composed according to the pattern tags associated with output streams are propagated downstream recursively associating the union of all input tags with outputs for each component. Cascade goals specified by end users are then matched to the description of the graph output. Graphs that include all goal tags become candidate flows or satisfying flows for the goal. For example if we annotate the output port of the FilterTradeByIndustry component with the tag ByIndustry there would be 2 5 5 3 150 satisfying flows for the Cascade goal ByIndustry. Planning is used to find best satisfying flows efficiently from the millions of possible flows present in a typical domain.

From Cascade patterns to HTN planning. In this section according to an exemplary embodiment of the present invention we describe an approach to create an HTN planning problem with preferences from any Cascade flow pattern with a set of Cascade goals. Additional details on this approach can be found in Composition of Flow Based Applications with HTN Planning by Shirin Sohrabi Octavian Udrea Anand Ranganathan and Anton Riabov 22International Conference on Automated Planning and Scheduling Jun. 26 2012 Atibaia Sao Paulo Brazil pp. 1 7 the disclosure of which is incorporated by reference herein in its entirety.

In particular we show how to 1 create an HTN planning domain specified in SHOP2 the base planner for HTNP P from the definition of Cascade components and 2 represent the Cascade goals as preferences. shows at a high level how the main elements in Cascade are encoded as HTN planning elements . For example a primitive component is encoded as an operator and a composite component is encoded as an HTN method. Next the steps of this transformation are described while using the example shown in as a running example.

To do this we employ SHOP2 s specification language written in Lisp when describing the planning elements or when giving examples. We consider ordered and unordered task networks specified by keywords ordered and unordered distinguish operators by the symbol before their names and variables by the symbol before their names.

Creating the HTN planning domain. In this section according to an exemplary embodiment of the present invention we describe an approach to translate the different elements and unique features of Cascade flow patterns to operators or methods in an HTN planning domain.

Creating new streams. One of the features of the composition of the stream processing applications is that components produce one or more new data streams from several existing ones. Further the precondition of each input port is only evaluated based on the properties of connected streams hence instead of a single global state the state of the world is partitioned into several mutually independent ones. Although it is possible to encode parts of these features in PDDL experimental results have shown poor performance. In Riabov A. and Liu Z. 2005. Planning for stream processing systems. In Proceedings of the 20National Conference on Artificial Intelligence AAAI 1205 1210 and Riabov A. and Liu Z. 2006. Scalable planning for distributed stream processing systems. In Proceedings of the 16International Conference on Automated Planning and Scheduling ICAPS 31 42 they conjectured that the main difficulty in the PDDL representation is the ability to address creating new objects that have not been previously initialized to represent the generation of new streams. In PDDL this can result in a symmetry in the choice for the object that represents the new uninitialized stream significantly slowing down the planner.

To address the creation of new uninitialized streams an exemplary embodiment of the invention uses the assignment expression available in the SHOP2 input language in the precondition of the operator that creates the new stream. Next we will discuss how to model Cascade components as operators and methods. Numbers are used to represent the stream variables using a special predicate called sNum. This number is then increased by manipulating the add and delete effects of the operators that are creating new streams. This sNum predicate acts as a counter to keep track of the current value that can be assigned for the new output streams.

The assignment expression takes the form assign v t where v is a variable and t is a term. Here is an example of how to implement this approach for the bargainIndex stream the outgoing edge of the abstract component CalculateBargainIndex in . The following precondition add and delete list belong to the corresponding operators of this abstract component.

Now for an invocation of the abstract component CalculateBargainIndex new numbers hence new streams are used to represent the bargainIndex stream.

Tagging model for components. In Cascade output ports of components are annotated with tags to describe the properties of the produced data. Some tags are called sticky tags meaning that these properties propagate to all downstream components unless they are negated or removed explicitly. The set of tags on each stream depends on all components that appear before them or on all upstream output ports.

To represent the association of a tag to a stream an exemplary embodiment of the invention uses a predicate Tag Stream where Tag is a variable representing a stream. Note that Tag should be grounded before any evaluation of state with respect to this predicate. To address propagation of tags a forall expression is used ensuring that all tags that appear in the input streams propagate to the output streams unless they are negated by the component.

A forall expression in SHOP2 is of the form forall X Y Z where X is a list of variables in Y Y is a logical expression Z is a list of logical atoms. Here is an example going back to . tradeQuote and filteredTradeQuote are the input and output stream variables respectively for the FilterTradeQuoteByIndustry component. Note all tags are known ahead of time and they are represented by the predicate tag tag . In addition a special predicate different is used to ensure the negated tag AllCompanies does not propagate downstream.

Tag hierarchy. Tags used in Cascade belong to tag hierarchies or tag taxonomies . This notion is useful in inferring additional tags. In the example in it is known that the TableView tag is a sub tag of the tag Visualizable meaning that any stream annotated with the tag TableView is also implicitly annotated by the Visualizable. To address the tag hierarchy SHOP2 axioms are used. SHOP2 axioms are generalized versions of Horn clauses written in this form head tail. The tail can be anything that appears in the precondition of an operator or a method. The following are axioms that express hierarchy of views.

Component definition in the flow pattern. Next the different pieces described so far are put together to create the HTN planning domain. In particular the abstract components are represented by non primitive tasks enabling the use of methods to represent concrete components. For each concrete component new methods that can decompose this non primitive task e.g. the abstract component are created. If no method is written for handling a task this is an indication that there are no concrete components written for this abstract component.

Components can inherit from other components. The net or expanded description of an inherited component includes not only the tags that annotate its output ports but also the tags defined by its parent. This inheritance model is represented directly on each method that represents the inherited component using helper operators that add to the output stream the tags that belong to the parent component.

Each primitive component is encoded as an HTN operator. The parameters of the HTN operator correspond to the input and output stream variables of the primitive component. The preconditions of the operator include the assign expressions as mentioned earlier to create new output streams. The add list also includes the tags of the output streams if any. The following is an HTN operator that corresponds to the TableView primitive component.

Each composite component is encoded as HTN method with task networks that are either ordered or unordered. Each composite component specifies a graph clause within its body. The corresponding method addresses the graph clause using task networks that comply with the ordering of the components. For example the graph clause with the BIComputationCore composite component in can be encoded as the following task. Note the parameters are omitted. Note also ordered task networks are used for representing the sequence of components and an unordered task network for representing the split in the data flow.

Structural variations of flows. There are three types of structural variation in Cascade enumeration optional invocations and the use of high level components. Structural variations create patterns that capture multiple flows. Enumerations choices are specified by listing the different possible components. To capture the choice invocation an exemplary embodiment of the invention uses multiple methods applicable to the same task. For example to address choices of source two methods are used one for TAQTCP and one for TAQFile. A component can be specified as optional meaning that it may or may not appear as part of the flow. Optional invocations are captured using methods that simulate the no op task. Abstract components are used in flow patterns to capture high level components. In HTN this is already captured by method for each concrete component. For example the task network of BIComputationCore includes the non primitive task CalculateBargainIndex and different methods written for this task handle the concrete components.

Specifying Cascade goals as preferences. While Cascade flow patterns specify a set of flows users can be interested in only a subset of these. Thus users are able to specify the Cascade goals by providing a set of tags that they would like to appear in the final stream. In an exemplary embodiment of the present invention the user specified Cascade goals are specified as PDDL3 preferences. Currently the use of simple preferences are exploited. Recall that simple preferences or final state preferences are a temporal formulae that express a preference for certain conditions to hold in the final state of the plan. For example preferring that a particular tag appears in the final stream is a simple preference.

An advantage of encoding the Cascade goals as preferences is that the users can specify them outside the domain description as an additional input to the problem. In addition by encoding the Cascade goals as preferences if the goals are not achievable a solution can still be found but with an associated quality measure. In addition the preference based planner HTNP P can potentially guide the planner towards achieving these preferences and can do branch and bound with sound pruning using admissible heuristics whenever possible to guide the search toward a high quality plan.

The following are example preferences that encode Cascade goals ByIndustry TableView and LinearIndex. These PDDL3 simple preferences are over the predicate TagStream . Note that we may define a metric function for the generated preferences. In PDDL3 the quality of the plan is defined using a metric function. The PDDL3 function is violated is used to assign appropriate weights to different preference formula. Note inconsistent preferences are automatically handled by the metric function. If the Cascade goals now encoded as preferences are mutually inconsistent a higher weight can be assigned to the preferred goal. Otherwise uniform weights can be used when defining a metric function.

Flow based HTN planning problem with preferences. In this section a flow based HTN planning problem is characterized with preferences and the relationship between satisfying flows and optimal plans is discussed.

A Cascade flow pattern problem is a 2 tuple P F G where F V E M is a Cascade flow pattern where is a directed acyclic graph and M is the main composite and G is a set of Cascade goals. is a satisfying flow for Pif and only if is a flow that meets the main composite M. A set of Cascade goals G is realizable if and only if there exists at least one satisfying flow for it.

Given the Cascade flow pattern problem P the corresponding flow based HTN planning problem is defined with preferences as a 4 tuple P s w D where s is the initial state consisting of a list of all tags and our special predicates wis the initial task network encoding of the main component M D is the HTN planning domain consisting of a set of operators and methods derived from the Cascade components v V and is a preorder between plans dictated by the set of Cascade goals G.

Computation. In the previous section a method in accordance with an exemplary embodiment of the invention that translates Cascade flow patterns and Cascade goals into an HTN planning problem with preferences was described. The relationship between optimal plans and satisfying flows was also shown. Now with a specification of preference based HTN planning in hand HTNP P is selected to compute these optimal plans that later get translated to satisfying flows for the original Cascade flow patterns. In this section ELA according to an exemplary embodiment is focused on and a description about how the required indexes for this heuristic can be generated in the preprocessing step is provided. ELA helps improve the HTN planning performance especially in the harder problem sets a problem can be harder if the goal tags appear in the harder to reach branches of search space. In addition ELA can improve the HTN performance making it comparable with an SPPL planner on Cascade problems. On the other hand the notion behind ELA and how we generate the required indexes is general enough to be used within other HTN planners as long as the set of tags specific pre defined predicates are known in advance.

ELA e.g. the enhanced lookahead function estimates the metric value achievable from a search node N. To estimate this metric value a set of reachable tags is computed for each task within the initial task network. A set of tags are reachable by a task if they are reachable by any plan that extends from decomposing this task. Note it is assumed that every non primitive task can eventually have a primitive decomposition.

The ELA function is an underestimate of the actual metric value because deleted tags preconditions that may prevent achieving a certain tag and the set of all reachable tags which in many cases is an overestimate are ignored. Nevertheless this does not necessarily mean that the ELA function is a lower bound on the metric value of any plan extending node N. However if it is a lower bound then it will provide sound pruning if used within the HTNP P search algorithm and provably optimal plans can get generated. A pruning strategy is sound if no state is incorrectly pruned from the search space. That is whenever a node is pruned from the search space that the metric value of any plan extending this node will exceed the current bound best metric can be proven. To ensure that ELA is monotone for each node the intersection of the reachable tags computed for this node s task and the set of reachable tags for its immediate predecessor are taken.

Proposition. The ELA function provides sound pruning if the preferences are all PDDL3 simple preferences over a set of predefined tags and the metric function is non decreasing in the number of violated preferences and in the plan length.

Proof The ELA function is calculated by looking at a reachable set of tags for each task. Hence it will regard as violated preferences that have tags that do not appear in the set of reachable tags. This means that these tags are not reachable from node N. Given that we ensure the ELA function does not decrease and all of the preferences are PDDL3 simple preferences over a set of predefined tags the is violated function for the hypothetical node N that ELA is evaluating the metric for is less than or equal to any node N reachable from node N for each preference formula . Moreover since it is assumed that the metric function is non decreasing in the number of violated preferences and in plan length the metric function of the hypothetical node Nwill be less than or equal to the metric function of every successor node N reachable from node N. This shows that the ELA evaluated at node N returns a lower bound on the metric value of any plan extending N. Thus the ELA function provides sound pruning.

Generation of the heuristic indexes. In this section we briefly discuss how to generate the reachable tags from the corresponding HTN planning problem. The set of reachable tags can also be generated from the description of the Cascade flow patterns.

Algorithm 1 shows pseudocode of our offline procedure according to an exemplary embodiment of the present invention that creates a set of reachable tags for each task. It takes as input the planning domain D a set of tasks or a single task w and a set of tags to carry over C. The algorithm should be called initially with the initial task network w and C . The reason for why the sets of tags to carry over is tracked is because we want to make sure we calculate not only a set of tags produced by a decomposition of a task network or a task but also we want to find a set of reachable tags for all possible plan extensions from this point on.

The call to GetRTags will produce a set of tags reachable by the set of tags w produced by w and C . To track the produced tags for each task a map R is used. If w is a task network then we consider three cases 1 task network is empty then return C 2 w is an ordered task network then for each task tcall the algorithm starting with the rightmost task tupdating the carry C 3 w is unordered then call GetRTags twice first to find out what each tasks produces line 8 and then again with the updated set of carry tags line 10 . This ensures that the reachable tags are overestimated regardless of the execution order.

If w is a task then update its returned value R w . If w is primitive find a set of tags it produces by looking at its add list. If w is non primitive then first find all the methods that can be applied to decompose it and their associated task networks. Then take a union of all tags produced by a call to GetRTags for each of these task networks. Note that this algorithm can be updated to deal with recursive tasks by first identifying when loops occur and then by modifying the algorithm to return special tags in place of a recursive task s returned value. A fixed point algorithm can then be used to remove these special tags and update the values for all tasks.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article or manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Referring now to according to an exemplary embodiment of the present invention a computer system can comprise inter alia a CPU a memory and an input output I O interface . The computer system is generally coupled through the I O interface to a display and various input devices such as a mouse and keyboard. The support circuits can include circuits such as cache power supplies clock circuits and a communications bus. The memory can include RAM ROM disk drive tape drive etc. or a combination thereof. Exemplary embodiments of present invention may be implemented as a routine stored in memory e.g. a non transitory computer readable storage medium and executed by the CPU to process the signal from the signal source . As such the computer system is a general purpose computer system that becomes a specific purpose computer system when executing the routine of the present invention.

The computer platform also includes an operating system and micro instruction code. The various processes and functions described herein may either be part of the micro instruction code or part of the application program or a combination thereof which is executed via the operating system. In addition various other peripheral devices may be connected to the computer platform such as an additional data storage device and a printing device.

The flowchart and block diagrams in the figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical functions s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

