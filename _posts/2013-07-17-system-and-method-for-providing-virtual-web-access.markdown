---

title: System and method for providing virtual web access
abstract: A client-based computer system adapted to communicate with a remote server through a network and to provide access to content or services provided by the server. The system includes a storage device and a cache. The cache is adapted to communicate with the server over the network, to intercept a request from the client to the server, and to store responses from the server on the storage device. The cache is further adapted to automatically determine when to send the request to the server over the network. The cache is still further adapted to provide a response, including from the responses stored on the storage device based upon the request, to appear as through the server provided the response. The system may also include a crawler. The crawler is adapted to operate in conjunction with the cache to cause requests to be sent to the server over the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08793347&OS=08793347&RS=08793347
owner: Mobophiles, Inc.
number: 08793347
owner_city: Santa Monica
owner_country: US
publication_date: 20130717
---
This application is a continuation of U.S. patent application Ser. No. 12 630 806 filed Dec. 3 2009 entitled SYSTEM AND METHOD FOR PROVIDING VIRTUAL WEB ACCESS which claims priority to and the benefit of U.S. Provisional Patent Application No. 61 119 377 entitled SYSTEM AND METHOD FOR PROVIDING VIRTUAL WEB ACCESS filed on Dec. 3 2008 the entire contents of all of which are herein incorporated by reference.

In client server computer systems remote server computers provide access to content such as web pages and services to local client computers over a network. While this allows for centralized management of such content and services issues related to connectivity such as being disconnected from the network or when the network is slow can affect the capability of the client. Although such content and services could be maintained and synchronized locally on the client that is a fat client this greatly complicates the client design and defeats one of the chief benefits of the client server architecture. Consequently there is a need to be able to provide the timely availability of the server content and services to the client when network connectivity is broken or insufficiently responsive and without having to maintain the server content or services locally.

Accordingly embodiments of the invention address these needs by allowing the client to work offline from the server or asynchronously with the server in such a manner that the user is unaware of the issues related to network connectivity or performance. This is accomplished by caching responses from recent server requests on a local storage device. Each new server request may then be intercepted by the cache before going to the server and an appropriate response from the cache returned before or even in place of making the actual request to the server. An optional crawler can refresh these responses or seed new responses in the cache by periodically submitting the same or related e.g. nearby requests to the server.

Write requests to the server can also be handled by storing the write requests as pending in the cache before sending them to the server. The crawler can also be used to send the write requests to the server in the proper order optionally consolidating write requests to the same portions of server content before sending such requests to the server. In addition pending write requests can also be modified or deleted prior to sending to the server.

Through this seamless caching of server content and services the client is able to function as if such content and services were locally available but without any of the server side logic or resources needed to maintain the content or services locally.

In an exemplary embodiment according to the present invention a client based computer system is provided. The client based computer system is adapted to communicate with a remote server through a network and to provide access to content or services provided by the server. The system includes a storage device and a cache. The cache is adapted to communicate with the server over the network to intercept a request from the client to the server and to store responses from the server on the storage device. The cache is further adapted to automatically determine when to send the request to the server over the network. The cache is still further adapted to provide a response including from the responses stored on the storage device based upon the request to appear as though the server provided the response. The request and the responses may conform to a hypertext transfer protocol HTTP specification.

The cache may be further adapted to provide the response based on the request s HTTP request type headers or body.

The request may be a write request to the server content. The cache may be further adapted to provide a response to the write request to appear as though the server provided the response while using the storage device to store the write request as pending until the cache can send the write request to the server.

The cache may be further adapted to consolidate on the storage device multiple pending write requests that are related or directed to a same portion of the server content including maintaining their order or relationship.

The cache may be further adapted to store a response from the server on the storage device to the write request sent to the server.

The cache may be further adapted to modify or delete the pending write request before sending the write request to the server.

The cache may be further adapted to intercept the request at an Application Programming Interface API level.

The system may be adapted to communicate with a specific set of servers through the network and to provide access to content or services provided by the set of servers. The cache may be further adapted to communicate with the set of servers over the network to intercept the request from the client to the set of servers and to store responses from the set of servers on the storage device. The cache may also be further adapted to automatically determine when to send the request to the set of servers over the network. The cache may be still further amended to provide the response including from the responses stored on the storage device based upon the request to appear as though the set of servers provided the response. The specific set of servers may be configured manually or automatically including through user specification favorites bookmarks history or activity.

The cache may be further adapted to intercept a new request that is related to the request for content or services provided by a corresponding server accessible through the network and that is not in the set of servers. The cache may also be further adapted to communicate with the corresponding server over the network store responses from the corresponding server on the storage device to requests that are related to the request automatically determine that the new request is related to the request automatically determine when to send the new request to the corresponding server over the network and provide a response to the new request including from the responses stored on the storage device based on the new request to appear as though the corresponding server provided the response.

The request may be issued from a web browser for a web page to the set of servers and the new request may be for embedded content of the web page on the corresponding server.

The automatic determination by the cache of when to send the request to the server may be based on connectivity between the client and server including a quality of the connectivity or accessibility of the server over the network.

The automatic determination by the cache of when to send the request to the server may be based on a type of the request or parameters of the request.

The automatic determination by the cache of when to send the request may be dynamically reconfigurable.

The cache may be further adapted to provide the response based upon a type or parameters of the request.

The cache may be further adapted to authenticate a user for the request without having to access the server.

The cache may be further adapted to provide the response by manufacturing the response from the server.

In another exemplary embodiment according to the present invention a method of seamless caching on a storage device of a client computer is provided. The seamless caching is of responses from a server computer accessible to the client computer through a network corresponding to content and services provided by the server computer. The method includes intercepting a request to the server computer from the client computer and automatically determining when to send the request to the server computer over the network or to provide a response including from the responses on the storage device based upon the request to appear as though the server provided the response.

The request may be a write request to the server computer content. The automatically determining may further include automatically determining when to store the write request on the storage device as pending. The storing the write request on the storage device as pending may include providing a response to appear as though the server provided the response and continuing to store the write request on the storage device until the write request can be sent to the server.

The storing the write request on the storage device as pending may further include consolidating on the storage device multiple write requests that are related or directed to a same portion of the server computer content including maintaining their order or relationship.

The method may further include the seamless caching on the storage device of the responses from a specific set of server computers accessible to the client computer through the network the responses corresponding to the content and services provided by the set of server computers. The method may also further include intercepting the request to the set of server computers and automatically determining when to send the request to the set of server computers over the network or to provide the response including from the responses stored on the storage device based upon the request to appear as though the set of server computers provided the response. The specific set of servers may be configured manually or automatically including through user specification favorites bookmarks history or activity.

The method may further include the seamless caching on the storage device of responses from a corresponding server computer accessible to the client computer through the network and that is not in the set of server computers the responses corresponding to requests that are related to the request. The method may also further include intercepting a new request that is related to the request to the corresponding server computer automatically determining that the new request is related to the request and automatically determining when to send the new request to the corresponding server over the network or to provide a response to the new request including from the responses stored on the storage device based on the new request to appear as though the corresponding server provided the response.

The request may be issued from a web browser for a web page to the set of server computers. The new request may be for embedded content of the web page on the corresponding server computer.

The method may further include authenticating a user for the request without having to access the server computer.

In yet another exemplary embodiment according to the present invention a client based computer system is provided. The system is adapted to communicate with a remote server through a network and to provide access to content or services provided by the server. The system includes a storage device a cache and a crawler. The cache is adapted to communicate with the server over the network to intercept a request from the client to the server and to store responses from the server on the storage device. The crawler is adapted to operate in conjunction with the cache to cause requests to be sent to the server over the network. The cache is further adapted to automatically determine when to send the request to the server over the network. The cache is still further adapted to provide a response from the responses stored on the storage device based upon the request to appear as though the server provided the response.

The crawler may be further adapted to cause the requests to be sent to the server based upon previous server responses.

The crawler may be further adapted to cause requests for web pages or content to be sent to the server by analyzing or performing actions based upon the previous server responses to requests for web pages or content.

The request may be a write request to the server content. The cache may be further adapted to provide a response to the write request to appear as though the server provided the response while using the storage device to store the write request as pending until the crawler can cause the write request to be sent to the server.

The crawler may be further adapted to consolidate on the storage device multiple pending write requests that are related or directed to a same portion of the server content including maintaining their order or relationship.

The system may be further adapted to communicate with a specific set of servers through the network and to provide access to content or services provided by the set of servers. The cache may be further adapted to communicate with the set of servers over the network to intercept the request from the client to the set of servers and to store responses from the set of servers on the storage device. The cache may also be further adapted to automatically determine when to send the request to the set of servers over the network. In addition the cache may be further adapted to provide the response from the responses stored on the storage device based upon the request to appear as though the set of servers provided the response. The crawler may be further adapted to operate in conjunction with the cache to cause requests to be sent to the set of servers over the network. The specific set of servers may be configured manually or automatically including through user specification favorites bookmarks history or activity.

The crawler may be further adapted to operate in conjunction with the cache to cause requests related to the request to be sent to corresponding servers over the network. The cache may be further adapted to store corresponding responses for the related requests on the storage device.

The cache may be further adapted to intercept a new request that is related to the request for content or services provided by a corresponding server accessible through the network and that is not in the set of servers communicate with the corresponding server over the network store responses from the corresponding server on the storage device to requests that are related to the request automatically determine that the new request is related to the request automatically determine when to send the new request to the corresponding server over the network and provide a response to the new request including from the responses stored on the storage device based on the new request to appear as though the corresponding server provided the response.

The request may be issued from a web browser for a web page to the set of servers. The new request may be for embedded content of the web page on the corresponding server.

The crawler may be further adapted to cause the pending write request to be sent to the server to appear to the server as if a user sent the pending write request.

The illustrative embodiments that follow are only exemplary applications of the present invention and not intended to limit the scope of the invention.

Embodiments of the invention provide applications running on a computer system called the client virtual access to services on a remote computer called the server by trapping these requests at the client and serving responses to them locally as if they came from the server. By responding locally at the client such as using responses stored on locally attached storage the embodiments enable both faster and more continuous access to these services such as when the server is inaccessible no path to server or server is down or when the network connection is slow low bandwidth high latency or both . For example the client may be running a browser that uses the hypertext transfer protocol HTTP to access resources served by a web server.

Embodiments of the invention allow the client both read and write access to content stored on a server even while offline. Generally a request is a read operation when it accesses data on the server while a write operation modifies data at the server. When an application on the client computer sends a request to the server the request is intercepted locally at the client and a local response is returned to allow the client application to behave as if the request was successfully completed at the server. The intercepted request can be sent to the server later without the client application s knowledge.

The general operation of an Internet client application involves issuing requests and receiving responses from a remote system. This application level networking protocol which generally corresponds to layer 7 of the OSI model typically maps to a request response scheme where the client message specifies a request for a particular operation to be performed by the server and the server response provides information e.g. the results about that operation. HTTP and FTP are examples of application level networking protocols.

Embodiments of the invention can intercept these requests and provide the necessary responses locally instead of synchronously requesting them from the server. The interception of these client requests can be enabled through a number of methods that are known to a person having ordinary skill in the art and the embodiments may leverage one or more of these interception methods. For example different types of requests may be preferably intercepted using one method over another.

One method to intercept requests is to do so at the application programming interface API . Internet based application software is generally structured to map to the request response orientation of the networking protocol where there is an Internet services layer designed to facilitate the issuance of these requests and the receipt of their corresponding responses. This Internet services layer is designed to specifically handle one or more networking protocols and is generally distinct from the other functional layers of the application such as an upper layer supporting the user interface e.g. browser or a lower layer supporting the transport level networking protocol e.g. TCP IP . For example the Microsoft Windows platform provides a software module in the form of a dynamically linked library DLL called WinInet which provides an easy way for different Internet based applications to communicate with servers using the application level protocols that it implements. By injecting an API interception layer between the application and the Internet services layer embodiments of the invention can respond to Internet requests locally.

Injecting an interception layer can take several different forms such as dynamically modifying function call entry points in memory to redirect them to other code third party software toolkits may provide this dynamic intercept injection capability such as Microsoft Detours EasyHook or madCodeHook. Another method is to provide a replacement software library that provides an implementation of intercepted APIs that can be loaded by a process instead of the original software library. An advantage of these API interception approaches is that requests can be seamlessly handled without any explicit knowledge of the user or the application. As another option some platforms explicitly provide support for providing an alternative implementation of the Internet services layer such as Microsoft Window s URLMON support for asynchronous pluggable protocols. Using Microsoft Windows URLMON interface a software component may provide a handler for a protocol specified within an URL including overriding the default handlers for HTTP and FTP provided by a Windows platform.

API Intercept has been injected between Client App and Internet Services allowing it to direct requests to Server via Internet Services Cache or any combination of the two.

Internet Services may be the same software module as Internet Services since Cache may choose to use any appropriate Internet services layer to access the Internet including the one used by Client App . Requests directed to Cache may be handled using responses stored locally on Storage . Access to Storage may be for example through Storage Services which is a common storage access layer such as a filesystem database or a combination thereof.

Another method to intercept requests is to configure the web client application to direct requests for a remote system through an intermediate entity called a proxy. The Internet services layer of most Internet based applications support the configuration of a proxy causing some or all requests to be sent to the proxy instead of the server. A proxy can operate locally to the client computer such as through a loopback localhost interface which allows the embodiments to respond to application requests locally a proxy may also operate separately from the client computer perhaps with beneficial characteristics over that of the web server such as an intermediate computer system with closer proximity and or higher bandwidth to the client computer. An advantage of this approach is that proxy based communication is standardized and commonly implemented across different applications and platforms.

Internet Services has been configured to direct one or more requests for Server to a proxy. The proxy may for example be another process local to Client but it may be any execution context such as another thread in the same process as Client App or a remote process on a computer that is perhaps more reliably accessible from the Client than Server such as another computer on the same local area network as Client . The proxy may for example receive protocol requests via Proxy Intercept and direct them to Server via Internet Services Cache or any combination of the two.

Internet Services may be the same software module as Internet Services since Cache may choose to use any appropriate Internet services layer to access the Internet including the one used by Client App . Requests directed to Cache may be handled using responses stored locally on Storage . Access to Storage may be for example through Storage Services which is a common storage access layer such as a filesystem database or a combination thereof.

Another method to intercept requests from the client to the server is to trap events within the application client. This may be done for example through an API provided by the application client to support 3rd party extensions also commonly called plug ins. For example many web browsers support a plug in API such as Internet Explorer s Browser Helper Object interface similarly Microsoft applications such as Microsoft Word support plug ins using the Component Object Model COM interface. These application level APIs generally support the ability for the plug in to register a function that is called when a particular application level event occurs such as when a request to a server also referred to as navigation is being made.

Another method to intercept requests is to trap events on the document loaded within the application client. For example web browsers generally implement an interface called the W3C Document Object Model DOM which allows HTML XML documents to define functionality such as the logic to execute when a user clicks on a document element such as a link or button. The DOM supports listeners for events on these document elements and a listener implements a handler function that is called when that event occurs. For example requests issued when a link is clicked can be intercepted by registering a JavaScript function for a click event on that link. An event handler may be registered by dynamically modifying the representation of the document in memory that is injecting which may take place at a number of different points. For example they may be injected by a proxy such as in by inserting a script block into an HTML document being requested. They may also be injected by a browser plug in by setting the onclick property on the DOM element.

An aspect of the invention according to some embodiments is that Internet requests from multiple client applications can be transparently intercepted and serviced locally.

Process is running WinInet Client such as Microsoft Word or Microsoft Internet Explorer which is a type of Client App that normally links to Microsoft s WinInet DLL which is a type of Internet Services . WinInet Intercept intercepts requests by WinInet Client which allows it to redirect requests intended for WinInet to Cache . WinInet Client loads Application Plugin which can be implemented as a COM Office addin for Microsoft Word or a browser helper object BHO for Microsoft Internet Explorer. The application plugin can provide access to Cache from the client user interface such as getting or setting cache contents or status. The application plugin can also serve to inject WinInet Intercept to enable interception of function calls between WinInet Client and WinInet . This allows Cache to receive and handle Internet requests issued from WinInet Client .

The embodiment applies to any Client App that accesses an Internet Services such as Mozilla Firefox which uses Mozilla Netlib for its Internet services. Basically any application that accesses the Internet via the API of an Internet Services can be intercepted by an API Intercept which can then redirect its Internet requests to Cache . A Client App that access a different Internet Services may use a different API Intercept to enable interception.

Cache may for example be common across applications such as in Processes and . Cache may include Cache Engine which in turn may include one or more software components providing application generic functionality. Cache may also include zero or more App Extenders which logically extends Cache Engine with application specific functionality. In some embodiments Cache Engine may be Java software running inside Java Virtual Machine JVM which enhances portability across different computing platforms. When it receives an Internet request Cache Engine may query the response data from storage such as via Database which may be accessed via a separate Process . Cache Engine may also call App Extender to assist with the request. If a valid response is found Cache Engine returns the response to the upper layer Client App such as WinInet Client in Process . Otherwise Cache Engine may cause the request to be issued to the server which may take place through another context such as via Crawler Process .

While Cache runs on the client computer in the embodiment of Cache may also run on one or more separate computing systems such as one with better availability or more bandwidth to the client computer than that of the server. For example Cache may run on another platform e.g. server phone etc. on the same or nearby local area network e.g. Ethernet WiFi Bluetooth thus allowing Cache to provide improved availability and or performance characteristics to the web application.

An aspect of the invention according to some embodiments is to support application specific customization through the support of 3rd party software. There are a number of direct and indirect ways that external software can assist with request handling. For example direct calls to application specific software can be supported through external functions that were linked with Cache Engine . As another example indirect calls with application specific software can be supported through inter process communications such as message queues or pipes that are opened by Cache Engine . The calls to external software may be conditional such as qualified based on the request parameters. For example calls to external software can be set by configuration parameters on Cache Engine such as configuration parameters that specify patterns to match against the request headers before a particular call is performed.

Process is running a crawler which supports communications with the servers often in the background i.e. not visible to the user . The crawler may be a Java software component running inside JVM which may be the same JVM instance as . The crawler requests server resources by programmatically controlling an Internet based Client App such as a WinInet Browser which may be the same or similar to WinInet Browser . WinInet Browser can be controlled programmatically through a Browser Control layer such as Web Application Testing in Java Watij or TeamDev JExplorer. Also similar to Process Process injects WinINet Intercept e.g. Crawler calls LoadLibrary via JNI to enable the interception of Internet requests from WinInet Browser .

Process may differ from Process in that Internet requests to Cache are transmitted to the server such as when a cached version is missing or needs to be refreshed these requests are passed by WinInet Intercept through to WinInet so that they may be handled by the server. Cache may support this behavior by providing a different operational mode than that of Process which may be explicitly requested by Crawler such as through a call made during initialization time. Any new response data received from the server may be stored to Database so that it may be persisted and made accessible such as by Process .

Some embodiments may access storage through Database which may consist of a filesystem database or combination thereof. Database may be accessed within the same process as that of Cache or it may be provided by a separate context or process such as Process . In some embodiments Process is running Database which manages access to the locally cached server content. Database may be a Java software component running inside JVM . Other processes may retrieve or store data from the database by communicating with Process using common inter process communications IPC mechanisms such as Java remote method invocation RMI or Java database connectivity JDBC . Database may also run in process with Client Process such as within Processes or for example this may be the case if Database supports inter process serialization of shared data.

Process is running a Manager which handles miscellaneous control and management tasks such as launching crawlers and watching for changes in server connectivity. Manager may be a Java software component running inside JVM . Other processes may access the services provided by manager by using common IPC mechanisms such Java RMI.

When the client is launched it will load application plugin . Application plugin will then inject WinINet Intercept . WinINet Intercept can be implemented in any manner that the application allows for extensibility such as a DLL that can be loaded into the process such as by using the LoadLibrary API.

In this embodiment intercept uses dynamic intercept injection at step to set up the interception of the WinINet APIs. Other embodiments could use other techniques such as using a different API to perform the WinINet API interception such as madCodeHook or using a replacement DLL that implements wrapper functions for WinINet APIs.

At step Intercept starts the Java Virtual Machine JVM . This embodiment uses Java for the implementation of the cache and interoperates with Java code using the Java Native Interface JNI API. Other embodiments could use any other language to implement the cache such as C C or a Microsoft .NET language such as C or Visual Basic. An advantage of implementing the cache using Java is that it allows the cache to run on any environment that can run a Java Virtual Machine.

At step the intercept calls an initialization method on cache . In this embodiment at step the initialization will register the cache with a manager to receive notifications of events from the manager. This allows the cache to be aware of things such as changes to server connectivity that the manager detects. In this embodiment the cache and manager can communicate using some IPC mechanism such as pipes or the Java Remote Method Invocation RMI API.

At step plugin will unload WinINet Intercept such as by using the FreeLibrary API. The intercept stops intercepting WinINet API calls at . In this embodiment Intercept uses dynamic intercept injection to intercept WinINet APIs. Other embodiments could use other techniques such as using a different API to perform the WinINet API interception such as madCodeHook or using a replacement DLL that implements wrapper functions for WinINet APIs.

At step intercept calls an uninitialization method on cache . In this embodiment at step the uninitialization will unregister the cache with a manager to stop receiving notifications of events from the manager. This informs the manager that it no longer needs to inform that client application of events such as changes to server availability. In this embodiment the cache and manager can communicate using some IPC mechanism such as pipes or the Java Remote Method Invocation RMI API.

Finally at step the JVM is stopped. In this embodiment the cache is implemented using Java. After the cache is uninitialized no more Java code is invoked and so the JVM is no longer needed. Other embodiments could use any other language to implement the cache such as C C or a Microsoft .NET language such as C or Visual Basic. An advantage of implementing the cache using Java is that it allows the cache to run on any environment that can run a Java Virtual Machine.

An aspect of the invention according to some embodiments is controlling which servers or more precisely the server applications are cached by the system. By controlling what is cached by the system a number of advantages are gained. For example this provides additional manageability of the cache such as allowing the user to specify different storage usage limits for each server application or different levels of asynchronous operation for each server application. As another example this provides additional manageability of other aspects of the system such as allowing it to enable connectivity testing or crawling of the cache enabled servers. One embodiment allows client requests to servers that are not configured to pass through directly to the server. Another aspect of configuring a server for caching is specifying the user credentials to associate with the server. Storing the user credentials serves several purposes allowing authenticated virtual sessions from a client application to the cache and allowing a crawler to create authenticated real sessions with a server.

There are a number of different ways that the system can enable or disable servers for caching. For example the system can operate inclusively such that only explicitly enabled or white listed servers are enabled for caching. In addition the system can operate exclusively such that all servers are enabled except those explicitly disabled or black listed. Further these servers may be configured manually such as via user input listed in a configuration file or hardcoded e.g. into Cache or Client App . The servers can also be configured automatically such as based on user activity e.g. top 10 most visited web sites or self enabled by the server e.g. when a user browses a web site it reports itself as being cacheable via the presence of a resource at a well known URL .

At step the plug in requests the list of server application types that cache supports. In this embodiment the cache can use the application type to control certain aspects of the logic such as the authentication method to use with the server.

To support HTTPS authentication that makes use of client site certificates the browser plug in will enumerate the certificates configured in the browser. In this embodiment this can be done using the Windows Crypto APIs in the Internet Explorer browser but in another embodiment such as using the FireFox browser the certificate database can be accessed using the Network Security Services NSS APIs.

At step the browser plug in will display a dialog box that will allow the user to specify information about the server to white list. The dialog box could have input fields to allow the user to specify things like the name of the resource to white list such as the URL of the server any credentials needed to access the resource such as the username and password and client side certificate if applicable to use to authenticate to the server and the application type of the server.

If the user had selected an option in the toolbar to white list the current URL then the dialog box will be pre populated with default information based on the current browser context such as pre populating the URL input field with the URL of the current document. Next the browser plug in queries the HTTP headers for information that could identify the application that the URL came from. For example the Microsoft Sharepoint server sends an HTTP response header that contains the string MicrosoftSharePointTeamServices followed by a version number e.g. 12.0.0.4518 which can be used to identify the document as being served from a Sharepoint server.

If the browser plug in is able to find a header that it can use to identify the application then it will set the application type input field to the identified application type. In another embodiment other information could be used to try to identify the application such as pattern matching against the URL path string. These steps set default values in the input fields in the dialog box and can still be overridden by the user.

After the user submits the request to white list the server the browser plug in makes a request to add a server account to the cache which will configure the URL as the basis for requests that should be intercepted and a user account that will contain the user credentials associated with the server account.

Next the system starts a process that will populate the cache with content from the server that was just white listed. This provides the advantage of allowing the system to verify the given user credentials with the server and build a pre emptive cache of server content while the client is presumed to have online access to the server.

Some embodiments of the invention may process protocol level requests through a caching layer allowing them to determine when and how to serve those requests such as either using a local cache of responses or retrieving the response from the server.

Referring now to Client App is an application such as Microsoft Internet Explorer that issues HTTP requests such as when a user or crawler accesses a hypertext link. Prior to the invention these requests were typically handled through calls into WinInet but according to some embodiments of the invention these requests are now intercepted by WinInet Intercept and redirected to Cache .

For each request Client App calls WinInet API functions to initialize the request so that the correct request can be identified across WinInet calls. Request initialization takes place in the UML frame Initialize Request .

When the request has been initialized Client App proceeds to sending the request. For HTTP requests this is supported by the WinInet API function HttpSendRequest. Instead of being sent out to the server the request is intercepted by WinInet Intercept at step and will be redirected to Cache where it can be handled locally.

Upon receiving a request WinInet Intercept first prepares the request before calling Cache which is handled in UML frame Prepare Request see . Next WinInet Intercept issues the request to Cache which will process it and provide a response as described in detail in UML frame Cache Request .

Upon completion of the request WinInet Intercept indicates completion to Client App at step via a return from a synchronous call to HttpSendRequest or a callback function such as for an asynchronous call . Client App obtains status and response data for the request in UML frame Read Response see .

An Internet services layer such as WinInet often provides a number of capabilities that are related to handling Internet requests. For example WinInet automatically manages HTTP cookies which are strings sent by the web server in response messages to the web client who then sends them back in subsequent requests to that server. This functionality along with other client side protocol state management is typically provided by the Internet services layer since it is needed across multiple client applications using the same application level network protocol. It is often desirable to leverage this functionality provided by the Internet services layer even when its calls are being intercepted.

The first step of initializing a request is to establish a connection handle that identifies a particular server which is supported using the WinInet API function InternetConnect. The call to InternetConnect is intercepted by WinInet Intercept at step and passed through to WinInet via InternetConnect . If successful WinInet returns a connection handle to WinInet Intercept at step . WinInet Intercept sets the server in step since this cannot be subsequently queried from the current WinInet API and it then returns a connection handle to Client App . Once a connection handle is established Client App may reuse it across multiple requests to the same server.

The next step of initializing a request is to establish a request handle that identifies a particular operation on a particular Internet resource. For HTTP this is supported using the WinInet API function HttpOpenRequest to specify the HTTP method and URL. The call to HttpOpenRequest is intercepted by WinInet Intercept at step and passed through to WinInet via HttpOpenRequest . If successful WinInet returns a request handle to WinInet Intercept at step which then returns a request handle to Client App at step . Note that WinInet maintains the association of the request handle with its method and URL at step as this can be subsequently queried from WinInet .

Referring now to when Client App calls WinInet Intercept at step to retrieve the response data it is intercepted by WinInet Intercept . A client application may make multiple WinInet calls to obtain the various parts of the response header information such as calling HttpQueryInfo for response headers and InternetReadFile for the response body. WinInet Intercept decides at step whether to handle the call or pass it through to WinInet . WinInet Intercept may for example handle the call by using the response returned from Cache that has been associated with the request handle. An exception is when Client App is querying for cookies since they are typically maintained by WinInet which is used to keep cookies updated across multiple requests if so then the cookies are queried from WinInet at step . Otherwise WinInet Intercept selects the requested data from the response at step . The response data requested by the caller is then returned at step .

An aspect of the invention according to some embodiments is to improve the continuity of access to server content even when access to the server is disrupted or lost. The embodiments support this by decoupling some or all requests between the user and the server which means that requests initiated by the user are handled virtually possibly without any communication with the server. These virtual requests may be for example handled locally using responses stored on local storage. Communication with the server may be performed in a separate request context handle possibly even in a different thread or process. This approach insulates the user s requests from connectivity changes since they are not the same as requests that go to the server.

Referring now to the request is issued to Cache by calling CacheRequest . Upon receiving a request Cache must decide whether to handle it at step based on factors such as whether it can be stored in the cache e.g. cached response for a read operation or pending request for write operation . For example this decision can be based on whether or not the URL for the resource falls within the set that may be cached such as by comparing against one or more base paths that are configured for caching. If Cache decides to handle it it proceeds to step . Otherwise it passes the request through to the server which may be handled directly by Cache Engine as described in UML frame Passthru Request .

An aspect of the invention according to some embodiments is that the resources contained within a page can also be automatically cached including those originating from an outside domain that is different from that of the page itself or from a subdomain of the domain being cached e.g. server1.mydomain.com may be automatically included when www.mydomain.com is white listed . For example this is common for web pages that aggregate or mash up content from different web services onto a single page possibly in a customizable manner where the various web content can be added or removed from that page. To accommodate this case Cache tracks page boundaries and automatically allows caching of content accessed within the boundary of a cacheable page including content from outside domains. Cache may use a request parameter such as the Referer header in an HTTP request as an indication of a resource s association with a particular page.

In other embodiments Client App may insert a custom request parameter such as using either the Pragma or a proprietary header in an HTTP request to more accurately indicate the page that contains a requested resource since the Referer header does not differentiate between references e.g. hyperlinks and containment. A custom request parameter may be inserted seamlessly before the request is received by Cache such as by Application Plugin or WinInet Intercept . WinInet Client may also either alternatively or in combination with notify Cache of page transitions such as through a function call triggered by a navigation event. For example WinInet Client may call Cache whenever it receives a callback for BeforeNavigate to indicate transition to a new containing page as long as the containing page is cacheable any resources subsequently requested while WinInet Client is still on that containing page will also be cacheable.

At step Cache decides whether to process the request as a virtual or real one. Virtual requests may be for example issued by a user application context such as a web browser process interacting with the user which are handled locally such as using cached responses. Real requests may be for example issued by a separate application context such as a crawler running in the background which handles issuing any requests that need to go to the server possibly including those needed to service virtual requests issued by the user. The operational mode may be specified for a request either implicitly e.g. Crawler set Cache in real mode via initialization time downcall dependent on connectivity state quality or explicitly e.g. via a HTTP header inserted by Crawler or WinInet Intercept configured by domain URL etc. .

If the request came from the crawler the request is handled as a real request in UML frame Real Request . Otherwise the request is handled as a virtual request in the UML frame Virtual Request see .

Upon completion of the request the response is returned to WinInet at step . The resulting response is then associated with the request at step so that it may be accessed by Client App through subsequent WinInet API functions. WinInet Intercept will also update the API context being maintained by WinInet such as calling InternetSetCookies at step to update the cookie state.

A virtual request is generally considered to be a request that may be preferably handled without direct interaction with the server and preferably in a manner that is transparent to the client application. In general requests received from an application that is interactive with a user is processed as a virtual request such that it is handled within Cache which provides a response to Client App that is virtually equivalent to a direct response from Server . These responses may also be dynamically constructed either in whole or in part.

Referring now to at step Cache Engine determines whether the request should be passed to an App Extender such as based on an URL pattern matching the request. If so the request is passed to App Extender which may perform any type of processing such as modifying the request or updating its own state.

At step Cache Engine determines whether the request is for a login such as based on the presence of login information in the request header or a match with a configuration parameter that identifies the login request of a particular web application. If so Cache Engine proceeds with login handling in UML frame Virtual Login see .

At step Cache Engine determines whether the request is stateful such as when indicated by an application specific configuration parameter. If so Cache Engine proceeds with session handling in UML frame Virtual Session .

At step Cache Engine performs response handling in UML frame Cache Response which will set the response for this request if the data for the response is in the cache.

At step Cache Engine performs post processing on the response in UML frame Virtual Fixup . Upon successful completion of Virtual Request a response for the request is returned to WinInet Intercept . If Virtual Request encounters a problem an error is returned to WinInet Intercept so it can be communicated to the user.

An aspect of the invention according to some embodiments is to support the authentication of a user by the server even if the server is not currently accessible or becomes subsequently inaccessible. Users may be for example authenticated by a server using authentication data carried within a request. Authentication may be supported directly by the application level protocol such as HTTP header authentication or it may be private proprietary to the application such as sending authentication data within the body of an HTTP POST request. The embodiments provide the ability to virtually authenticate a user regardless of the authentication method by obtaining the user s authentication data from the request and comparing it against the locally cached authentication data.

Referring now to at step Cache Engine extracts the user s authentication data from the login request if necessary. Authentication data may be provided externally and passed into Cache Engine such as when it is obtained by WinInet Intercept during processing for UML frame Prepare Request see or parsed by an App Extender at step of . The authentication data may also be specified within the request parameters such as within the body of an HTTP POST request. In this case Cache Engine may support application specific parsing of the login request here at step such as through a configuration parameter that identifies the appropriate input fields in an HTML form submission.

Cache Engine validates the authentication data associated with the login request against the cached authentication data. Authentication data is cached similarly to other web content in general the most recent authentication data that was valid for real requests to the server are cached and used to authenticate virtual requests. At step Cache Engine queries for the current authentication data for this user from Database such as his password and then at step compares the stored authentication data with what was obtained for this login request.

At step Cache Engine performs steps associated with an unsuccessful login such as when no authentication data was provided e.g. initial attempt to request authenticated content the user types an incorrect username or password or the locally cached authentication data is stale. In this case embodiments of the invention may pass the login request through to allow the server to perform the authentication. At step the request is set for pass thru operation and the request then issued to the server as described in UML frame Get Response . At step if the server successfully authenticated the login request then the user supplied authentication data is treated as valid and is used to update the locally cached credentials at step .

At step Cache Engine performs steps associated with a successful login. At step it marks the request as being authenticated which may be required when the response is looked up later. At step it may be necessary to create a session such as when indicated by a configuration parameter. A session may be necessary to maintain user state such as for applications that use proprietary authentication methods e.g. session cookies and or support stateful requests e.g. session timers . If so a session is created at step and the session state is initialized. The session has a unique identifier that may be returned in the response such as by a fix up assigned at step .

Responses for login requests may be modified before they are returned such as when an application specific configuration parameter specifies a regular expression or script to apply to the response body. For example there may be a configuration parameter that inserts the session identifier as a cookie or a configuration parameter that sets redirection URL based on an input field in the request body. If there are any fix ups necessary they are assigned to the request at step so that it may be applied later after the response is looked up.

The virtual session may be persistent or volatile. If the login session is volatile it is deleted when Cache terminates either implicitly e.g. stored in memory or explicitly e.g. stored on disk if persistent the login session is deleted if and when it is designated to expire. The session expiration may vary according to the application. Correspondingly the session identifier may need to include session expiration information such as via the expiration date of the HTTP session cookie.

At step Cache Engine determines whether the request should be passed to an App Extender such as based on an URL pattern matching the request. If so the request is passed to App Extender at step which may perform additional processing such as modifying the request or updating its own state.

An aspect of the invention according to some embodiments is that user credentials e.g. username and password are effectively cached locally at the client computer so that user authentication may be performed seamlessly even if the server is not accessible. The locally cached credentials may be used to verify user access to locally cached content for virtual requests as well as to authenticate to the real server for real requests .

In general the embodiments maintain the locally cached user credentials so that they reflect those actually used by the real server. This enables the embodiments to authenticate access to locally cached content using the same credentials that are used to access content at the server. Credentials may be provided by the user for local caching either explicitly or implicitly. For example user credentials may be provided explicitly through a configuration step such as an input dialogue or form provided by the embodiments as described in step .

In other embodiments user credentials may be provided implicitly such as when they are associated or contained within a request. For example username and password may be obtained from the user s current logon session such as provided by Microsoft Integrated Windows Authentication or from the internet services layer such as WinInet which may query the credentials from the user for use in HTTP header based authentication. As another example user credentials may be extracted from a login form e.g. via the DOM or login request e.g. POST body that was submitted by the user when he logged into the server.

The invention according to some embodiments may also automatically update a user s locally cached credentials if it has been successfully authenticated by the real server. This approach as described in step can seamlessly maintain changes to user credentials such as when a user changes his password from another client computer. For example if the user credentials associated with e.g. HTTP header based authentication or contained within a request e.g. form based login differ from that which is currently cached and if the server targeted by the request is accessible then the request including the user credentials may be passed through to the real server for verification. If the request is successfully authenticated then the locally cached credentials may be automatically updated as they have been directly verified by the server.

The locally cached user credentials may get out of sync from the real ones at the server. For example a user may have changed his password at the server but then attempt to access cached content from a client computer that is currently offline. If the client computer has not been updated either implicitly or explicitly with the new password then the embodiments may not be able to authenticate user requests using the new password. In this case the current locally cached credentials which are now out of sync with the server may be manually updated using any conventional means. For example it is common practice to allow the user to update to the new password by first correctly specifying the previous password. In another embodiment the user may be allowed to forcibly update the password such as when they no longer remember the previous password by correctly specifying another secret such as successfully answering a question about some personal detail which is commonly known as a password reset question.

An aspect of the invention in some embodiments is to support requests that take place in the context of a session such as for request authentication and or other user related state. Another aspect of some embodiments of the invention is to seamlessly support user sessions regardless of actual connectivity such as when the server is inaccessible when starting a session or when server connectivity is lost after a session is started. For example responses from accessing the frequently accessed pages of a user s favorite web site can be cached and refreshed by a crawler in the background during periods of server connectivity in addition to nearby content accessible by client side logic e.g. JavaScript . Then when connectivity is interrupted those pages appear to the user to be completely accessible along with their current content. For instance an online periodical such as a newspaper could have recent responses from crawling the top level pages cached along with nearby clickable content so that a user might be able to read experience the periodical while in a location with no network connectivity for example vacation travel obtaining current content as if there was network connectivity. Thus to the user this capability is seamlessly integrated into the existing web browser.

As background requests are considered stateless when they fully specify the parameters necessary for a server to unambiguously determine its response. As such stateless requests can then be used to uniquely identify the appropriate response in a cache of server responses. In the simplest case the request e.g. some or all of the HTTP headers and or body can be used to lookup its corresponding response e.g. used directly via string comparison or hashed into a lookup tag . Systems based on the representational state transfer REST architectural model such as many modern web sites application may use stateless requests. Since responses are looked up based only on the parameters directly specified within a request each response must be uniquely associated with a particular request so that a request will not ambiguously match more than one response. For example HTTP requests contain three major components i.e. request line headers and body and any combination of the three may play a factor in the lookup of a response. For example a stateless request using the HTTP method GET may uniquely identify its response based on a combination of the uniform resource identifier URL and headers e.g. cookies while a one using the HTTP method POST may need to include consideration of the body component.

However requests that leverage additional or implicit information to correctly determine their response such as additional state maintained at the server are considered stateful. As such this implicit request information may be maintained by embodiments of the invention to accurately identify the appropriate response among a cache of server responses. This additional request context may need to be considered when looking up the response for each stateful request and this context may be modified by these requests essentially affecting how subsequent requests are handled. For handling stateful requests the embodiments maintain and update a session context that logically corresponds to the state at the server which is then used to look up a response for a stateful request.

Referring now to at step an identifier is obtained for the session. Different applications may identify their session differently which may be indicated by an application specific configuration parameter for example FTP implicitly identifies its session based on the connection while a web site may embed the session identifier in an HTTP cookie.

At step the session is looked up. Then at step Cache Engine checks whether a session was found and if so whether it is valid such as verifying an inactivity timer. If so the request may be updated at step using the session context depending on the request and or the session context. For example if the session is used to authenticate requests then the request is marked as authenticated or the session may simply be associated with the request so that the context is available for the subsequent response lookup.

At step Cache Engine determines whether to call an App Extender such as when specified by a configuration parameter. If so the request is passed to App Extender at step which may perform additional processing such as modifying the request or updating its own state.

After a request has been preprocessed such as performing any login or session handling response handling can be performed for a request. In general a response may be obtained from a cache of previously stored responses dynamically generated or a combination thereof.

Referring now to at step Cache Engine determines whether the request was successfully authenticated if necessary. This decision can be based on whether the request matches a configuration parameter indicating that authentication is required. If so and the request has not been authenticated such as by a valid login or session then an authentication failure response is returned for the request. This response may be dynamically generated such as an HTTP response or it may be obtained from cache such as a redirect to the login page.

If the request did not require authentication or it was successfully authenticated then the normal response handling is performed starting with UML frame where Cache Engine selects the appropriate handling for a request which may be based on its type such as whether the request is for a read or write operation. Generally a request is a read operation when it retrieves data from the server while a write operation modifies data at the server a request that does both is typically also considered a write operation. Since Cache effectively provides an intermediate staging area for data exchanged between a Client App and Server a read operation generally retrieves data from the cache and a write operation generally stores data to the cache.

In the first case of a request is determined to be handled dynamically by a script such as when specified by a configuration parameter matching the request. If so at step this script may be executed within Cache Engine such as by an embedded scripting engine or it may be inserted into the response for deferred execution such as embedded in an HTML script tag that is subsequently executed by a web browser.

In the second case of a request is determined to be handled by external software such as by a call to an App Extender specified by a configuration parameter matching the request. If so at step the request is passed to App Extender who may respond to the call with a response.

In the third case of a request is determined to be a write operation such as based on a URL pattern specified in a configuration parameter. If so the write operation is processed in the UML frame Put Pending see .

In the last case of the request is passed to Cache where it may be serviced from the local cache of responses such as a stateless HTTP GET request or possibly issued to the server such as an HTTP POST request that was not identified as a write operation i.e. not put on the pending queue . Note that accesses to pending items may be preferably requested this way i.e. via special URL that references the item in the pending queue . If so the request is processed in UML frame Get Response .

An aspect of the invention according to some embodiments is to support lookups in the cache that properly differentiate between requests that appear similar e.g. same URL . These requests may be differentiated by the consideration of other information such as the session context or other client input e.g. HTTP cookies . This additional information can be incorporated in any appropriate means such as appending them into a single lookup string or using them as separate inputs in a structured query. One embodiment of the invention folds request parameters into a relatively short but unique tag which enables an efficient lookup. For example the request parameters may be collectively hashed into a code that is used as a unique identifier for searching in the cache of responses.

Another aspect of the invention according to some embodiments is to support lookups in the cache that properly recognize equivalent requests that only appear to be different such as when they specify the same parameters using a different order or are encoded using different schemes e.g. UTF 8 RFC 1738 etc. . For example cookies within an HTTP request may be ordered differently depending on how and when they were returned from the server from previous responses leading up to the current request.

Some requests may specify parameters that are irrelevant in uniquely identifying the corresponding response such as those that may be optional or transient. For example the HTTP Date header is optional in client messages and its value continuously changes even when every instance of that request refers to the same response. Another example is a request for a web form that can have edit controls that are pre populated with information from the request body. The lookup may not require all of the information in the request body in order to allow the web form to be retrieved from cache regardless of the instance specific information in the request.

Equivalent requests can be associated with the same response by any combination of commonly known methods. For example one approach is to normalize the request parameters ensuring that parameters are specified in the same order are using the same encoding and are using the same letter case. This approach is advantageous when the lookup tag for the request itself or derived directly on its request parameters e.g. hash function . Another approach is to use a flexible lookup mechanism where the responses are progressively narrowed using multiple partial comparisons excluding or filtering select portions of the request parameters using case insensitive comparisons or any combination thereof. The filtered request parameters may be saved to allow them to be restored so that the cached content may have them available for example in the case where a filtered parameter contains information that is used to pre populate an edit control in a retrieved web form.

The client typically identifies the session when it issues a stateful request which can be done explicitly or implicitly so that the server may factor the context into the lookup of the response. An example of explicit context identification is the use of an HTTP cookie to specify a unique session identifier this session cookie is returned during the user s login process and provided by the client whenever the user issues a request. An example of implicit context identification is the use of persistent TCP connections the server securely associates a TCP connection with a specific client e.g. cryptographically protected by the Secure Sockets Layer protocol so that requests received on that connection could uniquely be associated with a particular session.

Since the session context is included along with the request in the lookup of the response the response needs to be associated with this additional information from the session context. So when responses for stateful requests are retrieved from the server the cache engine not only associates the request parameters with the response it also includes the session context. When a stateful request needs to be retrieved later from the cache such as for an offline browsing session the cache lookup includes the session context such as the node requested prior to the current one. As requests are processed the context is continuously updated to indicate the node in the directed graph representing the sequence of requests leading up to the current one.

As an example FTP sessions maintain the notion of a current working directory which defines the context of FTP commands that operate on a relative path such as listing the current directory contents. In this case the running context tracks the current working directory which is then included in the lookup of for example a particular file or directory listing to retrieve.

Responses may be stored in a cache such as organized with a database and they may be looked up based on the request parameters. If the request is stateful it may include information from a session context. Responses for virtual requests may be cached previously using real requests sent to the server.

Referring now to at step Cache Engine determines whether to look up the currently cached entry which is optional if the request needs to be passed through to the server. If so it constructs the lookup data for the request at step . This may involve inclusion of additional parameters into the lookup such as a current path from a session context or a particular cookie from an HTTP header. This may also involve a normalization of the request parameters to ensure that lookups for equivalent requests will yield the same response. This may also involve filtering of the request parameters to allow lookups to exclude instance specific information in the request. In some cases information in request parameters that are filtered out may be restored using a fixup for example in the case where a request parameter specified a value that would pre populate an edit field in a form. This may further involve a restructuring or hashing of the request parameters into a smaller and or semantic structure such as to improve lookup efficiency.

At step Cache Engine looks for the cache entry in Database . This lookup may involve a single operation such as a query to a relational database or a filename lookup on a filesystem or it may involve many steps such as a search through multiple objects stored in a database or multiple files on a filesystem.

At step Cache Engine determines whether the request needs to go to the server such as when a response was not found or Cache has been configured to pass through some or all requests to the server. This includes requests that are not known to be safely cacheable such as an HTTP POST request but are also not currently configured to be processed as a pending write operation. If so then the response may be retrieved by another execution context such as to issue requests via a common session with the server but the request may also be issued by the current context. If the request is issued by another context then Cache Engine may retrieve the response from Database .

To issue the request to another context according to one embodiment Cache Engine creates a user task which contains the necessary information for another execution context to actually issue the request to the server. At step Cache Engine determines whether a user task should be created based on whether the server is accessible or the request can be deferred if the server is not accessible e.g. pass though requests are expected to be processed immediately . If Cache Engine decides to create the user task it first sets up the cache entry at step either creating it or holding it depending on whether it already exists to rendezvous with the context that will be actually retrieving the response from the server. Next Cache Engine creates a user task at step which notifies the other context e.g. crawler about the request.

At step Cache Engine decides whether it should wait for the response. If so then at step Cache Engine waits for the response which may be signaled if the response was retrieved by another execution context or issued asynchronously within the current context. If the response is stored in Database such as when retrieved by another context Cache Engine queries for the cache entry at step . At step Cache Engine sets either a response if available or an error depending on the failure cause e.g. timeout not online server error etc. . Cache Engine then releases the cache entry at step which subsequently allows the entry to be deleted e.g. not a cacheable entry evicted when out of space .

It is an aspect of the invention according to some embodiments that requests for web content are automatically determined to be served from cache or issued to the server depending on the accessibility of the server. When the server is inaccessible the embodiments automatically use Cache for read and write operations to minimize disruption to the user e.g. waiting for server requests to time out . When a server is accessible the embodiments may issue requests for read or write operations to the server or may use Cache in lieu of or in combination with issuing requests to the server. The embodiments may determine how to process requests when a server is accessible based on a variety of factors such as whether locally cached content is fresh e.g. as indicated by HTTP headers and or whether the system is configured for any asynchronous operation e.g. based on user preference .

Asynchronous operation means that requests are generally served from cache without waiting for a response from the server this is similar or equivalent to the operational mode used when the server is inaccessible. Although the request may have been handled locally a request may still be issued to the server such as to refresh the cached content in the background.

Embodiments of the invention may support different levels of asynchronous operation allowing them to provide different degrees of acceleration that often means some tradeoff with content freshness. For example a user may configure the system or a particular server for fully asynchronous operation to fully accelerate access to a web application this means that any content changes by the user or someone else may not be seen immediately even if the server is accessible. This degree of acceleration may also be configured dynamically in some embodiments. For instance when network connectivity is fast the operations are done synchronously while when the connectivity is slow the operations are done asynchronously. The following table which illustrates examples of different levels of asynchronous operation indicates where a request may be served from depending on server accessibility 

At step manager is signaled by a timer event or a network event to begin the process of checking server availability. The manager calls the database to enumerate the server accounts that were created during server white listing. The manager will then loop through every server account performing the availability check.

At step the manager attempts to test the availability of a server. The test may take different forms such as a UDP ping to the server an attempt to open a TCP IP socket connection to the server or an attempt to make a higher level protocol request to the server such as an HTTP or FTP request.

At step the result of the test is compared against the saved result of the last test that the manager made for the server. If the availability of the server has changed since the last test then first the new availability status is saved so that it can be compared against in the next test interval. The status is also updated in the database so that the status can be shared with other processes that access the database such as instances of a cache that are running in a client application .

At step the manager sends an event notification to inform of the change in server availability. This allows any process that registered for event notification with the manager to be aware of the change and take some action such as updating a user interface that might provide server status information.

After generating a response for the request it may be necessary to post process the response before returning it to the caller such as modifying the response to customize it for the current caller. There may also be additional finalization steps necessary such as updating the session based on the given response.

Referring now to at step Cache Engine checks whether a response has been associated with the request. If not then a default response is assigned to the request at step based on the reason for the lack of a response such as if an error was previously returned during a cache lookup.

At step Cache Engine checks whether a session needs to be updated based on the current request and or response. If so the session is updated at step such as updating a current working directory or resetting an inactivity timer.

At step Cache Engine checks whether there are any fix ups associated with the request such as fix ups from the previous processing phases for login or session handling or cache lookup. If so these fix ups are applied at step such as injecting script sections into an HTML response.

At step Cache Engine checks whether there are any fix ups associated with pending items. If so these are handled in UML frame Apply Dependent Fixups .

At step Cache Engine checks whether there are any other fix ups associated with the request and or response such as any specified by a configuration parameter matching this request and or response. If so they are applied at step such as injecting script sections into an HTML response.

At step Cache Engine checks whether the request should be passed to an App Extender such as based on an URL pattern matching the request or response. If so the request response is passed to App Extender at step which may perform any type of processing such as modifying the response or updating its own state.

A real request is one that is issued to the server and its response may be stored in a local cache so that it may be served locally whenever necessary such as for a virtual request. The cache storage may be locally accessible to the client system for example in a persistent high capacity storage memory such as a hard drive and can accommodate a large number of responses. The local cache may utilize any conventional means of storage including on a filesystem in a database or a combination thereof.

Real requests may be performed before they are actually requested by the user so that their responses may be available for servicing virtual requests at any time such as while offline. One embodiment of the invention performs these real requests using a context that is separate and transparent from the user s such as with a crawler running hidden in the background. The crawler may be able to issue the same requests that a user may perform including those dynamically generated such as by JavaScript to ensure that their responses are available when actually requested by the user.

Embodiments of the invention may acquire content from the Internet for their caches by a number of different means. For example the cache may store any content specifically requested by a user it may automatically discover the content or even a combination of the two. A common approach to automatically discover content is through a process commonly known as crawling.

An aspect of the invention according to some embodiments is that it can populate the cache automatically deciding what content to store based on factors such as but not limited to user input directly or inferred through user behavior such as Favorites or History recent activity connectivity to servers freshness of particular URL content depth of crawling etc.

An aspect of the invention according to some embodiments is that it can populate its cache using different crawling approaches. For example conventional crawlers recursively look for documents and paths to traverse by issuing protocol level requests to the server and examining their responses such as searching for anchor tags in HTML response bodies or files and subdirectories in FTP SMB messages. As another example some more recent crawlers leverage user interface interaction such as clicking on regions in a graphical user interface GUI this crawling approach can support discovery and access to Internet content without explicit knowledge of the application logic since the server responses are not directly analyzed or interpreted. For example a crawler that programmatically controls a browser by clicking on display elements is capable of supporting dynamic content such as display changes or asynchronous requests driven by JavaScript.

Real requests may result from a number of different sources e.g. user or crawler and it may be desirable or even necessary to coordinate multiple real requests through a common session with the server such as when a server restricts against multiple concurrent client sessions. One embodiment of the invention coordinates real requests through the crawler as this has the advantage sharing a server session between user related activity and discovery related crawling.

Other embodiments may support different execution contexts for submitting requests to the server. For example there may be multiple crawler processes each capable of supporting concurrent requests to the same or different servers. As another example the execution context may simply be executing within the same process as the user such as a separately spawned background thread.

Referring now to at step Crawl Manager launches one or more instances of Crawler if necessary. The number of Crawler processes may depend on a number of different factors such as whether the server supports multiple concurrent sessions or based on the local computer s capacity e.g. limits resulting from memory CPU or OS .

At step Crawler Manager signals one or more instances of Crawler if necessary. Crawler may be waiting to be notified of more work such as after completing work from a previous phase.

At step Crawler processes one or more tasks in a loop until for example there is no more work. Crawler requests work by calling Cache at step . The task may describe the parameters necessary for Crawler to submit the request to the server and it may specify parameters on crawling such as the maximum recursion depth for paths extending from the current point.

At step Crawler determines whether it needs to first log into the server before processing the current request. This decision can be based on whether the request matches a configuration parameter indicating that a login is required. If so Crawler performs the login process in the UML frame Crawl Login .

At step Crawler determines how to process the request which may vary depending on its type. In general requests may be submitted via user interface interaction such as clicking elements on a web page or they may be submitted via the application level protocol such as an HTTP GET or POST. User interface interaction may be generally preferable for handling cases that may depend on application level processing such as executing JavaScript functions associated with a DOM element in a browser. Such cases may include submitting a pending HTML form or crawling dynamic web pages.

In the first case of if the request is a pending form submission then it may be submitted via user interface interaction with a browser which is described in UML frame Crawl Form .

In the second case of if the request is a protocol level request then it may be submitted via a protocol level API such as one provided by Browser Control . Such a request may include virtual requests for uncached resources and requests issued from non browser applications e.g. Microsoft Word . Handling of a protocol level request is described in UML frame Protocol Request .

Otherwise in the last case of the request is processed via user interface interaction with a browser which is described in UML frame Crawl Page .

When Crawler completes processing its tasks it may wait for additional work e.g. signaled by Crawl Manager or it may exit possibly after waiting for some minimum amount of time. If so Crawler notifies Crawl Manager at step either directly e.g. IPC or indirectly e.g. Crawl Manager watching process termination .

Some servers require authentication so a crawler may need to perform a login process before processing its tasks. Since the cache needs to be populated with content associated with particular users the crawler needs to issue requests while logged in as these users. Also since the crawler operates in the background transparently from the user the login process needs to be performed automatically without direct assistance from the user.

Referring now to Crawler first obtains the login information for the user from Cache at step which in turn obtains it from Database at step . This login information may include information about the process itself e.g. method of authentication and or URL of login page as well as the user s authentication data e.g. username password which may be stored previously such as when the user first configured caching for the current server application.

At step Crawler determines which method it uses for the login process depending on the login information returned from Cache at step .

In the first case of Crawler performs a form based login. This may include for example requesting the login form at step which is processed as any other protocol request as described in UML frame Protocol Request . When the login form has been loaded Browser notifies Crawler at step who can then proceed to setting the user s authentication data into the form s input fields at step . When the authentication data has been entered Crawler submits the login request at step via the user interface e.g. clicking a button to submit the form which may cause Browser to issue the request to the server. In other embodiments Crawler may submit the login request in any other manner such as via the protocol e.g. constructing an HTTP POST request from the form data . The request to the server is processed as any other protocol request as described in UML frame Protocol Request . When the response to the login request is received by Browser it notifies Crawler at step .

In the second case of Crawler performs a protocol level login. It is common for an Internet Services such as WinInet to handle protocol level authentication. So Crawler simply initializes WinInet with the necessary authentication data such as the username at step and password at step note that these calls are initially intercepted by WinInet Intercept at steps and respectively.

As described in i.e. UML frame Cache Request a request received by Cache from Crawler is processed as a real request which may be issued to the server. As another example a request from the user may also be processed as a real request such as when it cannot be handled using locally stored responses or the request mode is configured for synchronous operation.

Referring now to at step Cache constructs the lookup data for the request. This may involve inclusion of additional parameters into the lookup such as a current path from a session context or a particular cookie from an HTTP header. This may also involve a normalization of the request parameters to ensure that lookups for equivalent requests will yield the same response. This may further involve a restructuring or hashing of the request parameters into a smaller and or semantic structure such as to improve lookup efficiency.

At step Cache selects the appropriate handling for the request which may be based on whether it should be handled locally such as a query for locally pending write operation or by the server such as a refresh of a cache entry or a submission of a pending item.

In the first case of the request is for a local object e.g. pending write operation so it is handled locally since it is not known or visible to the server. In this case Cache retrieves it from Database at step .

In the second case of the request is for the server. At step Cache selects the appropriate handling for the request which may be based on factors such as whether it is a read or write operation.

In the first case of the request is processed as a read operation to the server. At step a currently cached response if any is looked in the Database . At step Cache determines whether it should still issue the request to the server such as if a cached response was not found at step or the cached response was determined to be possibly out of date e.g. Pragma No cache header present current time is later than Expires header . If so the request is prepared such as setting the HTTP If Modified Since header based on the response s cache modification time. When ready the request is processed by passing it to the server as described in UML frame Passthru Request . Upon return from Passthru Request the response is checked at step to see whether it should be saved to the cache such as when the response indicates a successful completion of the request. If so the response is stored to Database at step .

In the second case of the request is processed as a write operation to the server if writes are allowed. In general the write operation was previously queued such as when the user submits a form while offline and is submitted to the server by a Crawler context. However write operations are disabled in a Crawler context that is performing discovery e.g. describing UML frame Crawl Page to avoid inadvertently submitting write operations to the server while crawling a page. The request for the write operation is described in UML frame Submit Pending .

In the last case of the request cannot be processed such as a write operation requested when crawling a page. The request is gracefully terminated by returning a no op response at step such as an empty HTML document.

An aspect of the invention according to some embodiments is that they can control the crawling by affecting the response it returns to the crawler which may be different from that actually returned from the server. At step Cache may examine the response and determine that it should not be returned to the caller e.g. crawler . For example the content type of an HTTP response may not be natively supported by Browser and returning this response may cause an external application to be launched to handle it such as a PDF file that may be opened by an external PDF viewer like Acrobat Reader. To prevent this case Cache may set a no op response at step such as an empty HTML document.

Before returning the response for the second case of Cache may wake up any contexts at step that are waiting for the current real request to be processed such as a user s instance of Browser that issued a virtual request for a previously uncached response.

As another embodiment the request to the server may be issued by WinInet Intercept instead of by Cache as described in . For example Cache may complete CacheRequest see with an appropriate completion data code that provides an indication to WinInet Intercept that it should issue the request to the server. WinInet Intercept can readily use the API of WinInet that it is intercepting to send the request to the server instead of having it sent from Cache as described in Passthru Request . Upon receiving a response from the server WinInet Intercept would then provide the response data to Cache so that it may be saved for subsequent access.

It may be preferable to discover content to cache via user interface interaction so that application level processing can be supported such as executing JavaScript code on a web page. For example this approach supports web pages that are considered to be dynamic such as those using client side logic e.g. JavaScript application plugins etc. to affect its layout content in response to user actions e.g. expanding a multi level menu zooming moving a map hovering to show context specific balloons etc. often without requiring navigation to another page. Since these web pages are changing dynamically the server resources accessible by a page need to be discovered by performing the user interactions that trigger their access. The page elements that may interacted with through the user interface are considered here to be eventable elements since they are generally associated with user interface events e.g. click focus hover for example a web browser may allow a page element to register a handler function to be called when a user interface event is triggered on it.

At step Crawler initializes the application prior to accessing the page such as actions that help prepare the application for correct and efficient operation. For example it may be desirable to open a new window for the page to avoid changing the window context of the previous page before the current navigation. It may also be desirable to trap the registration of event handlers so that eventable elements can be easily found e.g. enabling the interception of calls to the IHTMLElement method attachEvent .

An aspect of the invention according to some embodiments is that dynamic components of a page may be efficiently refreshed by protocol level requests from the server when the page is unchanged a page may be considered unchanged when its components such as its supporting logic e.g. JavaScript are unchanged. This approach has the advantage of avoiding the delay associated with interacting with the user interface such as waiting for dynamic UI elements to be requested from the server and or rendered on the screen. The embodiments may track the relevant components loaded within the context of a page such as the JavaScript loaded statically via inclusion or dynamically via XMLHttpRequest by the page. In one embodiment Crawler calls WinInet Intercept at step to set the current page that contains the resources subsequently requested within the context of that page WinInet Intercept includes this container page as a parameter to some or all requests sent to Cache e.g. via a custom value in the Pragma header . As previously mentioned in UML frame Cache Request Cache can use this request parameter to associate resources as components contained within the specified page.

Crawler loads the page by calling Browser Control at step which in turn calls Browser to perform the navigation at step . When the navigation occurs the embodiment performs processing related to eventable elements UML frame Process Eventables see . Crawler waits for the page to be ready by calling Browser Control at step which in turn calls Browser at step to wait for the page such as waiting until page elements have been initialized.

At step Crawler decides whether it needs to crawl the page such as when the page has never been crawled before or if the page particularly dynamic logic such as included scripts has changed since it was last crawled. At step Crawler queries Cache for the relevant components that make up the page such as client side logic that is included by that page. In loop each of these page components are refreshed from the server via protocol requests which is described in UML frame Protocol Request . If any of the components are determined to have changed at step then the page is set to be recrawled at step .

At step if the page needs to be crawled then it is processed in UML frame Crawl Dynamic see . Since this is the starting point of the crawl for the current page the entire page will be crawled.

In loop Browser triggers the events resulting from an action by Crawler such as navigating to a new page or interacting with a currently loaded page. When a registered event is triggered Browser will call the associated handler.

In the first case of a navigation event is detected and trapped such as when Crawler is working on a currently loaded page and it wants to detect a transition to another page. Detecting page transitions enables Crawler to determine whether it should stop e.g. exceeds recursion depth proceed within the current browser context or queue the request as a task to perform later perhaps by separate instance of Crawler . When the navigation event is triggered Browser notifies Browser Control at step which in turns notifies Crawler at step .

At step Crawler decides whether the new page should be crawled such as when the navigation depth has not been exceeded. If Crawler decides to crawl the page it then decides at step whether it should handle the new page now concurrently in another browser tab window via UML frame Crawl Page see or it should defer its handling such as queuing it to Cache at step . Finally Crawler returns a response at step to indicate to the current browser context of Browser whether the page navigation should be canceled such as when since its handling was performed by or deferred to a different context.

In the second case of element initialization is detected and its event registration is trapped such as when Crawler is interacting with a page and it wants to detect event registration of any new elements that might be instantiated. An element on a page may dynamically register event handlers such as in response to an interaction by Crawler and these event handlers may not be readily found since Browser may not expose them e.g. Microsoft Internet Explorer does not provide a query for handlers registered through its proprietary IHTMLElement method attachEvent . To handle this case embodiments of the invention trap the registration of event handlers by page elements at step such as by overriding the element s event registration method so that it may detect these dynamically registered handlers such as by inserting a custom DOM attribute into the element. This allows the embodiments to search for any eventable element regardless of whether it is uses a visible event handler e.g. searching DOM for onclick handler or one that is not readily visible e.g. searching for custom attribute inserted when attachEvent is called .

The following is an HTML Component for Internet Explorer e.g. installed via CSS behaviors that traps the registration of event handlers via IHTMLElement s attachEvent method 

In loop Crawler may call Browser Control to search for elements according to one or more parameters such as those with certain tags and or certain attributes. For example embodiments of the invention may search for HTML elements with certain tag names or attributes such as those with event handlers registered via the DOM e.g. onclick onmouseover any with certain custom attributes e.g. mobo attribute inserted by an embodiment to mark handlers registered through browser proprietary methods and any with tags matching a configuration parameter e.g. A DIV etc. . These eventable elements are added to a list for subsequent processing at step .

Prior to triggering the events on the eventable elements Crawler traps navigation to a new page which may result when triggering an event. This allows Crawler to be called so that it can for example limit crawling to a particular navigation depth or process the new page in a new concurrent browser window. For example Crawler can trap navigation by registering a pre navigation handler e.g. via Internet Explorer s DWebBrowserEvents2 s BeforeNavigate2 event callback allowing it to selectively block requests for write operations or limit the navigation depth.

In loop Crawler triggers each of the events on each of the eventable elements that were previous found. The events are triggered by calling Browser to fire the event i.e. as if the user had performed the associated action at step which in turns triggers the event within Browser . Triggering events may cause changes in the browser state such as navigation to a new page or loading new dynamic elements on the current page and the handling of these are described in UML frame Process Eventables .

Crawler calls Browser Control to wait for the page to be ready at step which in turn waits on Browser at step . At step current page is compared to its state prior to triggering the event at step to see whether it may have changed the page e.g. created new actionable elements .

If there are any changes resulting from then Crawler processes them in UML frame Crawl Dynamic see which may preferably be performed via recursion on just the differences that were found. When the crawling of these changes is completed the page is restored to the state prior to the click performed at step so that the next event may be cleanly processed upon the next iteration of loop .

In addition to discovering content based on the clickability of an element the invention according to some embodiments may also examine other content information to control its crawling behavior such as to increase or decrease the scope of the crawling activity.

It may be desirable to retrieve different responses for a variable request such as an HTML form so that they may be cached for offline or accelerated access. For example a web page may provide an HTML form for generating reports using various input fields. These input fields may allow free form user input such as a text field which may require field validation by the server or they may have fixed inputs such as provided by HTML select menus radio buttons or checkboxes.

For the fixed input fields the embodiments can be configured to iterate through one or more of the possible options so that these variations are cached if when the user attempts to access them. The fixed input fields may be selected via user interface interactions e.g. clicking or by modifying the form document content e.g. setting the selected checked attribute of an HTML element or setting the input fields within the POST request corresponding to the submitted form .

For the free from input fields the embodiments can determine an appropriate set of possible inputs such as looked up from an internal database of possible inputs that are chosen based on a criteria that may include information about the form e.g. URL form element ID etc. and or the input field e.g. type name input element ID etc. . For example the embodiments can be seeded with one or more sets of input fields for a specific report generation form and each of these input sets are submitted to cache the desired reports.

It may be desirable to limit the content that may be retrieved from the server such as to avoid caching content that is unlikely to be interesting to the user. For example a web page may provide a calendar that allows navigation to any day of any year. However it may be desirable to restrict crawling through dates beyond a certain range such as more than a few months prior to the current date to avoid the associated cost e.g. processing time storage utilization bandwidth consumption etc. of retrieving that content.

Embodiments of the invention may apply a filter on the content it will crawl such as filtering out eventable elements prior to clicking on them at step of . This filter is logically applied to the identifying information for the element such as based on the URL stored in href attribute of an HTML anchor tag or a particular form input field for elements associated with application logic such as JavaScript the embodiments may trap the request resulting from user interface interaction on the element preventing any requests that are disallowed by the filter. For example the Microsoft Sharepoint web application provides a calendar that is accessed through JavaScript enabled buttons associated with each day month or year. The embodiments can filter out undesirable date ranges by examining the date encoded within URL of the HTTP GET requests that result from clicking on the various date buttons. This filtering approach can apply to any portion of the request including the request headers and the request body e.g. HTTP POST .

An aspect of the invention according to some embodiments is that write operations can be supported even if the Client is offline by pending them such as in a queue and deferring their submission to the server until some other time such as when connectivity is restored. As with requests for read operations requests for write operations are pended by intercepting them when they are issued. A write operation can include any operation that will result in a change in content on the server such as creating modifying or deleting content. After the write operation is requested and stored but before it is sent to the server it is considered to be pending. 

There are different ways to intercept a client request for a write operation to a server. For example the request can be intercepted from within the client application such as capturing the HTML form input fields within a web browser or the request can be intercepted at the protocol layer such as capturing the HTTP POST request intended for the web server.

It may be desirable to intercept a write operation from within the client application such as when a write operation may logically consist of one or more protocol level requests. A write operation may be intercepted from within the client application using different mechanisms depending on the application and operation. For example a web browser may perform different types of write operations such as submitting an HTML form or copying a folder to an FTP site. A general approach for intercepting a write operation from a client application is to detect the write operation at an appropriate point prior to the issuance of its associated protocol level requests where the necessary parameters of the operation can then be captured. The write operation can subsequently be submitted to the server by logically replaying the application level write operation such as submitting an HTML form that has been populated with the recorded user input.

Another embodiment for intercepting a request is to utilize the Document Object Model DOM support in the browser which provides an API to access and manipulate a browser document. In this case the DOM of the form could be updated so that a handler function is called when the submit button on the form is clicked such as by registering a handler for the onclick or onsubmit events associated with the form. The handler function could then capture the form submission store it and send it to the server later to apply the write operation.

If the inspection determines that the request is for a write operation then it is intercepted so that it may be processed even if the server is unavailable. In this embodiment the form content which can be HTML is constructed by browser plug in containing the user input inline in the form. The form HTML and form location URL are then passed down into Cache so that the form can be retrieved later when it is actually submitted to the server. In other embodiments the form submission may be intercepted at the protocol level such as capturing the HTTP POST request that would result from this form submission. Intercepting the form and its data has the advantage that it allows the form submission to be fully recreated as if the user actually submitted later for example this can accommodate content that uses scripting languages such as JavaScript that may perform multiple HTTP requests and or it may avoid submitting form information to the server that may be stale.

After cache processes the submission it returns a response to the browser plug in which simulates a successful response from the server. The browser plug in then renders the response in the browser. This allows the client application to behave as if the request was processed by the server even though it was intercepted. In order to indicate to the web browser that the browser event handler intercepted the navigation and that the browser should not still perform it the cancel output parameter to DWebBrowserEvents2 BeforeNavigate2 is set to true. 

When the intercepted request is sent to the Cache it is first authenticated . In this embodiment the system is integrated with a read cache that is capable of managing authenticated user sessions. This means that the user can authenticate to the read cache as if they were authenticating to the server. The session may be authenticated in several ways including using credentials available in the HTTP headers passed in by Intercept or using HTTP session cookies. In another embodiment the read cache could be an independent system and the authentication of the user session could involve calling an API that the read cache provides that can verify the current user session. Yet another embodiment could involve using an independent password management system that could be configured with credentials used to control access to the system so that offline requests are authenticated.

Cache may perform any necessary processing on the input and then retrieve the URLs that are dependent on the write operation. A dependent URL is an URL to any content that is affected by the write operation that is being requested. When this system is used with a read cache the dependent URLs in the read cache need to be invalidated meaning that they should indicate that their information is out of date. In this embodiment the read cache shares a database with the system and so the dependent URLs can be invalidated when the system stores the list of dependent URLs in the database . In another embodiment the content in the read cache may not necessarily be web content and so may not necessarily be identified by an URL. Any suitable method for identifying and referencing information could be used for instance a path to a file on the local file system.

The write operation and other related information that is captured is stored in some persistent storage such as a database a filesystem or some combination thereof. By storing the operation the system ensures that the operation can be performed on the server later without losing any information that the user entered. For example if the server is not available because the client is not connected to a network the operation can be saved and retrieved later when the client does have connectivity to the server and perform the operation at the server. The database returns an identifier such as a request ID a name or a GUID that identifies the operation that it just saved. In other embodiments the write operation information can be stored in different ways such as in files on the file system or a combination of files and entries in a database that store the path to the files that contain the request operation information.

After saving the operation cache submits the request to a crawler . In this embodiment the crawler is responsible for sending the request to the server. Separating the communication with the server through the crawler has the advantage of allowing the system to wait for a response from the server so that it appears to communicate synchronously or run in an accelerated mode where it does not wait for a response from the server and instead constructs a response to return to the client immediately.

Cache next queries the database for a response associated with the request ID. In this embodiment the crawler and cache share a common database. In another embodiment where the crawler is separate from the cache the cache might have to retrieve the response from the crawler in a different way such as making an API call to the crawler or retrieving a file in a directory where the crawler writes response data.

If a response is not found in the database then a response may be manufactured to be sent back to the client. There are several reasons why a response might not be in the database for example if the crawler was not able to communicate with the server or if the server took too long to respond to the request from the crawler. The response is then returned to Intercept and then returned to the browser plug in to render .

In order to facilitate working with the HTML input in this embodiment cache uses the DOM API to construct a DOM object from the HTML of the form that it was given as input. This allows cache to do tasks like enumerating the elements in the HTML document using the DOM API. Cache then loops over elements in the document and determines if an element contains identifying information about the operation. A configuration parameter can be used for this determination. It can perform a pattern match on the URL of the submitted form and identify the name or ID of elements that are known to contain identifying information for the given form. This identifying information can be used by systems where information about the pending write operation is presented to the user such as when the read cache gets a request for content that would be affected by the write operation. This has a few advantages including allowing a viewer of the affected content to know that it may be out of date and allowing content to be updated and refreshed at the server independently.

Next there is handling for HTML elements of type file. A copy of the file is taken by creating a temporary directory and copying the file to that temporary directory. The advantage of handling the file in this manner is that it allows the system to take a snapshot of the file at the time of the request which allows the user to then operate on their local copy of the file as if it is a different version from the one submitted. The value of the HTML element is then updated so that instead of referencing the file in its original location it will reference the file that was copied to the temporary directory. This effectively branches a different version of the file that will be submitted to the server later. In another embodiment the file can be captured and stored in some other storage such as a database.

If there is any application specific logic configured for the URL of the form then it is called which allows any custom logic to be performed for example to handle input of a type other than HTML.

First the cache checks a configuration parameter that indicates if the response to the request could have been stored by the read cache. This is possible for certain types of requests that are idempotent and can return a cached response value for the given request. The database is then queried to see if the request had ever been made previously and the read cache had already stored a response.

If a response is still not found then a response is manufactured. In this embodiment the manufacturing process can use common information for the response such as in a template file and information from the current write operation can be substituted into the response template as necessary.

A configuration parameter can be used to find a response template that is appropriate for the location URL of the form being processed. The template can specify portions that need to be filled in with information from the request. For example this can be necessary in the case where a request specifies a name of a file to operate on and the response includes the filename to indicate it was operated on. Finally if any application specific logic needs to be executed a configuration parameter can be set that lets the cache execute any custom logic that may be needed to properly manufacture the response data.

It may be desirable to intercept write operations at the protocol level such as to support the interception of similar operations from different applications. For example many application level protocols such as Web based Distributed Authoring and Versioning WebDAV and the Microsoft FrontPage Server Extensions RPC protocol are commonly implemented as HTTP requests. In these cases the system can intercept the request at the protocol level e.g. HTTP and determine if the request is a write operation by inspecting the parameters such as the method e.g. POST PROPPATCH etc. and or request body contents of an HTTP request.

After this information about the request including identifying information list of dependent URLs and username is stored at the database and assigned a request ID. The request information is stored so it can be sent to the server later the identifying information is stored to show what write operations are pending to the server the dependent URLs are stored to be invalidated to indicate that they are out of date because of the write operation and the username is stored so that in a multi user environment write operations can be sent to the server using the appropriate set of credentials. In other embodiments the write operation information can be stored in different ways such as in files on the file system or a combination of files and entries in a database that store the path to the files that contain the request operation information.

Cache then submits the request to a crawler that is responsible for sending the request to the server. In this embodiment the crawler shares a common database so the cache can signal the crawler that there is work to submit for a given URL and username and the crawler can find the request in the database to submit. In another embodiment the crawler may be a separate system and the cache may need to submit work in a different way for example using an API that the crawler system makes available.

Cache next queries the database for a response associated with the request ID. In this embodiment the crawler and cache share a common database and so the crawler can store the response it received from the server in the database associated with the given request ID. In another embodiment where the crawler is separate from the cache the cache might have to retrieve the response from the crawler in a different way such as making an API call to the crawler or retrieving a file in a directory where the crawler writes response data.

If a response is not found in the database then a response is manufactured to be sent back to the client. There are several reasons why a response might not be in the database for example if the crawler was not able to communicate with the server or if the server took too long to respond to the request from the crawler. Finally if any application specific logic is configured for the request then a call is made to the application extender. There any custom logic can be executed to perform any necessary changes to the response.

A pending write operation can be submitted to the server later such as when the server becomes accessible such as when network connectivity to it is restored. In some embodiments a pending write operation can be submitted to the server on some scheduled interval such as attempting communication to the server every hour. In other embodiments a pending write operation would be submitted to the server when a user manually commands the system to communicate with the server.

As with read requests to the server pending writes may be handled in a separate execution context from that of the user since a user context may not be available at that time such as when the user has already terminated her browser process. The execution context that submits a pending write i.e. issues its associated requests to the server may be provided by any conventional means. For example a background process can be spawned or signaled when a pending write exists and connectivity with its associated server is restored. The execution context may submit the pending write operation as if the user had actually submitted it so that the delayed submission may be handled by the server equivalently to the user actually submitting it to the server herself. Since an embodiment provides for a crawler to handle real requests for read operations the crawler context may be leveraged to handle the real requests for pending write operations.

Referring now to in this embodiment the request ID is passed to the cache by appending it to the request URL. In other embodiments the request ID can be passed using different methods such as through a request header or a hidden input field added to the request body. Cache removes the request ID from the URL and saves it. At this point the write operation is sent as a pass through request see to the server.

After cache receives the response from the server it stores it in the database associated with the request ID. In this embodiment as illustrated in step in and step in when the write operation is submitted the cache can be configured to retrieve the response from the database after submitting the request to the crawler. This allows the flexibility of either accessing the server asynchronously or in a mode that appears synchronous to the client.

In this embodiment an integrated read cache contains content that was invalidated as a result of the write operation being requested as in step in and step in . At that time the content was invalidated so that when it is requested from the read cache an indication can be given that the contents may be out of date.

After the write operation is sent to the server the invalidated content can be refreshed in the read cache from the server so that its content is brought up to date to reflect the write operation being performed. In this embodiment the read cache shares a database with the system and so the system can specify through the database that the invalidated content can now be refreshed. In another embodiment where the read cache is a separate system the system may indicate to the read cache that it needs to refresh the URLs via an API that the read cache makes available or by deleting the content from the read cache forcing the read cache to retrieve a new copy of the content.

After the write operation is successfully sent to the server cache is able to perform any clean up necessary.

An aspect of the invention according to some embodiments is allowing access to write operations while they are pending that is after the user has submitted the write operation but before it is submitted to the server. This allows the pending write operation to be displayed on any dependent page that would be affected by the pending write operation. This also allows the user the ability to update or delete the write operation before it is submitted to the server allowing the user to access their content at any time after they submitted the write operation.

An embodiment makes use of a common caching layer to provide local storage for content associated with both read and write operations. When the write operation is intercepted by the system a list of dependent URLs was generated and invalidated as in step in and step in . When one of these invalidated URLs is requested from the read cache an indication is shown that presents information about the pending write operation.

Referring now to Cache first retrieves any dependent pending information associated with the URL of the document that is being requested. This is the identifying information about the write operations that are pending that has invalidated the URL that is being requested for example the name of a file that is pending to be uploaded to the server.

Cache retrieves a template for formatting the identifying information for the given URL of the invalidated content. Cache may use a configuration parameter that specifies the template to use for a given URL. Next cache retrieves script code that can run in the client application to perform the actual injection of the identifying information into the invalidated content. Using script code that runs in the client application provides the advantage of allowing the script code to use any APIs or facilities that the client application has natively available to it such as the DOM API available within a web browser.

The content can be formatted in any manner that can allow it to be displayed to the user such as using HTML rendered in a web browser. In order to perform this injection an HTML block is constructed that contains the identifying information the template for formatting the information and the script code for injecting the information. For example the block could be made up of JavaScript code that contains a string that was defined by the template and an HTML formatted unordered list of list items that contains the identifying information retrieved in step .

Once this HTML block is constructed it can be added 2110 to the HTML block of the invalidated content. When the browser loads the HTML document it will execute the JavaScript embedded in the block which can update the DOM and add the template formatted content in some appropriate place for example as additional table data in a table row appended to an existing table in the document.

The information about pending write operations may also be rendered by any other arbitrary application and or displayed in any other way. For example shows a UML sequence diagram for an embodiment where pending information is displayed using a toolbar in the web browser. In this embodiment the toolbar which can be implemented as a browser plug in can query U see for pending information. In this embodiment when the list of pending information is returned and the plug in is free to format and display the information in whatever form it chooses. Returning the information as an unformatted list of information allows the system to keep the data separate from any display or rendering concerns.

Referring now to when cache receives the request for pending information it can be given an URL to invalidated content. In this embodiment the URL is not a mandatory parameter such as when querying for all pending write operations in the system.

If the optional URL is given then cache checks the current session for the user that is logged in to that URL. In this embodiment the read cache is able to manage authenticated sessions which allows the system the ability to securely serve content specifically associated with a given user. The user information may be determined using credentials available in the HTTP headers passed in by Intercept or using HTTP session cookies.

The database is then queried for the request IDs of write operations that affect the given invalidated URL submitted by the given user. With this list of request IDs cache then loops to retrieve the identifying information that was saved for the write operations as in step in and step in . The invalidated content can now be fixed up to include the identifying information about the write operations that have affected it.

When the write operation is pending it can be updated or deleted before it is sent to the server. Updating the operation involves displaying the submitted form with the information that the user entered at the time they originally submitted the write operation allowing the user to change any information that they entered. Deleting the write operation involves identifying the operation and removing it from the system so that it will not be sent to the server and will not invalidate its dependent content anymore.

In this embodiment the HTML of the form with the user input entered inline was stored in the database in step in . Therefore it will be available to be displayed to the user if they choose to update the operation. An example of this use case could be when a user views invalidated content and from the identifying information displayed about a pending write operation determines that the information entered was incorrect. They could then choose to update the write operation.

When the form with the user information inline is presented to the user in this embodiment it is assigned a URL that contains the request ID of the original write operation that was associated with the write operation. When the user decides to submit the form again in step of cache can determine from the URL that the request is for an update . In other embodiments different methods can be used to associate the update with the request ID of the write operation to update for example using an HTTP header or a hidden input field in the form that contains the request ID.

If the user decides to delete the pending write operation they can do so through a similar mechanism. In this embodiment a URL is assigned that contains the request ID of the write operation to delete. If the user makes a request to that URL in step of cache can determine from the URL that the request is for a delete . Again other embodiments could be used to associate the delete request with the request ID to operate on as above.

A system and method of seamless network caching of server content and services has been described. By caching the responses of server requests both as they occur and in anticipation of future same or related requests as well as providing for asynchronous write support embodiments of the present invention provide seamless caching of the server using a thin client architecture. That is such an approach does not require client side replication of server logic or data. In this way the client can be agnostic to the application being cached with the user experiencing performance as if the server content and services were accessible locally even when connectivity to the server is interrupted. In addition the applications do not have to be modified to enable this capability e.g. it is not necessary to rewrite to custom API s . To the client the caching takes place as if it is communicating directly with the server.

There are many different ways such a system or method can be realized to provide the aforementioned benefits such as within the client the application server or some other device or system. For example the described system or method can be embedded within a nearby networked device such as a cellular modem or router to provide disconnected or accelerated application operation. As another example the described system or method can be hosted within any intermediate systems that are logically connected between the client and server such as on servers deployed by internet service providers ISPs to increase performance and or reduce bandwidth utilization.

It is noteworthy that although the foregoing examples have been shown with respect to specific Internet applications and protocols the present invention is not limited to these Internet applications or protocols. Other current and future Internet or other network applications or protocols can use the foregoing adaptive aspects.

Although the present invention has been described with reference to specific embodiments these embodiments are illustrative only and not limiting. Many other applications and embodiments of the present invention will be apparent in light of this disclosure and the following claims.

