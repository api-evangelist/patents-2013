---

title: Chaining image-processing functions on a SIMD processor
abstract: In a single-instruction-multiple-data (SIMD) processor having multiple lanes, and local memory dedicated to each lane, a method of processing an image is disclosed. The method comprises mapping consecutive rasters of the image to consecutive lanes such that groups of consecutive rasters form image strips, and vertical stacks of strips comprise strip columns. Local memory allocates memory to the image strips. A sequence of functions is processed for execution on the SIMD processor in a pipeline implementation, such that the pipeline loops over portions of the image in multiple iterations, and intermediate data processed during the functions is stored in the local memory. Data associated with the image is traversed by first processing image strips from top to bottom in a left-most strip column, then progressing to each adjacent unprocessed strip column.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08786614&OS=08786614&RS=08786614
owner: Calos Fund Limited Liability Company
number: 08786614
owner_city: Dover
owner_country: US
publication_date: 20130502
---
This application is a continuation of U.S. patent application Ser. No. 12 687 010 filed Jan. 13 2010 entitled METHOD FOR CHAINING IMAGE PROCESSING FUNCTIONS ON A SIMD PROCESSOR which claims benefit of priority to Provisional U.S. Patent Application No. 61 144 700 filed Jan. 14 2009 entitled METHOD FOR CHAINING IMAGE PROCESSING FUNCTIONS ON A SIMD PROCESSOR. The aforementioned priority applications are hereby incorporated by reference in their entireties.

The disclosure herein relates to methods and apparatus for parallel processing and more particularly image processing methods for single instruction multiple data SIMD processing environments.

An image processing function or kernel that implements a point operation on an image can be easily mapped to a SIMD processor and efficiently chained. This is because the order of the pixels presented to each SIMD processor is unimportant since each result pixel only depends on one source pixel.

Many image processing kernel functions however determine neighboring context to generate an output pixel value. To calculate the new value of a pixel the kernel often reads surrounding pixel values. Many ways exist to map such kernels to a SIMD processor where each mapping uses a different partitioning of data among the SIMD processing lanes or traverses the data in a different order. Usually performance optimized mappings vary based on the underlying algorithms being implemented which is partly why such a diversity of implementation strategies abound. Because of these differences image processing kernels cannot be guaranteed to easily chain together without glue logic that transposes data between SIMD processing lanes or via an extra global memory transfer. This both reduces performance and lowers productivity.

While existing solutions allegedly work adequately for their intended applications they are often inflexible in accommodating a large set of image processing algorithms especially when little to no loss of performance is desired. Thus improved mapping methods and apparatuses for image processing in SIMD processors are described herein.

Embodiments described herein provide a system and a method for implementing image processing functions on SIMD processors that allows for straightforward and high performance chaining of consecutive processing functions. A method such as described called raster per lane RPL achieves its results by precisely constraining both the data partitioning among SIMD processors and the data traversal order. Advantages of certain embodiments of this method may include 1 functions can be chained together to process images without intermediate trips to external memory or glue logic to reorganize intermediate pixel data thereby improving performance and 2 each function can be implemented separately possibly by independent parties in a modular fashion and then combined easily.

A SIMD architecture typically consists of multiple processing lanes that all execute the same operations but on different data. Throughout this document including any code listings N or NUM LANES refers to the number of lanes. The lanes each have a fast local private memory and all the lanes share an interface to a slower global memory. Typically the private memory is on chip SRAM e.g. on the order of 16 KB per lane and the global memory is off chip DRAM on the order of 1 GB shared by all of the lanes . DMA engines often manage transfers to and from global memory. An example of a SIMD architecture is the stream architecture.

SIMD processors execute functions known as kernels. Each kernel implements an image processing algorithm such as pixel color conversion scaling or filtering. Its arguments include scalars as well as streams which are designations of pre allocated regions of local private memory where input data can be read and output data can be written by each SIMD lane.

A sequence of kernels that process input image s to generate output image s is known as a kernel processing graph or simply kernel graph . Generally the outputs of one kernel will directly feed the inputs of another. There can be diverging and merging dataflows between kernels. Also kernels may have multiple inputs and or outputs.

A kernel graph may be implemented as a pipeline where chained kernels usually pass data through streams allocated in on chip local memory. Since only a portion of an input image resides in local memory pipelines typically loop over an input image processing a bit of the image during each iteration of the loop. An iteration typically transfers data from external memory to local memory calls each kernel in the pipeline then passes data back from local to external memory. Basically a pipeline implements a portion of a kernel graph in an optimized fashion where the source originates in global memory and the output is stored back to global memory but all intermediate data is stored in local memory.

Often especially in embedded computer systems an entire image cannot fit into the available global memory for instance in imaging applications that process 8 inch by 11 inch or larger pages that are sampled at 1200 dots per inch dpi in color. These images are processing incrementally with a portion of the image in a memory buffer at any given time. Usually the image is processed in sections from top to bottom. Each section is referred to as an incremental buffer and contains some number of lines of the image with the exact number dependent on the amount of available memory and the type of processing required.

Throughout the disclosure herein two types of code are shown in various examples control code and kernel code. The control code runs on a scalar processor that is responsible for coarse grain control of the SIMD lanes and of the DMA engines. Often this can just be the first SIMD processor depending on the exact architecture. Kernel code on the other hand is executed in lockstep across all SIMD lanes in parallel with the exact same code running on each lane but with different data. The disclosure herein presents control code in C language syntax with an extension for the stream datatype as provided in the StreamC language syntax. Note allocation for stream data in local memory may be performed statically for optimal performance however for simplicity this disclosure assumes that stream data are allocated dynamically. Kernel code is presented completely in the StreamC language syntax. Additionally all kernel code is contained in functions declared with the kernel keyword.

The raster per lane method described herein maps consecutive lines or rasters of an image to each of N parallel processor lanes. With reference to a group of N consecutive lines forms an image strip . An image strip or simply strip is an area of image pixels with a height equal to N and a width which is less than or equal to the width of the image. Importantly a strip resides in local on chip memory. Within a kernel function each lane reads and writes pixels from the line in their private memory. The entire strip is processed in parallel from left to right.

Referring now to a strip column consists of a vertical stack of strips usually equal to the height of the image. If the width of a strip is narrower than the width of the image then the full set of strip columns will completely cover the image with a small amount of horizontal overlap at interior edges. The data traversal order in the RPL method is to process the strips in a strip column from top to bottom and then the strip columns from left to right.

A programmer can use the following APIs to implement the RPL data partitioning and RPL data traversal order for their kernel functions and pipelines.

To access neighboring vertical context in an image a row tap function may be used from within a kernel. Exemplary code is shown below 

The code above relates to an example for a 3 high filter. Generating APIs for filters of other sizes is relatively straightforward. The row tap3 init controls inline kernel is called once before entering the main kernel loop. The function initializes a pair of control structures that are used with the function row tap3 get taps to extract the vertical context needed by each lane from vectors read from the current and previous strips. The controls take into account where the strips are in the overall frame so that the top and bottom edges are handled properly.

A kernel state t API provides access to the parameters and storage that is specific to a kernel. Code for an exemplary datatype is shown below for a kernel that processes data from a single input image and produces data for a single output image requires less than NUM LANES of vertical context and has no other input requirements such as look up tables or programmable filter coefficients. More complex kernels may seek additional private data and should use a datatype similar to kernel state t but customized for that particular kernel.

The fields in kernel state t allow the user to access a satisfactory amount of vertical and horizontal context. The datatype also holds a reference to the history strip used by the kernel to maintain vertical context from one strip to the next. The two additional fields provide a place to save this history buffer between pipeline calls when processing incremental buffers. The exemplary code reads 

The API also provides a strip t datatype that represents an image strip in local memory. Associated functions are used to load data from global memory into the local memory and to store it back out to global memory. Kernel interfaces also operate on strips and produce strips. Each strip has a scalar line0 argument associated with it which is the y position of the strip in some overall frame. It also holds the height of this frame in its lines parameter. The height of the strip itself is always fixed at NUM LANES. It is ok for strips to have negative line0s as well as line0s larger than lines. A negative value for line0 means that the top line of the input stream aligns above the upper boundary of the image. All the horizontal offsets and widths for the strip are isolated in the column element. Exemplary code reads 

A strip column t datatype is provided in the API to hold the data describing the horizontal offsets and widths for a vertical stack of strips in an image. The functions that operate on this datatype provide access to key DMA load and store parameters for every strip within this column i.e. load width load offset etc. . Additionally the strip column next function should be called after processing each column as it updates the fields within the strip column t data structure with the necessary parameters for the next column to process. For convenience a pointer to a common strip column t is shared by the strips. As an example relevant code may read 

An image t datatype keeps track of various useful parameters for a buffer in global memory that contains image data. With reference to it contains the dimensions of the active image area how the image data is organized in the memory buffer height width and stride and as shown in if processing incremental buffers it also contains the incremental buffer s position within the larger image or frame . Relevant coding examples may read 

The following pipeline example uses the above APIs to chain together two kernel functions to operate on an entire image where the intermediate data produced by the first kernel foo is consumed directly by the second kernel bar without being saved in global memory.

Referring to the lines of code above the kernel state API is used in lines 11 15 to compute the overall pipeline vertical and horizontal context requirements by summing the contributions from each kernel. Lines 17 21 compute a new strip column using the computed horizontal overlap requirement context width strip width max and the image width. The next 3 statements extract the frame height lines the starting line number of the image buffer line0 and the main loop termination limit line1 given the overall vertical context required by the pipeline context height . The next statement allocates a new tmp strip which will serve as the common input output strip for the kernels. The next 2 statements allocate and set private history strips for the two kernels. The outer while loop is executed once for each column. The last statement of this loop is the required strip column next call. The inner for loop gets called for each strip in the column. The strip load call initializes the tmp strip with the image data for the current source column strip. Each of the kernel calls uses this tmp strip as both the source and destination strip in practical implementations multiple strips are often used to increase parallelism between loads from global memory stores to global memory and kernel processing . The vertical line0 associated with tmp strip is updated by each kernel based on the delay being introduced. When the tmp strip is stored this internal line0 is used to position the strip in the output image. The private management of each kernel s history strip is carried on inside the foo function or bar function functions.

Note that in the pipeline described above all transfers with global memory and all processing steps are in units of strips. In contrast within a kernel function all accesses and processing steps are in units of pixels.

As alluded to earlier strips are the unit of processing with kernels accepting source strip s in local memory and then producing new destination strip s of the same size in local memory. In other embodiments kernels may be provided that perform arbitrary scaling and controlled handling to ensure that the input and output are quantized to units of strips.

As additional kernels are chained together in longer pipelines more local memory is allocated to maintaining vertical context strips for each kernel. This reduces the maximum strip width that can be processed.

When the maximum strip width is less than the image width the image is broken up into multiple overlapping columns of strips. The pipeline is run on all of the strips in the first column restarted at the top of the next column and so on until all of the columns are processed.

The strip column API isolates the computations involved in producing slightly overlapping strip columns. The function strip column new takes the image width in words the maximum strip width manageable and the total edge context words needed and produces a strip column record with all the horizontal sizes and offsets needed by the kernels loads and stores.

The left edge of the first strip column and the right edge of the last column will be handled correctly because each kernel assumes the left edge of each strip aligns with the left edge of the image and similarly for the right edge. However this also means that a few of the pixels at the interior strip edges may be incorrect. The strip column API accounts for this and will setup the store parameters to only store the valid set of pixels back to global memory. For example one embodiment includes generating pixels outside the left and right image boundaries by requiring kernels to assign an input line as the full width of the image and loading extra horizontal context for internal vertical edges and selectively storing valid data back to a global memory.

Each kernel operates to avoid introducing any horizontal phase error and except for scaling produces the same size strip as the source. The vertical phase shift introduced by each kernel is recorded by each kernel in the output strip line0. This line0 along with the horizontal offsets and sizes of the strip s column data are used by the store at the end of the chained kernels to position the output strip correctly in the output image.

The foo function and bar function that are used above are wrappers around the actual kernel code. They are used to simplify the pipeline code and to emphasize the modularity of the chained kernels. In the example implementation of foo function below the strip and kernel state APIs are used to extract the more primitive arguments used directly by the actual kernel. Many kernels will require a more complex datatype than kernel state t in order to manage additional private state such as tables etc. . Examples are provided below 

Although individual kernels may have additional arguments specific to their function the nominal kernel interface used above may be illustrated by the following 

In general all streams are typically accessed in a sequential fashion. Often when used in a pipeline the argument provided to prv stm and nxt stm will be the same stream and the argument provided to src stm and dst stm will be the same stream. In this way chained kernels in a pipeline seem to progressively transform the same area of local memory while rotating a delayed version of the source stream through their private history buffers. However note there is a tradeoff between sharing strip allocations in local memory versus parallelism of DMA transfers and kernel execution.

Kernels with the exception of slave kernels maintain any additional required vertical context by making copies of the source strip in local memory for use in the next call. So typically each processor will have convenient access to a vertical context of N previous scan lines by accessing data in either the current or previous strip in its own or a peer s local memory. More complex kernels may require more than one previous history strip. By making kernels responsible for providing their own additional vertical context it becomes much easier to swap kernels in and out of pipelines with little effect on other kernels.

As an example and referring now to for each source strip loaded such as at each chained kernel is called once at . Kernel K produces a y delayed destination strip at and copies the current source strip to its next output at . This will become the previous K source strip the next time K is called. Kernel K s destination strip becomes the current source strip for the chained K kernel which is called next at .

Generally speaking each kernel will introduce some minimum vertical phase delay. Referring to a 3 3 filter uses the current scan line at with two previous lines at and producing an output scan line at that is centered on the previous scan line. So the minimum vertical phase delay is 1. The output strip for this filter will have a line0 associated with it that is one less than the source strip s line0 value. When the next kernel in the chain reads this strip this new value of line0 will be provided.

The following example of a kernel implementing a 3 3 filter illustrates use of the row tap API described earlier to simplify accessing the vertical filter taps.

The initialization inline kernel row tap3 init controls specified in the exemplary code above is called once on entry and uses offset line0 and lines to compute 2 control structures ctl0 and ctl1. Each control structure has 3 elements corresponding to the 3 vertical taps. Each control tap is actually a vector of N values. These control taps incorporate all the special top and bottom effects. That is offset line0 and lines are not used anywhere else in the kernel.

Once the control structures have been initialized they can be used by the row tap3 get taps inline kernel shown in the code above to extract a set to taps from vertical context of 2 N lines represented by prv stm and cur stm. In this case get taps is called once before the loop and then once for each loop cycle. Since row tap3 get taps just returns the taps it is also generic and may be used by any 3 high filter. The row tap api includes these inline kernels for all odd sizes from 3 to N 1. The particular weighting function specific to this kernel is isolated in two inline calls 

The number of get taps necessary in the preamble before the loop and therefore the number of replication steps in the section after the loop is a function of how many taps are used by the filter and whether pixels are planar or pixel packed. The next history stream nxt stm is updated every time the source cur stm is read.

The row tap API assumes that the behavior beyond the top and bottom image edges is to replicate the boundary pixels. Since kernels are provided with the vertical position for their source strips as well as the number of scan lines in the overall frame they can properly handle required neighbors that are above or below the image boundary for instance replicated data from the top or bottom scan line or generating pixels outside the top and bottom image boundaries within kernel functions by passing the current line number and the total number of lines in the image to the kernel.

Kernels are written such that they process their strips as if the strip represented the full width of the image even though this is often not the case. This usually means the source data is internally replicated by the kernel at the beginning and end of the processing call to fill in missing context at the edges. This strategy removes the necessity of communicating and implementing different edge cases to the kernel with very little additional processing cost. In the example this is implemented in lines 38 and 58. This behavior can readily be changed by modifying for instance if a constant pixel color is required outside image boundaries.

The kernel produces a strip with a width that is equal to the source by reading ahead one word and replicating it for the initial left horizontal context. The loop then produces all but the last result. The last output is produced after replicating the last horizontal context result.

Full width processing of partial width strips is handled such that no horizontal phase error is introduced. The output strip should not be shifted either left or right relative to the source.

Note that there are only a few lines of code unique to the particular 3 3 filter described above in lines 35 46 and 48. Interestingly a new 3 3 filter could be created very quickly using this one as a template. Only the filter3 getHorResult pl1 and filter3 getVerResult functions need to be replaced with two new functions in order to generate a completely different 3 3 kernel.

Similarly this kernel implementation assumes that the filter is separable which means that the pixels can be filtered using a dot product in one dimension and then the results filtered using a dot product in the other dimension. This is possible when the 3 3 filter matrix is symmetric. A full matrix multiply can readily be employed instead by modifying the kernel code.

In some embodiments performance optimizations may be applied to the basic methods presented above. For example when handling large image sizes access to sufficient external memory may be constrained. In such cases the pipelines may be configured such that the external memory buffers only represent a small horizontal slice of the overall frame. After each strip column is processed the local memory previous strip history for each kernel is saved to external memory. Then when the next buffer arrives the history is restored before processing of that column begins. The history load and stores use the same strip column parameters as the primary image load and stores.

Since source strips overlap between columns two separate buffers in external memory are used to save and restore history streams. After processing all columns the buffers need to be swapped in preparation for the next call. Also each external memory carries two additional parameters 

The six coded statements below provide an example to add the capability to deal with incremental buffers 

Branching of the kernel processing graph occurs when a kernel produces multiple output strips or the same output gets used by different kernels. Conversely two or more branches of a processing graph are joined when they are used by the same kernel. For joins vertical phase alignment must be considered.

Kernels usually have an additional input offset that allows additional vertical delay to be introduced so that the delays of parallel branches in processing graphs can be easily equalized. This offset is assigned a positive number less than or equal to some kernel dependent limit. For kernels using only one history stream this limit is N 1 filter height. illustrates branching of output strips Y U and V at . Various delays may be employed such as at and to equalize the delays resulting from the branching. In the example of the equalized branches are then merged at .

Kernels that input multiple source strips are usually written assuming that there is zero vertical phase difference between their inputs. Branch delay equalization mentioned above can be used to make this happen. In some cases as an optimization this delay equalization may be effectively accomplished in the joining kernel. If neither of these is possible the addition of an explicit delay kernel may be required. A delay kernel is a very simple 1 1 copy filter that maintains a history strip and has the offset input that can then be used to increase the delay from 0.

One of the two ways branching can occur involves using a strip by two or more kernels. If more than one of the kernels inputting the strip is a filter requiring context they would each normally maintain a private history of the input. Since these private copies would be identical all but one is redundant. To optimize this case one of the kernels is designated as the master and the other filters are replaced with slave versions of their kernel. These slaves are given the master s copy of the previous source as their prv stm input. A slave kernel is identical to a master except that the input argument nxt stm is missing and internally the write to nxt stm is not present. The only other requirement is that all the slaves are called before the master which then updates the history strip.

Although nominally input and output strips are the same size some operators may change the width. An x and y scaling operation changes the strip width. The strip height however is maintained at N by sometimes not producing an output strip scaling down in y or not requiring another input strip before producing the next output strip scaling up in y .

Scaling is one of the more complex cases since most of the time some amount of filtering is also involved. Sometimes the filtering is easily factored out. For instance scaling down by 2 might involve filtering by a 3 3 filter using one kernel and the selecting nearest neighbor every other pixel scan as the output with another. Both kernels would need history strips. The second kernel s history strip is needed so that there is enough source data 2N scan lines to produce the N scan lines of one output strip. Although perhaps the most convenient this approach would not be the most efficient since ths of the 3 3 filter s work is being thrown away by the 2kernel. A more efficient implementation might try to incorporate the x scaling this into the filter so that it only did the work for half the pixels in x. This would leave only the Y nearest neighbor 2 1 scaling to the second kernel. A further optimization might just do the entire filter scale operation in one kernel. This implementation would be the most efficient although two history strips would still be required.

Whether or not filtering is built into the scaling kernel the following inner pipeline loop pseudo code shows how a generic enlarging or reducing scale kernel can be inserted in a set of chained kernels using this methodology. Since all kernels continue to operate on strips the only change to the kernels after scaling will be to the strip width argument passed in. Exemplary pseudo code reads 

The scale kernel takes an additional argument scaled strips which is the number of output strips that the scale kernel will be able to produce given the source strip being passed in from the first segment of pipeline. For reduction scaling this may be zero. For enlargement this may be greater than 1. Whatever additional vertical context the scale kernel needs is maintained by it when it updates its history strip s . The scale kernel will produce a new output strip if scaled strips is greater than zero. It will update its history strip s if scaled strips is less than two. To allow for use of strip columns and incremental buffers the scale kernel is restartable at sub pixel precision x and y offsets.

The disclosure above provides numerous examples to support the RPL method presented herein. In some embodiments the constraints and methodical procedures presented in this discussion for kernel and pipeline implementations may be encoded into a computer program i.e. compiler . For instance a straightforward language may be employed for specifying the key parameters for each kernel and for specifying how kernels are sequenced in a processing graph. A compiler would take these and map them to a pipeline or find the performance optimal grouping of the processing graph into one or more pipelines.

As described above the image processing kernels generated using the method presented here result in a straightforward templatized implementation. This means that multiple kernels can be combined into a single kernel using a formulaic approach and can even be encoded into a compiler. This could help reduce the invocation overhead inherent for a series of kernels that each only perform limited processing such as point operations.

With regard to the description provided some embodiments described herein may be implemented through use of programmatically implemented steps or sub steps. As used herein programmatically is intended to mean through the use of code or computer executable instructions. A programmatically performed step may or may not be automatic.

Still further some embodiments described herein may be implemented using programmatic modules or components. A programmatic module or component may include a program a subroutine a portion of a program or a software component or a hardware component capable of performing one or more stated tasks or functions. As used herein a module or component can exist on a hardware component independently of other modules or components. Alternatively a module or component can be a shared element or process of other modules programs or machines.

Furthermore one or more embodiments described herein may be implemented through the use of instructions that are executable by one or more processors. These instructions may be carried on a computer readable medium. Machines shown or described with figures below provide examples of processing resources and computer readable mediums on which instructions for implementing embodiments of the invention can be carried and or executed. In particular the numerous machines shown with embodiments of the invention include processor s and various forms of memory for holding data and instructions. Examples of computer readable mediums include permanent memory storage devices such as hard drives on personal computers or servers. Other examples of computer storage mediums include portable storage units such as CD or DVD units flash memory such as carried on many cell phones and personal digital assistants PDAs and magnetic memory. Computers terminals network enabled devices e.g. mobile devices such as cell phones are all examples of machines and devices that utilize processors memory and instructions stored on computer readable mediums. Additionally embodiments may be implemented in the form of computer programs or a computer usable carrier medium capable of carrying such a program.

