---

title: Method and system for integrating visual controls with legacy applications
abstract: A method is provided for controlling a legacy application. The method includes visually capturing a series of movements. The method also includes recording the series of movements at a first time as a recorded series of movements. Moreover, the recorded series of movements includes at least a command that is configured to control a legacy application. Furthermore, the method includes invoking the recorded series of movements at a second time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09141443&OS=09141443&RS=09141443
owner: General Electric Company
number: 09141443
owner_city: Schenectady
owner_country: US
publication_date: 20130107
---
Computer control applications may be used to control industrial systems. These computer control systems may be also be used to control various computer applications e.g. power network management applications . However often these computer control applications e.g. legacy applications may not suitably interface with newer computer control applications e.g. applications using visual controls . Thus to use such legacy computer applications with a visual computer control application the legacy computer applications and or the visual computer control applications often must be modified to create an interface e.g. application programming interface API suitable for communicating between the two applications. However creating the API and or modifying the legacy computer application and or the visual control application to interface between the applications can be costly and time intensive.

Certain embodiments commensurate in scope with the originally claimed invention are summarized below. These embodiments are not intended to limit the scope of the claimed invention but rather these embodiments are intended only to provide a brief summary of possible forms of the invention. Indeed the invention may encompass a variety of forms that may be similar to or different from the embodiments set forth below.

In one embodiment a method for controlling a legacy application includes visually capturing a series of movements. The method also includes recording the series of movements at a first time as a recorded series of movements. Moreover the recorded series of movements includes at least a command that is configured to control a legacy application. Furthermore the method includes invoking the recorded series of movements at a second time.

In another embodiment a system includes at least one processor and a memory communicatively coupled to the at least one processor. The system also includes an image capturing device configured to record a series of movements as a recorded series of movements in the memory at a first time as a recorded series of movements. Moreover the recorded series of movements includes at least a command that is configured to control a legacy application. Furthermore the system includes an input interface configured to invoke the recorded series of movements at a second time.

In a further embodiment a visual control apparatus includes an image capture device configured to capture a series of movements as a recorded series of movements. The visual control apparatus also includes a memory configured to record the series of movements as a recorded series of movements. Moreover the recorded series of movements includes at least a command that is configured to control a legacy application. Furthermore the visual control apparatus comprises a user interface configured to invoke or to edit the recorded series of movements.

One or more specific embodiments of the present invention will be described below. In an effort to provide a concise description of these embodiments all features of an actual implementation may not be described in the specification. It should be appreciated that in the development of any such actual implementation as in any engineering or design project numerous implementation specific decisions must be made to achieve the developers specific goals such as compliance with system related and business related constraints which may vary from one implementation to another. Moreover it should be appreciated that such a development effort might be complex and time consuming but would nevertheless be a routine undertaking of design fabrication and manufacture for those of ordinary skill having the benefit of this disclosure.

When introducing elements of various embodiments of the present invention the articles a an the and said are intended to mean that there are one or more of the elements. The terms comprising including and having are intended to be inclusive and mean that there may be additional elements other than the listed elements.

Control applications may use APIs to communicate with legacy applications. However in certain systems the use of APIs may be cumbersome and inefficient and or the APIs may be costly to design and update. For example certain visual control systems may capture visual movements e.g. hand movements facial expressions wand movements of a user but a visual control system using APIs to interact with legacy applications might use specifically designed APIs for each legacy application for which the visual control system may communicate. The techniques disclosed herein provide for the capture of such movements and audio e.g. voice commands and use the movements to control legacy applications without making direct changes to the code of legacy applications or requiring the development of an API for the legacy application of the visual control system. Accordingly different legacy applications may be controlled by the visual control system more efficiently than systems that use specific API development for each interface for each legacy application. Additionally the techniques include saving editing and or naming the series of movements that may be recalled by a user at a later time. By saving and recalling a recorded series of movements the visual control system allows a user to be more productive by allowing the user to invoke commands without performing each of the precise movements used to achieve a desired result.

The visual control system also includes an image capture device that may be integrated within the computing device or peripheral to the computing device e.g. connected via a universal serial bus or other connection such as the connections mentioned above . In various embodiments the image capture device may include any device capable of capturing video images such as a video camera still camera webcam scanner or other suitable devices. In certain embodiments the computing device may control the image capture device so that the processor controls various parameters of the image capture device . For example the image capture device may be capable of toggling between capturing video images and still images may activate or deactivate the image capture device zoom the image capture device pan the image capture device alter frequency e.g. frame rate or resolution of the captured images and or adjust various suitable properties of the image data captured by the image capture device . In some embodiments the processor is capable of optimizing and or otherwise altering the image data prior to storing the image data in memory .

As depicted the visual control system may be optimized to capture movements of the user by detecting movements of the user . For example in some embodiments the visual control system may be configured to interpret hand movements of the user to derive a gestural reduced instruction pose expression GRIPE notation Labanotation Hamburg Notation System hamnosys signing gesture markup language SIGML and or other notations that may then be used to store the user movements e.g. GRIPE movement list in the memory . Additionally or alternatively some embodiments of the visual control system may be configured to track the movement of a presentation wand in addition to or instead of tracking movement of hand movements. In certain embodiments the wand may assist in tracking hand gestures more precisely. For example the wand may transmit a signal e.g. infrared light colored light radio waves that may be tracked by the visual control system. In some embodiments the presentation wand may also be configured to control presentations manipulate on screen content control image capturing emphasize portions of a presentation e.g. laser pointer and or other presentation functions. In certain embodiments the visual control system may be configured to receive and or record information from one or more presentation wands . Moreover in some embodiments one or more presentation wands may be included as part of a mobile computing device or other input device configured to interface with the computing device . In such embodiments the mobile computing device may include a cellular phone a tablet computer a laptop computer a personal digital assistant or other similar devices

As further discussed below the computing device includes a capture application including non transitory machine readable computer instructions stored in memory and executed by the processor . This capture application may control the image capture device via the processor . In certain embodiments the capture application may include one or more applications stored in the memory . For example the capture application may include a separate program that the user may select or the capture application may be embedded within an operating system for the computing device and or embedded within firmware and or drivers for the image capture device . The capture application may interface with a legacy application for example by using a series of recorded movements and other techniques described in more detail below with respect to . Indeed rather than use an API or custom interface code the techniques described herein may capture visual movement and use the captured movement to control and or interface with the legacy application .

In other embodiments at least one command may correspond to multiple movements. Additionally or alternatively multiple commands may correspond to a single movement. In some embodiments the commands may include commands to start recording stop recording select a menu item advance through a menu open additional programs zoom and pan within windows resize windows open windows close windows and or other suitable application manipulations. Additionally in certain embodiments the recorded series of movements may include a pre determined number of commands e.g. 1 2 3 or more commands . Other embodiments of the recorded series of movements may include user defined limits to the number of movements. For example in such embodiments the first movement may correspond to a start recording command and the last movement may correspond to a stop recording command. In such embodiments the first movement and or the last movement may be concatenated from the recorded series of movements before the recorded series of movements is saved in the memory .

Returning to in addition to the image capture device the visual control system may include a microphone that is configured to capture audio signals such as voice commands uttered by the user . In such embodiments the processor is capable of storing the audio signals in addition to captured movements of the user . In certain embodiments the audio signals may be stored separately from the stored movements and may be accessed when the recorded series of movements recorded along with the audio signal is accessed. In other embodiments the audio signals may be converted to a movement and stored within the related recorded series of movements . Indeed the audio signals may be used in lieu of or additional to visual movements but may be converted and stored into movements by the techniques described herein. For example an audio command like zoom in may be converted to an equivalent zoom in visual movement and stored as the zoom in visual movement. Any number of audio commands such as record stop and select may be converted and stored as a movement. Indeed the audio signals and the movements may both be converted to similar data formats e.g. GRIPE and stored in the memory . For example the movements and audio signals may be translated to and stored as commands that may be used by the capture application . To insure that the audio and visual commands are received in proper order some embodiments may synchronize the audio visual commands during recording so that an earlier issued command e.g. either audio or visual is stored prior to a later issued command e.g. audio or visual command .

In certain embodiments the recorded series of movements may be used to control the capture application . As mentioned above the capture application may record the recorded series of movements and or control the legacy application that may be communicatively connected to the capture application . In some embodiments the capture application may be suitable of performing other functions in addition to capturing the movements of the user. For example in some embodiments the capture application may be used to enable teleconferencing through the computing device and or provide operating system functions e.g. save file open file print file launch application close application for the computing device while incorporating a capturing function embedded within the capture application suitable for capturing the movements and . In other words the capture application may be any application that is configured to receive controls from the user through image capture device and or microphone such as the Mezzanine platform made available by Oblong Industries Inc. of Los Angeles Calif. The legacy application communicatively coupled to the capture application may include Sluice or GeoView both available from General Electric Company of Schenectady N.Y. However in some embodiments the user may desire to perform actions that may not be provided in the capture application or the user may to desire to control an additional application such as additional legacy applications .

In certain embodiments the legacy application may include any application that is not incorporated within the capture application . For example the legacy application may include power network management applications such as Sluice GeoView GENe XA 21 and the PowerOn suite each made available by General Electric Company of Schenectady N.Y. as well as other similar network management applications. Specifically the applications may include Energy Management Systems EMS applications Demand Response Management Systems DRMS applications Distribution Management Systems DMS applications Outage Management Systems OMS applications Geospatial Information Systems GIS and or other suitable power network management applications.

Furthermore the illustrated computing device may include one or more displays that may display information provided by the computing device . For example the display may display information provided by the capture application the legacy application other applications stored in the memory and or other applications wirelessly connected to the computing device . Moreover the illustrated embodiment of the computing device couples to two displays but other embodiments of the computing device may couple to 1 3 4 or more displays configured to display information provided by the computing device . The displays may share a single workspace displayed across multiple screens. Further each display may be included in a monitor a tablet a cell phone a laptop a screen projector a web browser and so on. A workspace may enable different users communicatively coupled via a network to share content and applications interactively with any other user including users at other geographic locations. For example a first user may take control of the wand and or use hand and other body gestures at a first geographic location and use the wand and or hand and other body gestures to interactively control any number of applications in the workspace which may be displayed by all displays . A second user at a second geographic location may then ask for or receive control of the workspace and similarly take interactive control of the workspace. The second user s actions may then be presented by all of the displays . Indeed application sharing whiteboarding video conferencing and real time collaboration may be provided by using a shared workspace including sharing the workspace in various geographic locations.

It may be useful to describe more details of the legacy application s such as legacy applications useful in power network management. Accordingly illustrates an embodiment of the display illustrating various legacy applications . The capture application may be used to control any one or more of the legacy applications . For example in some embodiments the legacy applications may be displayed on or more displays . For example in some embodiments the display may be used to display all of the legacy applications . In such embodiments the legacy applications may be executed on a single computing device e.g. computer or server . In other embodiments one or more of the legacy applications may be executed on one or more computing devices and combined on one display . For example video from one or more computing devices may be combined on the display using video muzzling such as the window sharing capabilities integrated in the Mezzanine platform. In further embodiments the displayed legacy applications may be distributed across one or more displays .

In certain embodiments the display may display one or more legacy applications . Although the illustrated embodiment of the display shows 4 legacy applications other embodiments are configured to concurrently display 1 2 3 5 6 or more legacy applications . In the illustrated embodiment of the display the displayed legacy applications include Insight a DMS application a GIS application and an OMS application . Other embodiments of the display may include one or more other suitable power network management systems in addition to or in place of one or more of the illustrated legacy applications . For example the legacy application may include an EMS application that may be used to centrally monitor analyze optimize simulate and control generation and transmission assets in real time. A DRMS application may be used to dispatch load resources according to demand to optimally achieve load demand while taking various risks and rewards of a dispatch plan into the optimization. The DMS application may be used to manage renewable generation of power implement grid efficiency improvement measures and control isolation and restoration of outages. The GIS application may be used to model network infrastructures that may experience complex network asset management problems such as electrical telecommunications gas water and public utilities. The OMS application may be used to provide network management and advance workflow outage restoration support during storm conditions.

The proteins may be similar to data structures albeit more flexible and may contain information deposited by the capture application several times per second for example at a frequency of approximately 10 50 Hz into the pool . Proteins may be made up of two parts each one being a slaw descrips and ingests. Descrips may be slaw strings and ingests may be key value pairs where the key is a string. Slaws are data units having the ability to store multiple types of data including an unsigned multi bit integer e.g. 64 bit integer 128 bit integer complex number boolean vector string and or a list. In some embodiments the protein may be composed of one or more data structure units that are arbitrarily composed but may be self describing structured and or typed. An example protein format is as follows 

The capture to legacy pool is a directional communication channel from the capture application to the legacy application . The pool may be a multi point contact that allows one or more legacy applications to connect to the pool along with the capture application without making any changes to any other applications connected to the pool . In some embodiments the capture to legacy pool may be implemented as a ring buffer e.g. a circular data structure using a buffer as if it were connected end to end . Although the pool contains proteins that are arbitrarily composed e.g. contain any type of data the pool may control the order of data sent from the capture application to one or more legacy applications . For example in some embodiments the pool may be used as a queue that sends data to one or more legacy applications in the order sent from the capture application . In certain embodiments the data may be sent from the pool to one or more legacy applications upon receiving each movement from the capture application . In other embodiments a batch of movements may be sent after a certain number of movements have entered the pool . For example in some embodiments data may be sent from the pool to the legacy application after a set number of movements have occurred such as 2 3 4 5 or more movements. In other embodiments data may be sent from the pool to the legacy application after a full command is detected such that commands composed of one movement are sent after the one movement is detected by the computing device but multi movement commands are received after the full string of movements composing a command is detected by the computing device . As discussed below the recorded series of movements may be invoked by the user . When the user invokes the recorded series of movements the recorded series of movements may be invoked and sent as one packet of data to the legacy application at one time. As can be appreciated invoking the recorded series of movements may be faster that the user s movements thereby increasing the efficiency of the user while operating the computing device .

In addition to sending information from the capture application to the legacy application return information may be sent through the communication path through the legacy to capture pool as a protein . The legacy to capture pool may be constructed similarly to pool and the protein may be similar to the protein . The return information may include displayed images queries and or responses to the commands sent via pool . For example the legacy application may ask for additional information and or show more available navigation choices after a command is sent from the capture application to the legacy application . In some embodiments the capture application may present the information to the user and or capture more movements from the user to navigate through and or control the legacy application . By utilizing for example a round robin approach to send and receive data via the pools and in a circular fashion the techniques described herein enable a more efficient interface between the legacy application and the capture application .

The recorded series of movements then may be recorded to the memory using GRIPE or another suitable notation block . In some embodiments the recording of the movements may be first converted to a corresponding series of commands e.g. clicks through a navigation pane mouse movements keyboard presses and or keyboard shortcuts derived from movements recorded in the capture application . Once the series of movements are recorded block the processor enables the user to name the series of movements and or edit the series of movements block . In some embodiments upon recording the movements the processor causes one or more displays to present a user interface to the user and or causes the mobile computing device to present a user interface configured to edit the recorded series of movements . In other embodiments the series of movements is recorded and a user may invoke a menu that allows the user to edit or name the recorded series of movements using the computing device the mobile computing device or a remote computing device connected to the computing device . For example the recorded movements may be reordered certain movements may be deleted certain movements may be added and certain movements may be updated. Likewise data in the proteins may be edited e.g. updated inserted deleted . Once the series of movements has been recorded the processor presents a menu via the display and or the mobile computing device that enables the user to invoke the recorded series of movements block .

Additionally or alternatively in some embodiments the conversion of the series of movements may be edited such that the significance of recorded movements may be altered. In other words the correspondence between gestures and commands may be changed. For example a gesture that may correspond to a click in a navigation window may be redefined as a scrolling action or another command in the legacy application. For example a specific movement of the thumb when the hand is in a certain position may be mapped to any number of different legacy application commands.

Technical effects of the invention include using movements to control legacy applications without making direct changes to the code of legacy applications or developing an API for the legacy application and or the capture application . Accordingly different legacy applications may be interchanged more quickly and more cheaply than systems that use special API development for each interface between a legacy application and a capture application . Additionally the series of movements may be saved edited and or named to be recalled by a user to control the legacy application . By saving and recalling a recorded series of movements user productivity may be increased due to less time used to perform precise movements to achieve a desired result whether the desired result includes navigating or controlling the legacy application .

This written description uses examples to disclose the invention including the best mode and also to enable any person skilled in the art to practice the invention including making and using any devices or systems and performing any incorporated methods. The patentable scope of the invention is defined by the claims and may include other examples that occur to those skilled in the art. Such other examples are intended to be within the scope of the claims if they have structural elements that do not differ from the literal language of the claims or if they include equivalent structural elements with insubstantial differences from the literal languages of the claims.

