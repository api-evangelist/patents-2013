---

title: Systems and methods for implementing an enterprise-class converged compute-network-storage appliance
abstract: A distributed storage system that dispatches an input/output request is described. In an exemplary embodiment, a storage controller client receives the input/output request, wherein the distributed storage system includes the storage controller client, a plurality of storage controller servers, a plurality of virtual nodes distributed among a plurality of physical nodes, and each of the plurality of physical nodes is hosted on one of the plurality of storage controller servers. The storage controller client further computes a target virtual node for the input/output request, where the target virtual node is one of the plurality of virtual nodes. Using the computed target virtual node, the storage controller client determines a target physical node that corresponds to the target virtual node, where the target physical node is one of the plurality of physical nodes. In addition, the storage controller client dispatches the input/output request to a target storage controller that corresponds to the target physical node, wherein the target storage controller server is one of the plurality of storage controller servers. In addition, the virtual node includes a set of one or more mirrored copies across different fault domains for ensuring resiliency and high availability.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09521198&OS=09521198&RS=09521198
owner: Springpath, Inc.
number: 09521198
owner_city: Sunnyvale
owner_country: US
publication_date: 20131219
---
Applicant claims the benefit of priority of prior provisional application Ser. No. 61 739 685 filed Dec. 19 2012 the entirety of which is incorporated by reference.

This invention relates generally to a storage system and more particularly to software defined distributed storage system.

Enterprise storage systems currently available are proprietary storage appliances that integrate the storage controller functions and the storage media into the same physical unit. This centralized model makes it harder to independently scale the storage systems capacity performance and cost. Users can get tied to one expensive appliance without the flexibility of adapting it to different application requirements that may change over time. For small and medium scale enterprise this may require huge upfront capital cost. For larger enterprise datacenters new storage appliances are added as the storage capacity and performance requirements increase. These operate in silos and impose significant management overheads.

A software defined distributed storage system that separates the storage controller functions with that of storage media is described. In an exemplary embodiment a storage controller client dispatches an input output request to one of a plurality of storage controller servers in a software defined distributed storage system. The software defined distributed storage system further includes a plurality of virtual nodes distributed among a plurality of physical nodes and each of the plurality of physical nodes is hosted on one of the plurality of storage controller servers. Each physical node may be a commodity server hardware with one or more physical storage media Hard Disk Drive Solid State Drive Flash devices etc. for storing data and its metadata. Each virtual node is allocated some physical space in one or more physical storage media where its contents are stored with enough redundancy to recover from failures. The storage controller client receives the input output request. The storage controller client further computes a target virtual node for the input output request where the target virtual node is one of the plurality of virtual nodes. Using the computed target virtual node the storage controller client determines a target physical node that corresponds to the target virtual node where the target physical node is one of the plurality of physical nodes. In addition the storage controller client dispatches the input output request to a target storage controller server that corresponds to the target physical node wherein the target storage controller server is one of the plurality of storage controller servers.

In another embodiment a storage controller server receives a write operation request to store data where the write operation request is dispatched from a storage controller client to the storage controller server using a deterministic placement function. In response to the write operation request the storage controller server appends the data to a write log in an active log partition of the storage controller server.

In a further embodiment a storage controller server receives a read operation request where the read operation request is dispatched from a storage controller client to the storage controller server using a deterministic placement function. In response to receiving the read operation request the storage controller server reads the data that is indicated in the read operation request where at least part of the data is stored in a write log that is in an active log partition of the storage controller server.

A software defined distributed storage system called StorFS that separates the storage controller functions with that of storage media is described. In the following description numerous specific details are set forth to provide thorough explanation of embodiments of the present invention. It will be apparent however to one skilled in the art that embodiments of the present invention may be practiced without these specific details. In other instances well known components structures and techniques have not been shown in detail in order not to obscure the understanding of this description.

Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification do not necessarily all refer to the same embodiment.

In the following description and claims the terms coupled and connected along with their derivatives may be used. It should be understood that these terms are not intended as synonyms for each other. Coupled is used to indicate that two or more elements which may or may not be in direct physical or electrical contact with each other co operate or interact with each other. Connected is used to indicate the establishment of communication between two or more elements that are coupled with each other.

The processes depicted in the figures that follow are performed by processing logic that comprises hardware e.g. circuitry dedicated logic etc. software such as is run on a general purpose computer system or a dedicated machine or a combination of both. Although the processes are described below in terms of some sequential operations it should be appreciated that some of the operations described may be performed in different order. Moreover some operations may be performed in parallel rather than sequentially.

The terms server client and device are intended to refer generally to data processing systems rather than specifically to a particular form factor for the server client and or device.

A software defined distributed storage system called StorFS that separates the storage controller functions with that of storage media is described. In one embodiment this separation allows the storage controller to be co located with the user application in the same physical units or reside separately in a dedicated set of storage units. This set of storage units functions as a single unified storage system and balances the capacity and performance load across the distributed components. A cache accelerated distributed storage design along with efficiency and reliability features can provide a higher level of determinism in terms of quality of service and performance. The ability to converge compute and storage significantly simplifies the management and reduces both the capital cost as well as the operational cost.

In one embodiment the capacity and performance of a storage system can be increased in two ways scale up and or scale out. Scaling up refers to adding more resources e.g. storage compute etc. in the same physical storage unit. In this embodiment there can be a limit up to which a system can be scaled up. Thus further scaling requires adding more physical units that work in cohesion to provide increased capacity and performance. This is called scale out and has been the motivation of many distributed storage system designs. In an ideal scale out system adding the resources increases the capacity and performance by the same ratio without impacting the reliability characteristics of the storage system. In practice however this ideal scale out is hard to achieve. This is because previous distributed systems rely on a centralized component for synchronization of the distributed system s various tasks and managing storing of the distributed system metadata. In one embodiment this metadata is data that describes the distributed system and the location of users data. This centralized metadata becomes the bottleneck because the centralized metadata distributed storage system is not able to scale beyond a certain limit.

In one embodiment the StorFS system is a storage system that includes a plurality of storage nodes coupled together by an interconnection network. In this embodiment the StorFS system provides a distributed storage of data to one or more local and or remote applications that make use of the storage and or storage services provided the StorFS system. In one embodiment each of the storage nodes includes a storage controller that is used to manage storage requests of the local and or remote applications using the storage. The storage controller can include a storage controller client SC client a storage controller server SC server or both the SC client and SC server. In one embodiment the SC client handles and dispatches application storage requests to an SC server. The SC server handles the storage requests and can additionally perform storage services e.g. synchronous and asynchronous replication distributed data deduplication distributed garbage collection data flushing and distributed recovery .

In another embodiment the StorFS system uses the concept of virtual node vNode as the unit of data routing and management. In one embodiment there are four types of vNode 

The cluster resource manager CRM maintains a database that maps vNodes to their Mirror Set . The mirror set defines the actual physical locations of the corresponding vNode. where s are the way mirrors of Node 1 In one embodiment a mirror is defined by the tuple P D S where P indicates the physical node Dindicates the disk within that node and S denotes the Segment Stor within the disk. In one embodiment a Segment Stor is a thin provisioned logical partition in StorFS. One of the M in the mirror set is marked as primary and is responsible for mirroring data metadata to the other mirrors in the mirror set.

In one embodiment the SC client dispatches storage requests from the applications to an SC server that stores the data referenced by the storage request. In this embodiment the storage request includes an entity identifier that references the stored data and an offset that is an offset into that stored data. The entity identifier can be an iNode a file descriptor key value pair identifier etc. If the storage request is a write of data to the StorFS system the SC client determines which of the plurality SC servers is to handle the write storage request. In one embodiment the SC client computes the SC server to handle the write storage request using a deterministic placement function. In this embodiment the deterministic placement function uses the input parameters to compute the virtual node that or will store the data referenced in the write storage request. In one embodiment by using the deterministic placement function the StorFS system does not need to store location metadata to determine the initial virtual node for the data in the request. Instead the system stores metadata for the virtual node to the physical node conversion. With the virtual node identification in one embodiment the SC client determines the physical node identification and the SC server that corresponds to this physical node.

The SC server that stores the data referenced by the write storage request receives this request. In one embodiment the SC server stores this data in a write log by appending the data at the end of the write log. This can lead to a fast write for the data that allows a quick write storage fulfillment for the requesting application. In addition and in one embodiment the SC server can synchronously replicate the data referenced in the write storage request. In this embodiment the SC server determines the mirrors for this virtual node using a dynamic table that tracks the mirrors for each virtual node. In addition the SC server sends the data to the SC servers that are used for the mirror virtual nodes.

In one embodiment when the write log is full the SC server flushes the write log to persistent storage. In this embodiment for each virtual node that stores data in the full write log the StorFS system determines new virtual node for that data and sends the data to the SC server that corresponds to the new virtual node. The SC server stores this data in persistent storage. In addition the StorFS system can determine if the data that is stored in the write log for that virtual node is a duplicate of some other data stored elsewhere in the StorFS system. In one embodiment during the flushing operation the StorFS system determines if an entity is stored elsewhere by using a deduplication hints table. In one embodiment the hints table stores characteristics of the top K storage entities in the StorFS system. If there is a match with the entity being flushed the StorFS system updates the metadata for this entity but does not flush the entity to the persistent storage. If not the StorFS system flushes the entity to persistent storage.

In one embodiment during a flush to persistent storage the StorFS system can asynchronously replicate each virtual node in the write log. In this embodiment the StorFS system determines the mirrors of the virtual node and asynchronously sends the data and metadata of that virtual node to the mirror virtual nodes. In one embodiment the StorFS system transfers the data and metadata of the virtual node as a large bulk transfer so that this data transfer is more efficient.

In addition to the write operations of the StorFS system outlined above the StorFS system can perform additional storage services on the stored data. In one embodiment the StorFS system can perform distributed failure recovery distributed deduplication and distributed garbage collection. In one embodiment a virtual node can have one or more mirror nodes where each of the mirror nodes is stored in a different fault domain. If a component of the virtual node goes down and or becomes unresponsive a new virtual node is allocated. The StorFS copies the data and or metadata for the failed virtual node from the one or more mirror virtual nodes to the newly allocated virtual node. In one embodiment the StorFS copies the data from the mirror nodes in large segment making the restoration of that virtual node more efficient.

Furthermore in one embodiment the StorFS system can perform distributed data deduplication. As described above during a flushing of data from the write log to persistent storage the StorFS system checks to determine if the data being moved is duplicated elsewhere in the StorFS system. The StorFS system uses a hints table to determine whether data is duplicated. In one embodiment the hints table stores statistics about a partial set of data in the StorFS system. By using a partial set of data statistics the StorFS can do the data deduplication check efficiently. The StorFS system creates the hints table by creating a live object map of the data stored in the StorFS system. Using this map the StorFS system determines a top K statistics on the data stored in the StorFS system and uses these statistics in the hints table. In one embodiment there is a global hints table that is used by each of the SC servers to determine if data is being duplicated in the StorFS system. In one embodiment the hints table map stores a fingerprint for a VBA of content stored in the StorFS system.

In one embodiment the StorFS system stores data in logically sequential segments. As data is deleted these segments become unreferenced and can be reused. In one embodiment the StorFS system walks a metadata tree to determine which of the segments are not referenced. For each unreferenced segment the StorFS system collects the unreferenced segments and makes the segments available for future use. In addition these segments can be used for fast distributed recovery of a vNode that is hosted by component that fails. In one embodiment if a component of the StorFS system fails the StorFS system determines which vNodes are affected by component recovery. For each affected vNode the StorFS system can either create a new mirror vNode and resync this new vNode or resync that affected vNode.

In one embodiment the design of the StorFS system distributes both the data and the metadata and this system does not require storing a complete global map for locating individual data blocks in our system. The responsibility of managing metadata is offloaded to each individual storage nodes A C. In one embodiment a cluster manager CRM resides on each SC Server maintains some global metadata which is small compared to the local metadata. In one embodiment each logical file or entity is partitioned into equal sized stripe units . The location of a stripe unit is determined based on a mathematical placement function Equation 1 

In one embodiment the StorFS system receives the Entityand offset as input for each requested storage operation from an application A C. In this embodiment the StorFS system uses the offset to compute a stripe unit number Stripe Unit based on the stripe unit size Stripe Unit Size and the number of virtual nodes that the entity can be spread across Stripe Unit Per Stripe. Using the stripe unit number and the entity identifier Entity the StorFS system computes the virtual node identifier. As described below the StorFS system uses a hash function to compute the virtual node identifier. With the virtual node identifier the StorFS can identify which physical node the storage entity is associated with and can route the request to the corresponding SC server A C.

In one embodiment each vNode is a collection of either one or more data or metadata objects. The StorFS system does not store data and metadata in the same virtual node. This is because data and metadata may have different access patterns and quality of service QoS requirements. In one embodiment a vNode does not span across two devices e.g. a HDD . A single storage disk of a storage node A C may contain multiple vNodes. In one embodiment the placement function uses that a deterministic hashing function and that has good uniformity over the total number of virtual nodes. A hashing function as known in the art can be used e.g. Jenkins hash murmur hash etc. . In one embodiment the Stripe Unit Per Stripe attribute determines the number of total virtual nodes that an entity can be spread across. This enables distributing and parallelizing the workload across multiple storage nodes e.g. multiple SC servers A C . In one embodiment the StorFS system uses a two level indexing scheme that maps the logical address e.g. offset within a file or an object to a virtual block address VBA and from the VBAs to physical block address PBA . In one embodiment the VBA can be a tuple with following information 

In one embodiment the cluster manager CRM maintains a database of virtual node vNode to physical node pNode mapping. In this embodiment each SC client and server caches the above mapping and computes the location of a particular data block using the above function in Equation 1 . In this embodiment the cluster manager need not be consulted for every I O. Instead the cluster manager is notified if there is any change in vNode to pNode mapping which may happen due to node disk failure load balancing etc. This allows the StorFS system to scale up and parallelize distribute the workload to many different storage nodes. In addition this provides a more deterministic routing behavior and quality of service. By distributing I Os across different storage nodes the workloads can take advantage of the caches in each of those nodes thereby providing higher combined performance. Even if the application migrates e.g. a virtual machine migrates in a virtualized environment the routing logic can fetch the data from the appropriate storage nodes. Since the placement is done at the stripe unit granularity access to data within a particular stripe unit goes to the same physical node. Access to two different stripe units may land in different physical nodes. The striping can be configured at different level e.g. file volume etc. Depending on the application settings the size of a stripe unit can range from a few megabytes to a few hundred megabytes. In one embodiment this can provide a good balance between fragmentation for sequential file access and load distribution.

In one embodiment the distributed object layer provides a global distributed object namespace that is accessible over the network. At a very high level distributed object layer provides two simple interfaces 

KV Put and KV Get are further described in below respectively. In one embodiment the key is the VBA that uniquely identifies the object and can be accessed from any storage control server in the cluster. In another embodiment the key may be user defined unique identifier. The distributed object layer routes the I O requests to the storage control server that manages and stores the vNode indicated in the VBA. In one embodiment the KV Put interface is used to store an object referenced by the key. In one embodiment the KV Get interface is used to fetch an object referenced by the key.

At block process detects that the inactive mirror has come back up. In one embodiment process resynchronizes the inactive mirror with the current primary. In one embodiment process resynchronizes the inactive mirror by copying over segments missing in the inactive mirror from one or more active mirrors. For example and in one embodiment process resynchronizes the inactive mirror as described in below. In one embodiment at the end of the mirror resync process marks the inactive mirror as active. In this embodiment the updated AMS or Vwill be 6 In this embodiment at the end of the mirror resync the inactive mirror is marked as active. The mirrors are in sync at this stage. In this embodiment Mhandle the new I O and replicates the new I O to Mand M.

As described above the StorFS system provides an interface KV put to store an object referenced by a key. is a flow diagram of one embodiment of a process for KV put processing. In one embodiment process is performed by the distributed object layer as described in above. In process begins by receiving the VBA and the object that is to be stored at block . In one embodiment the VBA is the key used to reference the object. At block process determines the mirror set of the object s vNode. In one embodiment the object s vNode is determined from the input VBA received at block . For example and in one embodiment the VBA received includes the vNode as one of the elements of the tuple for the VBA.

Process determines if the local pNode is the primary mirror of the determined vNode at block . In one embodiment the local pNode can be determined if this pNode corresponds to the primary mirror based on the vNode for the VBA and a pNode vNode correspondence table. If the local pNode is not the primary process sends the VBA and object to the primary mirror at block . In one embodiment by sending the VBA and object the target pNode can store the object at the VBA. Execution proceeds to block below. If the local pNode is the primary mirror store the VBA and object in the primary s segment store. In one embodiment the segment store is a Segment Stor described above that is a thin provisioned logical partition in StorFS. In one embodiment the data in the mirrors is stored by segment which allows for efficient storage of the content for that vNode. Execution proceeds to block below.

At block process sends the VBA and object to the other mirrors. In one embodiment process sends the VBA and object to the active mirrors of the AMS of the vNode for the object. By sending the VBA and object to the active mirrors process provides data replication for each object store. Process determines if any of the non primary mirrors failed in response to the VBA and object being sent to them. If a non primary mirror failed process marks that non primary mirror as inactive. In one embodiment the StorFS system attempts to recover the inactive mirror as described above. Execution proceeds to block below. If none of non primary mirrors fail execution proceeds to block below.

At block process determines if the primary mirror failed. If the primary mirror did not fail in response to the store attempt process returns success to the client at block . If the primary mirror did fail at block process determines if the error is recoverable. An error is recoverable if there is an active mirror other than the failed primary available. If the error is recoverable execution proceeds to block in which process repeats the put process. If the error is not recoverable process returns a failure to the client.

As described above the StorFS system can additionally provide an interface KV get to fetch an object referenced by a key. is a flow diagram of one embodiment of a process for KV get processing. In one embodiment process is performed by the distributed object layer as described in above. In process begins by receiving the VBA for the object that is to be retrieved at block . In one embodiment the VBA is the key used to reference the object. At block process determines the mirror set of the object s vNode. In one embodiment the object s vNode is determined from the input VBA received at block . For example and in one embodiment the VBA received includes the vNode as one of the elements of the tuple for the VBA.

Process determines if the local pNode is the primary mirror of the determined vNode at block . In one embodiment the local pNode can be determined if this pNode corresponds to the primary mirror based on the vNode for the VBA and a pNode vNode correspondence table e.g. the CRM routing table . If the local pNode is not the primary process sends the request for object to the primary mirror at block . Execution proceeds to block below. If the local pNode is the primary mirror process fetches the object from the primary s segment store. In one embodiment the segment store is the uniform framework to manage different kind of storage devices and abstracts out the complexity of low level block management from the upper layers in the StorFS software stack. Execution proceeds to block below.

At block process determines if the fetch was successful. In one embodiment process determines if the fetch is successful by examining a return code associated with fetch attempt. If the fetch is successful process returns the object to the client at block . If the fetch is not successful process attempts a read repair at block . In one embodiment read repair involves fetching data from an active mirror and repairing the primary mirror with the fetched data. Process determines if the read repair is successful at block . If the read repair is successful the object is fetched and process returns the object to the client at block as described above.

If the read repair is not successful at block process determines if the error is recoverable. In one embodiment process determines that the error is recoverable by determining whether there is an alternative active mirror from where data can be fetched. If the error is recoverable process marks the primary mirror as inactive and elects a new primary at block . In one embodiment by electing a new primary process can use this primary to do another fetch of the object. Execution proceeds to block above in which process attempts the fetch using the newly elected primary. If the error is not recoverable process returns a failure at block .

At block process sends the input put request to SC server on the corresponding pNode. For example and in one embodiment if process executing on SC client A on physical server A and the corresponding pNode is on the SC Server C of physical server C process sends the input output request to the SC server C on physical server C. At block process determines if the input output request is related to creating or deleting an entity. In one embodiment an entity is data that is stored in the StorFS system . For example and in one embodiment the entity could be a file an object key value pair etc. If the request is not related to creating or deleting an entity execution proceeds to block below. If the I O request is related to creating or deleting an entity at block process determines which of the vNodes need to be updated. In one embodiment process determines the vNodes to be updated by computing all the vNodes that the entity can reside using the placement function Equation 1 . At block process sends the input output request to the SC server that corresponds to the vNodes determined at block .

At block process receives an I O request for write log processing. Process determines if the write log processing is complete at block . If the write log processing is not complete at block process wait for the write log processing to complete and execution proceeds to block . If the write log processing is complete process returns.

In one embodiment an application can use some type of middleware libraries to access networked storage. For example and in one embodiment virtual machines may use the hypervisor s built in NFS client or iSCSI client to access backend storage. In a clustered environment the goal of this middleware is not only to provide connectivity to backend storage but also availability by failing over to other cluster nodes in case of failure. In one embodiment the StorFS system uses an intelligent I O dispatcher that intercepts I O requests from the client e.g. NFS Client running inside a hypervisor and directs them to appropriate cluster nodes. In one embodiment the I O dispatching is performed by a SC Client such as SC Client A C as described in above. In one embodiment there are three modes of operation i I O requests are routed to the SC Client running on the same physical node i.e. to localhost ii A common FQDN Fully Qualified Domain Name entry for the cluster pointing to the localhost or 127.0.0.1 is created in the DNS configuration file typically etc hosts of each cluster nodes and iii Intercepting and rerouting incoming I O requests using software based routing mechanism like DVS Distributed Virtual Switch and Network Service Insertion framework available in many popular virtualization platforms e.g. VMware .

In one embodiment the Log structured sequential storage layout provides an efficient use of SSD and HDD I O bandwidth available for incoming writes. In this embodiment both the data and metadata are written to a new disk location as opposed to rewriting them at their old location. This layout transforms the incoming random I O traffic to large sequential writes in the backend of the physical storage media e.g. HDD SDD flash etc. . In addition this layout not only increases the write performance but also enables many kinds of data services provides protection from accidental deletes etc. This layout additionally increases the SSDs lifetime by writing in large erase cycle blocks. However a problem with the log structured layout is fragmentation of the physical storage media. This may not be a big problem in SSDs because of their high random I O performance but fragmentation can deteriorate performance in case of HDD spindles. In addition Log structured log enables variable sized chunks to be stored in it. This enables compression and deduplication of data blocks and stores them tightly on the storage media without any alignment restriction like sector alignment etc. .

As mentioned earlier the StorFS system uses a two level indexing scheme that maps the logical address to a virtual block address VBA and from the VBAs to physical block address PBA . The system allows for objects with contiguous VBAs to be stored close to each other. This addressing scheme further enables fast lookup of objects from the underlying media and reduces defragmentation significantly. As described above VBAs are unique across the StorFS cluster and no two objects in the cluster will have the same VBA.

When creating opening a Block Set a hierarchical path can be specified prepended with the string to indicate which driver should be used. If no driver name is specified the Block File file driver A is assumed and the path is treated as a standard Unix file or device. The Block File driver splits the file into fixed sized blocks and exports a single Block Set with all physical blocks allocated with physical block numbering 0 numBlocks 1 . The Block Partition driver part C can be stacked on top of the Block File A driver to allow a single physical disk Block Set to be partitioned into multiple Block Sets.

In one embodiment the Block Flash driver flash C can be stacked between the Block Partition E and File A drivers to provide flash specific semantics such as I O scheduling e.g. limiting the number of concurrent writes preventing concurrent reads writes etc. and invoking TRIM on block free. In one embodiment freeing a flash based block A is similar to freeing an HDD based block A except that in this embodiment the block flash driver gets invoked for the free request which performs a SCSI TRIM C before invoking the block file driver. In one embodiment a TRIM releases and prepares the specified region of a flash based device for future writes.

In one embodiment the segment store uses the block abstraction to build collections of ordered segments. Each segment within a Segment Store is uniquely identified by its logical id which is a monotonically increasing 64 bit number. This provides a uniform framework to manage different kind of storage devices and abstracts out the complexity of low level block management from the upper layers in the StorFS software stack.

In one embodiment both the data and metadata are distributed as well as replicated which allows for recovery in case of failure. In one embodiment the replication is performed across different fault domains so that a failure of a component in one domain does not impact the availability of components in other domains. A set of HDDs server nodes or a physical server rack is a few examples of fault domain. This allows the StorFS system to tolerate different kind of failures disk failures node failures and or rack failures. Replication of data however can impose a cost on a storage system. For example replication can impose significant overhead in terms of capacity and steady state performance.

In one embodiment the asynchronous replication module A stores the content to persistent storage A. In this embodiment the asynchronous replication module A can additionally replicate this content to the other storage nodes B C via the asynchronous replication modules B C respectively. These receiving asynchronous replication modules B C each store the content in the corresponding local perspective storage B C respectively.

To facilitate replication the block storage layer generates a unique monotonically increasing logical ID for the data metadata segment system writes. The replication engine uses these logical IDs to synchronize large chunks of segments across different mirrors. This scheme eliminates the need of expensive distributed coordination metadata comparison and or read modify write to replicate data and metadata. New incoming writes are logged and synchronously replicated in SSDs or other high speed storage medium. Periodically a flusher A C moves the logged content asynchronously from the high speed storage to its permanent location for persistence.

As described above the StorFS system can perform synchronous replication of the data being stored in the in the write log. is a flow diagram of one embodiment of a process to perform synchronous replication of a write log entry. In one embodiment process is performed by process at block of above to perform this synchronous replication. In process begins by receiving the write log entry at block . In one embodiment the write log entry is an entry to store an entity in the write log. At block process gets an active mirror set AMS for the write log entry. In one embodiment the AMS is a mirror vNode set for the vNode associated with the write log entry. In this embodiment the AMS includes this vNode and one or more active vNodes that is used to replicate the data and metadata of that vNode. Process prepares the write log entry at block . In one embodiment the write log entry consists of vNode ID timestamp checksum and other metadata along with the incoming data from the SC client.

At block process synchronously sends the write log entry to the pNodes that correspond to the mirror vNodes. In one embodiment process determines the corresponding SC server for each mirror vNode by looking up the corresponding pNodes in a vNode to pNode mapping table via the CRM. In one embodiment the write log entry is synchronous so that the success of the writing to the write log can be acknowledged to the requesting client. In this embodiment a synchronous write allows that the data is reliably stored before write is acknowledged to the client. At block process receives an acknowledgement from each pNode. While in one embodiment there is one SC server for each pNode in alternate embodiments there can be more than one SC server for each pNode. In one embodiment the acknowledgement indicates the write log entry have been stored at the corresponding pNode.

As described above the flusher asynchronously sends data and metadata to the target vNode and the mirror nodes to replicate the data and metadata being moved to persistent storage. is a flow diagram of one embodiment of a process to asynchronously replicate data and metadata. In process begins by receiving the data and the metadata for each target vNode for the asynchronous replication at block . In one embodiment the asynchronous replication is on a vNode by vNode basis. In this embodiment the asynchronous replication can include a replication of one or more vNodes. In one embodiment each vNode may contain a few bytes or up to several megabytes or greater.

At block process determines an AMS for the target vNode. In one embodiment the AMS for a target node includes the target vNode and one or more active replica vNodes that are used to store the replication data and metadata for the target vNode. The AMS is described further below. Process asynchronously sends the data and metadata for that vNode to the target vNode and other mirror nodes in the AMS at block . In one embodiment an asynchronous send of the data is one where the send is sent to the SC server that corresponds to the vNode receiving the data and control is returned to process before the receiving SC server completes the write. In one embodiment the receiving SC server receives the data and metadata and stores this content in the persistent storage of the SC server. After this storing of the data the SC server sends an acknowledgement to process . At block process sends an acknowledgement that the data and metadata has been stored. In one embodiment process completes when the process has received the acknowledgements for each of the issued writes.

In a typical replication based system strong consistency is obtained by enforcing the following 4 where R and W are the minimum number of replicas that must respond correctly to a read and write respectively N is the total number of replicas. The value of N does not change once it has been set. This implies that if there are three replicas R W must always be greater than 3. In one embodiment the StorFS system relaxes this requirement and yet provides strong consistency guarantee. For each vNode the CRM maintains an Active Mirror Set AMS which defines the currently active replicas for that vNode. If a replica goes out of sync e.g. because of failure etc. the replica is dropped from AMS. If a replica comes back up the replica syncs with the corresponding replicas in the AMS and is added back to AMS upon full resynchronization as referred to as a resync . The modified requirement for strong consistency in StorFS is AMS 5 where AMS is the cardinality of the AMS corresponding to a vNode. Thus the variable sized AMS can provide greater service availability because of the less stringent requirements and without compromising strong consistency guarantees. The AMS is further described in below.

In one embodiment the StorFS system is designed to handle multiple failures. When such a failure happens the StorFS system recovers from multiple sources in parallel which significantly reduces the total recovery time. This distributed recovery is made possible in part due to our placement logic that enables the mirrors to find different location of the replicas and stream large chunk of data from those replicas. Also if a particular replica lags behind the primary replica because of failures system reboot etc. the StorFS system can resynchronize itself with other active replicas by fetching those segments whose logical IDs are greater than the ones it has. In this embodiment there is no need to perform an expensive diff and merge operation across the distributed set of replicas.

If there is no heartbeat or I O failure is detected execution proceeds to block . If there is a heartbeat or an I O failure at block process determined the failed component related to the heartbeat or I O failure detect at block . In one embodiment the failed component could be the SC server performing process or could be a remote SC server. In one embodiment the failed component could be failed server of hardware component e.g. disk network server etc. .

Based on the failed component process determines the vNodes impacted by the component failure at block . In one embodiment process uses the CRM table to determined which vNodes are impacted by the component failure. In this embodiment process determines the whether the entire pNode has failed or a component within a pNode e.g. disk controller network interface etc. . If pNode fails all the vNodes in that pNode are impacted. If a pNode component fails one or some of the vNodes associated with that component are impacted. In one embodiment the CRM table includes information mapping vNodes to the pNode as well as which vNode is dependent on which component of the pNode e.g. which disk stores which vNode etc. . There can be one or more vNodes impacted by the failed component. Process additionally performs a processing loop blocks to perform a distributed recovery of the vNodes that correspond to the failed component.

At block process updates the AMS of that vNode. In one embodiment process marks that vNode as passive which indicates that the vNode is not an active vNode of the AMS. In one embodiment a passive vNode is a node that is not available to perform I O operations. In one embodiment a passive vNode attempts to catch up via the resync operation as described in below. In this embodiment once a passive vNode is resynced the vNode becomes an active vNode. In addition process marks the vNode as a candidate for recovery. In one embodiment recovering a vNode consists of copying data from other active vNode in the passive vNode s AMS so that the passive vNode can be brought up to date with the current content for that vNode. Process determines if the number of active mirror vNodes in the AMS for that passive vNode is greater than zero. If the number of active node in the AMS is greater than zero execution proceeds to block above. In one embodiment the passive vNode is marked for recovery and recovery of that vNode happens synchronously as described in below. If the number of active nodes if is zero at block process starts the StorFS recovery. In one embodiment the StorFS recover is further described in below. At block the process completes the recovery.

At block process determines if the number of active mirrors in the AMS for this vNode is greater than the threshold. In one embodiment if the number of active mirror is large enough then that vNode is not necessary for that vNode to be recovered. This means that there are enough active mirrors for the content that is stored in AMS vNode set. If the number of mirrors in the AMS for this vNode is greater than the threshold execution proceeds to block above and this vNode is not recovered. If there are enough active vNodes the passive vNode remains marked for recovery and recovery happens at a later time. If the number of mirrors in the AMS for this vNode is less than or equal to the threshold process determines if the node hosting the vNode is alive. In one embodiment process could send a heartbeat message to the node to determine if the node is alive. For example and in one embodiment this node may have temporarily failed and restored itself and is now back up. If the node hosting vNode is alive execution proceeds to block where process starts the resync process for this vNode.

If the node hosting the vNode is not alive at block process creates a new passive mirror vNode for this vNode. In one embodiment this new passive mirror vNode is used for recovery. In one embodiment process requests from the CRM to create the passive mirror vNode. In this embodiment the CRM determines a placement of the new mirror vNode based on the fault domain of the failed vNode. For example and in one embodiment the CRM places that new mirror vNode in a fault domain that is different from the fault domain of the failed vNode and other vNodes in the AMS set of the failed vNode. Process further marks this new mirror vNode as passive. In this embodiment the new passive vNode is the node used for the resync at block below. Execution proceeds to block below.

At block process performs a resync for the passive vNode. The passive vNode to be resynced could be the original vNode marked for recovery or a new passive mirror vNode created for the resync. In one embodiment the resync operation occurs by the passive node hosting the passive mirror vNode sending requests to one some or all of the active mirrors in the AMS set for the passive vNode. In one embodiment the passive mirror fetches the segments from other active mirrors whose ID is higher than its passive mirror s highest segment ID. In one embodiment the data in the mirrors is stored by segment which allows for efficient storage of the content for that vNode. In one embodiment the passive vNode that is being resync may have some the content already stored e.g. if a node that hosts the failed vNode fails and recovers this failed vNode may have some or most of the content and is missing the most recent content . In this embodiment the failed vNode will need the just the missing content. This missing content is identified by the segment ID. By comparing segment ID and not using diff and copy approach the resync process is more efficient because comparison of segment IDs is a more efficient process that comparison of the actual stored content. In addition the segment IDs are stored sequentially which allows the resync process to determine which is the latest segment ID successfully stored on the passive vNode. Once that is determined the resync process can copy segment ID greater the last successful segment ID to the passive vNode. In one embodiment the resync process can copy content from different active mirror vNodes. By resyncing using segments the resync process can use bulk transfers to copy content in logical segment ID order.

At block process checks if the active mirror vNodes and the passive vNode being resync have the same highest segment ID. If these vNodes do have the same highest segment ID the resync process for this passive vNode is complete and execution proceeds to block . At block process marks the passive vNode as active and adds the passive vNode into the AMS. Execution proceeds to block above where another vNode is resynced. If these vNodes do not have the same highest segment ID execution proceeds to block above.

In one embodiment the StorFS system distributes a storage workload across the cluster by stripping it across multiple virtual nodes. Stripping achieves capacity and performance load balancing and provides higher cumulative performance rather than being bottlenecked by one cluster node. One of the characteristics as well as the challenges in a hybrid storage compute cluster is the constant change in the StorFS systems behavior. For example an application s requirements may change workloads or resources may be added or removed to from the cluster and or there can be a failure in the StorFS system e.g. a network failure disk failure server failure etc. that may change the cluster s resource availability. The StorFS system is designed to continuously adapt to these kinds of changes by automatically balancing load across available resources. These resources are of different kinds CPU network memory storage capacity storage bandwidth etc.

In one embodiment the StorFS system performs a multi dimensional optimization across this heterogeneous set of resources. This is facilitated by estimating the requirements of each virtual node estimating resource availability in each cluster nodes and migrating one or more virtual nodes from one physical node to the other. For example and in one embodiment if the network becomes a bottleneck in a physical node pNode one or more metadata vNodes in that pNode can be relocated to another pNode that has more network capacity available. Similarly if a pNode runs out of disk capacity a new data vNode can be created on other pNodes or a vNode can be relocated to another pNode with more disk capacity. In one embodiment this migration is achieved by creating a new replica of the source vNode at the destination pNode. The vNode at the destination pNode is populated in parallel from the replicas of the source vNode. While the destination vNode is being updated the source vNode may change due to new I O from the client. This new I O is be appended to the source vNode and assigned new logical sequence ID. The destination vNode will continuously sync from the source based on these sequence IDs. Once they are in sync the vNode to pNode mapping in the Cluster Manager s routing table is updated so that I Os are routed to the new location. This ensures that the storage service remains uninterrupted when a vNode is being moved. This load distribution happens on a continuous basis and ensures that resources are utilized optimally and each workload receives the resource it need.

In one embodiment the StorFS system is capable of supporting different policies at different level of granularity at the file system level at the individual file level etc. These policies specify the performance reliability and other quality of service requirements of the applications. The system translate these high level polices to low level system configuration. For example the StorFS system is able to automatically select the type of storage medium SSD v. HDD based on application performance requirement. Similarly based on these policies the StorFS system can decide whether to compress or de duplicate the data the level of mirroring etc.

Data services like snapshot cloning backup disaster recovery etc. can be critical for any enterprise storage systems. A na ve way to implement such data services is to perform a full copy of the current storage. This is however very inefficient and takes lot of time and resources. More advanced storage systems implement these data services by keeping track of changes since the clones or snapshots were created instead of full copy. This consumes less storage resources. Single node data services are relatively easier to build as the metadata is readily available in one central place. Building efficient data services in a distributed storage system poses significant challenges.

In one embodiment the StorFS system uses techniques to efficiently track changes in a distributed setting. For example and in one embodiment the StorFS is capable of performing low overhead data services at different level of granularity from the file system level to the individual files level. As discussed above the StorFS system stripes file and file system data across multiple storage nodes in our cluster. Snapshotting a file for example involves creating a small metadata entry in the storage vNodes containing that file. This snapshot process is extremely fast and require minimal amount of resources. There is no data copy involved. Furthermore the StorFS permits creating large number of snapshots or clones without any deterioration in performance.

As shown in the computer system which is a form of a data processing system includes a bus which is coupled to a microprocessor s and a ROM Read Only Memory and volatile RAM and a non volatile memory . The microprocessor may retrieve the instructions from the memories and execute the instructions to perform operations described above. The bus interconnects these various components together and also interconnects these components and to a display controller and display device and to peripheral devices such as input output I O devices which may be mice keyboards modems network interfaces printers and other devices which are well known in the art. Typically the input output devices are coupled to the system through input output controllers . The volatile RAM Random Access Memory is typically implemented as dynamic RAM DRAM which requires power continually in order to refresh or maintain the data in the memory.

The mass storage is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD RAM or a flash memory or other types of memory systems which maintain data e.g. large amounts of data even after power is removed from the system. Typically the mass storage will also be a random access memory although this is not required. While shows that the mass storage is a local device coupled directly to the rest of the components in the data processing system it will be appreciated that the present invention may utilize a non volatile memory which is remote from the system such as a network storage device which is coupled to the data processing system through a network interface such as a modem an Ethernet interface or a wireless network. The bus may include one or more buses connected to each other through various bridges controllers and or adapters as is well known in the art.

Portions of what was described above may be implemented with logic circuitry such as a dedicated logic circuit or with a microcontroller or other form of processing core that executes program code instructions. Thus processes taught by the discussion above may be performed with program code such as machine executable instructions that cause a machine that executes these instructions to perform certain functions. In this context a machine may be a machine that converts intermediate form or abstract instructions into processor specific instructions e.g. an abstract execution environment such as a process virtual machine e.g. a Java Virtual Machine an interpreter a Common Language Runtime a high level language virtual machine etc. and or electronic circuitry disposed on a semiconductor chip e.g. logic circuitry implemented with transistors designed to execute instructions such as a general purpose processor and or a special purpose processor. Processes taught by the discussion above may also be performed by in the alternative to a machine or in combination with a machine electronic circuitry designed to perform the processes or a portion thereof without the execution of program code.

The present invention also relates to an apparatus for performing the operations described herein. This apparatus may be specially constructed for the required purpose or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but is not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine e.g. a computer . For example a machine readable medium includes read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices etc.

An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as but is not limited to one or more memories e.g. one or more flash memories random access memories static dynamic or other optical disks CD ROMs DVD ROMs EPROMs EEPROMs magnetic or optical cards or other type of machine readable media suitable for storing electronic instructions. Program code may also be downloaded from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a propagation medium e.g. via a communication link e.g. a network connection .

The preceding detailed descriptions are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the tools used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of operations leading to a desired result. The operations are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be kept in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion it is appreciated that throughout the description discussions utilizing terms such as receiving determining transmitting computing sending forwarding dispatching detecting performing scheduling communicating reading writing transferring updating returning merging appending fetching or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The processes and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform the operations described. The required structure for a variety of these systems will be evident from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

The foregoing discussion merely describes some exemplary embodiments of the present invention. One skilled in the art will readily recognize from such discussion the accompanying drawings and the claims that various modifications can be made without departing from the spirit and scope of the invention.

