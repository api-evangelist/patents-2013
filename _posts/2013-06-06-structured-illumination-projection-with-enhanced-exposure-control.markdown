---

title: Structured illumination projection with enhanced exposure control
abstract: A method for controlling a structured illumination pattern generating portion is provided for illuminating a workpiece during an image acquisition by a camera in a precision machine vision inspection system. A controllable spatial light modulator (e.g., a digital light processing projector) is part of the generating portion for generating the structured illumination pattern. The pattern may comprise an array of stripes including a sinusoidal gray level intensity variation across each stripe. An overall image exposure is increased by repeating a complete structured illumination pattern generation iteration, including gray level variation, a plurality of times during an image integration period. Structured illumination microscopy techniques for determining a workpiece surface profile may benefit, wherein multiple (e.g., 3 or 4) images are acquired at respective focus positions to be analyzed, by using the method to project a different phase of a structured light pattern for each of the multiple images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09350921&OS=09350921&RS=09350921
owner: Mitutoyo Corporation
number: 09350921
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20130606
---
Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions to allow workpiece inspection. One exemplary prior art system that can be characterized as a general purpose off line precision vision system is the commercially available QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the QVPAK 3D CNC Vision Measuring Machine User s Guide published January 2003 and the QVPAK 3D CNC Vision Measuring Machine Operation Guide published September 1996 each of which is hereby incorporated by reference in their entirety. This type of system is able to use a microscope type optical system and move the stage so as to provide inspection images of either small or relatively large workpieces at various magnifications.

General purpose precision machine vision inspection systems such as the QUICK VISION system are also generally programmable to provide automated video inspection. U.S. Pat. No. 6 542 180 the 180 patent teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the 180 patent automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text based programming for example or through a recording mode which progressively learns the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface or through a combination of both methods. Such a recording mode is often referred to as learn mode training mode or record mode. Once the inspection event sequence is defined in learn mode such a sequence can then be used to automatically acquire and additionally analyze or inspect images of a workpiece during run mode. 

The machine control instructions including the specific inspection event sequence i.e. how to acquire each image and how to analyze inspect each acquired image are generally stored as a part program or workpiece program that is specific to the particular workpiece configuration. For example a part program defines how to acquire each image such as how to position the camera relative to the workpiece at what lighting level at what magnification level etc. Further the part program defines how to analyze inspect an acquired image for example by using one or more video tools such as edge boundary detection video tools.

Video tools or tools for short and other graphical user interface features may be used manually to accomplish manual inspection and or machine control operations in manual mode . Their set up parameters and operation can also be recorded during learn mode in order to create automatic inspection programs or part programs. Video tools may include for example edge boundary detection tools autofocus tools shape or pattern matching tools dimension measuring tools and the like. It is generally desirable that complex hardware and software operations and or analysis are performed automatically e.g. without requiring user observation and or intervention in association with various video tools and or selectable operating modes. In that case relatively unskilled users may easily and transparently implement such complex operations and or analysis to achieve better measurement accuracy and or reliability.

Accuracies in the micron or sub micron range are often desired in such systems. This is particularly challenging with regard to Z height measurements. Z height measurements along the optical axis of the camera system are generally derived from a best focus position such as that determined by an autofocus tool. Determining a best focus position is a relatively complex process that generally depends on combining and or comparing information derived from multiple images. Thus the level of precision and reliability achieved for Z height measurements is often less than that achieved for the X and Y measurement axes where measurements are typically based on feature relationships within a single image. Recently known techniques generally referred to as structured illumination microscopy SIM methods are being incorporated in microscopic measurement and inspection systems in order to increase their measurement resolution and or accuracy beyond the optical limits normally associated with simple imaging e.g. to the micron and submicron level. 

Briefly many SIM methods include projecting a pattern of light stripes onto a workpiece in a first image and then shifting that pattern on the workpiece transversely to the stripes in a second image and so on for a third image or more. The resulting images may be analyzed according to known methods to improve the surface measurement resolution as described in greater detail below. Such techniques may enhance X Y and or Z measurements. However the systems and methods used in known structured illumination pattern SIP generating subsystems e.g. for forming and shifting the patterns have so far limited the economy versatility and or resolution and accuracy improvements of practical SIM systems in undesirable ways. In some methods of analysis it is desirable for the stripes to exhibit a sinusoidal intensity profile across the stripes. The article Autoexposure for Three Dimensional Shape Measurement Using a Digital Light Processing Projector by Ekstrand and Zhang in Optical Engineering 50 12 123603 December 2011 which is hereby incorporated herein in its entirety as a reference indicative of the state of the art states 

Some have solved this problem by using a prefabricated grayscale projection mask that effectively includes more than 8 bit resolution. The image exposure can be controlled by the exposure time Ekstrand and Zhang propose a solution to this problem that includes a projector defocusing technique. Their technique may use non sinusoidal structured patterns e.g. including binary patterns . The sinusoidal stripe patterns are realized by properly defocusing the projector. Because this defocusing technique alleviates the grayscale generation demands on the DLP an arbitrary exposure time can be used with the DLP in order to achieve a desired image exposure.

While the foregoing solutions allow projecting a sinusoidal stripe pattern with a versatile exposure time they have undesirable characteristics. For example a fixed mask lacks versatility and requires an expensive and bulky mechanical translation system in order to provide the desired shifts of the pattern position on the workpiece. The defocusing technique of Ekstrand and Zhang may require additional and or adjustable optical elements to provide the defocus and or may limit versatility in terms of minimum defocused stripe spacing and or may cause undesirable and or unpredictable interactions with the focus variations used for Z height points from focus techniques used in some precision machine vision inspection systems. Thus an improved method for economically generating a structured illumination pattern SIP that includes good grayscale resolution at a wide variety of exposure levels would be desirable.

A method is provided for controlling a structured illumination pattern generating portion used to illuminate a workpiece with a structured illumination pattern during an image acquisition by a camera portion in a precision machine vision inspection system. The structured illumination pattern generating portion comprises a structured illumination pattern controller a controllable spatial light modulator SLM and a light generator. The controllable SLM e.g. a digital light processing array such as a micro mirror array is controlled for generating the structured illumination pattern and the light generator emits radiation to the SLM. An image is acquired during an image integration period of the camera. The overall exposure is increased during the image integration period by a first exposure increment by generating a first complete structured illumination pattern iteration including gray level variations. The overall exposure is further increased during the image integration period by at least a second exposure increment by generating at least a second complete structured illumination pattern iteration including gray level variations.

In various implementations the second exposure increment and the first exposure increment may be substantially the same. The light generator may be operated to emit substantially the same radiation intensity during the first and second complete structured illumination pattern iterations. A ratio of the radiation intensity to a maximum controllable radiation intensity may be greater than 0.6. The structured illumination patterns may comprise an array of stripes including an approximately sinusoidal variation in gray level intensity across a stripe.

The at least a second exposure increment may further comprise a least significant bit LSB exposure increment that is less than the first and second exposure increments. The method may further comprise operating the light generator to emit a first radiation intensity during the first and second complete structured illumination pattern iteration and to emit an LSB radiation intensity that is less than the first radiation intensity during the complete structured illumination pattern iteration corresponding to the LSB exposure increment.

The image integration period of the camera may be a time period TIP and the method may further comprise generating each complete structured illumination pattern iteration including gray level variations within a respective time period TCPi wherein each respective time period TCPi is at most Ti 4. At least one of the respective time periods TCPi may correspond to the shortest possible time period allowed by the structured illumination pattern generating portion.

The image integration period of the camera may be a time period TIP comprising N equal subperiods TCPn and the method may further comprise generating each complete structured illumination pattern iteration including gray level variations within a respective subperiod TCPn. The structured illumination pattern SIP generating portion may further be operated such that no exposure increment occurs within at least one respective subperiod TCPn.

Generating the first complete structured illumination pattern iteration may comprise generating a first pattern subdivision exposure sequence comprising a plurality of respective pattern portions exposed using respective first iteration intensities of radiation from the light generator during respective first iteration subdivision times. Generating the at least a second complete structured illumination pattern iteration including gray level variations may comprise generating at least a second pattern subdivision exposure sequence comprising a plurality of respective pattern portions exposed using respective iteration intensities of radiation from the light generator during respective iteration subdivision times. At least the first and a second pattern subdivision exposure sequences may be identical.

The at least a second exposure increment may comprise an LSB exposure increment that is different than the first and second exposure increments. The method may further comprise generating the LSB exposure increment by generating a complete structured illumination pattern iteration including gray level variations by generating an LSB pattern subdivision exposure sequence comprising a plurality of respective pattern portions exposed using respective LSB iteration intensities of radiation from the light generator during respective LSB iteration subdivision times. The method may further include at least one of a making the respective LSB iteration intensities less than the corresponding respective first and second iteration intensities and b making the respective LSB iteration subdivision times less than the corresponding first and second iteration subdivision times. Alternatively the method may further include at least one of a making the respective LSB iteration intensities greater than the corresponding respective first and second iteration intensities and b making the respective LSB iteration subdivision times greater than the corresponding first and second iteration subdivision times.

The image integration period of the camera may be a time period TIP comprising N equal subperiods TCPn and the first and second complete structured illumination pattern iterations may correspond to approximately a 100 duty cycle and may be provided during one subperiod TCPn each. An LSB structured illumination pattern corresponding to a duty cycle between 0 and 100 may be provided during one subperiod TCPn with structured illumination patterns corresponding to either a 0 or 100 duty cycle being provided during the remaining subperiods TCPn of the time period TIP.

The acquired image may be one of a stack of images that is acquired. The stack of images may be acquired utilizing structured illumination microscopy such that for each stack image acquired at a given Z height the SIP that is provided by the SIP generating portion is phase shifted relative to the SIPs that are provided for the other stack images at the corresponding Z height. The first and second complete structured illumination pattern iterations may be repeated for the acquisition of each image in the stack.

Various embodiments of the invention are described below. The following description provides specific details for a thorough understanding and an enabling description of these embodiments. One skilled in the art will understand however that the invention may be practiced without many of these details. In addition some well known structures or functions may not be shown or described in detail so as to avoid unnecessarily obscuring the relevant description of the various embodiments. The terminology used in the description presented below is intended to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific embodiments of the invention.

Those skilled in the art will appreciate that the controlling computer system may generally consist of any computing system or device. Suitable computing systems or devices may include personal computers server computers minicomputers mainframe computers distributed computing environments that include any of the foregoing and the like. Such computing systems or devices may include one or more processors that execute software to perform the functions described herein. Processors include programmable general purpose or special purpose microprocessors programmable controllers application specific integrated circuits ASICs programmable logic devices PLDs or the like or a combination of such devices. Software may be stored in memory such as random access memory RAM read only memory ROM flash memory or the like or a combination of such components. Software may also be stored in one or more storage devices such as magnetic or optical based disks flash memory devices or any other type of non volatile storage medium for storing data. Software may include one or more program modules which include routines programs objects components data structures and so on that perform particular tasks or implement particular abstract data types. In distributed computing environments the functionality of the program modules may be combined or distributed across multiple computing systems or devices and accessed via service calls either in a wired or wireless configuration.

The vision components portion includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. The machine vision inspection system is also described in commonly assigned U.S. Pat. Nos. 7 454 053 7 324 682 8 111 905 and 8 111 938 which are each incorporated herein by reference in their entireties.

The vision components portion includes an optical assembly portion light sources and and a workpiece stage having a central transparent portion . The workpiece stage is controllably movable along X and Y axes that lie in a plane that is generally parallel to the surface of the stage where a workpiece may be positioned. The optical assembly portion includes a camera system an interchangeable objective lens and may include a turret lens assembly having lenses and . Alternatively to the turret lens assembly a fixed or manually interchangeable magnification altering lens or a zoom lens configuration or the like may be included.

The optical assembly portion is controllably movable along a Z axis that is generally orthogonal to the X and Y axes by using a controllable motor that drives an actuator to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece . Of course in other embodiments the stage could be moved along the Z axis relative to a static optical assembly in a known manner. The controllable motor is connected to the input output interface via a signal line .

A workpiece or a tray or fixture holding a plurality of workpieces which is to be imaged using the machine vision inspection system is placed on the workpiece stage . The workpiece stage may be controlled to move relative to the optical assembly portion such that the interchangeable objective lens moves between locations on a workpiece and or among a plurality of workpieces .

As will be described in more detail below for certain SIM operations the workpiece may be illuminated by SIP source light provided from the structured illumination pattern generating portion . The structured illumination pattern generating portion configures the structured illumination pattern that is output to the workpiece . One or more of a stage light a coaxial light structured illumination pattern generating portion and a surface light e.g. a ring light may emit source light and or respectively to illuminate the workpiece or workpieces . The light source may emit source light and the structured illumination pattern generating portion may emit SIP source light along a shared path including a beamsplitter as described in greater detail with reference to . The source light is reflected or transmitted as workpiece light and the workpiece light used for imaging passes through the interchangeable objective lens and the turret lens assembly and is gathered by the camera system . The image of the workpiece s captured by the camera system is output on a signal line to the control system portion . The light sources and the structured illumination pattern generating portion may be connected to the control system portion through signal lines or busses and respectively. To alter the image magnification the control system portion may rotate the turret lens assembly along an axis to select a turret lens through a signal line or bus .

In various exemplary embodiments the optical assembly portion is movable in the vertical Z axis direction relative to the workpiece stage using a controllable motor that drives an actuator a connecting cable or the like to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece captured by the camera system . The term Z axis as used herein refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor when used is connected to the input output interface via a signal line .

As shown in in various exemplary embodiments the control system portion includes a controller an input output interface a memory a workpiece program generator and executor and a power supply portion . Each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface may include a position control element and a speed acceleration control element although such elements may be merged and or indistinguishable. The lighting control interface includes lighting control elements that control for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system . The lighting control interface also includes a lighting control element that in the illustrated embodiment works in conjunction with the structured illumination pattern SIP generating portion to provide structured illumination during image acquisitions and particularly during a SIM mode image acquisitions as described in greater detail below.

The memory may include an image file memory portion a SIM SIP memory portion a workpiece program memory portion that may include one or more part programs or the like and a video tool portion . The video tool portion includes video tool portion and other video tool portions e.g. that determine the GUI image processing operation etc. for each of the corresponding video tools and a region of interest ROI generator that supports automatic semi automatic and or manual operations that define various ROIs that are operable in various video tools included in the video tool portion .

In the context of this disclosure and as known by one of ordinary skill in the art the term video tool generally refers to a relatively complex set of automatic or programmed operations that a machine vision user can implement through a relatively simple user interface e.g. a graphical user interface editable parameter windows menus and the like without creating the step by step sequence of operations included in the video tool or resorting to a generalized text based programming language or the like. For example a video tool may include a complex pre programmed set of image processing operations and computations which are applied and customized in a particular instance by adjusting a few variables or parameters that govern the operations and computations. In addition to the underlying operations and computations the video tool comprises the user interface that allows the user to adjust those parameters for a particular instance of the video tool. For example many machine vision video tools allow a user to configure a graphical region of interest ROI indicator through simple handle dragging operations using a mouse in order to define the location parameters of a subset of an image that is to be analyzed by the image procession operations of a particular instance of a video tool. It should be noted that the visible user interface features are sometimes referred to as the video tool with the underlying operations being included implicitly.

The video tool portion also includes Z height measurement tools portion which provides various operations and features related to Z height measurement operations as described in greater detail below. In one embodiment the Z height measurement tools portion may include Z height tools and Z height tools SIM SIP mode control . The Z height tools may include an autofocus tool and a multipoint autofocus tool for example. The Z height tools SIM SIP mode control may govern certain aspects of image stack acquisition and related structured light pattern generation operations in conjunction with the Z height tools that are configured in a mode that determines best focus heights and or Z height measurements based on SIM techniques e.g. as described further below .

Briefly the Z height measurement tools portion may perform at least some operations similarly to known Z height measurement tools for example performing operations in learn mode and run mode for generating all or part of a focus curve and finding its peak as a best focus position. The Z height measurement tools portion may perform at least some operations similarly to known Z height measurement tools for example performing operations in learn mode and run mode for generating all or part of a focus curve and finding its peak as a best focus position. Additional Z height measurement tool operations which are the subject of this disclosure are described in greater detail below.

Alternative configurations are also possible for the Z height measurement tools portion . For example the Z height tools may provide additional Z height measurement tool elements or the Z height tools may have a selectable mode option that controls whether they are configured to operate in a conventional contrast based analysis mode that uses conventionally lighted images e.g. using the light source to provide source light or a SIM based analysis mode that uses images lighted with specific structured illumination patterns e.g. using the structured illumination pattern generating portion to provide SIP source light . In either case the SIM SIP mode control may provide operations that govern the user interface and interrelationships of the Z height measurement tool elements in a manner that corresponds to their operating mode and or use of SIM image acquisition and analysis techniques. More generally this invention may be implemented in any now known or later developed form that is operable in conjunction with the machine vision inspection system to provide the features disclosed herein in relation to measurement operations based on SIM image acquisition and analysis techniques.

The signal line from the camera system and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller or elsewhere that initiates image acquisition. One or more display devices e.g. the display of and one or more input devices e.g. the joystick keyboard and mouse of can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various graphical user interface GUI features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera system and or to directly control the vision system components portion . The display devices may display user interface features associated with the video tools

In operation the light generator may emit light through a first part of the SIP optical portion such that it is properly configured e.g. collimated to illuminate an illumination area the pixel array of the SLM . The SLM may then generally transmit partially transmit or block light according to known methods to transmit or project a desired pattern along an optical path through the remainder of the SIP optical portion . As shown in the projected pattern is output from the SIP optical portion to be input to the beamsplitter where it is directed as coaxial light through the objective lens to provide SIP source light to illuminate the field of view.

In some embodiments the SLM may comprise a transmissive LCD type array such as a micro display graphics array from Forth Dimension Displays headquartered in Dalgety Bay Fife Scotland United Kingdom which includes an LCD pixel array that may generally be controlled by conventional video signals if desired and may be used to display an electronically generated 8 bit grayscale pattern that may transmit partially transmit or block the light through any given pixel of the pattern depending on its grayscale value. However the methods disclosed herein may be used to enhance certain advantages associated with an SLM comprising an arrangement of any now known or later developed type of controllable reflective shutters that can provide controllable light deflection in a desired pattern. One type of controllable reflective shutter array that may be used includes liquid crystal on silicon LCOS micro display products for example from Forth Dimension Displays headquartered in Dalgety Bay Fife Scotland. Various embodiments described below generally incorporate another type of array which is digital micromirror device DMD . DMDs and associated components are available for example from Texas Instruments DLP Products Plano Tex. DLP generally stands for digital light processing which is associated with the fact that the array elements in DMD devices are either in an on position or off position and projected transmitted grayscale patterns must be generated over a time as an accumulated sequence of superimposed binary patterns. The systems and methods disclosed herein are particularly advantageous for overcoming certain deficiencies of known DLP control methods and more particularly in relation to enhancing the accuracy of SIM techniques that are used to provide high accuracy measurements and the like.

In various embodiments the light generator may be used in a strobe illumination mode of operation to provide a combination of a very fast light generator response time in the s or ns range at suitable optical power levels. One example of a light generator may include one or more high intensity light emitting diodes LEDs such as one of the LEDs in the Luxeon product line available from Philips Lumileds Lighting Company of San Jose Calif.

In the embodiment shown in the SLM may be a commercially available DMD and the SLM controller portion may be a companion digital controller chip such as the chip sets available from Texas Instruments DLP Products referenced above. The SLM controller portion may respond to desired grayscale pattern definitions or requests and generate the synchronized control signals to the SLM and the light generator that provide the accumulated sequence of superimposed binary patterns that generate the desired grayscale pattern over time. However commercial SLM controllers have certain deficiencies for example as summarized previously in the Background section of this disclosure and as further outlined with reference to below. In the illustrated embodiment the TSP is used in conjunction with the SLM controller portion to overcome or reduce these deficiencies for example by allowing the grayscale control finer than 256 bits and or other advantages in some embodiments or implementations. In various embodiments the TSP may receive grayscale pattern and exposure level requests or control signals from the SIP lighting control element and or the SIM SIP memory portion which may store predetermined or learned control signal configurations or parameters related to various desired patterns over the line or buss . The TSP may then process the received signals and send multiple incremental grayscale pattern requests to the SLM controller portion such that the SLM controller portion may generate each of the incremental grayscale patterns with 256 bit resolution over time using its native control routines and circuits to control the SLM and the light generator . The TSP may thus control an overall image exposure achieved by the multiple incremental grayscale patterns because it may control the number of incremental requests within an image integration period of the camera which it may exchange control signals with over the line . In various embodiments some of the incremental requests may be for identical patterns and or exposure increments. In some embodiments one or more of the incremental requests may be for different patterns and or exposure increments. Greater than 256 bit grayscale resolution for the illumination pattern may be achieved in this manner if desired. In general it is desirable that the TSP provides dedicated processing and deterministic timing in relation to the control signals it receives and or sends to various components. In some embodiments the TSP may therefore comprise a programmable logic array or the like. In some optional embodiments rather than the SLM controller portion directly controlling the light generator the line may be omitted and a light control timing signal from the SLM controller portion may be output to the TSP on the line and the TSP may control the light generator over the line based on the timing signal from the SLM controller portion . This may allow providing additional features and or precise customized control of the light generator within the timing window required by the native operations of the SLM controller portion . Various features and operations outlined above are described in greater detail below.

The diagram illustrates a pattern subdivision exposure sequence comprising a plurality of respective pattern portions P P also referred to as subdivision pattern portions exposed using respective iteration intensities of radiation from a light generator during respective iteration subdivision times T T respectively. The pattern subdivision exposure sequence builds a simple 4 bit gray level sine wave pattern for the purpose of illustrating the basic principles that are relevant to this disclosure.

The diagram includes corresponding elements that are vertically aligned along pixel columns across light stripe. A truncated plan view shows a roughly sinusoidal gray level intensity variation GLV across the single structured illumination light stripe LS which is a stripe extending along the direction Ys. The lighter and darker shadings across the stripe LS represent the accumulated exposure or net intensity resulting from the intensity pattern subdivision exposure sequence which is designated PatIter k indicating that it may correspond to a complete grayscale pattern exposure iteration or increment k e.g. k 1 2 3 etc. as described further below. This particular stripe is lightest along the pixel column d and darkest along pixel columns a and a . Immediately above the plan view representation of PatIter k is a graph schematically representing the contributions to the net intensity profile across the PatIter k. The graph uses crosshatch patterns that are coded to be the same as the crosshatch patterns used to indicate the pixel columns that are activated to provide the respective subdivision pattern portions P P during respective subdivision times T T. It is assumed that the light generator is set to the same intensity for each of the times T T such that the accumulated intensity is proportional to the times. The times T T are binary subdivisions that is T 2 T T 2 T and T 2 T. It is shown that the pixels of the brightest Col. d are on in each of the subdivision pattern portions P P to provide the net intensity ni. The pixels of the next brightest columns c and c are on in each of the subdivision pattern portions except P to provide the net intensity ni. The pixels of the next brightest columns b and b are on only in the subdivision pattern portions P and P to provide the net intensity ni and the darkest columns a and a are on only in the subdivision pattern portion P to provide the net intensity ni. The timing diagram shows that the total time to generate the gray level strip pattern PatIter k is TIter k assuming negligible time between the time periods T T for the purposes of this illustration. It will be appreciated that latency times delays and the like may be calibrated or determined for particular machines light generators voltage levels etc. by design and or experiment and the results calibrated or stored e.g. in the SIM SIP memory portion such that a combination of timing operating voltages and the like that provide a desired or calibrated illumination level may be readily determined and or compensated for e.g. in the operation of the SIP controller .

The typical native control method outlined above may be used in DLP controllers e.g. in a digital DMD controller that adjust the overall time TIter k and or the light generator intensities used during the subdivision times to achieve a desired net gray level intensity pattern.

A general transfer function for a sine pattern exposure during a single image as outlined above with reference to may be expressed as 

Where PatIter k the k th iteration of a complete gray level pattern e.g. a stripe having a sinusoidal gray level intensity profile across the stripe within an image exposure period Ti a pattern generation time subdivision e.g. one of the time subdivisions T T as illustrated in Pi Pattern subdivision i e.g. the partial pattern of SLM pixels that is on during one of the pattern generation time subdivisions Ti e.g. one of the pattern subdivisions P P as illustrated in Ii Light intensity during the time subdivision Ti. In certain configurations binary time subdivisions are implemented such that Ti T i 1 2 i 1 and a constant intensity may be utilized throughout a single set of the pattern subdivisions such that I I I as implied in the illustration shown in .

The typical native control method outlined above which adjusts the overall time TIter k which is equivalent to increasing each of the times Ti and or the light generator intensities Li used during the subdivision times to achieve a desired net gray level intensity pattern increase. However this approach leads to previously outlined deficiencies and the inventor has found that SIM measurement accuracy may be sensitive to some selections of these variables that would be of no consequence in many other applications. Therefore the typical native control method for DLP s is inadequate for certain high resolution precision machine vision inspection operations and certain high accuracy SIM applications in particular. Related problems and solutions are described in greater detail below.

As a background for appreciating benefits of the systems and methods disclosed herein are used to briefly explain one exemplary known SIM technique for the purpose of illustrating the sensitivity of the technique to variations in the intensity and or intensity profile of the structured illumination used for the analyzed images. is used to explain a more subtle and underappreciated sensitivity to the structured illumination method that is relevant to certain applications of the SIM technique.

As shown in a series A of three phase shifted images I I that is with the illumination pattern phase shifted are captured at a vertical position Za. The small image of the optical system in shows that the projected illumination arising from the source SA as well as the imaging system are focused at a plane FP and the Z height Za is far from FP. As a result the corresponding modulation depth MDa is relatively small. As shown in a series B of three phase shifted images I Iare captured at a vertical position Zb. The small image of the optical system in shows that the projected illumination arising from the source SA as well as the imaging system are focused at a plane FP and the Z height Zb is closer to FP than was Za. As a result the corresponding modulation depth MDb is relatively larger than MDa. As shown in a series C of three phase shifted images I Iare captured at a vertical position Zc. The small image of the optical system in shows that the projected illumination arising from the source SA as well as the imaging system are focused at a plane FP and the Z height Zc is approximated at FP. As a result the corresponding modulation depth MDc is approximately as large as possible.

As shown in the modulation depths MDa MDc are plotted against their corresponding Z heights labeled vertical sample position and a modulation depth curve MC is fitted to the plotted points. The peak of the modulation depth curve MC indicates the Z height where the corresponding pixel location on the workpiece is in focus.

The SIM techniques outlined above are known to be capable of producing high resolution Z height measurements with high lateral resolution. However as will be apparent to one skilled in the art the accuracy of the techniques depends on fulfilling the assumptions that the intensity in each image is at the expected level e.g. the same in each image or otherwise known an compensated and the intensity profile of the light stripe in each image is the same and of a known shape . In one sense the systems and methods disclosed are directed to better fulfilling these assumptions over a wider exposure range in an economical manner. It should be understood that due to the high resolution potential of the SIM technique that even very small variations in the intensity and or intensity profile are significant to the resulting accuracy.

The illustration portion and the terminology used below will be understood based on the previous description of . In illustration portion the workpiece surface WS is represented as moving down at a constant speed in the figure relative to a focal plane of a structured illumination projection system and an imaging system. For purposes of the present discussion it is assumed that for sufficient image exposure the time TIter k described with reference to is extended and thus the subdivision times T T are extended as required and a single iteration of the pattern is used for image exposure.

In the illustration portion portions of the surface WS that pass through the best focus height for illumination and imaging are shown with a bold line. As shown in the first time slice representation during the subdivision T the portion of the surface WS that is illuminated and imaged at the best focus height as the surface WS moves down along the focus axis corresponds to the pixel columns c d and c of the light stripe. It is seen that the portions of the surface corresponding to the pixel columns a b b and a of the light stripe are generally not well focused. They should receive very little of the subdivision pattern portion P but may receive a blurred border of the subdivision pattern P because they are out of focus. In the second time slice representation during the subdivision T the portion of the surface WS that is illuminated and imaged at the best focus height as the surface WS moves down along the focus axis corresponds to the pixel columns b b and a of the light stripe. It is seen that the portions of the surface corresponding to the pixel columns a c d and c of the light stripe are generally not well focused. They should receive very little of the subdivision pattern portion P but may receive a blurred border of the subdivision pattern P because they are out of focus. In the third time slice representation during the subdivision T the portion of the surface WS that is illuminated and imaged at the best focus height as the surface WS moves down along the focus axis corresponds to the pixel column a of the light stripe. It is seen that the portions of the surface corresponding to the pixel columns b c d c b and a of the light stripe are generally not well focused. Except for column a they should receive the subdivision pattern portion P but receive only a blurred version of the subdivision pattern P because they are out of focus. In the fourth time slice representation during the subdivision T none of the surface WS is illuminated and imaged at the best focus height as the surface WS moves down along the focus axis. All columns should receive the subdivision pattern portion P but receive only a blurred version of the subdivision pattern P because they are all out of focus to varying degrees.

In the foregoing example and description the Z height relationships and effects are exaggerated to more clearly illustrate the problem. However it will be understood that none of the workpiece surface e.g. none of the pixel column locations a a receive the intended intensity contributions and or provide the intended image contributions intended for the intensity profile PatIter k due to the focus variations arising from the surface profile variation in combination with the Z motion during the subdivision times T T. Stated another way because of the way a gray level sine wave intensity profile is built over time by a typical DLP controller different surface heights of the object may essentially receive a different subdivision pattern i.e. an incomplete sampling of the sine pattern which indicates that the height information contrast etc. may be distorted. Or conversely over the full exposure period the image of the stripe may be focus weighted e.g. blurred differently in different regions in the subdivision patterns and therefore does not exhibit the intended ideal sine profile. In certain implementations this may be considered to violate the assumptions used in various previously outlined SIM equations and algorithms. These deleterious effects which may disturb both the overall stripe intensity and the imaged stripe intensity profile apply to any image acquired during a Z motion to some extent. The only solution that completely eliminates these problems is to stop the workpiece motion during each image acquisition e.g. the times T T which is undesirable with regard to throughput considerations. An alternative which significantly reduces the problem and increases accuracy is described in greater detail below with reference to .

The problem outlined with reference to shows that the previously described typical e.g. native gray level illumination pattern generation sequence may limit accuracy and or throughput when it stretches subdivision times to increase the exposure of an image e.g. due to low surface reflectance or the like . It is desirable to avoid this. Furthermore another potential downside to this kind of native control operation is that the overall projection duration may be different for each brightness level setting. These differences in duration of operation will vary heat generation of the structured illumination pattern generating portion and affect its repeatability between images. For example the repeatability of the light generator spectrum e.g. from one or more LEDs and or thermal expansion effects and or detector sensitivity and or various circuit components may all be affected. Furthermore another potential downside to this kind of native control operation is that the overall light generator intensity whether controlled through drive current or pulse width modulation or both may be different for each brightness level setting. In certain implementations dim scenes may require projection intensity or duty cycles levels close to 100 while highly reflective scenes may require intensity or duty cycles levels closer to 9 . However any InGaN based LED blue green white for example will have a different emission spectrum based on the drive current and the pulse duration. Typical shifts in dominant wavelength are on the order of 2 3 nm without active heat sinks e.g. Peltier coolers . Such variations may interact with detector sensitivities and or workpiece reflectance sensitivity to wavelength to create unpredictable image intensity and or spectrum variations from the expected values. It is desirable to avoid this.

Pattern brightness global or local pattern attenuation may also be varied by projecting with less than 8 bits. However this strategy reduces the amplitude and resolution of the intensity profile of the projected sine patterns adversely affecting the signal to noise ratio of the technique and may further violate the assumptions of SIM analysis if the shape of the intensity profile is actually altered by the reduced gray level resolution e.g. due to digitization errors and the like. 

As will be described in more detail below with respect to an alternative method is provided for controlling the brightness of a structured illumination pattern e.g. in an implementation utilizing SIM techniques . In various embodiments a DLP controller is part of a system and method that controls the image brightness by causing the DLP controller to generate the required instances of gray level patterns using a relatively consistent on time e.g. the time TIter k . Instead of increasing an exposure level by increasing the on time of a single gray level pattern generation sequence the method disclosed below causes the DLP controller to generate the gray level pattern sequence over a limited time and then repeat the generation of the gray level pattern sequence for a number of iterations in order to achieve the desired exposure level. In one specific implementation of this method a DMD e.g. DLP5500 and control electronics e.g. DLPC200 DLPA200 as well as an LED light generator are operated at a relatively consistent maximum operating speed of the DMD. In one implementation this is accomplished by dividing an image integration period into time periods in which complete structured illumination pattern iterations including gray level variations are generated and repeated. For example some versions of the components referred to previously have the capability to generate 8 bit gray level patterns as fast as 716 Hz 1.390 ms . A typical camera image acquisition frame rate may be 68 Hz e.g. a camera integration period on the order of 14.705 ms . Consequently these values may be up to approximately ten iterations of an 8 bit gray level pattern generation sequence i.e. 14.705 ms 1.390 ms in order to increase an exposure level during an image acquisition period. In one specific example implementation of this technique the image integration period may be divided into 9 time periods rather than 10 e.g. to allow for various time delays and latencies in the system and at least some of the complete structured illumination pattern iterations that are repeated in the time periods may correspond to the components being operated at a high in one implementation at the highest operating speed of the DMD and its controller e.g. 11.1 9 100 duty cycle . In this way the heat generation and light emission spectrum are relatively constant thus reducing variability in the projection components and the resulting structured illumination pattern.

The second timeline represents a camera integration duration that may have a controlled duration Tei Tsi . The controlled duration may be controlled based on a high speed clock such that it is relatively consistent. The camera integration duration may start at integration begin time Tsi and end at integration end time Tei. In some implementations the integration begin time Tsi may occur during a discrete latency period Tsi Tpta after the position trigger time Tpta has been used to initiate a camera integration period. The latency period may be relatively consistent or predictable in various systems.

The third timeline represents iterations of an illumination pattern trigger signal that may occur at some or all of the times Tptk where k 1 to 7 in this particular example depending on the required exposure level in order to trigger the corresponding gray level pattern generation sequence s represented by the signals on the timeline . For example in some embodiments an illumination pattern trigger signal may always be provided at the time TptC Tpt at the center of the camera integration period and corresponding to a time Txyz at which a position signal may be latched by a position latch signal shown on the timeline to best represent the image position of the image acquired during the camera integration period e.g. in case the camera and or workpiece are moving during the image acquisition . The time Txyz may be set at a predetermined time delay relative to the pattern trigger signal time TptC in various embodiments.

Each resulting gray level pattern generation sequence PatIter k e.g. PatIter 1 where k 1 may be thought of as a pattern generation sequence iteration k corresponding to PatIter k in that provides a corresponding increment of exposure. In the example outlined above PatIter due to its timing near the center of the integration time period is the first selected increment of exposure. For additional or increased exposure additional illumination pattern trigger signals may be provided. In one embodiment the additional signals may be selected to follow all or some of the selection sequence k 2 3 4 5 6 7. It will be noted that this sequence does not follow a chronological order. Rather the selection of timings for the increments of exposure alternate to each side the center of the integration time period. In this case the effective image exposure time as governed by the average of the selected illumination increment times will continue to tend toward the central time of the position latch signal as pattern generation sequence iterations are added. In for example the solid line gray level pattern generation sequences may provide the second and third exposure increments corresponding to identifiers k 1 2 3 and the dashed line gray level pattern generation sequences may provide the 4th 7th exposure increments as needed corresponding to increment identifiers k 4 5 6 7 . In some implementations the pulse trigger time Tptk may be based on the same high speed clock that is used to determine the camera integration duration .

It will be understood that the foregoing description is exemplary only and not limiting. As one example more or fewer pattern generation iteration time periods may be provided during a camera integration period e.g. 9 iterations as outlined previously. As another example the selection sequence need not be as outlined above and significant benefits will still be obtained. In one embodiment circuits and or routines corresponding to may be used to provide the signals shown in . For example the TSP may receive exposure level information for a particular exposure during the setup on the signal line . The signal may be input to the TSP on the line and or relayed by the TSP to the camera on the line . The TSP may further generate the trigger signals corresponding to an exposure level information and output them to the SLM controller portion on the line . The SLM controller portion may output corresponding signals to the SLM on the line . The TSP may generate the position latch signal at the appropriate time and output it on the line . Other possible embodiments may be realized by one of ordinary skill in the art.

With reference to it will be appreciated that if a gray level pattern generation sequence iteration k is executed in a short time e.g. as shown then if there is relative motion and focus change along the Z direction there will be less displacement during each subdivision time T T and each surface height will be exposed to a more complete or ideal sampling of the gray level pattern such that the height information contrast etc. will be less distorted. In other words for each gray level pattern generation sequence iteration k the image of a stripe is focus weighted more similarly in the different subdivisions and therefore a surface image will exhibit characteristics that better correspond to the intended ideal sine profile i.e. more closely approximating the assumptions used in the SIM equations and algorithms resulting in improved accuracy.

The following description uses equations to outline and understand alternatives and or preferences for providing structured illumination pattern iterations to provide exposure increments during an image acquisition in various embodiments. Repeating Equation 1 outlined previously a general transfer function for the k th full gray level pattern exposure increment during an image acquisition may be expressed as 

For convenience we may define a reference or standard gray level pattern increment of exposure PatIter std which is generated in a standard time increment TIter std using a standard light intensity I std as the light intensity Ii for each of the time subdivisions Ti std included in TIter std. In one embodiment we may select TIter std to be approximately the minimum operable time for generating a full gray level pattern sequence using the native SLP controller. However in other embodiments TIter std may be selected to be slightly longer for reasons described below.

As a first specific illustrative example suppose it is desired to increase the exposure to a specific level e.g. that is 3.2 times the exposure which is provided by one standard exposure increment PatIter std. Two possible approaches that might be taken in typical native control methods are illustrated by 

The methods illustrated by Equations 4 and 5 where only one exposure increment is used may be undesirable in that either the intensity or the overall projection timing period will be different for each brightness level setting. As previously outlined these differences will vary the heat generation of the projection device and or the LEDs and affect the overall system performance unfavorably. In addition an InGaN based LED blue green white will have a different emission spectrum based on the drive current and the pulse duration. Typical shifts in dominant wavelength are on the order of 2 3 nm without active heat sinks e.g. Peltier coolers . Furthermore with regard to the method illustrated by Equation 5 the length of time that each subdivision pattern is on is longer e.g. 3.2 times in the above example which indicates that if the focus height is changing at a high speed e.g. as desired in some implementations then the height sampling may become more non uniform as outlined with reference to . In other words each unique non sine component or subdivision of the pattern is more likely to be the only pattern received by a surface region at a particular height while that height is in focus. Conversely if it is desired for a particular surface region to receive the entire set of sub patterns so as to approach uniform gray level sine stripe sampling for all heights then the Z speed would have to be reduced.

In one implementation the method illustrated by Equation 6 may operate under the assumption that approximately the shortest possible times Ti are being used for Ti std such that one technique for achieving the decimal part of the exposure is to decrease the intensity during the last 0.2 pattern iteration relative to the presumed standard intensity level I std . The method illustrated by Equation 6 may also allow the height sampling to be more desirable as outlined with reference to i.e. a full gray level sine stripe pattern exposure is repeated 4 times throughout the exposure Z range not just once and the net intensity variation is made much smaller than that indicated for the method illustrated by Equation 5 in that the intensity is at a repeatable standardized level for three standardized exposure increments or approximately 94 of the total exposure in this example. In various other implementations it may be desirable for the intensity to never be reduced by amounts such as those indicated in the last term of Equation 6 e.g. to avoid spectral variations. Therefore another alternative based on the principles disclosed herein is illustrated by 

In one implementation the method illustrated by Equation 7 indicates that the height sampling remains at a desirable level e.g. a full gray level sine stripe pattern exposure is repeated three times throughout the exposure Z range not just once and there is only a relatively small intensity variation for just one increment of exposure.

Further alternative methods that may be implemented when the standard intensity I std and or the standard times Ti std are defined to allow for some amount of additional increase and or decrease in the system are illustrated by 

In various embodiments a decision regarding whether to utilize one of the alternative methods illustrated by Equations 6 7 8 or 9 may be determined based on a matter of judgment regarding which provides the best tradeoff. For example in various implementations a 0.8 exposure portion may be best achieved with intensity reduction in one of the exposure increments e.g. as in Equation 6 while a 0.2 exposure portion may be best achieved with a small intensity or time increase in one or more exposure increments e.g. one of Equations 7 8 or 9 . Various other alternatives and combinations of intensity and time in various exposure increments will be apparent to one of ordinary skill in the art based on the principles disclosed herein.

It will be appreciated that all of the methods illustrated by Equations 6 7 8 and 9 rely on a common principle of repeating an exposure pattern sequence not just once but a plurality of times during an exposure. In various implementations the repeated exposure pattern sequences may have an identical intensity and or may have identical time periods. Certain of the repeated exposure pattern sequences may also be generated in the shortest possible time allowed by the pattern generating system.

It will be appreciated that the embodiments outlined above with reference to and Equations 6 9 are exemplary only and not limiting. For example as previously outlined the number of time periods corresponding to a desired or maximum number of pattern generation sequence iterations within a camera integration period need not be seven as in . Rather it may be any desired number within the system operating capabilities e.g. 9 periods as outlined previously or 5 or 4 or may be adapted for a particular image exposure or the like. Of course as previously implied any member of a predetermined set of time periods may be set to provide a zero exposure increment for example by omitting its trigger or setting the source intensity to zero or leaving the source intensity on and setting the pattern Pi to off or the like. Furthermore if an even number of exposure increments are to be selected from an odd number of time periods and used to achieve an overall exposure level the central increment e.g. corresponding to TptC and or k 1 in may be omitted in some embodiments. Similarly if a single different decimal portion exposure increment is to be used to achieve a desired overall exposure level the central increment e.g. corresponding to TptC and or k 1 in may be selected to provide that different exposure increment in some embodiments. In such a case a central position latch signal may then still be most appropriate for indicating the effective position of the image acquisition.

From the foregoing it will be appreciated that specific embodiments of the invention have been described herein for purposes of illustration but that various modifications may be made without deviating from the scope of the invention. For example those skilled in the art will appreciate that the depicted flow chart may be altered in a variety of ways. More specifically the order of the steps may be rearranged steps may be subdivided and or performed in parallel steps may be omitted and alternative steps may be included etc. Accordingly the invention is not limited except as by the appended claims.

