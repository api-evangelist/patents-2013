---

title: Latency reduction for direct memory access operations involving address translation
abstract: Latency reduction for direct memory access operations involving address translation is disclosed. Example methods disclosed herein to perform direct memory access (DMA) operations include initializing a ring of descriptors, the descriptors to index respective buffers for storing received data in a first memory. Such example methods also include causing prefetching of a first address translation associated with a second descriptor in the ring of descriptors to be performed after a first DMA operation is performed to store first received data in a first buffer indexed by a first descriptor in the ring of descriptors and before second received data to be stored in the first memory is received, the first address translation being associated with a second DMA operation for storing the second received data in the first memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09460024&OS=09460024&RS=09460024
owner: VMware, Inc.
number: 09460024
owner_city: Palo Alto
owner_country: US
publication_date: 20130530
---
This patent arises from a continuation of U.S. Provisional Application Ser. No. 61 788 453 entitled LATENCY REDUCTION FOR DIRECT MEMORY ACCESS OPERATIONS INVOLVING ADDRESS TRANSLATION and filed on Mar. 15 2013. U.S. Provisional Application Ser. No. 61 788 453 is hereby incorporated by reference in its entirety.

This disclosure relates generally to direct memory access processing and more particularly to latency reduction for direct memory access operations involving address translation.

Virtualization allows a host processing platform to support multiple virtual machines by abstracting the physical e.g. hardware platform to enable each virtual machine to operate independently from the other virtual machines executing on the processing platform. In a virtual processing environment a hypervisor also referred to as a virtual machine monitor VMM abstracts the host s physical e.g. hardware platform and presents an abstracted or virtual processing platform to each of the virtual machines. To enable independent operation of the virtual machines such abstraction includes mapping one or more address regions in the host s physical memory to a virtual memory address space also referred to herein as a guest physical memory address space accessible by a guest operating system OS executed by a particular virtual machine. At least some virtual processing environments employ an input output memory management unit IOMMU to facilitate direct memory access DMA operations between one or more I O devices and the virtual memory address space that is accessible by a particular virtual machine. Such IOMMUs can provide automatic address translation between the guest physical memory addresses e.g. virtual addresses associated with a particular virtual machine and the actual host physical addresses e.g. machine level addresses also referred to as system physical addresses of the system memory thereby enabling the use of DMA operations for transferring data between an I O device and the virtual memory address space accessible by the virtual machine.

Wherever possible the same reference numbers will be used throughout the drawing s and accompanying written description to refer to the same or like parts elements etc.

Methods apparatus and articles of manufacture e.g. machine readable storage media to perform direct memory access DMA operations involving address translation are disclosed herein. Some disclosed example methods to perform such DMA operations include initializing a ring of descriptors in which the descriptors are to index respective buffers for storing received data in a first memory. Such example methods also include causing prefetching of an address translation to be performed after a first DMA operation is performed to store first received data in a first buffer in the first memory and before second received data to be stored in the first memory is received. In such examples the address translation is associated with a second DMA operation for storing the second received data in the first memory. For example prefetching of the address translation can be caused by causing an input output memory management unit IOMMU to prefetch the address translation and cache the address translation in an input output translation lookaside buffer IOTLB before the second received data is to be received and the second DMA operation is to be performed.

In some examples the first buffer is indexed by a first descriptor in the ring of descriptors and the second received data is to be stored in a second buffer indexed by a second descriptor that is a next descriptor in the ring of descriptors relative to the first descriptor. In such examples some disclosed example methods can cause prefetching of the address translation to be performed by initiating a third DMA operation to retrieve the second descriptor from the ring of descriptors. In such examples the third DMA operation is to cause a first address translation for translating a guest physical address of the second descriptor to a host physical address of the second descriptor to be prefetched and cached before the second received data is to be received and the second DMA operation is to be performed. Furthermore in some such example methods a fourth DMA operation is initiated to access the second buffer indexed by the second descriptor to cause a second address translation for translating a guest physical address of the second buffer to a host physical address of the second buffer to be prefetched and cached before the second received data is to be received and the second DMA operation is to be performed. For example the third DMA operation can be a DMA read operation initiated by a network interface card NIC to read the next descriptor which is the second descriptor from the ring of descriptors e.g. without post incrementing a pointer tracking the active descriptor to be used by the NIC and the fourth DMA operation can be a DMA write operation initiated by the NIC to perform a null write to the second buffer. In some such examples success of the DMA write operation is not to be signaled by the NIC to a NIC driver controlling the NIC e.g. because the DMA write operation is for a null write to the second buffer and not for storing any received data to the second buffer .

Additionally or alternatively some disclosed example methods can cause prefetching of the address translation to be performed by issuing a first transmit command having a transmit buffer address set to a guest physical address of the second descriptor. In such examples the first transmit command is to cause the NIC to initiate the third DMA operation to access the second descriptor. As in the preceding examples the third DMA operation is to cause the first address translation for translating the guest physical address of the second descriptor to the host physical address of the second descriptor to be prefetched and cached before the second received data is to be received and the second DMA operation is to be performed. However in the present examples the third DMA operation corresponds to for example a DMA read operation initiated by the NIC to read the transmit buffer address specified in the first transmit command which corresponds to the guest physical address of the second descriptor. Furthermore in some such example methods the methods further initiate a second transmit command having a transmit buffer address set to a guest physical address of the second buffer. In such examples the second transmit command is to cause the NIC to initiate the fourth DMA operation to access the second buffer. As in the preceding examples the fourth DMA operation is to cause the second address translation for translating the guest physical address of the second buffer to the host physical address of the second buffer to be prefetched and cached before the second received data is to be received and the second DMA operation is to be performed. However in the present examples the fourth DMA operation corresponds to for example a DMA read operation initiated by the NIC to read the data from the transmit buffer address specified in the second transmit command which corresponds to the guest physical address of the second buffer. In some examples the first and second transmit commands specify that their respective transmit buffer addresses are to be read but the data contained in the buffers is not to be transmitted e.g. by setting a flag in the transmit command by specifying an invalid data length for data stored in the buffer etc. .

Other disclosed example methods to perform DMA operations involving address translation include initializing a ring of descriptors in which the descriptors are to index respective buffers for storing in a first memory data to be transmitted. Such example methods also include causing prefetching of an address translation to be performed after a first DMA operation is performed to retrieve for transmission first data from a first buffer in the first memory and before second data is determined to be ready for transmission. In such examples the address translation is associated with a second DMA operation for retrieving the second data from the first memory. For example prefetching of the address translation can be caused by causing an input output memory management unit IOMMU to prefetch the address translation and cache the address translation in an input output translation lookaside buffer IOTLB before the second received data is determined to be ready for transmission and before the second DMA operation is to be performed.

In some such examples the first buffer is indexed by a first descriptor in the ring of descriptors and the second data is to be stored in a second buffer indexed by a second descriptor that is a next descriptor in the ring of descriptors relative to the first descriptor. In some such examples the methods cause prefetching of the address translation to be performed by initiating a third DMA operation to retrieve the second descriptor from the ring of descriptors. In such examples the third DMA operation is to cause a first address translation for translating a guest physical address of the second descriptor to a host physical address of the second descriptor to be prefetched and cached before the second data is determined to be ready for transmission and before the second DMA operation is to be performed. Furthermore in some such example methods a fourth DMA operation is initiated to access the second buffer indexed by the second descriptor to cause a second address translation for translating a guest physical address of the second buffer to a host physical address of the second buffer to be prefetched and cached before the second data is determined to be ready for transmission and before the second DMA operation is to be performed. For example the third DMA operation can be a DMA read operation initiated by a NIC to read the second descriptor from the ring of descriptors and the fourth DMA operation can a DMA read operation initiated by the NIC to perform a read from the second buffer. In some examples the NIC is to not transmit the data read from the second buffer using the DMA read operation e.g. because the DMA read operation corresponds to a dummy read to prefetch the address translation and the data that is read is not valid data to transmit .

Additionally or alternatively in some such examples the second buffer is allocated for use by a NIC driver controlling the NIC and the example methods further include initializing the second descriptor to index the second buffer copying the second data from a third buffer associated with an application to the second buffer when the application signals to the NIC driver that the second data is ready to be transmitted and issuing a transmit command to cause the NIC to transmit the second data stored in the second buffer. In such examples the address translations for the second buffer can be prefetched because the second buffer is allocated to the NIC driver and at a known location in memory rather than being allocated to the application and at an unknown e.g. random location in memory.

Yet other disclosed example methods to perform DMA operations involving address translation include reserving buffers in memory for use by a NIC driver controlling a NIC and initializing a ring of descriptors in which the descriptors are to index respective ones of the buffers reserved for use by the NIC driver. Such example methods also include exposing an interface for an application to request a first one of the buffers for storing data for transmission. Such example methods further include allocating the first one of the buffers to the application in response to receiving a request from the application via the interface. In at least some examples the buffers are located in a region of memory covered by a first number of page tables less than a total number of page tables used by an IOMMU to perform address translation. In this way the IOMMU can perform address translations for the buffers allocated to the NIC driver by walking fewer than the total number of page tables used by the IOMMU.

These and other example methods apparatus systems and articles of manufacture e.g. physical storage media to perform DMA operations involving address translation are disclosed in greater detail below.

As noted above an IOMMU can implement address translation to support DMA operations for storing data from an I O device to memory accessible by a particular virtual machine and or reading data from the memory accessible by the particular virtual machine to the I O device. Such address translation maps a guest physical memory address associated with a particular virtual machine to an actual host physical addresses in the system memory. While such address translations enable virtual machines to be allocated their own unique guest physical address spaces in memory such address translations can also increase the latency associated with DMA operations performed to write data to and or read data from a virtual memory space associated with a particular virtual machine.

For example a virtual processing environment can employ an IOMMU to perform DMA write operations to store data received by a NIC to a memory location e.g. buffer associated with a particular virtual machine. The IOMMU in such an example can also be employed to perform DMA read operations to retrieve data from a memory location e.g. buffer associated with a particular virtual machine and to provide the data to the NIC for transmission. Such DMA write and read operations can involve performing address translations to map guest physical memory addresses which are used by the virtual machine to represent the locations of the data buffers in memory to the actual host physical addresses of these buffers in memory. Furthermore some virtual processing environments may use rings or queues of descriptors to index the buffers in memory. In such examples the IOMMU may be used to perform DMA read operations to retrieve the descriptors from memory which may involve performing a second address translation in addition to the address translation associated with accessing the buffer indexed by a particular descriptor. The latency associated with such address translations can reduce the speed at which the IOMMU can perform DMA operations and thus may reduce the data throughput of the virtual processing environment.

Disclosed example methods apparatus systems and articles of manufacture e.g. physical storage media implement techniques capable of reducing the latency associated with DMA operations involving address translation. For example some such disclosed techniques perform address translation prefetching in which address translations associated with a DMA operation are caused to be prefetched e.g. by an IOMMU and cached e.g. in an IOTLB used by the IOMMU before a DMA operation that is to rely on the address translation is to be performed. In this way the address translation is available and cached for use by the IOMMU when the DMA operation is performed thereby avoiding a cache miss and the resulting page walk that would be performed by the IOMMU to determine the address translation. Other disclosed techniques additionally or alternatively include allocating the buffers to which data is to be stored and or from which data is to be read in known e.g. contiguous regions of memory. In this way the address translations for such buffers can be prefetched with higher accuracy than when the buffers are located randomly in memory e.g. according to a scatter gather implementation . Such buffer allocation can also decrease the number of page tables the IOMMU has to walk before determining an address translation for a particular memory location.

Turning to the figures a block diagram of an example virtual processing environment capable of implementing DMA operations involving address translation as disclosed herein is illustrated in . The virtual processing environment of the illustrated example includes an example host processor capable of supporting one or more virtual machines such as the example virtual machine . As such the host processor executes an example hypervisor to abstract the physical e.g. hardware platform of the virtual processing environment which includes the physical resources of the host processor e.g. such as the host s internal memory registers functions etc. and also the external physical resources connected to or otherwise in communication with the host processor via an example system bus . For example the example virtual processing environment of includes example memory e.g. system memory that is in communication with the host processor via the system bus and an example NIC that is in communication with the host processor via the system bus an example external interface bus and an example chipset . The hypervisor is able to abstract the interfaces to the memory and the NIC such that the virtual machine can access these resources independently from other virtual machines executing on the host processor .

In the illustrated example of the host processor can be implemented by any number and or type s of processors processing elements nodes etc. such as the processor included in the example processor platform of which is described in greater detail below. The system bus of the illustrated example can be implemented by any number and or type s of busses switching meshes fabrics interface circuits etc. such as a front side bus FSB a HyperTransport bus the bus included in the example processor platform of which is described in greater detail below etc. The memory of the illustrated example can be implemented by any number and or type s of memory elements storage elements etc. such as one or more of the example memories and or included in the example processor platform of which is described in greater detail below. The external interface bus of the illustrated example can be implemented by any number and or type s of busses switching meshes fabrics interface circuits etc. such as a peripheral component interconnect PCI bus etc. The chipset of the illustrated example can be implemented by for example a bus bridge such as a PCI bridge and or any other logic circuitry etc. for interconnecting the system bus and the external interface bus .

In the illustrated example the NIC can be any type of NIC capable of receiving data from and transmitting data on an example communication medium which may correspond to a communication network a transmission line a communication bus a data port etc. As such the NIC of the illustrated example can include an example medium access unit not shown to access the communication medium and process data received via the communication medium and or to be transmitted on the communication medium . Additionally the NIC of the illustrated example can include local memory not shown to store data locally after reception and or prior to transmission. In some examples the example NIC of can be implemented by the interface circuit included in the example processor platform of which is described in greater detail below.

In the illustrated example of the virtual machine implements a guest OS not shown upon which one of more example applications can be executed. The guest OS of the virtual machine also provides an example protocol stack to enable data to be transmitted by the application s to a destination location and or received by the application s from a source location. The protocol stack of the illustrated example can be implemented by any number and or type s of protocol stacks such as a transmission control protocol Internet protocol TCP IP protocol stack etc. The application s can include any number and or type s of applications capable of transmitting and or receiving data.

In the example virtual processing environment of the guest OS of the virtual machine also provides an example NIC driver to configure and manage operation of the NIC . In particular the NIC driver of the illustrated example configures and controls operation of the NIC on behalf of the application s being executed in the virtual machine . For example the NIC driver configures the NIC to receive from the communication medium data destined for an application executing on the virtual machine and to store the received data in the memory for retrieval by the application . Additionally or alternatively the NIC driver configures the NIC to retrieve from the memory data generated by an application executing on the virtual machine and to be transmitted to a destination via the communication medium .

To enable the virtual machine to operate independently of other virtual machines in the virtual processing environment the hypervisor executing on the host processor performs among other things memory address abstraction to map virtual also referred to as guest memory addresses used by the virtual machine to access locations in the memory to the actual machine also referred to as physical memory addresses for these locations in the memory . For example the hypervisor may map guest physical memory addresses in a first range e.g. the range of 0x0 to 0x1000 or some other range for the virtual machine to actual host physical addresses in a second range e.g. a range of 0x6000 to 0x7000 or some other range in the memory where 0x indicates that a number is written in hexadecimal format . In some examples the hypervisor may also map for a second virtual machine not shown guest physical memory addresses in the same first range or a different range to a range in the memory that is different than the second range which yields memory isolation between the virtual machine and the second virtual machine.

In the illustrated example of example transmit buffers correspond to guest physical memory of the VM allocated by one or more of the application s the protocol stack and or the NIC driver for storing data for transmission. Furthermore in the illustrated example the NIC driver places the guest physical addresses corresponding to the transmit buffers in an example descriptor ring which the hypervisor uses to map the transmit buffers to host physical or machine addresses. The descriptor ring is described in greater detail below. In some examples such as examples in which zero copy transmit is supported the same transmit buffers are also used to transmit the data e.g. in the form of data packets over the physical NIC . In the illustrated example of the hypervisor and the guest OS in the VM also allocate example receive buffers in the memory . For example the hypervisor can allocate receive buffers into which the physical NIC is to store received data e.g. packets whereas the guest OS in the VM can allocate receive buffers for use by the hypervisor to map and copy the data e.g. packets received and stored by the physical NIC e.g. for use by one or more of the application s the protocol stack and or the NIC driver . The receive buffers may be located in one or more contiguous regions in memory and or located randomly in the memory . Likewise the transmit buffers may be located in one or more contiguous regions in memory and or located randomly in the memory .

To support DMA operations to write data received by the NIC to the receive buffers and to read data from the transmit buffers to the NIC for transmission the example virtual processing environment of also includes an example IOMMU in the example chipset example address translation page tables stored in the memory and example receive and transmit descriptor rings and respectively stored in the memory . In the illustrated example of the hypervisor allocates the receive descriptor ring also referred to as a receive descriptor queue and the transmit descriptor ring also referred to as a transmit descriptor queue for the virtual machine . The receive descriptor ring includes a set of receive descriptors arranged sequentially in memory and in which each receive descriptor can be configured e.g. by the NIC driver to index a particular receive buffer in the set of receive buffers. The receive descriptor ring also includes at least two pointers referred to herein as a producer pointer and a consumer pointer to be used to select the active descriptors in the receive descriptor ring that are indexing the receive buffers to which received data is to be written by the NIC and from which received data is to be retrieved by the application s executing in the virtual machine . Similarly the transmit descriptor ring includes a set of transmit descriptors arranged sequentially in memory and in which each transmit descriptor can be configured e.g. by the NIC driver to index a particular transmit buffer in the set of transmit buffers. Like the receive descriptor ring the transmit descriptor ring also includes at least two pointers referred to herein as a producer pointer and a consumer pointer to be used to select the active descriptors in the transmit descriptor ring that are indexing the transmit buffers to which data to be transmitted is to be written by the application s executing in the virtual machine and from which this data is to be retrieved by the NIC for transmission via the communication medium .

In the illustrated example virtual processing environment of the descriptors in the receive descriptor ring and the transmit descriptor ring are configured by the NIC driver with the guest physical memory addresses of the respective receive buffers and transmit buffers to be indexed by the descriptors. In the illustrated example the NIC driver also initializes the NIC with the guest physical memory addresses of the respective receive descriptor ring and the transmit descriptor ring to enable the NIC to access these rings in memory. The chipset of the illustrated example includes the example IOMMU to among other things translate these guest physical memory addresses to their respective host physical memory addresses to allow the actual locations of the receive descriptor ring and the transmit descriptor ring as well as the receive buffers and transmit buffers to be accessed in memory using DMA operations. To support such address translation the example IOMMU utilizes the set of address translation page tables stored in memory and walks the address translation page tables using any appropriate page walking and address translation technique to translate the guest physical memory addresses associated with the virtual machine to the respective host physical addresses in the memory .

Example sequences of operations further demonstrating the use of address translation when performing DMA operations in the example virtual processing environment of are illustrated in . Prior to the example operations of the virtual processing environment illustrated in these figures the NIC driver has initialized the NIC with the starting guest physical addresses of the receive descriptor ring and the transmit descriptor ring as well as the lengths of each ring. Example producer and consumer pointers of the receive descriptor ring and example producer and consumer pointers of the transmit descriptor ring are also initialized by the NIC driver to point to the start of the respective rings and . Then referring to the example sequence of operations of when received data such as a received data packet is received by the NIC the NIC initiates a DMA read operation represented by the directed arrow to read the current receive descriptor that is at the location in the receive descriptor ring pointed to by the ring s producer pointer . The DMA operation initiated by the NIC is processed by the IOMMU in the chipset which performs an address translation represented by the directed arrow to map the guest physical address referenced by the receive descriptor ring s producer pointer to the actual host physical address of this receive descriptor in the receive descriptor ring . The IOMMU then performs the DMA read operation to retrieve and provide the contents of this receive descriptor to the NIC .

Next the NIC obtains the receive buffer address which is a guest physical address configured by the NIC driver during initialization or during run time operation from the retrieved receive descriptor and initiates a DMA write operation to write the received data to this receive buffer . Again this DMA operation is processed by the IOMMU which performs another address translation represented by the directed arrow to map the guest physical address of the receive buffer to the actual host physical address of the receive buffer in the memory . The IOMMU then performs the DMA write operation to write and store the received data e.g. the received data packet to the receive buffer .

Meanwhile the NIC also post increments the receive descriptor ring s producer pointer to point to the next receive descriptor in the receive descriptor ring . In parallel with the storage of the receive data to the receive buffers and referring to the example sequence of operations of the NIC driver uses the receive descriptor ring s consumer pointer to access the next descriptor in the receive descriptor ring . At some later time the descriptor ring s consumer pointer will have been incremented to point to the receive descriptor . At that time the NIC driver can use the receive descriptor ring s consumer pointer to access the receive descriptor and then use the contents of the receive descriptor to read the data previously stored in the receive buffer by the NIC . The NIC driver then post increments the receive descriptor ring s consumer pointer to point to the next receive descriptor in the receive descriptor ring . As described in further detail below the example techniques disclosed herein can reduce the DMA operation latency associated the address translations and or .

Referring to the example sequence of operations of for the transmit data case when an application is ready to transmit data the application calls the NIC driver with the guest physical address of the transmit buffer in which the data to be transmitted is stored. The NIC driver then configures the current available transmit descriptor pointed to by the transmit descriptor ring s producer pointer with the guest physical address of this transmit buffer . The NIC driver then post increments the transmit descriptor ring s producer pointer to point to the next available transmit descriptor included in the transmit descriptor ring .

At a later time and referring to the example sequence of operations of the NIC driver initiates a DMA read operation represented by the directed arrow to read the transmit descriptor which is at the location in the transmit descriptor ring pointed to by the ring s consumer pointer . The DMA operation initiated by the NIC is processed by the IOMMU in the chipset which performs an address translation represented by the directed arrow to map the guest physical address referenced by the transmit descriptor ring s producer pointer to the actual host physical address of the transmit descriptor in the transmit descriptor ring . The IOMMU then performs the DMA read operation to retrieve and provide the contents of this transmit descriptor to the NIC .

Next the NIC obtains the transmit buffer address which is the guest physical address that was configured by the NIC driver from the retrieved descriptor and initiates a DMA read operation to read the data from this transmit buffer . Again this DMA operation is processed by the IOMMU which performs another address translation represented by the directed arrow to map the guest physical address of the transmit buffer to the actual host physical address of the transmit buffer in the memory . The IOMMU then performs the DMA read operation to retrieve and provide data from the transmit buffer to the NIC for transmission. Meanwhile the NIC also post increments the transmit descriptor ring s consumer pointer to point to the next transmit descriptor in the transmit descriptor ring . As described in further detail below the example techniques disclosed herein can reduce the DMA operation latency associated the address translations and or .

Returning to from the foregoing example operations of the virtual processing environment it can be seen that writing data from the NIC to the memory and reading data from the memory to the NIC involves at least two address translations one translation to retrieve the appropriate descriptor and another translation to access the buffer indexed by the descriptor. Such address translations can introduce latency in the DMA operations facilitated by the IOMMU especially under circumstances in which the address translations are not cached locally in the IOMMU . For example the IOMMU can include a cache such as an IOTLB to store recently used address translations. However when cache sizes are limited and or buffers are located randomly in memory it may not be possible for the IOMMU to have the address translation for the next DMA operation in its cache. When an address translation is not cached the IOMMU performs a walk of its address translation page tables which can be time consuming and reduce the performance of DMA operations facilitated by the IOMMU .

To reduce the latency associated with performing address translations for DMA operations the virtual processing environment of the illustrated example further includes an example NIC DMA enhancer in the NIC and an example NIC driver DMA enhancer in the NIC driver . As described in detail below the NIC DMA enhancer causes the IOMMU to prefetch one or more address translations associated with a next DMA operation to be performed such that the address translation s are cached in the IOMMU by the time the next DMA operation is to be performed. As further described in detail below the NIC driver DMA enhancer can additionally or alternatively be used to cause the IOMMU to prefetch one or more address translations associated with a next DMA operation to be performed such that the address translation s are cached in the IOMMU by the time the next DMA operation is to be performed. In some examples the NIC driver DMA enhancer additionally or alternatively includes functionality to locate some or all of the buffers and or in contiguous memory location which may also help reduce the latency associated with DMA operations involving address translation. Example implementations of the NIC DMA enhancer and the NIC driver DMA enhancer are illustrated in which is described in detail below.

A block diagram of an example implementation of the NIC driver of that can include the example NIC driver DMA enhancer is illustrated in . In the illustrated example of the NIC driver of includes an example virtual NIC driver an example virtual NIC and an example physical NIC driver which can be implemented according to any conventional or otherwise appropriate technique. For example in the NIC driver of each of the virtual NIC driver and the virtual NIC is implemented for and executes in the context of the virtual machine whereas the physical NIC driver is implemented for and executes in the context of the hypervisor . Furthermore in the illustrated example of the virtual NIC driver of the virtual NIC driver is adapted to include the example NIC driver DMA enhancer described above and in further detail below. However in other examples the NIC driver DMA enhancer could be implemented by for example a paravirtualized NIC driver not shown implementing at least some of the functionality of the virtual NIC driver the virtual NIC and or the physical NIC driver .

Returning to although the example virtual processing environment illustrated in includes one virtual machine the disclosed example methods apparatus and articles of manufacture for performing DMA operations involving address translation can be used in processing environments having any number of virtual machines . For example in such virtual processing environments each virtual machine may be allocated respective receiver buffers transmit buffers and receive and transmit descriptor rings and . In such examples the IOMMU can maintain respective sets of address translation page tables and internal caches e.g. IOTLBs for the different virtual machines . The IOMMU in such examples can select a particular set of address translation page tables and or a particular internal cache based on for example 1 a process identifier ID associated with the application that is to transmit or receive the data 2 a virtual local area network VLAN ID or other networking identifier included in the data received or to be transmitted by the NIC 3 a virtual machine identifier etc.

Also although the disclosed example methods apparatus and articles of manufacture for performing DMA operations involving address translation are described in the context of performing DMA operations associated with the NIC of the example virtual processing environment such example methods apparatus and articles of manufacture can also be used to reduce latency associated with DMA operations performed by other I O devices in a virtual processing environment. For example the example NIC DMA enhancer disclosed herein could be included in any I O device that is to write data to and or read data from a memory using DMA operations and the NIC driver DMA enhancer disclosed herein could be included in the virtual machine driver responsible for managing such an I O device.

Furthermore although the IOMMU is shown as being included in the chipset in the illustrated example virtual processing environment the disclosed example methods apparatus and articles of manufacture for performing DMA operations involving address translation are not limited thereto. For example the IOMMU and the associated address translation processing and caching could be included in and or otherwise implemented by the NIC and or any other I O device that is to write data to and or read data from a memory using DMA operations.

An example implementation of address translation functionality included in the IOMMU of is illustrated in . Other functionality included in the IOMMU is omitted from the block diagram of for clarity. Turning to the IOMMU of the illustrated example includes example address translation logic configured to translate between guest physical memory addresses and host physical memory addresses in a virtual processing environment such as the virtual processing environment of . The example address translation logic can implement address translation associated with any number and or types of virtualization solutions such as Intel s Virtualization Technology for Directed I O VT d AMD s Graphical Aperture Remapping Table IBM s Translation Control Entries etc. The address translation logic utilizes one or more address translation page tables such as the address translation page tables that are arranged in for example a hierarchical structure that is traversed or walked by the address translation logic to perform an address translation. For example when the IOMMU intercepts a DMA operation e.g. a DMA write or a DMA read operation that is to access a location in memory such as in the memory of the address translation logic reads the guest physical memory addresses specified in the DMA operation. The address translation logic then walks the address translation page tables to determine the host physical address that is mapped to the guest physical address. The determined host physical address is then used in the DMA operation to enable the correct memory location to be accessed.

In the illustrated example of the IOMMU also includes an example IOTLB to cache or in other words store address translations determined by the address translation logic . For example the IOTLB can include entries for storing mappings of guest physical addresses to host physical addresses determined by the address translation logic from walking its address translation page tables. In an example operation when the IOMMU intercepts a DMA operation for accessing a location in memory the IOMMU determines whether the guest physical address specified in the DMA operation is cached in the IOTLB . If the guest physical address is cached in the IOTLB referred to as a cache hit the IOMMU can retrieve the host physical address mapped to this guest physical address without having to perform a potentially time consuming walk of its address translation page tables. However if the guest physical address is not cached in the IOTLB referred to as a cache miss the IOMMU walks its address translation page tables to determine the host physical address corresponding to the guest physical address specified in the DMA operation. The determined mapping between this guest physical address and the host physical address is then cached in the IOTLB to make this mapping available for subsequent DMA operations.

In the illustrated example of the IOMMU continues to cache address translation in the IOTLB until the IOTLB is full. Then the IOMMU implements any appropriate cache management technique to manage the inclusion and removal of the address translations in the IOTLB . For example the IOMMU can remove the oldest and or least used address translation entries from its IOTLB to make room for including a new address translation in the IOTLB . However for scenarios in which the transmit and or receive buffers and have a substantially random arrangement in memory and or are accessed in a substantially random order such IOTLB management techniques may be unable to yield a satisfactory cache hit rate.

As noted above in some examples the NIC driver of the virtual machine initializes the NIC with the starting location and size of the receive descriptor ring in the memory . The NIC driver also initializes the producer and consumer pointers used to select the receive descriptors in the receive descriptor ring . For example the NIC reads the producer pointer of the receive descriptor ring to obtain the guest physical address of the current receive descriptor in the receive descriptor ring to which received data is to be stored via a DMA write operation. Once the current receive descriptor is retrieved and used to obtain the current receiver buffer to which the current received data is to be stored the NIC increments the producer pointer of the receive descriptor ring such that the producer pointer points to the next descriptor in the receive descriptor ring which will be used for storing the next data received by the NIC .

In such examples the receive descriptor prefetcher can implement prefetching of a receive descriptor address translation as follows. After the NIC has initiated a DMA write operation to store the current received data in the current receive buffer and after the producer pointer of the receive descriptor ring has been incremented to point to the next descriptor in the receive descriptor ring the receive descriptor prefetcher initiates a DMA read operation specifying the guest physical address pointed to by the producer pointer of the receive descriptor ring which corresponds to the guest physical address of the next receive descriptor in the receive descriptor ring . However the receive descriptor prefetcher initiates this DMA read operation before the NIC has actually received the next data e.g. the next data packet over the communication medium . In this way the DMA read operation causes the IOMMU to determine if needed and cache the address translation mapping the guest physical address of the next receive descriptor in the receive descriptor ring to its host physical address before this address translation will be needed for storing the next data received over the communication medium . Also because the DMA read operation initiated by the receive descriptor prefetcher is a dummy read for the purposes of prefetching the address translation of the next receive descriptor in the receive descriptor ring and is not used to store any received data the producer pointer of the receive descriptor ring is not incremented after the dummy DMA read operation is performed. Thus the producer pointer of the receive descriptor ring still points to the next receive descriptor whose address translation was prefetched in the receive descriptor ring and is ready for use by the NIC when the next data is received over the communication medium .

In some examples the example NIC DMA enhancer additionally or alternatively includes an example receive buffer prefetcher as shown in the illustrated example of to cause the IOMMU to prefetch address translations for receive buffers indexed by the receive descriptors included in the receive descriptor ring . In the illustrated example the receive buffer prefetcher causes the IOMMU to prefetch an address translation which maps the guest physical address of a particular receive buffer to the host physical address of that receive buffer before the IOMMU is expected to need this address translation for processing a DMA operation that is to access the memory location of the receive buffer . Such prefetching can increase the likelihood that the address translation for this receive buffer will be cached in the IOTLB of the IOMMU when the address translation is actually needed thereby avoiding a cache miss and the associated processing latency incurred when the address translation logic of the IOMMU has to resort to performing a page walk of its address translation page tables to determine the needed address translation.

For example the receive buffer prefetcher can implement prefetching of a receive buffer address translation as follows. After the receive descriptor prefetcher initiates the DMA read operation described above to cause the IOMMU to prefetch the address translation associated with the next receive descriptor in the receive descriptor ring the receive buffer prefetcher reads the contents of the receive descriptor returned by the DMA read operation. These contents include the guest physical address of the receive buffer indexed by this next receive descriptor in the receive descriptor ring . The receive buffer prefetcher then initiates a DMA operation which may be for example a dummy read operation or a dummy write operation specifying the guest physical address of receive buffer indexed by the next receive descriptor. However the receive buffer prefetcher initiates this DMA access of the next receive buffer before the NIC has actually received the next data e.g. the next data packet over the communication medium . In this way the DMA access of the next receive buffer causes the IOMMU to determine if needed and cache the address translation mapping the guest physical address of the next receive buffer to its host physical address before this address translation will be needed for storing the next data received overt the communication medium . Also because the DMA operation initiated by the receive buffer prefetcher is a dummy read e.g. of data to be ignored or a dummy write e.g. of null data for the purposes of prefetching the address translation of the next receive buffer and is not used to store any received data or read any stored data the success of this DMA operation is not signaled to the NIC driver . Accordingly the NIC driver is not aware of the DMA operations initiated by the receive buffer prefetcher and or the receive descriptor prefetcher and thus does not attempt to read the dummy null data that may have been stored to the memory location s specified in these dummy DMA operation s .

In some examples the example NIC DMA enhancer additionally or alternatively includes an example transmit descriptor prefetcher as shown in the illustrated example of to cause the IOMMU in the example virtual processing environment to prefetch address translations for transmit descriptors included in the transmit descriptor ring In the illustrated example the transmit descriptor prefetcher causes the IOMMU to prefetch an address translation which maps the guest physical address of a particular transmit descriptor to the host physical address of that transmit descriptor in the receive descriptor ring before the IOMMU is expected to need the address translation for processing a DMA operation that is to access the memory location of the transmit descriptor. Similar to the receive descriptor prefetching performed by the receive descriptor prefetcher described above such transmit descriptor prefetching can increase the likelihood that the address translation for this transmit descriptor will be cached in the IOTLB of the IOMMU when this address translation is actually needed thereby avoiding a cache miss and the associated processing latency incurred when the address translation logic of the IOMMU has to resort to performing a page walk of its address translation page tables to determine the needed address translation.

As noted above in some examples the NIC driver of the virtual machine initializes the NIC with the starting location and size of the transmit descriptor ring in the memory . The NIC driver also initializes the producer and consumer pointers used to select the transmit descriptors in the transmit descriptor ring . For example the NIC reads the consumer pointer of the transmit descriptor ring to obtain the guest physical address of the current transmit descriptor in the transmit descriptor ring from which transmit data is to be obtained via a DMA read operation. Once the current transmit descriptor is retrieved and used to obtain the current transmit buffer from which the current data for transmission is to be retrieved the NIC increments the consumer pointer of the transmit descriptor ring such that the consumer pointer points to the next descriptor in the transmit descriptor ring which will be used for retrieving the next data for transmission by the NIC .

In such examples the transmit descriptor prefetcher can implement prefetching of a transmitter descriptor address translation as follows. After the NIC has initiated a DMA read operation to retrieve for transmission the transmit data stored in the current transmit buffer and after the consumer pointer of the transmit descriptor ring has been incremented to point to the next descriptor in the transmit descriptor ring the transmit descriptor prefetcher initiates a DMA read operation specifying the guest physical address pointed to by the consumer pointer of the transmit descriptor ring which corresponds to the guest physical address of the next transmit descriptor in the transmit descriptor ring . However the transmit descriptor prefetcher initiates this DMA read operation before the NIC has actually received a command from the NIC driver indicating the next transmit data e.g. the next transmit data packet is ready for transmission over the communication medium . In this way the DMA read operation causes the IOMMU to determine if needed and cache the address translation mapping the guest physical address of the next transmit descriptor in the transmit descriptor ring to its host physical address before this address translation will be needed for retrieving the next data to be transmitted over the communication medium . Also because the DMA read operation initiated by the transmit descriptor prefetcher is a dummy read for the purposes of prefetching the address translation of the next transmit descriptor in the transmit descriptor ring and is not used to retrieve any data for transmission the consumer pointer of the transmit descriptor ring is not incremented after the dummy DMA read operation is performed. Thus the consumer pointer of the transmit descriptor ring still points to the next transmit descriptor whose address translation was prefetched in the transmit descriptor ring and is ready for use by the NIC when the NIC driver indicates that next transmit data is ready for transmission over the communication medium .

In some examples the example NIC DMA enhancer additionally or alternatively includes an example transmit buffer prefetcher as shown in the illustrated example of to cause the IOMMU to prefetch address translations for transmit buffers indexed by the transmit descriptors included in the transmit descriptor ring . In the illustrated example the transmit buffer prefetcher causes the IOMMU to prefetch an address translation which maps the guest physical address of a particular transmit buffer to the host physical address of that transmit buffer before the IOMMU is expected to need this address translation for processing a DMA operation that is to access the memory location of the transmit buffer . Such prefetching can increase the likelihood that the address translation for this transmit buffer will be cached in the IOTLB of the IOMMU when the address translation is actually needed thereby avoiding a cache miss and the associated processing latency incurred when the address translation logic of the IOMMU has to resort to performing a page walk of its address translation page tables to determine the needed address translation.

For example the transmit buffer prefetcher can implement prefetching of a transmit buffer address translation as follows. After the transmit descriptor prefetcher initiates the DMA read operation described above to cause the IOMMU to prefetch the address translation associated with the next transmit descriptor in the transmit descriptor ring the transmit buffer prefetcher reads the contents of the transmit descriptor returned by the DMA read operation. These contents include the guest physical address of the transmit buffer indexed by this next transmit descriptor in the transmit descriptor ring . The transmit buffer prefetcher then initiates a DMA operation which may be for example a dummy read operation or a dummy write operation specifying the guest physical address of transmit buffer indexed by the next transmit descriptor. However the transmit buffer prefetcher initiates this DMA access of the next transmit buffer before the NIC has actually received an indication e.g. from the NIC driver that the next data e.g. the next data packet is ready for transmission over the communication medium . In this way the DMA access of the next transmit buffer causes the IOMMU to determine if needed and cache the address translation mapping the guest physical address of the next transmit buffer to its host physical address before this address translation will be needed for retrieving the next data to be transmitted over the communication medium . Also because the DMA operation initiated by the transmit buffer prefetcher is a dummy read e.g. of data to be ignored or dummy write e.g. of null data for the purposes of prefetching the address translation of the next transmit buffer and is not used to retrieve any data for transmission or store any data the success of this DMA operation is not signaled to the NIC driver . Accordingly the NIC driver is not aware of the DMA operations initiated by the transmit buffer prefetcher and or the transmit descriptor prefetcher .

In the example NIC DMA enhancer of the receive descriptor prefetcher the receive buffer prefetcher the transmit descriptor prefetcher and the transmit buffer prefetcher are illustrated as being communicatively coupled to example interface logic which permits information to be exchanged among some of all of the foregoing blocks e.g. depending upon which blocks are included in an example implementation . The interface logic can be implemented by for example but not limited to any number and or type s of communication control links busses digital logic software interfaces etc.

In some examples the receive address prefetcher of the NIC driver DMA enhancer illustrated in the example of implements address translation prefetching for the next receive descriptor in the receive descriptor ring as follows. After receiving an indication that a DMA write operation for writing current received data to a current receive buffer has completed successfully the receive address prefetcher reads the guest physical address pointed to by the producer pointer of the receive descriptor ring . This address pointed to by the producer pointer of the receive descriptor ring corresponds to the guest physical address of the next receive descriptor in the receive descriptor ring that is to be used by the NIC for storing the next data e.g. the next data packet to be received over the communication medium . The receive address prefetcher then prepares a new transmit command that is to cause the NIC to transmit data stored at a location specified in the transmit command rather than using the consumer pointer of the transmit descriptor ring to determine the location of the data to be transmitted. In the illustrated example the receive address prefetcher specifies in the new transmit command the guest physical address of the next receive descriptor pointed to be the producer pointer of the receive descriptor ring as the location of the data to be transmitted. The receive address prefetcher then causes the NIC driver to issue this new transmit command to the NIC which has been modified to recognize this new transmit command which causes the NIC to issue a DMA read operation to read the data at the location specified in the new transmit command. The DMA read operation causes the IOMMU to determine if needed and cache the address translation mapping the guest physical address of the next receive descriptor which is specified in the new transmit command issued by the NIC driver to its host physical address of this descriptor in the receive descriptor ring . In this way the address translation mapping the guest physical address of this next receive descriptor to its host physical address is already cached in the IOTLB of the IOMMU before this address translation is needed for storing the next data received by the NIC . Also in some examples the receive address prefetcher causes the NIC driver to indicate that the new transmit command is to be no operation NOP transmit command that is to cause the NIC to access the memory location specified in the transmit command but not actually read or transmit the data stored at that memory location. For example the NIC driver can indicate that the new transmit command is a NOP transmit command by setting an appropriate flag in the transmit command but specifying a negative or otherwise invalid length for the data to be transmitted etc.

In some examples the example NIC driver DMA enhancer additionally or alternatively includes an example transmit buffer initializer and an example transmit buffer filler as shown in the illustrated example of . As noted above in some examples the NIC driver programs the next transmit descriptor in the transmit descriptor ring e.g. as pointed to by the producer pointer of the transmit descriptor ring with the next transmit buffer storing the next data to be transmitted. The NIC driver in such examples may program the next transmit descriptor with the guest physical address of this transmit buffer just before the data stored in this buffer is to be retrieved for transmission. As such the NIC driver may change the guest physical address of the transmit buffer indexed by the next transmit descriptor after the next transmit descriptor has been prefetched by the transmit descriptor prefetcher of the example NIC DMA enhancer . In such examples the resulting transmit buffer address translation that is caused to be prefetched by the transmit buffer prefetcher may correspond to an old transmit buffer and thus the resulting address translation cached by the IOMMU in its IOTLB may not correspond to the actual next transmit buffer subsequently programmed by the NIC driver into the next transmit descriptor. Accordingly a cache miss may result when the NIC later attempts to retrieve the data stored in the actual e.g. updated transmit buffer indexed by the next transmit descriptor. Such behavior can occur for example in zero copy implementations in which transmit buffers are allocated as needed to the applications executing in the virtual machine and a particular application that is to transmit data calls or otherwise signals the NIC driver with a pointer to the transmit buffer in which the data is stored which the NIC driver then programs into the next transmit descriptor in the transmit descriptor ring .

To reduce the likelihood of cache misses occurring in the context of transmit buffer address translation the transmit buffer initializer of the example NIC driver DMA enhancer initializes a subset of the transmit buffers for use by the NIC driver and initializes the transmit descriptors in the transmit descriptor with the guest physical addresses of this subset of the transmit buffers . Then when a particular application that is to transmit data calls or otherwise signals the NIC driver with a pointer to the application s transmit buffer in which the transmit data is stored the transmit buffer filler of the example NIC driver DMA enhancer copies the data stored in the application s transmit buffer to the NIC driver s transmit buffer that is indexed by the next transmit descriptor in the transmit descriptor ring e.g. as pointed to by the ring s producer pointer . As such the transmit buffers allocated to the NIC driver are also referred to herein as transmit copy buffers. The NIC driver then issues a transmit command to the NIC indicating that there is data ready to be transmitted. In this way the transmit buffers indexed by the transmit descriptors in the transmit descriptor ring remain unchanged such that prefetching of the transmit buffer address translations is accurate and results in cache hits when the transmit buffers indexed by the transmit descriptors are later accessed by the NIC to retrieve the data for transmission.

In some examples the example NIC driver DMA enhancer additionally or alternatively includes the example transmit buffer initializer and an example transmit buffer allocator as shown in the illustrated example of to reduce the random nature in which the transmit buffers are located and used while still permitting zero copy transmit implementations. For example the transmit buffer initializer can be configured to initialize some or all of the transmit buffers to be located in one or more contiguous regions of memory that can be indexed for example using fewer than all of the address translation page tables employed by the IOMMU . The transmit buffer initializer also initially reserves these transmit buffers for use by the NIC driver . In such examples the transmit buffer allocator exposes or otherwise implements an application programming interface API or any other interface via which an application can request to be allocated one or more of the transmit buffers initially reserved for use by the NIC driver . Then in response to receiving a request from the application via this interface the transmit buffer allocator allocates the requested number of transmit buffers to the requesting application . In this way because the transmit buffers initially reserved for the NIC driver and subsequently allocated to the application s are located in contiguous region s of memory the IOMMU can perform address translations for these transmit buffers by walking fewer than the total number of page tables used by the IOMMU which can reduce the latency incurred by the IOMMU when performing address translations.

In the example NIC driver DMA enhancer of the receive address prefetcher the transmit buffer initializer the transmit buffer filler and the transmit buffer allocator are illustrated as being communicatively coupled to example interface logic which permits information to be exchanged with and or among some of all of the foregoing blocks e.g. depending upon which blocks are included in an example implementation . The interface logic can be implemented by for example but not limited to any number and or type s of communication control links busses digital logic software interfaces etc.

While an example manner of implementing the virtual processing environment is illustrated in one or more of the elements processes and or devices illustrated in may be combined divided re arranged omitted eliminated and or implemented in any other way. Further the example host processor the example virtual machine the example hypervisor the example system bus the example memory the example NIC the example external interface bus the example chipset the example communication medium the example application s the example protocol stack the example NIC driver the example IOMMU the example NIC DMA enhancer the example NIC driver DMA enhancer the example virtual NIC driver the example virtual NIC the example physical NIC driver the example address translation logic the example IOTLB the example receive descriptor prefetcher the example receive buffer prefetcher the example transmit descriptor prefetcher the example transmit buffer prefetcher the example receive address prefetcher the example transmit buffer initializer the example transmit buffer filler the example transmit buffer allocator and or more generally the example virtual processing environment may be implemented by hardware software firmware and or any combination of hardware software and or firmware. Thus for example any of the example host processor the example virtual machine the example hypervisor the example system bus the example memory the example NIC the example external interface bus the example chipset the example communication medium the example application s the example protocol stack the example NIC driver the example IOMMU the example NIC DMA enhancer the example NIC driver DMA enhancer the example virtual NIC driver the example virtual NIC the example physical NIC driver the example address translation logic the example IOTLB the example receive descriptor prefetcher the example receive buffer prefetcher the example transmit descriptor prefetcher the example transmit buffer prefetcher the example receive address prefetcher the example transmit buffer initializer the example transmit buffer filler the example transmit buffer allocator and or more generally the example virtual processing environment could be implemented by one or more analog or digital circuit s logic circuits programmable processor s application specific integrated circuit s ASIC s programmable logic device s PLD s and or field programmable logic device s FPLD s such as field programmable gate array s FPGA s . When reading any of the apparatus or system claims of this patent to cover a purely software and or firmware implementation at least one of the example virtual processing environment the example host processor the example virtual machine the example hypervisor the example system bus the example memory the example NIC the example external interface bus the example chipset the example communication medium the example application s the example protocol stack the example NIC driver the example IOMMU the example NIC DMA enhancer the example NIC driver DMA enhancer the example virtual NIC driver the example virtual NIC the example physical NIC driver the example address translation logic the example IOTLB the example receive descriptor prefetcher the example receive buffer prefetcher the example transmit descriptor prefetcher the example transmit buffer prefetcher the example receive address prefetcher the example transmit buffer initializer the example transmit buffer filler and or the example transmit buffer allocator is are hereby expressly defined to include a tangible computer readable storage device or storage disk such as a memory a digital versatile disk DVD a compact disk CD a Blu ray disk etc. storing the software and or firmware. Further still the example virtual processing environment of may include one or more elements processes and or devices in addition to or instead of those illustrated in and or may include more than one of any or all of the illustrated elements processes and devices.

Flowcharts representative of example machine readable instructions for implementing the example virtual processing environment the example host processor the example virtual machine the example hypervisor the example system bus the example memory the example NIC the example external interface bus the example chipset the example communication medium the example application s the example protocol stack the example NIC driver the example IOMMU the example NIC DMA enhancer the example NIC driver DMA enhancer the example virtual NIC driver the example virtual NIC the example physical NIC driver the example address translation logic the example IOTLB the example receive descriptor prefetcher the example receive buffer prefetcher the example transmit descriptor prefetcher the example transmit buffer prefetcher the example receive address prefetcher the example transmit buffer initializer the example transmit buffer filler and or the example transmit buffer allocator of are shown in . In these examples the machine readable instructions comprise one or more programs for execution by a processor such as the processor shown in the example processor platform discussed below in connection with . The program s may be embodied in software stored on a tangible computer readable storage medium such as a CD ROM a floppy disk a hard drive a digital versatile disk DVD a Blu ray disk or a memory associated with the processor but the entire program s and or parts thereof could alternatively be executed by a device other than the processor and or embodied in firmware or dedicated hardware. Further although the example program s is are described with reference to the flowcharts illustrated in many other methods of implementing the example virtual processing environment the example host processor the example virtual machine the example hypervisor the example system bus the example memory the example NIC the example external interface bus the example chipset the example communication medium the example application s the example protocol stack the example NIC driver the example IOMMU the example NIC DMA enhancer the example NIC driver DMA enhancer the example virtual NIC driver the example virtual NIC the example physical NIC driver the example address translation logic the example IOTLB the example receive descriptor prefetcher the example receive buffer prefetcher the example transmit descriptor prefetcher the example transmit buffer prefetcher the example receive address prefetcher the example transmit buffer initializer the example transmit buffer filler and or the example transmit buffer allocator may alternatively be used. For example the order of execution of the blocks may be changed and or some of the blocks described may be changed eliminated or combined.

As mentioned above the example processes of may be implemented using coded instructions e.g. computer and or machine readable instructions stored on a tangible computer readable storage medium such as a hard disk drive a flash memory a read only memory ROM a compact disk CD a digital versatile disk DVD a cache a random access memory RAM and or any other storage device or storage disk in which information is stored for any duration e.g. for extended time periods permanently for brief instances for temporarily buffering and or for caching of the information . As used herein the term tangible computer readable storage medium is expressly defined to include any type of computer readable storage device and or storage disk and to exclude propagating signals. As used herein tangible computer readable storage medium and tangible machine readable storage medium are used interchangeably. Additionally or alternatively the example processes of may be implemented using coded instructions e.g. computer and or machine readable instructions stored on a non transitory computer and or machine readable medium such as a hard disk drive a flash memory a read only memory a compact disk a digital versatile disk a cache a random access memory and or any other storage device or storage disk in which information is stored for any duration e.g. for extended time periods permanently for brief instances for temporarily buffering and or for caching of the information . As used herein the term non transitory computer readable medium is expressly defined to include any type of computer readable device or disk and to exclude propagating signals. As used herein when the phrase at least is used as the transition term in a preamble of a claim it is open ended in the same manner as the term comprising is open ended.

Example machine readable instructions that may be executed to implement address translation processing for DMA operations associated with receiving data in the example virtual processing environment of are illustrated in . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC driver of the virtual machine executing in the virtual processing environment initializes the receive descriptor ring which stores the receive descriptors indexing the receive buffers to be used by the NIC and the NIC driver for storing and retrieving data received via the communication medium . Then at block the NIC and or the NIC driver cause as described above prefetching of one or more address translations to be performed e.g. by the IOMMU after a current DMA operation for storing the current data received by the NIC has been performed and before the next data is to be received by the NIC . As described above the address translation s prefetched at block are associated with a next DMA operation to be performed to store the next data received by the NIC . For example the address translation s prefetched at block can correspond to an address translation mapping a guest physical address of the next receive descriptor in the receive descriptor ring to its host physical address and or an address translation mapping a guest physical address of the next receive buffer indexed by the next receive descriptor to the host physical address of this receive buffer . The processing at block can then be repeated indefinitely or until the virtual processing environment is rebooted restarted reinitialized etc.

Example machine readable instructions that may be executed to implement address translation processing for DMA operations associated with transmitting data in the example virtual processing environment of are illustrated in . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC driver of the virtual machine executing in the virtual processing environment initializes the transmit descriptor ring which stores the transmit descriptors indexing the transmit buffers to be used by the NIC and the NIC driver for storing and retrieving data to be transmitted via the communication medium . Then at block the NIC and or the NIC driver cause as described above prefetching of one or more address translations to be performed e.g. by the IOMMU after a current DMA operation for retrieving the current data for transmission by the NIC has been performed and before the next data is determined to be ready for transmission. As described above the address translation s prefetched at block are associated with a next DMA operation to be performed to retrieve the next data to be transmitted by the NIC . For example the address translation s prefetched at block can correspond to an address translation mapping a guest physical address of the next transmit descriptor in the transmit descriptor ring to its host physical address and or an address translation mapping a guest physical address of the next transmit buffer indexed by the next transmit descriptor to the host physical address of this transmit buffer . The processing at block can then be repeated indefinitely or until the virtual processing environment is rebooted restarted reinitialized etc.

Example machine readable instructions that may be executed to implement in the NIC of address translation processing for DMA operations associated with receiving data are illustrated in . The example machine readable instructions correspond to an example implementation by the NIC of the functionality provided by the example machine readable instructions of . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC is initialized by the NIC driver with the base address size and the producer and consumer pointers of the receive descriptor ring . At block the NIC receives a current received data packet via the communication medium . At block the NIC initiates a DMA read operation to retrieve via the IOMMU the current receive descriptor pointed to or indexed by the producer pointer of the receive descriptor ring . As described above the current receive descriptor indexes e.g. by including the guest physical address of the current receiver buffer to be used to store the data received at block . At block the NIC post increments the producer pointer of the receive descriptor ring to point to the next receive descriptor in the receive descriptor ring . As described above the next receive descriptor indexes e.g. by including the guest physical address of the next receiver buffer to be used to store the next data to be received by the NIC in the future. At block the NIC initiates a DMA write operation to store via the IOMMU the data received at block to the receive buffer indexed by the receive descriptor retrieved at block . At block the success of the DMA write operation performed at block is signaled to the NIC driver .

Next while the NIC is waiting for the next data packet to be received via the communication medium block the processing at blocks and or is performed. At block the receive descriptor prefetcher of the NIC causes the IOMMU to prefetch and cache an address translation mapping the guest physical address of the next receive descriptor pointed to by the producer pointer of the receive descriptor ring to the host physical address of this receive descriptor. As described above the receive descriptor prefetcher of the NIC causes the prefetching at block to be performed by for example initiating a DMA read operation to read the guest physical address pointed to by the producer pointer of the receive descriptor ring which corresponds to the guest physical address of the next receive descriptor in the receive descriptor ring . As further described above the DMA read operation performed at block causes the IOMMU to determine if necessary and cache the address translation mapping the guest physical address of the next receive descriptor to its host physical address. However because the next receive descriptor is not being read to actually store any received data the producer pointer of the receive descriptor ring is not post incremented at block .

At block the receive buffer prefetcher of the NIC causes the IOMMU to prefetch and cache an address translation mapping the guest physical address of the next receive buffer indexed by the next receive descriptor retrieved at block to the host physical address of this receive buffer . As described above the receive buffer prefetcher of the NIC causes the prefetching at block to be performed by for example initiating a DMA operation e.g. a dummy read or a dummy write to access the guest physical address of the receive buffer included in the next receive descriptor retrieved at block . As further described above the DMA operation performed at block causes the IOMMU to determine if necessary and cache the address translation mapping the guest physical address of the next receive buffer to its host physical address. Then when the next packet is received by the NIC block processing returns to block and the blocks subsequent thereto at which the NIC initiates DMA operations to store this next packet received via the communication medium . Due to the prefetching performed at block and or there may be a higher likelihood of achieving cache hits when performing the address translations for the DMA operations initiated to store this next received data.

Example machine readable instructions that may be executed to implement in the NIC driver of address translation processing for DMA operations associated with receiving data are illustrated in . The example machine readable instructions correspond to an example implementation by the NIC driver of the functionality provided by the example machine readable instructions of . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC driver initializes the base address size and the producer and consumer pointers of the receive descriptor ring . At block the receive address prefetcher of the NIC driver retrieves the producer pointer of the receive descriptor ring . For example the processing at block can be invoked by the receive address prefetcher of the NIC driver after receiving an indication that a DMA operation for storing current received data has succeeded and while waiting for the next such indication.

At block the receive address prefetcher of the NIC driver determines the guest physical address of the receive descriptor pointed to by the producer pointer of the receive descriptor ring . This receive descriptor corresponds to the next receive descriptor to be used by the NIC for storing the next data packet received via the communication medium . At block the receive address prefetcher of the NIC driver issues the new transmit command disclosed above which has a transmit buffer address set to the guest physical address of the receive descriptor determined at block . The transmit command issued by the NIC driver at block causes the NIC to initiate a DMA read operation to read the data stored at the guest physical address of the receive descriptor which in turn causes the IOMMU to determine if necessary and cache in its IOTLB an address translation mapping the guest physical address of this receive descriptor to its host physical address. As described above the transmit command issued at block can be configured to be a NOP transmit command such that the NIC does not actually transmit the data read from the next receive descriptor via the DMA read operation.

In some examples at block the receive address prefetcher of the NIC driver further determines the guest physical address of the receive buffer indexed by the next receive descriptor. This receive buffer corresponds to the next receive buffer to be used by the NIC for storing the next data packet received via the communication medium . In such examples at block the receive address prefetcher of the NIC driver issues another new transmit command which at block has a transmit buffer address set to the guest physical address of the receive buffer determined at block . The transmit command issued by the receive address prefetcher of the NIC driver at block causes the NIC to initiate a DMA read operation to read the data stored at the guest physical address of the next receive buffer which in turn causes the IOMMU to determine if necessary and cache in its IOTLB an address translation mapping the guest physical address of this next receive buffer to its host physical address. As described above the transmit command issued at block can be configured to be a NOP transmit command such that the NIC does not actually transmit the data read via from the next receive buffer via the DMA read operation. Due to the prefetching performed at block and or there may be a higher likelihood of achieving cache hits when performing address translations for the next DMA operations initiated by the NIC to store this next data received via the communication medium .

Example machine readable instructions that may be executed to implement in the NIC of address translation processing for DMA operations associated with transmitting data are illustrated in . The example machine readable instructions correspond to an example implementation by the NIC of the functionality provided by the example machine readable instructions of . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC is initialized by the NIC driver with the base address size and the producer and consumer pointers of the transmit descriptor ring . At block the NIC receives a transmit command from the NIC driver indicating that there is data ready to be transmitted via the communication medium . At block the NIC initiates a DMA read operation to retrieve via the IOMMU the current transmit descriptor pointed to or indexed by the consumer pointer of the transmit descriptor ring . As described above the current transmit descriptor indexes e.g. by including the guest physical address of the current transmit buffer storing the data to be transmitted by the NIC . At block the NIC post increments the consumer pointer of the transmit descriptor ring to point to the next transmit descriptor in the transmit descriptor ring . As described above this next transmit descriptor indexes e.g. by including the guest physical address of the next transmit buffer to be used to store the next data to be transmitted by the NIC in the future. At block the NIC initiates a DMA read operation to retrieve via the IOMMU the data stored in the transmit buffer indexed by the transmit descriptor retrieved at block . At block the NIC transmits the data retrieved at block over the communication medium .

Next while the NIC is waiting for the next transmit command from the NIC driver block the processing at blocks and or is performed. At block the transmit descriptor prefetcher of the NIC causes the IOMMU to prefetch and cache an address translation mapping the guest physical address of the next transmit descriptor pointed to by the consumer pointer of the transmit descriptor ring to the host physical address of this transmit descriptor. As described above the transmit descriptor prefetcher of the NIC causes the prefetching at block to be performed by for example initiating a DMA read operation to read the guest physical address pointed to by the consumer pointer of the transmit descriptor ring which corresponds to the guest physical address of the next transmit descriptor in the transmit descriptor ring . As further described above the DMA read operation performed at block causes the IOMMU to determine if necessary and cache the address translation mapping the guest physical address of the next transmit descriptor to its host physical address. However because the next receive descriptor is not being read to actually retrieve any data for transmission the consumer pointer of the transmit descriptor ring is not post incremented at block .

In some examples e.g. such as in the examples described above in which the transmit buffers are allocated to copied to and or otherwise managed by the NIC driver at block the transmit buffer prefetcher of the NIC causes the IOMMU to prefetch and cache an address translation mapping the guest physical address of the next transmit buffer which is indexed by the next transmit descriptor retrieved at block to the host physical address of this transmit buffer . As described above the transmit buffer prefetcher of the NIC causes the prefetching at block to be performed by for example initiating a DMA read operation to access the guest physical address of the transmit buffer included in the next transmit descriptor which was retrieved at block . As further described above the DMA operation performed at block causes the IOMMU to determine if necessary and cache the address translation mapping the guest physical address of the next transmit buffer to its host physical address. Then when the next transmit command is received by the NIC block processing returns to block and the blocks subsequent thereto at which the NIC initiates DMA operations to retrieve the next packet to be transmitted via the communication medium . Due to the prefetching performed at block and or there may be a higher likelihood of achieving cache hits when performing address translations for the DMA operations initiated to retrieve this next data to be transmitted.

Example machine readable instructions that may be executed to implement in the NIC driver of address translation processing for DMA operations associated with transmitting data are illustrated in . The example machine readable instructions correspond to an example implementation by the NIC driver of the functionality provided by the example machine readable instructions of . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC driver initializes the base address size and the producer and consumer pointers of the transmit descriptor ring . At block the transmit buffer initializer of the NIC driver initializes as described above a subset of the transmit buffers for use by the NIC driver as transmit copy buffers . At block the transmit buffer initializer of the NIC driver initializes the transmit descriptors in the transmit descriptor ring to index the transmit copy buffers initialized at block . At block the NIC driver receives a call from an application including a pointer to the application s transmit buffer which is storing the data to be transmitted. At block the transmit buffer filler of the NIC driver copies the data for transmission from the application s transmit buffer to the current transmit copy buffer indexed by the transmit descriptor pointed to by the producer pointer of the transmit descriptor ring . At block the transmit buffer filler of the NIC driver post increments the producer pointer to point to the next transmit descriptor in the transmit descriptor ring which indexes the next transmit copy buffer into which the NIC driver will copy the next data to be transmitted. At block the NIC driver issues a transmit command to the NIC indicating there is data that is ready to be transmitted.

Example machine readable instructions that may be executed to implement transmit buffer allocation processing in the NIC driver of are illustrated in . With reference to the preceding figures and associated descriptions the example machine readable instructions of begin execution at block at which the NIC driver initializes the base address size and the producer and consumer pointers of the transmit descriptor ring . At block the transmit buffer initializer of the NIC driver initializes as described above some or all of the transmit buffers to be located in one or more contiguous regions of memory and reserves these transmit buffers for allocation by the NIC driver . As described above the transmit buffers initialized at block are located in the memory such that they can be indexed for example using fewer than all of the address translation page tables employed by the IOMMU . At block the transmit buffer allocator of the NIC driver exposes as described above an API via which an application can request to be allocated one or more of the transmit buffers reserved at block for allocation by the NIC driver . At block the transmit buffer allocator of the NIC driver allocates the requested number s of transmit buffers to those application s from which requests are received.

The processor platform of the illustrated example includes a processor . The processor of the illustrated example is hardware. For example the processor can be implemented by one or more integrated circuits logic circuits microprocessors or controllers from any desired family or manufacturer.

The processor of the illustrated example includes a local memory e.g. a cache . The processor of the illustrated example is in communication with a main memory including a volatile memory and a non volatile memory via a bus . The volatile memory may be implemented by Synchronous Dynamic Random Access Memory SDRAM Dynamic Random Access Memory DRAM RAMBUS Dynamic Random Access Memory RDRAM and or any other type of random access memory device. The non volatile memory may be implemented by flash memory and or any other desired type of memory device. Access to the main memory is controlled by a memory controller.

The processor platform of the illustrated example also includes an interface circuit . The interface circuit may be implemented by any type of interface standard such as an Ethernet interface a universal serial bus USB and or a PCI express interface.

In the illustrated example one or more input devices are connected to the interface circuit . The input device s permit s a user to enter data and commands into the processor . The input device s can be implemented by for example a microphone a camera still or video a keyboard a button a mouse a touchscreen a track pad a trackball isopoint and or a voice recognition system.

One or more output devices are also connected to the interface circuit of the illustrated example. The output devices can be implemented for example by display devices e.g. a light emitting diode LED an organic light emitting diode OLED a liquid crystal display a cathode ray tube display CRT a touchscreen a tactile output device a light emitting diode LED a printer and or speakers . The interface circuit of the illustrated example thus typically includes a graphics driver card a graphics driver chip or a graphics driver processor.

The interface circuit of the illustrated example also includes a communication device such as a transmitter a receiver a transceiver a modem and or network interface card to facilitate exchange of data with external machines e.g. computing devices of any kind via a network e.g. an Ethernet connection a digital subscriber line DSL a telephone line coaxial cable a cellular telephone system etc. .

The processor platform of the illustrated example also includes one or more mass storage devices for storing software and or data. Examples of such mass storage devices include floppy disk drives hard drive disks compact disk drives Blu ray disk drives RAID systems and digital versatile disk DVD drives.

The coded instructions of may be stored in the mass storage device in the volatile memory in the non volatile memory and or on a removable tangible computer readable storage medium such as a CD or DVD.

As an alternative to implementing the methods and or apparatus described herein in a system such as the processing system of the methods and or apparatus described herein may be embedded in a structure such as a processor and or an ASIC application specific integrated circuit .

Although certain example methods apparatus and articles of manufacture have been disclosed herein the scope of coverage of this patent is not limited thereto. On the contrary this patent covers all methods apparatus and articles of manufacture fairly falling within the scope of the claims of this patent.

