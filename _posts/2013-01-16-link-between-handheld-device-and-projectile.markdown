---

title: Link between handheld device and projectile
abstract: A projectile can be equipped with a camera and be configured to detonate after receiving a command to detonate. After the projectile is thrown the camera can capture images. These images can be sent by way of the physical link to the handheld device. The handheld device can display the images. A user of the handheld device can view the images and determine if the projectile should detonate based on the images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09036942&OS=09036942&RS=09036942
owner: The United States of America, as represented by the Secretary of the Army
number: 09036942
owner_city: Washington
owner_country: US
publication_date: 20130116
---
The innovation described herein may be manufactured used imported sold and licensed by or for the Government of the United States of America without the payment of any royalty thereon or therefor.

In a combat setting a warfighter can identify an enemy target. This enemy target can be considered a threat to the warfighter and in view of this threat the warfighter can make a decision to attempt to eliminate the threat. Various weapons can be used to eliminate the threat. For example a shrapnel grenade can be used to eliminate the threat. The shrapnel grenade can have a pin in place that stops the shrapnel grenade from activating. When the pin is pulled a timer of the shrapnel grenade can activate unless the timer is manually paused or the pin is replaced. The warfighter can throw the shrapnel grenade and the shrapnel grenade can detonate after the timer expires. The goal can be for the timer to expire when the shrapnel grenade reaches the threat such that the threat is subjected to the shrapnel.

A system comprising an access component a stitch component a display an interface an analysis component a determination component and a causation component is described. The access component is configured to access a plurality of images where the plurality of images are collected from a projectile by way of a physical link. The stitch component is configured to produce a composite image from the plurality of images where the composite image is of a higher resolution level than a resolution level of individual images of the plurality of images. The display is configured to display the composite image while the interface is configured to receive an input after the display displays the composite image. The analysis component is configured to perform an analysis of the input The determination component is configured to make a determination on if the input is an instruction to cause an ordnance of the projectile to explode where the determination is based at least in part on a result of the analysis. The causation component is configured to cause the ordnance of the projectile to explode in response to the input being the instruction to cause the ordnance of the projectile to explode.

A system comprising a detonation component and an image acquisition component is described. The detonation component is configured to cause an ordnance to detonate. The image acquisition component is configured to cause a capture of a plurality of images where the detonation component and the image acquisition component are retained in a housing and where the housing is tethered to a handheld device by way of a physical link.

A handheld device comprising a display an interface a processor and a computer readable medium is described. The display is configured to display a compound image where the compound image is an image stitched from a plurality of images where the compound image is of a higher resolution level then a resolution level of individual images of the plurality of images and where the plurality of images are obtained from an grenade tethered by a physical link to the handheld device. The interface is configured to obtain an input while the computer readable medium is configured to store computer executable instructions that when executed by the processor cause the processor to perform a method. The method comprises performing an analysis of the input making a determination on if the input is an instruction to cause an ordnance of the grenade to detonate where the determination is based at least in part on a result of the analysis and causing the ordnance of the grenade to detonate in response to the input being the instruction to cause the ordnance of the grenade to detonate.

Systems methods and other embodiments disclosed herein are related to a physical link between a handheld device and a projectile. The projectile can be a grenade e.g. concussion grenade and the grenade can be used in a modern combat operation. In an example of a modern combat operation multiple combat teams of several members each can attempt to eliminate threats in a large building. The multiple combat teams can enter the large building from different points of entry and attempt to systematically enter rooms to eliminate threats. Due to various factors such as darkness noise limited operational intelligence and heightened senses the work performed by the multiple combat teams can be difficult confusing and dangerous.

For example a first combat team can enter from a west entry point and a second combat team can enter from an east entry point. These combat teams can progressively go through rooms attempting to identify and eliminate threats. One way to identify and eliminate threats is to throw a concussion grenade in a room and after the concussion grenade detonates a combat team enters the room. This method has multiple drawbacks. A first drawback is that the concussion grenade is wasted if the room does not have any target inside. A second drawback is that friendly forces may be inside the room and as such the friendly forces become concussed causing them to be temporarily ineffective or have mild to severe injuries. For example unbeknown to one another the first combat team and the second combat team can be in adjoining rooms in the large building. The first combat team can throw the concussion grenade in the room of the second combat team and the concussion grenade can detonate after a timer expires. Thus the second combat team is subjected to the concussion grenade.

To alleviate unintentional subjection to a projectile such as the concussion grenade the projectile can be equipped with a camera and be configured to detonate after receiving a command to detonate. After the projectile is thrown the camera can capture images. These images can be sent by way of the physical link to the handheld device. The handheld device can display the images. A user of the handheld device can view the images and determine if the projectile should detonate based on the images. Returning to the example in the previous paragraph the concussion grenade can have a camera that sends images along a physical link to a handheld device. If the first combat team throws the concussion grenade in the room with the second combat team then a user of the handheld device can identify that the second combat team is in the room and not cause the concussion grenade to detonate. Therefore the second combat team would not be subject to the concussion grenade.

The following includes definitions of selected terms employed herein. The definitions include various examples. The examples are not intended to be limiting.

 One embodiment an embodiment one example an example and so on indicate that the embodiment s or example s can include a particular feature structure characteristic property or element but that not every embodiment or example necessarily includes that particular feature structure characteristic property or element. Furthermore repeated use of the phrase in one embodiment may or may not refer to the same embodiment.

 Computer readable medium as used herein refers to a medium that stores signals instructions and or data. Examples of a computer readable medium include but are not limited to non volatile media and volatile media. Non volatile media may include for example optical disks magnetic disks and so on. Volatile media may include for example semiconductor memories dynamic memory and so on. Common forms of a computer readable medium may include but are not limited to a floppy disk a flexible disk a hard disk a magnetic tape other magnetic medium other optical medium a Random Access Memory RAM a Read Only Memory ROM a memory chip or card a memory stick and other media from which a computer a processor or other electronic device can read. In one embodiment the computer readable medium is a non transitory computer readable medium.

 Component as used herein includes but is not limited to hardware firmware software stored on a computer readable medium or in execution on a machine and or combinations of each to perform a function s or an action s and or to cause a function or action from another component method and or system. Component may include a software controlled microprocessor a discrete component an analog circuit a digital circuit a programmed logic device a memory device containing instructions and so on. Where multiple components are described it may be possible to incorporate the multiple components into one physical component or conversely where a single component is described it may be possible to distribute that single logical component between multiple components.

 Software as used herein includes but is not limited to one or more executable instructions stored on a computer readable medium that cause a computer processor or other electronic device to perform functions actions and or behave in a desired manner. The instructions may be embodied in various forms including routines algorithms modules methods threads and or programs including separate applications or code from dynamically linked libraries.

The access component is configured to access a plurality of images where the plurality of images is collected from a projectile by way of a physical link . The projectile can be equipped with a camera to capture the plurality of images e.g. two or more images or a single image. The plurality of images can be transferred from the projectile to the system over the physical link . The access component can function as a collection component that receives the plurality of images from the physical link . The access component can be a passive component that collects the plurality of images or an active component that performs processing on the plurality of images e.g. improving contrast ratio color space correction etc. . As an example of an active component the plurality of images can be sent in a compressed file format e.g. compressed by a component of the projectile and the access component can decompress the plurality of images once received.

The stitch component is configured to produce a composite image from the plurality of images. In one example the projectile can be rolled into a room and as the projectile rolls the projectile can capture the plurality of images. Further the projectile can have multiple cameras that are pointed in different directions. These multiple cameras can capture the plurality of images and the stitch component can create a composite image that is a panoramic view of an area. In one embodiment the stitch component can being image stitching as individual images of the plurality of images arrive. For example the access component can collect a first image and a second image of the plurality of images. The stitch component can stitch together the first image and the second image into a composite image while a third image of the plurality of images is being collected. Once the third image is collected or once the first image and second image are stitched together the third image can be stitched into the composite image. In one embodiment the first image is taken at a first point in time the second image is taken at a second point in time after the first point in time and the third image is taken at a third point in time after the second point in time. The stitch component can stitch the first image with the third image to form the composite image. The stitch component can improve the composite image by stitching in the second image. In one embodiment the composite image is of a higher resolution level than a resolution level of individual images of the plurality of images.

The display is configured to display the composite image e.g. at least part of the composite image and the interface is configured to receive an input after the display displays the composite image. The display e.g. a screen and the interface e.g. graphical user interface of the display hardware keypad etc. can be used together. The display can provide notice that the composite image can be viewed and give an instruction of a key to press on the interface to cause the composite image to be displayed upon the interface . When the key is pressed the display displays the composite image. The interface can be used to change how the composite image is displayed upon the display . For example the interface can include keys for zooming in or out for the composite image panning the composite image and others. In one embodiment the interface is part of the display e.g. the interface is part of a touch screen that is the display .

The analysis component is configured to perform an analysis of the input of the interface and the determination component is configured to make a determination on if the input is an instruction to cause an ordnance of the projectile to explode. The determination can be based at least in part on a result of the analysis. The causation component is configured to cause the ordnance of the projectile to explode in response to the input being the instruction to cause the ordnance of the projectile to explode. The instruction can be produced by an operator e.g. by way of the interface or be proactively e.g. automatically generated.

For example a user can view the composite image that is presented on the display and make an identification that the projectile is near a threat. Based on this identification the user can press a button on the interface for the ordnance of the projectile to detonate. The analysis component identifies that the button is pressed e.g. identifies what button is pressed and the determination component determines a function associated with the pressed button e.g. an instruction to cause the ordnance to explode . When the determination component determines that the button to cause the ordnance to explode is pressed the causation component can function to cause the ordnance of the projectile to explode. For example this can be done by sending an electronic impulse from the system to the projectile along the physical link . The electronic impulse from the causation component can cause the ordnance to detonate upon receipt.

The compensation component is configured to produce a compensation factor for a difference between how a first image of the plurality of images is captured and how a second image of the plurality of images is captured. The compensation factor assists image stitching functionality such as by incorporating information about the movement of the projectile and other environmental factors. The stitch component is configured to produce the composite image through performance of a stitch of the first image together with the second image where performance of the stitch comprises use of the compensation factor. It is to be appreciated by one of ordinary skill in the art that while discussion is made of the compensation factor regarding two images the compensation factor can be used in stitching multiple images.

In one example with regard to the compensation factor the first image can be taken at a first point in time and the second image can be taken at a second point in time. The target can make a movement between the first moment in time and the second moment in time. This movement can cause difficulty in stitching the first image and the second image together since the target is in different locations and or positions among the images. The compensation component can create a compensation factor based on this movement where the movement can be mathematically determined by an accelerometer e.g. built into the projectile . Examples of the compensation factor can include modifying an image applying a mathematical formula to the images e.g. where the mathematical formula modifies pixel values making an estimate etc.

In one example with regard to the compensation factor the projectile can be thrown into a room and while the projectile travels e.g. in flight after touching ground etc. images can be captured of the room. Due to changes from when images are captured e.g. changes in altitude due to the throw the compensation factor can be produced and used to compensate for those changes. Multiple compensation factors can be used and the multiple compensation factors can be used in producing the composite image.

The projectile of can be the explosive ordnance device that is linked to the handheld device . The handheld device can be a smart phone a laptop computer a specifically designed device or other device. The handheld device can supply power to the explosive ordnance device by way of the physical link and or retain a power supply. Components of the system of and or the system of can be part of the handheld device e.g. the access component of is part of the handheld device the stitch component of is part of the handheld device the analysis component of is part of the handheld device the determination component is part of the handheld device and the causation component is part of the handheld device . The interface of and the display of can be part of the handheld device . The physical link can be a tether between the explosive ordnance device and the handheld device e.g. used to retrieve the explosive ordnance device .

The explosive ordnance device can be equipped with the image capture component that is configured to cause capture of the plurality of images. In one embodiment the image capture component is a single fixed camera. In one embodiment the image capture component is a single camera that is moveable e.g. from command of the interface of . In one embodiment the image capture component is multiple cameras e.g. fixed and or movable that take images concurrently or at different times. In one embodiment the image capture component is at least one infrared sensor that captures at least one heat based image that is part of the plurality of images.

The explosive ordnance device uses the transfer component to send the plurality of images from the explosive ordnance device to the handheld device e.g. along the physical link . The access component of e.g. that is part of the handheld device is configured to collect the plurality of images sent by the transfer component . The transfer component can send metadata about the plurality of images e.g. additional information about the images such as time taken or exposure length obtained by the explosive ordnance device to the handheld device . The handheld device can display the metadata e.g. by way of the display of use the metadata in creating the composite image etc.

The system is an example of the projectile of . The projectile of can include an ordnance e.g. lethal weapon payload smoke payload concussion payload sound wave emitter payload etc. and the detonation component can be configured to cause the ordnance to detonate e.g. in response to receiving a command from the causation component of .

In one embodiment the detonation component functions in response to a command from the handheld device . The handheld device can display a stitched image derived from a plurality of images and based on the stitch image a user can cause the handheld device to send the command to the detonation component . The image acquisition component is configured to cause a capture of the plurality of images.

The detonation component and the image capture component e.g. a camera are retained in a housing e.g. the projectile of . The housing is tethered to the handheld device by way of the physical link e.g. optical fiber conducting wire etc. . The housing can also retain the ordnance e.g. ordnance of where the plurality of images e.g. still images video images are sent from the housing to the handheld device by way of the physical link . Sending the plurality of images over the physical link can lower jamming susceptibility and lower a likelihood of detection e.g. if wireless communication is not used . Individual images of the plurality of images can be visual images infrared images night vision images etc. In one embodiment the plurality of images cover an area of about 360 degrees around the housing. The handheld device can be configured to perform an image stitch of the plurality of images to create a composite image e.g. by way of the stitch component of . In one embodiment the stitch component of is retained by the housing and the composite image is sent from the housing to the handheld device along the physical link . In one embodiment the composite image covers the area of about 360 degrees around the housing.

In one embodiment the plurality of images from which the composite image is derived are captured by use of a light illumination. The light illumination is of a level sufficient to cause at least partial visual impairment to a person. For example the housing can be thrown into a room and when a condition is met e.g. once movement of the housing stops light illumination can occur that blinds a target. Therefore the housing can be used as a flash grenade. The housing can be outfitted with multiple ordnance types such as flash smoke concussion shrapnel strong sound emitter and others. In one example the light illumination is initially used to blind a target and also used to provide lighting for image capturing. Images captured by way of this image capturing can be stitched together e.g. at the housing at the handheld device etc. and presented on a display of the handheld device . Stitching can occur when a condition is met e.g. when a certain reading is measured by an accelerometer of the housing . Upon viewing this image a user can decide to enter an area where the target is located and where light illumination occurs e.g. since a target may be blinded and or a command can be sent from the handheld device to have another function occur after light illumination e.g. a concussion ordnance can detonate . Thus the housing can retain more than one ordnance type e.g. flash and concussion that can be caused to be detonated by the detonation component .

The sensor component e.g. a sensor that can be retained by the housing is configured to obtain a contextual information set a set of information different from the actual images where the contextual information set is information about surroundings of the housing after deployment of the housing e.g. after the housing is thrown towards a threat . In one embodiment the contextual information set is sent across the physical link to the handheld device and presented on a display of the handheld device e.g. the display of .

The sensor analysis component is configured to analyze the contextual information set to produce a sensor analysis result. The setting selection component is configured make a selection of a setting set for the image capture component where the selection of the setting set is based at least in part on the sensor analysis result. The implementation component is configured to cause the capture of the plurality of images to occur in accordance with the setting set.

In one example the sensor component can obtain distance and lighting data in an area upon which the housing is thrown. The sensor analysis component can evaluate the distance and lighting data and based on this evaluation the setting selection component selects the setting set. Regarding the distance data the sensor analysis component identifies a distance between the housing and the target. The setting selection component selects a focus level based on the distance identified e.g. selects a focus level for optimal image quality . Regarding the lighting data the sensor analysis component determines if a lighting level determined from the lighting data is sufficient to capture visual images. If not then the setting selection component selects a flash level to be used in capturing the plurality of images and the implementation component causes light illumination to occur in accordance with the flash level.

In one embodiment using the flash or another feature such as a laser range finder can be overridden automatically or by user command. For example if the housing is deployed in an area where the target does not know another force is nearby then the flash can be disabled so as not to alert the target. This disabling can be through a user command to not use the flash a lack of command to enable the flash an inference drawn by the housing e.g. how the housing is deployed etc. When lighting is desirable yet not feasible due to contextual circumstances e.g. a covert operation is being performed the image acquisition component can capture the plurality of images without flash and less than optimal composite image can be produced since optimal light was not used e.g. with optimal being with using flash .

The housing can retain the obtainment component the evaluation component and the instruction component . The obtainment component is configured to obtain an operator instruction from the handheld device by way of the physical link . In one embodiment the operator instruction is entered by way of the interface of . The evaluation component is configured to perform an evaluation of the operator instruction. The instruction component is configured to make a determination on if the operator instruction is to cause the ordnance to detonate where the determination is based at least in part on a result of the evaluation. The detonation component is configured to cause the ordnance to detonate in response to the determination being that the operator instruction is to cause the ordnance to detonate.

The image analysis component is configured to analyze the plurality of images e.g. obtained by the image acquisition component and or the composite image to produce an analysis result. The threat component is configured to proactively e.g. automatically make a determination on if the detonation component should cause the ordnance to detonate based at least in part on the analysis result. The detonation component causes the ordnance to detonate in response to the determination being that the detonation component should cause the ordnance to detonate.

For example the system is connected to the handheld device by way of the physical link . The composite image can be generated but with a less than ideal quality level. A user can view the composite image and see a human figure. Based on viewing this human figure the user can give a user instruction to detonate the ordnance. However in viewing the human figure the user can mistakenly identify the human figure as a threat where the human figure can be a friendly force. Therefore following user instruction can cause an accident in that the ordnance detonates toward a friendly force.

The image analysis component and the threat component can work together to prevent the accident from occurring. The image analysis component analyzes the plurality of images and or the composite image and based on this analysis a determination is made that the human figure is a friendly force with a certainty level above a threshold level. In one example this analysis can include viewing of image pixels of a patch on a uniform of the human figure. While the patch may not be visible to the human eye the analysis can result in a determination that the patch is a patch likely to be worn by a friendly force and not worn by a threat. Based on this determination the system can override the user instruction to detonate the ordnance. The system can send a message as to why the override occurs e.g. the message is displayed on the interface of . In one embodiment the user can supersede the override and cause the ordnance to detonate while in one embodiment the user can be prevented from superseding the override. In short final authorization for use of the detonation component can reside with the system e.g. detonation does not occur regardless of a command from the handheld device or with the handheld device e.g. a user can give final authorization that overrides a decision of the system .

The RFID component is configured to identify a radio frequency information set evaluate the radio frequency information set to produce an evaluation result and make a determination on if the ordnance should detonate based at least in part on the evaluation result. The detonation component can cause the ordnance to detonate in response to the determination being that the ordnance should detonate.

In one embodiment the RFID component is configured to prevent the detonation component from causing the ordnance to detonate when a detonation instruction is identified for the ordnance and when the determination is that the ordnance should not detonate. It can be beneficial to have a check and balance configuration to stop accidental detonation of the ordnance e.g. by employing image analysis as discussed with . Use of a radio frequency identifier can function as part of this check and balance configuration.

For example the system can be part of a flash grenade. The flash grenade can be thrown into a room where a user of the handheld device is not located. The image acquisition component captures images and sends these images along the physical link . The images are stitched together and displayed e.g. on the handheld device . A person can be identified in the room by a user and the user can send a command from the handheld device for the ordnance to detonate. The command can travel along the physical link to the flash grenade and in turn the system . The person can have an RFID device that indicates that they are friendly. Since the command may be an error e.g. detonate the flash grenade nearby a friendly person the RFID component can stop the command from being followed. In one embodiment an indication can be displayed on the handheld device as to why detonation does not occur and or the handheld device can be able to override this command stop.

In one embodiment the radio frequency information set is that a person without an authorized RFID tag is handling the ordnance. In this embodiment the determination is that the ordnance should detonate because the person without the authorized radio frequency identification tag is handling the ordnance. The ordnance can be part of a shrapnel grenade that is thrown toward a target. The target can attempt to disarm the shrapnel grenade or attempt to throw the shrapnel grenade to a place of origin or other location. Either of these situations can be seen as undesirable from the perspective of a user throwing the shrapnel grenade. Therefore if the shrapnel grenade is handled by someone without an RFID tag e.g. after a length of time after a pin is removed then the shrapnel grenade can detonate. However if the shrapnel grenade is handheld by a friendly force with an RFID tag then it can be desirable for detonation in response to the handling to be stopped. Therefore the system can function to determine if a handler has an RFID tag e.g. indicating that the handler is a friendly force . If the handler has a RFID tag then detonation does not occur otherwise the shrapnel grenade detonates.

The system can connect to the handheld device by way of the physical link and a command can be received by the system from the handheld device to override detonation stoppage. For example RFID tags used by a friendly unit can have individual identifiers. A specific RFID tag can be stolen and used by an enemy soldier. When the enemy soldier handles a housing with the system e.g. the housing retains the ordnance the specific RFID tag can be identified e.g. by a component of the system by the handheld device by a combination thereof etc. . The handheld device can display a number of the specific RFID tag and or an indication that the tag is stolen. Based on this information a user of the handheld device can cause the ordnance to detonate e.g. send a command that overrides a normal stop of such a command by sending a command to the detonation component that the detonation component follows.

The smoke component is configured to cause a smoke to be produced where the image acquisition component is configured to cause the capture of the plurality of images after the smoke is produced. The image acquisition component can be configured to cause the capture of the plurality of images through a non visual capture technique. The housing retains the detonation component the image acquisition component the smoke component and the ordnance.

In one embodiment the plurality of images are captured by way of a thermal image technique within a frequency range that is not substantially interfered with by the smoke or captured by way of another non visual image capture technique. Thermal images can be sent to the handheld device along the physical link and be stitched into a composite image at the handheld device or at the system . The stitched image is displayed on the display of and a user can make a decision from viewing the stitched image e.g. decide to enter a room decide to send an electrical pulse etc. . This decision can be to send a neutralize command e.g. stop detonation from being possible to the detonation component .

The creation component is configured create the composite image where the housing retains the creation component along with the detonation component and the image acquisition component . In one embodiment the creation component employs an algorithm to create the composite image where the algorithm is configured to manipulate at least one individual image of the plurality of images to produce a manipulated image set e.g. at least one manipulated image and one non manipulate image . The creation component creates the composite image by combining individual images of the manipulated image set. The composite image can be sent from the housing that incorporates the system to the handheld device along the physical link . While shown as part of the system the detonation component the image acquisition component and or the creation component can be part of the handheld device .

In one embodiment the image acquisition component can include a rotatable camera e.g. fish eye camera . At a first instance in time the camera captures a first image from a first position and at a second instance in time different from the first instance in time the camera captures a second image from a second position different from the first position . The first image and the second image can have an overlap. This overlap can be useful to ensure that gaps do not occur among the plurality of images and or to increase resolution in the composite image. Therefore when individual images are stitched together stitching can be performed more easily since common references can exist among images e.g. a common item in two pictures due to the overlap . In addition some of the overlap may have inconstancies. For example an object in overlapped portions can move from the first instance in time to the second instance in time. In view of this the first image and or the second image can be manipulated so the object does not appear as distorted in the composite image. In one embodiment if a problem among individual images of the plurality of images cannot be rectified e.g. manipulation cannot successfully correct a discrepancy among images then the image acquisition component can capture one or more images e.g. capture an image of an area from which the discrepancy arises .

A handheld housing e.g. acrylic housing retains a camera and the gyroscopic component . The handheld housing can connect to the handheld device by way of the physical link . The handheld housing can also retain the detonation component the image acquisition component and other components disclosed herein along with the gyroscopic component . After the handheld housing is deployed the gyroscopic component is configured to stabilize the handheld housing while the camera captures the plurality of images e.g. through use of counterbalancing weights where the image acquisition component causes the camera to capture the plurality of images. In one embodiment the gyroscopic component can stabilize proactively e.g. without instruction when a criterion is met and or in response to identification of a stabilization instruction e.g. sent from the handheld device . For example the stabilization instruction can be entered into the interface of .

The interface is configured to obtain an input e.g. an input from a user while the display is configured to display a compound image. The interface and display can function as a single unit e.g. as a smart phone screen such as a screen that enables zoom features through two finger touch . The compound image is an image stitched from a plurality of images where the compound image is of a higher resolution level then a resolution level of individual images of the plurality of image. The plurality of images are obtained from a grenade e.g. a grenade that functions as the projectile of that can be launched from a grenade launcher tethered by physical link to the handheld device .

The handheld device also comprises the computer readable medium configured to store computer executable instructions that when executed by the processor cause the processor to perform a method. In one embodiment the method comprises performing an analysis of the input making a determination on if the input is an instruction to cause an ordnance of the grenade to detonate e.g. the determination is based at least in part on a result of the analysis and causing the ordnance of the grenade to detonate e.g. send a detonation instruction signal from the handheld device to the grenade in response to the input being the instruction to cause the ordnance of the grenade to detonate.

For example a police officer for a SWAT special weapons and tactics team can throw a concussion grenade in a room view a stitched images produced from images captured by the concussion grenade and place an input for the concussion grenade to detonate. The input is analyzed and identified as a command for the concussion grenade to detonate. If a stop condition does not exist e.g. a friendly RFID tag is identified near the grenade then a signal can be sent to the concussion grenade for an ordnance of the concussion grenade to detonate.

In one embodiment the interface is configured to present a command portion. The command portion can be used to command operation of the grenade. For example the command portion can be configured to direct movement of the grenade control when images are captured from the grenade control how images are captured from the grenade e.g. control focus of the camera control which camera to use e.g. a digital camera or a thermal camera and others.

In one example a soldier can send a smoke grenade into a room. However the smoke grenade can land in a location that obstructs the view of at least one camera of the smoke grenade. The smoke grenade can be equipped with movement capabilities e.g. wheels . The smoke grenade can receive movement commands from the handheld device e.g. by way of the interface and follow those commands such that the smoke grenade is no longer obstructed.

In one embodiment the grenade e.g. functioning as the projectile of can include a self correction capability. For example a camera of the grenade can take a photograph and the grenade can include a component e.g. the evaluation component of to evaluate the photograph. A determination can be made by way of the processor that the camera is blocked. The grenade can first attempt to move the camera and determine if the camera is still blocked. If the camera is still blocked then the grenade can attempt to move to an unblocked location e.g. perform at least one move and check action . Once in an unblocked location the grenade can capture the images and the images can be sent to the handheld device for stitching or stitching occurs at the grenade and the stitched image is received by the handheld device . For example the processor can be used in processing the individual images for use in a stitching algorithm.

At an image set e.g. one or more images can be received e.g. from the projectile of stitched together into a stitched image at and the stitched image is displayed at . In one embodiment the stitched image can be in the image set received at and then displayed at without stitching at . Data can be collected about the stitched image at and this data is displayed at e.g. such that the stitched image and data are displayed concurrently . Example data can include identifiers of individuals shown in the stitched image coordinate information of the stitched image time data of when images were take upon which the stitched image is based etc. A person can enter a command e.g. by way of the display of and or the interface of . This command can be received at and be analyzed at e.g. by the analysis component of . The command can be verified at and then be followed at .

In one example a user can enter a command to have more images taken and for another stitched image to be produced. This command can be received and analyzed to determine what is being requested. The command can be verified to make sure that what is being requested can be followed that the determination is accurate etc. An instruction can be created based on this determination e.g. through use of the processor of and the command can be followed by sending the instruction e.g. to the projectile of .

In one embodiment the processor of and the computer readable medium of can both be part of the projectile of . The projectile of can collect images at and transfer the images at . The images can be transferred after the images are collected or while images are being collected e.g. a first image is taken and while a second image is taken the first image is transferred. In one embodiment the images collected at are stitched together at the projectile of and then the stitched image is transferred at . After transferring the images the projectile of can wait to receive an instruction or perform at least one other function e.g. gather more images gather data such as location and or voice data etc. . The instruction e.g. an instruction to detonate a specific ordnance of the projectile of can be received at and verified at . The verification can include determining that the instruction came from an authorized source. Upon verifying the instruction the instruction can be followed at .

The method and the method of can function together. For example the method of can function on the handheld device of while the method can function on the projectile of that is tethered to the handheld device of e.g. tethered by way of the physical link of . In one example the images that are transferred at can be the same images that are received at of . In another example following the command at causes the instruction to be sent that is received at .

Various components disclosed herein can perform different tasks and different features can be used for various aspects disclosed herein. The projectile of can be reusable such as by having a replaceable flash ordnance compartment that can be refilled with flash cartridges and be deployed with a primary goal of surveillance and a secondary goal of detonation. The projectile of can be at least partially hidden in an area of an environment that an enemy may visit and then an ordnance of the projectile of can be detonated when the enemy is the area e.g. the projectile of is placed in a waiting situation .

Aspects disclosed herein can be used in various environments. Dismounted soldiers can use aspects disclosed herein to learn more about their immediate surroundings e.g. learn what is in hidden areas such as buildings or caves and detonate the grenade if desired. Aspects disclosed herein can be used to provide controlled detonation of ordnance placed in a location that may eventually have enemy activity or uses by police. For example aspects can be used to combat criminals or be used in hostage situations.

In addition to police hunters can also use aspects disclosed herein such as using the projectile of to look into a bear s cave to determine if a bear is present in the cave. The projectile of can be used as a probe into areas where humans cannot reach such as tunnels pipes or caves as well as areas that are hazardous to humans e.g. radiation toxic gases etc. . The projectile of can be outfitted with a sensor such as a radiation detector and or the projectile of can include a sampling device and once a sample is taken the projectile of can be retrieved by way of the physical link of . The projectile of can be used in demolition activities. For example the interface of can be used to control the projectile of such that the projectile of is moved to a precise position that can facilitate improved e.g. optimal demolition e.g. place projectile of at a load bearing point of a building . The projectile of can include various features e.g. audio sensors an infrared camera and infrared illuminator a chemical sensor radiation sensor physical sensor collection device a non explosive self destruct component .

In addition the projectile of can communicate with the system of by way of wireless communication as opposed to the physical link of and vice versa. The handheld device of can communicate with the explosive ordnance device of by way of wireless communication as opposed to the physical link of and vice versa. The handheld device of can communicate with the grenade by way of wireless communication as opposed to the physical link and vice versa.

While discussed as related to explosives e.g. such as practicing aspects with regard to the grenade aspects disclosed herein can be applied to other areas. For example a baseball can retain an image camera and transmit individual images to a broadcaster that can use those images in the broadcast e.g. the individual images a stitched image from the individual images etc. . Other applications for aspects disclosed herein can include deep sea or space exploration spying movie making and others.

