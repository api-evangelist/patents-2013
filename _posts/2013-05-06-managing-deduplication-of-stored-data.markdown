---

title: Managing deduplication of stored data
abstract: In one aspect, in general, a method for managing data in a data storage system comprises receiving data to be stored in the data storage system, computing values corresponding to different respective portions of the received data, generating identifiers corresponding to different respective portions of the received data, with an identifier corresponding to a particular portion of data including the computed value corresponding to the particular portion of data and metadata indicating a location where the particular portion of data is being stored in the data storage system, and storing at least some of the identifiers in an index until the index reaches a predetermined size.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08898107&OS=08898107&RS=08898107
owner: Permabit Technology Corp.
number: 08898107
owner_city: Cambridge
owner_country: US
publication_date: 20130506
---
This application claims priority under 35 USC 120 to U.S. patent application Ser. No. 13 117 629 filed on May 27 2011 which claims priority to U.S. Patent Application Ser. No. 61 384 212 filed on Sep. 17 2010 the entire contents of which are both hereby incorporated by reference.

Some data storage systems are configured to include a deduplication function that is used to reduce the amount of storage capacity that is needed to store received data e.g. data to be archived in the data storage system . In some implementations deduplication works by segmenting received data into segments also called chunks of data that are identified in an index by a value such as a cryptographic hash value. A form of data compression can be achieved by preventing duplicate segments from being stored when the data is being stored in the data storage system. For example a given file made up of one or more segments that has already been stored e.g. an email attachment attached to multiple emails in an email storage system can simply be replaced with a reference to the previously stored file if the previously stored file has the same segments. Alternatively a given segment within a given file that is the same as another segment in the given file or another file e.g. a portion of document within a ZIP archive that is also stored in another ZIP archive can be replaced with a reference to the duplicate segment.

In one aspect in general a method for managing data in a data storage system comprises receiving data to be stored in the data storage system computing values corresponding to different respective portions of the received data generating identifiers corresponding to different respective portions of the received data with an identifier corresponding to a particular portion of data including the computed value corresponding to the particular portion of data and metadata indicating a location where the particular portion of data is being stored in the data storage system and storing at least some of the identifiers in an index until the index reaches a predetermined size.

In another aspect in general a method for managing data in a data storage system comprises receiving data to be stored in the data storage system computing values corresponding to different respective portions of the received data generating identifiers corresponding to different respective portions of the received data with an identifier corresponding to a particular portion of data including the computed value corresponding to the particular portion of data and metadata indicating a location where the particular portion of data is being stored in the data storage system storing at least some of the identifiers in an index until the index reaches a predetermined size and in response to determining that a first identifier corresponding to a first portion of data received after the index reached the predetermined size was not already stored in the index before the first portion of data was received storing the first identifier in the index and designating for removal at least a second identifier corresponding to a second portion of data to be removed from the index such that the index does not exceed the predetermined size.

The method further comprises in response to determining that the first identifier was not already stored in the index before the first portion of data was received storing the first portion of data in the data storage system.

The method further comprises determining logical boundaries corresponding to the different respective portions of the received data.

The method further comprises determining a domain corresponding to a section of a file system including the particular portion of data being stored in the data storage system.

The method further comprises determining a first domain corresponding to first one or more respective portions of the data being stored in the data storage system and a second domain corresponding to a second different one or more respective portion of the data being stored in the data storage system.

The method further comprises executing deduplication for data segments of the received data such that data segments belonging to the first domain is not deduplicated with data segments belong to the second domain. The method further comprises determining a domain tag to reference the domain. In some examples the domain tag comprises a namespace.

Designating for removal at least a second identifier from the index comprises designating for removal one or more identifiers based at least in part on an order in which identifiers were added to or updated in the index.

The one or more identifiers selected to be removed are the identifiers that have been least recently added to or updated in the index.

The method further comprises in response to determining that a third identifier corresponding to a third portion of the received data was already stored in the index before the third portion of data was received updating the third identifier in the index.

Updating the third identifier in the index comprises updating an order of the third identifier relative to other identifiers in the index.

Updating the order comprises updating a position of an entry storing the third identifier within the index.

The method further comprises in response to determining that the third identifier was already stored in the index before the third portion of data was received associating a first data structure representing data that included the third portion of data with a duplicate of the third portion of data that was already stored in the data storage system before the third portion of data was received.

Associating the first data structure with the duplicate of the third portion of data comprises storing a reference to the duplicate of the third portion of data in a data structure that is separate from the index.

The data that included the third portion of data is a file included in the received data and the third portion of data is a segment of the file.

The index includes multiple entries each entry storing one of the computed values and a reference to the portion of data corresponding to the computed value stored in the entry.

Computing values corresponding to different respective portions of the received data comprises computing unique values that uniquely identify different respective portions of the received data and using at least part of a unique value that uniquely identifies a particular portion of the received data as the computed value corresponding to the particular portion of the received data.

The unique values are hash values computed from the respective portions of the received data using a hash function.

The data storage system comprises one or more storage media coupled to a computing system that receives the data to be stored in the data storage system.

The data storage system further comprises an application that manages data stored in the one or more storage media.

The application uses an application programming interface to access one or more functions that compute the values corresponding to different respective portions of the received data and manage the index including determining whether particular identifiers are stored in the index.

At least one of the locations comprises a volatile storage medium and at least one of the locations comprises a non volatile storage medium.

The method further comprises in response to removing a particular portion of data from the data storage system removing the identifier corresponding to the particular portion of data from the index.

The method further comprises in response to modifying a particular portion of data in the data storage system removing the identifier corresponding to the unmodified particular portion of data from the index and adding a new identifier corresponding to the modified particular portion of data.

The method further comprises determining different levels of abstractions corresponding to the received data for referencing the different respective portions of the received data. The different levels of abstractions include virtual segments and physical segments the virtual segments being based in part on virtual memory addresses and the physical segments based in part on physical memory addresses. A first level of abstraction corresponding to the received data references a second level of abstraction of the received data. The method comprises causing a software layer to define the different levels of abstractions. The method comprises sending data regarding a new data segment to a deduplication engine receiving deduplication advice from the engine and based on the advice reallocating one or more physical segments from corresponding one or more virtual segments to different respective one or more virtual segments.

In another aspect in general a computer readable storage medium stores a computer program for managing data in a data storage system. The computer program includes instructions for causing a computing system to receive data to be stored in the data storage system compute values corresponding to different respective portions of the received data generate identifiers corresponding to different respective portions of the received data with an identifier corresponding to a particular portion of data including the computed value corresponding to the particular portion of data and metadata indicating a location where the particular portion of data is being stored in the data storage system store at least some of the identifiers in an index until the index reaches a predetermined size and in response to determining that a first identifier corresponding to a first portion of data received after the index reached the predetermined size was not already stored in the index before the first portion of data was received store the first identifier in the index and select at least a second identifier corresponding to a second portion of data to be removed from the index such that the index does not exceed the predetermined size.

In another aspect in general a system for managing data comprises a data storage system and a computing system. The computing system is configured to receive data to be stored in the data storage system compute values corresponding to different respective portions of the received data generate identifiers corresponding to different respective portions of the received data with an identifier corresponding to a particular portion of data including the computed value corresponding to the particular portion of data and metadata indicating a location where the particular portion of data is being stored in the data storage system store at least some of the identifiers in an index until the index reaches a predetermined size and in response to determining that a first identifier corresponding to a first portion of data received after the index reached the predetermined size was not already stored in the index before the first portion of data was received store the first identifier in the index and select at least a second identifier corresponding to a second portion of data to be removed from the index such that the index does not exceed the predetermined size.

Other aspects and advantages will be apparent from the detailed description drawings appendices and claims.

There are a great many possible implementations of the invention too many to describe herein. Some possible implementations that are presently preferred are described below. It cannot be emphasized too strongly however that these are descriptions of implementations of the invention and not descriptions of the invention which is not limited to the detailed implementations described in this section but is described in broader terms in the claims.

The deduplication engine is configured to provide an optional deduplication function for use by the data storage system . In this example the deduplication engine provides an application programming interface API that includes various functions that can be called from within the software layer of the data storage system . The software layer can store new data in the media optionally taking into account advice returned as output of the functions of the API about whether portions of the data have already been stored in the media and if so where the portions are stored. In response to the deduplication advice indicating which new segments of data have duplicates that are already stored the software layer can determine whether to represent some of the new segments by referring to the previously stored duplicates instead of storing the new segments.

When deduplication advice is desired for new data the software layer provides the new data to the deduplication engine by calling a function of the API . The function can be called at any of a variety of stages including while the new data is being written to the media or at any subsequent time as determined by the software layer . Along with the new data the software layer can provide other input to the function such as application specific metadata. For example location information can be provided that describes where the new data is located e.g. in a temporary storage location within the media or other storage media in the system or an external location. The software layer is also able to improve the accuracy of the advice from the deduplication engine by calling functions of the API to update the index when data is deleted or modified. In some implementations the software layer may also provide a sequence number along with the application specific metadata to the function. The software layer can use the sequence number to quickly verify whether or not the deduplication advice is valid. If the location information has changed since the last time the software layer queried the deduplication engine then the sequence number will indicate that the deduplication advice is outdated.

In some implementations the deduplication advice can be used by a remote user or client of a data storage system to determine if a data segment needs to be transmitted over a network. For example if the data segment is a duplicate of an existing copy of the segment then the existing copy of the segment can be referenced instead thus saving network capacity and possibly also storage capacity.

The deduplication engine includes a segmentation and index management module that performs various actions to handle calls to the functions of the API . The module segments the new data into variable length segments optionally taking into account characteristics of the new data to determine appropriate boundaries for the segments. For example duplicate data may occur in files having different block alignments such as when a file appears within two ZIP archives at different locations relative to the start of the archive. Content aware segmentation enables the embedded file to be located and deduplicated even if the file appears at different offsets in the two archives.

The module computes fingerprints as identifiers corresponding to different respective segments. In some implementations the module computes hash values that uniquely identify different respective segments and includes the entire hash value or a shorter portion of the hash value or a shorter computed value based on the hash value in the fingerprint. In some implementations the module uses SHA 256 cryptographic hashing algorithm designed by the National Security Agency to compute the hash values for the respective segments. For example techniques for using abbreviated values for the fingerprint are described in U.S. Pat. No. 7 457 800 and U.S. Pat. No. 7 457 813 each of which is incorporated herein by reference.

In some implementations the fingerprint also includes a domain tag representing a domain in which one or more segments are being stored and managed. For example the domain tag can corresponds to a section of a file system in which the one or more segments are being stored a portion of a storage medium including for example any of the following a disk or disk volume e.g. identified by a logical unit number LUN a data protected set of disks a storage device or a cluster of storage devices . The inclusion of the domain tag in the fingerprint enables the system to distinguish between different segments that may have identical content and therefore identical hash values but are stored in different media and or file systems where it may be difficult to create references to between data stored in those different media and or file systems.

The deduplication engine stores the fingerprints in an index that includes multiple entries each entry storing one of the fingerprints. Each entry stores a reference to the segment corresponding to the fingerprint stored in the entry.

In some implementations different data segments may need to be indexed in a same index without being deduplicated across the segments. By way of example a service provider may have two customer volumes on a same underlying media but data cannot be shared between volumes. To address this situation the index may support the creation of a domain identifier or tag e.g. a namespace to be associated with each segment e.g. Client1 and Client2 . The data segment associated with a first domain e.g. Client1 will not deduplicate with the data segment associated with the second domain e.g. Client2.

When a duplicate segment is identified a duplicate data advisory can be sent to the software layer . In some implementations the advisory can be synchronously sent via a function return. In some implementations the advisory can be asynchronously sent via a previously registered callback function. The advisory provides metadata necessary for the software layer to determine the duplicate information. For example the metadata can include a location of the duplicate data and possibly a sequence number each corresponding to the new segment and the previously stored segment. In some examples the software layer may notify the deduplication engine that the advice is outdated e.g. based on sequence numbers described above . In such instances the deduplicate engine updates its index to remove the outdated information. In some examples the software layer can unify data extents within the file system specific to the software layer based on the advice.

When a duplicate segment is identified a reference to the segment can also be stored in a data structure that is separate from the index. In some implementations the data storage system stores a reference to the location of a duplicate segment using a data structure that is independent of the deduplication engine such as a data structure in the file system inode structure of the media where the data structure is able to point directly to the location the duplicate data is stored on the media e.g. a location on a disk . This can provide the advantage of the data storage system being able to operate more independently of the deduplication engine without the need to rely on the index to access files that include segments that are references to duplicate segments from other files or locations within the same file. In such implementations the deduplication engine does not become critical to the reliability and availability of the data storage system for data retrieval.

In alternative implementations the data storage system only stores the fingerprint value for the duplicate segment. In such implementations the data storage system would have to query the deduplication engine as to where the referenced segment was located and the deduplication engine would become critical to the operation of the data storage system .

The index is managed such that the size of the index does not exceed a predetermined maximum size. This enables the deduplication engine to limit the amount of storage space required for the index. The deduplication engine provides deduplication advice for data that falls within a deduplication window corresponding to the most recently seen segments in order of how recently they have been seen. In some implementations the index can include an on disk volume for recording names corresponding to the data segments. Using this on disk volume the deduplicate engine is able to determine the deduplication window for which the engine provides deduplication advice.

Referring to an example deduplication window is shown. Before the index reaches the size limit a new segment is added to the most recently seen side of the deduplication window when its fingerprint is stored in the index and gradually moves to the least recently seen side of the deduplication window as fingerprints for additional segments are stored in the index. After the index reaches the size limit one or more least recently seen segments are removed from the deduplication window by removing its fingerprint from the index to prevent the index from exceeding the size limit when an entry with a new fingerprint is added. Before or after the index reaches the size limit a segment whose fingerprint is already stored in the index added to the recently seen side of the deduplication window when it is seen again for example by updating its fingerprint in the index.

Referring to an example index record is shown. For example the index record can include a key portion and a value portion each of a predetermined length e.g. 32 bytes each for a total of 64 bytes . In some implementations the key portion can include a key representing a result of a hash function operating on the contents of a data segment. For example the hash function can be based on the SHA 256 cryptographic hash described above. In some examples the key can include the hash value in combination with a domain identifier e.g. a namespace . For example the hash value and the domain identifier can be combined based on one of the following expressions Key XOR hash SHA256 domain identifier Key SHA256 hash domain identifier 

In some implementations the value portion can be application provided metadata describing a data segment. For example the value portion can include an address in the storage medium corresponding to a location where the data segment is stored. In some examples the value portion can also include other metadata such as a sequence number and or a transaction identifier which may be used to validate the deduplication advice.

In some implementations when the index reaches a predetermined size a batch of data records representing the fingerprints e.g. millions of records may be marked as being discardable. These records may then be purged from the index at a time that is convenient. For example the records can be purged as part of an operation involving data that may be in a proximity of the data marked as being discardable.

The module can be configured to perform other functions associated with managing the index and providing deduplication advice for the segments e.g. as described in the exemplary embodiments of the attached appendices .

In an implementation a process for adding a new unique record i.e. a record that does not already exist in the window is shown. The unique record has key 1000 and value 1000 and is added to the most recently used end . As such an updated most recently used end is shown. To make room for the new unique record an older record is removed from the window . For example the older record is at the least recently used end of the window . As such an updated least recently used end is shown.

Referring now to a deduplication window operation can be carried out where a previous record in the window is updated. For example the software layer may look up the window for a record with key 3 and value 3 e.g. record . Such an operation involves adding a new copy of the record . The new record can be added to the most recently used end . As such an updated most recently used end is shown. To make room for the new copy of the record an older record is removed from the window as before. For example the older record is at the least recently used end of the window . As such an updated least recently used end is shown.

The deduplication engine can be integrated as an inline parallel or post process solution depending on the structure and requirements of the software later .

In some implementations the deduplication engine can be configured to operate outside of the data read path. In some implementations the deduplication engine can also be configured to not write or alter data written to the storage medium . As discussed above the deduplication engine provides deduplication advice to the software layer which in turn decides how to process the data based on the advice. In this manner the data on the storage medium is protected against data corruption.

As an inline solution the deduplication engine can process incoming data segments in real time. For example some applications in the software layer can benefit from immediate data optimization and for which a latency can be masked by parallelism and write caching. In this implementation the deduplication engine may be configured to intercept the write path to determine if data is duplicate and then pass advice to the software layer .

As a parallel solution the deduplication engine can be configured to receive a copy of the data as it is written to storage medium . In this manner write latency can be avoided. If a duplicate segment is identified the software layer can respond to deduplication advice by asynchronously pushing an update to the storage medium .

As a post processing solution the deduplication engine can be configured to receive data back from storage medium either on demand or on a fixed schedule. The deduplication device can provide deduplication advice to the software layer which then can push updates to the storage medium .

The deduplication engine can be deployed as an embedded process within the software layer including a set of libraries which is enabled to provide support to any application within the software layer . In some implementations the deduplication engine can be deployed in a grid configuration which would allow distributed clients anywhere on a network to share a same deduplication index. In such implementations for example the deduplication engine can use a plurality of servers so the deduplication load is distributed rather than concentrated on a single server. In such a scheme multiple client systems can create index sessions by connecting to the shared deduplication engine . In some implementations in order to deduplicate data between clients systems each client system can connect to a same set of servers.

In some implementations features of the deduplication index can be developed using an application programming interface API . For example the API may include parameters relating to an upper limit of memory e.g. quantified in gigabytes to be used by the index a number of bytes to be designated for each data segment for representing metadata e.g. up to 32 bytes and a maximum data segment size.

Along these lines an example API is described below. It should be understood that there may be many ways of implementing the API and the following is for illustration only. The API described below enables the creation of a deduplication index in an embedded deduplication engine.

The path variable can be for example a path to a directory where a local index will write its data files.

The indexSession variable can be used to create deduplication contexts as described in detail below. The index session defined as described above is thread safe i.e. the API may make calls to the session in multiple threads. In some implementations each context can be associated with a single domain corresponding to a single deduplication domain. For example the data segments that are indexed in this manner and associated with a same domain will deduplicate against each other. Further in examples data segments associated with contexts corresponding to different domains will not deduplicate against each other.

In some implementations each context can also represent a specific index type e.g. a Block index a Stream index or a File index. A same index type may be used for all contexts associated with any given domain.

The API for a Block index can support deduplication at a granularity of client defined chunks of data but without or with limited content awareness. For example the Block API may allow the software layer to specify the data segments to be indexed for deduplication. As such when the deduplication engine recognizes identical data segments it may synchronously or asynchronously respond with the location of the canonical copy.

The APIs for Stream and File indices can support content aware segmentation on file types such as Microsoft Office PDF ZIP tar and Microsoft Hyper V images VHD . Stream and File index may need additional processing within the software layer . For example the software layer may need variable sized extent unification.

In some implementations to create a Block type context an example API can be configured to support the following definitions 

In some implementations to create a Stream type context an example API can be configured to support the following definitions 

In some implementations to create a File type API an example API can be configured to support the following definitions 

In some implementations upon receiving deduplication advice from the deduplication engine the software layer may save space by unifying duplicate and data segments. In some situations the software layer may not perform such unifying. Such situations can include for example when contents of the data s canonical location has been modified or deleted. As such that location may no longer contain an exact copy of the new data segment. In another situation the canonical location of the data can be unchanged but the new data segment may have been updated between the time it was posted and the time a response was asynchronously received from the deduplication engine . In some examples the reference count e.g. sequence number of the data segment canonical location may be at its maximum and can no longer accept new incoming references.

An example mechanism by which the APIs may facilitation communication with the deduplication engine is described as follows. An example block API is used below to describe the process. In some implementations the block API can allow the software layer to provide information to the deduplication engine synchronously via a function called for example udsIndexBlock or asynchronously via a function called for example udsPostBlock which uses a callback to return results. In example implementations involving the synchronous variant udsIndexBlock may have the following signature 

In the above snippet the first argument context is a Block API handle corresponding to the deduplication engine library. The second argument UdsBlockAddress is metadata defined by the software layer that describes the block.

In some implementations a size of the metadata e.g. up to 32 bytes can be specified when the index is created. Also in some situations information may be provided that uniquely describes the block. For example such information may be a logical unit number LUN and or a logical block address a file inode and an offset into the file .

In some examples the calling application in the software layer can also provide a length of the data segment and a pointer to the data itself. When the function returns the deduplication engine can use a variable hashExists to indicate if the block has been seen before or not. The deduplication engine can also provide the address of a canonical segment. If the segment is recognized as a duplicate the canonical segment address is the previously stored metadata for the segment. Optionally the calling application may also provide a buffer to hold the segment s UdsBlockName.

This snippet example above begins by configuring and creating a new local index making a session to it and opening a UdsBlockContext over the session to the new index in a default domain . In some implementations next the snippet can read lines of the input and index them to the deduplication index along with the line number where the line was seen . If the text has never been seen before the snippet can print the line otherwise the snippet prints the line number where the text was first encountered.

The asynchronous variant may be invoked by calling udsPostBlock instead of udsIndexBlock. In some implementations the results can delivered in a separate thread via an asynchronous callback. An example function and its callback may be defined as follows 

In some examples the arguments to the synchronous and asynchronous interfaces may be the same. In some examples a difference between the two types of interfaces can involve a type called UdsCookie. As with UdsBlockAddress this type may be entirely abstract and defined by the software layer . Unlike UdsBlockAddress however UdsCookie is not stored in the index. Instead the Application Software uses UdsCookie to provide the callback thread with context for handling deduplication advice. In some implementations the deduplication engine may not deliver the callbacks in the order in which they were posted. To ensure that all outstanding callbacks have been delivered the software layer can call function udsFlushBlockContext.

When the duplicate data segment no longer matches the previously stored data segment the duplicate advice is deemed stale. To prevent data corruption the software layer does not apply the stale advice. An example of validating advice is to read the new data segment and compare it with the data segment stored in the storage medium . If the contents match the storage locations may be unified. Alternatively the storage system can include a sequence number with the storage location metadata and use the sequence number to detect modifications.

In some implementations the software layer can store hash information associated with the data segment with the data segment. In this case the application may only need to compare the hashes instead of comparing the actual data.

Referring to an example file system using sequence or generation numbers is shown. As shown each inode in the file system can be associated with two additional pieces of metadata a dirty bit which indicates whether or not the file has been scanned for deduplication since its last modification and a sequence field typically a 64 bit integer that tracks file modifications. At time T 1 labeled a file foo is stored at inode 1 of the file system. The dirty bit is set to Yes to indicate that the file has not been scanned by the deduplication engine . Further the sequence number for the file is set to 1. At time T 2 labeled the file foo is scanned by the deduplication engine setting the dirty bit to No . The sequence number remains unchanged as the data is not altered by this process. At time T 3 labeled another file bar is scanned by the deduplication engine . As shown the deduplication advice indicates that the file bar shares a chunk i.e. data segment with the file foo at inode 1 having a sequence number of 1. Since the sequence numbers are the same the advice may be acted on by the software layer .

At time T 3 labeled the file foo may be updated. This newly updated file has not been scanned by the deduplication engine and as such the dirty bit is set to Yes . Further since the file has been updated a new sequence number of 2 is assigned. At time T 4 labeled a new file baz is scanned by the deduplication engine which reports that the file shares a data segment with the file foo at the inode 1 with sequence number 1. However since the sequence number of the file foo at inode 1 is now 2 the advice is deemed stale. In this manner the software layer may not act upon the advice and may instead perform other actions. For example the software layer may perform data comparison operations or update the file mappings. Subsequently at time T 5 labeled the file foo is rescanned by the deduplication engine thus setting the dirty bit to No .

By including the sequence of the file in the data segment metadata i.e. along with the inode number deduplication advice is returned that indicates whether or not the file was modified since it was previously indexed. For files that are infrequently modified but are commonly duplicated i.e. fixed content this mechanism may help avoid extra disk reads when processing deduplication advice.

Referring to a logical unit implementing deduplication advice is shown. In some implementations the deduplication engine provides a mechanism for a storage medium to identify identical data segments within the logical unit identified by a logical unit number or LUN . In some examples the mechanism described below may allow for the medium to reclaim the space occupied by the duplicate segments for storing additional data. For example the data segments may be reallocated as part of a system for volume extension.

In some situations an example deduplication API can use two user defined data structures for performing deduplication. For example the data structures may store block addresses represented by UdsBlockAddress and callback data represented by UdsCookie . The data structures can identify abstractions of the storage system. For instance in a file system the abstractions can be block numbers and the higher level inodes that are referred to specific blocks. Within a logical unit the abstractions can be physical segment numbers which may themselves be further virtualized and a higher level virtualization of those physical segments. For example the physical segment numbers may be based on physical memory addresses and virtual segment numbers may be based on a higher level virtualization of the physical segments. As such virtual memory addresses may be assigned to the virtual segments.

As such physical segment numbers or physical chunk numbers PCNs are the content of the UdsBlockAddress abstract data type and virtual segment numbers or virtual chunk numbers VCNs are the content of the UdsCookie abstract data type.

In an example scenario consider that the logical unit has one to one mapping between the PCN and VCN . In this example scenario the logical unit is assumed to contain no duplicate data.

The row labeled reference count RefCnt counts a number of references for a particular PCN. When a logical unit is not using deduplication the reference counts will either be zero or one.

Referring to in an example scenario the virtual segments and may be updated so that their contents are substantially identical to the contents of virtual segments and . When segments and are updated and rewritten to the storage the storage system uses the udsPostBlock API call to provide the VCN PCN and data segment information for the updated segments. When the duplicate data is identified the deduplication engine may invoke a previously registered callback e.g. udsRegisterDedupeBlockCallback to provide the VCN and PCN of the duplicate block along with the PCN of canonical location for that block. For example after being notified of the update to VCN mapped to PCN the deduplication engine can invoke the callback advising that VCN currently mapped to PCN should be remapped to point at PCN .

The software layer can deduplicate the data referenced by the inodes as long as it can reference the segments and provide the segments to the deduplication engine . For example the software layer may determine how to reference the software layer s data storage elements.

In an example implementation a segment reference can be identified with three items an inode number an index of the link e.g. the third arrow of inode 1 and a sequence number for the link. Such a data structure may be packaged up as an instance of UdsCookie. In an example implementation the segments can be identified by a segment number e.g. number 104 and a sequence number for the segment. Such a data structure can constitute an instance of UdsBlockAddress.

As the software layer stores the segments to the storage medium the file system may call udsPostBlock with the link the segment address and the segment data. The deduplication engine may compute the segment s signature and determines whether the segment has been indexed. If the segment is unknown it is stored in the index. Otherwise the deduplication engine can use the UdsDedupeBlockCallback to inform the file system that the link may be re pointed at another segment having the same contents. The file system may then free the unreferenced segment. The deduplication engine can create new index entries in response to calls to udsPostBlock in connection with Inode 1.

In some examples the deduplication engine may generate duplicate data advisories to inform the file system that the segment may be deduplicated with an existing copy elsewhere in response to calls to udsPostBlock when processing inode 2. In this regard referring now to the result after inode 2 is processed is shown. The first 3 block references of Inode 2 are pointed at blocks zero through two allowing blocks through to be freed.

The techniques described above can be implemented using software for execution on a computer system. For instance the software defines procedures in one or more computer programs that execute on one or more programmed or programmable computer systems e.g. desktop distributed client server computer systems each including at least one processor at least one data storage system e.g. including volatile and non volatile memory and or storage elements at least one input device e.g. keyboard and mouse or port and at least one output device e.g. monitor or port. The software may form one or more modules of a larger program.

The software may be provided on a computer readable storage medium such as a CD ROM readable by a general or special purpose programmable computer or delivered over a communication medium e.g. encoded in a propagated signal such as network to a computer where it is executed. Each such computer program is preferably stored on or downloaded to a storage medium e.g. solid state memory or media or magnetic or optical media readable by a general or special purpose programmable computer for configuring and operating the computer system when the storage medium is read by the computer system to perform the procedures of the software.

Many other implementations of the invention other than those described above are within the invention which is defined by the following claims.

