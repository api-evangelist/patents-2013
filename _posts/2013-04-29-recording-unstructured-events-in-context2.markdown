---

title: Recording unstructured events in context
abstract: Recording an unstructured event in context can include detecting a first occurrence indicative of a start to the unstructured event utilizing a sensing feature of a client device. Upon detection of the first occurrence, device activity data associated with the client device is tracked. A second occurrence indicative an end to the unstructured event is detected utilizing the sensing feature. Following detection of the second occurrence, an event object for the unstructured event spanning between the first and second events is presented. The event object includes or is otherwise associated with the device activity data tracked during the timespan.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09575823&OS=09575823&RS=09575823
owner: Hewlett Packard Enterprise Development LP
number: 09575823
owner_city: Houston
owner_country: US
publication_date: 20130429
---
Calendar applications allow users to schedule events with selected attendees. Each event is digitally represented by an event object that identifies a predetermined time period and selected attendees. An event object can also include additional details such as a slideshow presentation links for accessing selected information and any other items an event organizer might include or otherwise attach. The event object appears in each attendee s calendar and spans the predetermined time period. After the event a given attended can refer back to that event object as needed to review the context of the event.

While an individual may plan various events over a day reality often renders that schedule incomplete due to impromptu meetings and other schedule changes. Scheduled events are recorded as event objects for use by any number of calendaring applications. Such events can thus be referred to as structured events with corresponding event objects including the time periods for the events participants and any attachments or other data that can provide additional event context. Impromptu or non scheduled events on the other hand are not recorded and the participant s memory is often the only source of context. Thus with structured events a participant can refer back to the event object to recall the context of an event. For unstructured events a participant is left to her own memory to recall any event related activities.

Embodiments described below operate to help detect and record unstructured events in context. The context here includes information corresponding to activities related to the event. Such activities can include accessing documents communicating messages sharing documents and any other participant action taken during the event. An event can be an in person meeting such as a gathering in a common location or a remote meeting such as a phone call instant messaging session or virtual meeting. It is also noted that events such as commutes to and from work can have a single participant.

Various embodiments described in detail below operate by detecting a first occurrence indicative of a start to the unstructured event. The occurrence is detected utilizing a sensing feature of a client device. Such an occurrence may for example include the positioning of two or more client devices such as smart phones within proximity of one other. Another occurrence may be triggering of a virtual meeting using a client device. Upon detection of the first occurrence device activity data associated with the client device is then tracked. This data can include any data related to an activity by the user that can be monitored by the client device such as messages sent and received documents accessed web pages browsed and audible conversations.

The device activity is tracked until the detection of a second occurrence indicative an end to the unstructured event. Such an occurrence for example may include the client device moving out of proximity of the other client devices or the cling of a virtual meeting as detected utilizing the sensing feature. Following detection of the second occurrence an event object for the unstructured event spanning between the first and second events is presented. The event object includes or is otherwise associated with the device activity data tracked during the timespan. That event object may be displayed for example as a calendar item such that the user can look back at a day s events and review activities that occurred during those events. However event objects can be stored in any type of repository from which they can be searched.

The following description is broken into sections. The first labeled Illustrative Examples presents example screen views of a user interface for a calendar application and a user interface in which a user is prompted to record an unstructured event. The second section labeled Components describes examples of various physical and logical components for implementing various embodiments. The third section labeled as Operation describes steps taken to implement various embodiments.

Interface also allows user to select using controls from among plurality of device activity types monitored during the corresponding event. In this example monitored event types include pictures taken messages communicated files accessed and web pages viewed. The user has selected to include pictures using control and files accessed using control . Through control the user can choose to save the event object to include or otherwise be associated with activity data of types selected using controls . Once saved the event can be added after the fact to the user s calendar. depicts a screen view of the user s actual schedule after the day s unstructured events have been detected and recorded. The user can now access additional event objects to review the day s otherwise unstructured events.

Client device is shown to include device functions and sensing feature . Device functions represent generally the hardware and programming for providing the computing functions for which device is designed. Such hardware can include a processor and memory display and any physical user input buttons. The programming can include an operating system and applications. Sensing feature represents generally any component configured to detect a change in state of client device . Such a change in state may be an environmental state that can be correlated with the occurrence of an event to be recorded. For example sensing feature may include any of a positioning feature an accelerometer and a communication feature that can be used to detect device position motion and proximity to client device and . Sensing feature may also include a microphone and camera for use in monitoring audio and visual signals generally proximate to device . Sensing feature may be software configured to detect the start and stop of phone calls virtual meetings and other events where the client device facilitates interaction between the user and another individual.

Event recording system discussed in more detail below represents generally a combination of hardware and programming configured to record events in context. Briefly event recording system is configured to through use of sensing feature detect an occurrence of an event monitor device activities during the event and generate an event object that includes or is otherwise associated with those device activities. System may be wholly integrated within device functions . System may be implemented was a component of server device where it takes action based in part on data received from device functions and sensing feature via link . System may be distributed across client device and server device where for example event detection and activity monitoring are performed on device and the corresponding event records are generated by server device . It is noted that event recording system may also be included on client devices and .

Such device states can take various forms. For example utilizing the sensing feature occurrence engine may detect a device state in which the client device has moved within range of one or more other client devices and has remained in range for a threshold time period. Such a state is indicative of and may be correlated with the occurrence of a meeting. Here sensing feature may include a positioning feature that utilizes GPS Wi Fi or other radio communication for triangulation. Sensing feature may also include short range wireless communication such as NFC Near Field Communication such that signal detection from another client device indicates relatively close proximity between the two. In another example sensing feature may include the client device s microphone such that captured audible signals can be compared to audible signals captured by other client devices. When the audible signals captured by two or more devices match it can be presumed that those client devices are in proximity and that a meeting is occurring. The device state is one in which the device s captured audible signal matches the audible signal captured by another device.

As an example occurrence engine may detect a device state by detecting an occurrence of a first condition followed in time by the occurrence of a second condition. The first condition is indicative of an event start and the second condition of an event end. The some period between the conditions corresponds to the time period of the detected event. Continuing with the examples above the first condition may be met upon detecting that the client device is in proximity with another client device and has remained in proximity for a threshold period. The second condition may be met upon detecting that the client device is no longer in proximity of the other client devices or is moving away from the other devices.

Activity engine represents a combination of hardware and programming configured to maintain device activity data for a client device during a time period associated with an unstructured event. The device activity data is data indicative of a user s interaction with the client device during that unstructured event. Device activity data can be categorized into any of a number of data types based on the functionality of the given client device. Device activity data can include data indicative of documents accessed web sites browsed pictures taken conversations recorded messages communicated and any other data that may be recorded by client device. Thus the device activity data defines at least in part a context of the unstructured event.

Object engine represents a combination of hardware and programming configured to following the identification of the second condition by the occurrence engine present an event object that includes or is otherwise associated with the device activity data. Presenting the event object can include generating and saving the event object. As noted the device activity data can include a plurality of data types. Object engine may perform its function by communicating a prompt indicating that an unstructured event has been detected. provides an example. Through the prompt the user is allowed to select from among the plurality of data types and indicate whether or not to store the device activity data. Upon receiving a response to the prompt that the activity device is to be stored object engine is configured to record the event object such that the event object includes or is otherwise associated with only the device activity data matching the data types selected via the prompt.

Object engine may also be configured to maintain data type preferences indicative of data types selected via previous prompts such that by default previously selected data types are selected by default in a current prompt. In other words object engine may be configured to maintain data type preferences indicative of a first data type selected via previous prompts and a second data type not selected via the previous prompts. Thus when presenting a current prompt device activity data for the first type is selected by default and data of the second type is not. Looking back to as an example types and may have been selected by default as represented by check marks while types and were not.

In performing its function activity engine may track device activity data starting when occurrence engine detecting the first condition such as when the client device is in proximity with another client device. Activity engine may continue to track the device activity data until occurrence engine detects the second condition such as when the client device is no longer in proximity with the other device. In an example the first condition may be met upon the occurrence of a first trigger followed after a predetermined first time frame by a second trigger. The second condition may be met upon the occurrence of a third trigger followed within a predetermined second time frame by a fourth trigger. The first trigger is a change of state of the client device detected by occurrence engine using the device s sensing feature. This change of state can be correlated with the possibility of the beginning of an unstructured event. For example the first trigger may include the client device coming into proximity of another client device as detected by using the client devices communication or positioning feature. The second trigger includes the client device remaining in that state for a threshold period such that it can be correlated with a likelihood that the unstructured event is in progress. For example the second trigger may include the client device remaining in proximity of the other client device for a minimum period.

The second condition may be met upon the occurrence of a third trigger followed within a predetermined second time frame by a fourth trigger. The third trigger is a change of state of the client device detected by occurrence engine using the device s sensing feature. This change of state can be correlated with the possibility of the end of the unstructured event. For example the third trigger may include the client device moving as detected using the client devices accelerometer or positioning feature such as when the user stands and begins walking. The fourth trigger is a detected device state that can be correlated with a likelihood that the unstructured event has ended. For example the fourth trigger may include the client device leaving the proximity of the other client device as detected using the client device s positioning or communication feature. Thus the initial device motion signals a possibility or hint that the event is ending and the device moving out of proximity signals a likelihood that that the event has ended.

Activity engine is configured to begin to track the device activity upon the occurrence of the first trigger and stop tracking if the second trigger occurs within the first time frame. Upon occurrence of the second trigger after the expiration of the first time frame activity engine continues to track the device activity until the occurrence of the fourth trigger. Object engine may be configured to present the event object only upon occurrence of the fourth trigger. That event object includes or is otherwise associated with the device activity tracked between the occurrence of the first and third triggers.

As noted device activity data can be categorized into any of a number of data types. Thus data in type field identifies the activity type for a corresponding entry . Again examples include photos taken message sent or received files accessed and any other data type that can be recorded or otherwise monitored by a client device. Data in timing field indicates a time that the activity associated with a given entry was recorded by the client device.

Event objects represent unstructured events detected by occurrence engine and generated by object engine . Each event object is shown to include event data and activity data . Event data includes data identifying a corresponding unstructured event detected by occurrence engine . Referring back to such information may be information depicted as details which can include an event subject location start and stop times and participants. Activity data represents the activity data maintained by activity engine that was recorded between the start and end times identified by occurrence engine . That activity data may be data from the activity fields of the corresponding entries in log or it may include data acquired using information from those fields .

As noted above object engine may also be configured to maintain data type preferences indicative of data types selected via previous prompts such as interface depicted in . Upon occurrence engine detecting the end of an unstructured event object engine may present a prompt such as interface through which the user can select types of activity data to include in a corresponding object record . Object engine can maintain a record of such selections as preference data . Analyzing past selections object engine can identify activity types likely to be selected and then by default select those types to include in a corresponding event object . For example where a give type is selected a threshold number of consecutive times that type may be selected by default.

In foregoing discussion engines were described as combinations of hardware and programming. Engines may be implemented in a number of fashions. Looking at the programming may be processor executable instructions stored on tangible memory resource and the hardware may include processing resource for executing those instructions. Thus memory resource can be said to store program instructions that when executed by processing resource implement system of .

Memory resource represents generally any number of memory components capable of storing instructions that can be executed by processing resource . Memory resource is non transitory in the sense that it does not encompass a transitory signal but instead is made up of more or more memory components configured to store the relevant instructions. Memory resource may be implemented in a single device or distributed across devices. Likewise processing resource represents any number of processors capable of executing instructions stored by memory resource . Processing resource may be integrated in a single device or distributed across devices. Further memory resource may be fully or partially integrated in the same device as processing resource or it may be separate but accessible to that device and processing resource .

In one example the program instructions can be part of an installation package that when installed can be executed by processing resource to implement system . In this case memory resource may be a portable medium such as a CD DVD or flash drive or a memory maintained by a server from which the installation package can be downloaded and installed. In another example the program instructions may be part of an application or applications already installed. Here memory resource can include integrated memory such as a hard drive solid state drive or the like.

In the executable program instructions stored in memory resource are depicted as activity module occurrence module and object module . Activity module represents program instructions that when executed cause processing resource to implement activity engine of . Occurrence module represents program instructions that when executed cause the implementation of occurrence engine . Likewise object module represents program instructions that when executed cause the implementation of object engine .

A first occurrence is detected utilizing a sensing feature of a client device step . The first occurrence is indicative of a start to the unstructured event. Referring back to occurrence engine may be responsible for implementing step . Step may be accomplished for example by using a positioning or communication feature of a client device to detect that the device and presumably its user has come into proximity of one or more other client devices and their users. Such an occurrence can be indicative of the start of a meeting between those users. Other first occurrences can include the start of a virtual meeting phone call or any other client device facilitated interaction between the device s user and another.

Upon detection of the first occurrence device activity data associated with the client device is tracked step . Referring again to activity engine may be responsible for implementing step . The activity data can be indicative of any activity that can be recorded by the corresponding client device such as messages communicated web pages and files accessed voice recordings and photo and videos captured. The activity data can be tracked for example by recording the activity in a log such as activity log depicted in .

A second occurrence indicative of an end to the unstructured event is detected utilizing the sensing feature step . Referring back to occurrence engine may be responsible for implementing step . Step may be accomplished for example by using a positioning or communication feature of a client device to detect that the device and presumably its user are no longer in proximity of the other client device or devices. Such an occurrence can be indicative of the end of a meeting between those users. Other second events can include closing of a virtual meeting ending of a phone call or any other change in client device state indicative of the end of an event.

Following detection of the second occurrence an event object is presented step . The event object is for the unstructured event and spans between the first and second events. The event object includes or is otherwise associated with the device activity data tracked during the timespan between the first and second occurrences detected in steps and . Referring again to object engine may be responsible for implementing step . An event object may be presented for example by communicating a prompt through which the user of the client device can select from among various types of tracked activity data and to record the a corresponding event object including only the selected types of activity data tracked during the timespan.

Detecting a first occurrence in step can include detecting an occurrence of a first trigger followed after a predetermined first time frame by a second trigger. Detecting the second occurrence in step can include detecting an occurrence of a third trigger followed within a predetermined second time frame by a fourth trigger. Tracking in step then includes beginning to track the device activity data upon the occurrence of the first trigger and stopping to track if the second trigger does not occur within the first time frame. The first trigger for example can include the client device coming into proximity of another client device. The second trigger occurs when the device remains in proximity for at least the first time frame. The third trigger can include the client device moving with respect to the other client device and the fourth trigger can be met when the client device continues to move for the second time frame. Presenting in step can then include presenting the event object only upon occurrence of the fourth trigger. That event object includes or is otherwise associated with the device activity data tracked between the occurrence of the first and third triggers.

Step can include tracking device activity data that includes data of a plurality of types. Presenting in step can include communicating a prompt for the user to indicate whether or not to record the unstructured event. That prompt identifies and allows the user to select from among the plurality of types. Upon a positive response to the prompt the event object is recorded to include or otherwise be associated with device activity data of those types of device data selected via the prompt. Such a prompt may be a current prompt. Data type preferences can be maintained that are indicative of a first data type selected via previous prompts and a second data type not selected via the previous prompts. Communicating in step can then include communicating the current prompt allowing selection from among the plurality of data types where by default the first data type is selected and the second data type is not selected.

Embodiments can be realized in any memory resource for use by or in connection with processing resource. A processing resource is an instruction execution system such as a computer processor based system or an ASIC Application Specific Integrated Circuit or other system that can fetch or obtain instructions and data from computer readable media and execute the instructions contained therein. A memory resource is any non transitory storage media that can contain store or maintain programs and data for use by or in connection with the instruction execution system. The term non transitory is used only to clarify that the term media as used herein does not encompass a signal. Thus the memory resource can comprise any one of many physical media such as for example electronic magnetic optical electromagnetic or semiconductor media. More specific examples of suitable computer readable media include but are not limited to hard drives solid state drives random access memory RAM read only memory ROM erasable programmable read only memory flash drives and portable compact discs.

Although the flow diagram of shows a specific order of execution the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks or arrows may be scrambled relative to the order shown. Also two or more blocks shown in succession may be executed concurrently or with partial concurrence. All such variations are within the scope of the present invention.

The present invention has been shown and described with reference to the foregoing exemplary embodiments. It is to be understood however that other forms details and embodiments may be made without departing from the spirit and scope of the invention that is defined in the following claims.

