---

title: Landmarks from digital photo collections
abstract: Methods and systems for automatic detection of landmarks in digital images and annotation of those images are disclosed. A method for detecting and annotating landmarks in digital images includes the steps of automatically assigning a tag descriptive of a landmark to one or more images in a plurality of text-associated digital images to generate a set of landmark-tagged images, learning an appearance model for the landmark from the set of landmark-tagged images, and detecting the landmark in a new digital image using the appearance model. The method can also include a step of annotating the new image with the tag descriptive of the landmark.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09020247&OS=09020247&RS=09020247
owner: Google Inc.
number: 09020247
owner_city: Mountain View
owner_country: US
publication_date: 20130205
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 12 466 880 filed May 15 2009 the entire content of which is incorporated herein by reference.

The present invention relates generally to digital image collections and more particularly to identifying popular landmarks in large digital image collections.

With the increased use of digital images increased digital storage capacity and interconnectivity offered by digital media such as the Internet ever larger corpora of digital images are accessible to an increasing number of people. Persons having a range of interests from various locations spread throughout the world take photographs of various subjects and make those photographs available for others to view for instance on the Internet. For example digital photographs of various landmarks and tourist sites from across the world may be posted on the web by persons with different levels of skill in taking photographs. Such photographs may show the same landmark from different perspectives under different conditions and or from different distances.

The vast number of such images available can be useful as an indicator of or guide to popular landmarks. To leverage information contained in these large corpora of digital images it is necessary that the corpora be organized. For example at digital image web sites such as Picasa Web Albums from Google Inc. Mountain View Calif. starting at a high level menu one may drill down to a detailed listing of subjects for which photographs are available. Alternatively one may be able to search one or more sites that have digital photographs. Some tourist information websites for example have downloaded images of landmarks associated with published lists of popular tourist sites.

Most conventional digital photograph organizing systems rely on users to tag photographs. As numerous new photographs are added to these digital image collections it may not be feasible for users to manually label the photographs in a complete and consistent manner that will increase the usefulness of those digital image collections. A system that can automatically extract information such as the most popular tourist destinations from these large collections is described in U.S. patent application Ser. No. 12 119 359 titled Automatic Discovery of Popular Landmarks also assigned to Google. Inc. California. The system described in application Ser. No. 12 119 359 uses a processing pipeline comprising a clustering stage based on geo coding and a clustering stage based on matching visual features of the images. What is needed however are other approaches to automatically discover landmarks and annotate images containing landmarks.

Methods and systems for automatic detection of landmarks in digital images and annotation of those images are disclosed. In one embodiment a method for detecting and annotating landmarks in digital images includes the steps of automatically assigning a tag descriptive of a landmark to one or more images in a plurality of text associated digital images. This generates a set of landmark tagged images. An appearance model can be learned for the landmark from the set of landmark tagged images. This allows detection of the landmark in a new digital image using the appearance model. The method can also include a step of annotating the new image with the tag descriptive of the landmark.

Another embodiment is a system for automatically detecting and annotating landmarks in digital images. The system has at least one collection of text associated digital images stored in a memory medium and at least one processor communicatively coupled to the medium. The processors are configured to automatically assign a tag descriptive of a landmark to one or more images in a plurality of text associated digital images. This generates a set of landmark tagged images. An appearance model can be learned for the landmark from the set of landmark tagged images. This allows detection of the landmark in a new digital image using the appearance model.

Further features and advantages of the present invention as well as the structure and operation of various embodiments thereof are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

While the present invention is described herein with reference to illustrative embodiments for particular applications it should be understood that the invention is not limited thereto. Those skilled in the art with access to the teachings herein will recognize additional modifications applications and embodiments within the scope thereof and additional fields in which the invention would be of significant utility.

The present invention includes methods and systems for automatically identifying and classifying objects in digital images. For example embodiments of the present invention may identify classify and prioritize most popular tourist landmarks based on digital image collections that are accessible on the Internet. The method and systems of the present invention can enable the efficient maintenance of an up to date list and collections of images for the most popular tourist locations. In some embodiments the popularity of a tourist location can be approximated based on the number of images of that location posted on the Internet by users.

Numerous individuals take digital photographs of surroundings in their neighborhoods locations visited in their day to day activities and sites visited on their touristic travels. The cameras that are used are of various levels of quality and sophistication. The individuals who capture the images are of various skill levels. The images are captured from various angles in varied levels alighting with varied levels of surrounding visual noise in various weather conditions etc. Many of these images are then posted on photo sharing websites or made digitally available through other means. Access to a vast collection of digital images such as digital photographs is made available through networks such as the Internet.

Often users who post images online also annotate the posted images for example by adding one or more tags and or captions. A tag can be used to name an image. Tags can also be assigned to images to assign keywords that relate to an image. For example an image of the Eiffel Tower may have assigned to it the tags Eiffel Tower Paris France Europe summer or the name of a person who is shown to be posing in front of the Tower. Tags are valuable as organization tools at various levels of granularity France may be useful in order to classify the image under searches for landmarks in France while having only Eiffel Tower as a tag could exclude the image from searches for landmarks in Paris and or France Despite the variation in accuracy and usefulness of the tags of images in determining landmarks contained in those images the corpora of user tagged images are a source of valuable information for purposes of building automatic landmark recognition systems.

Other potential sources of information include various other documents and electronic sources that link text and images. For example magazine articles about the Eiffel Tower may include a photograph of its subject. Newspaper content magazine and journal content articles written and or posted by individuals including blog postings about various landmarks etc. often include images that are directly tied to the textual description. Images having recognizable landmark associated text can be referred to as landmark tagged images.

Embodiments of the present invention leverage several types of data available regarding images in order to obtain information about popular landmarks. For example geo tags text tags author information timestamps e.g. time or origin and visual match information are some of the types of information that are utilized in embodiments of the present invention. Some of this information is available with each image e.g. in EXIF tags associated with the image . Other information is either user assigned or algorithmically assigned. When taken individually each of these data types can have substantial weaknesses. For example geo location data e.g. geo tags are generally based on the location of the camera and not the landmark that is being photographed. Also in some cases the geo location information is based on user provided information such as city name and may therefore not be accurate. Text tags provided by authors and third parties may not accurately describe the landmark. Author information for each image can be based on a camera identifier a person who captures the image or a person who uploads the image to a web site. Visual match information can also be erroneous in situations such as when several landmarks exist in a small area when landmarks look alike and or when image quality is not sufficient. Embodiments of the present invention therefore leverage several types of available information to obtain a high degree of landmark detection and accurate annotation in digital images.

A system for building a database of annotated popular landmark images according to an embodiment of the present invention is shown in . System includes a computer a user interface networks and a text image document collection an n gram collection n gram filters database database of un annotated images database of appearance models annotated images and text image sources . A person of skill in the art will appreciate that system can include more less or different components and modules than those listed above while still being consistent with the present invention.

Computer may include one or more computers servers or like computing devices that are interconnected by a communication medium. For example computer can comprise one or more commercially available computing servers that are coupled by one or more local area network such as an Ethernet network Gigabit Ethernet network WIFI network or the like. A computer includes a processor volatile memory persistent memory network interface database interface a communication medium to couple modules of computer and an unsupervised image annotator module . Processor can include one or more commercially available central processing units CPU graphics processor units GPU field programmable gate array FPGA digital signal processors DSP and application specific integrated circuits ASIC . Processor controls processing within computer receiving inputs and outputting data into or from computer . For example the processing logic of unsupervised image annotator module can be executed on processor .

Volatile memory can include a volatile memory such as dynamic random access memory DRAM static random access memory SRAM or the like. Volatile memory can be used to store configuration parameters source data and intermediate results of the processing of module . Configuration parameters can include connection information for text image sources and other parameters that configure the operation of for example processing of unsupervised image annotator module . Persistent memory can include one or more non volatile memory devices such as magnetic disk optical disk flash memory read only memory ROM or the like. Persistent memory can be used for storing the logic instructions for unsupervised image annotator module configuration parameters and to store intermediate and other results of the processing in module .

Network interface can include the functionality to communicate with entities connected to computer through networks including network such as text image sources . For example network interface can include processing components including Internet Protocol IP and Hyper Text Transfer Protocol HTTP processing such that enables computer to connect to text image sources to obtain text and image information. For example HTTP protocol processing machine software can be implemented as part of network interface . Database interface includes the functionality to connect computer to one or more databases used in processing images for landmarks according to embodiments of the present invention. It should be noted that the use of the term database does not necessarily refer to a database management system DBMS but rather encompasses any collection of data. Database interface therefore can include DBMS functionality to connect to one or more DBMS systems comprising one or more databases or processing logic to communicate with the type of database of each type of database . Communication medium can connect modules of computer including modules and . Communication medium can include a communication devices such as a PCI bus USB Ethernet or the like.

Unsupervised image annotator module includes the functionality to identify landmarks generate appearance models for selected landmarks and to annotate images according to an embodiment of the present invention. Landmarks contained in images can be identified based on explicit tags already associated with the image or through algorithmic means as described below. The functionality of unsupervised image annotator module can be implemented in software firmware hardware or any combination thereof. In one embodiment processing logic for the functionality of unsupervised image annotator module can be implemented in a computer programming language or script language such as C C Assembly Java JavaScript Perl or the like.

Networks can include a means of connecting computer to one or more text image sources . Network can include a means of connecting computer to one or more databases . Networks and can include one or more network mediums including peripheral connections such as USB FireWire or local area networks such as Ethernet WIFI or wide area networks such as a PSTN or Internet. In one embodiment network includes the Internet and network includes an Ethernet based local area network.

User interface can be connected to one or more computers using any one or a combination of interconnection mechanisms such as PCI bus IEEE 1394 Firewire interface Ethernet interface an IEEE 802.11 interface or the like. User interface allows a user or other external entity to interact with computer . In some embodiments one or more databases can also be interacted with through user interface . One or more of a graphical user interface a web interface and application programming interface may be included in user interface .

Text image sources can include various types of digital document collections that include images of landmarks and associated text e.g. landmark tagged images . In one embodiment text image sources include one or more photo collections that have photos associated with captions and tags. Captions as used herein refer to a title assigned to a photo. Tags as used herein refer to one or more words or phrases assigned to a photo. Often captions as well as the tags are assigned by the author e.g. originator of the photograph or person uploading the photograph to a photosharing website of the photograph. However captions and tags can also be assigned to a photograph by a third party or an automated tool. Unless each is identified separately the term tag in the following description includes tags as well as captions.

Text image sources can also include collections of hypertext documents that hyperlink images to documents and vice versa and can also include newspaper corpora magazine and journal corpora blog archives digital libraries having digitized books third party annotated photo depositories and personal and business web sites. For example tourism and or travel related websites digital travel guides city websites etc. are some resources that generally includes images of landmarks and descriptions of those landmarks. However any collection of digital data where a correlation between one or more images and associated text can be drawn can be included in text image sources .

Text image collection is a database where in some embodiments local copies and or modified versions of text image data originally accessed in remote text image sources are saved for example for more convenient and reliable access for processing by unsupervised image annotator . For example because accessing data and images in text image sources over network which can be a wide area network such as the Internet may involve long latencies there may be a process not shown in computer that makes copies of such data and images in a local or locally attached network location such as in text image collection . Text image collection can also include collections of images that are already tagged for example user photo collections in Picasa Web Albums and or image collections already processed according to teachings in the present invention. In some embodiments text image collection can include a data structure corresponding to each image in which the data structure includes one or more pointers to images and or documents in text image sources for example to avoid having to create a separate copy of the image and or documents from text image sources .

N gram collection is a database that includes a collection of n grams. N grams can be extracted from captions tags or text documents associated with images in for example text image collection or text image sources . As used herein an n gram is a sequence of one or more words. The selection of n grams can be done using methods similar to one or more of several techniques used for example in text analysis. The selection and extraction of n grams according to embodiments of this invention is further described below.

N gram filters database includes one or more lists of n grams to be filtered out of n gram collection and or one or more filtering rules to be applied to n gram collection . For example one list in n gram filters database can be a bad words list where the n grams appearing in the bad words list are not extracted from text image collections or text image sources and are removed from n gram collection if they are found to be present. Another list may be a list of n grams that occur too frequently in image associated text and therefore are of little value as landmark identifiers. Words such as the and of can be considered in this category. Another list can be a list of phrases that are known to appear too frequently and are therefore not sufficiently useful as discriminatory landmark identifiers.

Unannotated images database includes images that are yet to be annotated e.g. tagged according to embodiments of the present invention. For example unannotated images database can include the tagged digital images uploaded by one or more users in order to be processed using an embodiment of the present invention.

Appearance models database ill holds the recognition models herein referred to as appearance models that are derived in order to recognize landmarks in images for example images in unannotated images database .

Annotated images database contains the images that are annotated according to embodiments of the present invention. For example images from unannotated images database are stored in annotated images database after they are processed by unsupervised image annotator according to an embodiment of the present invention. A person of skill in the art will recognize that although databases are described as separate databases above databases can be arranged and or implemented in various ways consistent with the present invention.

Landmark identifier module includes the functionality to identify landmarks in text image collections and or text image sources . Landmark identifier module can in one embodiment use images and associated text from text image sources as input and copy such images and associated text to text image collection . Landmark identifier module can also analyze the text in text image sources while using and updating n grams collection . N gram filters database can also be used in the processing within landmark identifier module .

Appearance model generator includes the functionality to generate one or more appearance models for each landmark that is for example identified by landmark identifier module . In one example appearance model generator can take as input the images and identified landmarks in text image collection and generate one or more appearance models for each of the landmarks. The generated appearance models can be written to appearance models database .

An appearance model as used herein is a template to be used in the automatic recognition of certain common features in images. In one embodiment of the present invention an appearance model used for the recognition of a landmark can include a feature vector comprising numerical scores for a set of predetermined image features. Methods of object recognition in images and of generating feature vectors are well known in the art. For example methods of object recognition in images are described in David G. Lowe Object recognition from local scale invariant features Corfu Greece September 1999 pp. 1150 1157. In addition to the visual recognition components an appearance model can also include information such as geo location information for the corresponding landmark. For example the geo location information in the appearance model for a particular landmark can specify a geographic point and or a geographic area. Specifying a geographic area can reduce uncertainties created due to the variance in accuracy of the geo location information of images.

Image annotator module includes the functionality to automatically recognize landmarks in images and appropriately annotate such images with information identifying the one or more corresponding landmarks. In one embodiment image annotator module can use appearance models from appearance models database to automatically recognize landmarks in images from unannotated images database . The images can then be annotated for example by associating one or more tags according to the recognized landmarks in each image and the annotated images can be written to annotated images database .

In step images and text associated with those images are analyzed to identify landmarks particularly popular landmarks. Popular landmarks in general are those landmarks that appear most frequently in the analyzed image text sources such as text image sources . The input to the processing in step in one embodiment is one or more image text sources accessible to the one or more computers on which process is being executed. For example process can be executing on computer and can have accessibility to text image sources over a network . The output from step according to one embodiment can be a selected set of images identified landmarks in those images and associated text and n grams. For example the output of step can be written into text image collection . Step is further described with respect to below.

In step one or more appearance models are derived or learned for landmarks identified in step . A person skilled in the art will recognize that one of many methods may be used to learn an appearance model from the landmark tagged images obtained as a result of step . According to one embodiment the appearance model for a particular landmark comprises a feature vector that numerically quantifies one or more visual aspects of one or more images considered to contain the particular landmark. As described earlier feature vector generation is well known in the art and an approach for feature vector generation such as that can be used in the present invention is described in David G. Lowe Object recognition from local scale invariant features cited above. The feature vector for example ideally includes a substantial number of features that are relatively invariant to the numerous varying conditions such as camera distance camera angle image quality lighting conditions etc. In some embodiments of the present invention the one or more appearance models corresponding to a particular image can also include non visual aspects of an image such as geo location information. An appearance model can include any information including visual characteristics of the particular landmark and geo location information that can be used in automatically recognizing the existence of that landmark in images.

In step the one or more appearance models obtained in step are used to detect a corresponding landmark in images. In one embodiment one or more appearance models in appearance model database are used in the detection of a corresponding landmark in unannotated images database. For example feature vectors of an appearance model from appearance models database can be compared to feature vectors generated for the image from unannotated images database that is being considered. If the feature vectors match beyond a predetermined threshold level the image being considered is recognized to include the landmark that corresponds to the matched appearance model. Object recognition technology such as that can be used in step in an embodiment of the present invention is generally well known. One approach to object recognition that can be used in the present invention is described in Lowe Object recognition from local scale invariant features cited above.

In step the image being analyzed can be annotated if it is determined to have within it a particular landmark corresponding to the one or more appearance models that were used in the detection for example in step . Annotated images and the respective annotations can be written to annotated images database . The annotation associated with an annotated image can include text associated with each one of the appearance models that were found to have a match in that annotated image. It is also contemplated that the annotations associated with the annotated image can include text or phrases based on additional processing of the text associated with the corresponding appearance models. For example in an embodiment in which the text associated with the corresponding appearance models are of the form of simple tags such as Statue of David and Rome step may include additional processing to generate a sentence such as Statute of David in Rome Italy Statue of David in Palacio Veccio Rome Italy or the like.

In processing involved in step is shown in further detail. The functionality of step includes steps . In step an n gram set of words or phrases descriptive of landmarks is generated and or an existing n gram set is updated. For example step can take as input text image sources and produce as output n grams in n gram collection . A more detailed description of step as in how one or more n grams descriptive of landmarks are generated is provided below in relation to .

In step a set of n grams that are preliminarily considered as being useful for landmark determination is scored. For example the initial set of n grams considered in step can be the set of n grams derived from text image sources in step . The processing of step can create a list of n grams in n gram collection . The n grams are filtered according to various criteria including having each n gram scored and keeping only a predetermined number of n grams with the highest scores. An n gram score S k is assigned to each of the n grams N k in n gram collection . A method of determining S k is described below. Processing of step is further described with respect to below.

In step images are assigned tags from n gam collection . For example for each pair of image and n gram combination a pairing score can be assigned. The pairing score can be defined such that the higher valued pairing scores imply strongly related image and n gram pairs. In one example the pairing formed by image I i from image text collection and the n gram N k from n gram collection can be assigned a pairing score defined by the product of the strength L i k of the link between I i and N k and the n gram score of N k i.e. L i k S k . A method of determining L i k is described below. A list of candidate n grams can be generated by focusing on the n grams with high pairing scores and truncating the list appropriately. In one instance the list can be truncated when the pairing score falls lower than half of the highest pairing score in the list. In this manner each image can be assigned the most relevant n grams.

In step a list of potential landmark descriptor n grams are retrieved from text associated with images in text image sources . The extraction of n grams from photo repositories where photos are associated with tags and or captions can include the collection of the set of tags and or captions associated with photos of the photo repositories of text image source . When image text sources include other documents and or content that associates images with corresponding text one or more of numerous text analysis methods can be used to extract terms tags that potentially correspond to landmarks. For example a text associated with an image in a tourism website can be automatically analyzed using a method well known in the art such as term frequency inverse document frequency TF IDF over the text available to identify potential tags. In one embodiment TF IDF is applied to the tags associated with photos in a photo repository from a text image source .

Predetermined rules can be applied to determine a narrowed and or filtered set of tags that refer to landmarks from the potentially large number of available tags. For example in step one or more filtering rules or criteria can be applied to the set of n grams of potential landmark descriptors collected in step . One filter that can be applied to the list of potential landmark descriptor n grams is a bad words filter. The bad words filter includes a list of n grams and phrases that are predetermined as bad and or unhelpful to discriminate among landmarks. Another filter that is applied can be a stop word list. The stop word list can include n grams that are expected to Occur so frequently in tags and or descriptors that they are unlikely to be helpful as landmark descriptors. Words such as of the and and are example n grams that can be included in a stop word list. Another filter that can be applied is a minimum reliability measure such as a minimum number of authors filter. The minimum number of authors filter can be used to remove any n grams from the list of potential landmark descriptor n grams that have less than a predetermined number of unique authors using those n grams in their tags. For example it may be predetermined that for any n gram to be included in n gram collection the n gram Should be detected in the tags used by three or more unique authors.

In step the list of potential landmark descriptor n grams remaining after the one or more rules and or filters are applied in step can be written in n gram collection . The set of n grams from n gram collection used by subsequent processing steps such as processing step is a set of n grams that have been filtered according to several filters as described above and would therefore include only n grams that are substantially descriptive of landmarks

In step a matching images graph is created from images in for example text image collection . Nodes in the matching images graph represents images in text image collection . Each edge in the matching images graph represents the extent to which the images corresponding to the two connected nodes match. For example the matching score M i j assigned to the edge between images I i and I j can be a numeric value that is derived based on the match between the feature vector of image I i and the feature vector of image I j . Individual features in the feature vectors may be assigned configurable weights and the matching score M i j can be the summation of such the weights of the matching features.

In step links referred to as image name links are formed between each of the n gams in n gram collection and images in text image collection . The image name links can be a binary variable set to 1 if the n gram is contained by the tags of the images and 0 otherwise. However in order to increase the robustness of the results the output is smoothed by averaging over a set of images that are visually similar rather than considering single images. For example image name link between image I i and n gram k L i k can be defined as 

where as noted above M i j is the matching score between images I i and I j in the image matching graph and W j is the correlation weight of image I j .

In step the geo reliability of each image in text image collection is estimated. The geo reliability of image I i G i is an estimation of the accuracy of the image s geo location information based on a comparison of the visual consistency of images with geo location coordinates within a predetermined distance to each other. For example 

In step a geo variance can optionally be computed for each n gram N k . For example geo variance V k of N k can be expressed as loc loc 

where loc i represents the geo location of image I i and EW is the weighted expectation. The weighted expectation is helpful in capturing the variance of the most significant location points for the n gram. Weights can be computed as L i k W i G i i.e. the product of image name link image weight and image s geo reliability. Subsequently n grams with V k larger than a threshold geo variance can be filtered out from the n gram collection .

In step the n gram score S k of each n gram N k in text image collection is determined using a measure that is designed to capture the internal link strength between images that have n gram N k in its tags and the external link strength between images that have n gram N k in its tags and images that do not have n gram N k in its tags. For example S k can be expressed as 

The larger the S k the more likely that n gram N k refers to a meaningful visually distinguishable entity and therefore more likely to be a landmark name.

In step after the n grams are scored a further filtering can optionally be implemented to identify the most popular landmark n grams. For example the n gram scores of a predetermined number of n grams having the highest n gram scores can be averaged to determine a threshold average score. Thereafter all n grams other than those n grams having a score higher than the threshold average score can be removed from n gram collection .

In step n grams that are considered to refer to the same landmark location are merged. Although the scoring step and the subsequent filtering based on scores generally leaves a list of n grams that meaningfully refer to landmarks many n grams referring to the same landmark can still remain in n gram collection . Multiple n grams referring to the same landmark can exist because of several reasons including different names for the same landmark different formulations of the same name and substring truncation. It would be desirable to merge such duplicate n grams together in a meaningful manner. To address this in one example if two n grams N k and N l have their scores within a predetermined distance from each other and if the images they are linked to are substantially overlapped then the two n grams N k and N l are merged. The substantial overlap of images can be determined for example by considering the Bhattacharya distance of L i k for each image I i and n gram N k pair and determining whether the Bhattacharya distance is above a predetermined threshold. The computation of Bhattacharya distance is well known in the art.

The processing functionality of module and or modules can be achieved in software hardware or a combination thereof. For example modules and may be implemented entirely as software modules or some of the functionality of the appearance model generator module may be implemented using hardware such as a field programmable gate array FPGA . It will be understood by a person of skill in the art that unsupervised image annotator module and or computer may include additional components and modules that facilitate the functions of the present invention.

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor s and thus are not intended to limit the present invention and the appended claims in any way.

The present invention has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.

The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can by applying knowledge within the skill of the art readily modify and or adapt for various applications such specific embodiments without undue experimentation without departing from the general concept of the present invention. Therefore such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.

The breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

