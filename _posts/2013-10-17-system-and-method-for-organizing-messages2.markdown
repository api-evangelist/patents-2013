---

title: System and method for organizing messages
abstract: A system and method for sorting messages within an interface including providing a navigational menu with at least three menu options of at least three message collections, the menu options ordered according to an ordered horizontal virtual arrangement of a set of message collections; upon receiving user selection of one of the menu options, activating the message collection corresponding to the user selected menu option, which comprisesâ€”displaying the message collection of the selected menu option and virtually positioning the remaining set of message collections off screen; within the active message collection of the set of message collections, detecting a gesture swipe in a horizontal direction; selecting a sorting option corresponding to a message collection virtually positioned in the horizontal direction relative to the active message collection; and transferring the message to the message collection of the selected sorting option.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09654426&OS=09654426&RS=09654426
owner: DROPBOX, INC.
number: 09654426
owner_city: San Francisco
owner_country: US
publication_date: 20131017
---
This application claims the benefit of U.S. Provisional Application Ser. No. 61 728 626 filed on 20 Nov. 2012 which is incorporated in its entirety by this reference.

This invention relates generally to the messaging interface field and more specifically to a new and useful system and method for organizing messages in the messaging interface field.

Email is a ubiquitous form of communication in modern society. Email has grown beyond a tool for corresponding with others to a tool for organizing and managing people s lives and businesses. Many people use email as a way to manage tasks. But as a seemingly ever increasing amount of content is communicated over email users struggle to manage the volume of messages that are received every day. At the same time people are moving to rely more and more on mobile computing. Many organizational tools that are available on desktop do not translate to interfaces to handheld or tablet mobile computing devices. Thus there is a need in the messaging interface field to create a new and useful system and method for organizing messages. This invention provides such a new and useful system and method.

The system and method for organizing and sorting digital content functions enables an intuitive and natural interface when interacting with digital content on a device. The system and method applies gesture associated actions to digital content according to a currently active message collection. The gesture to action mapping can depend on the directionality and magnitude of the gesture along an axis and on the virtual position of inactive message collections along the same axis. The input gestures and the sorting action are dynamically remapped when navigating to a new message collection to simulate pushing a message between ordered stacked or arranged content collections. The method is primarily used for sorting between at least three collections but can additionally be applied to four five or any suitable number of collections. The method can have particular benefits when applied to enabling powerful and natural content sorting capabilities on a device with limited screen real estate such as on a mobile device a wearable computer a tablet computing device or any suitable computing device.

The following description of preferred embodiments of the invention is not intended to limit the invention to these preferred embodiments but rather to enable any person skilled in the art to make and use this invention.

As shown in a system for organizing messages of a preferred embodiment may include a computing device with a display and an application including a message client a mailbox view controller and a gesture detection engine . The system functions to render an interactive interface for sorting and managing messages of a mailbox. The system can enable users to quickly and intuitively manage email through a gestural interface. The system can provide a mailbox organization configuration that is managed through gestures applied directly to messages. The system can be configured for interfacing with an email account but may alternatively or additionally be used with alternative information streams such as social network messaging news streams task lists or any suitable updated collection of information.

The computing device and display of a preferred embodiment functions to process and render the interface for a user. The computing device can be a mobile device such as a smart phone but may alternatively be a tablet a desktop computer a gaming system a TV connected computing device a wearable computing device or any suitable computing device. The device can includes an input device capable of detecting gestural input. Preferably the input device is a touch screen but may alternatively be a user motion image detection system device motion sensors a cursor positioning device e.g. a mouse or trackpad or any suitable input device.

The message client of a preferred embodiment functions to manage the sending receiving and manipulation of messages. The message client is preferably a native application operable on the computing device. The message client may alternatively be a web based application an operating system based service a notification service a framework operable within a second application or any suitable computer readable medium storing computer readable instructions that defines user interactions. The message client preferably communicates with a server of a message service provider server of a mailbox service that is a proxy for the message service provider or any suitable messaging service. The message client preferably manages an email account. The message client may alternatively manage social network messaging instant messaging information streams or any suitable source of messages. The message client preferably receives messages and appropriately incorporates those messages into a rendered interface. The message client may additionally send messages. Additionally the message client preferably translates inputs detected by the gesture detection engine into corresponding response actions translated for the message service provider. For example moving an email to a list may involve creating a folder and adding the message to the folder on the message service provider. Moving a message to trash may queue the message for deletion on the message system provider.

The mailbox view controller of the application of a preferred embodiment functions to render the interface on the display of the device. The mailbox view controller preferably depicts messages as a list of message items. The message items which are actionable through a gesture input may alternatively be in presented or rendered in a gallery view as shown in a stacked view as shown in a coverflow view a card view within a document article view or any suitable view of mailbox item or items. The mailbox view controller additionally cooperatively works with the gesture detection engine to render input feedback while the gesture is in progress. For example as a user slides a touch contact point horizontally across a message the action of the current gesture state is displayed according to the planned execution. Additionally the message is preferably animated as a function of the gesture input. The animation is preferably a horizontal sliding animation that is proportional to the gesture input displacement. Here horizontal is meant to indicate a first axis. The first axis is preferably perpendicular or otherwise distinguishable from a scrolling axis. For example if the gestures are substantially horizontal then the view is preferably scrollable if scrolling is enabled along a vertical axis.

The mailbox view controller may additionally be configured to display full messages lists folders streams of an account and or any suitable portion of the application interface. In one preferred variation the navigation of directories e.g. folders or lists of a mail account is accessed through interface interaction that promotes a consistent cognitive mapping of directory location and the sorting behavior of gesture actions. A navigational interface preferably includes an ordered set of views that the message client controls to provide a consistent simulated graphical order arrangement. A navigational view can be a pane a modal view an application operating mode or any suitable visual state that contains interface elements. The positional arrangement is preferably aligned along a horizontal axis and more preferably the views are substantially modular wherein only a limited number of views are active at one time e.g. one modular view on a phone two side by side possibly on a tablet . As shown in the views of the navigational interface may include optional list stream view in a first position a deferred message stream view in a second position an inbox in a third central view and an archive stream view in a fourth view. As mentioned above the actions corresponding to a gesture preferably map to the current navigational view order and changing navigational views re indexing what actions are mapped to a gesture state. In effect navigating between views can impact which actions a user can reach because the gesture functions to simulate sorting messages to various categorizes that are either one or optionally two navigational positions away in navigable directions e.g. right or left . In one variation the consistent indexing is preferably maintained within the central view e.g. the inbox and the adjacent navigational views. In some cases the model may break down because access to critical actions is lost by adhering directly to the corresponding navigational based mapping. For example when viewing a list stream view the mapping may include actions to add to the inbox setting a reminder condition and archiving. The mailbox view controller may alternatively be divided into any suitable assortment of components.

The mailbox view controller can additionally make use of graphical animation of navigation views and or message items to reinforce cognitive cues and feedback relating to gesture to action mapping. For example the gesture states preferably depend on swiping touch events along an axis. When detecting an in progress gesture the message mailbox view controller is preferably configured to animate the message item while revealing a UI element that communicates the current action. When the swiping touch event is completed the message item preferably animates off the screen in the direction of the view that corresponds to the action.

The gesture detection engine of a preferred embodiment functions to analyze and convert user input to actions by the message client. The gesture detection engine preferably executes any number of heuristics to identify different classes of input gestures. There is preferably a plurality of defined gestures that correspond to various message actions. Preferably the gesture detection engine is coupled to the touch events of a touch screen device. More preferably the detected gestures are orthogonal to scrolling or content navigation touch gesture detection e.g. provided by a user interface scroll view . In other words the gesture detection engine detects various gesture states that do not conflict with other gesture functionality. An additional benefit of the described gesture detection configuration is that the interface does not require constant presentation of interaction elements and thus increases screen area for content. The gesture detection engine can preferably achieve this benefit while maintaining an intuitive and discoverable user input interface. The gesture detection engine of a touch device preferably processes the touch start position the direction of touch motion velocity of touch motion acceleration of touch motion the distance of touch motion time progression of touch motion pressure of touch input number of touch inputs relationship of multiple touch inputs off screen edge touch event swiping onto the screen or off the screen and or any suitable parameter of the touch input. The gesture detection engine preferably continuously updates the determined gesture state during received input to reflect the current gesture state the corresponding action of the gesture state and any suitable rendering updates to the user interface to reflect the current state. Touch based devices preferably involve the touch input to be directly applied to displayed user interfaces. For example the user touches the message item displayed on the screen. Alternatively the touch events may not be directly applied. For example on a wearable computing device the touch sensing may be on a different physical component e.g. an arm of glasses where the user interface displayed in a heads up display. In another embodiment the gesture detection engine processes natural user motion detected by a vision system. Motions of a hand may have similar gesture patterns as touch gesture patterns but additional or alternative gestures may be used. Similarly device motion sensors such as accelerometers and gyroscopic sensors of a mobile device may be used to convert movement of a device to an action. As yet another variation desktop computers can preferably use cursor input devices such as a mouse or trackpad to receive inputs and those gestures may then be translated to actions. The gestures are preferably configured for the form of input device.

As shown in a method S for organizing messages of a preferred embodiment may include receiving a message stream S detecting an initiated gesture for at least one message S tracking gesture state S identifying action of gesture state S and applying a message action on the message according to a final gesture state S. The method functions to enable gesture based management of a messaging system. Incoming messages can quickly grow out of control and thus the method allows a user to easily sort and apply automatic actions on the messages to simplify management of the messages. The method is preferably used for management of an email account but may alternatively be used with any suitable messaging system event or content stream. The method preferably relies upon a collection of gestures that are mapped to a message action. The gestures and message actions are not limited to those described in this document and may include any suitable gesture to action mapping of the gestures and message actions shown and or described in this document and any suitable alternatives.

Step S which includes receiving a message stream functions to interface with a message source. A message client preferably manages the receiving of messages. The message stream is preferably a chronologically ordered list of messages of a same folder list tag categorization or otherwise grouped together. The stream may alternatively be alphabetically ordered or ordered in any suitable manner. The method can preferably act on any suitable list or stream of messages. The method may be primarily used for sorting the inbox folder of an email account but the method may additionally be used on sent messages other message streams detail views of a message or message thread or any suitable content stream to improve organization. The message stream is preferably for a messaging account but may additionally be for a plurality of messaging accounts. Similarly while the stream is preferably a message stream the stream could be a notification alert stream a list of files in a file path or any suitable collection of actionable items. A preferred embodiment preferably includes an inbox message stream a conditional message stream list streams an archive stream and a trash stream as shown in . New messages and or updated messages e.g. emails that have been triggered for reminding preferably appear in the inbox message stream. The conditional message stream is preferably a deferred response list that may be customized to move a message to the mailbox stream upon satisfying a condition. In one variation the conditional message stream is a later deferred steam for removing a message from an inbox until a particular condition is satisfied. The condition is preferably a time condition. For example the message may be acted upon so that the message is moved to a conditional message stream and then subsequently moved into the inbox stream a week later. The condition can additionally or alternatively be based on the accessing device e.g. phone tablet work computer home computer geographic position proximity to other users e.g. move message to inbox when near Angela and Alex other actions e.g. responded to another email and or any suitable condition. A list stream is any suitable grouping of messages. Preferably a user generated label or category is used to group messages. The archive message stream may be used for messages that generally require no more action. The trash stream preferably includes any messages that are awaiting automatic or user initiated deletion. The method may use any suitable number of streams and types of streams. Also the gesture based interaction with a message of a stream may be performed on any suitable message stream.

Step S which includes detecting an initiated gesture for at least one message functions to start gesture tracking that determines an action performed on a message. An initiated gesture is preferably detected after an interaction event satisfies a gesture condition which functions to distinguish gesture input from other user interaction input such as scrolling. Preferably the gesture is initiated upon detecting at least a single touch event and then the touch point moving in a direction substantially along a first axis e.g. in a horizontal direction . Taps or vertical swipes are preferably detected as other forms of user interaction input such as opening a message or scrolling. A message is preferably selected as the acted upon message based on the starting point of the gesture. If a touch event occurs at a coordinate of an interface that coincides with the location of a view of the message the message is selected. In one variation a plurality of messages is displayed in a vertically scrolling list. In another variation a plurality of messages is displayed in a gallery grid scrolling view. As yet another variation a plurality of messages is displayed in a stacked message view. A message can be selected for a gesture action by starting the touch gesture at the desired message and moving the touch point substantially perpendicular to the direction of scrolling e.g. at an angle between 45 and 90 from the axis of vertical scrolling . More preferably only the displacement of a touch event along one axis is considered in assessing gesture state e.g. only the horizontal x axis is considered . When viewing a message not in a list view but in a detail view e.g. displaying the full message or message thread the gesture can preferably begin anywhere over the message view. In interfaces for devices with more limited screen real estate such as watches glasses and other wearable computing devices one message item may be presented at a time and so any initiated gesture would be directed at the focused item. Alternatively a message may be selected according to any suitable heuristic.

Step S which includes tracking gesture state functions to progressively track a gesture input. An input is preferably tracked while a gesture input is in progress. For example a gesture recognition engine preferably updates gesture state while a user is moving their finger on the screen. Progressive tracking of a gesture functions to allow gesture feedback as a user is performing a gesture. Progressive tracking of a gesture may additionally function to enable gestures to be reverted to a preceding gesture state change the set of progressive gesture states engaged and or even canceled. As an alternative approach tracking gesture state can include tracking an input displacement along a first axis from an initial input point mapping the tracked input displacement to a set of ordered gesture states and identifying an action of the mapped gesture state. The gesture input is preferably supplied through various exposed interfaces of the device. The raw or parameterized gesture input e.g. touch events and coordinates of a touch point is then used to calculate the current gesture state. As described elsewhere a preferred variation has a second gesture state mapped to an input displacement in a first direction of the first axis that is greater than an input displacement of a second gesture state and similarly a variation can include mapping a third gesture state to an input displacement in a second direction of the first axis that is greater than that of a fourth gesture state.

The method may additionally include displaying a graphic representation of the current gesture state. The gesture state graphic preferably includes text indication color indication graphics indication graphic dimensional transformation and or any suitable visual cue for the current gesture state. The message item preferably animates with the gesture input. In a preferred variation the message item slides along the axis of the gesture in proportion to the gesture input. The gesture state graphic is preferably displayed within the area revealed by the moved message item. The revealed area is the screen area that was previously occupied by content of the message and or digital content item. When moved or translated screen area is exposed and can be used to communicate information about the current state of the gesture. Other variations may include changing transparency of the message deforming the message item transforming properties of the message item e.g. changing color revealing overlaid icons or other suitable approaches. The method may alternatively generate gesture state feedback such as audio or tactile feedback. The gesture state preferably corresponds directly with an action performed upon completing the gesture. Any suitable heuristics conditional logic machine learning and or other suitable algorithms may be used to track a gesture. Gestures may have varying progressive ranking. In other words gestures may have a first state a second state third state etc. The progressive ranking states may be characterized by a gesture that must first pass through a preceding gesture state. For example a second gesture state may be obtained by a user making a gesture which transitions from the first state to the second state. The progress through the ordered gesture states may be reflected in the user interface. Alternatively a gesture engine may interpret an input as a metric for which gesture states may be defined and the gestures may not be detected in a progressive manner. Additionally there may be different classes of gestures. In a first preferred embodiment there are two classes of gestures each with a first state and a second state. Gestures may alternatively be defined in any suitable manner.

In a preferred embodiment the method detects at least two classes of gestures each with a first and a second state i.e. at least four different gestures . The first class of gestures may be characterized by swiping substantially to the left. The second class of gestures may be characterized by swiping substantially to the right. Here left and right define distinct directions along an axis. For both classes of gestures the distance of the swipe velocity acceleration and timing may be factored into determining if the action is a primary gesture or a secondary gesture. In general terms the swipes may be described as a short left swipe a long left swipe a short right swipe and a long right swipe. An inherent gesture state may exist for no action which may be defined for minimal swiping in either direction. Swipes are preferably translations or displacement of at least one point of user input. A touch event starting at a point of a message view and moving substantially horizontally to the right a short distance and or slowly is preferably a first state gesture as shown in . A touch event starting at a point of a message view and moving to substantially horizontally to the right a long distance and or with high acceleration is preferably a second gesture as shown in . As another variation timing of the touch motion may impact the gesture state. For example each pause in motion during a swipe may transition to a new gesture state. This may function to enable a user to make higher order gestures by pausing several times. In a similar variation changes in direction of a gesture may be used to transition between higher and or lower order gestures. For example a touch that zigzags back and forth may be used to shift between different orders of a gesture state. The thresholds between different gesture states can additionally be tuned according to user expectations. The thresholds can alternatively be automatically set in different application instances according to individual user patterns. The threshold between two gesture states in a first direction can be proportional to the input mechanism used to generate the gesture input. On a touch screen the input mechanism is commonly a single finger but may alternatively be multiple fingers or a stylus. In a vision based system the input mechanism can be a full hand arm controller object or any suitable visually tracked object. A first gesture state is preferably activated when the gesture input has traveled a distance of approximately the width of an average input mechanism 75 125 width of average input mechanism . The second gesture input activates to a second progressively ordered gesture state when the gesture input has traveled a distance approximately three times the average input mechanism width. If an average input mechanism is given a unit of one then the transition between the first and second gesture states can occur between 2 and 4 units with three being preferred. On a touch device this can equate to roughly thresholds of 60 pixels and 200 pixels on a screen with a resolution of 163 ppi. In one exemplary implementation the threshold between gesture states in a direction is 200 screen units e.g. 200 pixels or 400 pixels on a high resolution screen . Swipes to the right less than 200 are preferably a first gesture state as shown in and swipes to the right greater than 200 are preferably a second gesture state as shown in . Additionally a first gesture state is preferably active for a minimum amount of time e.g. 250 milliseconds . In other words gesture input swipes that are completed terminated in less than 250 milliseconds e.g. relatively fast swipe are interpreted as a fast swipe as shown in which is based on user patterns where a quick swipe was intended for the first progressively encountered action as opposed to interpreting it as a more forceful gesture to indicate a secondary gesture state. The time threshold may alternatively be any suitable value to mark a fast or quick gesture. Such time limits may be based on the type of device and or input sensing approach of a device. Other conditions for gesture sate detection may alternatively be used. As mentioned above gestures may be from inputs other than touch devices. For example device sensor input may be used similarly. In one embodiment tilting a device to the right may indicate a class e.g. right or left gesture and translating the device will progress the gesture through the gesture states. Performing a touch input that transitions across the edge of the screen may additionally be used as a condition for setting gesture state. Detecting gesture input that transitions across the edge of the screen preferably includes transitions onto the touch sensitive area or out of the touch sensitive area. In one variation detecting a transition onto the touch area would be when the initial touch input position is substantially close to the edge of the screen. Detecting a transition off the touch area would be when the final touch input position is substantially close to the edge of the screen. Other gesture state modifiers may be the number of touch inputs. For example the number of fingers on the display may augment the gesture state. Any suitable gesture heuristics may alternatively be used.

Step S which includes identifying an action of the gesture state functions to map an action to the detected gesture. Each gesture preferably corresponds to an action to perform on a message. Additionally a plurality of gestures may correspond to a single action which may function to enable different variations of a gesture to result in the same action. For example a primary gesture may include a short quick swipe to the right or a long slow swipe. The actions are preferably sorting actions for the message. For example the actions may include moving to an archive the trash a custom list a reminder stream a starred marked stream a task list and or any suitable stream directory category. In one preferred embodiment the gestures correspond to actions that also correspond to stream navigation. For example the list navigation is preferably configured to reinforce or represent a right to left arrangement of streams with the main inbox centrally positioned. For example moving a list to a custom list from the inbox preferably requires a long swipe to the left and the custom list may be accessed and viewed by selecting a button to the far left. Thus the navigation and gesture are in agreement by reinforcing a far left position of the custom list.

Some streams may modify the message or perform conditional logic on the management of the message. A message may be added to a reminder stream that will conditionally move the message out of the reminder stream after a condition is satisfied. The condition is preferably an amount of time but may alternatively be according to geo location of the user absolute geo location of other users geo location of users relative to the device user response by another recipient of the message response to another message device access e.g. next time on desktop computer a combination of Boolean logic for multiple conditions programmatic logic e.g. accessed through application programming interface API and or any suitable conditions. The message is preferably moved into an inbox after the condition is satisfied but the message may be moved to any suitable location or acted upon in any suitable manner. For the marked list a mark or indicator e.g. star important label may be applied to the message.

Step S which includes applying a message action on the message according to a final gesture state functions to apply the identified action on the message. The final gesture state is determined by when the gesture input ends. For touch devices removing a touch point of contact ends the gesture input. The actions are preferably message sorting actions. As mentioned above the sorting actions may include moving to an archive the trash a custom list a reminder stream a starred marked stream a task list and or any suitable stream. The actions may alternatively include replying to a message forwarding the message adding the message to a calendar sharing the message through an alternative form of communication e.g. social media SMS MMS messaging transferring contents to an application and or any suitable type of action. The actions can directly correspond to actions of a messaging service. For example adding a message to a list may include moving or copying an email to an email folder. In some cases a folder system may be generated on a messaging service to accommodate the list architecture of the application. In some cases the architecture of message organization may be transparently generated by the system of the email client. In other words the organization of the messages may not be transferred to the messaging service and may not be reflected in the user interface provided by the original messaging service. Applying the message action on the message according to the final gesture state may additionally include animating a message transition. The animated message transition is preferably the message animating out of the stream in the direction of the swipe. In some cases this direction also corresponds to the direction of the destination message stream view.

Additionally the method may include retrieving action option selection. The action option selection view preferably enables a user to customize the action by setting a parameter of the action. The action option selection is preferably a secondary view that is displayed directly after completion of a gesture. The action of moving a message to a reminder stream preferably triggers the display of an action option selection view allowing a user to specify an amount of time to wait or a particular time when the message should be moved into the inbox. The action of moving to a custom list preferably has an action option selection view allowing a user to select or create a new list to which the message will be added. Preferably the actions are fixed to set gestures. Alternatively actions may be updated based on the currently viewed message stream. The gesture state to action mapping is preferably re indexed to correspond to the navigational displacement. For example the actions may rotate so that a swiping direction always maps to the cognitive mapping of the navigational location of a particular list. In one implementation navigational order is list streams reminder stream inbox stream archive stream and trash stream. When in the inbox a short swipe to the left is the reminder action towards the reminder stream one to the left a long swipe to the left is the list sorting action towards the list streams two to the left a short swipe to the right is the archive action towards the archive stream one to the right and a long swipe to the right is the delete action towards the trash stream two to the right . If the user navigates to the archive stream the actions are rotated or re indexed such that a short swipe to the left is the add to inbox action towards the inbox stream one to the left a long swipe is the reminder action towards the reminder stream two to the left and a short or long swipe to the right is the delete action towards the only stream to the right . When viewing other streams the actions can be re indexed in a similar manner.

In an exemplary use case shown in the method functions to show the manner in which the progressive gesture states can be used by a user to flexibly select different item actions. With a single swiping gesture the user can survey different action options change his mind and even engage different classes of ordered gesture states. This scenario is meant as an example representing some of the affordances of the method but the method is not limited to just this scenario. A user touches a message item initiating a gesture input. At this stage the user has not moved in a significant horizontal direction and thus the gesture state is for no action. The user then moves his point of contact to the left 165 screen units e.g. pixels to the left. The message preferably slides partially to the left. At this stage the gesture state is a first gesture state A. The corresponding action is preferably graphically displayed in the screen area revealed by the message sliding partially to the left. The user then moves his point of contact further to left of 300 screen units to the left of the initial touch point. The message graphically slides further to the left proportional to the touch displacement. Movement of 300 screen units in this example is past a gesture state threshold and the gesture state progresses to a second gesture state B. The action of the second gesture state is graphically displayed in the area to the right of the message replacing the graphical indicator of the first gesture state. The user may change his mind and move his finger to the right 135 screen units the current touch input at 150 left of the initial touch point. The message slides to the right in proportion to the updated gesture input and the gesture state progressively reverts to the first gesture state A. The user then moves the input to substantially the initial touch point. The message slides to hide any indication of a gesture state and the current gesture state is not mapped to any action. The user is in a position to cancel the gesture input. The user can then move his finger in the opposite direction 130 screen units to the right and engage another set of progressively ordered gesture states. The message slides to the right and a graphical indicator of an action of a third gesture state A is displayed in the area to the right of the slid message. The user can then move the touch input further to the right to 250 screen units and the gesture state changes to a fourth gesture state B. The user can continue changing the gesture state within the limitations of the detected gesture states. If at any point the user removes his finger the gesture input is terminated and the action of the current gesture state is preferably performed.

In one exemplary embodiment an email client application preferably provides an opt out form of email inbox management. The application allows users to quickly and intuitively sort mail so that they can respond to it at the right time and or context. Typically a user would use the application with the goal of maintaining a clean inbox. The email client application preferably configures types of email streams an inbox a later stream a list stream an archive stream and a trash.

The gesture to action mapping of the application preferably includes a long swipe to the left to move a message to a list stream as shown in a short swipe to the left to move a message to the later stream as shown in a short swipe to the right to move a message to the archive stream as shown in and a long swipe to the right to move a message to the trash as shown in . As mentioned above the stream navigation preferably corresponds to gestures to action mapping. In a navigation view such as a navigation bar at the top there is preferably a button to the far left to display a list of list streams as shown in . In the middle of the navigation view there is preferably a split button with buttons from left to right to display the later stream inbox stream and archive stream as shown in . This left to right organization of stream navigation preferably reinforces the mental model of the gesture to action mapping.

The primary email stream is the email inbox where new mail and email reminders are added. The inbox is preferably the home screen or the initial screen viewed when opening an app. Ideally the majority of email sorting will be performed from the inbox. The list stream is preferably a collection of streams for various lists. The list stream may be user created and or pre created lists. A list is preferably beneficial to a user by allowing the user to file the message so that the user can view the message at a time of his or her choosing. A list stream is preferably one of several labels categories folders tags groups or other message organization mechanisms. Sorting a message to a list stream preferably sorts the message into at least one specified list stream. The user preferably sets an action option selection to specify the destination list of a message as shown in . The later stream is preferably a conditional stream for messages that will be conditionally added to the inbox a subsequent time. When adding a message to a later stream a user preferably makes an action option selection specifying when or according to what condition the message should be added to the inbox as shown in . The later stream preferably helps users by deferring a response to an email until an appropriate time. The archive stream is a general stream for messages that no longer need a response. The trash is preferably a message stream for messages to be deleted.

In alternative exemplary embodiment an email client application preferably provides an opt in form of email inbox management. The application allows users to quickly and intuitively sort mail so that they can mark messages that need a response. Typically a user would use the application with the goal of marking all messages requiring a response. This variation is substantially similar to the one described above except that in place of a later stream a marked stream preferably allows messages to be marked with specific labels such as a star an important symbol respond to symbol or any suitable label. Additionally the marked stream may be used in combination with the first exemplary embodiment described above or with any suitable alternative variations.

As shown in an alternative method S description of the above method for organizing messages of a preferred embodiment can include providing a set of navigation views with an active navigation view S at message items of a navigation view detecting an ordered set of gesture states mapped to an actions that correspond to the order of navigation views S transitioning the active navigation view S and re indexing the ordered set of detected gesture states S. The method functions to emphasize the navigation driven aspect of the detected gesture states. The tracking of gesture input and actions applied to messages are preferably substantially similar to the method described above. The navigation views are preferably modal views of different content collections. In other words only a single navigation view or pane is active at a time and the other navigation views are graphically simulated to exist in set positions relative to the other navigation views. The simulated positions are preferably reinforced by graphical animations between the navigation views. Accessing the navigation views can be achieved in any suitable manner. In one variation a series of navigation buttons in a navigation bar may provide ways to access the views. As an example the navigation views may include a list view to access a collection of list views a later view an inbox view an archived view and a trash view. When a new navigation view is selected for activation an animation preferably simulates either a right or left animation corresponding to a set order of the navigation views. The order of the navigation views additionally corresponds to the index of actions within the gesture state options. As described above four possible gesture states may be configured for detection not including the neutral gesture state of canceling a gesture input . The mapping of gesture states to actions is remapped to reflect the position within the set of navigation views. The navigation views and the corresponding action mapping are preferably not cyclical. For example the trash view may be the navigation view to the far right with the archive view directly to the left and the inbox view two views to the left. When viewing the trash view swipes to the left preferably move the message to the archive for a first state or to the inbox in a progressively acceded second gesture state . Swiping to the right may not invoke any action. In one variation swiping to the right invokes a deletion action for that message as opposed to just moving it to the trash . In some variations the navigation views may occupy the same navigational order or index. For example the list view and the archive view may both be treated as being one to the left of the inbox view. As another alternative when at the end of a set of navigational views e.g. the far left navigation view a gesture state which would otherwise be blank can be set to another defined action such as a common action like archive .

As shown in a method S for interacting with digital content of a preferred embodiment can include detecting an initiated gesture for at least one digital content item S tracking gesture state S identifying action of a current gesture state S and applying an action on the digital content item according to a final gesture state S. The method S is preferably substantially similar to the methods above but implemented in other contexts other than messaging applications. Blocks S and are preferably substantially similar to blocks S S S and S except as applied to other forms of digital content. Similarly the method S is preferably implemented by a system substantially similar to the above system. The method S may alternatively be implemented as an interactive service of an operating system or some suitable platform as opposed to within a self contained application environment. The digital content can be media file items photos video music and the like files of a file system notifications or alerts from various sources and or any suitable digital content. In the context of messages and specifically email the actions are preferably sorting organizing related actions which can be applied to digital content in a similar manner. Alternative actions for digital content can include sharing content synchronizing the content between different devices or people queuing the digital content performing a transformation on the content altering meta data to the content. Some of these actions may include displaying a secondary view with action options similar to the variations of the later and list actions above . For example a sharing action may initially trigger a secondary view with a list of different social media sites and communication channels to share the content over. The secondary view for selecting options of the action can have any level of complexity. Transforming content can include actions such as applying an image filter to an image translating a message encrypting a message converting file format and or any suitable transformation. Altering meta data can include changing privacy settings geo tagging the content starring or labeling content and or changing meta data in any suitable manner.

The method S can include the navigation to action correspondence described for the above system and methods but the gesture tracking components can alternatively occur independent of a navigational architecture that defines the actions. In one variation the actions are preferably related to the properties and or state of the digital content item being acted upon. This may or may not include dependence on the navigational views. In one variation identifying an action mapped to the current gesture state comprises identifying an action mapped to the current gesture state based on an application navigational context. Depending on the current location or context of an application or operating system different actions may be enabled or mapped. In one variation identifying an action mapped to the current gesture state includes identifying an action mapped to the current gesture state based on a content type of the digital content item. For example a thumbnail of a picture may have different gesture to action mapping than a text document. Similarly the gesture detection can be implemented within an application for a portion of an operating system service e.g. a notification center as a universal gesture tool that can be applied to any file or defined forms of content as a tool to be leveraged by developers or implemented in any suitable environment.

Additionally the method S may include simultaneously receiving input S which functions to enable multiple users devices and or multiple digital items to receive progressive gestural input. In one variation multiple gesture inputs can be applied to items simultaneously or in overlapping time sequence. In other words translation of a gesture applied to an item is interpreted independently from gestures applied to one item. For example two items may simultaneously receive touch gesture input and based on the final gesture state both receive an action. The final gesture state may be the same gesture state but may alternatively be different final gesture states which would result in different actions being applied to the two messages. In a similar example received gesture input may overlap in time a first gesture input may be initiated for a first item. After initiating the first initiated gesture and before completing the gesture a second gesture input maybe initiated for a second item. In this way gesture inputs do not block or prevent gestures being applied to other items. This aspect may be invoked so that one user can perform several gesture inputs at once but it can similarly be applied so that multiple people can collaborate on one device.

In another variation shown in block S can be used in multi device collaboration. Where in traditional user interfaces a user may click a button and the action instantaneously happens the progressive gesture interface uses numerous visual cues that correspond to the action performed or about to be performed on an item. This aspect lends itself to real time collaboration on shared resources. The gesture input of a second user on a second device can be graphically reflected across multiple devices. In particular the sliding animation of the digital content and the gesture state graphic are indicators of what is about to happen and animating the digital content off the screen can indicate which action was committed. In one variation collaborators can even compete over the gesture state where a user can add to or subtract gesture input from a gesture input which can function to enable a tug of war interaction over the gesture state. For example while talking a user may touch a digital item and move 100 screen units to activate a first gesture state and pause while discussing. The second user may disagree with this action and tap the item and move 100 screen units in the opposite direction to cancel the action. If the second user moved 100 screen units in the same direction as the first user then a second gesture state may be engaged. Thus the method may include receiving multiple gesture inputs simultaneously.

As shown in an implementation of method S can be applied for file system related contexts. In this implementation file items e.g. file icons thumbnails or actually opened file content can be reactive to progressive gesture inputs. The file system can be a file system of a device such as a mobile device a desktop computer a remote file system a shared file system or any suitable file system or drive. There are preferably at least two gesture states and two actions but any suitable number of gesture states may be configured. In one example the gesture detection is used in a use case similar to the messages above. There are a limited number of high priority actions that correspond to different organizational issues. There can be an action to move the file similar to the list option wherein if the move action is selected the user specifies a folder or location to store the digital content item. There can be a later action to temporarily store the file elsewhere until conditionally moving the file where the user will notice the file e.g. in a new content folder . There can be an archive action to store the file in a default location. And there can be a trash action that moves the file to the trash or deletes the file. Since files may have different affordances other actions can be used. For example there may additionally or alternatively be a synchronize action. The synchronize may be used to synchronize a file between devices. Preferably a secondary view is displayed with different device location options where the file should be synchronized. In the case where the file system is a cloud based file system that synchronizes files between multiple devices the synchronize action can be used to selectively decide if the file should be kept local or if it should be uploaded and synchronized with all or some other devices. For example the file may be a very large file that only one other device will ever need access to. A user can simply use this option to set this file to only be synchronized with the device of interest. There can be a sharing option. The sharing option either activates a default sharing option or can display in a secondary view various sharing options. Sharing options can include posting to a social network email SMS messaging MMS messaging sharing through an application communication channel inviting select people to collaborate access the file or share in any suitable manner.

As one example a first gesture state may be mapped to moving the file to a set folder a second gesture state may be mapped to setting which devices the file synchronized with for an account a third gesture state may be mapped to sharing the file with at least a second user and a fourth gesture state may be mapped to archiving or deleting the file. Other alternative or additional actions may include rating the file marking the file performing actions specific to the file type and or performing any suitable file related action. One aspect of the gesture interface is that animations and graphics correspond to the actions. As an additional variation actions can be applied to folders or a selection of files as well as individual files.

As shown in an implementation of method S can be applied for media related contexts. The gesture based input can be used with media files to apply media related actions. Media files can include audio files videos files images multimedia files and or any suitable type of media file. The method may be applied to the media playing media organization media editing media browsing media marketplace and or any suitable media application. In one variation the method may be applied to a media player. Songs and videos may be displayed in a list like format. Gesture input could be applied to each of the media items. In the case of a music player application the set of actions mapped to gesture states can include actions such as add to playlist queue song share song purchase song favorite or rate the song send audio to a particular device e.g. send to TV or over Bluetooth speakers and or any suitable song related action. The actions can similarly be applied to a video player or a photo organization application.

As shown in an implementation of method S can be applied a notification center. The notification center is preferably part of an operating system of a device such as a mobile device a desktop computer a TV connected device a wearable computing device or any suitable computing device. The notification center may alternatively be part of an application. Preferably notifications appear within a list. The notifications can come from several various sources and vary in type. Notifications can include application specific alerts communication alerts error notifications reminders event updates synchronization alerts collaboration alerts and or any suitable type of notification. The gesture state to action mapping is preferably specific to the type of notification which functions to enable a user to respond to a notification in various manners. Furthermore the user may respond to a notification and perform application specific actions without opening that application. In one variation developers of applications can configure various actions for the set of gesture states detected in a notification item. Additionally or alternatively some notifications may come with a predefined gesture state to action mapping. For example an event notification may appear on the user s mobile phone. As opposed to simply selecting or swiping the notification to open up their corresponding event item the user may use various gestures to take different actions such as setting a second reminder for the event inviting another user to the event requesting directions to the event location marking the event as complete rescheduling the event and or any suitable configured event action.

As shown in the implementation of method S can be applied to computing devices with limited display area in a manner substantially similar to that of the navigation implementation. Devices with limited display area can include wearable computing devices such as a watch computing device glasses with a heads up display a small MP3 player a camera or any suitable device. With unlimited display area applications media messages information and any suitable form of content may require utilizing a majority of the screen real estate. Method S can be used to provide an intuitive interaction model without requiring user interface elements taking screen real estate away from the content. For example glasses based computing devices may include header display and a touch sensitive input sensor on at least one of the arms of the glasses. The touch sensitive input may afford gesture input on two axis a vertical axis and a horizontal axis. The first axis e.g. the vertical axis may be used to scroll through different items. The second axis e.g. horizontal axis may be used to invoke actions on the current modally displayed content. Similar to the notification implementation the method may include providing a developer interface to customize gesture state to action mapping.

As shown in a method S for interacting with digital content of a preferred embodiment can include visually displaying a set of menu options horizontally organized wherein selection of a menu option selectively sets a corresponding collection as active S setting an initial collection to the active collection S which comprises displaying the initial collection S setting at least a second and third collection to be virtually located in a horizontal direction from the initial collection S detecting a swiping gesture in a horizontal direction S and transferring the message item to a collection according to the currently active collection and the direction of the horizontal direction of the gesture S. The method functions to enable an intuitive and natural interface for sorting content. The method can have particular benefits when applied to enabling powerful and natural content sorting capabilities on a device with limited screen real estate such as a mobile device wearable computer tablet computing device or any suitable computing device. The method is preferably implemented with an application but may alternatively be applied to an operating system a notification system a multi application messaging application a website a social network a file system or any suitable environment of sorting digital content. The method preferably relies on reinforcing user heuristics of mapping collection order to gestures applied to a message. As opposed to a set of fixed gestures that provides the same action mapping across different contexts the gestures e.g. the gesture state and the sorting action are dynamically remapped to simulate pushing a message between ordered stacked or arranged collections. The method is primarily used for sorting between at least three collections but can additionally be applied to four five or any suitable number of collections. The method is substantially similar to the navigational architecture used in the system and methods above. In one variation the method is preferably facilitated by the progressive gesture method as described but may alternatively use basic gestures or any suitable gesture input technique when activating a message collection.

Step S which includes visually displaying a set of menu options horizontally organized functions to provide a navigation architecture and interface with an application. Selection of a menu option selectively sets a corresponding collection as active. The set of menu options are preferably displayed within a toolbar or navbar as actionable buttons. In one variation the menu options can be presented as grouped buttons or tabs in which only one menu option can be active at a given time. Each menu option preferably maps to one collection. In one variation a menu option can map to a set of selectable collections e.g. a collection of multiple lists . The message collections or more generally digital content collections or message streams are preferably a set of sorted message items or digital content. The message items are preferably email messages of at least one email account but can alternatively be application text messages photo messages or content video messages or content audio messages or content and or any suitable form of media content. Preferably the digital content can only exist in one message collection at a time as in a folder or categorization filing organization system but the digital content can alternatively exist within multiple collections at one time as in a labeling based filing organization system. The set of selectable collections include a left collection an initial collection and a right collection. Additional collections can additionally be used such as a far left collection and a far right collection. As shown in one preferred implementation includes the far left collection set as list collections that are selectable from a secondary interface the left collection set as a deferred message collection the initial collection set as an inbox stream the right collection set as an archive collection and the far right collection set as a trash collection. The initial collection is preferably the main central or emphasized collection but any suitable collection in the order may be emphasized. The set of collections preferably have an associated order. That order is preferably represented through the virtual positioning of the rendered views of the collections. The order preferably corresponds to the order of the menu options. Here the initial collection is preferably a centrally located collection. And the order from left to right is far left collection left collection initial collection right collection and far right collection.

Step S which includes setting an initial collection to the active collection functions to enter or navigate to one of the collections of the menu options. In one preferred instance a collection is preferably activated in response to user selection or programmatic selection of a menu option. The menu option is preferably given focus e.g. changes colors or indicates selection in any suitable manner . Each menu option is preferably used in activating a collection that will be modally displayed within the application. Herein modal display of a collection describes the manner in which the collection view is the only collection view displayed on the screen. Additional collections are preferably virtually located off the screen. Virtually located preferably describes how the management of inter collection transitions to simulate a collection panning moving or being animated from a virtual location off the screen of the device application window. Step S preferably includes displaying the activated collection S and setting non active ordered collections to a virtual location relative to the active collection S. As mentioned above the displayed activated collection is preferably modally displayed. The other collections are preferably set to a virtual location in a horizontal direction from the active collection. Setting a virtual location preferably describes setting the state of the application such that transitioning to another collection would include an animation that corresponds to the relative horizontal positioning between the original active collection and the new active collection. The animation can include panning from the original active collection to the new active collection sliding the new active collection over the original active collection sliding the old active collection away to reveal the new active collection and or performing any suitable animation transform that reflects a relative virtual location between the two collections. For example if the initial collection is active then the right collection is virtually located to the right. If the right collection is activated the initial collection is preferably animated off the screen to the left and the right collection is animated into the screen from the right. The virtual location may simulate simply direction of the order. For example transitioning to the far right collection can from the initial collection include panning from initial collection to the far right collection directly not showing right collection . In another variation a virtual displacement can be simulated. For example transitioning to the far right collection can from the initial collection include panning from initial collection to the right collection to the far right collection.

In one preferred implementation when the menu option of the initial collection is selected the initial collection is set to the active collection. Setting the initial collection to active includes displaying the initial collection setting the left collection to be virtually located to the left of the initial collection and setting the right collection to be virtually located to the right of the initial collection. When the menu option of the left collection is selected the left collection is set to the active collection which includes displaying the left collection and setting the initial collection to be virtually located to the right of the initial collection. Upon selection of the right collection setting the right collection to the active collection which comprises displaying the right collection and setting the initial collection to be virtually located to the left of the initial collection. Such an implementation can be similarly expanded for more than three collections.

Step S which includes detecting a swiping gesture in a horizontal direction functions to detect a user input that indicates user intent to sort a message or messages. The gesture is preferably a horizontal gesture and the horizontal axis is preferably perpendicular to the axis of scrolling the active collection. Detection of a swiping gesture is preferably substantially similar to the gesture detection described above. Alternatively other forms of input gestures can be detected. In one implementation basic right or left sliding gestures are preferably detected. The direction of gesture detection is preferably parallel or substantially aligned with the horizontal axis of the virtually ordered collections. In this variation detection of a gesture includes detecting a swipe e.g. an input event with some displacement between input start and end and the direction of the gesture. In another implementation there may be multiple collections virtually located in the same direction relative to the active collection. For example the right collection and the far right collection are both virtually located to the right of the initial collection. In this variation the magnitude speed or other properties of the input may be collected or measured to determine the sorting destination of the item. Preferably messages are acted on individually but multiple messages or all messages may be sorted simultaneously.

Step S which includes transferring the message item to a collection according to the currently active collection and the direction of the horizontal direction of the gesture functions to contextually apply sorting or content moving actions on a message. Transferring the message item to a collection preferably removes the message from the current collection and adds the message to the selected collection. This may include altering a collection parameter of the message altering a message list of a collection transferring the message item data to a destination of the collection. In one application the collections can be different device locations and the sorting interface is used to manage sharing of digital content between different devices people. Within an email application transferring preferably includes changing the folder or label of the message to the new collection. As mentioned above the message item preferably exists in only one collection at any one time though there may be some overlap while transferring the message but a message item can alternatively coexist in multiple collections. For example if the collections are music playlists or file tags the content can preferably remain in the current collection and be copied to the new collection or add a tag reference to the new collection. Transferring preferably includes initially selecting a sorting or destination option that corresponds the message collection that is virtually positioned in the horizontal direction relative to the active message collection and then moving sorting the message to the selected message collection. In some variations prior to moving the message a secondary option interface may be displayed to modify augment or set the manner in which the message is moved. For example if the collection is a set of collections a list of individual collections can be displayed so that a user can specify a specific collection within the set of collections.

The transferring action is preferably dependent on at least the currently active collection and the direction of the gesture. Additionally magnitude of gesture displacement or other properties can be used. The gesture state to action mapping can additionally be over ridden such that customized behavior can be selectively enforced for particular contexts. The gestures detected can be identical or corresponding gesture but depending on which collection is active the message item is transferred to a different collection. When the initial message collection is active and upon detection of the swipe gesture in a right horizontal direction the message item is transferred the right collection. When the initial message collection is active and upon detection of the swipe gesture in a left horizontal direction the message item is transferred the left collection. When the left collection is active and upon detection of the swipe gesture in a right horizontal direction the message item is transferred to the initial collection. When the right collection is active and upon detection of the swipe gesture in a left horizontal direction the message item is transferred to the initial collection.

As another example of remapping when there are more than three collections when the right collection is active and upon detection of the swipe gesture in a right horizontal direction transferring the message item to the far right collection occurs. When combined with gesture displacement magnitude detection this can be further expanded so that a gesture can move a message not just to adjacent collections but to collections removed by one or more places. For example when the initial message collection is active and upon detection of the swipe gesture in a right horizontal direction the message item is transferred the right collection if the displacement is less than a defined magnitude and the message item is transferred to the far right collection if greater than the defined magnitude.

An alternative embodiment preferably implements the above methods in a computer readable medium storing computer readable instructions. The instructions are preferably executed by computer executable components preferably integrated with a gesture detection engine. The computer readable medium may be stored on any suitable computer readable media such as RAMs ROMs flash memory EEPROMs optical devices CD or DVD hard drives floppy drives or any suitable device. The computer executable component is preferably a processor but the instructions may alternatively or additionally be executed by any suitable dedicated hardware device.

As a person skilled in the art will recognize from the previous detailed description and from the figures and claims modifications and changes can be made to the preferred embodiments of the invention without departing from the scope of this invention defined in the following claims.

