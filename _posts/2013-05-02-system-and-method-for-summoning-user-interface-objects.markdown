---

title: System and method for summoning user interface objects
abstract: Provided is a system and method for summoning user interface object(s) of a display to a gesture position of a user. In a pressure sensitive display embodiment, a user maintains a convenient touch position to the display, performs a summon gesture, and user interface object(s) are automatically moved to the user's touch position as requested. When a summon gesture is recognized, a user interface object, or point or interest thereof, automatically transitions to a desired position where the gesture was recognized. Objects can transition in a variety of manners. Also, a magnetic mode can be activated for virtually magnetizing objects of interest to a user's position, for example as the user touches various places on the display. A user's configurations can be stored into a cloud system for convenient access and use at a plurality of different data processing system user interfaces.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09134880&OS=09134880&RS=09134880
owner: 
number: 09134880
owner_city: 
owner_country: 
publication_date: 20130502
---
This application is a divisional application of application Ser. No. 13 052 095 filed Mar. 20 2011 and entitled System and Method for Summoning User Interface Objects . The entire specification from the aforementioned application Ser. No. 13 052 095 is included herein in original form except for modifications resulting from a Preliminary Amendment filed Mar. 24 2011 to modify minor errors in six paragraphs and an Amendment B filed Mar. 15 2013 to shorten the abstract.

The present disclosure relates generally to data processing system graphical user interfaces e.g. touch screen interface e.g. using gestures and more particularly to summoning user interface objects to a convenient position of a user of the user interface.

Touch interfaces are becoming commonplace in everything from mobile data processing systems to large display touch screen interfaces. A movement away from blackboards whiteboards and drawing boards to large data processing system touch screen displays is underway. In fact many schools of the future may incorporate large touch screen display interfaces for instructing students.

U.S. Pat. No. 5 621 880 Method and apparatus for providing contextual navigation to historical data Johnson provides automatic focusing of a window which contains a user specified search criteria at some time in history however objects are not summoned to the user s most convenient input location in the user interface such as the display location where a gesture is entered for object search criteria. The present disclosure is needed for bringing user interface objects to a user in particular for very large displays rather than forcing a user to physically navigate to a user interface object in order to interface with it. Similarly U.S. Pat. No. 5 483 633 Method and apparatus for surfacing an object based on forthcoming criteria Johnson provides automatic surfacing of a user interface object which will contain a user specified search criteria at some time in the future however objects are not summoned to the user s most convenient input location in the user interface such as the display location where a gesture is entered for object search criteria.

Perceptive Pixel s Multi touch Collaboration Wall embodies a large pressure sensitive display with advanced multi touch interfaces across a variety of industries. Outstanding display performance characteristics and display driver interfaces supporting data processing system software enables many different applications for use. Such displays can be manufactured quite large depending on the customers or applications. New methods are required for navigating large touch screen interfaces in particular when a user may have to walk or physically move to different positions to interact with sought user interface objects. Art involved in such displays includes publications 20100302210 Touch Sensing Han et al 20100177060 Touch Sensitive Display Han 20090256857 Methods Of Interfacing With Multi Input Devices And Multi Input Display Systems Employing Interfacing Techniques Davidson et al 20080180404 Methods Of Interfacing With Multi Point Input Devices And Multi Point Input Systems Employing Interfacing Techniques Han et al 20080029691 Multi Touch Sensing Display Through Frustrated Total Internal Reflection Han and 20060086896 Multi touch sensing light emitting diode display and method for using the same Han . U.S. Pat. No. 7 598 949 Multi touch sensing light emitting diode display and method for using the same Han is also relevant.

Fingerworks was a gesture recognition company innovating multi touch products. Fingerworks was acquired by Apple Inc. Art involved includes publications 20060238521 20060238522 Identifying Contacts On A Touch Surface Westerman et al 20060238520 User Interface Gestures Westerman et al and 20060238518 Touch Surface Westerman et al . Relevant patents include U.S. Pat. No. 7 705 830 System and method for packing multitouch gestures onto a hand Westerman et al U.S. Pat. No. 7 656 394 User interface gestures Westerman et al U.S. Pat. No. 7 764 274 Capacitive sensing arrangement Westerman et al U.S. Pat. No. 7 782 307 Maintaining activity after contact liftoff or touchdown Westerman et al U.S. Pat. No. 7 619 618 Identifying contacts on a touch surface Westerman et al and U.S. Pat. Nos. 7 339 580 6 888 536 6 323 846 Method and apparatus for integrating manual input Westerman et al .

Other touch screen and gesture related art includes publication 20050210419 Gesture control system Kela et al and U.S. Pat. No. 7 840 912 Multi touch gesture dictionary Elias et al U.S. Pat. No. 7 728 821 Touch detecting interactive display Hillis et al and U.S. Pat. No. 5 644 628 telecommunications terminal interface for control by predetermined gestures Schwarzer et al .

Handwriting recognition was made popular on tablet notebook computers as well as some personal Digital Assistance PDA devices through recognition of stylus strokes on a pressure sensitive detection surface. Relevant art includes publications 20050219226 Apparatus and method for handwriting recognition Liu et al 20030195976 Method and system for creating and sending handwritten or handdrawn messages Shiigi and 20030063067 Real time handwritten communication system Chuang . Relevant patents include U.S. Pat. No. 7 587 087 On line handwriting recognition Nurmi U.S. Pat. No. 7 580 029 Apparatus and method for handwriting recognition Liu et al and U.S. Pat. No. 6 731 803 Points based handwriting recognition system Aharonson et al . Finger driven interfaces such as those above disclosed by Westerman et al incorporate similar methods for handwriting recognition with touch surface gestures.

Synaptics Inc. has also been involved in touch interface technology. Art includes U.S. Pat. Nos. 6 414 671 6 380 931 6 028 271 5 880 411 and 5 543 591 Object position detector with edge motion feature and gesture recognition Gillespie et al .

Those skilled in the art recognize that users can use advanced touch gestures at any display location to interface with the associated data processing system s and there are a variety of hardware and software configurations enabling gestures to drive a user interface. In a small touch display it may be desirable to quickly find or focus a user interface object which is hidden or overlaid by other objects. In a large touch display interface it may be desirable to find user interface objects without physically moving to them to access or find them in particular when the physical display is considerably large.

 BumpTop is a desktop environment that simulates the normal behavior and physical properties of a real world desk. Physics is applied to various gestures for bumping and tossing objects for realistic behavior and automatic tools enhance selecting and organizing things. BumpTop was initially targeted for stylus interaction however multi touch gestures have been incorporated. The BumpTop company was acquired by Google. Real Desktop is also a product for bringing more of a desktop reality to the traditional two dimensional computer interface desktop. It turns your desktop into a room and you organize your files folders and desktop shortcuts as tiles in that room. You can drag and drop those tiles or throw them into each other and watch as they bounce around. The real world metaphor implementations can cause burying documents and information just like a disorganized desk in the real world. Methods for improving the usability of some disorganized users may be needed.

User interface object s of a display are conveniently summoned to a user s gesture position i.e. user s display location where gesture is input in a user interface. In a pressure sensitive display embodiment a user performs a gesture the gesture is recognized and user interface object s are automatically moved to the user s input position as requested. In a three dimensional imaging display embodiment e.g. U.S. Pat. No. 7 881 901 Method and apparatus for holographic user interface communication Fein et al a user performs a gesture the gesture is recognized and user interface object s of the three dimensional navigable environment are automatically moved to the user s gesture position as requested. For simplicity the term cursor shall be used herein to represent the point in a user interface where a user directs the user interface whether it is by gesture stylus pointing device e.g. mouse or any other method for user input.

A summon gesture can be static or dynamic. Static gestures are predefined and each is recognized for performing a particular type of command e.g. summon command . Static gestures may be well known gestures recognized by certain processing or as configured and saved to a dictionary for subsequent use from a library such as described by U.S. Pat. No. 7 840 912 Multi touch gesture dictionary Elias et al . A dynamic gesture is determined at the time of gesture specification and may take on so many different definitions that a gesture dictionary would not be practical. Dynamic gestures can have a seemingly infinite number of meanings for example as recognized for a handwriting command to specify object search criteria. A static and dynamic gesture is referred to as a written gesture. For example a written gesture may contain handwriting which is converted to a text string i.e. the search criteria for comparing to text of user interface objects. When a summon gesture may be static or dynamic is recognized a user interface object or point or interest thereof automatically transitions to a desired position display location where the gesture was recognized. Configurations or the gesture itself govern how the object s transition to the user s position. An object s display location and orientation prior to recognizing the summon gesture is referred to as an original position and an object s display location and orientation after being summoned is referred to as a summoned position. An appropriate display coordinate system is preferably implemented to distinguish between the minimum granulation of addressing a display location e.g. a pixel so as to determine with the utmost accuracy where on the display an original position summoned position and specific display location resides in the particular display embodiment. An original position is distinct from a summoned position most of the time. Objects can transition by a number of methods including 

For cases where a plurality of objects are summoned a scrollable informative list user interface object can result so the user may manipulate results and then summon one or more objects from the list. Optionally summoning a plurality of objects can result in summoning the objects together in a group in a configurable manner including 

Also a magnetic mode can be activated for virtually magnetizing objects of interest to a user s position for example as the user touches various places on a touch sensitive display. Objects of interest in the current context of the gesture or cursor are automatically gravitated i.e. scaled moved transitioned etc to the gesture or cursor position.

Significant effort may be invested in making user interface configurations. It is therefore important to make a user s configurations available whenever needed for example at a similar data processing system display in a different office building or different country. The user s data processing system configurations e.g. user interface gestures are optionally stored into the cloud for convenient access and use at a plurality of different data processing system user interfaces e.g. in different locations .

A primary advantage herein is to minimize user manipulation of a user interface for accomplishing a result. A user interface is made more convenient by bringing a user interface object to the user rather than requiring the user to find move to and act on a user interface object. The user interface is made to work more for anticipating what a user wants to do in a user interface. If the user decides the object s were not of interest after being summoned to the user the objects can conveniently be returned to their original position s e.g. cancel undo request or to other position s desired by the user.

It is an advantage to summon objects regardless of the underlying type of user interface environment and or the type of cursor used for driving the user interface. Processing is disclosed for being embodied in different user interface environments. The system and method disclosed can be used in two dimensional user interfaces e.g. touch screen gesture interface or pointing device interface or three dimensional user interfaces e.g. holographic gesture interface or pointing device holographic interface . The system and method disclosed can be used for any type of cursor involved including gestures pointing devices voice driven cursor position user s touch position user s input tool cursor position e.g. stylus user manipulated cursor position e.g. mouse cursor or any other user interface input location position.

It is an advantage to make moving user interface objects in small or large display systems more convenient. In a small display overlaid objects can quickly be found without navigating to find them. In a larger display a user need not move to an object in order to interface with it. For example a multi monitor system supporting a plurality of monitors for a single desktop is supported. In one embodiment a data processing system adapter contains a plurality of ports for plugging in a plurality of monitors which can be used to navigate a single desktop. Similarly a data processing system adapter contains a plurality of ports for plugging in a plurality of monitors which can be used to navigate multiple desktops. Also a multi station system supporting a plurality of users to a single display system is supported. In one embodiment a plurality of cursors are monitored simultaneously for carrying out operations of the present disclosure for example in multi user systems including those of Han et al mentioned above.

Another advantage is in anticipating what a user wants to do in a user interface and providing a proposed result for consideration. For example objects can magnetically transition toward the user s input position cursor position for indicating to the user likelihood of being of interest to the user. As the user s cursor position is detected within the display interface objects of interest gravitate toward the cursor position. The user can conveniently confirm summoning the objects.

Yet another advantage is in summoning user interface object s by any conceivable search criteria. For example hand written gestures in a multi touch touch screen interface can be used to specify any desired search criteria for finding objects of interest.

A further advantage is allowing the user to store his configurations to a service e.g. cloud platform for later recalling them at another data processing system for user interface control. Consider a large multi country company that has deployed large gesture user interface displays in meeting rooms around the world. The present disclosure enables a user to store configurations for convenient access when needed to any of those displays at different locations. Also configurations are stored in a universal format which can be translated appropriately to different display systems so that every display need not be exactly the same. The user may store any useful data processing system configurations which can be reused when needed at any data processing system the user encounters during his travels.

Yet another advantage is summoning user interface object s to a current user interface input position based on a search criteria for a particular time such as CURRENT search criteria matched against currently displayed user interface objects CURRENT WITH HISTORY search criteria matched against information to have been present at some time in the past for currently displayed user interface objects PAST search criteria matched against user interface objects which are not currently displayed i.e. active at some point in the past FUTURE search criteria matched against newly displayed user interface objects and SPECIFIED search criteria specified by a user e.g. dynamic gesture provides date time range for sought user interface objects that may have contained a search criteria.

A further advantage is summoning user interface object s to a current user interface input position using different languages. Single byte character code sets and double byte character code sets are supported so that a user can summon based on a particular language Chinese French German etc contained in a user interface object. Also a user can change between languages for summon search specifications to summon only those objects which contain the same language or any objects which contain a different language that criteria has been translated for and produced a matching result. The present disclosure is fully National Language Support NLS enabled.

Further features and advantages of the disclosure as well as the structure and operation of various embodiments of the disclosure are described in detail below with reference to the accompanying drawings. In the drawings like reference numbers generally indicate identical functionally similar and or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit s in the corresponding reference number. None of the drawings discussions or materials herein is to be interpreted as limiting to a particular embodiment. The broadest interpretation is intended. Other embodiments accomplishing same functionality are within the spirit and scope of this disclosure. It should be understood that information is presented by example and many embodiments exist without departing from the spirit and scope of this disclosure.

With reference now to detail of the drawings the present disclosure is described. Obvious error handling is omitted from the flowcharts in order to focus on key aspects. A thread synchronization scheme e.g. semaphore use is assumed where appropriate. Flowchart processing is intended to be interpreted in the broadest sense by example and not for limiting methods of accomplishing the same functionality. Disclosed user interface processing and or screenshots are also preferred embodiment examples that can be implemented in various ways without departing from the spirit and scope of this disclosure. Alternative user interfaces since this disclosure is not to be limiting will use similar mechanisms but may use different mechanisms without departing from the spirit and scope of this disclosure. Novel features disclosed herein need not be provided as all or none. Certain features may be isolated in some embodiments or may appear as any subset of features and functionality in other embodiments.

When the user specifies an object search criteria on display A which matches a criteria found only in window window is instantly and automatically moved to the user s input position. The user did not have to physically move to the objects try to find the search criteria and then drag out window to begin interfacing with it. Summon processing determined which object the user was looking for and moved the object from its original position to the user s last input position referred to as the summoned position as shown in display . A variety of configurations or embodiments can be incorporated for how the object should be positioned with respect to the summoned position e.g. which e.g. x y coordinates to use at the summoned position when multiple coordinates are detected as being simultaneous last points of input and how the newly position object s should arrive at the summoned e.g. x y position e.g. object centered top left hand corner scaled in size etc . A variety of configurations or embodiments can be incorporated for how the object transitions from the original position to the summoned position as discussed below. In one embodiment summoned position configuration is indicated in a TR e.g. a field of fields for example to indicate what point of a summoned object coincides with which point of the last detected user input location on the display i.e. the summoned position . An alternate embodiment may support positioning criteria being specified or assumed by the gesture itself.

Similarly when the user performs a summon gesture at display A display C may result if the search criteria determines that document is being sought by the user from the heap . Perhaps the class of user interface object indicates to uniquely transition the document to the user in a different manner than if the object class of window was found for example as positioning the lower right hand corner of the document in portrait view mode to the summoned position. Similarly when the user performs a summon gesture at display A display D may result if the search criteria determines that icons and are being sought by the user. Perhaps the class of user interface objects indicate to uniquely transition the icons to the user in a different manner than other object classes. Similarly when the user performs a summon gesture at display A display E may result if the user s summon gesture search criteria determines that there is an associated portion of data e.g. linked file exploded view containing data hyperlink to web page etc to the video . Any of a variety of associated data may be searched and then instantly provided to the summoned position of the user in an appropriate form may be completely different graphic representation than object being summoned depending on the class of data type of data location of data or other characteristic of the associated data. Similarly when the user performs a summon gesture at display A display F may result if the search criteria determines that there is a plurality of objects which match the summon gesture search criteria and an informative scrollable list is best displayed at the summoned position so the user can in turn decide which object s are to be summoned.

With reference now to display G depicts the user navigating a large map display. In one embodiment the entire display provides a single window into manipulating the map. In another embodiment the map is manipulated within the context of a window on the display G. The user can perform a summon gesture anywhere on the display for searching for criteria that is matched to data associated with the map for example resulting in display H. For example the user may have specified to summon an address on the map by hand writing the address. Display H instantly results e.g. when unique address portion recognized thereby preventing user specification of entire address e.g. unique street number s by automatically panning the building in the map with the matching address to the summoned position. Furthermore depending on data which is associated to the map there may be a viewing angle change a zoom out zoom in axis rotation or other graphical manipulation which should be performed in order to transition properly to the summoned position.

With reference now to display I depicts the user navigating a large map display. In one embodiment the entire display provides a single window into manipulating the map. In another embodiment the map is manipulated within the context of a window on the display I. The user can perform a summon gesture anywhere on the display for searching for criteria that is matched to data associated to the map for example resulting in display J. For example the user may have specified to summon an exploded view e.g. a different graphic representation of an address on the map by hand writing the address. Display J instantly results e.g. when unique address portion recognized thereby preventing user specification of entire address e.g. unique street number s by automatically providing an exploded view. In one example the user specifically gestured for the exploded view to transition to the summoned position. In another example the associated data to the map was configured for producing an exploded view in anticipation of what was best for the user when he specified such a search criteria.

With reference now to display K depicts the user entering a gesture to display K for a magnetic mode. The magnetic mode magnetizes objects with a matching search criteria so that every place a user subsequently touches the display or interacts with the display such as in a 3D holographic embodiment all objects matching the search criteria transition toward the current cursor e.g. touch position for a configurable percentage of distance in a configured transition manner e.g. may also scale e.g. larger over distance . This allows the user to be detected at different display positions while gravitating objects which match a search criteria toward the active touch position without moving objects fully to a summoned position. When the user is not detected at a position the object s return to their original positions. Preferably objects transition in a linear progression toward the summoned location. However a variety of methods for transitioning may be configured. Thus display L depicts the user touching a portion of the display after entering magnetic mode and objects satisfying the search criteria gravitate toward the user s position detected e.g. field set to 50 . Removing touch from display L results in the objects returning to their original positions.

The data processing system includes a display device interface for driving a connected user interface embodiment e.g. display . In a preferred embodiment a user interface embodiment display has at least one sensitive display surface for user input and at least one display device control interface for controlling input and or output to the display device. User interface embodiment may include a plurality of distinct display devices to accomplish a user interface embodiment . Display device interface may include a plurality of device interfaces for accomplishing a user interface embodiment . Two dimensional and three dimensional display embodiments may be supported. User interface embodiment provides display means to data processing system for example Liquid Crystal Displays LCDs Light Emitting Diode LED displays Electroluminescent EL displays customized Color Plasma Displays CPDs customized Flat Panel Displays FPDs conventional RGB monitors any of the displays of art discussed above or the like. User interface embodiment may further provide user input detection means for example with a touch sensitive surface of the display or holographic position detection within a 3D image generated. Thus user input and presentation output may be provided via the display means.

The data processing system may further include one or more distinct input peripheral interface s to input devices such as a keyboard keypad Personal Digital Assistant PDA writing implements touch interfaces mouse voice interface or the like. User input user input user events and user actions used interchangeably to the data processing system are inputs accepted by the input peripheral interface s or by interface described above. Input peripheral interface s may provide user input detection means depending on the data processing embodiment or configurations thereof. The data processing system may still further include one or more output peripheral interface s to output devices such as a printer facsimile device or the like. Output peripherals may also be available via an appropriate interface.

Data processing system can include communications interface s for communicating to an other data processing system via analog signal waves digital signal waves infrared proximity copper wire optical fiber other wave spectrums or any reasonable communication medium. There may be multiple communications interfaces e.g. cellular connectivity 802.x etc . Other data processing system may be a service for maintaining universal configurations as discussed with .

Data processing system programs also called control logic or processing code may be completely inherent in the processor s being a customized semiconductor or may be stored in main memory for execution by processor s as the result of a read only memory ROM load not shown or may be loaded from a secondary storage device into main memory for execution by processor s . Such programs when executed enable the data processing system to perform features of the present disclosure as discussed herein. Accordingly such data processing system programs represent controllers of the data processing system.

In some embodiments the disclosure is directed to a control logic program product comprising at least one processor having control logic software firmware hardware microcode stored therein. The control logic when executed by processor s causes the processor s to provide functions of the disclosure as described herein. In another embodiment this disclosure is implemented primarily in hardware for example using a prefabricated component state machine or multiple state machines in a semiconductor element such as a processor .

The different embodiments for providing control logic processor execution processing code executable code semiconductor processing software hardware combinations thereof or the like provide processing means for the present disclosure for example as described by flowcharts.

Those skilled in the art will appreciate various modifications to the data processing system without departing from the spirit and scope of this disclosure. A data processing system preferably has capability for many threads of simultaneous processing which provide control logic and or processing. These threads can be embodied as time sliced threads of processing on a single hardware processor multiple processors multi core processors Digital Signal Processors DSPs or the like or combinations thereof. Such multi threaded processing can concurrently serve large numbers of concurrent tasks. Concurrent processing may be provided with distinct hardware processing and or as appropriate software driven time sliced thread processing. Those skilled in the art recognize that having multiple threads of execution may be accomplished in different ways in some embodiments. This disclosure strives to deploy software to readily available hardware configurations but disclosed software can be deployed as burned in microcode to new hardware.

Data processing aspects of drawings flowcharts are preferably multi threaded so that applicable data processing systems are interfaced with in a timely and optimal manner. Data processing system may also include its own clock mechanism not shown if not an interface to an atomic clock or other clock mechanism to ensure an appropriately accurate measurement of time in order to appropriately carry out time related processing.

Further provided to data processing may be one or more math coprocessor s for providing a set of interfaces for very fast mathematical calculations. Those skilled in the art appreciate that optimal mathematical calculation e.g. floating point speeds are best accomplished in an interfaced customized hardware component. Graphical coordinate system calculations can benefit from such performance.

If block determines the user entered a static summon gesture at block then block sets criteria data to the gesture meaning or function block invokes summon action processing of with criteria as a parameter and processing continues back to block . Block also sets criteria with the summoned position information to know where to summon object s . In some embodiments criteria deduced from the gesture may also specify how to transition the object e.g. data of . If block determines the user did not enter a static summon gesture then processing continues to block . Static gestures are gestures with an assigned meaning function perhaps maintained to a library of gestures for a data processing system so that a different meaning function can be assigned by an administrator. Static gestures may be assigned with a macro an operating system command or some defined set of processing. A static summon gesture is a static gesture with an assigned meaning function for summoning user interface object s .

If block determines the user entered a dynamic summon gesture at block then block continues to recognize the remainder of the gesture for determining the meaning function. For example block detects the user s handwriting to determine a search criteria for summoning user interface object s or detects further gesture manipulations in real time in order to determine the search criteria. When the criteria is recognized or an error was detected or a reasonable timeout occurred e.g. lack of touch recognition for not recognizing the search criteria processing continues to block . If block determines the entire dynamic summon gesture was recognized processing continues to block for processing already described for setting user interface object s search criteria otherwise processing continues to block where the user is notified with an error that the gesture was invalid or not recognized. Block provides any reasonable audio and or visual notification before processing continues back to block . Some embodiments may not inform the user of an error e.g. return directly to block processing and some embodiments may require the user to acknowledge the error. If block determines the user did not enter a dynamic summon gesture then processing continues to block . A dynamic summon gesture is similar to a static summon gesture except the dynamic summon gesture is treated differently by having the data processing system anticipate additional information entered by the user as part of the gesture for providing further assigned meaning function. For example as part of dynamic summon gesture specification determined at block the user may provide search criteria specifications including decipherable gesture hand written textual graphical or predefined gesture meaning information. Alternate embodiments may not require recognizing enough of the gesture at block to know it is a dynamic summon gesture before monitoring for additional user specification at block e.g. dynamic portion of gesture may be provided as a prefix or as the gesture entirely rather than as a suffix to recognizing a dynamic gesture is being specified . Full National Language Support NLS is to be supported in dynamic summon gesture specifications so that a user can search for user interface object s by 

If block determines the user wanted to modify a data processing system configuration at block e.g. a user interface control configuration then processing continues to block . If block determines the user wants to configure a gesture e.g. static summon gesture or dynamic summon gesture then block interfaces with the user for gesture configuration before processing continues back to block . A user may create alter or delete gestures at block . Some embodiments will authenticate the user prior to allowing block processing to ensure the user is an authorized gesture administrator. At block a user may redefine some common dynamic summon gestures to be static summon gestures by defining all criteria including what was previously specified in real time e.g. at block as part of the static summon gesture meaning function for ready use criteria specification at block . Very complex dynamic summon gestures can be made static so that all criteria is known at the time of gesture recognition at block . For example the gesture for recognition is stored along with textual search criteria e.g. a text string for searching user interface objects i.e. this prevents the user from having to handwrite the textual search criteria every time to perform the search . If block determines the user wants to modify another type of configuration then block interfaces with the user for configuration modification before processing continues back to block . A user may create alter or delete other data processing system configurations at block . Some embodiments will authenticate the user prior to allowing block processing to ensure the user is an authorized administrator. Configurations preferably initialized with a reasonable default which can be made at block include 

If block determines the user did not want to modify configuration data then processing continues to block .

If block determines the user wanted to get universal configurations at block then block determines display criteria e.g. user interface type s situational location of display calendar entry for date time of user making request at data processing system of display type of meeting or presentation detected or any other determined condition for the user being at the data processing system of block authenticates the user to a remote service and processing continues to block . Different block embodiments may use previously provided user credentials assume some credentials or require the user to perform a login. If block determines the service could not be successfully accessed processing continues to block for providing an error to the user in a similar manner as described above otherwise block continues to block where the remote service is accessed for configurations applicable to the current data processing system of as determined by block display criteria block where the user may qualify suggestions with specific configurations to retrieve block for retrieving the configurations to the data processing system and saving locally for subsequent in effect use and then back to block . If block determines the user did not want to get universal configurations then processing continues to block .

If block determines the user wanted to save universal configurations at block then block determines display criteria e.g. user interface type s situational location of display calendar entry for date time of user making request at data processing system of display type of meeting or presentation detected or any other determined condition for the user being at the data processing system of block accesses configurations of the data processing system that may be saved block authenticates the user to a remote service and processing continues to block . Different block embodiments may use previously provided user credentials assume some credentials or require the user to perform a login. If block determines the service could not be successfully accessed processing continues to block for providing an error to the user in a similar manner as described above otherwise block continues to block where the user may qualify specific configurations to be saved and the display criteria to be saved with those configurations for best qualifying future downloads block for saving the configurations of the data processing system to the remote service authenticated at block and then back to block . If block determines the user did not want to save universal configurations then processing continues to block .

If block determines the user requested to cancel i.e. undo the last user interface object s summon request then block performs rollback processing which results in returning any objects to their original position s which were last summoned. Preferably the cancellation request is performed with a static gesture in a touch user interface embodiment. Block effectively does an undo of the last performed summoning action. Blocks and enable the ability to perform the rollback. Different rollback embodiments may use transition information in reverse e.g. transition backwards or instantly return the object s to their original position s . Block may destroy a list produced at block terminate application s started at block or return object s to their original position s which were transitioned by . Block appropriately handles errors for example those caused by user interface navigation subsequent to the last summoning action. An expiration time or event may be implemented for the ability to perform a rollback. Block continues back to block .

A user at the data processing system can save or retrieve configurations e.g. gestures or any other configuration so as to prevent having to recreate or modify configurations at every data processing system he wants to interface with. Configurations can be maintained at a single data processing system and then made available to other data processing systems. For example the user at data processing system saves his configurations to the cloud i.e. remote service in the United States over a communications connection and later accesses those configurations at data processing system Y in Germany over a connection . The user may make changes to configurations at data processing system Y which can be saved to the cloud for accessing at different data processing system Z over connection . Display criteria determined at blocks and help make certain configurations dependent on conditions of particular data processing systems. Data processing systems Y and Z may have identical user interfaces or may have different user interfaces. Universal configurations are stored in a universal format and converted appropriately using display criteria determined at blocks and . Universal configurations enable a user to make a configuration one time for use at a plurality of different data processing systems and for maintaining a single usable copy. Connections and can be of any of those described with communications interface s . Any of the configuration data maintained at blocks and can be maintained to universal configurations for access at various data processing systems.

Field can be used to associate to a specific data object or user interface object which is associated e.g. child or parent object with a user interface object e.g. examples of E and video . Custom field may also be used to perform exploded views panning viewing re orientations axis rotations different perspectives or view angles or any conceivable custom transition.

Some TR fields are multi part fields i.e. have sub fields . TRs may be fixed length records varying length records or a combination with field s in one form or the other. Some TR embodiments will use anticipated fixed length record positions for subfields that can contain useful data or a null value e.g. 1 . Other TR embodiments may use varying length fields depending on the number of sub fields to be populated. Other TR embodiments will use varying length fields and or sub fields which have tags indicating their presence. Other TR embodiments will define additional fields to prevent putting more than one accessible data item in one field. In any case processing will have means for knowing whether a value is present or not and for which field or sub field it is present. Absence in data may be indicated with a null indicator 1 or indicated with its lack of being there e.g. varying length record embodiments .

Referring back to block if the object in the list is indicated as not being a currently active object in the display block determines the application for the object block invokes the application for being presented at the summoned position block places the application started into the rollback unit of work started at block and processing returns to block for a next record in the list. Referring back to block if all records in the list have been processed block frees the list and the invoker of processing is returned to at block . Referring back to block if a list is to be presented to the user block builds a list may be scrollable with invocable handles e.g. user interface object handle or fully qualified executable path name or invocable handle thereof block presents the user interface list at the summoned position block places the list into the rollback unit of work started at block and processing continues to block already described. Block may provide easy selectable informative descriptions for entries in the presented list which are each mapped to the invocable handles. Block provides similar processing to iterative processing started at block except a presented list is built for the user. Once the list is produced at block the user can interact with it for selecting any of the entries to invoke the handle i.e. invoke application implies starting it causes same processing as blocks through invoke user interface object handle implies summoning it causes same processing as block . Referring back to block if the summon request was not for currently active user interface objects processing continues to block .

If block determines the user requested to search historically presented user interface objects then block invokes get object list processing of with history i.e. search historically presented objects search criteria accessed at block and means e.g. memory address to return a list as parameters. On the return from processing continues to block for subsequent processing described above. If block determines the user did not request to search historically presented user interface objects then block saves criteria accessed at block for comparing to newly created objects in the user interface of the data processing system and the invoker of processing is returned to at block .

In some embodiments historically presented user interface objects are searched automatically after failure to find a currently active user interface object which satisfies the search criteria. processing invoked at block should be reasonable in what history is searched at the data processing system. Maintaining history for every user interface object and every change thereof while associating it to the application can be costly in terms of storage and performance. A trailing time period of history which is automatically pruned may be prudent or the types of object information saved for being searched may be limited. In some embodiments currently active user interface objects can be matched to search criteria by searching historical information which was present at some time in history to the user interface object.

In some embodiments block will incorporate processing to position the sought object of the application to the summoned position. Such embodiments may rely on application contextual processing e.g. methods analogous to U.S. Pat. No. 5 692 143 Method and system for recalling desktop states in a data processing system Johnson et al for producing a user interface object which depends on invoking an application and subsequently navigating it in order to produce the sought object at the summoned position.

A data processing system provides Application Programming Interfaces APIs for developing GUI applications. While varieties of data processing systems e.g. Windows Linux OS X Android iOS etc may provide different models by which a GUI is built e.g. programmed by a programmer appropriate interfaces e.g. APIs are used for building a user interface to accomplish similar functionality e.g. icons windows etc and elements entry fields radio buttons list boxes etc thereof . The present disclosure is applicable to any variety of data processing systems however a reasonably common GUI model shall be described to facilitate discussing operation of the present disclosure from a programming processing standpoint.

A window is defined herein as an area of the display controlled by an application. Windows are usually rectangular but other shapes may appear in other GUI environments e.g. container object of user interface in a three dimensional GUI embodiment . Windows can contain other windows and for purposes herein every GUI control is treated as a window. A GUI control controls the associated application. Controls have properties and usually generate events. Controls correspond to application level objects and the events are coupled to methods of the corresponding GUI object such that when an event occurs the object executes a method for processing. A GUI environment provides a mechanism for binding events to methods for processing the events. Controls may be visible e.g. button or non visible e.g. timer . A visible control which can be manipulated by the user of a GUI can be referred to as a widget. A widget includes frame button radio button check button list box menu button i.e. to build menus text entry field message box label canvas i.e. area for drawing image i.e. area for graphic display scale scroll bar and other visible controls well known to those skilled in the art. A frame is used to group other widgets together and it may contain other frames. A frame may represent an entire window. For purposes of this disclosure a searchable data object may also be associated with a window frame or control.

Other GUI terminologies include layout which is a format specification for how to layout controls within a frame e.g. through a coordinate system relative positioning pixel specifications etc parent which represents a position in a GUI hierarchy which contains one or more children and child which represents a position in a GUI hierarchy which is subordinate to a parent. GUI applications consist of a GUI object hierarchy. For example a frame for an application window may contain frames which in turn contain frames or controls thereby forming a tree hierarchy. The hierarchy structure provides means for the programmer to apply changes preferences or actions to a parent and all of its children. For example a desktop can be the topmost window or frame of the hierarchy tree. A GUI has at least one root window and windows have an organizational hierarchy wherein windows form a tree such that every window may have child windows. This makes windows searchable by starting at a root window and searching siblings in turn down the tree. Regardless of terminology there is a method for searching GUI objects starting from the root e.g. desktop or main window of context of the tree down to the leaves of the tree.

A key concept in GUI programming is the containment hierarchy. Widgets are contained in a tree structure with a top level widget controlling the interfaces of various child widgets which in turn may have their own children. Events e.g. user input actions arrive at an applicable child widget. If the widget does not deal with the event the event will be passed to the parent GUI object up the containment hierarchy until the event is completely processed. Similarly if a command is given to modify a widget the command can be passed down the containment hierarchy to its children for organized modification. The GUI object containment tree facilitates events percolating up the tree and commands being pushed down the tree. The GUI object containment tree facilitates searching all objects.

Graphical user interfaces manage windows. A window belongs to a window class making it possible to search them by class . In fact every GUI object control frame etc can be of some class. Some windows have text attached to them e.g. titlebar text to facilitate identifying the window and this may be viewed as a data object associated to the window object. Every window has a unique handle e.g. numeric ID for programmatic manipulation but windows may also be identified by their text class and attributes. A GUI may have multiple containment hierarchies or a somewhat different method for a containment hierarchy. For purposes of this disclosure all GUI objects are contained in what shall be referred to as the GUI object tree wherein every object is a node on that tree. Various tree traversal and search enhancement techniques may be utilized to maximize performance when searching the tree.

With reference back to block continues to block . Block checks if all target information has been searched. If target information was found for processing block determines if the target information e.g. currently active user interface object or historical object information contains data which matches the search criteria accessed at block . Block may perform a language translation to match search criteria against information in a different language a graphical comparison a textual comparison or any other comparison method. Thereafter if block determines a match was found block inserts a record into the return list with at least the object handle which can be summoned e.g. may be a parent object to the matched currently active object or invocable application handle to produce the object which at one time contained the search criteria or the handle of an object with a special relationship to the searched object and object type e.g. compare to field for transition processing and processing continues back to block . If block determines no match was found then processing continues directly back to block . Block gets the next target information to be searched thereby starting an iterative loop for handling all target information with blocks through . If block determines all target information has been checked processing continues to block . If block determines the search criteria indicates to select the best fit rather than a plurality of objects then block determines the best fit object block appropriately sets the list to that single object or application invocation handle and processing returns to the invoker e.g. at block with the list created. If block determines a single best fit is not being sought then block continues to block for returning the list built to the invoker. Searching currently active user interface objects and using appropriate handles in the list is straightforward while embodiments supporting searching historical information may significantly deteriorate data processing system performance during search time and in keeping large amounts of information for objects without valid handles. In an alternate embodiment handles are maintained uniquely at the data processing system over a reasonable time period to ensure uniqueness across all currently active and historically presented user interface objects.

In some embodiments block may automatically check historical information for a currently active user interface object in order to satisfy a search criteria e.g. which has not been satisfied by a currently active user interface object . In some embodiments sophisticated search processing systems and methods may be used instead of the simple processing of for searching target information.

Examples of searches which are accomplished with static or dynamic gestures include summoning object s by 

Special application relationship of object such as family object with relationship to searched object e.g. Father Son etc service object with relationship to searched object e.g. Police Department Fire Department etc or any other determinable relationship of one or more objects to the searched object 

If block determines a transition configuration was found at block then block calculates a loop index for object transition movement that may be applicable for the identified TR block iterates through all but one instance of graphically transitioning the object toward the summoned position block completes the last graphical change for the final summoned position of the object block finalizes any applicable transition processing further indicated by the transition configuration for the object and processing returns to the invoker e.g. at block . There are various embodiments for accomplishing blocks and . For example the data processing system can automatically be fed iterative user input drag requests to cause moving the object being transitioned. Specific data processing system interfaces may also be provided for automatically transitioning an object based on a configured type of transition. If block determines no suitable TR configuration was found block processes a reasonable default such as instantly removing the object from the user interface at block and making it reappear as it was at the summoned position at block before continuing back to the invoker at block .

Present disclosure magnetic mode processing shall be described for the flowcharts already described. With reference back to the user may enable magnetic mode and disable magnetic mode as handled at block . For example a user may enable magnetic mode with a gesture implied search criteria or search criteria specified at gesture time and disable magnetic mode with a static gesture similarly to as was described for blocks and except summon action processing invoked at block behaves differently because magnetic mode being enabled is indicated in criteria set at block . Once the data processing system is in magnetic mode any detected input of the user interface e.g. any touch to the touch sensitive display causes objects satisfying the magnetic mode search criteria can be any of the same search criteria as described above for static and dynamic summon gestures to gravitate towards the currently active user input position i.e. current touch position detected . When active user input detection ends e.g. user no longer touches the touch sensitive display objects return back to their original positions. Touches detected at block cause invocation of magnetic mode object transition for currently active user interface objects matching the search criteria by invoking block with the criteria also indicating magnetic mode is enabled. A soon as a touch is not detected rollback processing already described for block is immediately invoked to return objects back to where they were originally.

Further provided at block is the ability for a user to confirm summoning the objects e.g. static gesture for confirm while in magnetic mode with disclosed summon gesture processing. Magnetic mode provides to the user a proposed result without a full summoning execution. The proposed result can then be confirmed by the user to perform complete summoning. Once the objects are confirmed to be summoned a preferred embodiment disables magnetic mode automatically just prior to summoning objects an alternate embodiment may keep magnetic mode enabled until the user explicitly disables the mode . When magnetic mode is confirmed for summoning as determined at block processing continues directly to block for subsequent normal summon action processing i.e. no magnetic mode indicated using search criteria as though magnetic mode was never used.

Thus magnetic mode processing includes blocks and . With reference to magnetic mode processing always involves currently active user interface objects. Thus magnetic mode processing includes blocks and through no block . With reference to block additionally accesses a magnetic mode indicator parameter passed by block from criteria which causes different processing when magnetic mode is enabled. Processing of blocks through and blocks through use magnetic mode percentile field for transitioning at a percentage of overall distance toward the detected user input position. Recommended values for field are 25 to 80 so the gravitation of objects toward the cursor position e.g. summoned position is evident without bringing objects all the way to the cursor i.e. a magnetic effect . Other TR fields may be used and some TR fields may be overridden to ensure desirable magnetic mode functionality e.g. linear gravitation movement . For example scaling and ghosting can still be used from the TR but a non linear mathematical function for the summon path may be overridden.

Magnetic mode provides a convenient way to identify objects of interest without cluttering a proposed summoned position until the user is ready to confirm the summoning of the object s . There may also be a variety of user interface navigation scenarios where magnetic mode is useful.

While various embodiments of the present disclosure have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of the present disclosure should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

