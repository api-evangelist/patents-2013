---

title: Transferring a mobile tag using a light based communication handshake protocol
abstract: Technology is described for transferring one or more mobile tags using a light based communication protocol. A mobile device, for example a smart phone, with an image sensor and an illuminator, like a camera flash, initiates transfer of data formatted in a mobile tag displayed by another device by automatically controlling the illuminator to generate sequences of light representing data transfer messages. The other device, for example a user wearable computer device with sensors capturing biometric and health related data, has a photodetector unit for capturing the sequences of light and converting them into digital data. A processor of the other device identifies the data transfer messages and causes a display of one or more mobile tags responsive to the messages. In this way, a number of mobile tags may be used to transfer several kilobytes of biometric data, for example 4-7 KBs, using low power for the wearable device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08941487&OS=08941487&RS=08941487
owner: Salutron, Inc.
number: 08941487
owner_city: Fremont
owner_country: US
publication_date: 20130307
---
This application claims priority under 35 USC Section 119 e to the following provisional applications U.S. provisional application No. 61 609 136 to Lee et al. filed Mar. 9 2012 entitled Communications Link Between Health Monitor and Mobile Computing Device U.S. provisional application No. 61 749 465 to Lee et al. filed Jan. 7 2013 entitled Communications Link Between Health Monitor and Mobile Computing Device U.S. provisional application No. 61 749 913 to Lee et al. filed Jan. 8 2013 entitled Communications Link Between Health Monitor and Mobile Computing Device and U.S. provisional application No. 61 848 644 to Lee et al. filed Jan. 7 2013 entitled Communications Link Between Health Monitor and Mobile Computing Device all of which are hereby incorporated by reference.

There are various devices that can be used to monitor the health of a person or animal. An example of such a device is a heart rate monitor in a wrist watch form as described in U.S. Pat. No. 6 843 771 entitled Ultrasonic Monitor for Measuring Heart Rate and Blood Flow Rate to Lo et al. issued Jan. 18 2005 and assigned to Salutron Inc. A user wearable computer device may also collect data from other types of sensors such as accelerometer data which can provide data on speed for applications such as pedometers and calorie counting. The biometric data captured by health monitoring devices can be used by various applications on a mobile computing device also referred to as a mobile computer device such as a smart phone or uploaded over a network to a remote computer system for further analysis and tracking of the user s biometric data.

Health monitoring sensors typically have contact with the skin and are often placed at various joints of the body such as the wrist or ankle for better capture of pertinent data rather than being supported in a back pack on a person s back. A user wearable health monitoring computer device also has to have a battery that is comfortable to wear by a human and also does not drain too quickly. It can be challenging to communicate the biometric data from a user wearable health monitoring computer device to a mobile computer device in an efficient and cost effective manner.

The technology provides for transferring one or more mobile tags between computer devices using a light based communication handshake protocol.

The technology provides one or more embodiments of a method for transferring one or more mobile tags using a light based communication handshake protocol. An embodiment of the method comprises capturing image data of an electronically displayed mobile tag with an image sensor of a mobile computer device. A successful read of data encoded in the mobile tag is identified and based on the data encoded in the mobile tag it is identified whether the mobile tag is the last mobile tag of data in a series. Responsive to the mobile tag not being the last mobile tag of data in the series a sequence of light flashes is generated with an illuminator of the mobile computer device in accordance with a communication handshake protocol for indicating to display a next mobile tag. Responsive to the mobile tag being the last mobile tag of data in the series the display of the mobile computer device is updated to indicate an end of data transfer for the user.

The technology provides one or more embodiments of a system for transferring one or more mobile tags using a light based communication handshake protocol. An embodiment of the system comprises a mobile device including a processor a memory storing software and data and being accessible by the processor as well as an image sensor and an illuminator both communicatively coupled to the processor. The mobile device further comprises one or more user input devices from which the processor under control of the software receives user input indicating a request for transfer of data from another computer device. The processor under control of the software causes the image sensor to be turned on and causes the illuminator to generate a sequence of light flashes indicating a message requesting transfer of the data in accordance with a communication handshake protocol.

The processor under control of the software identifies a mobile tag in image data being captured by the image sensor and extracts data encoded in the mobile tag. Responsive to the data extracted from the mobile tag indicating there is more data to be transferred the processor causes the illuminator to generate a sequence of light flashes indicating a message to display another mobile tag encoded with data.

Another embodiment of the technology comprises a user wearable biometric sensing computer device for communicating biometric data to a mobile computer device. The user wearable biometric sensing computer device further comprises a processor a display communicatively coupled to the processor one or more biometric sensing units for generating biometric data communicatively coupled to the processor a memory accessible by the processor for storing software and the biometric data and a photodetector unit communicatively coupled to the processor which unit captures one or more sequences of light flashes and converts the one or more sequences of light flashes into digital data and stores the digital data in the memory.

The processor identifies one or more messages in the digital data based on a communication handshake protocol for the one or more sequences of light flashes and controls displaying of the biometric data formatted in one or more mobile tags in accordance with a mobile tag code on the display based on the one or more messages identified in the one or more sequences of light flashes. A user wearable support structure supports the processor the display the memory the one or more biometric sensing units and the photodetector unit.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

The technology provides for a low power transfer of data based on a communication handshake protocol in which sequences of light flashes representing messages are detected by a photodetector of a device particularly a low power computer device like a user wearable biometric sensing device. The photodetector converts the photons of the light flashes to electrical signals which are then converted from analog to digital form as digital data e.g. bit values of 1 s and 0 s from which a processor of the computer device having the photodetector identifies data transfer messages like start and next. The computer device receiving the light flashes responds by displaying one or more mobile tags of data which a mobile computer device for example a smart phone generating the light flashes captures with its image sensor for example its camera and extracts the data in each tag using mobile tag recognition technology.

As described further below a user wearable biometric sensing computer device may be embodied as a wrist wearable computer device with a watch like unit housing and supporting the computer hardware and software biometric sensors and providing a watch like display. In some examples biometric data based on sensor readings from the various sensors such as heart rate and blood flow sensors or accelerometers may be transferred in the mobile tags. Depending on an application several kilobytes KB of data may be transferred in a session for example 4 7 KB. In an example where each mobile tag can encode about 1 KB a secession of mobile tags may be displayed on the watch like display. The communication handshake allows the mobile device recognizing the mobile tag to communicate when to send the next tag and can acknowledge no errors or indicate an error occurred to the user wearable device. In some embodiments the computer device encoding the mobile tag encodes a symbol character or other representation indicating this is the last tag of data.

Some examples of mobile tagging codes are QR Code DataMatrix Cool Data Matrix Aztec Upcode Trillcode Quickmark Shotcode mCode and Beetagg which are also examples of two dimensional 2D barcodes which a mobile device with the corresponding 2D barcode reader software installed can read. Another type of mobile tag which uses color rather than black and white squares is Microsoft s High Capacity Color Barcode HCCB standard. Some of these codes encode data redundantly to account for perspective and glare issues. In some embodiments to save on size of data to be transferred redundant encoding of data may be omitted.

Each device has a respective processing unit with one or more processors communicatively coupled to a respective display respective user input devices and respective communication interfaces for communicating over wire or wirelessly with other computer systems to which they may be networked. A computer system may be embodied in one or more computer devices. A respective memory which may provide both non volatile and volatile storage is accessible by its respective processing unit and other components like its respective display and communication interfaces. Memory is also accessible to interface circuitry for the photodetector and interface circuitry for other sensors for buffering and or storing of their digital data readings. Memory stores data which may include user profile data sensor and photodetector digital data readings reference data transfer messages for identifying by comparison whether the digital data contains a data transfer message and data generated during runtime and for storage by the various software applications stored including a mobile tag communication software application . Examples of other applications which may be stored are also illustrated with biometric related type of applications. Additionally a mobile tag generator for a mobile tag code may be stored in the other applications .

Memory in the mobile device is also accessible to an image sensor embodied as a camera for buffering and storing of image data. Memory stores data some examples of which may include user profile data captured image data as mentioned images moving or still and text as visual aids discussed further below and data generated during runtime and for storage by the various software applications stored. A mobile tag communication software application for a mobile tag reading device a camera system control software application and image processing software are stored as well as other applications . Each of the memories and are examples of processor readable storage devices which fix data in place for reading and writing.

The complexity of the architecture components vary. For example for an embodiment of the user wearable biometric sensing computer device as a wrist watch with a display the user input and output devices may include small buttons e.g. on the side of the watch the top of the watch and display may also be an input device by being a touch sensitive display which may be activated with a stylus or finger in some embodiments. Output devices other than the display may include a beeping device. The memory processing capability of the processing unit communication interface wireless range and number of connections supported as well as quality of display on the display and sound quality of speakers as audio output devices of the mobile computer device very likely substantially exceed that of the biometric sensing computer device in this example which prioritizes being light weight and low power.

An example of a communication interface s of the biometric sensing computer device may be a type of USB port a Bluetooth port or an IR port. Some examples of communication interface s on the mobile computer device are a USB port a cellular network connection and a WiFi wireless connection which allow the mobile computer device to communicate over one or more communication network s with other computer systems . Some examples of a communication network are a local area network and the Internet. As illustrated by the dashed arrow in some embodiments the devices may also communicate using a Bluetooth IR or other wireless wired connection.

The user wearable biometric sensing computer device also has sensor interface circuitry for other sensors besides the photodetector which other sensors include biometric monitoring sensors which provide the data from which calories heart rate distance walked and the like can be determined for requesting applications some of which may execute locally such as the illustrated examples of other applications a calorie counter application a distance calculator a heart rate monitor application and a pedometer application. The photodetector on the wearable device also sends its signals to a photodetector interface circuitry and together they provide a photodetector unit which detects and converts flashes of light into electrical signals which the photodetector interface circuitry converts to digital data readable by a processor of the processing unit .

The photodetector may is sensitive to light including the wavelength of light of the camera illuminator . In some examples the photodetector detects peaks and valleys or highs and lows of light intensity as the camera illuminator placed over the photodetector generates flashes of light. These highs and lows may be correlated to be bit values of 0 s and 1 s and sequences of these bit values can represent messages. A serial communication protocol may be used to implement the handshake. An example of an analogous communication handshake protocol using messages for asynchronous communication with a handshake is the RS 232 handshake protocol. Another example of an analogous protocol is Universal Asynchronous Retriever Transmitter UART . In one version of the protocol a bit value of one is represented by a detection of the light flash as represented by its intensity and a bit value of zero is represented by an intervening time period of not detecting light at the intensity of the light flash. In other words an on and off sequence of flashes can represent one or more bits or other values. In other embodiments the communication protocol can represent higher level values for example 0 to F in hexadecimal. For example the communication protocol may use a time period at a certain level of light intensity to represent a bit value and a time period at a lower level of light intensity to represent another bit value if the camera illuminator allows variation in the light flash intensity. In other examples the light intensity of the camera illuminator light flashes varies to indicate more than two values. Also the time periods for different intensity values may be varied as well to indicate different values in other examples and the intensity values and time periods may also be varied for representing different values

The mobile computer device includes an embodiment of an image sensor as a camera and includes as an illuminator a camera illuminator often referred to as a camera flash. As illustrated in the memory the mobile device includes camera system control software with which an executing version of a mobile tag communication software application for a data reader computer device can communicate for example through an application programming interface API . The application communicates via the camera control software for automatically controlling light flash generation by the camera illuminator in accordance with the communication handshake protocol. The application may also interact with the camera control software for receiving notice that image data has been captured and its buffer location. The mobile tag communication software may include or interface with a mobile tag reader application e.g. for identifying a mobile tag. One or more standard mobile tag reader applications may be included or interfaced with or the mobile tag reader software can be customized for example to avoid the use of redundant data or to identify a customized tag appearance for display dimensions of a device.

The mobile tag communication software application may also have performed real time transformations necessary for perspective scaling and orientation or rotation issues. For example special symbols in the tag are identified from which a transformation matrix can be derived for reorienting and resizing an image and determining if all of a 2D bar code displayed in a tag was captured in the image data. The application may also have performed symbol or character recognition.

The mobile tag communication software application can also communicate with the image processing software for identifying camera related issues such as focus correction need blur levels glare detection and other image processing functionality provided by digital cameras generally.

Additionally the image processing software can be used to identify the user wearable computer device in image data based on pattern recognition with one or more reference images stored in memory. In some embodiments the image processing software can generate an outline version image of an object in which an outline of a perimeter of an object appears while the rest of the object appears to be see through. Contrast ratio can be turned to extremes or edges isolated using edge detection software. In other examples the outline version image which can be used as a visual alignment aid is generated offline for different models of tag generator devices like the user wearable biometric sensing computer device and downloaded over a communication network by the mobile tag communication software

The user wearable biometric sensing computer device includes a data generator version of the mobile tag communication software application . The software identifies messages in the digital data generated by the photodetector based on a communication handshake protocol. Additionally the mobile tag communication software application includes a mobile tag encoder or interfaces with mobile tag generation software for example mobile tag generation software for a standard mobile tag code. In some cases the mobile tag generator may modify a standard tag or use its own custom version for example to avoid encoding redundant data to speed the data transfer as a user may be holding the mobile device near the sensing computer device. The mobile tag communication software formats the generated mobile tag for display on its device s display and causes each tag to be displayed responsive to messages like start next send or display re send or re display identified from the light flashes detected by the photodetector . Each tag may have an identifier code and a sequence number in its data to assist the data reader version of the software to track which tags in a series of tags have been received and read successfully and which had errors for resending.

In the contextual example of a user is wearing the biometric sensing device embodied in a wrist watch form factor with its watchface display illustrating heartbeat data and photodetector on the face of the watch above the display. In other embodiments the photodetector may be positioned on or within the display . The user is holding a mobile device embodied as smartphone and has already initiated the mobile tag communication application to start uploading data with user input see . The mobile tag communication application displays instructions or position hints such as Please line up and displays another visual aid which is the outline version image for the wrist wearable biometric sensing device . In other examples the alignment aid may be a simpler shape such as a rectangle or a circle. The outline version helps the user also achieve a good distance of the mobile device from the display which has been predetermined offline for optimal reading under certain light conditions. The outline version image may be adjusted based on ambient light conditions identified in image data by the image processing software or an ambient light sensor not shown on the mobile device .

In this contextual example an exchange of data may occur as in the following example. The first mobile tag displayed may be a set of handshake characters previously stored in the memory in both devices for verifying recognition quality. The wrist biometric sensing computer device goes into an upload mode and displays the hand shake characters. The phone waits for the hand shake characters and on successful reception the phone sends an acknowledgement message via the camera illuminator which is detected by the photodetector on the watch face. The wrist device starts with a first mobile tag of biometric data. Upon successful detection of the message characters and the data encoded therein passing a data integrity check the phone causes the camera illuminator to send a light signal of flashes encoding a message to the watch to proceed with the next mobile tag. In the last mobile tag is included an end of message character. Once the phone receives the last mobile tag with the end of message character the phone may have the illuminator send an end of message or end of data acknowledgement for the photodetector to detect and both devices may end the communication session or start another session for a different type of data e.g. heart rate after calorie burn data.

The mobile device may use one or more sequences of light flashes to send small amounts of data to the wearable biometric sensing device . For example a person s most current weight may be downloaded for a calorie counting application. A small text message advertisement may be sent down. Additionally the messages for the communication protocol may also include data identifying from which application data is to be uploaded and a password or authentication code which verifies permissible access to the data stored on the sensing computer device .

Glare may be a factor. Alignment between the camera and the watchface may be causing perspective or rotation issues particularly if a simpler visual guide is used than the outline version image. The image data may be adjusted for perspective or rotation identified within certain ranges. The mobile tag software may identify a user positioning hint for display to the user to identify to the user how to move the smartphone to improve the reading of the data. A data integrity check for example a checksum may be performed on the extracted data to verify whether errors have occurred in the data. Additionally messages may be encoded with cyclic redundancy codes or other error correction codes.

The technology may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Likewise the particular naming and division of modules routines applications features attributes methodologies and other aspects are not mandatory and the mechanisms that implement the technology or its features may have different names divisions and or formats.

For illustrative purposes the method embodiments below are described in the context of the system and apparatus embodiments described above. However the method embodiments are not limited to operating in the system and apparatus embodiments described above and may be implemented in other system and apparatus embodiments.

Responsive to the tag being the last mobile tag of data optionally in step the mobile tag communication application may cause the camera illuminator to generate a sequence of light flashes indicating an end of data transfer acknowledgement message. In step the display of the mobile device is updated for indicating the end of data transfer for the user so the user can move at least one of the devices. Optionally in a case where the data extracted from the tags or even the tags themselves are being sent to a remote computer system over a network in step the mobile tag communication application sends a notification indicating the end of the data transfer to another computer system receiving over a network .

Responsive to the tag not being the last mobile tag of data in step the application causes an illuminator of the mobile computer device to generate a sequence of light flashes indicating to display a next mobile tag in accordance with a communication handshake protocol.

In step the mobile device receives user input indicating a request to upload mobile tag data from a user wearable computer device e.g. and notifies the mobile tag communication application which in step causes the camera software to automatically turn an image sensor of the mobile device on for capturing image data.

Optionally in step one or more visual aids is displayed for assisting a user in positioning the user wearable computer device in a field of view of the image sensor. The mobile communication tag application via the camera software in step generates one or more sequences of light flashes by an illuminator of the mobile device which one or more sequences indicate a request to the user wearable computer device to start displaying one or more mobile tags in accordance with the communication handshake protocol.

In step it is determined whether a mobile tag of data has been successfully read within a pre set time period. As noted in an example above there may be an initial exchange of predetermined handshake characters stored at both devices to verify a mobile tag can be read. Additionally a checksum or other error checking or data integrity checking scheme may be applied to the data extracted from the tag to verify whether an error has occurred or not.

Responsive to an unsuccessful read in step a notification is output indicating an unsuccessful read of the mobile tag data via audio data visual data on the mobile device display or both and the determination in step is periodically performed until either a successful read or the user exits the application. Optionally in step one or more positioning hints are output to the user in audio data visual data or both and the determination in step is periodically performed until either a successful read or the user exits the application.

Responsive to a successful read in step the application determines whether the data in the mobile tag indicates it is the last mobile tag of data for display. Responsive to the tag being the last tag of data in step a notification indicating an end of data transfer is output to the user. Optionally steps and may be performed as well.

Responsive to the tag not being the last mobile tag of data in step a sequence of light flashes is generated by the illuminator indicating to display a next mobile tag in accordance with a communication handshake protocol.

Responsive to the start request being indicated by the sequence of light flashes within the pre set time period optionally in step the data such as biometric data for transfer may be encoded at this point in one or more mobile tags with a last mobile tag indicating an end of data. In other examples the biometric data may be continuously encoded in mobile tags and stored as memory permits prior to a data transfer session with a mobile device. In other examples the data may be encoded in a respective tag after a successful read of a previous tag. In step an initial mobile tag is displayed. In step it is determined whether a sequence of light flashes indicating a next tag request has been received within a pre set time period. If so in step the mobile tag communication application causes the next mobile tag to be displayed and returns to step to wait for another message or time out of the pre set time period.

If a message indicating a next tag request is not received in the pre set time period the mobile tag transfer application in step determines whether a sequence of light flashes indicating re display instructions has been received within a pre set time period. If not in step the application may save the current location of data not yet transferred and release the processor and display for other applications. If the message received within the pre set time period is not a next tag request or a re display request but an end of data acknowledgement message the mobile tag communication application identifies all data has been successfully read and ends its processing by releasing the processor and display for other applications.

As discussed further below re display instructions may result from various causes for example glare or contrast. The re display instructions may simply be to re display the currently displayed mobile tag as is. In other examples the re display instructions may request display of a tag not using a designated portion of the display or certain character locations in the tag depending on design choice. A display may have designated quadrants for example and one quadrant is to be avoided. The tag may have to be displayed in parts over time which is stitched by the image processing software at the request of the mobile device mobile tag communication application . In other examples data displayed on a certain designated portion of the display may be requested to be redundantly encoded in the tag so it appears elsewhere on a readable portion of the display. Responsive to receiving the re display instructions in step application causes the currently displayed mobile tag to be re displayed in accordance with the received re display instructions and returns to step .

In the examples described above the positioning of the image sensor or camera and illuminator with respect to a display and photodetetector of another computer device displaying a mobile tag is not automatically controlled. A user is involved. There may be slight motion of the user hand or a user may get interrupted and move the devices out of alignment. Besides motion to one side or the other the user may be moving the device or devices so that the distance between them and hence the scale of the image data changes. Additionally the mobile tag is being read off a display some examples of which are a liquid crystal display LCD or a light emitting diode LED display which contributes its own brightness and contrast in addition to that of the environment of the user. Speaking of environment a user may be indoors outdoors out in very bright sunlight or out on a moonless night. Each of these examples may cause errors in being able to identify a device which generates the mobile tag and read the data in a displayed mobile tag.

One of the first stages in being able to retrieve mobile tag data is detecting the region of the image acquired by the camera that corresponds to the display of the device displaying the mobile tag. One way to handle this problem is to detect the borders of the image and compare to borders which are defined a priori. They could be for example the stored actual borders of the display in the watch based examples shown in . Object detection software or pattern recognition by the image processing software may be used to identify the display area. The captured image data may be scaled rotated and translated to see if a match with a reference image of the device e.g. displaying the tag may be obtained. Another way to address this problem is to use some special symbols located on the corners of the region of interest which is display in the illustrated examples above which is similar to the case of QR code detection. For example the three large corner squares in a QR code can be identified and scale rotation and perspective or orientation of the tag can be identified. This way also provides the advantage of indicating a level of brightness expected from the characters to be recognized. Another advantage of this way is that it is possible to use Haar like features for the detection of the special symbols. Haar like features can also be used for identifying different regions in the image and region of interest of display .

Before character identification within the mobile tag adjustments to the image data may be performed by the image processing software or the mobile tag communication application based on the identified corners and or borders of the region of interest e.g. display . Adjustment for perspective and rotation correction may be performed first based on dimensions data stored for the display or a region of interest thereon. If the region of interest is a square or rectangle the dimensions data indicates what the distance and relative positions are between the corners in the image data. The distance between the corners can also identify the scale of the display or other region of interest on the display from a reference image.

Real life conditions will deviate from this scenario. The software executing on the mobile device may have performed correction for perspective and rotation distortion by applying an inverse perspective rotation transformation when the exact shape orientation and size e.g. rectangle and square of the undistorted region of interest is stored. The applied transformation transforms the distorted coordinates to the undistorted coordinates based on the stored corner positions and the detected corner positions. The distance between the camera and the display to be read may also be an input to the transformation to address scale differences with the size of the corresponding undistorted rectangle square.

Once the inverse transformation is found it could be used to transform every pixel on the original image obtained from the first stage. Something to keep in mind is that this is a dynamic process since the perspective rotation and scaling could change continuously.

As mentioned above another challenge for this stage is the uncontrolled level of brightness as the user could activate detection indoors or outdoors under variable luminance conditions due to natural or artificial light with or without shadows. Additionally the reflective material on the watch could at any moment produce glare thus partially or totally blocking the displayed data and precluding successful detection. Contrast is another parameter that needs to be varied in order to facilitate detection given the potential wide range of brightness that may exist.

The detection of the image corners transformation of data for perspective rotation and scale correction and the identification of brightness contrast and glare are continuously performed during a tag transfer session between the devices in order to provide a base line of readiness for subsequent image adjustment and character identification.

If the detection of the region of interest in image data process in the first stage used special symbols on the corners of the display then brightness and contrast variations were used and identified as part of the detection process. The levels of brightness and contrast identified in the detection of the special symbols can be used in a third stage to perform character recognition within a 2D bar code or other type of mobile tag.

A second stage of adjustment of image data includes identification of un usable portions of a display. Glare is still a potential problem for the next stage of character identification since glare could block portions of the inner image region even when the corners have been successfully detected. The image processing software may identify one or more portions of the displayed data affected by glare and adjust the brightness and contrast of the image data. The mobile tag communication application can interface with the image processing software to identify if the adjusted image data was successfully read or not. Depending on the aggressiveness of the glare it may not be possible to recover the character by performing further brightness contrast adjustment e.g. no more adjustment levels available to the image processing software after a number of unsuccessful reads. The mobile tag communication application may then send re display instructions using the illuminator indicating that the data in the identified glare portions redundantly coded elsewhere in a tag to display on another portion of the display from which data has been successfully read. Besides providing redundant information that would allow acquiring the data on different parts of the display allowing the data to be shown in areas not affected by the glare another solution is to send re display instructions which designate portions of the display as un usable and requesting keeping display of data for transfer to the unaffected portions.

Aspects of the camera may also prevent or cause errors in detection of the display to be read or character recognition within a tag. Variation in focus is an example. An incorrect focus may be perceived as a blurred image thus presenting an obstacle for detection and delaying data transfer. Continuous detection of the image corners may signal when a correct focus has been achieved.

Received images may also be down sampled by the image processing software since the image resolution obtained from the camera is likely several times higher than a typical resolution used to perform detection of a region of interest and character identification within a tag.

Additionally due to varying luminance conditions it may be possible that some portions of the image get distorted or blurred even precluding detection of the special symbols of the region of interest e.g. the corners of the rectangle or square of a tag including special handshake characters displayed on the display . The varying luminance conditions may also preclude the identification of characters even though the corners are successfully detected. Similar solutions as per glare may be employed by the image processing application and the mobile tag communication application executing on both devices by identifying one or more legible readable regions of the image similarly as what is mentioned for glare above and adjusting character presentation to display in these readable areas.

Once the region of interest is defined in image data and image adjustments made a third stage of character identification or character recognition can proceed. In many embodiments the characters are identified as binary values. The mobile tag communication application or a mobile tag reader application it interfaces with may transform the acquired image to gray levels first and then to black and white levels or straight to the black and white levels. A threshold intensity value is applied to each pixel in order to define it as a black pixel or a white pixel. In many examples the threshold value is set dependent upon the brightness level identified in the ongoing processing of stage .

The image data in the region of interest may be processed starting with the upper left corner and shifting by a pre established number of pixels in order to find the first character. Small errors in previous stages can put the character in a different position from the one expected. Therefore a certain amount of searching may be performed at this point in order to obtain the character. Movements causing even small rotations and changes in scale and perspective may result in increased or reduced character sizes. There are several methods that can be used for identification. For example one using eigenvalues may be used. As previously mentioned the display and image capture of a known sequence of characters in an initialization stage of the communication handshake protocol assists in identifying the image distortions and their causes.

Additional characters could be identified in a similar way by shifting from the upper left corner towards other locations where these characters are expected to be found i.e. second third fourth character etc . When recognizing additional characters some tolerance for shifting rotation scaling may be provided. In some examples the software performing the character or symbol recognition for the tag can apply the corrections made for the first character for the remaining characters.

Although relying on user positioning and support of at least one of the computer devices may increase the prevalence of some distortions in the image data a user can also be an asset for removing or lessening the sources of the distortions. For example the mobile tag communication application can provide visual indicators of the identified problems and positioning hints. For example if glare spots have been identified a simple text message display of Glare is preventing data read informs the user and the user can move the one or more devices to a different position with less sources of reflected light. A user can usually see glare on the display and identify when positioning has removed the glare using human sight. Additionally an image of the display with an overlay of outlines of the identified glare spots may be displayed with text requesting repositioning of one or both devices. For perspective rotation and scale distortions based on the transforms for correction directions and distance in which to move the sensing device may be identified and filled in to variable positions of a prestored message for display on the device or as audio output. For example the mobile device identifies that it has read the 2D barcode correctly by doing a check sum. If it has not read it due to a camera focus issue then the mobile device alerts the user who can reposition the phone to make sure the focus of the device camera is right. Additionally the visual aids such as the outline in may help the user keep the devices in a good position range for reading. Other embodiments may also include one or more structures which position the devices to reduce image distortions and thus increase the speed of the transfer of data.

The foregoing detailed description has been presented for purposes of illustration and description. It is not intended to be exhaustive or limiting to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. The described embodiments were chosen in order to best explain the principles of the disclosed technology and its practical application to thereby enable others skilled in the art to best utilize the technology in various embodiments and with various modifications as are suited to the particular use contemplated.

