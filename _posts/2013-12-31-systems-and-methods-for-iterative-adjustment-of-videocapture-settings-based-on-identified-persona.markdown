---

title: Systems and methods for iterative adjustment of video-capture settings based on identified persona
abstract: Disclosed herein are systems and methods for iterative adjustment of video-capture settings based on identified persona. In an embodiment, a method includes receiving video frames being captured by a video camera of an ongoing scene. The method also includes identifying a persona in one or more of the received frames at least in part by identifying, in each such frame, a set of pixels that is representative of the persona in the frame and that does not include any pixels representative of a background of the frame. The method also includes selecting, based collectively on the brightness values of the pixels in the identified set of pixels of one or more frames, an adjustment command for one or more adjustable video-capture settings of the camera, as well as outputting the selected commands to the camera for use in continuing to capture video data representative of the ongoing scene.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09485433&OS=09485433&RS=09485433
owner: PERSONIFY, INC.
number: 09485433
owner_city: Chicago
owner_country: US
publication_date: 20131231
---
Online data communications are quite prevalent and pervasive in modern society and are becoming more so all the time. Moreover developments in software communication protocols and peripheral devices e.g. video cameras along with developments in other computing disciplines have collectively enabled and facilitated the inclusion of multimedia experiences as part of such communications. Indeed the multimedia nature and aspects of a given communication session are often the focus and even essence of such communications. These multimedia experiences take forms such as audio chats video chats that are usually also audio chats online meetings e.g. web meetings and the like.

Using the context of online meetings as an illustrative example it is often the case that one of the participants is the designated presenter and often this designated presenter opts to include some visual materials as part of the offered presentation. Such visual materials may take the form of or at least include visual aids such as shared desktops multiple slide presentations and the like. In some instances from the perspective of another attendee at the online meeting only such visual materials are presented on the display of the online meeting while the presenter participates only as an audio voiceover. In other instances the presenter may be shown in one region of the display while the visual materials are shown in another. And other similar examples exist as well.

Improvements over the above described options have recently been realized by technology that among other capabilities and features extracts what is known as a persona of the presenter from a video feed from a video camera that is capturing video of the presenter. The extracted persona which in some examples appears as a depiction of the presenter from the torso up i.e. upper torso shoulders arms hands neck and head and in other examples appears as the entire body from head to foot is then visually combined by this technology with content such as a multiple slide presentation such that the presenter appears to the attendees at the online meeting to be superimposed over the content thus personalizing and otherwise enhancing the attendees experiences. This technology is described in the following patent documents each of which is incorporated in its respective entirety into this disclosure i U.S. patent application Ser. No. 13 083 470 entitled Systems and Methods for Accurate User Foreground Video Extraction filed Apr. 8 2011 and published Oct. 13 2011 as U.S. Patent Application Pub. No. US2011 0249190 ii U.S. patent application Ser. No. 13 076 264 entitled Systems and Methods for Embedding a Foreground Video into a Background Feed based on a Control Input filed Mar. 30 2011 and published Oct. 6 2011 as U.S. Patent Application Pub. No. US2011 0242277 and iii unpublished U.S. patent application entitled System and Methods for Persona Identification Using Combined Probability Maps filed Dec. 31 2013.

As mentioned this persona extraction is carried out with respect to video data that is being received from a camera that is capturing video of a scene in which the presenter is positioned. The persona extraction technology substantially continuously e.g. with respect to each frame identifies which pixels represent the presenter and which pixels do not and accordingly generates alpha masks e.g. generates an alpha mask for each frame where a given alpha mask may take the form of or at least include an array with a respective stored data element corresponding to each pixel in the corresponding frame where such stored data elements are individually and respectively set equal to 1 one for each presenter pixel and to 0 zero for every other pixel i.e. for each non presenter a.k.a. background pixel .

The described alpha masks correspond in name with the definition of the A in the RGBA pixel data format known to those of skill in the art where R is a red color value G is a green color value B is a blue color value and A is an alpha value ranging from 0 complete transparency to 1 complete opacity . In a typical implementation the 0 in the previous sentence may take the form of a hexadecimal number such as 0x00 equal to a decimal value of 0 zero while the 1 may take the form of a hexadecimal number such as 0xFF equal to a decimal value of 255 that is a given alpha value may be expressed as an 8 bit number that can be set equal to any integer that is i greater than or equal to zero and ii less than or equal to 255. Moreover a typical RGBA implementation provides for such an 8 bit alpha number for each of what are known as the red channel the green channel and the blue channel as such each pixel has i a red R color value whose corresponding transparency value can be set to any integer value between 0x00 and 0xFF ii a green G color value whose corresponding transparency value can be set to any integer value between 0x00 and 0xFF and iii a blue B color value whose corresponding transparency value can be set to any integer value between 0x00 and 0xFF. And certainly other pixel data formats could be used as deemed suitable by those having skill in the relevant art for a given implementation.

When merging an extracted persona with content the above referenced persona extraction technology creates the above mentioned merged display in a manner consistent with these conventions in particular on a pixel by pixel i.e. pixel wise basis the merging is carried out using pixels from the captured video frame for which the corresponding alpha mask values equal 1 and otherwise using pixels from the content. Moreover it is noted that pixel data structures typically also include or are otherwise associated with one or more other values corresponding respectively to one or more other properties of the pixel where brightness is an example of one such property. In some embodiments the brightness value is the luma component of the image or video frame. In other embodiments the brightness value may be the pixel values of one of an R G or B color channel or other similar color space e.g. gamma compressed RGB or R G B or YUV or YCbCr as examples . In other embodiments the brightness value may be a weighted average of pixel values from one or more color channels.

Furthermore a given video camera typically has one or more adjustable video capture settings that affect the characteristics of the pixels that are stored by the video camera for various video frames. Two common examples of such settings are exposure and gain. In the context of a given pixel exposure refers in general to the amount of light that is captured by i.e. let into the pixel and is dependent on multiple factors including the duration of time for which the pixel is left open to gather light as well as the nature and dimensions of the opening i.e. aperture though which such light is gathered during that time. Gain refers in general to the degree to which the signal that is received in connection with a given pixel is amplified and often has both analog and digital stages referred to respectively in the art as analog gain and digital gain. And certainly there are many other adjustable video capture settings that could be listed here as exposure and gain are but two examples. Moreover the definitions that are provided in this disclosure in connection with these and other video capture and video processing settings are meant to aid and guide the reader and are not meant to exclude all or part of any respective definitions that are attributed to such terms and their equivalents by those having ordinary skill in the relevant art.

This disclosure describes systems and methods for iterative adjustment of video capture settings based on identified persona. As described in an example a video camera is capturing video frames that are each made up of two mutually exclusive sets of pixels 1 the pixels that are identified as being part of an identified and later extracted persona in the frame and that are referred to at times herein as persona pixels and 2 all other pixels in the frame which are referred to at times herein as non persona pixels background pixels and the like. The present systems and methods use the persona pixels and not the non persona pixels as the basis for adjusting one or more adjustable video capture settings of the video camera as it continues to capture additional frames that also include the persona. This pixel selectivity enhances what is known in the art as the dynamic range of the persona that is extracted from the video and later merged with content as described above. Because the non persona pixels are discarded by the time the persona has been merged with the content anyway deeming them irrelevant to the video capture settings of the video camera is commensurate with their irrelevance to the merged persona and content result that is displayed to end users.

One embodiment takes the form of a method that includes receiving frames of video data that are being captured by a video camera and that are representative of an ongoing scene where the video camera has one or more adjustable video capture settings. The method also includes identifying a persona in one or more of the received frames at least in part by identifying in each such frame a set of pixels that is representative of the persona in the frame and that does not include any pixels representative of the background of the frame. The method also includes selecting based collectively on the brightness values of the pixels in the identified set of pixels of one or more respective frames a respective adjustment command for one or more of the adjustable video capture settings. The method also includes outputting the selected adjustment commands to the video camera for use by the video camera in continuing to capture video data representative of the ongoing scene.

Another embodiment takes the form of a video capture controller that includes various modules configured to carry out the various functions described in the preceding paragraph. In the embodiment the video capture controller includes a frame receiving module configured to carry out the receiving function a persona identification module configured to carry out the identifying function a video capture adjustment module configured to carry out the selecting function and a command output module configured to carry out the outputting function.

The preceding paragraph is an example of the fact that in the present disclosure various elements of one or more of the described embodiments are referred to as modules that carry out i.e. perform execute and the like various functions described herein. As the term module is used herein each described module includes or at least has access to any necessary hardware e.g. one or more processors microprocessors microcontrollers microchips application specific integrated circuits ASICs field programmable gate arrays FPGAs memory devices and or one or more of any other type or types of devices and or components deemed suitable by those of skill in the relevant art in a given context and or for a given implementation. Each described module also includes or at least has access to any necessary instructions executable for carrying out the one or more functions described as being carried out by the particular module where those instructions could take the form of or at least include hardware i.e. hardwired instructions firmware instructions software instructions and or the like stored in any non transitory computer readable medium deemed suitable by those of skill in the relevant art.

In at least one embodiment identifying in a given frame the set of pixels that is representative of the persona in the given frame and that does not include any pixels representative of the background of the given frame involves i obtaining a binary alpha mask for the given frame where the binary alpha mask has a a first data value e.g. 1 one associated with each pixel that is representative of the persona and b a second i.e. different data value e.g. 0 zero associated with each pixel that is in the given frame but that is not representative of the persona and ii configuring the identified set of pixels for the given frame to include only those pixels that are associated with the first data value in the corresponding binary alpha mask. In at least one such embodiment obtaining the binary alpha mask for the given frame involves generating the binary alpha mask by processing image depth data of the given frame. In at least one other such embodiment obtaining the binary alpha mask for the given frame involves receiving the binary alpha mask from a video processor that generated the alpha mask by processing image depth data of the given frame.

In at least one embodiment selecting based collectively on the brightness values of the pixels in the identified set of pixels of one or more respective frames a respective adjustment command for one or more of the adjustable video capture settings involves i generating a statistical model reflecting a distribution of those brightness values along a brightness spectrum and ii selecting a respective adjustment command for one or more of the adjustable video capture settings based at least in part on the statistical model. In at least one such embodiment the statistical model includes a histogram. In at least one other such embodiment identifying in a given frame the set of pixels that is representative of the persona in the given frame and that does not include any pixels representative of the background of the given frame involves i generating a binary alpha mask for the given frame by processing image depth data of the given frame where the binary alpha mask has a a first data value e.g. 1 one associated with each pixel that is representative of the persona and b a second i.e. different data value e.g. 0 zero associated with each pixel that is in the given frame but that is not representative of the persona and ii configuring the identified set of pixels for the given frame to include only those pixels that are associated with the first data value in the corresponding binary alpha mask.

In at least one embodiment the adjustable video capture settings include one or more of exposure aperture shutter speed frame rate gain analog gain digital gain zoom optical zoom and digital zoom.

In at least one embodiment the method further includes selecting based at least in part on the pixels in the identified set a respective adjustment command for one or more video processing settings. In at least one such embodiment the video processing settings include one or more of white balance contrast gain vibrance hue saturation color temperature and sharpness.

In at least one embodiment the video camera has an associated application programming interface API and selecting one or more of the adjustment commands involves selecting one or more of the adjustment commands from the API.

In at least one embodiment at least one of the selected adjustment commands specifies a particular value for the corresponding adjustable video capture setting.

In at least one embodiment at least one of the selected adjustment commands specifies a relative change to the corresponding adjustable video capture setting.

Another embodiment takes the form of a method that includes receiving a video frame sequence being captured by a video camera receiving a sequence of image depth data corresponding to the video frame sequence and generating a series of persona alpha masks by processing the video frame sequence and the sequence of image depth data. The method also includes generating a sequence of histograms based on the video frame sequence and the sequence of persona alpha masks selecting video capture adjustments based on the histograms and transmitting the video capture adjustments to the video camera for adjusting the continued capturing of the video frame sequence.

In at least one embodiment the persona alpha masks are binary in that each persona alpha mask has i a first data value e.g. 1 one associated with each pixel in the corresponding frame that is representative of the persona and ii a second data value e.g. 0 zero associated with each pixel that is in the corresponding frame but that is not representative of the persona. In at least one embodiment the histograms reflect distributions along a brightness spectrum of pixels from the video frame sequence that match corresponding persona alpha masks. In at least one embodiment selecting video capture adjustments based on the brightness distribution data models involves time filtering the brightness distribution data models to select video capture adjustments that gradually adjust one or more video capture settings of the video camera. In at least one embodiment the video capture adjustments pertain to one or both of exposure and gain.

The above overview is provided by way of example and not limitation as those having ordinary skill in the relevant art may well implement the disclosed systems and methods using one or more equivalent components structures devices and the like and may combine and or distribute certain functions in equivalent though different ways without departing from the scope and spirit of this disclosure.

The video camera may include any combination of hardware and executable instructions e.g. executable software instructions capable of performing the video camera functions described herein. In an embodiment the video camera is configured to capture one or more frames of video data that are representative of an ongoing scene . The video camera has one or more adjustable video capture settings that control various aspects and properties of the video camera and of the video data captured thereby. An example arrangement of video camera is described below with reference to .

The VCC may include any combination of hardware and executable instructions e.g. executable software instructions capable of performing the VCC functions described herein. In an embodiment as depicted in the VCC includes a frame receiving module a persona identification module a video capture adjustment module and a command output module . In an embodiment the frame receiving module is configured to carry out the functions described below in connection with step of . In an embodiment the persona identification module is configured to carry out the functions described below in connection with step of . In an embodiment the video capture adjustment module is configured to carry out the functions described below in connection with step of . In an embodiment the command output module is configured to carry out the functions described below in connection with step of .

As depicted in the example configuration of the video camera communicates with the VCC and in particular with the frame receiving module as shown generally at the frame receiving module communicates with the persona identification module as shown generally at the persona identification module communicates with the video capture adjustment module as shown generally at the video capture adjustment module communicates with the command output module as shown generally at and the VCC and in particular the command output module communicates with the video camera as shown generally at . Those having skill in the art will appreciate that the VCC may include additional and or different modules that the modules and may perform additional and or different functions and or additional and or different communication paths and links could be implemented as the arrangement described herein is provided by way of example and not limitation.

In various embodiments the video system also includes a video processor capable of performing the video processing functions described herein. In at least one embodiment the video processor has one or more adjustable video processing settings that control various aspects and properties of the video processor. The video processor may take the form of or at least include any combination of hardware and or software incorporated into the video camera the VCC and or any other component of the video system regardless of whether such component is depicted in .

In the example that is depicted in the video system further includes a computing device that conveys content data e.g. a multiple slide presentation to a merging system as shown generally at . In an example configuration the computing device is or at least includes a computer e.g. a laptop computer that is being used by a presenter whose persona is identified and extracted to the exclusion of the background from video of the scene by the video system . In various different examples the video camera may be a peripheral device of the computing system e.g. an installed video camera a video camera connected to the computing system via a Universal Serial Bus USB connection or the like .

The merging system is configured and programmed to carry out the functions described above and elsewhere herein in connection with merging the persona with the content to produce merged content and further to convey i.e. send transmit and the like shown generally at the merged content to a distribution system along with corresponding audio data metadata and or any other data necessary or otherwise useful or helpful in properly presenting the merged content on end user devices .

The distribution system is configured and programmed to perhaps among other functions then convey as shown generally at the merged content received from the merging system for presentation of the merged content on an arbitrary number of end user devices shown generally at . In various different example arrangements the distribution system is or at least includes a platform that provides online meeting services generally with some representative and non limiting examples being 1 the GoToMeeting service provided by Citrix Systems Inc. of Santa Clara Calif. and 2 the WebEx service provided by Cisco Systems Inc. of San Jose Calif. just to name a few. In some example arrangements the merging system and the distribution system each have a structure and arrangement similar to that of the computing system that is described below in connection with . In some cases a single server or server system having such a structure and arrangement includes both the merging system and the distribution system . And certainly other architectures could be selected by those of skill in the art.

The communication interface may include any number of wired communication interfaces e.g. USB Ethernet and or the like and or wireless communication interfaces e.g. cellular Wi Fi Bluetooth RF infrared and or the like for engaging in wired or wireless communication respectively. The processor may include one or more processors of any types deemed suitable by those of skill in the relevant art with some representative examples including microprocessors central processing units CPUs digital signal processors DSPs image signal processors ISPs and the like. The data storage may include one or more instances of one or more types of non transitory data storage deemed suitable by those having skill in the relevant art with some representative examples including read only memory ROM random access memory RAM disk based storage flash memory optical storage technology and the like. In at least one embodiment the data storage contains the program instructions that are executable by the processor for carrying out at least the video camera functions described herein.

The image sensor module may be or include any combination of hardware and executable instructions e.g. executable software instructions capable of and configured for performing the image sensor module functions described herein. In an embodiment the image sensor module includes a hardware image sensor configured to convert an optical image into an electronic signal. In an embodiment the hardware image sensor takes the form of or includes a charge coupled device CCD sensor which itself includes an array of light sensitive cells that each correspond to a respective pixel of a frame captured by the video camera . Light that strikes a respective cell in the CCD sensor is held as a small electrical charge that is then transferred through one or more output nodes to be converted to a voltage that represents the amount of light captured by the respective cell. These voltage signals are then typically sent to another component external to the sensor for analog to digital conversion. The CCD sensor may take other forms as well.

In an embodiment the hardware image sensor takes the form of or includes a metal oxide semiconductor CMOS sensor. Similar to the CCD sensor the CMOS sensor contains an array of light sensitive cells that each correspond to a respective pixel of a frame captured by the video camera and light that strikes a respective cell in the CCD sensor is held as a small electrical charge. However the CMOS sensor differs from the CCD sensor in that unlike the electrical charges of the respective cells of the CCD sensor that are transferred through one or a limited number of output nodes for conversion to respective voltage signals the electrical charges of the respective cells of the CMOS sensor are converted to voltages by the respective cells. The CMOS sensor may take other forms as well. Those having skill in the art will appreciate that the image sensor module may take other forms as well without departing from the scope and spirit of this disclosure.

The control register module may be or include any combination of hardware and executable instructions e.g. executable software instructions capable of and configured for performing the control register module functions described herein. In an embodiment the control register module includes one or more hardware registers having associated hardware register addresses that are associated with respective adjustable video capture settings of the video camera . As a general matter the processor may control various settings including various adjustable video capture settings of the video camera by 1 writing values to various registers of the control register module at various times via the system bus in order to maintain or change the state of various settings and 2 reading values from various registers of the control register module at various times to effect i.e. enforce implement operate according to and the like the current values of various settings. As is known in the art such writing and reading operations would typically be carried out according to a clock cycle by which the various communications and operations of the various components of the video camera are coordinated.

In an embodiment each register has a hardware address that consists of a first number of bits e.g. 8 bits and each instance of register data i.e. each register data value consists of second number of bits e.g. 16 bits . Accordingly in an embodiment where the system bus is 8 bits 1 byte wide one 8 bit register address transfer and two 8 bit register data transfers are required when writing data to or reading data from a register at a given address. In this example embodiment a write operation a.k.a. sequence begins with the processor perhaps acting in response to control communication received by the video camera via the communication interface from e.g. the VCC sending a write start command e.g. a write start bit to the control register module which then responds with an acknowledgement. Thereafter the processor sends an 8 bit register address and a 16 bit register data value as two 8 bit register data transfers as well perhaps as a write stop indicator e.g. a write stop bit to the control register module which accordingly writes the provided register data value to the specified register address. Similarly in this example embodiment a read operation a.k.a. sequence begins with the processor sending a read start command e.g. a read start bit to the control register module which then responds with an acknowledgement. Thereafter the processor sends an 8 bit register address to the control register module which responds by sending the register data value as two 8 bit transfers from the specified register address to the processor perhaps followed by a read stop indicator e.g. a read stop bit . And certainly other approaches could be implemented by those of skill in the art in various different contexts.

As mentioned above the video camera has one or more adjustable video capture settings. Some representative example adjustable video capture settings include an exposure the quantity of light reaching the image sensor module an aperture the size nature and dimensions of the opening through which light travels to the image sensor module a shutter speed the length of time for which a shutter of the video camera is open while the image sensor module is capturing a frame a frame rate the rate at which the video camera e.g. the processor reads entire pixel arrays i.e. frames from the image sensor module an analog gain the increasing or amplification of the electrical charge of a respective cell prior to analog to digital conversion a digital gain the increasing of a pixel value after analog to digital conversion an optical zoom the focal length of a lens of the video camera and a digital zoom a cropped area of a frame captured by the video camera being stored for display as having increased dimensions and thus decreased resolution as compared with that same area in the larger context of the entire frame . And certainly many other adjustable video capture settings could be listed here as the preceding list is provided by way of example and not limitation.

In some instances one or more of the adjustable video capture settings as they are described in this disclosure will be labeled i.e. named differently and or will be realized as a combination of multiple other e.g. lower level settings for example an adjustable exposure setting may be realized as a combination of one or more of shutter speed aperture and frame rate being themselves adjustable. And certainly other examples could be provided as known to those of skill in the art. An extension of this concept i.e. the abstracting of multiple e.g. lower level commands or settings into one or more e.g. higher level commands or settings that is known to those of skill in the art is known as an API and is discussed below.

In an embodiment one or more of the adjustable video capture settings of the video camera are adjustable via an API associated with the video camera . As a general matter an API is a set of routines i.e. function calls and the like that may be used by an application to carry out lower level functions of in this case the video camera . Different APIs may expose respectively different lower level functions in the form of different provided routines. For example some APIs allow changing a setting to a particular specified value while other APIs allow changing a setting in a relative manner e.g. increase decrease up down greater smaller etc. A relative change option could allow specification of the amount by which to change the value of the setting e.g. increase by 5 down by 0.04 or may only allow specification of the relative direction of the change among other possible implementations. Some APIs allow selection among a pre defined collection of values for groups of respective settings for example a respective API may allow for selection of a camera operation mode e.g. portrait mode macro mode sports mode night mode or the like in which a plurality of settings e.g. an aperture frame rate and or gain are set to respective values associated with the respective mode. Some APIs may allow adjustment of values for specific registers in a corresponding control register module. Those having skill in the art will recognize that APIs take other forms as well.

In addition to the one or more adjustable video capture settings one or more post processing aka video processing functions may be performed by the VCC and or one or more other processing entities. Such functions may be associated and or controlled by one or more adjustable video processing settings with some representative examples including a white balance global adjustment of the intensities of the colors to render neutral tones accurately a contrast ratio of the luminance of the brightest color in a frame to that of the darkest color a gain a vibrance saturation of lower saturated colors a hue similarity to or difference from references such as standard red green blue and yellow a saturation a difference between a color and gray relative to the brightness of the color a color temperature the temperature of an ideal black body radiator that radiates light of comparable hue to that of the light source and or sharpness e.g. edge contrast . And certainly many other adjustable video processing a.k.a. post processing or video post processing settings could be listed here as the preceding list is provided by way of example and not limitation.

At step the VCC identifies the persona in one or more of the received frames at least in part by identifying in each such frame a set of pixels that is representative of the persona in the frame and that does not include any pixels representative of the background of the frame. In general the captured video comprises a background portion and a foreground portion where the background portion may comprise a wall outdoor scene or any other background scene and the foreground portion may comprise a human user or presenter. Persona identification is performed to identify the foreground portion such that the user image may be extracted and displayed without the background pixel data. In some embodiments the persona identification module may be used to analyze i depth information ii image pixel information or both to generate a plurality of foreground background probability maps. The maps may then be aggregated into a single probability map that is then processed by the persona identification module which may utilize a graph cut algorithm an active contour algorithm an active shape algorithm or a combination thereof to identify the pixels of an image frame that correspond to a user persona. The above documents that are incorporated by reference provide additional examples of persona extraction.

In at least one embodiment step involves i obtaining a binary alpha mask for the given frame where the binary alpha mask has a a first data value e.g. 1 one associated with each pixel that is representative of the persona and b a second different data value e.g. 0 zero associated with each pixel that is in the given frame but that is not representative of the persona and ii configuring the identified set of pixels for the given frame to include only those pixels that are associated with the first data value in the corresponding binary alpha mask. In at least one such embodiment step involves generating the binary alpha mask by processing image depth data of the given frame in at least one other such embodiment step involves receiving the binary alpha mask from a video processor that generated the mask by processing image depth data of the given frame.

At step the VCC selects based collectively on the brightness values of the pixels in the identified set of pixels of one or more respective frames a respective adjustment command for one or more of the adjustable video capture settings of the video camera . In at least one embodiment step involves i generating a statistical model e.g. a histogram reflecting a distribution of those brightness values along a brightness spectrum and ii selecting a respective adjustment command for one or more of the adjustable video capture settings based at least in part on the statistical model.

At step the VCC outputs the adjustment commands that were selected at step to the video camera for use by the video camera in continuing to capture video data representative of the ongoing scene . In at least one embodiment step involves selecting one or more of the adjustment commands from an API associated with the video camera . In at least one embodiment at least one of the selected adjustment commands specifies a particular value for the corresponding adjustable video capture setting. In at least one embodiment at least one of the selected adjustment commands specifies a relative change to the corresponding adjustable video capture setting.

In at least one embodiment the VCC and or another entity also selects based at least in part on the pixels in the identified set a respective adjustment command for one or more video processing settings. In at least one such embodiment the one or more video processing settings include one or more of white balance contrast gain vibrance hue saturation color temperature and sharpness.

At step the computing system receives a video frame sequence being captured by a video camera such as the video camera .

At step the computing system receives a sequence of image depth data corresponding to the video frame sequence that was received at step .

At step the computing system generates a series of persona alpha masks by processing the video frame sequence that was received at step and the sequence of image depth data that was received at step . In at least one embodiment the persona alpha masks generated at step are binary having i a first data value e.g. 1 one associated with each pixel in the corresponding frame that is representative of the persona and ii a second i.e. different data value e.g. 0 zero associated with each pixel that is in the corresponding frame but that is not representative of the persona.

At step the computing system generates a sequence of histograms based on the video frame sequence that was received at step and the sequence of persona alpha masks that was generated at step . In at least one embodiment the generated histograms reflect distributions along a brightness spectrum of pixels from the video frame sequence that was received at step that match corresponding persona alpha masks that were generated at step .

At step the computing system selects video capture adjustments based on the histograms that were generated at step . In at least one embodiment selecting the video capture adjustments based on the histograms involves time filtering the histograms to select video capture adjustments that gradually adjust one or more video capture settings of the video camera. In at least one embodiment the video capture adjustments pertain to one or both of exposure and gain.

At step the computing system transmits the video capture adjustments that were selected at step to the video camera for adjusting the continued capturing of the video frame sequence.

Although features and elements are described above in particular combinations those having ordinary skill in the art will appreciate that each feature or element can be used alone or in any combination with the other features and elements without departing from the scope and spirit of the present disclosure.

