---

title: Determination of device body location
abstract: In some implementations, a mobile device can analyze motion sensor data during a voice call to determine whether the mobile device is on a stationary object or worn on a user's body (e.g., in the lap or pocket of a user of the mobile device). The mobile device can adjust the transmit power level of the telephony transceiver during the voice call based on the determination.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09432954&OS=09432954&RS=09432954
owner: Apple Inc.
number: 09432954
owner_city: Cupertino
owner_country: US
publication_date: 20130607
---
Mobile devices often include telephony features that allow users to receive and place voice calls over a wireless network. For example modern smartphones include wireless transceivers that allow the smartphones to receive and place telephone calls over cellular voice and or data networks e.g. CDMA 2G 3G 4G LTE etc. . These wireless transceivers can transmit at different power levels. Transmitting at high power levels can improve the quality of the voice calls. Transmitting at low power levels may be required when the mobile device is worn on or near the user s body to comply with government regulations.

In some implementations a mobile device can analyze motion sensor data during a voice call to determine whether the mobile device is on a stationary object e.g. table or worn on a user s body e.g. in the lap or pocket of a user of the mobile device . The mobile device can adjust the transmit power level of the telephony transceiver during the voice call based on the determination.

Particular implementations provide at least the following advantages The user can experience better quality voice calls when the mobile device is on a stationary object e.g. a table during voice call because the voice call can be transmitted using a high transmission power level.

Details of one or more implementations are set forth in the accompanying drawings and the description below. Other features aspects and potential advantages will be apparent from the description and drawings and from the claims.

In some implementations a mobile device can be configured with one or more motion sensors. For example a motion sensor can be an accelerometer gyroscope or other type of motion sensor. In some implementations the mobile device can be configured with telephony components that allow a user to make and receive telephone calls. For example telephony components can include one or more radio frequency transceivers that are configured to access one or more radio access technologies e.g. GSM UMTS 2G 3G LTE etc. .

In some implementations the mobile device can be configured to adjust the transmission power of the telephony components when the mobile device connects to a voice call. For example the mobile device can be configured to adjust the transmission power based on whether the mobile device is on a stationary object e.g. a table or worn on the user s body e.g. on the user s lap in the user s pocket etc. .

In some implementations the mobile device can be configured to sample the filtered motion signal for a period of time i.e. the sample period . For example the mobile device can be configured to collect samples of the motion signal over the sample period. The mobile device can sample and store into a buffer five 5 seconds of the filtered motion signal for example. In some implementations the motion signal samples can be analyzed to determine the variance of the motion signal during the sample period. For example the motion signal sample can be passed through a variance filter or other variance calculating function that will determine the variance of the motion signal samples.

Once the variance of the motion signal samples is determined the variance can be compared to a variance threshold value to determine if the variance threshold value has been exceeded by the motion signal samples. For example if the variance of the motion signal samples is greater than the motion variance threshold then the mobile device can determine that the mobile device is located or positioned on the user s body . If the variance of the motion signal samples is not greater than the motion variance threshold then the mobile device can compare the amount of time that has passed since the voice call was connected e.g. T T to a threshold period of time . For example if the threshold period of time has elapsed since the voice call was connected and the variance of the motion signal as determined from the motion signal samples has not exceeded the variance threshold within the threshold period of time then the mobile device can determine that the mobile device is located on a stationary object and not located on the user.

If the threshold period of time has not elapsed since the call was connected then the mobile device can collect another set of motion signal samples and determine whether the variance of the motion signal samples exceeds the variance threshold . Collecting samples and comparing the variance of the samples to the variance threshold can continue until the threshold period of time has elapsed and the on object location of the mobile device is determined. If the variance of a set of motion signal samples exceeds the variance threshold before the threshold period of time has elapsed then an on user location location of the mobile device can be determined.

In some implementations the mobile device can determine that the threshold period of time has elapsed using a counter. For example if the threshold period of time is one minute and the sample period is ten seconds then the mobile device can determine that the threshold period of time has elapsed after six motion signal samples have been taken. Thus in some implementations each time the mobile device determines whether the threshold period of time has elapsed the mobile device can increment a counter e.g. starting from zero . Once the counter has reached a number n equal to the threshold period of time divided by the sample period n threshold period sample period then the mobile device can determine that the mobile device is on a stationary object as described above.

In some implementations when a voice call is connected the mobile device can be configured to adjust the transmit power of the telephony components of the mobile device to a low power level as if it has determined that the mobile device is being worn on the user s body. For example the mobile device can be configured to default or initialize to the on body location. After the threshold period of time has passed and if the variance of the motion signal never exceeds the threshold variance then the mobile device can determine that the mobile device is located or positioned on a stationary object and can increase the transmit power to a high power level.

In some implementations the mobile device can be configured to start in an unknown state when a voice call is connected . In some implementations the mobile device can be configured to start in the on body state when a call is connected . Once the call is connected the mobile device can monitor the movement of the mobile device to determine a stationary object or on body position for the mobile device as described above with reference to . For example if an on stationary object location e.g. on table is determined then the state machine can transition from unknown state to on object state . If an on body location e.g. on user s lap in user s pocket is determined then the state machine can transition from unknown state to on body state .

In some implementations the state machine can include an in hand state for transitioning between the on object state and on body state . For example if the mobile device is on an object such as a table the user will likely pick up the mobile device before putting the mobile device on the user s body e.g. in the user s pocket on the user s lap . If the mobile device is on the user s body the user will likely pick up the mobile device before putting the mobile device on a stationary object. In either case the mobile device will be held in the user s hand during the transition from an on body location to an on object location or from an on object location to an on body location.

Similarly the state machine can be configured with an in hand state for transitioning between on object state and on body state . For example once in the on object state or the on body state the mobile device can continue analyzing motion data e.g. motion signal from the mobile device s motion sensor. If the motion data indicates a pattern of motion consistent with the mobile device being picked up or held in hand the state machine can transition from on object state or on body state to in hand state .

In some implementations when the state machine indicates that the mobile device is in the in hand state the mobile device can perform process to determine whether to transition to on object state or on body state . For example when the state machine is in the in hand state the mobile device can perform steps of process to determine whether and when to transition from the in hand state to the on body state or on object state .

At step the mobile device can determine whether the mobile device is on the user s body or on an object. For example the mobile device can perform process of and or use state machine of to determine whether the mobile device is located on the user s body e.g. in pocket on lap etc. or on a stationary object e.g. table desk floor etc. .

At step the mobile device can adjust the transmit power of the mobile device based on the location or position of the mobile device. For example if the mobile device is on the user s body the mobile device can reduce the transmit power of the mobile device to a predetermined low power level. If the mobile device is on a stationary object e.g. away from the user s body then the mobile device can increase the transmit power of the mobile device to a predetermined high power level.

One or more Application Programming Interfaces APIs may be used in implementations described herein. An API is an interface implemented by a program code component or hardware component hereinafter API implementing component that allows a different program code component or hardware component hereinafter API calling component to access and use one or more functions methods procedures data structures classes and or other services provided by the API implementing component. An API can define one or more parameters that are passed between the API calling component and the API implementing component.

An API allows a developer of an API calling component which may be a third party developer to leverage specified features provided by an API implementing component. There may be one API calling component or there may be more than one such component. An API can be a source code interface that a computer system or program library provides in order to support requests for services from an application. An operating system OS can have multiple APIs to allow applications running on the OS to call one or more of those APIs and a service such as a program library can have multiple APIs to allow an application that uses the service to call one or more of those APIs. An API can be specified in terms of a programming language that can be interpreted or compiled when an application is built.

In some implementations the API implementing component may provide more than one API that provide access to different aspects of the functionality implemented by the API implementing component. For example one API of an API implementing component can provide a first set of functions and can be exposed to third party developers and another API of the API implementing component can be hidden not exposed and provide a subset of the first set of functions and also provide another set of functions such as testing or debugging functions which are not in the first set of functions. In other implementations the API implementing component may itself call one or more other components via an underlying API and thus be both an API calling component and an API implementing component.

An API defines the language and parameters that API calling components use when accessing and using specified features of the API implementing component. For example an API calling component accesses the specified features of the API implementing component through one or more API calls or invocations embodied for example by function or method calls exposed by the API and passes data and control information using parameters via the API calls or invocations. The API implementing component may return a value through the API in response to an API call from an API calling component. While the API defines the syntax and result of an API call e.g. how to invoke the API call and what the API call does the API may not reveal how the API call accomplishes the function specified by the API call. Various API calls are transferred via the one or more application programming interfaces between the calling API calling component and an API implementing component. Transferring the API calls may include issuing initiating invoking calling receiving returning or responding to the function calls or messages in other words transferring can describe actions by either of the API calling component or the API implementing component. The function calls or other invocations of the API may send or receive one or more parameters through a parameter list or other structure. A parameter can be a constant key data structure object object class variable data type pointer array list or a pointer to a function or method or another way to reference a data or other item to be passed via the API.

Furthermore data types or classes may be provided by the API and implemented by the API implementing component. Thus the API calling component may declare variables use pointers to use or instantiate constant values of such types or classes by using definitions provided in the API.

Generally an API can be used to access a service or data provided by the API implementing component or to initiate performance of an operation or computation provided by the API implementing component. By way of example the API implementing component and the API calling component may each be any one of an operating system a library a device driver an API an application program or other module e.g. the API implementing component and the API calling component may be the same or different type of module from each other . API implementing components may in some cases be embodied at least in part in firmware microcode or other hardware logic.

In some implementations an API may allow a client program to use the services provided by a Software Development Kit SDK library. In other embodiments an application or other client program may use an API provided by an Application Framework. In these implementations the application or client program may incorporate calls to functions or methods provided by the SDK and or provided by the API or use data types or objects defined in the SDK and provided by the API. An Application Framework may in these implementations provide a main event loop for a program that responds to various events defined by the Framework. The API allows the application to specify the events and the responses to the events using the Application Framework. In some implementations an API call can report to an application the capabilities or state of a hardware device including those related to aspects such as input capabilities and state output capabilities and state processing capability power state storage capacity and state communications capability etc. and the API may be implemented in part by firmware microcode or other low level logic that executes in part on the hardware component.

The API calling component may be a local component e.g. on the same data processing system as the API implementing component or a remote component e.g. on a different data processing system from the API implementing component that communicates with the API implementing component through the API over a network. An API implementing component may also act as an API calling component e.g. it may make API calls to an API exposed by a different API implementing component and an API calling component may also act as an API implementing component by implementing an API that is exposed to a different API calling component.

The API may allow multiple API calling components written in different programming languages to communicate with the API implementing component thus the API may include features for translating calls and returns between the API implementing component and the API calling component. However the API may be implemented in terms of a specific programming language. An API calling component can in one embedment call APIs from different providers such as a set of APIs from an OS provider and another set of APIs from a plug in provider and another set of APIs from another provider e.g. the provider of a software library or creator of the another set of APIs.

For example the API implementing component can include additional functions methods classes data structures and or other features that are not specified through the API and are not available to the API calling component . The API calling component may be on the same system as the API implementing component or may be located remotely and accesses the API implementing component using the API over a network. While illustrates a single API calling component interacting with the API other API calling components which may be written in different languages or the same language than the API calling component may use the API .

The API implementing component the API and the API calling component may be stored in a machine readable medium which includes any mechanism for storing information in a form readable by a machine e.g. a computer or other data processing system . For example a machine readable medium includes magnetic disks optical disks random access memory read only memory flash memory devices etc.

Note that the Service B has two APIs and one of which Service B API receives calls from and returns values to Application and the other Service B API receives calls from and returns values to Application . Service A which can be for example a software library makes calls to and receives returned values from OS API and Service B which can be for example a software library makes calls to and receives returned values from both OS API and OS API . Application makes calls to and receives returned values from OS API .

Sensors devices and subsystems can be coupled to the peripherals interface to facilitate multiple functionalities. For example a motion sensor a light sensor and a proximity sensor can be coupled to the peripherals interface to facilitate orientation lighting and proximity functions. Other sensors can also be connected to the peripherals interface such as a global navigation satellite system GNSS e.g. GPS receiver a temperature sensor a biometric sensor magnetometer or other sensing device to facilitate related functionalities.

A camera subsystem and an optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips. The camera subsystem and the optical sensor can be used to collect images of a user to be used during authentication of a user e.g. by performing facial recognition analysis.

Communication functions can be facilitated through one or more wireless communication subsystems which can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. The specific design and implementation of the communication subsystem can depend on the communication network s over which the computing device is intended to operate. For example the computing device can include communication subsystems designed to operate over a GSM network a GPRS network an EDGE network a Wi Fi or WiMax network and a Bluetooth network. In particular the wireless communication subsystems can include hosting protocols such that the device can be configured as a base station for other wireless devices.

An audio subsystem can be coupled to a speaker and a microphone to facilitate voice enabled functions such as speaker recognition voice replication digital recording and telephony functions. The audio subsystem can be configured to facilitate processing voice commands voiceprinting and voice authentication for example.

The I O subsystem can include a touch surface controller and or other input controller s . The touch surface controller can be coupled to a touch surface . The touch surface and touch surface controller can for example detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with the touch surface .

The other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of the speaker and or the microphone .

In one implementation a pressing of the button for a first duration can disengage a lock of the touch surface and a pressing of the button for a second duration that is longer than the first duration can turn power to the computing device on or off. Pressing the button for a third duration can activate a voice control or voice command module that enables the user to speak commands into the microphone to cause the device to execute the spoken command. The user can customize a functionality of one or more of the buttons. The touch surface can for example also be used to implement virtual or soft buttons and or a keyboard.

In some implementations the computing device can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations the computing device can include the functionality of an MP3 player such as an iPod . The computing device can therefore include a 36 pin connector that is compatible with the iPod. Other input output and control devices can also be used.

The memory interface can be coupled to memory . The memory can include high speed random access memory and or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices and or flash memory e.g. NAND NOR . The memory can store an operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks.

The operating system can include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations the operating system can be a kernel e.g. UNIX kernel . In some implementations the operating system can include instructions for determining whether the mobile device is on a user s body or on a stationary object and adjusting the transmit power of the mobile device accordingly. For example operating system can implement the mobile device locating and transmission power adjustment features as described with reference to .

The memory can also store communication instructions to facilitate communicating with one or more additional devices one or more computers and or one or more servers. The memory can include graphical user interface instructions to facilitate graphic user interface processing sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GNSS Navigation instructions to facilitate GNSS and navigation related processes and instructions and or camera instructions to facilitate camera related processes and functions. The memory can store software instructions to facilitate other processes and functions such as the mobile device locating and transmission power adjustment processes and functions as described with reference to .

The memory can also store other software instructions such as web video instructions to facilitate web video related processes and functions and or web shopping instructions to facilitate web shopping related processes and functions. In some implementations the media processing instructions are divided into audio processing instructions and video processing instructions to facilitate audio processing related processes and functions and video processing related processes and functions respectively.

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. The memory can include additional instructions or fewer instructions. Furthermore various functions of the computing device can be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

