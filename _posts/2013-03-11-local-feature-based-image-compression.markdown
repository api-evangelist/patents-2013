---

title: Local feature based image compression
abstract: The use of local feature descriptors of an image to generate compressed image data and reconstruct the image using image patches that are external to the image based on the compressed image data may increase image compression efficiency. A down-sampled version of the image is initially compressed to produce an encoded visual descriptor. The local feature descriptors of the image and the encoded visual descriptor are then obtained. A set of differential feature descriptors are subsequently determined based on the differences between the local feature descriptors of the input image and the encoded visual descriptor. At least some of the differential feature descriptors are compressed to produce encoded feature descriptors, which are then combined with the encoded visual feature descriptor produce image data. The image data may be used to select image patches from an image database to reconstruct the image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09349072&OS=09349072&RS=09349072
owner: Microsoft Technology Licensing, LLC
number: 09349072
owner_city: Redmond
owner_country: US
publication_date: 20130311
---
Image compression reduces the sizes of image files for ease of storage and transfer. Some image compression schemes may rely on statistical correlation among pixels of an image to achieve compression. Techniques such as increasing the number of prediction directions as well as the use of partitions and transforms have increased compression coding efficiency of these image compression schemes. The use of such techniques often significantly increases the complexity of both image encoders and image decoders for relative small gains in coding efficiency.

Other image compression schemes may take into account visual redundancy in addition to statistical redundancy. These schemes may compress an image by identifying and utilizing features within the image to achieve higher coding efficiency. For example edge based and segmentation based coding schemes take into account the human eye s ability to identify edges and group similar regions of an image. However the lack of development in edge and segmentation detection tools may limit the efficacy and efficiency of these image compression schemes.

Described herein are techniques for using local feature descriptors of an image to generate compressed image data as well as reconstructing the image using image patches that are external to the image based on the compressed image data. The characterization of an image region of the image by a local feature descriptor may be invariant to scale and rotation. During compression of an image an encoder may obtain at least two types of descriptors from the image. A first type is a visual descriptor in the form of a down sampled version of the image with embedded key feature descriptors. A second type is a group of differential feature descriptors that are formed from the visual descriptor and local feature descriptors of the image. These two types of descriptors are combined to generate compressed image data.

During the reconstruction of the image from the compressed image data a decoder may recreate the local feature descriptors of the image based on the visual descriptor and the differential feature descriptors in the compressed image data. The decoder may further perform descriptor based matching using the recreated local feature descriptors to retrieve candidate image patches from an image database. The decoder may integrate these candidate image patches to form a reconstruction of the image.

Accordingly the techniques make use of visual correlation among multiple images to compress and reconstruct an image. Such techniques may reduce the amount of visual redundancy and provide efficient compression of images without resorting to the increased computational complexity associated with current image compression schemes.

This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Described herein are techniques for using local feature descriptors of an image to generate compressed image data as well as reconstructing the image using image patches that are external to the image based on the compressed image data. The characterization of an image region of the image by a local feature descriptor may be invariant to scale and rotation. One example type of local feature descriptors may be Scale Invariant Feature Transform SIFT descriptors of the image.

During compression of an image an encoder may obtain at least two types of descriptors from the image. A first type is a visual descriptor in the form of a down sampled version of the image with embedded key feature descriptors. A second type is a group of differential feature descriptors that are formed from the visual descriptor and local feature descriptors of the image. These two types of descriptors are combined to generate compressed image data.

During the reconstruction of the image from the compressed image data a decoder may recreate the local feature descriptors of the image based on the visual descriptor and the differential feature descriptors in the compressed image data. The decoder may further perform descriptor based matching using the recreated local feature descriptors to retrieve candidate image patches from an image database. The decoder may integrate these candidate image patches to form a reconstruction of the image.

Accordingly the techniques make use of visual correlation among multiple images to compress and reconstruct an image. Such techniques may reduce the amount of visual redundancy and provide efficient compression of images without resorting to the increased encoding computational complexity associated with current image compression schemes. Examples of techniques for using local feature vectors to generate compressed image data and recreate the image based on the compressed image data in accordance with various embodiments are described below with reference to .

The image encoder may be implemented by a computing device . Likewise the image decoder may be implemented by a computing device . In some embodiments each of the computing device and the computing device may be a general purpose computer such as a desktop computer a tablet computer a laptop computer one or more servers and so forth. However in other embodiments the computing device may be one of a smart phone a game console a personal digital assistant PDA or any other electronic device that interacts with a user via a user interface.

The image encoder may produce compressed image data for an input image . The compressed image data may include an encoded visual descriptor and encoded feature descriptors . The visual descriptor may be a down sampled version of the input image that is embedded with key feature descriptors. The encoded feature descriptors may include differential feature descriptors that are partially derived from local feature descriptors of the input image . The local feature descriptors may characterize corresponding image regions in the input image in which the local feature descriptors are invariant to the scaling and rotation of the input image . In some embodiments the local feature descriptors may be Scale Invariant Feature Transform SIFT descriptors of the image. In other embodiments the local feature descriptors may be Speeded Up Robust Feature SURF descriptors. In additional embodiments the local feature descriptors may be other types of local feature descriptors.

The image decoder may receive the compressed image data from the image encoder via a network that connects the computing device to the computing device . The network may be a local area network LAN a larger network such as a wide area network WAN and or a collection of networks such as the Internet. Protocols for network communication such as TCP IP may be used to implement the network . The network may be implemented using various wireless communication interface technology e.g. cellular Wi Fi Ultrawideband Bluetooth satellite transmissions and or the like. Alternatively or concurrently the network may also be implemented using various wired communication technology such as LAN Ethernet WAN Ethernet a universal serial bus USB a high speed serial bus and or the like.

The image decoder may decode each of the encoded visual descriptor and the encoded feature descriptors . The visual descriptor and the differential feature descriptors that are produced by the decoding may be used by the image decoder to recreate the local feature descriptors of the input image . Subsequently the image decoder may perform descriptor based matching using the recreated local feature descriptors to select candidate image patches from an image database . The image database may include image patches that are stored in one or more cloud servers. Alternatively or concurrently the image database may include image patches that are stored on a computing device such as the computing device or the computing device . The image decoder may further integrate the candidate image patches to create an output image . In various embodiments the output image may be identical or similar in appearance to the input image .

In this way the use of the compressed image data may enable the computing device to transfer the input image to the computing device while reducing the amount of network bandwidth used to accomplish the transfer. As such network congestion due to the transfer of large image files may be reduced or eliminated. While each of the image encoder and the image decoder are illustrated as standalone components each of these components may also be integrated with other applications in other embodiments. For example the image encoder may be part of an image generation or editing application and the image decoder may be part of a web browser or image viewing application. Further while the image encoder and the image decoder are illustrated as being implemented by separate devices these components may be implemented by a single computing device in some embodiments.

The computing device may include a network interface one or more processors memory and or user controls that enable a user to interact with the router. The network interface may include wireless and or wireless communication interface components that enable the computing device to transmit and receive data via a network. In various embodiments the wireless interface component may include but is not limited to cellular Wi Fi Ultra wideband UWB Bluetooth satellite transmissions and or so forth. The wired interface component may include a direct input output I O interface such as an Ethernet interface a serial interface a Universal Serial Bus USB interface and or so forth. As such the computing device may have network capabilities. For example the computing device may exchange data with other electronic devices e.g. laptops computers servers etc. via one or more networks such as the Internet.

The memory may be implemented using computer readable media such as computer storage media. Computer readable media includes at least two types of computer readable media namely computer storage media and communication media. Computer storage media includes volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other tangible medium that may be used to store information for access by a computing device. In contrast communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transmission mechanism. As defined herein computer storage media does not include communication media.

The memory of the computing device may implement the image encoder . The image encoder may include a visual description extraction module a visual description encoder module a differential feature descriptor module a feature descriptor encoder module and a multiplex module . Additionally the memory may also store a user interface module and a data store .

The visual description extraction module may generate a visual descriptor in the form of a down sampled image . The down sampled image may carry image information such as outline shape color and objects information. For example the generation of the down sampled image may include filtering of the input image as represented by the following equation 1 in which G represents a discrete low pass filter with the support T 1. The kernel of the low pass filter may be a Gaussian function with variance . Following filtering the visual description extraction module may generate the down sampled image from the input image as follows 2 2 . . . 2 2 in which n may represent an integer. Parameter r may represent the down sampling ratio at one dimension. In some embodiments r may be set as 2 or 4. In other embodiments r may be set as 8 or 16. As such the down sample ratio of the down sampled image may be 64 1 or 256 1 with respect to the input image .

The visual description encoder module may compress the down sampled image to produce the encoded visual descriptor . In some embodiments the down sampled image may be compressed using High Efficiency Video Coding HEVC . However in other embodiments other lossless or lossy image compression algorithms may be applied to compress the down sampled image such as Joint Photographic Expert Group JPEG or JPEG 200.

The differential feature descriptor module may generate differential feature descriptors . In order to do so the differential feature descriptor module may initially obtain a corresponding set of local feature descriptors for each of the input image and the encoded visual descriptor . A set of local feature descriptors may characterize the features around key points that are extracted from a series of smoothed and re sampled images of an original image. The use of the series of smoothed and re sampled images may enable basic salient features to become more apparent and fine features to become less apparent with each successive scale level. In at least some embodiments the local feature descriptors of an image may be SIFT descriptors.

In some embodiments the differential feature descriptor module may obtain the local feature descriptors of an image by initially generating a Gaussian scale space for the image. The Gaussian scale space for the image may be generated by repeatedly applying the filtering algorithm represented in equation 1 and the down sampling algorithm represented in equation 2 with a parameter r to the image. The Gaussian scale space generated for an image may include a set of generated images I . . . I . . . I . . . I in which n 0 n N may represent an octave index in the space that indicates that the input image is down sampled n times. Further k 0 k K may be a filtering index in an octave and the visual description extraction module may generate differences of the images in the Gaussian scale spaced by D I I.

Indeed Dmay constitute a Laplacian scale space L x with x x y s in which s may be a scale index and is defined as s n k 1 K 2 with K 3 and 1 k K 2. As such the differential feature descriptor module may detect feature points in the Laplacian scale space L x by the maxima and the minima in D. In at least one embodiment if a sample is the largest or smallest of its first set of predetermined number of neighbors e.g. eight neighbors and a second set of predetermined number of neighbors e.g. nine neighbors respectively in Dand D the differential feature descriptor module may consider the sample to be a feature point in the image.

Further given a vector xin which x x y s the differential feature descriptor module may derive the sub pixel and a finer scale index to xby fitting a 3D quadratic to L x . Accordingly the Taylor expansion of L x at xmay be described as follows 

The differential feature descriptor module may also calculate an orientation of a SIFT descriptor in a region such as the region of I around x y . The size of region may be set as W W in which W 9 . The differential feature descriptor module may calculate the local image gradients dand dusing a centered derivative mask 1 0 1 . Further by partitioning an orientation arctan d d evenly into multiple bins such as 36 bins covering 360 degrees the differential feature descriptor module may calculate a histogram with 36 bins as follows 

The differential feature descriptor module may also extract a feature vector in a region of I around x y . The size of the region may be set as W W in which W square root over 2 B 3 . The differential feature descriptor module may first rotate the region to which provides rotation invariance for the SIFT descriptors. The factor square root over 2 may provide a complete rectangle region after rotation. In some embodiments the rectangle region may be further partitioned into uniform sub regions such as 4 4 sub regions. In such an instance B 4 and each sub region has 9 samples. Additionally the differential feature descriptor module may evenly partition the gradient orientation into multiple bins such as 8 bins. Thus for a sub region j of such an instance an 8 dimension vector vmay be generated by using the following equation 

Thus by performing the techniques described above on the input image the differential feature descriptor module may obtain local feature descriptors for the input image . However in order to obtain local feature descriptors for the encoded visual descriptor the differential feature descriptor module may initially use a visual descriptor decoder component to decompress the visual descriptor into a decompressed image . However any local feature descriptors that are extracted from the decompressed image may not correlate with the local feature descriptors that are directly extracted from the input image at location x y and scale index s. Accordingly the differential feature descriptor module may first up sample the decompressed image to the same resolution as the input image . Subsequently the differential feature descriptor module may performed the techniques described above on the decompressed image to obtain a set of corresponding local feature descriptors for the up sampled decompressed image .

The differential feature descriptor module may generate the differential feature descriptors by using the feature vectors of the local feature descriptors as the prediction for the local feature descriptors . Accordingly for a local feature descriptor e.g. SIFT descriptor S x y s v extracted from the input image the differential feature descriptor module may generate a prediction vector in the scale space by using location x y scale sand orientation . The differential feature descriptor module may evaluate the prediction using the normalized mean square error MSE as follows 

Thus by implementing the above techniques the differential feature descriptor module may generate the differential feature descriptors . The differential feature descriptors may represent the differences between the local feature descriptors of the encoded and the local feature descriptors .

The feature descriptor encoder module may compress at least some of the differential feature descriptors into encoded feature descriptors . In various embodiments the action performed by the feature descriptor encoder module may be dependent on the octaves of the differential feature descriptors . For octaves with scale index s logr the feature descriptor encoder module may exclude feature vector v from coding and instead is designated as the reconstruction. For octaves with scale index logr s s

For those of the differential feature descriptors that are to be compressed the feature descriptor encoder module may first compress the locations of the differential feature descriptors . The number of differential feature descriptors to be compressed may be determined based on the number of locations. Scale indices and orientations may then be respectively compressed in raster scan order. Subsequently the residual feature vectors are coded and compressed one by one. In at least one embodiment the feature descriptor encoder module may use a fixed length lossless compression algorithm to perform the compressions.

Locations may indicate positions at which orientations and feature vectors are calculated. Second locations may be used to calculate the transformation between retrieved image patches and the input image. Thus given x 1 y 1 . . . x M y M as the set of all feature descriptor locations in which M may represent a total number the feature descriptor encoder module may first generate a binary matrix Bof the same size as the input image for which each element is defined as 

Furthermore smay indicate the region sizes to calculate and v respectively. For every s the feature descriptor encoder module may code its octave index n by a first predetermined number of bits e.g. 3 bits and quantize s n into 16 levels at precision of 1 16 and code by a second predetermined number of bits e.g. 4 bits . The feature descriptor encoder module may further quantize every into 128 levels at precision of 45 16 3 degrees and code by a third predetermined number of bits e.g. 7 bits as indicates the rotation invariance of differential feature descriptors . Therefore for a differential feature descriptor sand coding may take 14 bits.

In the compression of the residual feature vector the feature descriptor encoder module may first generate a binary string in which each bit in the binary string indicates whether a corresponding residual feature vector is zero or not after transform and quantization. This feature descriptor encoder module may also compress the string via binary arithmetic coding. Given a residual feature vector the differential feature descriptor module may code the residual feature vector as two 8 8 matrices 

The multiplex module may integrate the encoded visual descriptor and the encoded feature descriptors into the image data . In various embodiments the image data may be a stream of data that is transferrable to other computing devices over the network .

The user interface module may enable a user to interact with the modules of the image encoder and applications using a user interface not shown . The user interface may include a data output device e.g. visual display audio speakers and one or more data input devices. The data input devices may include but are not limited to combinations of one or more of keypads keyboards mouse devices touch screens microphones speech recognition packages and any other suitable devices or other electronic software selection methods. For example the user interface module may enable the user to select input images to be encoded by the image encoder or create the input images to be encoded by the image encoder .

In alternative embodiments the functions that are performed by one or more modules that are stored in the memory may be implemented in hardware rather than as software instructions. For example one or more fixed hardware logic circuits may implement the functions performed by the one or more modules stored in the memory .

The data store may store the inputs to the image encoder intermediate products and or end products that are generated by the image encoder . These entities may include the input image the down sampled image the differential feature descriptors the local feature descriptors the decompressed image the local feature descriptors and or the image data . The data store may also store data for other applications such as a photo editing software that is implemented on the computing device .

The image decoder may interact with an image database that stores a database of images. The images in the image database may be categorized according to local feature descriptors. For example a local feature encoder may have been used to generate millions of local feature descriptors that describe aspects of the images in the image library . In various embodiments the local feature descriptors may be trained into a predetermined number of visual words by an approximate k means algorithm. The visual words in the image database may be further organized into k d trees to facilitate nearest neighbor searching. As such a visual word v may be assigned to each local feature V of all images in the image database according to the nearest Euclidian distance. Additionally the visual words of the images in the image database may be organized into groups accordingly to overlap between the visual words.

As shown with respect to the candidate groups in example 1 in the origin may be the central local feature descriptor. The region of this local feature descriptor may completely cover the regions of member local feature descriptors 2 . . . 5 . In at least one embodiment if the number of member local feature descriptors is more than 3 the member local feature descriptors may be bundled as a group. However this bundling is not based on additional detection of stable regions. Furthermore a polar coordinate system may be used for one dimensional geometric modeling. As further shown in the example the polar axis may align with the orientation of the central local feature descriptor. The polar plane may be partitioned into R sectors ordered counterclockwise. A sector index r may be assigned to each member local feature descriptor in the group. Accordingly such a geometric verification may allow for rotation invariance. Therefore the local feature descriptors in the image database may be extended as S x s v r V by adding visual word v and sector index r.

The computing device may include a network interface one or more processors memory and or user controls that enable a user to interact with the router. The network interface may include wireless and or wireless communication interface components that enable the computing device to transmit and receive data via a network. In various embodiments the wireless interface component may include but is not limited to cellular Wi Fi Ultra wideband UWB Bluetooth satellite transmissions and or so forth. The wired interface component may include a direct I O interface such as an Ethernet interface a serial interface a Universal Serial Bus USB interface and or so forth. As such the computing device may have network capabilities. For example the computing device may exchange data with other electronic devices e.g. laptops computers servers etc. via one or more networks such as the Internet.

The memory may be implemented using computer readable media such as computer storage media. Computer readable media includes at least two types of computer readable media namely computer storage media and communication media. Computer storage media includes volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other non transmission medium that may be used to store information for access by a computing device. In contrast communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transmission mechanism. As defined herein computer storage media does not include communication media.

The memory of the computing device may implement the image decoder . The image decoder may include a de multiplex module a visual descriptor decoder module a differential feature decoder module a descriptor generation module a matching module and an integration module . Additionally the memory may also store a user interface module and a data store .

The de multiplex module may receive the image data via the network interface . In turn the de multiplex module may parse the encoded visual descriptor and the encoded feature descriptors from the image data . The visual descriptor decoder module may decompress the encoded visual descriptor to produce a decompressed image which is the reconstructed visual descriptor . For example the encoded visual descriptor may be decompressed using JPEG JPEG 200 or HEVC depending on the original compression algorithm.

The differential feature decoder module may decompress the encoded feature descriptors to recreate the differential feature descriptors . In various embodiments the decompression may be achieved using an inverse of the techniques implemented by the feature descriptor encoder module . Accordingly the differential feature decoder module may produce the differential feature descriptors tilde over Z .

The descriptor generation module may generate reconstructed local feature descriptors from the reconstructed visual descriptor and differential feature descriptors tilde over Z . The reconstructed visual descriptor may be initially up sampled by the descriptor generation module to the original resolution of the input image . In at least one embodiment the up sampling may be accomplished using a convolution with Lanczos kernel L as follows 10 in which k is the up sample ratio. The resulting image may be used by the descriptor generation module to generate the vectors v based on the decoded tilde over Z producing the set of approximated local feature descriptors tilde over Z as follows 11 

In other words the descriptor generation module may extract the local feature descriptors while taking into consideration the scale and orientation information at the key point positions denoted by hacek over Z . Accordingly the two sets tilde over Z and Z may form the set of local feature descriptors tilde over Z which are the reconstructed local feature descriptors as follows 12 .

The matching module may retrieve correlated image patches from the image database for reconstructing an image by performing visual word based matching. In order to do so the matching module may quantize the local feature descriptors into visual words. In various embodiments the matching module may use an approximate k means algorithm to training the local feature descriptors into the visual words. The matching module may then compare the visual words from the local feature descriptors to the visual words that correspond to the images in the image database . As shown in example G S i on the left side is a query group of visual words that may match a candidate group of visual words G S j on the right side that corresponds to an image in the image database . In such a scenario the matching may be scored as follows . 13 in which E G G may be the number of matched visual words between two groups. According to the one dimensional geometric model in the polar coordinate system matched visual words are to have the same sector index. Thus since E G G is the number of matched visual words but with different sector indices the matching module may subtract that number from E G G .

The matching module may use an inverted file index to find groups of visual words that match. In various embodiments each visual word may have an entry in an index that contains the list of images in which the visual word appears. Because a group of visual words are used there may be multiple members in each group. In various embodiments the number of member visual words in a group may be limited to 128. Further the number of sectors in the one dimensional geometric model may be set between 4 and 8.

In the example the matching module may first use the central visual word 1 in the query group find groups with the same central visual word in the inverted file index and every candidate group may be scored. As shown in the example there may be four pairs of matching member visual words. Thus E G G may have the value of 5 after counting the central visual word. But the visual word 4 has sector index 6 and 3 in the two groups respectively. Because of this inconsistency E G G may be equal to 1 . Thus the matching module may calculate the matching score E G G of the two groups as 4 . This score may be assigned to the image in the image database that contains the candidate group. After all query groups are matched the matching module may select multiple images with one or more high sum scores as partial duplicate images.

The matching module may further perform image patch retrieval based on the selected partial duplicate images. Since the number of images is limited every query local feature descriptor may be directly matched with those on the partial duplicate images. Accordingly the matching module may fully utilize the discriminative power of the local feature descriptors. For example for a query descriptor S if the Euclidean distance of the closest neighbor is smaller than distance of the second closest neighbor the closest neighbor may be considered a correct match to the query descriptor S.

Further for a pair of matched descriptors tilde over S and S the matching module may find two image patches Pand Pin an up sampled visual descriptor and an image that contains S according to their respective locations scales and orientations. In some instances it may be difficult to estimate the transformation between them by matching corresponding pixels because Pmay be too blurred. In such instance the matching module may use the locations of query local feature descriptors as extracted from an original image.

In various embodiments the matching module may find local feature descriptors located in the patches Pand P. The correspondences may be established by matching every local feature descriptor in Pwith those in P. The matching module may further use the locations of the matched pairs of local feature descriptors to estimate the transformation H between Pand Pby using the Random Sample Consensus RANSAC algorithm. In at least one embodiment a designated pairs of locations e.g. four pairs may be randomly selected to calculate H. The rest of the pairs of locations may be used to verify H. If a pair of locations fits with H the matching module may count the pair as an inlier otherwise it is an outlier. In this way the matching module may obtain H with the maximum number of inliers.

In scenarios in which the scales of local feature descriptors are small the retrieved patches may also be small. For example the pairs of matched descriptors may be less than four. In this example the matching module may directly write the transformation H from the locations scales and orientations of tilde over S and S. As such H between Pand Pmay be assumed to be a combination of translation rotation and scaling as follows 

In some instances the image patches that are retrieved by the matching module for reconstructing an image may be directly sent to the integration module for stitching into the image. However in other instances the matching module may detect that one or more of the image patches include partial content that do not exist in the image to be reconstructed. Accordingly the matching module may segment and remove such partial content prior to stitching.

In various embodiments the matching module may perform graph based segmentation to detect the extraneous partial content for removal. The matching module may model an image patch circumflex over P as an undirected graph G V E in which a vertex v V corresponds to a pixel and an edge v v E connects a pair of neighboring vertices v v V. Each edge may be associated with a non negative weight w v v to measure the dissimilarity between two vertices. For two neighboring regions C1 C2V the largest weights within these two regions may be denoted as wand w respectively. The minimum weight of the boundary between C1 and C2 may be denoted as W. The matching module may perform a segmentation between C1 and C2 as follows 

The integration module may stitch image patches that are retrieved for reconstructing an image together to form the image such as the output image . In various embodiments the integration module may stitch the image patches in increasing order according to their MSE values with respect to the down sampled image . For example after the removal of inconsistent regions the integration module may stitch the image patch tilde over P to other image patches. In some instances since tilde over P may be from an image with different illumination than one or more other image patches directly stitching it to the up sampled image will result in block artifacts.

Thus instead of directly stitching tilde over P the integration module may apply a gradient field g to tilde over P in order to interpolate the corresponding image patch f in . This operation may formulated as the following minimization problem min with . 17 in which may be the region of tilde over P to stitch an may be the boundary of in and is the gradient operator. The solution to equation 17 may be the unique solution of the Poisson equation with Dirichlet boundary conditions as follows div over with . 18 in which may be the Laplacian operator and div g may be the divergence of g. Solving Poisson equation 18 is an intensive computing process. However solving the Poisson equation is equivalent to solving the following Laplace equation 0 over with . 19 in which the image patch to stitch is f tilde over P tilde over f .

Nevertheless instead of solving either the Poisson equation 18 or the Laplace equation 19 the integration module may in some instances adopt the membrane interpolation method in which tilde over f is approximated by smoothly spreading the discrepancies along the boundary to the entire region . Accordingly the interpolation value tilde over f may be written as 

The user interface module may enable a user to interact with the modules of the image decoder and other applications using a user interface not shown . The user interface may include a data output device e.g. visual display audio speakers and one or more data input devices. The data input devices may include but are not limited to combinations of one or more of keypads keyboards mouse devices touch screens microphones speech recognition packages and any other suitable devices or other electronic software selection methods. For example the user interface module may enable the user to select input images to be encoded by the image encoder or create the input images to be encoded by the image encoder .

In alternative embodiments the functions that are performed by one or more modules that are stored in the memory may be implemented in hardware rather than as software instructions. For example one or more fixed hardware logic circuits may implement the functions performed by the one or more modules stored in the memory .

The data store may store the inputs to the image decoder intermediate products and or end products that are generated by the image decoder . These entities may include the image data the decompressed image and or the reconstructed local feature descriptors . The data store may also store data for other applications such as an image viewing software a web browser a word processing application etc. that is implemented on the computing device .

In some embodiments the tasks performed by the image decoder may be implemented in parallel or partially in parallel by multiple computing devices rather than as performed by a single computing device . For example functions as such image patch retrieval and image patch segmentation may be implemented in parallel or partially in parallel by multiple devices. Further the matching of image patches in the image database to local feature descriptors in the image data may be performed in parallel using multiple computing devices.

At block the image encoder may extract a visual descriptor in the form of a down sampled image from an input image . The down sampled image may include key feature descriptors that carry image information such as outline shape color and objects information.

At block the image encoder may compress the down sampled image into the encoded visual descriptor . In some embodiments the down sampled image may be compressed using HEVC . However in other embodiments additional lossless or lossy image compression algorithms may be applied to compress the down sampled image such as JPEG or JPEG 2000.

At block the image encoder may obtain local feature descriptors of the input image and the encoded visual descriptor . In various embodiments each set of local feature descriptors may be extracted by developing a series of smoothed and re sampled images of a starting image. The use of the series of smoothed and re sampled images may enable basic salient features to become more apparent and the fine features to become less apparent with each successive scale level. In at least some embodiments each set of the local feature descriptors may include SIFT descriptors.

At block the image encoder may determine a set of differential feature descriptors based on the differences between the local feature descriptors of the input image and the local feature descriptors of the encoded visual descriptor . At block the image encoder may compress at least some of the differential feature descriptors in the set to produce the encoded feature descriptors . For example the image encoder may compress the entire set of encoded feature descriptors or exclude one or more encoded feature descriptors from the set before performing the compression.

At block the image encoder may combine the encoded visual descriptor and the encoded feature descriptors to produce image data . In various embodiments the image data may be a stream of data that is transferrable to other computing devices over the network .

At block the image encoder may decompress the encoded visual descriptor . In various embodiments the decompression may be performed using a JPEG JPEG 2000 HEVC or another decompression algorithm. The decompression by the image encoder may generate the decompressed image .

At block the image encoder may upscale the decompressed image into an up sampled image. In this way the local feature descriptors that are eventually produced from the decompressed image may correlate in scale with the local feature descriptors that are produced from the input image .

At block the image encoder may extract the local feature descriptors from the up sampled image. In various embodiments the local feature descriptors may be extracted by at least generating a Gaussian scale space for the up sampled image and then identify feature vectors of the up sampled image in the Gaussian scale space.

At block the image encoder may generate the differential feature descriptors by using the feature vectors of the local feature descriptors from the up sampled image as the prediction for the local feature descriptors . In various embodiments the differential feature descriptors may be obtained by evaluating the prediction using the normalized mean square error MSE .

At block the image encoder may discard one or more nonessential differential feature descriptor from the set of differential feature descriptors . In some embodiments the image encoder may discard one or more differential feature descriptors when their octaves are below a predetermined threshold as such differential feature descriptors are unlikely to result in the retrieval of relevant image patches for image reconstruction.

At block the image encoder may compress locations of the remaining differential feature descriptors . In various embodiments locations may indicate positions in an image at which orientations and feature vectors are calculated. At block the image encoder may compress scale indices in the remaining differential feature descriptors . At block the image encoder may compress orientations of the remaining differential feature descriptors . In at least one embodiment the scale indices and the orientations may be respectively compressed in raster scan order.

At block the image encoder may compress residual feature vectors of the remaining differential feature descriptors . In various embodiments the feature descriptor encoder module may use a fixed length lossless compression algorithm to perform the compressions.

At block the image decoder may receive image data that includes an encoded visual descriptor and encoded feature descriptors . In at least one embodiment the image decoder may receive the image data from the computing device via the network .

At block the image decoder may extract the encoded visual descriptor and the encoded feature descriptors from the image data . In various embodiments the extraction may be performed via a de multiplexer component of the image decoder .

At block the image decoder may decompress the encoded visual descriptor to produce the decompressed image . In various embodiments the encoded visual descriptor may be decompressed using JPEG JPEG 2000 or HEVC depending on the original compression algorithm.

At block the image decoder may decompress the encoded feature descriptors to reproduce the differential feature descriptors . In various embodiments the decompression of the encoded feature descriptors may be achieved using an inverse of the techniques implemented by the image encoder .

At block the image decoder may reconstruct the local feature descriptors based on the decompressed image and the differential feature descriptors . In various embodiments the reconstruction may include up sampling the decompressed image to the resolution of the input image and then obtain the local feature descriptors while taking into consideration the scale and orientation information at the key point positions in the decompressed image .

At block the image decoder may obtain image patches from the image database by performing image matching based on the local feature descriptors. In various embodiments the image decoder may derive visual words from the local feature descriptors and compare such visual words to visual words that describe image patches in the image database to obtain the matching image patches .

At block the image decoder may integrate the image patches into the output image that visually resembles the input image . For example the output image and the input image may have little or no visually perceptible differences in appearance. In various embodiments the image patches may be stitched together in increasing order according to their MSE values with respect to the down sampled image .

At block the image decoder may select candidate images from an image database by matching visual words that describe the candidate image patches to the visual words that describe the local feature descriptors . The local feature descriptors are derived from the image data . In various embodiments the image decoder may use an approximate k means algorithm to training the local feature descriptors into the visual words and further use an inverted file index to find groups of visual words that match.

At block the image decoder may retrieve the candidate images as image patches from the image database . The image database may include image patches that are stored in one or more cloud servers. Alternatively or concurrently the image database may include image patches that are stored on a computing device such as the computing device or the computing device .

At block the image encoder may perform graph based segmentation to remove extraneous content from one or more of the image patches. Extraneous content may be inconsistent content in an image patch that is determined to produce block artifacts in the output image .

The techniques described herein make use of visual correlation among multiple images to compress and reconstruct an image. Accordingly such techniques may reduce the amount of visual redundancy and provide efficient compression of images without resorting to the increased computational complexity associated with current image compression schemes.

In closing although the various embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed subject matter.

