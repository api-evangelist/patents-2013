---

title: Remote access encoding
abstract: A method and apparatus for remote access encoding is provided. Remote access encoding may include receiving, at a host device, from a client device, a remote access request indicating a portion of a display area of an operating environment of the host device, rendering a representation of the portion of the display area, wherein rendering includes generating rendered content including a plurality of frames, generating an encoded block, and transmitting encoded content to the client device, wherein the encoded content includes the encoded block. Generating the encoded block may include identifying a current block from a plurality of blocks in a current frame, wherein the current frame is one of the plurality of frames, determining whether the current block is a static block, determining a coding quality for encoding the current block, and determining whether to encode the current block as a skipped block.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09225979&OS=09225979&RS=09225979
owner: GOOGLE INC.
number: 09225979
owner_city: Mountain View
owner_country: US
publication_date: 20130130
---
A computing device may execute an operating environment that may include elements such as file system objects and executing applications. The computing device may render a representation of the operating environment as part of a graphical interface which may be output for presentation on a display unit of the computing device. The representation of the operating environment may be rendered at a defined display resolution which may define a display area included in the graphical interface. Accordingly it would be advantageous to provide high resolution video transmitted over communications channels having limited bandwidth.

An aspect is a method for remote access encoding. Remote access encoding may include receiving at a host device from a client device a remote access request indicating a portion of a display area of an operating environment of the host device rendering a representation of the portion of the display area wherein rendering includes generating rendered content including a plurality of frames generating an encoded block and transmitting encoded content to the client device wherein the encoded content includes the encoded block. Generating the encoded block may include identifying a current block from a plurality of blocks in a current frame wherein the current frame is one of the plurality of frames determining whether the current block is a static block determining a coding quality for encoding the current block and determining whether to encode the current block as a skipped block.

Another aspect is another method for remote access encoding. Remote access encoding may include receiving at a host device from a client device a remote access request indicating a portion of a display area of an operating environment of the host device rendering a representation of the portion of the display area wherein rendering includes generating rendered content including a plurality of frames generating an encoded block and transmitting encoded content to the client device wherein the encoded content includes the encoded block. Generating the encoded block may include identifying a current block from a plurality of blocks in a current frame wherein the current frame is one of the plurality of frames identifying a reference block from a plurality of blocks in a reference frame on a condition that the reference block is a high quality reference block and the current block is a static block encoding the current block as a skipped block and indicating that the skipped block is a high quality block and on a condition that the reference block is a low quality reference block and the current block is a static block encoding the current block as a skipped block and indicating that the skipped block is a low quality block.

Remote access technologies such as remote desktop or screen sharing may allow a computing device client to remotely access an operating environment of another computing device host . For example the host device may render a representation of a display area of the operating environment which may be associated with a defined resolution and may transmit the rendered output to the client device for presentation on a display unit of the client device. Rendering the representation of the display area may include for example encoding the content of the display area as a series of frames which may include video compression using one or more video compression schemes. Video compression schemes may include identifying temporal or spatial similarities between frames or between blocks in a frame and omitting repetitious information from the encoded output.

Content rendered for remote access may include significant areas of static content wherein corresponding portions of consecutive frames remain unchanged and corresponding pixel values are identical. For example elements of the operating environment such as a background or an out of focus window may remain static for two or more consecutive frames. Implementations of remote access encoding may improve coding efficiency and quality by increasing the likelihood that static content is compressed using high quality configuration and encoding blocks including static content as skipped blocks. Portions including static content can be identified using a quality oriented technique. In some implementations context information such as information indicating movement of a window within the operating environment of the host device may be used to identify portions to encode using high quality configuration.

The computing device may be a stationary computing device such as a personal computer PC a server a workstation a minicomputer or a mainframe computer or a mobile computing device such as a mobile telephone a personal digital assistant PDA a laptop or a tablet PC. Although shown as a single unit any one or more element of the communication device can be integrated into any number of separate physical units. For example the UI and processor can be integrated in a first physical unit and the memory can be integrated in a second physical unit.

The communication interface can be a wireless antenna as shown a wired communication port such as an Ethernet port an infrared port a serial port or any other wired or wireless unit capable of interfacing with a wired or wireless electronic communication medium .

The communication unit can be configured to transmit or receive signals via a wired or wireless medium . For example as shown the communication unit is operatively connected to an antenna configured to communicate via wireless signals. Although not explicitly shown in the communication unit can be configured to transmit receive or both via any wired or wireless communication medium such as radio frequency RF ultra violet UV visible light fiber optic wire line or a combination thereof. Although shows a single communication unit and a single communication interface any number of communication units and any number of communication interfaces can be used.

The UI can include any unit capable of interfacing with a user such as a virtual or physical keypad a touchpad a display a touch display a speaker a microphone a video camera a sensor or any combination thereof. The UI can be operatively coupled with the processor as shown or with any other element of the communication device such as the power source . Although shown as a single unit the UI may include one or more physical units. For example the UI may include an audio interface for performing audio communication with a user and a touch display for performing visual and touch based communication with the user. Although shown as separate units the communication interface the communication unit and the UI or portions thereof may be configured as a combined unit. For example the communication interface the communication unit and the UI may be implemented as a communications port capable of interfacing with an external touchscreen device.

The processor can include any device or system capable of manipulating or processing a signal or other information now existing or hereafter developed including optical processors quantum processors molecular processors or a combination thereof. For example the processor can include a general purpose processor a special purpose processor a conventional processor a digital signal processor DSP a plurality of microprocessors one or more microprocessor in association with a DSP core a controller a microcontroller an Application Specific Integrated Circuit ASIC a Field Programmable Gate Array FPGA a programmable logic array programmable logic controller microcode firmware any type of integrated circuit IC a state machine or any combination thereof. As used herein the term processor includes a single processor or multiple processors. The processor can be operatively coupled with the communication interface communication unit the UI the memory the instructions the power source or any combination thereof.

The memory can include any non transitory computer usable or computer readable medium such as any tangible device that can for example contain store communicate or transport the instructions or any information associated therewith for use by or in connection with the processor . The non transitory computer usable or computer readable medium can be for example a solid state drive a memory card removable media a read only memory ROM a random access memory RAM any type of disk including a hard disk a floppy disk an optical disk a magnetic or optical card an application specific integrated circuits ASICs or any type of non transitory media suitable for storing electronic information or any combination thereof. The memory can be connected to for example the processor through for example a memory bus not explicitly shown .

The instructions can include directions for performing any method or any portion or portions thereof disclosed herein. The instructions can be realized in hardware software or any combination thereof. For example the instructions may be implemented as information stored in the memory such as a computer program that may be executed by the processor to perform any of the respective methods algorithms aspects or combinations thereof as described herein. The instructions or a portion thereof may be implemented as a special purpose processor or circuitry that can include specialized hardware for carrying out any of the methods algorithms aspects or combinations thereof as described herein. Portions of the instructions can be distributed across multiple processors on the same machine or different machines or across a network such as a local area network a wide area network the Internet or a combination thereof.

The power source can be any suitable device for powering the communication device . For example the power source can include a wired power source one or more dry cell batteries such as nickel cadmium NiCd nickel zinc NiZn nickel metal hydride NiMH lithium ion Li ion solar cells fuel cells or any other device capable of powering the communication device . The communication interface the communication unit the UI the processor the instructions the memory or any combination thereof can be operatively coupled with the power source .

Although shown as separate elements the communication interface the communication unit the UI the processor the instructions the power source the memory or any combination thereof can be integrated in one or more electronic units circuits or chips.

A computing and communication device A B C can be for example a computing device such as the computing device shown in . For example as shown the computing and communication devices A B may be user devices such as a mobile computing device a laptop a thin client or a smartphone and computing and the communication device C may be a server such as a mainframe or a cluster. Although the computing and communication devices A B are described as user devices and the computing and communication device C is described as a server any computing and communication device may perform some or all of the functions of a server some or all of the functions of a user device or some or all of the functions of a server and a user device.

Each computing and communication device A B C can be configured to perform wired or wireless communication. For example a computing and communication device A B C can be configured to transmit or receive wired or wireless communication signals and can include a user equipment UE a mobile station a fixed or mobile subscriber unit a cellular telephone a personal computer a tablet computer a server consumer electronics or any similar device. Although each computing and communication device A B C is shown as a single unit a computing and communication device can include any number of interconnected elements.

Each access point A B can be any type of device configured to communicate with a computing and communication device A B C a network or both via wired or wireless communication links A B C. For example an access point A B can include a base station a base transceiver station BTS a Node B an enhanced Node B eNode B a Home Node B HNode B a wireless router a wired router a hub a relay a switch or any similar wired or wireless device. Although each access point A B is shown as a single unit an access point can include any number of interconnected elements.

The network can be any type of network configured to provide services such as voice data applications voice over internet protocol VoIP or any other communications protocol or combination of communications protocols over a wired or wireless communication link. For example the network can be a local area network LAN wide area network WAN virtual private network VPN a mobile or cellular telephone network the Internet or any other means of electronic communication. The network can use a communication protocol such as the transmission control protocol TCP the user datagram protocol UDP the internet protocol IP the real time transport protocol RTP the Hyper Text Transport Protocol HTTP or a combination thereof.

The computing and communication devices A B C can communicate with each other via the network using one or more a wired or wireless communication links or via a combination of wired and wireless communication links For example as shown the computing and communication devices A B can communicate via wireless communication links A B and computing and communication device C can communicate via a wired communication link C. Any of the computing and communication devices A B C may communicate using any wired or wireless communication link or links. For example a first computing and communication device A can communicate via a first access point A using a first type of communication link a second computing and communication device B can communicate via a second access point B using a second type of communication link and a third computing and communication device C can communicate via a third access point not shown using a third type of communication link. Similarly the access points A B can communicate with the network via one or more types of wired or wireless communication links A B. Although shows the computing and communication devices A B C in communication via the network the computing and communication devices A B C can communicate with each other via any number of communication links such as a direct wired or wireless communication link.

Other implementations of the computing and communications system are possible. For example in an implementation the network can be an ad hock network and can omit one or more of the access points A B. The computing and communications system may include devices units or elements not shown in . For example the computing and communications system may include many more communicating devices networks and access points.

The encoder can encode an input video stream such as the video stream shown in to generate an encoded compressed bitstream . In some implementations the encoder may include a forward path for generating the compressed bitstream . The forward path may include an intra inter prediction unit a transform unit a quantization unit an entropy encoding unit or any combination thereof. In some implementations the encoder may include a reconstruction path indicated by the broken connection lines to reconstruct a frame for encoding of further blocks. The reconstruction path may include a dequantization unit an inverse transform unit a reconstruction unit a loop filtering unit or any combination thereof. Other structural variations of the encoder can be used to encode the video stream .

For encoding the video stream each frame within the video stream can be processed in units of blocks. Thus a current block may be identified from the blocks in a frame and the current block may be encoded.

At the intra inter prediction unit the current block can be encoded using either intra frame prediction which may be within a single frame or inter frame prediction which may be from frame to frame. Intra prediction may include generating a prediction block from samples in the current frame that have been previously encoded and reconstructed. Inter prediction may include generating a prediction block from samples in one or more previously constructed reference frames. Generating a prediction block for a current block in a current frame may include performing motion estimation to generate a motion vector indicating an appropriate reference block in the reference frame.

The intra inter prediction unit may subtract the prediction block from the current block raw block to produce a residual block. The transform unit may perform a block based transform which may include transforming the residual block into transform coefficients in for example the frequency domain. Examples of block based transforms include the Karhunen Lo ve Transform KLT the Discrete Cosine Transform DCT and the Singular Value Decomposition Transform SVD . In an example the DCT may include transforming a block into the frequency domain. The DCT may include using transform coefficient values based on spatial frequency with the lowest frequency i.e. DC coefficient at the top left of the matrix and the highest frequency coefficient at the bottom right of the matrix.

The quantization unit may convert the transform coefficients into discrete quantum values which may be referred to as quantized transform coefficients or quantization levels. The quantized transform coefficients can be entropy encoded by the entropy encoding unit to produce entropy encoded coefficients. Entropy encoding can include using a probability distribution metric. The entropy encoded coefficients and information used to decode the block which may include the type of prediction used motion vectors and quantizer values can be output to the compressed bitstream . The compressed bitstream can be formatted using various techniques such as run length encoding RLE and zero run coding.

The reconstruction path can be used to maintain reference frame synchronization between the encoder and a corresponding decoder such as the decoder shown in . The reconstruction path may be similar to the decoding process discussed below and may include dequantizing the quantized transform coefficients at the dequantization unit and inverse transforming the dequantized transform coefficients at the inverse transform unit to produce a derivative residual block. The reconstruction unit may add the prediction block generated by the intra inter prediction unit to the derivative residual block to create a reconstructed block. The loop filtering unit can be applied to the reconstructed block to reduce distortion such as blocking artifacts.

Other variations of the encoder can be used to encode the compressed bitstream . For example a non transform based encoder can quantize the residual block directly without the transform unit . In some implementations the quantization unit and the dequantization unit may be combined into a single unit.

The decoder may receive a compressed bitstream such as the compressed bitstream shown in and may decode the compressed bitstream to generate an output video stream . The decoder may include an entropy decoding unit a dequantization unit an inverse transform unit an intra inter prediction unit a reconstruction unit a loop filtering unit a deblocking filtering unit or any combination thereof. Other structural variations of the decoder can be used to decode the compressed bitstream .

The entropy decoding unit may decode data elements within the compressed bitstream using for example Context Adaptive Binary Arithmetic Decoding to produce a set of quantized transform coefficients. The dequantization unit can dequantize the quantized transform coefficients and the inverse transform unit can inverse transform the dequantized transform coefficients to produce a derivative residual block which may correspond with the derivative residual block generated by the inverse transformation unit shown in . Using header information decoded from the compressed bitstream the intra inter prediction unit may generate a prediction block corresponding to the prediction block created in the encoder . At the reconstruction unit the prediction block can be added to the derivative residual block to create a reconstructed block. The loop filtering unit can be applied to the reconstructed block to reduce blocking artifacts. The deblocking filtering unit can be applied to the reconstructed block to reduce blocking distortion and the result may be output as the output video stream .

Other variations of the decoder can be used to decode the compressed bitstream . For example the decoder can produce the output video stream without the deblocking filtering unit .

The host device may execute an operating environment which may include an instance of an operating system and may be associated with an account such as a logged in user account. As shown a representation of the operating environment may include a display area . The display area may indicate a height and a width of the representation of the operating environment. For example the display area may be associated with a defined display resolution which may be expressed in physical units of measure such as millimeters or logical units of measure such as pixels. For example the display area may have a display resolution of 1920 width by 1080 height pixels. The host device may render the display area and may transmit the rendered content to the client device via the network . In some implementations the host device may render the content as a series of frames which may include an I frame followed by one or more P frames. The rendered content may be encoded and the encoded content may be transmitted to the client device . For example the rendered content may be encoded as shown in .

The client device may execute an operating environment which may include a remote access application . The client device may receive the rendered output from the host device via the network and may present the representation of the display area A via a graphical display unit of the client device .

In some implementations the client device may be configured to present the representation of the display area A at a display resolution that differs from the display resolution rendered by the host device . For example the client device may scale the rendered output for presentation via the graphical display unit of the client device . In some implementations the host device may receive an indication of the display resolution of the client device and may render the representation of the operating environment using the display resolution of the client device .

For example the host device may adjust the display resolution of the host device to match the display resolution of the client device and may render the representation of the display area at the adjusted display resolution. Adjusting the display resolution may cause unwanted interference with the operating environment of the host device .

In another example rendering the representation of the display are at the host device may include scaling or sampling the representation of the display area to generate output at the display resolution of the client device which may consume significant resources such as processing resources and may produce graphical artifacts.

Rendered video such as remote access video may include relatively large amounts of static content wherein pixel values remain static do not change from frame to frame. Static content may be compressed using high quality encoding. Quality and contextual metrics may be used to simplify and improve encoding performance. Implementations of remote access encoding may include initiating remote access at rendering content at encoding rendered content at and transmitting the encoded content at . Although not shown separately the client device may receive the encoded content may decode the content and may output the content to a local graphical display unit for presentation.

Remote access may be initiated at . Initiating remote access may include establishing a connection between the client device and the host device. The client device and the host device may exchange information for performing remote access. For example the host device may receive a remote access request from the client device.

The host device may render a representation rendered content of the display area or a portion of the display area of the operating environment of the host device at . In some implementations the host device may generate the rendered content as a sequence of frames. Each frame may include implicit or explicit information such as the request identifier offset information buffer information a timestamp or any other information relevant to the rendered sequence of frames.

The host device may encode the rendered content at . Encoding the rendered content may include identifying a current block at determining whether a block is a static block at determining a coding quality for encoding a current block at determining whether to encode the current block as a skipped block at or a combination thereof.

A current block of a current frame may be identified for encoding at . For example the representation of the display area of the operating environment may be rendered as video stream such as the vides stream shown in and the encoding may include block based encoding wherein a block of a frame of the video stream may be encoded based on for example a reference block in a previously encoded reference frame.

Remote access encoding may include determining whether a block is a static block at . In some implementations a portion or portions of a rendered display area may be static static content from frame to frame. A block in a frame that includes content that is the same as the content of a corresponding reference block may be referred to as a static block. In some implementations static blocks may be identified based on differences between blocks of a current frame and corresponding blocks of an unencoded raw frame corresponding to the reference frame identified for encoding the current frame. Blocks for which the difference between the current block and the corresponding block is within a threshold which may be zero may be identified as static blocks and may be assigned a zero motion vector. In some implementations static blocks may be identified prior to instead of or as part of performing motion estimation.

In some implementations identifying static blocks may include using information indicating movement of an element of the operating environment. For example the movement information may indicate motion of a window in the operating environment or motion such as scrolling of content within a window of the operating environment such that the content changes location within the frame but otherwise remains static. The motion information may be used identify a non zero motion vector indicating the difference in location of the element between the current frame and the reference frame. Blocks including the static content may be identified as static blocks and may be assigned the non zero motion vector.

Remote access encoding may include determining a coding quality for encoding a current block at . In some implementations the coding quality of an encoded block may indicate differences between a current frame raw frame and a corresponding reconstructed frame. For example the coding quality may be measured based on a sum of absolute differences SAD in the transform domain or spatial domain. For example the SAD for an encoded block may be smaller than a threshold and the block may be a high quality block. Pixels in a high quality block may be referred to as high quality pixels.

In some implementations determining a coding quality for encoding a current block may be based on a relative priority importance of the content included in the block. For example video encoding may be subjected to resource utilization limitations such as bit rate constraint and content may be prioritized so that blocks including important content important blocks may be encoded using high quality encoding using a relatively large amount of resources i.e. higher priority in bit allocation . Bits allocated for encoding important blocks may not be used for encoding the important blocks and may be used for encoding other blocks. In some implementations important blocks may be encoded before other blocks. For example a frame may be divided into slices and the important blocks may be included in a slice that may be encoded before other slices.

In some implementations the priority for encoding a block may be based on the context of the content included in the block relative to the operating environment. For example a topmost window in the operating environment may be relatively important to a user in focus and blocks of the rendered content including the topmost window may have a higher priority than other blocks. Blocks encoded using high quality encoding may suffer less quantization distortion than other blocks convergence between a current frame and subsequent frames may be faster than for blocks that are not encoded using high quality encoding. Corresponding blocks in subsequent frames may be encoded as skipped blocks. Some subsequent frames may be encoded without encoding residual data. For example encoding a first subsequent block may include encoding residual data and encoding other subsequent blocks may not include encoding residual data. In another example priority may be based on the frequently and recency with which a window has been in focus or interacted with by a user. The higher the focus frequency and recency the higher the priority. For example windows may be indexed in order of focus frequency focus recency or based on a combination of focus frequency and focus recency.

In some implementations a static block may be encoded using high quality encoding. For example encoding a static block as a high quality block may allow subsequent corresponding blocks to be encoded using fewer resources which may reduce overall resource utilization bit count . Bits utilized for encoding a static block as a high quality block can be used to improve the efficiency of encoding blocks which use the static block as a reference block. For example a current block may be identified as a static block in a current frame and the likelihood that a corresponding block in a subsequent frame is a static block may be high. In some implementations the likelihood that the corresponding block in the subsequent frame is a static block may be particularly high when the current block does not include a portion of a topmost window.

Remote access encoding may include determining whether to encode the current block as a skipped block at . In some implementations determining whether to encode the current block as a skipped block may be based on whether the current block is a static block whether a reference block identified for encoding the current block is a high quality reference block or a combination thereof.

In some implementations determining whether to encode the current block as a skipped block may include determining whether a reference block for encoding the current block is a high quality reference block or a low quality reference block. For example a reference block aligned with a block boundary and encoded using high quality encoding may be a high quality reference block a reference block that overlaps multiple blocks that were encoded using high quality encoding may be a high quality reference block and a reference block that overlaps with a block was not encoded using high quality encoding may be a low quality reference block.

In some implementations encoding a static block using a high quality reference block may include identifying the current block as a skipped block identifying a motion vector indicating the reference block and identifying the current block as a high quality block.

In some implementations such as implementations where processing resources are limited encoding a static block using a low quality reference block may include identifying the current block as a skipped block identifying a motion vector indicating the reference block and identifying the current block as a low quality block.

In some implementations encoding a static block using a low quality reference block may include encoding the block without identifying the block as a skipped block which may include using very good motion vector estimation. In some implementations the encoder may utilize the motion vector directly in the coding process. In some implementations the encoder may utilize the motion vector as a good starting point to find the best motion vector for coding the block.

Non static blocks in the current frame may be encoded using a non static block encoding technique such as the encoding shown in .

Other implementations of the diagram of remote access encoding as shown in are available. In implementations additional elements of remote access encoding can be added certain elements can be combined and or certain elements can be removed. Remote access encoding or any portion thereof can be implemented in a device such as the computing device shown in or the computing and communication devices A B C shown in . For example an encoder such as the encoder shown in can implement remote access encoding or any portion thereof using instruction stored on a tangible non transitory computer readable media such as memory shown in .

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Moreover use of the term an embodiment or one embodiment or an implementation or one implementation throughout is not intended to mean the same embodiment or implementation unless described as such. As used herein the terms determine and identify or any variations thereof includes selecting ascertaining computing looking up receiving determining establishing obtaining or otherwise identifying or determining in any manner whatsoever using one or more of the devices described herein.

Further for simplicity of explanation although the figures and descriptions herein may include sequences or series of steps or stages elements of the methods disclosed herein can occur in various orders or concurrently. Additionally elements of the methods disclosed herein may occur with other elements not explicitly presented and described herein. Furthermore not all elements of the methods described herein may be required to implement a method in accordance with the disclosed subject matter.

The implementations of the computing and communication devices and the algorithms methods or any part or parts thereof stored thereon or executed thereby can be realized in hardware software or any combination thereof. The hardware can include for example computers intellectual property IP cores application specific integrated circuits ASICs programmable logic arrays optical processors programmable logic controllers microcode microcontrollers servers microprocessors digital signal processors or any other suitable circuit. In the claims the term processor should be understood as encompassing any of the foregoing hardware either singly or in combination. The terms signal and data are used interchangeably. Further portions of the computing and communication devices do not necessarily have to be implemented in the same manner.

Further all or a portion of implementations can take the form of a computer program product accessible from for example a tangible computer usable or computer readable medium. A computer usable or computer readable medium can be any device that can for example tangibly contain store communicate or transport the program for use by or in connection with any processor. The medium can be for example an electronic magnetic optical electromagnetic or a semiconductor device. Other suitable mediums are also available.

The above described implementations have been described in order to allow easy understanding of the application are not limiting. On the contrary the application covers various modifications and equivalent arrangements included within the scope of the appended claims which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structure as is permitted under the law.

