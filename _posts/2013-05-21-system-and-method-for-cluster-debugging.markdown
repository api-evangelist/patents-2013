---

title: System and method for cluster debugging
abstract: A system and method of cluster debugging includes detecting debug events occurring in one or more first virtual machines, storing debug records, each of the debug records including information associated with a respective debug event selected from the debug events and a timestamp associated with the respective debug event, merging the debug records based on information associated with each timestamp, starting one or more second virtual machines, each of the one or more second virtual machines emulating a selected one of the one or more first virtual machines, synchronizing the one or more second virtual machines, retrieving the merged debug records, and playing the merged debug records back in chronological order on the one or more second virtual machines. In some examples, the method further includes collecting clock synchronization records. In some examples, merging the debug records includes altering an order of one or more of the debug records based on the clock synchronization records.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09141512&OS=09141512&RS=09141512
owner: Red Hat, Inc.
number: 09141512
owner_city: Raleigh
owner_country: US
publication_date: 20130521
---
The present disclosure relates generally to computing systems and more particularly to cluster debugging.

As the value and use of information continues to increase individuals and businesses seek additional ways to process and store information. One option is a computing system. Computing systems may vary in complexity from a single processor operating in relative isolation to large networks of interconnected processors. The interconnected processors may be in close proximity to each other or separated by great distances both physically and as distance is measured in computer networking terms. The interconnected processors may also work together in a closely cooperative fashion or in a loose weakly coupled fashion. Because technology and processing needs and requirements may vary between different applications the structure and arrangement of the computing system may vary significantly between two different computing systems. The flexibility in computing systems allows them to be configured for both specific users specific uses or for more general purposes. Computing system may also include a variety of hardware and software components that may be configured to process store and communicate information based on the needs of the users and the applications.

Additionally some examples of computing systems include non transient tangible machine readable media that include executable code that when run by one or more processors may cause the one or more processors to perform the steps of methods described herein. Some common forms of machine readable media include for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read.

Computing systems generally rely on one or more software components to deliver the services and information required by users and other systems. In many computing systems the one or more software components are designed to operate in a cooperative fashion among several nodes in a cluster. In some examples one or more of the several nodes may be executing more than one of the one or more software components either in parallel and or through the use of virtual machines. As the number of nodes in the cluster increases it may become increasingly complex to debug the one or more software components executing on each of the nodes and or to debug the one or more software components as a whole. As the complexity of each of the one or more software components increases the complexity of the debugging is also likely to increase.

Accordingly it would be desirable to provide improved methods and systems for debugging software components executing on a cluster of nodes.

According to one embodiment a method of cluster debugging includes detecting debug events occurring in one or more first virtual machines storing debug records each of the debug records including information associated with a respective debug event selected from the debug events and a timestamp associated with the respective debug event merging the debug records based on information associated with each timestamp starting one or more second virtual machines each of the one or more second virtual machines emulating a selected one of the one or more first virtual machines synchronizing the one or more second virtual machines retrieving the merged debug records and playing the merged debug records back in chronological order on the one or more second virtual machines.

According to another embodiment a non transitory machine readable medium comprising a first plurality of machine readable instructions which when executed by one or more processors associated with one or more computing systems are adapted to cause the one or more processors to perform a method including detecting debug events occurring in one or more first virtual machines storing debug records each of the debug records including information associated with a respective debug event selected from the debug events and a timestamp associated with the respective debug event merging the debug records based on information associated with each timestamp starting one or more second virtual machines each of the one or more second virtual machines emulating a selected one of the one or more first virtual machines synchronizing the one or more second virtual machines retrieving the merged debug records and playing the merged debug records back in chronological order on the one or more second virtual machines.

According to yet another embodiment a system for cluster debugging includes a cluster including a plurality of nodes coupled together using a network a database coupled to the network and a debugging workstation coupled to the network. Each of the plurality of nodes executes one or more first virtual machines and a debugging database extension DDE . Debug events occur in each of the one or more first virtual machines are detected. The database stores debug records. Each of the debug records includes information associated with a respective debug event selected from the debug events and a timestamp associated with the respective debug event. The stored debug records are merged based on information associated with each timestamp. The debugging workstation executes a playback module and one or more second virtual machines. Each of the one or more second virtual machines emulates a selected one of the one or more first virtual machines. The one or more second virtual machines are synchronized. The playback module retrieves the merged debug records and plays the merged debug records back in chronological order on the one or more second virtual machines.

In the following description specific details are set forth describing some embodiments consistent with the present disclosure. It will be apparent however to one skilled in the art that some embodiments may be practiced without some or all of these specific details. The specific embodiments disclosed herein are meant to be illustrative but not limiting. One skilled in the art may realize other elements that although not specifically described here are within the scope and the spirit of this disclosure. In addition to avoid unnecessary repetition one or more features shown and described in association with one embodiment may be incorporated into other embodiments unless specifically described otherwise or if the one or more features would make an embodiment non functional.

Node includes one or more processors and memory . The one or more processors are coupled to memory . In some examples the one or more processors may control operation and or execution of software components on node . Memory may be used to store any number of software components. Memory may further be used to store the software components while the software components are executing. As shown in memory is storing Java virtual machines JVMs as they are being executed on node . Although node is shown with three JVMs being executed any number of JVMs may be executed on node as long as node includes sufficient computing resources to handle them. In some examples each of the JVMs may be executing in separate virtual environments and or guest operating systems on node .

Node includes one or more processors and memory . The one or more processors are coupled to memory . In some examples the one or more processors may control operation and or execution of software components on node . Memory may be used to store any number of software components. Memory may further be used to store the software components while the software components are executing. As shown in memory is storing a JVM as it is being executed on node . Although node is shown with only one JVM being executed any number of JVMs may be executed on node as long as node includes sufficient computing resources to handle them.

JVMs and or may be any type of virtual machines. In some examples JVMs and or may be part of any application server including JBoss WebSphere Glassfish WildFly and the like. In some examples JVMs and or may be a Cassandra JVM Daemon JVM a REST API JVM and or the like. Although JVMs and are described as Java virtual machines it is understood that JVMs and or may be other types of virtual machines.

Cluster debugging system further includes a workstation . In some examples workstation may be used by a software developer and or an operator to manage monitor and or debug the software components executing on cluster . Workstation is coupled to nodes and of cluster using network . Although workstation is shown as a stand alone unit other configurations for workstation are possible. In some examples workstation may be one of the nodes of cluster . Workstation includes one or more processors and memory . The one or more processors are coupled to memory . In some examples the one or more processors may control operation and or execution of software components on workstation . Memory may be used to store any number of software components. Memory may further be used to store the software components while the software components are executing. As shown in memory is storing an integrated development environment IDE as it is being executed on workstation . In some examples IDE may facilitate the managing monitoring and or debugging of the software components executing on cluster . In some examples IDE may be executing in a virtual environment and or a guest operating system on workstation .

Memories and or may include one or more types of machine readable media. Some common forms of machine readable media may include floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read.

At the process one or more JVMs are started. Before debugging of software components may begin the software components begin execution. Each of the software components is executed in a node of a cluster. In the examples of the software components are being executed using one or more JVMs being executed on the nodes of the cluster. Each of the one or more JVMs is started so that the respective software components may begin execution. In some examples the one or more JVMs may include the JMVs and . In some examples the cluster may be cluster and the nodes may include nodes and .

At the process debug events are detected. As each of the one or more JVMs executes the software components conditions may develop which trigger debug events. As each of the debug events is triggered the one or more JVMs may respond to the debug events. In some examples one or more of the debug events may be triggered by a debug rule in a corresponding JVM and or a corresponding software component. In some examples one or more of the debug events may be triggered when an exception is thrown. In some examples one or more of the debug events may be triggered based on a watchpoint. In some examples one or more of the debug events may be triggered by a breakpoint.

At the process debug data is sent to a workstation. Once a debug event is triggered the corresponding JVM may execute debug handling software in order to process the debug event. The debug handling software may collect the corresponding debug data from the corresponding JVM and or the corresponding software component in which the debug event occurred. In some examples the debug data may include tracing data. In some examples the debug data may include byte codes. After the debug data is collected it is sent to a workstation such as workstation . In some examples the debug data may be directed to an IDE such as IDE . In some examples the debug data may be sent using a message transmitted over a network such as network . In some examples the debug data may be associated with a TCP port. In some examples the TCP port may be unique to the corresponding JVM and or the corresponding software component.

At the process the debug data is used to debug. As the debug data sent during process is received at the workstation it may be used to support debugging of the software components being executed on the cluster. In some examples the debug data may be presented to a software developer and or an operator to manage monitor and or debug the software components. In some examples the debug data may be logged on the workstation for later review.

According to certain examples method may be a less than ideal approach to debugging software components in a cluster. In some examples the debug data is only assembled at the workstation in real time and it may not be possible to temporarily stop the flow of debug data and the corresponding JVMs which is a common debugging technique used on when debugging software components executing on a single computer. In some examples the debug data may not be received at the workstation in a same chronological order as the respective debug events because different transmission latencies may exist between the workstation and the corresponding nodes of the cluster. In some examples when the chronological order of the debug events is not preserved it may reduce the effectiveness of the debugging. In some examples method may not provide an adequate record and playback module. In some examples even though the debug data may be logged it may not be possible to replay the logged data to debug the cluster because the logged debug data is separated from the JVM which generated it. Accordingly improved cluster debugging systems would be desirable.

DDEs and or may be used to enhance the collection of debug data before it is sent to workstation . In some examples as the DDEs and collect the debug data associated with debug events DDEs and may tag and or associate the debug data with a timestamp including when the debug event occurred. In some examples DDEs and may also tag and or associate the debug data with a JVM identifier of the JVM on which the corresponding debug event occurred. In some examples DDEs and may further generate and store synchronization records to address clock synchronization and clock skew issues between nodes and .

Cluster debugging system further includes a database . In some examples database may be coupled to nodes and or using network . Database may be used to store the debug data collected by DDEs and . In some examples database may be used to store debug records including the debug data for debug events the timestamp associated with the debug data and or the JVM identifier of the JVM associated with the debug data. In some examples DDEs and may transmit the debug records to database as they are generated. In some examples database may store the debug records after the debug records are collected from DDEs and . In some examples the debug records may be stored in database using database transactions. In some examples DDEs and may each include a transactor for database . In some examples database may store the debug records as key value pairs. In some examples a key portion of each key value pair may include a timestamp and or a JVM identifier. In some examples the timestamp may correspond to the timestamp associated with the debug data. In some examples the JVM identifier may identify the JVM associated with the debug data. In some examples a value portion of each key value pair may include the collected debug data. In some examples the debug data may include byte codes. In some examples database may be a NoSQL database. In some examples database may be a Datomic database. In some examples database may index the debug records based on timestamps. In some examples database may further store synchronization records.

Although database is shown separately in database may be hosted on any suitable device in cluster debugging system . In some examples database may be hosted on a server. In some examples database may be hosted on workstation . In some examples database may be hosted on any one of the nodes in the cluster including node and or node . In some examples database may be distributed across multiple nodes workstations and or servers.

At the process one or more JVMs are started. Before debugging of software components may begin the software components begin execution. Each of the software components is executed in a node of a cluster. In the examples of the software components are being executed using one or more JVMs being executed on the node of the cluster. Each of the one or more JVMs is started so that the respective software components may begin execution. In some examples the one or more JVMs may include the JMVs and or . In some examples the cluster may be cluster and the node be node and or .

At the process debug events are detected. As each of the one or more JVMs executes the software components conditions may develop which trigger debug events. As each of the debug events is triggered the one or more JVMs may respond to the debug events. In some examples one or more of the debug events may be triggered by a debug rule in a corresponding JVM and or a corresponding software component. In some examples one or more of the debug events may be triggered when an exception is thrown. In some examples one or more of the debug events may be triggered based on a watchpoint. In some examples one or more of the debug events may be triggered by a breakpoint. In some examples a timestamp associated with when the debug event occurred may be recorded and or associated with the debug event. In some examples a JVM identifier associated the JVM on which the debug event occurred may be recorded and or associated with the debug event.

At the process debug records are stored using a debugging database extension. Once a debug event is triggered the corresponding JVM may execute debug handling software in order to process the debug event. The debug handling software may collect the corresponding debug data from the corresponding JVM and or the corresponding software component in which the debug event occurred. In some examples the debug data may include tracing data. In some examples the debug data may include byte codes. The debug data for a debug event may be used to form a debug record. In some examples the debug record may include the debug data. In some examples the debug record may include the timestamp associated with the debug event. In some examples the debug record may include the JVM identifier associated with the debug event. In some examples the debug data may be associated with a TCP port. In some examples the TCP port may be unique to the corresponding JVM and or the corresponding software component.

In some examples the debug handling software may use the debugging database extension DDE on the node to record and or store each debug record. In some examples the debug records may be stored locally in the node for later collection. In some examples the debug records may be stored in a shared database such as database . In some examples the DDE may be DDE and or DDE .

At the process synchronization messages are exchanged. In some examples cluster based computer systems may often suffer from clock synchronization issues and or clock skew between the nodes in the cluster. In some examples differences in timing between clocks of the nodes of the cluster may exist. In some examples the differences may affect a relative accuracy between the timestamps of debug events recorded in different nodes. In some examples when the differences are significant enough the timestamps of two debug events may erroneously reverse a relative order in which the two debug events occurred. In some examples this may not be desirable. In some examples in order to address clock synchronization and or clock skew the nodes in the cluster may exchange synchronization messages to minimize any effects due to clock synchronization issues and or clock skew.

At the process latency detection messages are transmitted. In some examples as part of a clock synchronization process two nodes in a cluster may exchange messages that include information regarding clocks of the two nodes. In some examples latency may exist between a first time at which a message is generated at a first node and a second time at which the message is received at a second node. In some examples a difference between the first time and the second time is the latency and or a delay due to practical transmission characteristics. In some examples when the first node and the second node are separated by a distance in network terms e.g. by network the latency may be significant. In some examples the latency may be estimated by exchanging messages. In some examples the first node may begin measurement of the latency by transmitting one or more latency detection messages to the second node. In some examples the one or more latency detection messages may include a first timestamp associated with when the respective latency detection message is transmitted by the first node. In some examples the first node may record the first timestamp without including the timestamp in the latency detection message. In some examples the latency detection message may be a ping message. In some examples the latency detection message may be an echo request.

At the process latency detection responses are received. In response to the latency detection messages transmitted by the first node during process to the second node the second node may return a latency detection response. In some examples the latency detection response may include a second timestamp associated with when the second node received the corresponding latency detection message. In some examples the latency detection response may include a third timestamp associated with when the second node transmits the latency detection response. In some examples the first node may record a fourth timestamp associated with when the first node receives the latency detection response. In some examples the latency detection response may be a ping response message. In some examples the latency response message may be an echo response.

At the process a latency is estimated. By examining the first second third and fourth timestamps the latency of messages between the first node and the second node may be estimated. In some examples a difference between the first timestamp and the fourth timestamp may estimate twice the latency of messages between the first node and the second node. In some examples a difference between the first timestamp and the second timestamp may estimate the latency of messages transmitted from the first node to the second node. In some examples a difference between the third timestamp and the fourth timestamp may estimate the latency of messages transmitted from the second node to the first node. In some examples other combinations of the first second third and fourth timestamps may be used to estimate the latency. In some examples timestamps associated with multiple pairs of latency detection messages and latency responses may be aggregated to more accurately estimate the latency. In some examples the aggregation may involve averaging.

At the process clock messages are received. In some examples as part of clock synchronization nodes in the cluster may exchange clock messages. In some examples the clock messages each include a current time of a clock in a node e.g. the second node that is transmitting the respective clock message. In some examples the current time includes a timestamp for the second node. In some examples the clock messages may be latency detection messages and or latency detection responses.

At the process the estimated latency is removed. In some examples the clock messages received during process may be received at the first node after some latency from the second node. In some examples the latency indicates that a current time at the first node may not be the same as the current time reported for the second node in the clock message. In some examples any difference between the current time of the first node and the reported current time of the second node may be adjusted by removing the estimated latency. In some examples the estimated latency may be added to the reported current time of the second node. In some examples the estimated latency may be subtracted from the current time of the first node.

At the process clock skew is determined. By comparing the current time at the first node to the reported current time of the second node after accounting for estimated latency an estimate of the clock skew between the first node and the second node may be determined. In some examples the clock skew between the first node and the second node may be determined using Equation 1 where TSis a timestamp associated with when the clock message was received during process by the first node TSis a timestamp associated with the current time reported for the second node in the clock message and EL is the estimated latency determined during process . Clock skew 1 2 Eqn. 1

In some examples when the clock skew is zero the clock of the first node and the clock of the second node are synchronized. In some examples when the clock skew is negative the clock of the second node may be skewed ahead of the clock of the first node. In some examples when the clock skew is positive the clock of the first node may be skewed ahead of the clock of the second node. In some examples the clock skew may be used to determine a correct chronological ordering of the debug records stored during process . In some examples the clock skew may be used to adjust one or more timestamps associated with debug records for the first node and or the second node.

Referring back to at the process synchronization records are stored. The clock skew determined during process may be stored in a synchronization record. In some examples the synchronization record may be associated with a timestamp based on when the clock skew is determined. In some examples the association of the timestamp with the clock skew may address any drift that occurs in the clock skew. In some examples the synchronization record may be associated with the first node and the second node. In some examples the synchronization record may be stored in the first node. In some examples the synchronization record may be stored in a database. In some examples the database may be database .

Referring back to 3 cluster debugging system further includes workstation . In some examples workstation may be used by a software developer and or an operator to manage monitor and or debug the software components executing on cluster . Memory may be used to store any number of software components. Memory may further be used to store the software components while the software components are executing. As shown in memory is storing an integrated development environment IDE as it is being executed on workstation . Memory is also storing a playback module and one or more JVMs .

Playback module may be used within workstation to load and playback debug records associated with cluster . In some examples playback module may playback the debug records in a same chronological order in which the corresponding debug events occurred in JVMs and in cluster . In some examples the debug records may include the debug records stored in database . In some examples the debug records may be associated with the debug events detected and or recorded by DDEs and . In some examples playback module may coordinate with IDE to facilitate debugging of the software components being executed in cluster .

In some examples in order to better simulate the environment of cluster JVMs may each be used to emulate JVMs and or . In some examples each one of the JVMs may be used to emulate a respective one of JVMs and . As an example JVM may emulate JVM JVM may emulate JVM JVM may emulate JVM and JVM may emulate JVM . In some examples each of the JVMs may be of the same type as the respective one of the JVMs and . In some examples by emulating each of the JVMs and separately playback module may be able to playback the debug records in the emulated NM that corresponds to the JVM or in which the corresponding debug event occurred.

At the process debug records are collected. Debug records corresponding to debug events are collected for use during debugging. In some examples the debug events may be debug events that occurred in JVMs executing on one or more nodes in a cluster. In some examples the debug events may be the debug events detected during process and stored during process . In some examples the JVMs may be the JVMs and or and the one or more nodes may include nodes and . In some examples the debug records may be collected from DDEs in each of the nodes such as DDEs and or . In some examples the debug records may be collected from a database such as database . In some examples each of the debug records may include a timestamp corresponding to when the respective debug event occurred. In some examples the debug records may include a JVM identifier corresponding to the JVM on which the respective debug event occurred.

At the process synchronization records are collected. Synchronization records corresponding to differences in clock synchronization and or clock skew between the one or more nodes in the cluster are collected to help ensure that a chronological order of the collected debug records may be correctly determined. In some examples each of the synchronization records may include a clock skew between two of the nodes in the cluster. In some examples the synchronization records may further include a synchronization timestamp corresponding to when the respective clock skew was determined. In some examples the synchronization records may be the synchronization records stored during process . In some examples the synchronization records may be collected from the one or more nodes of the cluster. In some examples the synchronization records may be collected from a database such as database .

At the process the debug records are merged based on the synchronization records. In some examples because each of the timestamps included in the debug records may correspond to a time on a respective node there may be relative differences in a first time base associated with a first node and a second time base associated with a second node due to clock skew between the first node and the second node. In some examples it may be important to account for the differences in the first and second time bases as it may indicate that even though a first timestamp for a first debug event from the first node is earlier than a second timestamp for a second debug event from the second node the second debug event may have occurred before the first debug event. As the debug records collected during process are merged the timestamps included in the debug records may be adjusted by the clock skew included in the synchronization records collected during process . In some examples when the first timestamp is within a clock skew threshold of the second timestamp a clock skew in a synchronization record associated with the first node and the second node may be used to adjust the first timestamp or the second timestamp. In some examples the synchronization record used to adjust the corresponding timestamp may further be selected based on a synchronization timestamp included in the synchronization record that is closest to the first timestamp and or the second timestamp. In this way the clock skew used may be the clock skew measurement determined at a time closest to the first timestamp and or the second timestamp.

At the process one or more JVMs are started. One or more JVMs are started which correspond to each JVM that was being executed in the cluster from which debug records are collected. In some examples the one or more JVMs are the JVMs . In some examples each of the one or more JVMs may emulate the corresponding JVM that was being executed in the cluster. In some examples each of the one or more JVMs may be of a same type as the corresponding JVM that was being executed in the cluster. In some examples each of the one or more JVMs may be configured with a separate TCP port for receiving debug information. In some examples the one or more JVMs may be started in conjunction with an IDE such as IDE .

At the process the one or more JVMs are synchronized. The one or more JVMs are synchronized so that they may be cooperatively controlled by the IDE. In some examples the IDE may be used to start each of the one or more JVMs in synchronization. In some examples the IDE may be used to stop each of the one or more JVMs at a same time. In some examples each of the one or more JVMs may be synchronized by starting each of the one or more JVMs during process with the switch suspend y .

At the process the merged debug records are retrieved in chronological order. In order to support playback of the debug events recorded using method each of the corresponding merged debug records are retrieved in chronological order. In some examples the chronological order may be determined from the timestamps included in the debug records as adjusted during process by the synchronization records. In some examples the merged debug records may be retrieved from a database such as database . In some examples the merged debug records may be retrieved by a playback module such as playback module .

At the process the debug records are presented to the one or more JVMs. To complete the playback of the debug events each of the debug events in the debug records is played back on a corresponding one of the one or more JVMs. In some examples the corresponding one of the one or more JVMs may be determined based on a JVM identifier in the respective debug record. In some examples the debug events may be played back on the corresponding JVM at a playback time that may be approximately equivalent to when the original debug event occurred in the cluster as indicated by a timestamp included in the respective debug record. In some examples the respective debug record may include byte codes for playback in the corresponding one of the one or more JVMs. In some examples the debug event may be presented to the corresponding one of the one or more JVMs using the TCP port assigned to the corresponding one of the one or more JVMs. In some examples the TCP port may be identified based on the JVM identifier associated with the corresponding one of the one or more JVMs.

According to certain examples the cluster debugging of methods and may provide advantages over the cluster debugging of method . In some examples the recording of method may support repeated playback using method . In some examples the recording of method may support playback using method that may not need to occur in real time thus providing a more robust debugging environment. In some examples the merging of clock synchronization records with the debug records may help ensure a correct chronology of the debug events during playback.

Some examples of nodes and or and or workstation may include non transient tangible machine readable media that include executable code that when run by one or more processors e.g. one or more processor and or may cause the one or more processors to perform the processes of methods and or as described above. Some common forms of machine readable media that may include the processes of methods and or are for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read.

Although illustrative embodiments have been shown and described a wide range of modification change and substitution is contemplated in the foregoing disclosure and in some instances some features of the embodiments may be employed without a corresponding use of other features. One of ordinary skill in the art would recognize many variations alternatives and modifications. Thus the scope of the invention should be limited only by the following claims and it is appropriate that the claims be construed broadly and in a manner consistent with the scope of the embodiments disclosed herein.

