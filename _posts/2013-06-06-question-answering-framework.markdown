---

title: Question answering framework
abstract: Described herein is a technology to facilitate automated question answering. In one implementation, an input question is first received. Different search strategies may be used to search multiple types of data from multiple types of knowledge databases to generate one or more candidate answers to the input question. The one or more candidate answers are evaluated to generate a final answer to the input question.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09213771&OS=09213771&RS=09213771
owner: SAP SE
number: 09213771
owner_city: Walldorf
owner_country: DE
publication_date: 20130606
---
The present disclosure relates generally to information retrieval and more specifically to a question answering framework.

The rapid development of science and technology has led to a rapidly increasing amount of published information. Question answering QA systems have been designed to access and search through such information to automatically answer questions posed by humans in a natural language.

One of the major challenges in such QA systems is to provide relevant answers amid multifarious search results. Search engines often return a large set of search results that are irrelevant to the question causing the user to be confused and lost in the myriad of results. Even the top ranked search result may not be related to the question itself. This is especially prevalent in cases where the question is short and includes common words with spellings that are very similar to names or content of other different topics such as the name of a film or lyrics of a popular song.

There are two common causes of retrieving irrelevant answers. Firstly irrelevancy may be caused by low accuracy in question parsing and text analysis. In other words the QA system may not correctly interpret the meaning of the input question. Irrelevancy in answers may also be caused by low accuracy in the answer finding capability of the QA system.

In addition answers tend to be limited in domain specific QA systems. Most QA systems support only a certain kind of domain and do not support access to a wide collection of knowledge bases. Frequently no answer is provided for questions with answers from an unsupported domain. Even if answers can be found they may not be comprehensible by the user. In most cases the answers may be very long with many definitions principle introductions references related topics etc. that make it difficult for the user particularly a school age child to quickly understand.

Even further the performance of conventional QA systems is typically unsatisfactory. In order to correctly interpret human language and extract answers from large knowledge bases QA systems often employ a wide data search and deep data mining that are computationally expensive and often result in slow retrieval time and low accuracy.

A computer implemented technology for facilitating question answering is described herein. In accordance with one aspect of the technology an input question is first received. Different search strategies are used to search multiple types of data from multiple types of knowledge databases to generate one or more candidate answers to the input question. The one or more candidate answers are evaluated to generate a final answer to the input question.

In accordance with another aspect an input question is first received. The technology then determines one or more types of knowledge databases available for searching. If a question answer paired knowledge database is available question answer paired data from the question answer paired knowledge database is searched to determine a first candidate answer to the input question. If a plain text knowledge database is available plain text data from the plain text knowledge database is searched to determine a second candidate answer to the input question. If a resource description framework RDF knowledge database is available RDF data from the RDF knowledge database is searched to determine a third candidate answer to the input question. The first second or third candidate answer may then be evaluated to generate a final answer to the input question.

With these and other advantages and features that will become hereinafter apparent further information may be obtained by reference to the following detailed description and appended claims and to the figures attached hereto.

In the following description for purposes of explanation specific numbers materials and configurations are set forth in order to provide a thorough understanding of the present frameworks and methods and in order to meet statutory written description enablement and best mode requirements. However it will be apparent to one skilled in the art that the present frameworks and methods may be practiced without the specific exemplary details. In other instances well known features are omitted or simplified to clarify the description of the exemplary implementations of the present framework and methods and to thereby better explain the present framework and methods. Furthermore for ease of understanding certain method steps are delineated as separate steps however these separately delineated steps should not be construed as necessarily order dependent in their performance.

A technology for facilitating question answering is described herein. One aspect of the technology provides a question answering QA framework that supports multiple types of knowledge databases. A knowledge database generally refers to an information repository where information may be collected organized shared searched and or used. Different types of knowledge databases include for example formulated question answer paired knowledge databases plain text knowledge databases and resource description framework RDF knowledge databases which will be described in more detail in the following description.

One aspect of the present technology implements a different search strategy for each type of knowledge database. Different search strategies may be combined to support a query in multiple types of knowledge databases and provide the most relevant answer in response to the query. This allows the user to combine knowledge databases without having to consolidate data from the different types of knowledge databases. With such expanded knowledge database support the user can build a comprehensive knowledge system that increases the rate of answer finding particularly for specific domain areas.

Another aspect of the present technology provides an improved methodology for question pairing and answer assembling with enhanced accuracy in question identification and answer extractions. With in memory technology parallel computing and in built text analysis functionality more data may be processed with high accuracy and speed that are acceptable to the user. It is only with such powerful computing ability that multiple data sources and unlimited domains are feasible. These and other advantages and aspects will be described in more detail in the following description.

The framework described herein may be implemented as a method a computer controlled apparatus a computer process a computing system or as an article of manufacture such as a computer usable medium. These and various other features will be apparent from the following description.

Computer system includes a central processing unit CPU an input output I O unit and a memory module . Other support circuits such as a cache a power supply clock circuits and a communications bus may also be included in computer system . In addition any of the foregoing may be supplemented by or incorporated in application specific integrated circuits. Examples of computer system include a handheld device a mobile device a personal digital assistance PDA a workstation a server a portable laptop computer another portable device a mini computer a mainframe computer a storage system a dedicated digital appliance a device a component other equipment or some combination of these capable of responding to and executing instructions in a defined manner.

Memory module may be any form of non transitory computer readable media including but not limited to dynamic random access memory DRAM static random access memory SRAM Erasable Programmable Read Only Memory EPROM Electrically Erasable Programmable Read Only Memory EEPROM flash memory devices magnetic disks internal hard disks removable disks magneto optical disks Compact Disc Read Only Memory CD ROM any other volatile or non volatile memory or a combination thereof.

Memory module serves to store machine executable instructions data and various software components for implementing the techniques described herein all of which may be processed by CPU . As such the computer system is a general purpose computer system that becomes a specific purpose computer system when executing the machine executable instructions. Alternatively the various techniques described herein may be implemented as part of a software product which is executed via an application server and or a data server . Each computer program may be implemented in a high level procedural or object oriented programming language e.g. C C Java Advanced Business Application Programming ABAP from SAP AG Structured Query Language SQL etc. or in assembly or machine language if desired. The language may be a compiled or interpreted language. The machine executable instructions are not intended to be limited to any particular programming language and implementation thereof. It will be appreciated that a variety of programming languages and coding thereof may be used to implement the teachings of the disclosure contained herein.

In one implementation the memory module of the computer system includes an application server or stack and a data server or stack . Application server or stack may store a QA framework that may be coded using a high level programming language such as Java C ABAP etc. Other types of programming languages are also useful. QA framework may include a set of function modules or programs of a QA framework designed to perform various data collection and or QA processing functions such as question parsing answer retrieval and ranking answer assembly and so forth. More details of these and other exemplary functions will be provided in the following description.

Data server or stack may include a database management system DBMS and a database . DBMS may be coded using a database query language such as SQL or extensions thereof. Other types of programming languages are also useful. DBMS may include a set of programs functions or procedures e.g. HANA custom procedures for defining administering and processing the database . More particularly DBMS may include an index server and a preprocessor server . Index server provides database functionality for storage and retrieval of query data e.g. indexes that is associated with information stored in the database while preprocessor server may serve to analyze documents to be indexed by the index server . More details of these and other exemplary functions will be provided in the following description.

A user at the client computer may interact with a user interface to communicate with the database via the application server and the DBMS . In one implementation database is an in memory database that relies primarily on the system s main memory for efficient computer data storage. More particularly the data in the in memory database may reside in volatile memory and not persistently stored on a hard drive thereby allowing the data to be instantly accessed and scanned at a speed of several megabytes per millisecond. The in memory database allows seamless access to and propagation of high volumes of data in real time. Parallel processing may further be achieved by using a multicore processor in conjunction with the in memory database . In memory database technology includes systems such as SAP s HANA high performance analytic appliance in memory computing engine.

Column based data storage may further be implemented in the in memory database where data tables are stored as columns of data in sequence and in compressed memory blocks. This may facilitate faster aggregation of data when calculations are performed on single columns. Alternatively row based data storage is also possible. In some implementations instead of updating entire rows only fields that have changed will be updated. This avoids having to lock entire data tables during updates to prevent conflicting modifications to a set of data. High levels of parallelization may be achieved which is critical to real time processing of live data streams and performing constant and substantially simultaneous updates.

It should be appreciated that the different components and sub components of the computer system may be located on different machines or systems. For example application server and data server may be implemented on different physical machines or computer systems. It should further be appreciated that the different components of the client computer may also be located on the computer system or vice versa.

As shown client devices to communicate with the QA framework to provide one or more input questions and to receive responses to the input questions from the QA framework . The input question may be expressed in natural language and provided in the form of a statement or an answer seeking an appropriate question. The client devices to and the QA framework may communicate with each other over a network using a web service. The web service may implement various web technologies including a representational state transfer REST based interface remote procedure call RPC based technologies simple object access protocol SOAP based technologies service oriented architecture SOA based technologies and so forth.

In response to the question provided by one or more client devices the QA framework may automatically generate one or more answers. In some implementations the QA framework includes a data collector and a QA processor . The data collector may serve to retrieve information from one or more different knowledge databases to for generating the answers. In one implementation the data collector retrieves data by automatically downloading a collection of data from the knowledge databases to parsing and converting the data into a native format suitable for storage in the database . The downloading may be performed on demand or periodically at predetermined time intervals. Additionally or alternatively the data collector may include a crawler spider robot or other similar application that is configured to automatically discover and retrieve relevant information directly from the one or more knowledge databases to . Even further the data collector may retrieve previously stored information directly from the database .

Knowledge databases KBs to may provide information in different formats. The knowledge databases may be structured semi structured or unstructured. A first exemplary type of knowledge database provides a structured collection of formulated or prepared question answer pairs. Such question answer paired knowledge databases include but are not limited to Yahoo Answers WikiAnswer and Baidu Zhidao.

A second exemplary type of knowledge database provides a semi structured or unstructured collection of natural language documents containing plain text paragraphs. Such plain text knowledge databases may include but are not limited to public or private databases or knowledge bases Intranets the Internet web pages e.g. news website domain based website Wikipedia etc. which can be searched and or crawled for content. In some implementations the data collector retrieves the plain text from the plain text knowledge databases and preprocesses the plain text before storing it in the database . The plain text may be preprocessed by categorizing it using for example a training model.

A third exemplary type of knowledge database stores fact based information in the Resource Description Framework RDF format. RDF is a standard data model for data interchange on the Web. It is published by the World Wide Web Consortium W3C and is generally used to conceptually describe or model information that is implemented in web resources. A collection of RDF statements intrinsically represent a labeled directed multi graph. As such an RDF based data model is naturally suited for certain types of knowledge representation. In practice RDF data often persist in relational databases or native representations also known as Triple stores .

RDF knowledge databases include for instance YAGO and DBPedia. YAGO extracts data from Wikipedia WordNet and GeoNames. More particularly YAGO is built on Wikipedia s info boxes and category pages. Info boxes are standardized tables that contain basic information about the entity described in the article. For instance there are info boxes for countries which contain the native name of the country its capital and its size. Info boxes may be much easier to parse and exploit relative to natural language text. RDF may also express entities facts relations between facts and properties of relations. Facts in YAGO are represented in RDF triple store format and may be queried using SQL and or SPARQL language.

QA processor serves to automatically process the input question received by the QA framework and generate one or more answers in response to the question. In one implementation QA processor further includes a question parser an answer retrieval and ranking unit and an answer assembler .

Question parser analyzes the question to identify one or more properties associated with the question. Such properties may include but are not limited to question type answer type expected by the user key words search focus of key words and so forth. In addition question parser may convert the input question into a database query statement e.g. in SQL based on the identified properties by using a predetermined template. The query statement may then be sent to the query language processor in the DBMS to access data in the database .

Answer retrieval and ranking unit performs or invokes a search function to retrieve one or more candidate answers to the input question. The search function may be for example a full text search function provided by the DBMS . Answer retrieval and ranking unit may further generate credit points or scores for each candidate answer based on pre defined evaluation rules. The credit points or scores may then be used to rank and or order the candidate answers. Answer assembler may serve to identify the most suitable answer from the candidate answers extract the relevant answer paragraph from the whole text content and or construct the answer text. These and other exemplary features will be described in more detail in the following paragraphs.

QA framework is communicatively coupled to the DBMS which includes an index server and preprocessor server . Index server generally includes the actual data and the engines for processing the data. It may also coordinate and use other servers. Index server may include a query language processor and a search module . Search module may further include a data store optimizer and execution controller data store operators and a text search engine .

To search for data stored in the database a query statement e.g. SQL or a full text search may be invoked. If a query statement is received from the question parser the query language processor checks the syntax and semantics of the query statement and generates the logical execution plan. Data store optimizer and execution controller receives the logical execution plan from the query language processor as input and generates the optimized physical execution plan. Data store optimizer and execution controller then executes the optimized physical execution plan by invoking data store operators to access in memory data stored in database .

In some implementations to enhance the performance of the search in memory computing may be leveraged by the DBMS . Data collector may download original documents from the knowledge databases and store them as in memory data in the database . The in memory data may be column based which can be more efficient than traditional row storage databases. Alternatively row based in memory data is also useful.

Text search engine provides full text or document indexing and search capabilities to allow full text queries to be run. Full text queries may include simple words and phrases or multiple forms of a word or phrase. In one implementation text search engine accelerates query execution by building one or more full text indexes to facilitate location of records. Document analyzer in the preprocessor server may segment sentences or paragraphs in the original documents from the knowledge databases to into separate words for the text search engine to build the full text indexes . In the case of certain languages based on ideographic characters e.g. Chinese Japanese Korean etc. there are no spaces between words. For example in Chinese the sentence English translation His name is Yao Ming there are no spaces between the words His Name is Yao Ming . Document analyzer may provide a mechanism to recognize such words.

In response to a full text query the text search engine may perform a full text search against text data in full text indexes to return search results . The search may include an exact search for words and phrases a fuzzy search that tolerates typing errors and a linguistic search that finds variations of words based on linguistic rules of a particular language e.g. English . Search results may include any document returned by the search that contains at least one match also known as a hit . A match occurs when a target document contains all the terms specified in the full text query and meets other search conditions such as the minimum match distance or similarity measure between the terms.

At the QA processor receives an input question. The type of question may include but is not limited to a fact list definition How Why or hypothetical question. The question may also be closed domain i.e. under a specific domain or open domain i.e. about nearly anything . In addition the question may be multidimensional. For example the question What does SAP stand for may be interpreted as a factual question. Alternatively it may also be interpreted as an abbreviation question.

At the question parser processes the input question to identify properties associated with the question before passing the query to the DBMS . In one implementation the question parser includes or invokes functions from a natural language processing NLP library for parsing the natural language input question. NLP may also be used to parse document content from the knowledge databases and extract more detailed semantic and linguistic information.

The input question or document content may be parsed into a set of linguistic distinctions including but are not limited to distinctions as parts of speech POS sentences named entities text tokens document categories word chunks sentence structures word dependencies and so forth. For instance part of speech POS tagging is a major NLP function that determines if a word in a sentence is a preposition a noun or any other parts of a speech. Tokenization generally refers to the segmentation of a sentence into tokens e.g. words punctuation marks numbers etc. . Text chunking generally refers to dividing text into syntactically correlated groups of words such as noun groups verb groups and so forth. Such chunks of text typically do not specify the internal structure or their role in the original sentence. Named entities generally refer to atomic elements with predefined categories such as the names of persons organizations locations expressions of times quantities monetary values percentages etc.

The question parser may use the extracted NLP distinctions to derive higher level properties associated with the input question. Such properties may include but are not limited to the question class e.g. what which when where who why etc. question sub class expected answer type e.g. about location person date money etc. focus keyword etc. The question properties may be used to identify the input question s keywords for performing a full text search and finding the most related paragraph.

More particularly the question parser may derive the question class by using pre defined templates that describe a certain question class based on the NLP distinctions. For example a WHAT question may begin with WHAT or sometimes contains a WHAT in the beginning of the question. Accordingly the template for WHAT class may be pre defined as token value is WHAT group type is NP token type is WP where NP represents proper noun and WP represents wh pronoun . To identify the question class a multiple tier loop e.g. two tier loop may be implemented to parse the input sentence. For example the question parser may first scan the sentence to identify one or more chunk groups. If a question class cannot be identified based on chunk groups the question parser may further scan the sentence to identify one or more tokens. If the tokens match a certain pre defined template the corresponding class is determined accordingly and saved.

For purposes of illustration assume that the input question is What is Microsoft Office . A chunk group identifier may mark the question as follows What is Microsoft Office . In other words What is and Microsoft Office are identified as chunk groups with corresponding types WP VBZ and NP and its two children are both NNP . If these chunk group types are associated with a pre defined question class then the question class is identified accordingly. For example the question class may be identified as What class which is defined by the question word What its token type is WP and the question s target group type is NP . If the chunk groups do not match any pre defined template the question may be tokenized as WP VBZ NNP NNP where VBZ represents a verb 3rd person singular present and NNP represents a Proper noun singular.

Once the question class is determined the name entity list may be checked to see if any name entity matches the first NN token type where NN represents a noun singular or mass. If a match is found the matching name entity from the list is directly selected as the focus. If no match is found a code level check may be performed to determine the sub class. More particularly one or more pre defined keywords may be used to determine the sub class. For example the classes CAPITAL CITY COUNTRY etc. belong to a sub class LOCATION. Therefore in the question What city is the largest one in China the pre defined keyword city may be used to determine the sub class location .

Another property that may be identified based on the input question is the expected answer type. Answer type generally refers to the type of answer expected by the user or application in response to the input question. In some implementations the input question class and or sub class is mapped to the corresponding answer type in pre defined tables.

For instance according to a previous rule the question parser may only know that the questions What company is the largest in the world What entrepreneur is the richest in the world are all WHAT WHO questions. The first noun e.g. company and entrepreneur after the question word what may be used to identify the answer type. Since it is not easy to manually create a rule to cover all cases an existing training data set may be used as a reference for further determination of the question type.

Yet another property that may be identified based on the input question is the focus . Focus generally refers to a sequence of words that defines what the input question is looking for. For example in the question What is the capital of China the question parser understands that the question is asking about a LOCATION. However the question class LOCATION may be too broad and it may be helpful to narrow down the search to focus on CAPITAL. This means that the answer should be the name of a capital or city name . The question parser may identify the focus by extracting from the input question the first noun after the question class word e.g. CAPITAL .

Yet another property that may be identified based on the input question is keyword . An input question may include one or more keywords which provide the context of the input question and may significantly impact the search results. Keywords may include the focus although it is not necessarily so in all cases. It may be important to identify the keywords of an input question so that a search may be performed to find the paragraph related to the question. To identify the keywords the following ordered set of heuristics may be used 

During runtime the question parser processes each heuristic to extract one or more keywords in accordance with the heuristic order shown. For example Heuristic 1 may be processed before Heuristic 2 Heuristic 2 processed before Heuristic 3 and so forth. It should be appreciated that other types of heuristics or any other heuristic order may also be applied. In one implementation the question parser considers only keywords extracted based on the first 4 heuristics keywords extracted based on the last 2 heuristics may be considered only if more keywords are needed to identify the answer. Alternatively if an answer cannot be found using any of the extracted keywords keywords may be dropped in a reversed order in which they have been entered in next several iterations of search so as to broaden the search criteria.

Returning to at the QA processor identifies the type of knowledge database KB available for providing data to the QA framework . As discussed previously the KB may be a question answer paired KB a plain text KB an RDF KB and or any other type of KB. The data from the different types of KB may be downloaded and stored in the database or retrieved directly from the KB using for instance a crawler application in the data collector . The type of KB available may be stored in a configuration file. Different search strategies may be implemented for different types of data from the different types of knowledge databases. It should be appreciated that more than one type of knowledge database may be available. By supporting different types of knowledge databases the present technology is able to provide a high answer finding rate using an expanded collection of knowledge databases.

In one implementation at the QA processor determines that a question answer paired KB is available. At the answer retrieval and ranking unit invokes a full text search by the DBMS to generate search results . shows a table containing exemplary question answer paired data from a question answer paired KB. The table may be downloaded from the question answer paired KB and stored in for example the database . As shown each row of the table stores a pair of question or TITLE and answer or CONTENT . To facilitate the search two full text indexes may be generated based on the columns TITLE and CONTENT which represent question and answer contents.

The answer retrieval and ranking unit may invoke the full text search of the question answer paired data by generating a query statement e.g. SQL based on one or more question properties e.g. focus keywords etc. and sending the query statement to the query language processor of the DBMS for processing and execution. The full text search may be performed based on the full text indexes rather than the original table.

As discussed previously the full text search may provide fault tolerance for user input of the question text. This allows the search to accommodate typographical errors and improve search quality by returning more possible search results. In one implementation an n gram matching algorithm is used to provide a fuzzy full text search. shows an exemplary n gram model . For each string a set of n grams may be generated. The fuzzy search may be performed by matching the n grams of the input string with the n grams of the data string. For example assuming that the input string is hans and the data strings are gans and haas the fuzzy match score between hans and gans is 63 i.e. 5 out of 7 n grams match while the fuzzy match score between hans and haas is also 63 . If the desired minimum match score is less than 63 the data strings hans and haas are returned as search results.

Returning to at the answer retrieval and ranking unit ranks the search results to determine the most relevant candidate answer. The search results may include a set of candidate question answer pairs related to the input question. The answer retrieval and ranking unit may rank the search results by assigning a score to each candidate question answer pair. The most related question is identified based on the scores and the corresponding answer is returned as the candidate answer.

In some implementation a fuzzy score is assigned to each candidate question answer pair. The fuzzy score may be computed by determining a measure of similarity between the input question and candidate questions. The measure of similarity is determined by comparing the words in the input question and each candidate question. For example if the input question is Who is Bill Gates and the candidate question contains the exact same words the fuzzy score is 1.0. However if the candidate question is Who is Bill Gate s daughter the fuzzy score may be computed as follows SCORE Common Word Count Word Count of Input Question Word Count of Candidate Question 4 4 5 0.894. 1 

At the QA processor may determine that a plain text KB is available. At a search is performed on plain text data from the plain text KB. The question parser may construct a query statement based on a mining set of search terms e.g. keywords focus etc. associated with the input question. The query statement is then sent to the query language processor for processing and to invoke the search to generate search results. Candidate plain text paragraphs may be returned as search results.

The answer retrieval and ranking unit may iteratively refine the search by broadening or narrowing the search criteria until the number of search results meets a pre specified threshold. The search may be broadened by expanding the mining set of search terms i.e. conflation . A synonyms dictionary e.g. WordNet may be used to add synonyms of extracted question properties e.g. focus keywords etc. to the mining set.

For example the input question may be as follows Who is the principal of Thomas Jefferson high school . The keywords may be principal Thomas Jefferson high school and the focus may be principal . The answer retrieval and ranking unit may use expanded keywords to perform the search. Expanded keywords are obtained by for example mapping original keywords or stems of keywords to synonyms as previously described. For example if the keywords are high school the synonym senior may be added to the mining set which may include the following 

In the above mentioned mining set of search terms the word high may be considered too common in the English language and may represent a totally different meaning than the original keywords high school by itself or combined in other phrases. Such common words may be removed from the mining set to yield more accurate search results. To identify common words the answer retrieval and ranking unit may perform a look up on a pre defined list of common words.

Another method of expanding the mining set of search terms to broaden the query is via stemming. Stemming generally refers to a process for reducing inflected or sometimes derived words to their stem base or root form. For example a stemmer for English may identify the string cats and possibly catlike catty etc. based on the root cat and stemmer stemming stemmed based on stem . Once the stem of a keyword is determined variations of the stem may be added to the mining set of search terms to broaden the query.

At the answer retrieval and ranking unit ranks the search results to determine the most relevant candidate answer. The search results may include a set of plain text candidate paragraphs. The number of candidate paragraphs may be very large particularly when the keywords of the input question are common or ordinary words. The answer retrieval and ranking unit may rank the candidate paragraphs by assigning a score to each candidate paragraph. The candidate paragraph most relevant to the input question may be identified based on the scores and returned as the candidate answer.

In one implementation the score includes a term frequency inverse document frequency TF IDF score. A TF IDF score is computed by counting the number of words or synonyms of the words that are common to both the candidate paragraph and the input question. For example if the candidate paragraph shares a same common word with the input question 2 points may be assigned. If the candidate paragraph shares a same synonym with the input question 1 point may be assigned. No points may be assigned if there are no common words or synonyms. The final score for the candidate paragraph may be obtained by the following Final Score Total Score Number of different words 2 

In some cases the text of the original candidate paragraph may be too long and therefore not suitable as a candidate answer. Before computing the score and ranking such candidate paragraph the answer retrieval and ranking unit may segment the long text of the candidate paragraph into smaller segments of text. In one implementation hierarchy information in metadata provided by the knowledge database is used to split the search result text. For example original web pages from Wikipedia contain hierarchy information of each paragraph in the metadata that may be used to segment the text. Other information such as font size and indentation format may also be used to derive the hierarchy and segment the text.

In some implementations particularly where there is no information available for segmentation a tokenization method is used to segment the text. The original text may be tokenized by removing stop words and using the remaining words as basic units. Stop words generally refer to words that are filtered out prior to or after processing the natural language text. For example the is are etc. are very common words that may be considered stop words.

Referring back to at the answer assembler constructs the candidate answer based on the most relevant candidate paragraph. There are many ways of delivering the same answer. In one implementation the answer assembler determines the template of the input question and maps the question template to an answer template. The candidate answer may then be assembled in accordance with the answer template.

In some cases the level of detail in the most relevant paragraph may be too high and needs to be further reduced to yield higher precision. For instance the question may be as follows 

It should be appreciated that not all paragraphs may be refined or shortened. For example a factoid question such as Why is the sky blue may yield the following paragraph The sky is blue because of the way the Earth s atmosphere scatters light from the sun. It is not necessary to shorten such paragraph. The entire paragraph may be returned as the candidate answer.

To extract the candidate answer from the paragraph the answer assembler may employ a machine learning framework. For example the input question may be as follows 

In some implementations the training set is generated by first collecting a set of known question and answer pairs. For example the question When was Bill Gates born may be paired with the known answer Oct. 28 1955. The set of known question and answer pairs may then be analyzed to extract the key words e.g. Bill Gates born etc. . The internet e.g. Google Bing Yahoo etc. or other knowledge databases may be searched via for example a search engine to collect documents associated with the key words. Unnecessary sentences in the documents that do not include the keywords may be removed. In addition the documents may be tokenized for further analysis. The longest matching strings may be retrieved from the original documents to form the training set.

For example the following training information may be collected Entrepreneur Bill Gates was born on Oct. 28 1955 in Seattle Wash. Bill Gates born on 28 Oct. 1955 Seattle Wash. is the founder of Microsoft and so forth. Based on the collected information the following answer templates may be identified i was born on and ii born on .

After the training set is generated the candidate answer may be extracted from input paragraphs. For purposes of illustration assume that the input question is When was Wolfgang Amadeus Mozart born . The original text of a paragraph returned by the answer retrieval and ranking unit may be as follows Wolfgang Amadeus Mozart was born on 1756 . Based on the training set the input question type may correspond to the answer template was born on . Since the paragraph matches the answer template the answer 1756 may be extracted as the candidate answer.

The above mentioned answer assembly mechanism is particularly suitable for factoid and certain types of questions. However it should be appreciated that not all types of questions may be processed by the above mentioned answer assembly mechanism. A degradation mechanism may be required for certain question types. For instance if answer extraction is difficult the answer assembler may search the paragraph only by the keywords and return only the search result as the candidate answer. Although answer accuracy may not be high at least basic related information is provided to the end user.

Referring back to at the QA processor may determine that an RDF KB is available. At the answer retrieval and ranking unit invokes an RDF search by the DBMS . The RDF search may be invoked by submitting a query constructed by the user using SPARQL Protocol and RDF Query Language SPARQL . SPARQL is standardized by the RDF Data Access Working Group of the W3C and is an official W3C recommendation. SPARQL allows for a query to include triple patterns conjunctions disjunctions patterns etc. SPARQL also allows for federated queries where the query is distributed to multiple locations and results from the distributed query are aggregated. SPARQL queries are translated to SQL queries before processing by query language processor .

Alternatively the above mentioned input question may be translated into a more readable SPARQL query as follows 

To facilitate the query formulation process a SPARQL to SQL mapping engine may be implemented. This allows SPARQL queries to be supported by an SQL based DBMS. To map keywords to SPARQL triple patterns relevant Internationalized Resource Identifiers IRIS related to each keyword may first be retrieved. An IRI within an RDF graph is a Unicode string that conforms to the syntax defined in RFC 3987 IRI . IRIs generalize uniform resource identifiers URIs or uniform resource locators URLs . Every absolute URI or URL is an IRI.

Next a pre configured SPARQL triple pattern template is applied to the query based on the retrieved IRIs. Some SPARQL triple pattern templates may be configured based on observations of YAGO facts e.g. predicates like etc. . For keywords that have no pre configured patterns the DBMS performs a full text fuzzy search on the subject and object columns to retrieve an approximately matching IRI in the YAGO facts table. The matching IRI is then used in the SPARQL query.

As discussed previously to enable a full text search on subject and object columns a full text search index may first be created on the subject and object columns. The answer retrieval and ranking unit may generate the following SQL statement to perform the fuzzy search 

If no answer is retrieved with the selected SPARQL query the query may be repeated with a reduced fuzzy co efficient and or reduced number of keywords until some answers are retrieved.

After the search results are obtained the number of search results i.e. count is compared to a pre specified threshold. If the search count is less than the pre specified threshold the search criteria may be broadened by for example removing search terms and or changing logical operators between the search terms from AND to OR. For example the original search criteria may be as follows principal Thomas Jefferson high school . The search criteria may be expanded to the following principal school principal head teacher Thomas Jefferson high school senior high school .

Conversely if the search count is higher than the pre specified threshold the search criteria may be narrowed by for example adding search terms and or changing logical operators between the search terms from OR to AND. Accordingly a suitable number of search results e.g. text paragraphs may be returned.

Referring back to at the answer retrieval and ranking unit ranks the RDF search results to determine the most relevant candidate answer. The answer retrieval and ranking unit may rank the RDF search results by assigning a fuzzy score or any other suitable score to each RDF search result. The most related question may be identified based on the score and the corresponding candidate answer is returned as the candidate answer.

At the QA processor determines whether there are any other types of KB available. If so step is repeated to determine what type KB is available. It should be appreciated that steps and or may also be performed in parallel to obtain the search results .

At the QA processor evaluates the candidate answers to find the final answer to be returned to the user. Each type of knowledge database e.g. question answer paired KB plain text KB RDF KB etc. may yield zero or one candidate answer. Where there are multiple types of knowledge databases there may be multiple candidate answers.

Since it is not easy to compare the candidate answers obtained from the different types of knowledge databases the QA processor may use one or more pre defined heuristic rules based on the question type to determine the final answer. In some implementations all the candidate answers are ranked to find the final best one. The ranking may be based on one or more pre defined heuristic rules. For example if the candidate answer was retrieved from a question answer paired KB and its SCORE is greater than or equal to 80 the candidate answer will be returned as the final answer. Such candidate answer is deemed the most accurate and thus assigned the highest priority because question answer pairs are defined manually. Next if no candidate answer was retrieved from a question answer paired KB the answer assembler determines if the input question is a pure factoid question. If so the candidate answer retrieved from an RDF KB is returned as the final answer if possible. RDF data are structure data that are naturally suitable for factual description which is typically used to answer a factoid question. Factoid questions are questions such as what is who is and etc. Next if there is no suitable candidate answer retrieved from an RDF KB the candidate answer retrieved form the plain text KB is returned as the final answer.

In some cases the QA processor may determine that all the candidate answers are not good enough or that there is no candidate answer. In such case the answer assembler may send a text message to the end user such as Sorry I don t know the answer. 

The evaluation process may be refined by recording the feedback from the end user in historical question and answering tasks. In such case the user may rate or input a ranking score for each answer. The QA processor may also allow the end user to correct the answer and manually answer the question. The QA processor may then improve its question answering capability based on the user feedback.

Although the one or more above described implementations have been described in language specific to structural features and or methodological steps it is to be understood that other implementations may be practiced without the specific features or steps described. Rather the specific features and steps are disclosed as preferred forms of one or more implementations.

