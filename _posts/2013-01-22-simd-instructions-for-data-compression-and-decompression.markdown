---

title: SIMD instructions for data compression and decompression
abstract: An execution unit configured for compression and decompression of numerical data utilizing single instruction, multiple data (SIMD) instructions is described. The numerical data includes integer and floating-point samples. Compression supports three encoding modes: lossless, fixed-rate, and fixed-quality. SIMD instructions for compression operations may include attenuation, derivative calculations, bit packing to form compressed packets, header generation for the packets, and packed array output operations. SIMD instructions for decompression may include packed array input operations, header recovery, decoder control, bit unpacking, integration, and amplification. Compression and decompression may be implemented in a microprocessor, digital signal processor, field-programmable gate array, application-specific integrated circuit, system-on-chip, or graphics processor, using SIMD instructions. Compression and decompression of numerical data can reduce memory, networking, and storage bottlenecks. This abstract does not limit the scope of the invention as described in the claims.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09298457&OS=09298457&RS=09298457
owner: Altera Corporation
number: 09298457
owner_city: San Jose
owner_country: US
publication_date: 20130122
---
The technology described herein relates to encoding and decoding of numerical data using specialized single instruction multiple data SIMD instructions for efficient storage and or transfer of encoded data in a computing system.

In present high performance computing applications it is often necessary to transfer vast amounts of numerical data among multiple processor cores or between processor cores and memory. The limited data transfer rates of interfaces among processor cores and between cores and memory devices can create bottlenecks for overall data processing speed and performance. In data rich applications storage of numerical data challenges memory resources and storage devices. Reducing the demands on data transfer and storage capacity for numerical data can improve the efficiency economy and performance of the computing system. Compression of numerical data may reduce these demands however at the cost of additional computations. In applications having vast quantities of numerical data it is especially important that the compression be computationally efficient in order to minimize demands on computing resources.

In present microprocessor architectures single instruction multiple data SIMD processing performs the same operation indicated by a single instruction on multiple data elements or operands. A SIMD operation is performed in parallel on the multiple operands rather than sequentially thus accelerating computations. Advantages of SIMD implementations include reduced processing time over sequential processing decreased numbers of instructions and greater processing efficiency. Implementations of SIMD technology are available from many companies including 

The previous list of SIMD implementations is not meant to be exhaustive only illustrative that SIMD processing has been widely integrated into microprocessor architectures. Embodiments of the present invention utilize novel SIMD constructs and defines functionality that may be implemented in new SIMD instructions to accelerate the process of encoding and decoding a plurality of numerical samples per instruction.

Commonly owned patents and applications describe a variety of compression techniques applicable to fixed point or integer representations of numerical data or signal samples. These include U.S. Pat. No. 5 839 100 the 100 patent entitled Lossless and loss limited Compression of Sampled Data Signals by Wegener issued Nov. 17 1998. The commonly owned U.S. Pat. No. 7 009 533 the 533 patent entitled Adaptive Compression and Decompression of Bandlimited Signals by Wegener issued Mar. 7 2006 incorporated herein by reference describes compression algorithms that are configurable based on the signal data characteristic and measurement of pertinent signal characteristics for compression. The commonly owned U.S. Pat. No. 8 301 803 the 803 patent entitled Block Floating point Compression of Signal Data by Wegener issued Apr. 28 2011 incorporated herein by reference describes a block floating point encoder and decoder for integer samples. The commonly owned U.S. pat. application Ser. No. 13 534 330 the 330 application filed Jun. 27 2012 entitled Computationally Efficient Compression of Floating Point Data by Wegener incorporated herein by reference describes algorithms for direct compression floating point data by processing the exponent values and the mantissa values of the floating point format. The commonly owned patent application Ser. No. 13 617 061 the 061 application filed Sep. 14 2012 entitled Conversion and Compression of Floating Point and Integer Data by Wegener incorporated herein by reference describes algorithms for converting floating point data to integer data and compression of the integer data. At least a portion of the operations for compression and decompression described in these applications may be implemented using the SIMD technology described in the present specification.

The commonly owned patent application Ser. No. 12 891 312 the 312 application entitled Enhanced Multi processor Waveform Data Exchange Using Compression and Decompression by Wegener publication number 2011 0078222 published Mar. 31 2011 incorporated by reference herein describes configurable compression and decompression for fixed point or integer numerical data types in computing systems having multi core processors. In a multi core processing environment input intermediate and output waveform data are often exchanged among cores and between cores and memory devices. The 312 application describes a configurable compressor decompressor at each core that can compress decompress integer or numerical waveform data. The 312 application describes configurable compression decompression at the memory controller to compress decompress integer or numerical waveform data for transfer to from off chip memory in compressed packets. At least some operations of the configurable compressor and decompressor of the 312 application may be implemented using the SIMD technology described in the present specification.

The commonly owned patent application Ser. No. 13 617 205 the 205 application filed Sep. 14 2012 entitled Data Compression for Direct Memory Access Transfers by Wegener incorporated herein by reference describes providing compression for direct memory access DMA transfers of data and parameters for compression via a DMA descriptor. The commonly owned patent application Ser. No. 13 616 898 the 898 application filed Sep. 14 2012 entitled Processing System and Method Including Data Compression API by Wegener incorporated herein by reference describes an application programming interface API including operations and parameters for the operations which provides for data compression and decompression in conjunction with processes for moving data between memory elements of a memory system. The SIMD instructions described herein may be implemented for the compression and decompression operations described in the 205 application and the 898 application.

In order to better meet the requirements of higher speed data transfer reduced memory utilization and minimal computation in many computing applications a need exists for computationally efficient compression and decompression of numerical data using SIMD technology.

Computational efficiency gained by SIMD implementations of compression of numerical data can provide for more efficient data transfer and memory utilization.

In one aspect data compression of numerical data may be implemented using resources of a computer system. The data processor of the computer system may execute SIMD instructions that implement at least a portion of the operations for compression of data samples. The operations include determining a maximum exponent value for operands of a first register corresponding to an encoding group of data samples interleaving bits of the operands to produce a plurality of nibbles to store in a second register wherein the bits are mapped to a given nibble based on a place value of the bits in respective operands. A subset of nibbles is selected from the plurality of nibbles in the second register wherein a number of nibbles for the subset is based on the maximum exponent value. The subset of nibbles includes interleaved mantissa bits of the operands. The interleaved mantissa bits of the subset of nibbles are packed in a compressed data packet wherein the packed interleaved mantissa bits represent compressed data for the encoding group of data samples.

An exponent token may generated to represent the maximum exponent value an exponent difference between maximum exponent values for a current encoding group and a previous encoding group or a pair of exponent difference values. The exponent token is stored in the compressed data packet.

In one aspect the data samples may provide the operands for the first register. In other aspects redundancy removing operations may be applied to the data samples and the resulting samples are provided as operands to the first register. The redundancy removing operations may include calculating first or higher order derivatives of the data samples and or attenuating the data samples. One or more of the redundancy removing operations may be implemented using SIMD instructions and registers.

In another aspect decompression of compressed data may be implemented using resources of a computer system. The data processor of the computer system may execute SIMD instructions that implement at least a portion of the operations for decompression of compressed data. Compressed data stored in a compressed data packet includes exponent tokens and packed interleaved mantissa bits for a plurality of encoding groups. The operations include transferring a plurality of compressed data bits from the compressed data packet to a decode bit register. For processing the exponent tokens the operations include extracting and decoding an exponent token from the decode bit register to produce at least one decoded exponent value wherein each decoded exponent value corresponds to a particular encoding group. For processing the packed interleaved mantissa bits the operations include transferring a portion of the compressed data bits from the decode bit register to a packed mantissa register the portion including packed interleaved mantissa bits corresponding to the particular encoding group transferring a subset of nibbles from the packed mantissa register to a first subset of nibbles in a staging register and inserting fill values into a second subset of nibbles in the staging register. The decoded exponent value indicates the number of nibbles from the subset from the packed mantissa register that form the first subset in the staging register. Deinterleaving the bits of the nibbles in the staging register produces a plurality of operands to store in a first register. The deinterleaving maps bits of a given nibble based on a place value of the bits in respective operands. The resulting operands have a data format used by the data processor.

In one aspect the resulting operands represent decompressed data samples. In other aspects signal regeneration processing is applied to the operands to produce the decompressed data samples. The signal regeneration operations may include calculating first or higher order integration and or amplifying the operands. One or more of the redundancy removing operations may be implemented using SIMD instructions and registers.

Other aspects and advantages of the present invention can be seen on review of the drawings the detailed description and the claims which follow.

Embodiments of the compression and decompression described herein may encompass a variety of computing architectures that represent digital data using a numerical format referred to herein as numerical data. Numerical data may include both integer data of various bit widths such as 8 bits 16 bits 32 bits 64 bits etc. and floating point data of various bit widths such as 32 bits 64 bits or 128 bits. The numerical data may be generated by a variety of applications and the computing architectures may be general purpose or specialized for particular applications. The numerical data may result from detected data from a physical process a data created by computer simulation or intermediate values of data processing. For example the numerical data may arise from analog sensor signals that are converted by an analog to digital converter ADC to a digital signal whose samples are represented in a numerical format typically an integer format. For another example the digital data may be spatial data points for a simulated computer graphics image in either integer or floating point format.

The preprocessor block includes processes to prepare the input data for the compression operations. These may include a number aligner in embodiments including a hardware accelerator coupled to an internal bus on the integrated circuit. The number aligner aligns samples to be compressed of one width with the internal bus which may have a different width from that of the samples. In one example an internal bus may be a 64 bit wide interface to DDR memory DDR3 while the samples to be compressed are 16 bit integers. In another example an internal bus may be a 128 bit wide bus and the samples to be compressed may be 32 bit single precision floating point data. Floating point samples may be input directly to the selector or converted to an integer format by a floating point prepreprocessor prior to compression operations. Integer samples may be delivered directly to the selector . Image samples are delivered to an image preprocessor which can perform a variety of functions unique to image file encoding color space conversion color space decimation and the like. For some applications the samples can be delivered to a center frequency estimator which can be applied for sample streams that can benefit from a redundancy removal algorithm that depends on the center frequency of the sample stream. The output of the center frequency estimator is applied to the control block which utilizes the center frequency to generate a stride parameter for the redundancy remover as discussed below.

The inputs to the selector include the output of the floating point preprocessor the samples delivered directly from the number aligner and the output of the image preprocessor . The selector selects the appropriate data stream based on parameters applied by the control block to provide input samples for the compressor block . The parameters may be determined from a DMA descriptor compliant with the API delivered to the control block .

The compressor block can include a redundancy remover and a bit packer . The compressor can implement compression algorithms that can be configured for lossless and lossy compression in response to parameters provided by the control block . A header generator is included with the redundancy remover and the bit packer for use in the assembly of packets to be delivered on line including the compressed data after redundancy removal. Embodiments of the redundancy remover and bit packer using SIMD operations are described with respect to .

The control block controls the routing of the samples through the various logic blocks and applies the parameters of the compression as needed to the various logic blocks. The control block also controls an attenuation factor utilized in some compression modes to control fixed rate or fixed quality operations for example those based on statistics fed back about the characteristics of compressed packets. The control block may receive a DMA descriptor that provides for instance data type parameters for the selector and compression parameters for the compressor .

The decompressor block includes a bit unpacker and a signal regenerator that expand the compressed data to produce decompressed samples. Decompression parameters may be extracted from packet headers by the header extractor . The control block provides parameters extracted from the packet headers to the decompressor to configure decompression operations. A DMA descriptor or an API may provide additional parameters such as data type to the control block . These may be used by the postprocessor to perform appropriate operations.

The bit unpacker and header extractor process the compressed data packet to separate header bits and compressed data bits. The header bits of the packets are extracted and delivered to the control block . The parameters from the extracted packet header are used by the control block to control the signal regenerator . Embodiments of the bit unpacker and header extractor as described in more detail below with respect to .

The signal regenerator performs inverse operations of the redundancy remover . Embodiments of the signal regenerator using SIMD operations are described in further detail below. The output of the signal regenerator is applied to an appropriate unit of the postprocessor block . Depending on the incoming data type the output of the signal regenerator can be routed through the floating point postprocessor or through the image postprocessor . The floating point postprocessor may perform integer to floating point format conversion to invert format conversion performed by the floating point preprocessor . The selector is controlled by the control logic in response to the API parameters DMA descriptor parameters or parameters carried by the packets being decompressed. The inputs to the selector include the output of the floating point postprocessor the direct output of the signal regenerator or the output of the image postprocessor in this example. The output of the selector is then applied to a number aligner complementary to that discussed above connection when necessary to form the output .

Additional aspects of the components shown in are described in the 061 application the 205 application and the 898 application. In light of the organization of the components shown in some details of the individual components of the compression and decompression functions using SIMD registers and instructions are provided next.

The example instruction formats above are illustrative of a few possible instruction syntaxes that SIMD instruction sets might use to express the same result. Other instruction syntaxes are possible and do not restrict the form of SIMD instructions in embodiments of the present invention. Companies that develop SIMD architectures such as Intel AMD ARM etc. often develop their own SIMD instruction set syntax or they may adopt the instruction syntax of another company. The various SIMD operations described in the present specification will use the following instruction syntax dType REG C REG A operator REG B where dType indicates the data type of the operands and and operator indicates the desired operation . Typically but not exclusively operator has a special prefix suffix or other label that indicates a SIMD operation. For instance Intel s SIMD instructions often contain the letters P for parallel or V for vector in the operand to indicate that the instruction is a SIMD instruction. Operations may be unary one input value or operand generates one output value binary two input values or operands generate one output value or tertiary three input values or operands generate one output value although other operators may accept or require other numbers of input operands and may generate other numbers of output results. Operands may also include memory address from which input samples may be read or a memory address to which output samples may be written. SIMD instructions may also include immediate values operands whose value is encoded in the instruction and selection of various options for the SIMD operation.

For example for addition and subtraction operators the four operands B B B B in SIMD register REG B are added to or subtracted from the four operands A A A A in SIMD register REG A resulting in the answer C C C C in SIMD register REC C . In this example 

In many applications mathematical operations are applied to sequences of samples that represent a waveform that in turn may represent signal samples such as the output of analog sensors digitized by an analog to digital converter ADC one or more rasters or color planes of an image sequences of pixel arrays representing video etc. As described in the 312 application sampled data waveforms are often but not exclusively obtained by digitizing real world analog signals such as speech audio images video or other sensor output signals using an analog to digital converter ADC . Sampled data signals can also be simulated and can either be fed directly or after additional waveform data processing operations to a digital to analog converter DAC in order to generate analog speech audio images or video signals. In this specification the term sampled data waveforms also includes such intermediate and or final sampled data waveforms generated from mathematical and or logical operations performed upon input or intermediate sampled data waveforms.

The SIMD derivative instruction generates the first derivative of a sequence of five samples from SIMD register REG A and register and stores the result in REG B

In sample A is stored in register not in SIMD register REG A . Alternative embodiments for SIMD registers to store sample A and its predecessor samples A A etc. are described below with respect to . illustrates extended capabilities of s DERIV instruction in accordance with a preferred embodiment. Sometimes sequences of samples are interleaved i.e. odd and even indices in an array contain samples from two different numerical sequences. In this case samples with odd indices A A A A etc. are correlated and samples with even indices A A A etc. are correlated with each other. In this case the DERIV instruction includes an additional parameter called stride that indicates the distance between correlated samples in the sequence.

B A A B A A B A A B A A For example in SIMD instruction the stride is indicated as the second parameter to the DERIV instruction REG B DERIV REG A .

The maximum exponent or block exponent is used for efficient encoding and packing of the group input samples from register REG A as further described below. The maximum exponent or block exponent corresponds to a group of samples referred to herein as an encoding group. For the examples of the SIMD register holds four samples for the encoding group corresponding to the maximum exponent.

The SIMD instructions described above may be used in a computer program for removing redundancy from numerical data. The redundancy removal operations reduce the dynamic range of numerical input operands. The exponent calculation instructions determine the number of relevant bits or block exponent for an encoding group of the range reduced samples. The block exponent for the encoding group is used for efficient bit packing operations to form compressed data packets.

The nibble interleaver may also be applied to operands whose bit width is other than 32 bits. For the SIMD register length of 128 bits for example Intel SSE SSE2 SSE3 at least the following combinations are possible 

For a SIMD register length of 256 bits for example Intel AVX at least the following combinations are possible 

A preferred implementation of the nibble interleaver network may use wires connecting the bit locations of the register to the appropriate locations in register to produce the sequential order of nibbles as shown in . This implementation has the advantage of minimizing delay for the interleaving operation. A useful feature of nibble interleaver is that its operation can be performed entirely using wires such as by nibble interleaving network rather than combinatorial logic transistors . In system on chip SoC implementations which are also called application specific integrated circuits ASICs transistors and wires are combined to create the functional elements of integrated circuits. An attractive feature of implementing nibble interleaving using wires is that they require significantly less delay than cascades of combinatorial logic elements transistors . A nibble interleaver implemented using only the wires of nibble interleaving network will operate both faster and with lower latency than an alternate implementation that uses combinatorial logic elements.

The bit packing operations described below include selecting subset of bits from samples to be packed. The sequential order of nibbles allows simpler operations for selecting a subset of bits from the register REG Ai for bit packing operations.

Ordinarily selecting four M bit subsets of the four 32 bit samples val3 val2 val1 val0 would require several circuits called masking circuits and barrel shifters. Masking circuits typically clear set to 0 one or more bits of an input operand masking circuits can optionally clear either the Nmask most significant bits or Nmask least significant bits of an input operand. Barrel shifters are relatively complex devices that position input operands in one of several output bit locations by shifting the input operands to the left up shifting or to the right down shifting .

An alternate implementation for bit packing that may employ masking circuits and barrel shifters. For example the alternative implementation could pack the four operands val3 val2 val1 val0 of SIMD register REG A with example exponent 19 into SIMD register REG Ai in the following way 

In contrast the preferred implementation for the nibble interleaver groups the input bits in a different order based on place value as illustrated in s REG Ai using only wires. For the bit packing example a subset of 75 sequential bits may be selected from in REG Ai 75 0 . In the design of SoC and ASIC devices faster speed and lower latency are preferable features. The preferred implementation of the nibble interleaver can operate significantly faster and with less latency than an alternate bit packer implemented using masking circuits and barrel shifters.

In a preferred embodiment for bit packing operations a subset of bits is selected from the interleaved bits of REG Ai . The selection operation may depend upon the data type of operands in SIMD input register.

For example SIMD input register RA may contain four 32 bit operands whose operands may be four 32 bit integers or four 32 bit floating point samples. SIMD register RB holds the results of SIMD instruction RB DERIV RA the first derivative of the input samples from the SIMD input register . SIMD register RC stores the result of SIMD instruction RC DERIV RB the second derivative of the input samples from the SIMD input register . Registers RAe RBe and RCe respectively hold the block exponents for SIMD registers RA RB and RC . Derivative selection signal DERIV SEL controls the operation of SIMD register selector and exponent register selector . In one alternative the derivative selection signal may be set in accordance with a parameter selected by a user. In another alternative the redundancy remover may measure the samples and derivatives and set the derivative selection signal to select the registers providing the most compression. In a preferred embodiment derivative selection signal is fixed for each group of samples to be stored in the same compressed data packet and derivative selection signal is indicated in the packet header as further described with respect to .

The register selector provides access to the selected SIMD register RA RB or RC for the nibble interleaver . The register selector may be implemented by a mux with three inputs from registers and one output provided to the nibble interleaver . The widths of the mux inputs and output are preferably the same as the SIMD registers . For this example the widths are 128 bits but other widths are possible. The nibble interleaver reorders the bits of the operands of the selected register according to their place value as described with respect to and stores the interleaved bits in register RD . For this example of four operands in each register each nibble in the register RD has one bit from each operand of the selected register. Intermediate SIMD registers RE and RD store the nibble interleaved output of nibble interleaver for sequential encoding groups.

The maximum exponent values for the registers are calculated in accordance to the EXPMAX instructions and stored in the corresponding exponent registers as described with respect to . The selector selects the exponent register RAe RBe or RCe in accordance with the derivative selection signal . The selected exponent register RAe RBe or RCe corresponds to the selected SIMD register RA RB or RC. Sequential selected exponent values are stored in registers and . Register stores the exponent e from a previous iteration. Differences between the selected maximum exponent values for successive iterations are calculated and stored in the exponent difference registers and . Exponent difference register holds the difference d between the maximum exponent value e and the maximum exponent value that preceded e e while exponent difference register holds the difference between maximum exponent value e and maximum exponent value e. The exponent token generator further described with respect to generates exponent token tok that requires token length TOK LEN bits. In a preferred embodiment the exponent token lengths may be 0 4 or 8 bits. The SIMD registers RE and RD store the sequential nibble interleaved outputs of nibble interleaver while exponent token generator generates exponent token . Output staging register RF stores the exponent token and a version of intermediate register that has been shifted by token length TOK LEN bits.

Output size register stores the number of bits Nnew to be packed by the encoded memory packer which is further described with respect to . If the data type of operands in the input register RA is 32 bit integer a number of least significant nibbles from the output staging register RF as described with respect to will be packed. If the data type of operands in input register are 32 bit floats a number of most significant nibbles from the output staging register RF as described with respect to will be packed. The number of bits to be packed including exponent tokens and encoded mantissas for the encoding group is indicated by the parameter Nnew.

The exponent token generator provides exponent tokens based on the exponent difference values or the maximum exponent values. shows a preferred encoding table of the exponent token generator for the mapping between the exponent tokens and the exponent difference values or the maximum exponent values. The inputs to exponent token generator include maximum exponent e maximum exponent e exponent difference d and exponent difference d . An exponent token can represent one maximum exponent e or maximum exponents e and e represented indirectly by exponent differences d and d . Exponent token generator generates exponent tokens that fall into three conditions 

When exponent differences d and d are both in the range to the corresponding maximum exponents e and e can be represented using a 4 bit exponent token whose token length is 4 bits. When exponent differences d and d are not both in the range 1 to 1 but exponent difference d is in the range 2 to 2 the single exponents e can be represented using a 4 bit exponent token whose token length is 4 bits. When either d or d fall outside the range 2 to 2 the maximum exponent e is absolutely encoded using an 8 bit exponent token whose token length is 8 bits. In this final condition the exponent token begins with the 3 bits 111 followed by the 5 bits abcde which can represent absolute exponent lengths from 0 to 32. When the exponent for an encoding group is 0 no mantissa bits are sent for that encoding group. Exponent token generator also calculates the total number of exponent token bits plus mantissa bits to determine Nnew the number of bits to be packed for the encoding group. The number of bits for each encoded mantissa in the encoding group is given by the maximum exponent value. The number of mantissa bits in the encoding group is given by the number of mantissas in the encoding group multiplied by the number of bits per encoded mantissa. Exponent token generator may generate one or two exponent tokens token length TOK LEN 1844 values and Nnew values depending on the d and d values. During joint exponent encoding when only one token is generated for two maximum exponents no exponent token is encoded for the second mantissa group as indicated by the token lengths for the rows . The resulting encoded groups correspond to the configuration shown in . For example when d d2 0 0 exponent token is 0100 token length is 4 for the first mantissa group and 0 no token for the second mantissa group. Similarly Nnew is e1 4 for the first mantissa group and e2 for the second mantissa group. The 803 patent entitled Block Floating point Compression of Signal Data describes other embodiments of the exponent token generator .

The example of the redundancy remover depicted in calculates first order and second order derivatives and the corresponding maximum exponent values for the registers . The selectors each select from three alternatives in accordance with the with the derivative selection signal . In other embodiments the redundancy remover may include registers and instructions for additional higher order derivatives wherein the selectors may select from more than three alternatives. In another embodiment the redundancy remover may calculate the first order derivative not the second order derivative using two registers and two exponent registers and the selectors would select from two alternatives. In another embodiment the redundancy remover may use a fixed derivative order and would not include selectors and . In another embodiment the redundancy remover may calculate the maximum exponent of the input samples in register for the exponent register and may not include derivative operations the associated registers and and the selectors and . For this alternative embodiment the bit packer would encode and pack the block exponents and mantissas of the input samples in register

After packing the new bits into output registers and or if the updated bit count register equals or exceeds Nout all Nout bits of formerly active register will be written to encoded output array . illustrates the details of how the active register s Nout bits are written to encoded output array under the control of write control logic . Memory arrays may use at least 3 registers to write to locations in the associated encoded output array 

Write control logic maintains a packed array pointer that holds the address of the next location to be written in packed array . After bit count register has been incremented by Nnew or HDR LEN write control logic detects when the MSbit of bit counter has changed state from 0 to 1 or from 1 to 0 . When this occurs the previous active register now contains Nout bits that will be written to packed array . To perform this write write control logic activates write enable signal which causes the contents of data register to be written to the address specified in address register the address stored in packed array pointer . If MSbit is set to 1 the Nout bits of output register will be written to data register . If MSbit is set to 0 the Nout bits of output register will be written to data register . Write mux is controlled by the inverted MSbit signal inverted by inverter . When the input to inverter is a 0 the output is a 1. When the input to inverter is a 1 the output is a 0. After the newly written data value in data register has been written to packed array write control logic enables the address increment signal which increments the output pointer. Packed array pointer may be incremented by 1 or other appropriate amount depending on the addressing scheme used to access packed array . The packed array may hold one or more compressed data packets described with respect to .

To summarize have described embodiments of the compressor or numerical encoder which accepts integer or floating point input samples in a SIMD input register and generates encoded compressed data arranged in compressed data packets and written to packed array using a sequence of SIMD instructions. will now describe the operations of the decompressor or numerical decoder which accepts encoded compressed data from a compressed data packet and outputs decoded integer or floating point samples in a SIMD output register. The decompression operations include operations for bit unpacking and signal regeneration. Operations for bit unpacking process the compressed data packets to produce unpacked mantissas and decoded exponents for the encoding groups. Operations for signal regeneration invert the operations of the redundancy removal applied for compression to produce decompressed samples. In the examples described in the SIMD registers are assumed to have a width of 128 bits and store four 32 bit integers or four 32 bit floating point samples. In alternative implementations the SIMD registers could hold more or fewer than 128 bits and the operands in the SIMD registers could be 8 16 32 64 where operands typically are an integer divisor of the SIMD register width. Variations in SIMD registers and operands do not limit the scope of the present invention. The examples below are simply illustrative of one implementation of SIMD instructions for a decoder.

As shown in bit fetch state machine table bit fetcher has three states a header parsing state an exponent decoding state and a mantissa unpacking state which correspond to the three types of encoded units previously discussed with respect to . In the header parsing state bit fetcher provides 48 bits from decode bit register to packet header parser . In a preferred embodiment of the packet header further described in a packet header contains either 32 or 48 bits. After parsing the packet header packet header parser returns an R SHIFT value of 32 or 48 or in a preferred embodiment a HDR LEN indicator of 0 or 1 to bit fetcher . Bit fetcher then right shifts the decode bit register by 32 bits when HDR LEN 0 or by 48 bits when HDR LEN 48 . If after right shifting the number of bits in decode bit register is less than 128 packet header parser reads an additional 128 bits from packed array . Similarly bit fetcher provides 8 bits to exponent decoder which returns a R SHIFT count of 0 4 or 8 bits or in a preferred embodiment a TOK LEN indicator of 0 1 or 2 to bit fetcher . Bit fetcher then right shifts the decode bit register by 0 4 or 8 bits when TOK LEN 0 1 or 2 respectively. If after right shifting the number of bits in decode bit register is less than 128 packet header parser reads an additional 128 bits from packed array . Similarly bit fetcher provides 128 bits to mantissa unpacker which returns a R SHIFT count of 4 Nexp where Nexp is the exponent bit width for the current mantissa group. Bit fetcher then right shifts the decode bit register by 4 Nexp bits. If after right shifting the number of bits in decode bit register is less than 128 packet header parser reads an additional 128 bits from packed array .

As previously described with respect to the least significant nibbles of 32 bit integers or the most significant nibbles of 32 bit floating point samples are stored in packed mantissas P MANTS . The integer sign extender and floating point mantissa filler align the nibbles in packed mantissas for integer and floating point samples respectively as described with respect to . The mantissa mux selects the appropriate nibble alignment using the data type indicator . The nibble deinterleaver completes the mantissa unpacking operation and generates the contents U MANTS of unpacked SIMD register as described with respect to .

Signal regeneration operations may be applied to the unpacked samples the SIMD register to reverse the operations performed by the redundancy remover . The signal regeneration operations may include SIMD integration instructions as previously described with respect to . The integration operation is performed in accordance with the parameter DERIV from the derivative field which was previously decoded by packet header parser . The DERIV parameter determines the integral order for the integration operations that will invert the derivatives calculated redundancy remover . When an attenuation operation was applied to the samples during compression the decompression operations include multiplication by an amplification factor that approximately inverts the attenuation factor. The amplification factor is determined in accordance with the ATTEN parameter from the attenuation field of the packet header .

The initialization phase begins when start pointer address instruction saves the output array pointer in a local variable called startPtr. The pack header instruction V PACK HDR writes attenuator setting and derivative selector to encoded packet header . In other embodiments pack header instruction may include additional header parameters such as those described with respect to . Attenuator initialization instruction loads attenuator setting into all four 32 bit operands of SIMD register R which will be used in the encoding loop to attenuate the input samples by the same amount. Derivative specifier instruction loads derivative selection parameter deriv or DERIV SEL into a register that controls exponent register selector and SIMD register selector previously described with respect to .

The encoding loop of begins with loop initialization and control instruction which specifies the start and end values of loop counter variable i and the incrementing of i with every loop iteration. SIMD register load instruction V LOAD loads four 32 bit operands from the current input array pointer into SIMD register R. The input array pointer is incremented after the four operand fetch effectively advancing the input array pointer to the next four operand memory location. The SIMD multiplication instruction multiplies each of the operands in SIMD register R by the attenuator setting previously stored in SIMD register R . Two sequential SIMD derivative instructions and generate the first and second derivatives of the four input operands as previously described with respect to . The first derivative is stored in SIMD register R while the second derivative is stored in SIMD register R. Maximum exponent calculation and selection instruction V EXPMAX combines the operations of the EXPMAX instruction the DERIV SEL parameter and the selectors and previously described with respect to . In one alternative the operations of the V EXPMAX instruction may calculate the maximum exponent of the samples in a selected SIMD registers R R or R as determined by derivative selection parameter deriv i.e. DERIV SEL . In another alternative the operations of the V EXPMAX instruction calculate the maximum exponents for the samples in the SIMD registers R R and R and select from the maximum exponents i.e. from registers in in accordance with derivative selection parameter deriv i.e. DERIV SEL . The operations of V EXPMAX instruction store the maximum exponent in register Re i.e. register e and store the corresponding selected mantissas from R R or R in SIMD register R. The packing instruction V PACK REG combines the operations of the nibble interleaver and exponent token generator as described with respect to . The operations generate the appropriate exponent token with the four packed mantissas from the selected SIMD register R R or R using the maximum exponent information in SIMD register Re. The SIMD conditional write instruction V WRITE IF FULL implements the operations of the encoded memory packer described with respect to . These operations combine the exponent token and four packed mantissas with any previously stored bits in output register and write any full 128 bit words of output register to packed array .

The update phase of begins with the SIMD flush instruction V FLUSH which causes any remaining bits in output register to be written to packed array . Derivative update instruction V UPDATE DERIV examines the three exponent registers previously described with respect to and updates derivative selection parameter deriv corresponding to the lowest count i.e. the input samples first derivative or second derivative for the current encoding group that required the fewest mantissa bits. The updated derivative selection parameter deriv or DERIV SEL will be used to select the SIMD register R R or R and the corresponding maximum exponent for the next encoding group processed in the next iteration. Packet length calculation instruction calculates the difference between the final output pointer value outPtr and the initial output pointer startPtr which represents the number of 128 bit words written to packed array for the compressed data packet. Packet length error calculation instruction calculates the difference between the current compressed packet s size pktLen and the target packet length during fixed rate encoding. The SIMD attenuator update instruction V UPDATE ATTEN updates attenuator setting based on the packet difference previously calculated by packet length error calculation instruction . The V UPDATE ATTEN instruction is further described with respect to . Encoder function completes when function return instruction is executed.

The initialization phase begins when SIMD decode initialization instruction V INIT DECODE initializes all decoder state machines and pointers. Instruction V INIT DECODE copies the input pointer to an internal decoder register that points to the first 128 bits of packed array . This instruction also increments input pointer after reading the first 128 bits of packed array into decode bit register as previously described with respect to . Referring to bit fetcher also maintains an internal counter of the available number of bits in decode bit register and reads in additional 128 bit groups from packed array as required as packet header parser exponent decoder and mantissa unpacker specify how many bits R SHIFT are discarded from decode bit register . Whenever additional 128 bit groups are read from packed array the bit fetcher references and then advances the current input pointer. SIMD header fetch and decode instruction V DECODE HDR fetches and decodes attenuator setting atten and derivative selection parameter deriv from packet header . In other embodiments instruction V DECODE HDR may return additional header parameters such as those described with respect to . SIMD attenuator initialization instruction V LOAD loads the reciprocal of attenuator setting atten into all four 32 bit operands of SIMD register R. Register R will be used in the encoding loop to amplify the samples at the end of signal regeneration processing.

The decoding loop of begins with the while loop initialization and control instruction which specifies that the code within the braces will be repeated until the counter value N is zero or negative. The SIMD fetch exponent instruction V FETCH EXP causes 8 bits from decode bit register in bit fetcher to be transferred to exponent decoder . Next the exponent decode instruction V DECODE EXP instruction performs the exponent decode functions previously described with respect to on these 8 bits. The decoded exponents resulting from the V DECODE EXP instruction are stored in register R and the number of exponents is saved in the local variable nExps . Next SIMD mantissa decode instruction V DECODE MANTS causes 128 bits to be transferred from decode bit register in bit fetcher to mantissa unpacker which decodes and sign extends the most significant SIMD register bits for packed integers or decodes and zero fills the least significant SIMD register bits for packed floats as previously described with respect to . The result of mantissa unpacking is stored in register R. The V DECODE MANTS instruction includes a control parameter 1 which specifies that the first exponent in register R will be used to decode these four mantissas since it is possible that the exponent token decoded by V DECODE EXP instruction represented two exponents. Next the V INTEG N macro further described in invoked by instruction may calculate first or second order integration the contents of register R or no integration under the control of the derivative selection parameter deriv . The SIMD multiplication instruction V MPY multiplies each operand in SIMD register R by an amplification factor that is the reciprocal of the attenuator setting that was stored in SIMD register R by V LOAD instruction . The SIMD register write instruction V STORE writes the contents of the SIMD register R four 32 bit words to the decoded output array. The V STORE instruction increments output pointer to reflect that 128 output bits were written to the output array. Finally instruction decrements group counter while loop iteration counter .

Conditional test if instruction determines whether an additional four mantissas should be decoded which occurs when the value of local variable nExps equals 2. In that case the sequence of instructions and generates the second group of decoded 32 bit operands and writes them to the output array.

The update phase of begins with the SIMD flush instruction V FLUSH which advances encoded input array pointer if any partial bits remain in packed array . Decode function completes by executing function return instruction .

Similarly SIMD regenerate mantissas instruction V REGEN represents the sequential execution of four SIMD instructions 

Conditional execution of if statements generally slows down software execution especially if the conditional test is performed in a loop such as while loop . For this reason an alternative embodiment of s decode loop would include three separate while loops each while loop containing the appropriate number of calls 0 1 or 2 to V INTEG instruction for the derivative selection parameter deriv value. Doing the derivative test once prior to the main decode loop speeds up the loop by moving the cost of executing conditional test if instruction outside of the main loop. This alternative embodiment also does not require the V INTEG N macro .

Referring back to the amount of attenuation applied by attenuation instruction in the main encoding loop is determined by the atten parameter loaded by SIMD attenuator initialization V LOAD instruction . When the atten value is set to 1.0 the attenuation instruction does not modify any of the numerical operands to be encoded. Similarly if the atten value is set to less than 1.0 by SIMD attenuator initialization V LOAD instruction and is then never modified during compression processing attenuation instruction will apply the same attenuator value less than 1.0 to every input sample to be compressed which supports the fixed quality mode. In the case where fixed rate encoding is required the atten value may change. When the numerical data are difficult to compress more random than predictable a smaller attenuator value removes more least significant bits of each operand to increase the compression ratio. Similarly when the numerical data are easier to compress more predictable than random a larger attenuator value preserves more least significant bits of each operand. To achieve a fixed output bit rate the atten value may be modified depending on the on going average size of the sequence of compressed data packets in the packed array .

A variety of implementation alternatives exist for the embodiments of the numerical encoders compressors and decoders decompressors . The implementations can include logic to perform the processes described herein where the logic can include dedicated logic circuits configurable logic such as field programmable logic array FPGA blocks configured to perform the functions general purpose processors or digital signal processors that are programmed to perform the functions and various combinations thereof. The above referenced 312 application describes configurable compressors decompressors that are applied to numerical data in a multi core processing system. The numerical compression and decompression techniques using SIMD operations described herein may be implemented in the configurable compressors and decompressors described in the 312 application.

The numerical compression and decompression operations can be implemented in hardware software or a combination of both and incorporated in computing systems. The hardware implementations include ASIC FPGA or an intellectual property IP block. The numerical compression and decompression operations can be implemented in software or firmware on a programmable processor such as a digital signal processor DSP microprocessor microcontroller multi core CPU or GPU. The compressed data packets may be provided for data transfer of compressed numerical data between components of a data processing system or computer system such as between the data processor and memory between multiple processor cores between memories of the data processing system. The compressed data packets may also provide for data transfer of compressed numerical data over a communication channel or network to storage devices computer readable media or to another data processing system.

User interface input devices may include a keyboard pointing devices such as a mouse trackball touchpad or graphics tablet a scanner a touch screen incorporated into the display audio input devices such as voice recognition systems microphones and other types of input devices. In general use of the term input device is intended to include all possible types of devices and ways to input information into computer system that may be suitable for providing user inputs .

User interface output devices may include a display subsystem a printer a fax machine or non visual displays such as audio output devices. The display subsystem may include a cathode ray tube CRT a flat panel device such as a liquid crystal display LCD a projection device or some other mechanism for creating a visible image. The display subsystem may also provide non visual display such as via audio output devices. In general use of the term output device is intended to include all possible types of devices and ways to output information from computer system to the user or to another machine or computer system.

Storage subsystem stores the basic programming and data constructs that may provide some or all of the functions for the SIMD implementations of compression and or decompression described herein. These software modules are generally executed by processor .

The processor s may include one or more of a DSP microprocessor microcontroller central processing unit CPU or graphics processing unit GPU or a combination of these devices. The processor s may also include dedicated application specific integrated circuit ASIC or field programmable gate array FPGA logic implementing some or all of the compression and or decompression functionality. The processor s include registers that may function as the SIMD registers and combinatorial logic having one or more pipeline stages to implement the SIMD instructions for compression and decompression described above. Memory subsystem typically includes a number of memories including a main random access memory RAM for storage of instructions and data during program execution and a read only memory ROM in which fixed instructions are stored. The memory subsystem may store parameters used for the operations of compression and decompression such as exponent encoding table and exponent decoding table . File storage subsystem provides persistent storage for program and data files and may include a hard disk drive a floppy disk drive along with associated removable media a CD ROM drive an optical drive or removable media cartridges including Universal Serial Bus USB thumb drives with USB interface and flash media storage. The databases and modules implementing the functionality of certain embodiments may be stored by file storage subsystem .

Bus subsystem provides a mechanism for letting the various components and subsystems of computer system communicate with each other as intended. Although bus subsystem is shown schematically as a single bus alternative embodiments of the bus subsystem may use multiple busses.

Computer readable medium can be a medium associated with file storage subsystem and or with communication interface subsystem . The computer readable medium can be a hard disk a floppy disk a CD ROM an optical medium removable media cartridge USB thumb drive flash media storage or electromagnetic wave. The computer readable medium is shown storing a compressed data file of data compressed using the SIMD operations described herein. The computer readable medium may store programs or libraries implementing the functions of compression and or decompression using SIMD instructions and may include an expanded instruction set for the processor s that includes the SIMD instructions useful for compression decompression programs or libraries. In some embodiments the compression decompression program or library or the expanded instruction set are configured for a specific hardware configuration class of hardware configurations or for one or more hardware accelerators. In other embodiments the compression decompression program or library or expanded instruction set include components that support a plurality of variant hardware configurations classes of hardware configurations.

In one embodiment the compression decompression library is used by providing library access to a compiler which links the application programs to the components of the library selected by the programmer. Access to the library by a compiler can be accomplished using a header file for example a file having a .h file name extension that specifies the parameters for the library functions and corresponding library file for example a file having a .lib file name extension a .obj file name extension for a Windows operating system or a file having a .so file name extension for a Linux operating system that use the parameters and implement the operations for compression decompression including at least some SIMD operations. The components linked by the compiler to applications to be run by the computer are stored possibly as compiled object code for execution as called by the application. In other embodiments the library can include components that can be dynamically linked to applications and such dynamically linkable components are stored in the computer system memory possibly as compiled object code for execution as called by the application. The linked or dynamically linkable components may comprise part of an application programming interface API that may include parameters for compression operations as described in the 898 application.

At least one of the processor s includes an execution unit that comprises logic configured to execute single instruction multiple data SIMD instructions including logic responsive to one or a combination of the following instructions 

 1 A first SIMD instruction V DERIV that includes a multiple data identifier that identifies multiple operands to calculate differences between a pairs of operands in the multiple operands identified by the multiple data identifier to produce a plurality of difference value operands. A multiple data identifier can consist of a register pointer e.g. REG A that points to a SIMD register which is used by the logic to store multiple operands that are operated upon in execution of the instruction. The plurality of difference values can include the same number of result data values as are included in SIMD register. In connection with V DERIV as described herein the instruction identifies a single SIMD register that holds a number N such as four or eight operands and identifies implicitly or explicitly a location for the extra one two or more operands that are used to generate the number N of differences for storage in an destination SIMD register.

 2 A second SIMD instruction V EXPMAX that includes a multiple data identifier that identifies multiple operands to determine a maximum exponent value of the multiple operands identified by the multiple data identifier.

 3 A third SIMD instruction V PACK REG to pack a number of bits from each of the plurality of operands based on a maximum exponent value which can be determined in response to the V ECPMAX SIMD instruction for example to form the compressed data group wherein the compressed data group represents the plurality of operands.

 4 A fourth SIMD instruction V DECODE MANTS that includes a multiple data identifier that identifies a destination for multiple data values of constant data length which using an exponent for a group of packed mantissas decodes and sign extends most significant bits for integer data types to produce the multiple data values identified by the multiple data identifier or decodes and zero fills least significant bits for floating point data types to produce the multiple data values identified by the multiple data identifier.

 5 A fifth SIMD instruction V INTEG that includes a second multiple data identifier that identifies multiple operands to calculate sums of pairs of operands in the multiple operands identified by the second multiple data identifier to produce a plurality of integrated value operands.

The processor s can be controlled using one or more of the SIMD instructions along with other logic and instructions to perform the compression and decompression processes described herein.

Implementations of execution units with SIMD registers and instruction sets vary by silicon vendor. In general SIMD can be implemented using microcoded instructions that control programmable logic. In one example implementation the existing 128 bit registers used in conjunction with the Intel SSE SIMD instruction set could also be used to store the operands for the instructions implementing the redundancy remover and bit packer . Implementations of new SIMD instructions such as those listed in would still require specification of one or more input operands multiple data identifiers or register pointers and the location where the result output operand s register pointers would be stored. Specifying the input and output registers could be similar to or may even be identical to how the input and output registers operands are specified using existing SIMD instructions. The new instructions would include a new unique opcode that specifies the new operation. When the new SIMD opcode instruction is invoked combinatorial logic that corresponds to the new opcode instruction would access the one or more input operands from among the existing SIMD registers. Once the result has been generated by the combinatorial logic for the new instruction the result s would be stored in the specified SIMD output register s . Thus each new SIMD opcode instruction could typically but not exclusively be accompanied with dedicated logic for the new instruction which would be used whenever the corresponding SIMD opcode is executed. For a given opcode instruction hardware accelerator implementations are possible that improve the speed and or decrease the latency of the new instruction. Speed and latency are modified by varying the number of pipeline stages in the combinatorial logic for each new SIMD instruction. Other implementations of the new SIMD instructions may use dedicated input and output registers in addition to or instead of existing SIMD registers.

While the preferred embodiments of the invention have been illustrated and described it will be clear that the invention is not limited to these embodiments only. Numerous modifications changes variations substitutions and equivalents will be apparent to those skilled in the art without departing from the spirit and scope of the invention as described in the claims.

