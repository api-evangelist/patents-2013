---

title: Advanced persistent threat (APT) detection center
abstract: A computerized method is described in which one or more received objects are analyzed by an advanced persistent threat (APT) detection center to determine if the objects are APTs. The analysis may include the extraction of features describing and characterizing features of the received objects. The extracted features may be compared with features of known APT malware objects and known non-APT malware objects to determine a classification or probability of the received objects being APT malware. Upon determination that the received objects are APT malware, warning messages may be transmitted to a user of associated client devices. Classified objects may also be used to generate analytic data for the prediction and prevention of future APT attacks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09628507&OS=09628507&RS=09628507
owner: FireEye, Inc.
number: 09628507
owner_city: Milpitas
owner_country: US
publication_date: 20130930
---
Embodiments of the disclosure relate to the field of data security. More specifically one embodiment of the disclosure relates to a system of discovering and identifying advanced persistent threats APTs based on features of previously discovered identified APTs and non APTs. Detected APTs may be used to generate analytic data for the prediction of and prevention against future APT attacks.

Over the last decade malicious software malware has become a pervasive problem for Internet users. In some situations malware is a program or file that is embedded within downloadable content and designed to adversely influence or attack normal operations of a computer. Examples of different types of malware may include bots computer viruses worms Trojan horses spyware adware or any other programming that operates within an electronic device e.g. laptop computer desktop computer tablet computer smartphone server router wearable technology or other types of electronics with data processing capabilities without permission by the user or an administrator.

Advanced persistent threats APTs are a type of malware that target a particular individual and seek to extract a particular set of information that is known to be accessible to the defined target. The targets may include individuals and organizations with high value information e.g. classified or sensitive defense secrets and information that would be considered trade secrets or intellectual property . For example an electronic mail email message may be sent to the Chief Executive Officer CEO of a company. The email message may contain an attachment such as a Portable Document Format PDF document with embedded executable malware that is intended to perform industrial espionage. When opened the executable malware in the document may target financial data for the company only accessible to the CEO. Although the document may be identified as malware by traditional malware detection systems these systems may fail to properly identify the attack and associated objects as APTs. Although described in relation to the commercial sector APTs may seek to perform nation state attacks for the purposes of political terrorism or espionage.

In one embodiment of the invention of an Advanced Persistent Threat APT detection center is provided that analyzes one or more objects received from a client device or another digital device. These objects may be generally defined as selected portions of content under analysis that may contain advanced persistent threats APTs . An APT is a type of malware that is directed at a particular target and seeks to surveil extract and or manipulate data to which the defined target would have access. An APT attacker may utilize non public or non commonly known information to support the APT attack. The targets may include individuals and organizations with high value information e.g. classified or sensitive defense secrets and information that would be considered trade secrets or intellectual property . In some instances APTs may seek to perform nation state attacks for the purposes of political terrorism or espionage.

The APT detection center may determine whether received objects are APTs by extracting features from the received objects. A feature is information associated with a characteristic and or behavior of the object where the feature may be static e.g. derived from metadata associated with the object and or dynamic e.g. based on actions performed by the object after virtual processing of the object such as detonation . The extracted features may be compared against features of known APT objects known non APT malware objects and or known benign objects that were previously classified and recorded stored in an APT intelligence database.

Following classification of the one or more received objects the results of the classification may be reported to a user of the client device s and stored in the APT intelligence database. In one embodiment data mining and analysis may be performed on classified objects stored in the APT intelligence database such that additional analytics regarding APTs may be generated. For example in one embodiment the APT detection center may perform one or more of 1 creating attacker profiles 2 collecting evidence associated with suspected APT attacks 3 determining a level of severity of an APT malware object 4 discovering and identifying overall APT campaigns 5 performing attribution of APT attacks and 6 predicting future APT trends. This analysis of data from the APT intelligence database may produce useful data for the prediction of and prevention against future APT attacks.

In the following description certain terminology is used to describe aspects of the invention. For example in certain situations both terms logic and engine are representative of hardware firmware and or software that is configured to perform one or more functions. As hardware logic or engine may include circuitry having data processing or storage functionality. Examples of such circuitry may include but is not limited or restricted to a microprocessor one or more processor cores a programmable gate array a microcontroller an application specific integrated circuit wireless receiver transmitter and or transceiver circuitry semiconductor memory or combinatorial logic.

Logic or engine may be in the form of one or more software modules such as executable code in the form of an executable application an application programming interface API a subroutine a function a procedure an applet a servlet a routine source code object code a shared library dynamic load library or one or more instructions. These software modules may be stored in any type of a suitable non transitory storage medium or transitory storage medium e.g. electrical optical acoustical or other form of propagated signals such as carrier waves infrared signals or digital signals . Examples of non transitory storage medium may include but are not limited or restricted to a programmable circuit a semiconductor memory non persistent storage such as volatile memory e.g. any type of random access memory RAM persistent storage such as non volatile memory e.g. read only memory ROM power backed RAM flash memory phase change memory etc. a solid state drive hard disk drive an optical disc drive or a portable memory device. As firmware the executable code is stored in persistent storage.

The term content generally refers to information transmitted as one or more messages where each message s may be in the form of a packet a frame an Asynchronous Transfer Mode ATM cell or any other series of bits having a prescribed format. The content may be received as a data flow namely a group of related messages within ingress data traffic. An object may be construed as a portion of the content namely information within one or more of the messages.

Herein content and or objects may include one or more types of data such as text software images audio metadata and or other digital data. One example of content may include web content or any data traffic that may be transmitted using a Hypertext Transfer Protocol HTTP Hypertext Markup Language HTML protocol or may be transmitted in a manner suitable for display on a Web browser software application. In one embodiment the content and or objects may be independent of operating systems running on electronic devices of the described system.

Another example of content and or objects includes electronic mail email which may be transmitted using an email protocol such as Simple Mail Transfer Protocol SMTP Post Office Protocol version 3 POPS or Internet Message Access Protocol IMAP4 . A further example of content includes an Instant Message which may be transmitted using Session Initiation Protocol SIP or Extensible Messaging and Presence Protocol XMPP for example. Yet another example of content includes one or more files that are transferred using a data transfer protocol such as File Transfer Protocol FTP for subsequent storage on a file share.

The term malware is directed to software that produces an undesired behavior upon execution where the behavior is deemed to be undesired based on customer specific rules manufacturer based rules any other type of rules formulated by public opinion or a particular governmental or commercial entity or an indication of a potential exploit in a particular software profile. This undesired behavior may include a communication based anomaly or an execution based anomaly that 1 alters the functionality of an electronic device executing application software in a malicious manner 2 alters the functionality of an electronic device executing that application software without any malicious intent and or 3 provides an unwanted functionality which is generally acceptable in other context.

As noted above an advanced persistent threat APT is a type of sophisticated network attack that is directed at a particular target and seeks to surveil extract and or manipulate data to which the defined target would have access to. APTs may seek to maintain a persistent attack on a target system for a prolonged period of time in comparison with traditional malware. APTs include but are not limited to targeted attacks on individuals and organizations with high value information e.g. classified or sensitive defense secrets and information that would be considered trade secrets or intellectual property nation state attacks cyber industrial espionage cyber warfare and watering hole attacks. For example an email message that is specifically directed to a particular individual at a company e.g. an officer of the company and attempts to extract sensitive data that the defined target would have access to may be defined as an APT. In some embodiment APTs may utilize key loggers or other data exfiltration methods. APTs often use spearfishing for gaining initial network entry where the APT malware may be specifically directed to a person in an organization and personal information is included in the object to elicit an action by the targeted individual that permits access by the APT malware. For example an APT email message may include text greetings that are personalized for the defined target along with an attachment e.g. a Portable Document Format PDF document . The attachment may contain malicious content such that upon opening detonating or otherwise activating the attachment the malicious content attempts to extract and or manipulate targeted data accessible to the defined target.

The term transmission medium is a communication path between two or more systems e.g. any electronic devices with data processing functionality such as for example a security appliance server mainframe computer netbook tablet smart phone router switch bridge or router . The communication path may include wired and or wireless segments. Examples of wired and or wireless segments include electrical wiring optical fiber cable bus trace or a wireless channel using infrared radio frequency RF or any other wired wireless signaling mechanism.

In general a virtual machine VM is a simulation of an electronic device abstract or real that is usually different from the electronic device conducting the simulation. A VM may be used to provide a sandbox or safe runtime environment separate from a production environment to enable detection of APTs or malware in a safe environment. The VM may be based on specifications of a hypothetical computer or emulate the computer architecture and functions of a real world computer. A VM can be one of many different types such as for example hardware emulation full virtualization para virtualization and or operating system level virtualization virtual machines.

The term computerized generally represents that any corresponding operations are conducted by hardware in combination with software and or firmware.

Lastly the terms or and and or as used herein are to be interpreted as inclusive or meaning any one or any combination. Therefore A B or C or A B and or C mean any of the following A B C A and B A and C B and C A B and C. An exception to this definition will occur only when a combination of elements functions steps or acts are in some way inherently mutually exclusive.

As this invention is susceptible to embodiments of many different forms it is intended that the present disclosure is to be considered as an example of the principles of the invention and not intended to limit the invention to the specific embodiments shown and described.

Referring to an exemplary block diagram of a first illustrative embodiment of a communication system is shown. Herein the communication system includes an APT detection center communicatively coupled to client device s e.g. one or more client devices A and B over transmission medium forming a network . In general according to this embodiment the APT detection center receives objects from the client device s for processing and classification. In response to receiving the objects the APT detection center automatically determines whether the received objects are APTs and in response to detection of one or more APT objects may be configured to transmit warning messages to a corresponding client device and or other devices e.g. network device managed by information technology personnel . The warning messages would indicate to a targeted recipient e.g. client IT personnel etc. of a targeted APT type malware.

It is contemplated that the APT detection center may conduct further operations including one or more of the following creating attacker profiles based on detected APT objects preserving evidence associated with detected APT objects uncovered during a suspected APT attack gauging a level of severity of an APT object and predicting future APT attack trends. This automated analysis provides an efficient system for combating and preventing APT attacks. Each element of the communication system will be described by way of example below.

As noted above the communication system may include one or more client devices A and B coupled to the APT detection center through the network . Network may be a private network e.g. enterprise network in which both the APT detection center and the client devices A and B are on the same network. Alternatively network may be a public network in which the APT detection center is remotely accessed by a network device e.g. client A B etc. .

Herein the client device s may be any type of digital devices including laptop computers desktop computers tablet computers smartphones servers network devices e.g. firewalls and routers wearable technology process controllers or other types of electronics with data processing capabilities and typically have network connectivity. Furthermore the client device s may include one or more processors with corresponding memory units for processing data. The processors and memory units are generally used here to refer to any suitable combination of programmable data processing components and data storage that conduct the operations needed to implement the various functions and operations of the client device s . The processors may be special purpose processors such as an application specific integrated circuit ASIC a general purpose microprocessor a field programmable gate array FPGA a digital signal controller or a set of hardware logic structures e.g. filters arithmetic logic units and dedicated state machines while the memory units may refer to microelectronic non volatile random access memory. An operating system may be stored in the memory units of the client device s along with application programs specific to the various functions of the client device s which are to be run or executed by the processors to perform the various functions of the client device s . For example the memory units of a client device may store email and or web browser applications that are run by associated processors to send receive and view corresponding data objects.

According to another embodiment of the invention as shown in an exemplary block diagram of a second illustrative embodiment of communication system deploying one or more malware content detection MCD systems e.g. MCD system which is an electronic device that is adapted to analyze information associated with network traffic routed over a local network to client device s . More specifically MCD system is configured to conduct static analysis of an object within content under analysis e.g. a file that is part of message s transmitted via the network traffic received via local network and where applicable classify the object with different malicious scores. An object may be classified with a first level e.g. suspicious assigned a score less than or equal to a first threshold when at least one characteristic identified during scanning of the object by the static scanning engine indicates a certain level of probability that the object includes malware. Similarly the file may be classified with a second level e.g. malicious assigned a score greater than or equal to a second threshold greater than the first threshold when at least one characteristic observed during these scanning operations indicates a certain greater level of probability that the file includes malware.

The MCD system is shown as being coupled with the local network normally behind a firewall not shown via a network interface . The network interface operates as a data capturing device referred to as a tap or network tap that is configured to receive data traffic propagating to from the client device s and provide content from the data traffic to the MCD system .

In general the network interface receives and duplicates the content that is received from and provided to client device s normally without an appreciable decline in performance. The network interface may duplicate any portion of the content for example one or more files that are part of a data flow or part of the payload contained within certain data packets metadata or the like.

It is contemplated that for any embodiments where the MCD system is implemented as an dedicated appliance or a dedicated computer system the network interface may include an assembly integrated into the appliance or computer system that includes network ports network interface card and related logic not shown for connecting to the local network to non disruptively tap data traffic and provide a copy of the network traffic to the static scanning engine . In other embodiments the network interface can be integrated into an intermediary device in the communication path e.g. firewall router switch or other network device or can be a standalone component such as an appropriate commercially available network tap. In virtual environments a virtual tap vTAP can be used to duplicate files from virtual networks.

Referring still to MCD system may include a scanning engine a database a scheduler a storage device a dynamic analysis engine and a reporting module . In some embodiments the network interface may be contained within the MCD system . Also static scanning engine scheduler and or dynamic analysis engine may be software modules which are executed by one or more processors or different processors and are configured to receive content and analyze one or more objects associated with that content. After analysis the object s that may constitute APT objects are output from reporting module back through network interface to APT detection center .

In one embodiment the static scanning engine may serve as a filter to permit subsequent malware analysis only on a portion of incoming content which effectively conserves system resources and provides faster response time in determining the presence of malware within the analyzed content. As shown in the static scanning engine receives the copy of incoming content from the network interface and applies heuristics to determine if any of the content is suspicious . The heuristics applied by the static scanning engine may be based on data and or rules stored in the database . Also the static scanning engine may examine the image of the captured content without executing or opening the captured content.

For example the static scanning engine may examine the metadata or attributes of the captured content and or the code image e.g. a binary image of an executable to determine whether a certain portion of the captured content matches e.g. a high level of correlation with a predetermined pattern of attributes that is associated with a malicious attack. According to one embodiment of the disclosure the static scanning engine flags content from one or more data flows as suspicious after applying this heuristic analysis.

Thereafter according to one embodiment of the invention the static scanning engine may be adapted to transmit at least a portion of the metadata of the suspicious content to the dynamic analysis engine . The portion of the metadata may identify attributes of the runtime environment in which the suspicious content should be processed and on occasion of the client device s to which the suspicious content was being sent. Such metadata or attributes are used to identify a configuration of the VM needed for subsequent malware analysis. In another embodiment of the disclosure the dynamic analysis engine may be adapted to receive one or more messages e.g. data packets from the static scanning engine and analyze the message s to identify the software profile information associated with the needed VM.

For instance as an illustrative example the suspicious content under test may include an email message that was generated under control of Windows 7 Operating System using a Windows Outlook 2010 version 1. Upon determining that the email message includes suspicious content such as an attachment for example static scanning engine provides software profile information to scheduler to identify a particular configuration of VM needed to conduct dynamic analysis of the suspicious content. According to this illustrative example the software profile information would include 1 Windows Operating System OS 2 Windows Outlook 2010 version 1 and perhaps an Adobe reader if the attachment is a PDF document.

The static scanning engine supplies the software profile information to the scheduler which determines whether any of the VM disk files within storage device feature a software profile supporting the above identified configuration of OS and one or more applications or a suitable alternative. .

The dynamic analysis engine is adapted to execute multiple VMs to simulate the receipt and processing of different types of suspicious content as well as different operating environments. Furthermore the dynamic analysis engine monitors and analyzes the activities and other behaviors of such content during processing in the VM. The behaviors may include those expect and or not expected during processing of that type of content. Unexpected behaviors can be considered anomalous behaviors. Examples of anomalous behaviors may include unusual network transmissions opening certain ports to retrieve data unusual changes in performance and the like. This detection process is referred to as a dynamic malicious content detection.

The dynamic analysis engine may flag the suspicious content as malware according to the observed behavior of the VM. In response to detecting anomalous behaviors that tend to indicate an APT attack e.g. either certain combinations of anomalous behaviors or anomalous behaviors of a particular APT related nature the reporting module may issue not only alerts warning of the presence of malware but also may create a message including the suspicious objects for transmission to the APT detection center.

As shown in the APT detection center is communicatively coupled to one or more malware content detection MCD systems over network e.g. cloudbased . In general the APT detection center receives objects from the MCD system where the objects are previously statically scanned and or dynamically analyzed as described above. In response to receipt of the object s the APT detection center is configured to automatically determine whether the received objects are APTs and in response to detection of an APT object transmits warning messages to MCD system and or a corresponding client device as described above.

Further in some embodiments although not shown the APT detection center may be implemented behind the firewall of and communicatively coupled so as to be part of local network . Hence APT detection and classification is performed entirely or primarily within the enterprise. Alternatively APT detection center may be resident on the client device s and or the MCD system such that APT detection and classification is performed entirely or primarily on the client device s and or MCD system .

In one embodiment the client device s may each include one or more network interfaces for communicating with the APT detection center and other devices over the network . The network interfaces may communicate with one or more devices using wireless and or wired protocols including the IEEE 802.3 and the IEEE 802.11 suite of standards. In one embodiment as will be described in greater detail below the network interfaces of the client device s allow transmission of suspect potential APT objects to the APT detection center for analysis and classification over the network .

The network may be any network or networks including for example the Internet capable of transferring data between the APT detection center and the client device s . For example the network may include one or more wired or wireless routers switches and other digital networking devices that operate using one or more protocols e.g. IEEE 802.3 and IEEE 802.11 to transfer data between a source and its intended destination. Alternatively network may include a public network e.g. Internet or is solely an enterprise network.

In one embodiment the communication system may include an external server for providing data to the APT detection center . The data received from the external server may be associated with objects received from the client device s . For example the data received from the external server may further describe the operation and features of suspect objects received from the client device s as will be explained in further detail below. The external server may be any computing or storage device including a laptop computer a desktop computer or a web server. As shown in the external server may maintain a separate connection with the APT detection center distinct from the network . However in alternate embodiments the external server may communicate with the APT detection center over the network . Although shown as a single external server in other embodiments two or more external servers may be in communication with the APT detection center to supplement data of suspected APT objects.

The APT detection center includes multiple components for processing suspect objects received from the client device s . The processing may include the determination of whether the received objects are APTs based on comparisons with previously identified APTs and previously identified non APTs as will be discussed in further detail below.

As shown in the APT detection center may include an APT server an APT intelligence database and one or more APT analysis systems . Each element of the APT detection center will be described by way of example below. Furthermore this disclosure describes the supply of the object from one of the client device s although it is contemplated that the objects for APT analysis by the APT detection center may be supplied from the MCD system or any other network device or directly via a suitable interface.

In one embodiment the APT server may include a network interface for communicating with various components external to the APT server . The network interface may communicate with one or more devices using wireless and or wired protocols including the IEEE 802.3 and the IEEE 802.11 suite of standards. In one embodiment the network interface allows the APT server to communicate with the APT intelligence database the APT analysis systems the external server and or the client devices A and B over one or more wired and or wireless transmission mediums.

In one embodiment as shown in the persistent storage unit may store logic including a feature extractor a feature normalizer a dropped object extractor an APT classifier a warning generator graphical user interface GUI and or configuration logic . Each of these elements may be discrete software components that may be processed run by one or more of the processors . Each element stored in the persistent storage unit and shown in will be described below by way of example using the method for discovering and classifying APT objects shown in .

The method for discovering and classifying APT objects may begin at operation with receipt of a suspect object from the client device A. In one embodiment operation may be performed by the network interface of the APT server . In this embodiment the suspect object may be received from the client device A over the network through the network interface as shown in . The transmission may be made using either wired or wireless transmission mediums between the client device A and the APT server .

In one embodiment a user of the client device A submits a suspect object through an interface. The interface may be generated by the GUI logic and served to the client device A using the configuration logic of the APT server . In this fashion the APT server may operate as a web server to deliver data and a user interface to the client device A.

Although the APT server is described above to serve the web interface to a browser of the client device A in other embodiments a separate web server may be in communication with the client device A and the APT server to provide the web interface and facilitate transmission of the suspect object to the APT server from the client device A.

Although described above as transmission of a suspect object through the web interface in other embodiments a suspect object may be received at operation through different techniques. For example as shown in the MCD system may scan ingress traffic to the client device s . In one embodiment the MCD system may be deployed as an inline security appliance not shown or coupled to the network via the network interface as shown in . Herein the MCD system may analyze intercepted objects for malware or other indicators of suspicious content. Upon detecting malware in an intercepted object the infected object may be forwarded to the APT detection center such that the object is received at operation .

In some embodiments the transmission to the APT detection center may include additional data related to the malware analysis by the MCD system such as characteristics of the intercepted object detected by the system . In some embodiments the MCD system may transmit an email message within which the suspect object was received a client identifier and other context information along with the suspect object. This additional information may be used to determine the context of the suspect object e.g. location of the target industry of the target and or the origin of the attack which is associated with a client profile that is accessible using the client identifier.

For example in one embodiment a suspect object may be received through an anti virus and or anti malware tool running on the client device A. The tool may periodically or aperiodically and without direct provocation by the user transmit objects to the APT server for processing and analysis. This independent transmission of suspect objects allows the client device A to maintain an automatic examination of potential APT objects on the client device A without direct interaction by a user.

In one embodiment a suspect object may be any digital data structure. For example a suspect object may be a file e.g. a Portable Document Format PDF document a component of a web page an image etc. As described above a user of the client device A may manually determine that an object is suspected to be APT malware or the client device A may automatically classify the object as potential APT malware. Although described in relation to receiving a single suspect object from the client device A in other embodiments the APT detection center and the method may be used in relation to multiple suspect objects. For example the APT detection center and method may be used to analyze multiple suspect objects received from the client device A and or the client device B. The suspect objects may be processed by the APT detection center separately using the operations of the method to determine whether each received suspect object is APT malware.

Referring back to following receipt the suspect object is detonated e.g. processed by virtual execution or other operations to activate the suspect object at operation to produce raw data describing behavior and characteristics of the suspect object. In one embodiment one or more APT analysis systems of the APT detection center detonate the suspect object to generate the raw data. The APT analysis systems may be one or more separate computing devices or processing units that may independently and discretely activate or detonate the suspect object such that operations associated with the suspect object are performed. For example in one embodiment the suspect object may be a PDF file. In this embodiment one or more APT analysis systems may detonate the PDF file by opening the file using an Adobe Reader or other appropriate document reader and monitoring activities performed and other behaviors of the PDF document and any objects embedded therein.

After detonating the suspect object the one or more APT analysis systems record operations performed by the suspect object e.g. behaviors and other data that describe the suspect object e.g. characteristics . This recorded data forms raw data describing the suspect object. Use of the APT analysis systems ensure that detonation of the suspect object is controlled and will not result in infection of the client device A and or the compromise of sensitive data. In one embodiment the APT analysis systems may include one or more virtual machines with various profiles and may in some cases simulate the client device A during detonation of the suspect object. These profiles may include software to be run by a virtual machine to process a suspect object. For example the profiles may include an operating system and one or more suitable computer applications that are required to process the objects. For example the applications may include a document reader e.g. an Adobe Reader for PDF documents and or a web browser for web pages for detonating the suspect object. The APT analysis systems may include separate processors and memory units for use in detonating the suspect object.

As noted above detonation of the suspect object at operation produces raw data that describes characteristics and behaviors of the suspect object. For example the raw data may include details regarding origin of the suspect object stored in metadata data generated by the suspect object during detonation data attempted to be accessed by the suspect object both locally and from remote systems during detonation etc.

Although described as raw data being generated after the suspect object has been detonated in other embodiments the raw data may be generated prior to detonation of the suspect object. For example raw data may be generated that reflects metadata for the suspect object obtained during a static analysis of the suspect object including for example communications protocols anomaly checks and object source blacklist checks.

During dynamic analysis in some cases the suspect object may generate drop separate objects during detonation. These dropped objects may be new files e.g. binary files or other segments of data or executable code created by the original suspect object. In this embodiment as further shown in operation the dropped objects may be extracted and passed back to operation for detonation. Accordingly each of the dropped objects are detonated in a similar fashion as was described in relation to the suspect object to generate raw data characterizing each dropped object. In one embodiment the dropped objects are associated with the suspect object in the APT intelligence database as will be described in further detail below. In one embodiment the dropped file extractor of performs operation to detect extract and pass dropped objects to operation .

After detonation of the suspect object and any dropped objects produced by the suspect object at operation as shown in operation features associated with the suspect and dropped objects may be extracted from the raw data produced at operation . In one embodiment the features characterize the suspect and or dropped objects. For example the features may describe behavior of the objects during detonation and or metadata associated with the objects. In one embodiment the extracted features may include information as to whether a suspect object attempted to make out bound communications during processing of the suspect object e.g. by a virtual machine to outside data sources. In another embodiment the extracted features may indicate the suspect object is attempting to exfiltrate or send out data such as identification information of the host that detonates the suspect object e.g. the APT analysis systems to an external location. Exfiltration of data may indicate that the object is an APT. The features provide a comprehensive characterization of an associated object such that a comparison may be performed to determine whether the object is APT malware as will be described in greater detail below.

In one embodiment the extracted features include data that manifest exhibit that an associated attacker has prior knowledge about the target. For example the features may include details regarding financial records of a competitor personal information about the target in the body of a message e.g. the name or the calendar information of the target generation of another object process file that takes advantage of non public or not commonly known information of the target etc. In one embodiment an object associated with features that exhibit that an associated attacker has prior knowledge about the target may indicate that the object is an APT.

In one embodiment at operation data related to the suspect object and the dropped objects may be retrieved from external data sources while generating features. For example data may be retrieved from the external server through the network interface . In this embodiment the external server may be a device on the same local area network as the APT detection center or connected to the APT detection center over a wide area network e.g. the Internet . For example as discussed above the external server may be connected to the APT detection center through the network .

In one embodiment the data retrieved from the external server may include data related to servers attempted to be accessed by the suspect and dropped objects while being detonated e.g. internet protocol IP address of a server . In another embodiment the external data may include data collected by third parties related to the suspect object e.g. malware classification information . In one embodiment operation may be performed by the feature extractor .

Following generation of features for the suspect object and or the dropped objects the features may be normalized at operation . Normalizing features eases comparisons that may be later performed as described below. In one embodiment normalizing the features includes converting feature data into discrete and or continuous data values. Discrete data may only take particular values. For example discrete data may be numeric e.g. the number of dropped objects created or categorical e.g. the type of file extension of the suspect object . In contrast continuous data is not restricted to defined separate values but may occupy any value over a continuous range. Between any two continuous data values there may be an infinite number of other data values.

For example in one embodiment the features for the suspect object may include data indicating the size of the suspect object in bytes. Operation may normalize this size data value by comparing the size of the suspect object with a predefined value. For instance the size of the suspect object may be compared with the predefined value kilobytes to generate a discrete Boolean data value indicating whether the suspect object is greater than kilobytes. In one embodiment operation may be performed by the feature normalizer after receiving features from the feature extractor .

At operation the feature data may be stored in the APT intelligence database . The APT intelligence database may be a local or remote database that stores feature data for objects analyzed by the APT detection center . In one embodiment the APT intelligence database includes feature data for both objects flagged as APT malware and objects that are flagged as not being APT malware as will be described in further detail below.

In one embodiment each entry in the APT intelligence database includes an object identifier to uniquely identify the object in the database one or more features for each object generated at operations and identifiers references links to associated dropped objects and a flag indicating if the object has been classified as APT malware. In some embodiments the features stored in the APT intelligence database are normalized as described above in relation to operation .

The APT intelligence database may follow a relational object hierarchical or any other type of database model. In one embodiment the APT intelligence database is spread across one or more persistent data storage units. The persistent data storage units may be integrated within the APT server or within a separate host device. For example the APT intelligence database may be located on a remote host device and accessible by the APT server over the network . In another example the APT intelligence database may be coupled to the APT server through a peripheral connection e.g. a Universal Serial Bus or IEEE 1339 connection .

As noted above multiple data values may be stored in the APT intelligence database to describe the suspect and dropped objects analyzed at operations . The data values may include an APT malware flag that indicates whether the analyzed objects are determined to be APT malware by the APT detection center . Initially this APT malware flag may be set to a default value pending operations .

Following the storage of the suspect and dropped objects in the APT intelligence database operation may determine whether the suspect object is APT malware based on a comparison with one or more objects stored in the APT intelligence database . The comparison attempts to determine similarities between the suspect object and objects known to be APT malware and or objects known to not be APT malware. For example the suspect object may be considered similar to a known APT object when a predefined number of features are determined to be shared between the objects.

The comparison at operation may be performed using one or more discrete and or continuous data values in the set of features for the suspect object. In one embodiment at operation features for the suspect object and features for the dropped objects associated with the suspect object are compared with objects in the APT intelligence database .

In one embodiment operation may be performed by the APT classifier . In this embodiment the APT classifier queries the APT intelligence database based on features of the suspect object and or the dropped objects associated with the suspect object to determine whether the suspect object is APT malware.

In one embodiment the APT classifier may utilize statistical and machine learning to determine whether the suspect object is APT malware. Machine learning refers to a process or system that can learn from data i.e. be trained to distinguish between good and bad or in this case between APT malware objects and non APT malware objects. The core of machine learning deals with representation and generalization that is representation of data objects e.g. the behaviors and other analytical results which can be collectively represented by features of the objects generated at operations and and functions performed on those objects e.g. weighting and probability formulas . Generalization is the property that the process or system uses to apply what it learns on a learning set of known or labeled data objects to unknown or unlabeled examples. To do this the process or system must extract learning from the labeled set that allows it to make useful predictions in new and unlabeled cases.

For machine learning the APT classifier may operate in a training mode and in an operational mode. In a training mode the APT classifier employs threat heuristics training logic to subject known samples i.e. labeled samples of APT malware objects and known samples of clean or non APT malware objects to calibrate threat heuristics logic for probability scoring and or decision making of objects. To accomplish this the threat heuristics training logic may submit APT malware and non APT malware stored in the APT intelligence database to analyzers. In some embodiments the threat heuristics training logic may employ a special forensics system. In alternative embodiments the threat heuristics training logic may test the APT malware and non APT malware each time it processes a different object or it may store the results of prior tests for use for future processing of objects. The threat heuristics training logic may assign a probability score to each of the possible patterns resulting from testing the APT malware and non APT malware. These probability scores and classification labels are indicative of whether an object is APT malware. In one embodiment the machine learning routines and operations described above may be performed by the learning module shown in and based on inputs from the APT server and the APT intelligence database .

In an operating mode the threat heuristics analysis logic combines all features with respect to a current suspect object under test to form a current pattern containing potential indicators of APT malware activity. Then the threat heuristics analysis logic compares that pattern and or in some embodiments each and every one of the features contained therein with those obtained during the training mode. Where features are separately analyzed the threat heuristics analysis logic may assign weights or decisions based on experience during training to features that are deemed more closely associated with APT malware. It then assigns a probability score or classification label to each of the possible patterns and or in some embodiments to each of the features within each pattern as to its likelihood of appearing in a malicious and or clean sample based on the learned probability scoring. This may involve determining how closely a pattern of features in a suspect object compares to a labeled sample using a proximity calculation based on the probability of encountering each attribute in an APT malware and non APT malware pattern. The end result may be a composite probability score for the current suspect object under test. The score is indicative of whether the current suspect object under test is APT malware. If the score exceeds a predefined threshold value a decision may be made to apply an APT label to the object and therefore the current suspect object is classified as an APT. Accuracy in prediction of APT malware will depend on the selection and number of relevant features identified the selection of weights to be assigned to each the comparison process used the quality of training and the threshold selected. The threshold selected will be dependent on the training process.

Upon determining at operation that the suspect object is APT malware the method moves to operation to flag the suspect object as malware in the APT intelligence database . In one embodiment flagging the suspect object as APT malware includes setting an APT malware data value associated with the suspect object in the APT intelligence database to a selected value e.g. true .

After flagging the suspect object as APT malware in the APT intelligence database operation may send a warning to the client device A i.e. the original device transmitting the suspect object . The warning informs a user of the client device A that the suspect object is APT malware and should be discarded deleted or otherwise avoided. In one embodiment the warning may be a transmission to a component of the web interface . For example as shown in a dialog box of the web interface may be updated to indicate that the suspect object is APT malware. In other embodiments other warnings may be transmitted to the client device A. For example email messages pop up messages or other signals may be transmitted between the APT detection center and the client device A to represent the warning message.

Similarly upon determining at operation that the suspect object is not APT malware the method moves to operation to determine whether the suspect object is non APT malware or a benign object based on comparisons with features of known previously classified objects in the APT intelligence database . This comparison may be performed using machine learning and statistical analysis similar to that described above in relation to operation . Upon determining that the suspect object is non APT malware operation flags the suspect object as non APT malware in the APT intelligence database . In one embodiment flagging the suspect object as non APT malware includes setting an APT malware data value associated with the suspect object in the APT intelligence database to a selected value e.g. false . Upon determining that the suspect object is non malware and is benign operation flags the suspect object as non malware in the APT intelligence database . In one embodiment flagging the suspect object as non APT malware includes setting a malware data value associated with the suspect object in the APT intelligence database to a selected value e.g. false .

Although not shown in the in one embodiment a message may be transmitted to the client device A indicating that the suspect object is non APT malware and or non malware benign. For example the dialog box of the web interface may be updated to indicate that the suspect object is non APT malware and or non malware. In other embodiments other messages may be transmitted to the client device A to indicate that the suspect object is not APT malware. For example email messages pop up messages or other signals may be transmitted between the APT detection center and the client device A. These warnings may be transmitted to other subscribers in addition to the subscriber associated with the current suspect object.

By transmitting a warning message or other messages to the client device A identifying a classification of the suspect object a user of the client device A may be better prepared and less susceptible to advanced persistent threats. For example upon receiving a warning message from the APT detection center at operation the user may delete quarantine the suspect object s e.g. an email or file and or report the suspect object s to a network administrator. Also the APT detection center may generate an identifier for the APT malware including its metadata such as for example its characteristics and behaviors observed during processing. The identifiers may be stored in the APT intelligence database and may be distributed to one or more client devices and MCD system . The identifier or parts thereof may be used to generate a signature for the APT malware which may be used in turn by the client devices and MCD systems to block future objects content where signature matches are found. This proactive action may ensure that the client device A is not infected by the suspect object and sensitive data accessible to the user is not compromised by the suspect object.

Although described above in relation to providing a web interface for directly informing a user of the status of a suspect object i.e. whether the suspect object is APT malware non APT malware or non malware in other embodiments the APT detection center may utilize APT malware determinations for different additional operations. For example in one embodiment at operation the APT detection center may perform one or more of 1 creating attacker profiles 2 collecting evidence 3 determining the level of severity of an APT malware object 4 discovering and identifying overall APT campaigns 5 performing attribution of APT attacks and 6 predicting future APT trends. In one embodiment detection of APT objects by the APT detection center may be used for evidence collection and analysis at operation using the post analysis detection module shown in . For example by recording features and characteristics of APT objects and non APT objects the APT detection center may develop a collection of evidence that may be used for development of future defense systems and or determination of attack trends.

For example in one embodiment the objects in the APT intelligence database may be mined examined to create attacker profiles at operation using the attacker profiler logic and stored in the APT intelligence database . The attacker profiles may describe individuals and or organizations generating and disseminating APT objects. For example multiple objects in the APT intelligence database that have been identified as APT objects may each include similar features that described a potential attacker.

As shown in attacker profiles A C are each associated in the APT intelligence database with one or more APT objects A F. The attacker profiles describe an individual or an organization that generates and or disseminates APT objects based on shared features in a set of APT objects associated with the attacker profiles . For example attacker profile A is associated with APT objects A and B which may be stored in the APT intelligence database . As shown each of the APT objects A and B share features and . In this example attacker profile A is defined by features and shared between associated APT objects A and B. In one embodiment the features identifying an attacker may include an originating server for the APT objects an originating country for the APT object infrastructure similarities between APT objects dynamic action similarities of the APT objects etc.

As also shown in attacker profile B is associated in the APT intelligence database with APT objects B and C. This relationship is based on the APT objects B and C sharing features and . Accordingly in some embodiments APT objects may be associated with multiple attacker profiles based on disjointed feature similarities between sets of APT objects stored in the APT intelligence database . As each new APT is identified the corresponding attacker profile may be updated to reflect the attack such that the attacker profiles are cumulative.

Attacker profile C shown in is associated in the APT intelligence database with APT objects D F. These APT objects D F share features and . Although other features are present in each APT object D F that are not shared between other APT objects D F the shared features and are determined to be sufficient to correlate the APT objects D F with the single attacker profile C.

In one embodiment the attacker profiles may be utilized to attribute APT campaigns to specific attackers using the attacker profiler logic . For example upon detection and classification of an APT object using the method or any other technique the newly classified APT object may be compared against the APT objects associated with each attacker profile as stored in the APT intelligence database to attribute the newly classified APT object to a specific attacker or set of attackers. The comparison may utilize machine learning and or statistical analysis as described above to determine a correlation or match at a prescribed level e.g. with respect to a threshold that is predetermined or manually set. This attribution may be useful in informing user of the client device s network administrator law enforcement or other organizations of the APT attack. This attribution may lead to more accurate identification and signatures generations which may lead to more accurate future detection and blocking of APT objects.

In one embodiment APT campaigns may be determined based on analysis of classified APT objects over time using APT campaign identifier logic of . As shown in APT objects which may be stored in the APT intelligence database are mapped against a timeline or to be more specific their stored metadata that specifies time information for the APT attack is mapped against the timeline. The APT objects may be compared against specified time frames to determine a possible campaign by a particular attacker defined by an attacker profile . For example the time frames may be between 1 30 seconds 1 5 hours 1 3 days or any other segment of time.

In one embodiment the number of detected APT objects associated with an attacker profile in a specified time frame is compared against a campaign threshold value. In some embodiments the campaign threshold value may be set based on prior APT campaigns stored in the APT intelligence database . If the number of detected APT objects associated with an attacker profile in the specified time frame is above the campaign threshold value a campaign by the attacker associated with the attacker profile is confirmed for the specified time frame at operation .Information regarding the campaign and its included APT objects is then stored in the APT intelligence database .

For example as shown in in time frame A there are two instances of APT object A that have been detected and three instances of APT object B that have been detected. In this example the campaign threshold value may be set to four. Since there are collectively five APT objects A and B from a single attacker profile A as shown in during the time period A which is greater than the campaign threshold value of four a campaign corresponding to the attacker profile A has been detected.

In another example seven APT objects have been detected during time period B. In particular two instances of APT object B two instances of APT object C and three instances of APT object E have been detected during time period B. However since there are not five or more APT objects i.e. above the campaign threshold value of four from the same attacker profile during the time period B an APT campaign is not detected.

In the time period C two APT objects D have been detected two APT objects E have been detected and one APT object F has been detected. Since there are collectively five APT objects D E and F from a single attacker profile C during the time period C which is greater than the campaign threshold value of four a campaign corresponding to the attacker profile C has been detected.

In one embodiment a detected campaign may be determined relative to an individual industry and or class. For example APT campaigns may be determined relative to targets in any of various categories for example the financial industry government institutions etc. Information regarding these detected campaigns including their targeted industries and classes e.g. categories may be stored in the APT intelligence database .

In one embodiment an alert or report of a detected campaign may be forwarded to victims of the campaigns to warn of an ongoing attack. In one embodiment the features associated with the attacker profile committing the attack and if applicable the targeted industries or classes may also be transmitted along with a warning to the user. In other embodiments a detected campaign may be reported to network administrators in a target industry and or law enforcement personnel. In addition to reporting upon detecting a campaign associated features may be assigned higher weights during machine learning. Based on this continued learning process previously classified non APT objects may be re analyzed with these new weights to determine if these objects were in fact APTs and part of a campaign.

In one embodiment the level of severity of an APT object may be determined based on previously categorized APT objects in the APT intelligence database at operation using the severity determination logic shown in . For example an administrator may rank the severity of an initial seed APT object in the APT intelligence database . The ranking may be on a one to ten scale where one indicates a non severe attack and a ten indicates a very severe attack. The severity may be based on the size of the target attacked e.g. the number of employees or the financial statistics of the target the damage caused by the attack i.e. the cost incurred to the target based on the attack and other similar factors. The initial seed APT object may be associated with an attacker profile based on a feature set for the APT object. Upon detection of another APT object that shares features with the initial seed APT object such that the newly detected APT object may be associated with the same attacker profile the newly detected APT object may also inherit the same severity ranking as the initial seed object. The determination of severity may be recursively performed for new APT objects based on previously ranked objects. In one embodiment the severity level for a newly detected APT object may be communicated to a user of a client device or another entity for example as part of an APT alert or report.

In one embodiment the APT detection center may use stored APT objects in the APT intelligence database to predict future attacks and or determine APT trends at operation using the prediction logic shown in . For example as shown in a cluster of APT objects E are detected in February 2012 again in May 2012 and yet again in August 2012. Based on these trends the APT detection center may determine that the APT object E attacks occur with a frequency of every three months. The frequency can be computed based on an average value of the time intervals or more complicated statistical analyses of the time intervals between past attacks. This information may be extrapolated to compute a prediction of a next attack and information regarding past attacks can be used to warn potential targets e.g. a user of client device A or those within a specified industry or class or informing law enforcement personnel of a potential upcoming attack based on previous trends. For example in the above scenario an attack of APT objects E is predicted to occur in November 2012 based on a previous trend of attacks.

In one embodiment the APT detection center may detect trends that indicate the likely occurrence of a future APT attack at operation using the trend analysis logic shown in . For example as shown in a single APT object B is detected in January 2012 followed by a number of APT objects B in February 2012. Similarly a single APT object B is detected in June 2012 followed by a number of APT objects B in July 2012. This trend of a probe APT object B followed by a plurality of APT objects B the next month may be determined to be a trend by the APT detection center such that upon detection of a single APT object B the APT detection center may determine that this detected object B is a probe object that foreshadows a larger scale APT attack in the next month. This information may be used to warn potential targets e.g. a user of client device A or informing law enforcement personnel.

Similar to the description provided above in relation to campaign classifications in one embodiment a detected trend may be determined relative to an individual industry and or class of targets. For example APT trends may be determined relative to the financial industry government institutions etc. Moreover where a plurality of malware and or campaigns targeting various industries or classes or a specific industry or class are discovered predictions as to future trends may be made using mathematical modeling techniques known to those of ordinary skill in the art and stored in the APT intelligence database .

Information regarding the frequency trends and predictions may be stored in the APT intelligence database and modified or confirmed as further APTs are identified. Information regarding the modifications and confirmations may be also issued in warnings and reports. The various warnings and reports may be distributed on a subscription basis.

As described above based on captured extracted features the APT detection center using the method may automatically detect APT attacks objects through the use of previously identified APT object non APT objects and general benign objects. Classified objects may be stored in the APT intelligence database such that data mining and analysis can be performed. For example in one embodiment the APT detection center may perform one or more of 1 creating attacker profiles 2 collecting evidence 3 determining the severity level of an APT malware object 4 discovering and identifying overall APT campaigns 5 performing attribution of APT attacks and 6 predicting future APT trends. This analysis of data in the APT intelligence database may produce useful data for the prediction and prevention of future APT attacks.

As described in greater detail based on captured extracted features the APT detection center may be configured to automatically detect APT attacks objects through the use of previously identified APT object non APT objects and general benign objects. More specifically techniques for detecting APT attacks objects by discovering and identifying advanced persistent threats APT using an APT detection center alone or in combination with malware analysis conducted by the static analysis engine and or the dynamic analysis engine may entail the one or more of the following 

 A An APT server receives an object to be classified. The object may already have been analyzed by a malware detection system or logic and found to be suspicious or even malicious. Malware detection systems may compare features e.g. characteristics and or behaviors of the object with features associated with known malware. The malware detection systems may compare the objects with features of known malware and known non malware. The feature set for purposes of this comparison may be obtained from a database whose contents are derived from past malware analysis. Malware may include APT as well as non APT malware.

 B The APT server extracts features of the object describing behavior of the received object. These extracted features may include those associated specifically with an APT either alone or in combination with other extracted features. Indeed these extracted features may be highly correlated with an APT either alone or when considered in combination with other extracted features. The extraction process may take advantage of information stored in the intelligence database to provide efficient identification and extraction of such features. The APT server stores the received object along with the extracted features in an APT database. These stored extracted features may include features that perform any of the following 

1 indicate the object intends to employ spearfishing or other impersonation techniques to gain unauthorized entry to a system network or IT resource or unauthorized access to data for purposes of data exfiltration or other common APT activity 

2 identify a source or origin of the object for example a geographic location or enterprise organization website e.g. URL or device e.g. IP address from which communication packets constituting the object were sent as identified for example in packet headers which may or may not map to or be associated with sources of prior APT attacks or campaigns 

3 identify the location or identify a destination of the object for example a geographic location or enterprise organization website e.g. URL or device e.g. IP address to which communication packets constituting the object were sent as identified for example in packet headers which may or may not map to or be associated with targets of prior APT attacks or campaigns 

6 indicate the object has prior knowledge about its destination for example details regarding financial records personal information and or

7 indicate the object has an embedded object or will create or drop another object process or file particular where the object process or file is designed to takes advantage of non public or not commonly known information of the destination.

The foregoing is not intended as a complete list of such potentially extracted features. APTs are becoming ever more sophisticated and evolving so that currently or in the future they may exhibit different types of features or different combinations of features. Accordingly the present description is intended to provide a framework and guidance to allow those skilled in the art to practice the invention.

 C An APT classifier compares the extracted features with features of objects in the APT database to determine whether the object constitutes an APT. The classifier may classify the object in response to determining that its extracted features include one or more APT related features either when considered alone or in combination with other extracted features having a predetermined level of correlation with one or more features of known APT objects in the APT database. The classification may also be based at least on part on correlation of the features either alone or in combination with features of known non APT malware or known benign objects. The APT classifier may use the information stored in a local intelligence database and or may access a cloud based APT database that may have information gathered from a number of APT detection centers.

 D The APT classifier may use information concerning prior APT campaigns in making the classification of whether the object constitutes an APT. The APT classifier may also determine whether the current object is part of an on going APT campaign based on its features having a correlation above a threshold with campaign information accessed in the intelligence database.

 E Post detection logic implemented within the APT detection center or separate from the APT detection center may be configured to 1 determining or updating APT attacker profiles 2 determining or updating severity information regarding the APT attack represented by the object 3 discovering or updating APT campaign trends 4 making APT predictions based on APT trends taking into account the APT object and information contained in the intelligence database and 5 performing attribution of the APT object to its author or publisher. The post detection logic may use the information in a local intelligence database and or may access by a look up in a cloud based database that may have information gathered from a number of APT detection centers.

 F The APT classifier flagging the received object as an APT object in the intelligence database and also recording in the intelligence database information regarding attacker profiles severity campaigns trends predictions and attributions if any.

 G Reporting module issuing an alert or report on the newly discovered or confirmed APT and related information as stored in the intelligence database.

In some embodiments the malware detection system may be implemented separately from the APT detection system and in others they may be integrated together at some level. When integrated the system may determine whether the object is benign malware or APT malware based on a single extraction classification process.

