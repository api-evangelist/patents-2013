---

title: Digital annotation-based visual recognition book pronunciation system and related method of operation
abstract: A digital annotation-based visual recognition book pronunciation system and its method of operation are disclosed. In one embodiment, a mobile application program in the system extracts graphical feature points from a page image of a book captured by an integrated camera lens, transmits the graphical feature points to a digital annotation database executed in a cloud computing server, retrieves a book pronunciation content associated with the page image of the book, and superimposes an icon or a representation of the book pronunciation content on the page image of the book displayed as a real-time augmented application on the display panel of the mobile device. The system further includes the digital annotation database that stores relational data between the page image of the book and the book pronunciation content recited by a human narrator, and a related image analysis and matching program.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09462175&OS=09462175&RS=09462175
owner: 
number: 09462175
owner_city: 
owner_country: 
publication_date: 20131118
---
The present invention generally relates to visual recognition of an object by an electronic device and also relates to virtually attaching or associating digitized information to the object. More specifically the present invention relates to one or more embodiments of digital annotation based visual recognition book pronunciation systems and related methods of operation.

Modern portable electronic devices such as smart mobile phones and wearable electronic glasses are increasingly capable of performing visual recognition of certain objects using a camera lens global positioning system GPS coordinate information electronic map information and other resources. In some instances an electronically recognized object such as a landmark a building and a tourist attraction enable a portable electronic device and or a data storage connected to the portable electronic device to retrieve useful information which can be overlaid on top of the electronically recognized object on a real time basis. For example a user wearing electronic glasses may glance at a landmark and a transparent display on the electronic glasses may display historical or background information associated with the landmark. The real time overlaying of information on top of a user s current line of sight is also known as augmented reality. 

A massive scale visual recognition of objects and digital annotation of various information to the objects are still at an early stage of engineering feasibility and commercialization today. The sole inventor of the present invention had also previously invented a novel massive scale visual recognition and digital annotation engine with a trademarked name Slin Gooz which is in the process of being deployed in various industries and market segments. However various applications involving augmented reality have not yet addressed substantial synergistic benefits in education markets.

For example in the English as Second Language ESL education markets or in the early childhood education markets only specialized printed publications that embed certain printed dot patterns are able to be read aloud when a specialized text reading pen scans a particular word using optical character recognition and or infrared signature detection methods. The existing book pronunciation technologies require specialized text prints for compatibility with the specialized text reading pen which significantly limits the availability and the selection of books that can be utilized for voice pronunciation of books contents. Furthermore the specialized text reading pen requires a constant contact to the surface of the book for deciphering the specialized text prints thereby causing user inconvenience and distraction. Moreover the existing book pronunciation technologies do not easily enable a third party entity to create update and or revise book pronunciation contents for a particular book as the specialized text reading pen typically only accesses locally stored voice data and or locally stored algorithms for book pronunciations.

Therefore it may be advantageous to devise a novel book pronunciation system and its related infrastructure that can perform visual recognition on any conventional printed publications for voice pronunciation of conventional printed publication contents without requiring a specialized text reading pen or special printed dot patterns only recognized by the specialized text reading pen. Furthermore it may also be advantageous to devise a novel book pronunciation system and its related infrastructure that enable a dynamically updatable selection of voice pronunciation files and contents which can be virtually attached to or associated with a physical book or a printed publication via digital annotation across a cloud computing network.

In addition it may also be advantageous to devise a mobile application that uniquely utilizes a smart portable device e.g. a smart phone as a graphical feature points extraction tool for a visual recognition of a particular printed publication as a voice pronunciation tool for an annotated dataset retrieved from a computer server and also as a voice pronunciation contents generator for a variety of books printed publications. Moreover it may also be advantageous to devise a method of operating a novel book pronunciation system and its related infrastructure in a sustainable business ecosystem which encourages creation maintenance and utilization of robust voice pronunciation files and contents.

Summary and Abstract summarize some aspects of the present invention. Simplifications or omissions may have been made to avoid obscuring the purpose of the Summary or the Abstract. These simplifications or omissions are not intended to limit the scope of the present invention.

In one embodiment of the invention a digital annotation based visual recognition book pronunciation system is disclosed. This system comprises a mobile device with a CPU a memory unit a display panel an integrated camera lens and a wireless transceiver for data communication a mobile application program executed on the CPU and the memory unit of the mobile device wherein the mobile application program extracts graphical feature points from a page image of a book captured by the integrated camera lens transmits the graphical feature points to a digital annotation database executed in a cloud computing server retrieves a book pronunciation content associated with the page image of the book and superimposes an icon or a representation of the book pronunciation content on the page image of the book displayed as a real time augmented application on the display panel of the mobile device the digital annotation database executed in the cloud computing server wherein the digital annotation database stores relational data between the page image of the book and the book pronunciation content recited by a human narrator an image analysis and matching program executed in the cloud computing server wherein the image analysis and matching program compares the graphical feature points from the page image of the book against a stored list of images or other graphical feature points in the digital annotation database and wherein a correct image match allows the mobile device to retrieve the book pronunciation content associated with the page image of the book and the cloud computing server configured to receive information from or transmit information to the mobile application program executed on the CPU and the memory unit of the mobile device via a wireless data network.

Furthermore in another embodiment of the invention a method of operating a digital annotation based visual recognition book pronunciation system is disclosed. This method comprises the steps of registering a book cover image and page images of a book to a digital annotation database executed on a cloud computing server using a first mobile device generating and recording a book pronunciation content associated with the book using the first mobile device uploading the book pronunciation content to the digital annotation database from the first mobile device to create relational data and linkage among the book cover image the page images of the book and the book pronunciation content transmitting a mobile application program to a second mobile device wherein the mobile application program is configured to extract graphical feature points from a page image of the book captured by an integrated camera lens send the graphical feature points to the digital annotation database retrieve the book pronunciation content associated with the page image of the book and superimpose an icon or a representation of the book pronunciation content on the page image of the book displayed as a real time augmented application on a display panel of the second mobile device and streaming the book pronunciation content to the second mobile device upon a user request made via the mobile application program executed on the second mobile device.

Specific embodiments of the invention will now be described in detail with reference to the accompanying figures. Like elements in the various figures are denoted by like reference numerals for consistency.

In the following detailed description of embodiments of the invention numerous specific details are set forth in order to provide a more thorough understanding of the invention. However it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances well known features have not been described in detail to avoid unnecessarily complicating the description.

The detailed description is presented largely in terms of description of shapes configurations and or other symbolic representations that directly or indirectly resemble one or more digital annotation based visual recognition book pronunciation systems and related methods of operation. These process descriptions and representations are the means used by those experienced or skilled in the art to most effectively convey the substance of their work to others skilled in the art.

Reference herein to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment. Furthermore separate or alternative embodiments are not necessarily mutually exclusive of other embodiments. Moreover the order of blocks in process flowcharts or diagrams representing one or more embodiments of the invention do not inherently indicate any particular order and do not imply any limitations in the invention.

One objective of an embodiment of the present invention is to provide a novel book pronunciation system and its related infrastructure that can perform visual recognition on any conventional printed publications for voice pronunciation of conventional printed publication contents without requiring a specialized text reading pen or special printed dot patterns only recognized by the specialized text reading pen.

Another objective of an embodiment of the present invention is to provide a novel book pronunciation system and its related infrastructure that enable a dynamically updatable selection of voice pronunciation files and contents which can be virtually attached to or associated with a physical book or a printed publication via digital annotation across a cloud computing network.

Yet another objective of an embodiment of the present invention is to provide a mobile application that uniquely utilizes a smart portable device e.g. a smart phone as a graphical feature points extraction tool for a visual recognition of a particular printed publication as a voice pronunciation tool for an annotated dataset retrieved from a computer server and also as a voice pronunciation contents generator for a variety of books printed publications.

In addition another objective of an embodiment of the present invention is to provide a method of operating a novel book pronunciation system and its related infrastructure in a sustainable business ecosystem which encourages creation maintenance and utilization of robust voice pronunciation files and contents.

For the purpose of describing the invention a term digital annotation is defined as associating one or more pieces of data or datasets with a physical object which is electronically recognized and stored as image data and or as graphical feature points in a data storage. For example a piece of data that undergoes data association and or linking with an image data of a physical object is called digitally annotated. The data association and or linking i.e. digital annotation between the piece of data and the image data of the physical object may be graphically represented as a sticky note i.e. representing the piece of data attached to the image or the image data of the physical object.

Furthermore for the purpose of describing the invention a term visual recognition is defined as electronically recognizing a physical object by comparing a captured image data and or graphical feature points extracted from the captured image data with a stored image data and or stored graphical feature points.

Moreover for the purpose of describing the invention a term book pronunciation is defined as vocalizing at least some contents of a book or a printed publication by a real human narrator who records his or her voice using an electronic device such as a smart phone a tablet computer and wearable electronic glasses.

In addition for the purpose of describing the invention a term augmented reality is defined as displaying showing superimposing and or embedding textual multimedia or other information to one or more objects viewed through a display a viewfinder or another electronic unit capable of showing the one or more objects.

Furthermore for the purpose of describing the invention a term cloud is defined as a data network connected environment for information access storage erasure and update. The data network connected environment can be provided using a physical connection a wireless connection or both. For example a cloud computing server can store image data and any associated annotated datasets in a database and a mobile device that queries for any annotated datasets to a newly captured image from a mobile application program can retrieve any associated annotated datasets from the cloud computing server via wireless and or wired data communication over a cloud network.

In the preferred embodiment of the invention a mobile electronic device utilizes its integrated camera to capture a book image data using a novel mobile application program capable of sending an image query to a cloud computing server . In the preferred embodiment of the invention the mobile application program executed in the mobile device may transmit the captured image data to the cloud computing server which in turn performs graphical feature points extraction from the captured image data to query a matched image data stored in a digital annotation database operating in the cloud computing server . In an alternate embodiment of the invention the mobile application program executed in the mobile device may first perform graphical feature points extraction from the captured image data before sending the extracted graphical feature points or related data to the cloud computing server .

In the preferred embodiment of the invention if the matched image data is found in the digital annotation database any annotated datasets which are linked and associated with the matched image data may be retrieved and then transmitted to the mobile device or . The matching between the captured image data and the matched image data may involve graphical feature points comparisons between the captured image data and the matched image data . A probability analysis to determine a likely match or an unlikely match between the captured image data and the matched image data can be performed by an image analysis and matching program executed on a CPU and a memory unit of the cloud computing server . The image analysis and matching program are configured to access a variety of datasets and image data in the digital annotation database which is also stored inside or operatively connected to the cloud computing server .

Continuing with in the preferred embodiment of the invention annotated datasets are typically textual or multimedia e.g. video audio photographs and etc. information that are associated with the matched image data . In the example as shown in a user selected annotated dataset among a plurality of annotated datasets can be visually superimposed on a view of a book through a display panel on a mobile device . Typically the user is given menu choices in a mobile application program running in the mobile device to inspect a list of annotated datasets and select a particular annotated dataset.

In the example as shown in the user selected annotated dataset is visually superimposed on top of a book cover. The user selected annotated dataset may be an audio file icon a video file icon a photograph a hyperlink or another source of information that is superimposed on top of the view of the book cover through the display panel on the mobile device . In some embodiments of the invention the user may interact with the user selected annotated dataset by touching an icon a graphics representation or a text link within the superimposed space containing a representation of the user selected annotated dataset . For example if a sound file icon is displayed on top of the view of the book cover through the display panel on the mobile device the user may initiate book pronunciation by touching the sound file icon.

In the service application example as shown in if the digital annotation database operating in the cloud computing server finds an appropriate match for the captured image data or the graphical feature points derived from it annotated datasets that are associated and linked with the matched image data can be retrieved for real time streaming or transmission to the mobile device . In one embodiment of the invention if the matched image data is found in the digital annotation database operating in the cloud computing server any annotated datasets that are linked and associated with the matched image data may be retrieved and then transmitted to the mobile device . If the image data stored in the digital annotation database and the captured image data do not match successfully then a notification message indicating that no matching image is found can be transmitted to the mobile device instead of a selection menu for accessing the annotated datasets . The matching between the captured image data and the matched image data may involve graphical feature points comparisons between the captured image data and the matched image data.

In a preferred embodiment of the invention a probability analysis to determine a likely match or an unlikely match between the captured image data and the matched image data can be performed by an image analysis and matching program executed on a CPU and a memory unit of the cloud computing server . The image analysis and matching program are configured to access a variety of datasets and image data in the digital annotation database which is also stored inside or operatively connected to the cloud computing server .

Continuing with once at least a portion of the annotated datasets are streamed or transmitted to the mobile device one or more icons for the annotated datasets may appear virtually attached to an image of a book viewed through a display panel of the mobile device depending on a particular need of an application. Furthermore the mobile application program executed on a CPU and a memory unit of the mobile device may initiate a multimedia action such as pronouncing contents of the book that matched the image data of the book stored in the digital annotation database in the cloud computing server .

In a preferred embodiment of the invention the annotated datasets for the matched image of the book are stored in a relational database that associates an image data of a particular book with the annotated datasets for the book. The creation of the annotated datasets may be performed by a content creator a publisher or a user by electronically submitting textual and or multimedia contents which they believe are related to the book. Examples of the annotated datasets include but are not limited to audio video image text and three dimensional graphics data as shown in .

In the example as shown in an audio file icon appears in the display panel of the mobile device for book pronunciation once the digital annotation database operating in the cloud computing server finds the matched image data and makes the associated annotated datasets available for download or retrieval by the mobile device . Typically the mobile application program executed on the CPU and the memory unit of the mobile device can display a selection of book pronunciation options or other information from annotated datasets from the cloud computing server to allow the user to select a desired content replay option before the book pronunciation is initiated in the mobile device . In one embodiment of the invention a user selected annotated dataset may be an audio file icon a video file icon a photograph a hyperlink or another source of information viewable on the display panel on the mobile device . In some embodiments of the invention the user may interact with the user selected annotated dataset by touching an icon a graphics representation or a text link containing a representation of the user selected annotated dataset. For example as shown in the sound file icon displayed on the display panel of the mobile device may activate a book pronunciation from the user selected annotated dataset retrieved from the digital annotation database when it is touched by the user s finger.

If the image match search is successful then any annotated datasets stored in the digital annotation database may be retrieved by the mobile application program based on a user s menu selections. In the embodiment of the invention as disclosed in a user is given a list of audio contents each of which is related to vocal book pronunciation of the book identified by the image match search as shown in a third screenshot . For example book pronunciation contents for a book called The Cat in the Hat is provided as a list of audio contents once the digital annotation based visual recognition book pronunciation system identified the image of the book and its related annotated datasets. In this example the related annotated datasets to The Cat in the Hat are four content choices i.e. Random House Audio Tina See NancyMom and SpanishDad for book pronunciation as shown in the third screenshot . In the example as shown in the user may touch a particular menu entry item at his or her discretion to initiate book pronunciation for The Cat in the Hat. 

Then in one embodiment of the invention the mobile application program executed on the mobile device may begin to play already locally downloaded voice pronunciation content for Tina Reads Dr. Seuss as shown in a second screenshot . In an alternate embodiment of the invention the mobile application program executed in the mobile device may begin to stream the voice pronunciation content for Tina Reads Dr. Seuss from a digital annotation database in a cloud computing server as also shown in a second screenshot .

Furthermore in one embodiment of the invention as shown in a third screenshot if a user aims the integrated camera of the mobile device to a different page of the book the change in aiming of the integrated camera to the different page can trigger playback of different contents from the voice pronunciation content for Tina Reads Dr. Seuss. For example the second screenshot shows playing the front cover of the voice pronunciation content for Tina Reads Dr. Seuss. Once the integrated camera of the mobile device points Page instead of the front cover as shown in the third screenshot the mobile application program begins to play Page of The Cat in the Hat with voice pronunciation provided by Tina Reads Dr. Seuss. 

In another embodiment of the invention the screenshot sequence provided by the first screenshot the second screenshot and the third screenshot may be part of a different user application utilizing the digital annotation based visual recognition book pronunciation system instead of being a continued application from .

In the embodiment of the invention as shown in if the continuous play mode is on a selected book pronunciation content is continuously played once visual recognition of a book image matching for the book and annotated dataset retrieval to the mobile device are completed for the book even if an integrated camera lens of the mobile device no longer aims at a specific content in the book. On the other hand if the continuous play mode is off then the user is required to continue aiming the integrated camera lens of the mobile device at the specific content for continuous play of the selected book pronunciation content.

Furthermore if the contents local save mode is on any selected annotated datasets that have been streamed and or retrieved by the mobile device are saved in a local storage of the mobile device. Typically most of the selected annotated datasets may be book pronunciation audio contents or other multimedia files involving video and audio files. On the other hand if the contents local save mode is off then any selected annotated datasets that have been streamed and or retrieved by the mobile device are not permanently stored in the local storage of the mobile device other than being temporarily stored for buffering of a multimedia streaming from a cloud computing server.

In one embodiment of the invention the captured image of the book is compared against a plurality of book related image data in the digital annotation database operating in a cloud computing server. If a matching image is found then any content created by the user is dynamically associated with the matching image as a newly annotated dataset. On the other hand if the matching image is not found in the digital annotation database then a new data entry for the captured image of the book is created in the digital annotation database and is subsequently associated with any annotated datasets provided by a content creator a book publisher a teacher and or a user.

As shown in a first screenshot of the user can pair the book with a content to be created by aiming the integrated camera lens to a page in the book. Then by touching a button on a menu screen that provides the functionality of recording or creating the content the user can initiate recording and or creating his or her book pronunciation content as shown in a second screenshot of . An audio microphone integrated in the mobile device may be utilized for any audio recordings for creating the user s book pronunciation content. In a preferred embodiment of the invention the user s book pronunciation content is a direct recitation of texts contained in the book. However in other embodiments of the invention the user s book pronunciation content generation may also add instructive descriptive and or additional comments other than the direct recitation of the texts alone.

After the user completes creating and or recording the book pronunciation content the mobile application program executed in the mobile device is configured to transmit the book pronunciation content to the digital annotation database operated in the cloud computing server. If the digital annotation database successfully pairs the image of the book i.e. The Cat in the Hat with the newly created book pronunciation content the cloud computing server can transmit an updated list of book pronunciation contents to the mobile device. Then the mobile device can display the updated list of book pronunciation contents for the book which now includes the user s newly created book pronunciation content i.e. Debbie on Dr. Seuss as shown in a third screenshot of .

The embodiment of the invention as shown is one of many embodiments of the invention for content creation and pairing with book images. For example book pronunciation content creation and book image to book pronunciation content pairing in a digital annotation database may be completed by a book publisher or a professional content creator that generates a large number of book pronunciation contents which may be processed in parallel by a multiple number of people.

In this embodiment of the invention the second mobile device utilizes its integrated camera to capture a book image data using a novel mobile application program capable of sending an image query to a cloud computing server . The first mobile device on the other hand records a voice pronunciation content and transmits the newly recorded voice pronunciation content to the cloud computing server for data pairing between the book related image data and the newly recorded voice pronunciation content. In a preferred embodiment of the invention the first mobile device and the second mobile device may be a single electronic device that serves functions of capturing the book image data recording the voice pronunciation content and transmitting relevant data for pairing and storage in the digital annotation database in the cloud computing server . In another embodiment of the invention the first mobile device may be utilized by a first user and the second mobile device may be utilized by a second user.

In the embodiment of the invention as shown in the mobile application program executed in the first mobile device may transmit the captured image data of the book to the cloud computing server which in turn performs graphical feature points extraction from the captured image data to query a matched book related image data stored in a digital annotation database operating in the cloud computing server . In an alternate embodiment of the invention the mobile application program executed in the first mobile device may first perform graphical feature points extraction from the captured image data before sending the extracted graphical feature points or related data to the cloud computing server .

If the matched book related image data is found in the digital annotation database then any annotated datasets which are linked and associated with the matched book related image data may be retrieved and then transmitted to any connected mobile devices. Furthermore if the first mobile device transmits a user s book pronunciation content associated with the matched book related image data to the digital annotation database then the user s book pronunciation content from the first mobile device becomes a new annotated dataset which is dynamically linked and associated with the matched book related image data stored in the digital annotation database . This new annotated dataset is then readily accessible over the cloud network by any connected mobile devices executing the mobile application program for the digital annotation based visual recognition book pronunciation system.

Furthermore this new annotated can graphically appear as a virtual sticky annotation icon attached on a book image when the book image is viewed through a camera lens of the mobile device in an augmented reality environment as shown in . Other virtual sticky annotation icons also attached to the book image also represent other annotated datasets to the matched book related image data such as book pronunciation contents recited by other content providers related video files or other textual or multimedia contents. The visualization of virtual sticky annotation icons as shown in and the visually superimposed annotated datasets as previously shown in are part of a novel augmented reality environment provided by the mobile application program and the rest of the digital annotation based visual recognition book pronunciation system.

In a preferred embodiment of the invention book publishers may also additionally provide book pronunciation contents as annotated datasets to the digital annotation database wherein the annotated datasets are paired with the corresponding registered images of books at the time of book publication. Alternatively book publishers may not provide any book pronunciation contents but may simply register images of books in the digital annotation database and rely on third party content creators and or users to add book pronunciation contents to the digital annotation database.

Subsequently when the consumer purchases the book from the bookstore the consumer can utilize a mobile device such as a smart phone or a tablet computer to download a book pronunciation mobile application program e.g. SayBooks App which provides a user menu to download and stream a variety of book pronunciation contents stored in the digital annotation database. The digital annotation database associates the book cover image and the book page images with any uploaded book pronunciation contents and other annotated datasets in a relational database. If the consumer wants to download a particular book pronunciation content or another annotated dataset associated with the book from the digital annotation database then the digital annotation database content provider can provide book pronunciation content streaming or other digital content streaming to the consumer from the cloud computing server.

The publisher license fee business model assumes that the paper printed versions of the book from the book publisher will experience higher volume sales due to the book s compatibility with the digital annotation based visual recognition book pronunciation system. Therefore the book publisher may be motivated to provide some paper printed book sales royalties to the digital annotation database content provider for the book publisher s rights to upload book pronunciation contents and other digital contents in the digital annotation database operated by the digital annotation database content provider . In the publisher license fee business model as shown in the book publisher may pay three to five percent of the paper printed book sales revenue as royalties to the digital annotation database content provider . In this business model the bookstore typically does not pay royalties to or share revenues with the digital annotation database content provider . However in some embodiments of the invention it may be desirable to allow the bookstore to either pay royalties to the digital annotation database content provider or alternatively share revenues with the digital annotation database content provider .

In the open content market place business model as shown in a third party content creator is also empowered by the digital annotation database content provider to add extra book pronunciation contents and or other digital contents associated with the book. Typically any extra book pronunciation contents and or other digital contents provided by the third party content creator rely on paid download license fees from the consumer . The digital annotation database managed by the digital annotation database content provider associates the book cover image and the book page images with any uploaded book pronunciation contents and other annotated datasets in a relational database. If the consumer desires to download a particular book pronunciation content or another annotated dataset associated with the book from the digital annotation database then the digital annotation database content provider can provide book pronunciation content streaming or other digital content streaming to the consumer from the cloud computing server.

Furthermore the open content market place business model also involves the mobile application store such as Apple s App Store or Android s Play Store which enables widespread availability of the book pronunciation contents and or other digital contents provided by the book publisher and the third party content creator . Preferably the mobile application store is dynamically linked to the digital annotation database of the digital annotation database content provider so that any updated book pronunciation contents and other digital contents for the book can be readily downloaded and or streamed to the consumer s mobile device through the mobile application store .

Then when the consumer purchases the paper printed version of the book from an online or offline bookstore the consumer can utilize a mobile device such as a smart phone or a tablet computer to download a book pronunciation mobile application program e.g. SayBooks App from the mobile application store or from the digital annotation database of the digital annotation database content provider . The book pronunciation mobile application program e.g. SayBooks App provides a user menu to download and stream a variety of book pronunciation contents stored in the digital annotation database.

The open content market place business model is designed to share revenues generated from the consumer s content download fees with multiple entities. For example when the consumer pays a content download fee to the mobile application store related to the book the mobile application store the digital annotation database content provider and the book publisher can all share revenues at specific percentage ratios. If the third party content creator is not involved in the content downloaded by the consumer then the revenue sharing ratios may be thirty percent for the mobile application store thirty percent for the digital annotation database content provider and forty percent for the book publisher in one example as shown in . On the other hand if the third party content creator is involved in the content downloaded by the consumer then the revenue sharing ratios may be thirty percent for the mobile application store thirty percent for the digital annotation database content provider thirty five percent for the third party content creator and five percent for the book publisher as also shown in .

In the teaching curriculum business model as shown in a third party content creator is typically an educational material creator and is also empowered by the digital annotation database content provider to add extra book pronunciation contents and or other digital contents associated with the book. Typically any extra book pronunciation contents and or other digital contents provided by the third party content creator rely on paid download license fees from the consumer . The digital annotation database managed by the digital annotation database content provider associates the book cover image and the book page images with any uploaded book pronunciation contents and other annotated datasets in a relational database. If the consumer desires to download a particular book pronunciation content or another annotated dataset associated with the book from the digital annotation database then the digital annotation database content provider can provide book pronunciation content streaming or other digital content streaming to the consumer from the cloud computing server.

Furthermore the teaching curriculum business model also involves the teacher who gives in person or video based instruction to the consumer. The teacher can utilize the book pronunciation contents and or other digital contents provided by the book publisher and the third party content creator as supplementary teaching materials. Furthermore the paper printed version of the book may serve as a paper based textbook to a group of students. In some instances the teacher may directly encourage downloading of certain book pronunciation contents and or other digital contents associated with a textbook or another printed instruction material. Furthermore in some instances the digital annotation database content provider may organize and manage curriculum packages which the teacher and the consumer can readily download to their mobile devices.

Continuing with when the consumer purchases the paper printed version of the book e.g. a textbook from an online or offline bookstore or from the teacher the consumer can utilize a mobile device such as a smart phone or a tablet computer to download a book pronunciation mobile application program e.g. SayBooks App from the digital annotation database of the digital annotation database content provider . The book pronunciation mobile application program e.g. SayBooks App provides a user menu to download and stream a variety of book pronunciation contents stored in the digital annotation database.

The teaching curriculum business model is designed to share revenues generated from the consumer s content download fees with multiple entities. For example when the consumer pays a tuition to the teacher the digital annotation database content provider and the book publisher can share revenues at specific percentage ratios. If the third party content creator is not involved in the content downloaded by the consumer then the revenue sharing ratios may be a fixed amount e.g. 3 000 per year or a certain percentage for the digital annotation database content provider with certain percentages e.g. thirty percent allocated to the book publisher in one example as shown in . On the other hand if the third party content creator is involved in the content downloaded by the consumer then the revenue sharing ratios also involve allocating certain percentages to the third party content creator as also shown in .

In the teaching curriculum business model once various book pronunciation contents and other digital contents associated with books are uploaded to a digital annotation database operated by the digital annotation database content provider one or more content curators organize and create customized teaching curriculum for educational needs of various segments of student population. These content curators may be teachers themselves or professionals who primarily create curriculum for various segments of student population. After each curriculum is organized and created by the content curators data link relationships for curriculums with various combinations of book pronunciation contents and other digital contents may be stored in the digital annotation database. Then a consumer e.g. a school a book reader a teacher a student or a casual user is able to download free or paid book pronunciation contents and other digital contents from the digital annotation database operated by the digital annotation database content provider. In one embodiment of the invention the downloading of the book pronunciation contents and other digital contents may be covered by tuition paid to teachers or educational institutions. In another embodiment of the invention the consumer is a school or a teacher who pays a curriculum license fee to the content curators as shown in .

One or more digital annotation based visual recognition book pronunciation systems and related methods of operation have been disclosed in the descriptions above and also in the corresponding drawings. Various embodiments of the present invention exhibit several advantages over conventional electronic methods and systems for book pronunciations. For example an embodiment of the present invention provides a novel book pronunciation system and its related infrastructure that can perform visual recognition on any conventional printed publications for voice pronunciation of conventional printed publication contents without requiring a specialized text reading pen or special printed dot patterns only recognized by the specialized text reading pen.

Furthermore an embodiment of the present invention also provides a novel book pronunciation system and its related infrastructure that enable a dynamically updatable selection of voice pronunciation files and contents which can be virtually attached to or associated with a physical book or a printed publication via digital annotation across a cloud computing network. In addition an embodiment of the present invention also provides a mobile application that uniquely utilizes a smart portable device e.g. a smart phone as a graphical feature points extraction tool for a visual recognition of a particular printed publication as a voice pronunciation tool for an annotated dataset retrieved from a computer server and also as a voice pronunciation contents generator for a variety of books printed publications. Moreover an embodiment of the present invention also provides a method of operating a novel book pronunciation system and its related infrastructure in a sustainable business ecosystem which encourages creation maintenance and utilization of robust voice pronunciation files and contents.

While the invention has been described with respect to a limited number of embodiments those skilled in the art having benefit of this disclosure will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. Accordingly the scope of the invention should be limited only by the attached claims.

