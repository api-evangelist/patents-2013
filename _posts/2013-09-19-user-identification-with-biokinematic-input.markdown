---

title: User identification with biokinematic input
abstract: Systems and methods for user identification based on biokinematic input are disclosed herein. The system may include a multi-touch sensitive display including a sensor configured to receive biokinematic input including data representing detected positions of digit touches made by digits of a user, in each of a series of successive time intervals during a defined identification gesture. The system may further include a user identification module executed by a processor of the computing device. The user identification module may be configured to receive the biokinematic input from the sensor, and to compare relative positions of the digit touches and/or relative rates of change in said positions of the digit touches to a stored user template of verified biokinematic data for the user. If a match is determined, an indication that the user has been successfully identified may be displayed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08856543&OS=08856543&RS=08856543
owner: Microsoft Corporation
number: 08856543
owner_city: Redmond
owner_country: US
publication_date: 20130919
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 12 981 097 filed Dec. 29 2010 the disclosure of which is incorporated herein by reference in its entirety.

Biometric techniques have been developed to identify humans based on characteristic physical traits such as fingerprints and palm prints. For example palm scanners have been developed that are used to authorize or deny access to buildings and fingerprint scanners have been developed which are used to access websites and files or logon to an operating system. These systems employ a dedicated scanner with high resolution imaging capabilities sufficient to obtain a detailed scan of the skin patterns on a finger or palm thereby enabling identification of the characteristic physical traits in those skin patterns that distinguish one user from another.

There are several barriers to adoption of such biometric techniques on tablet computing devices and touch screen mobile telephones. While dedicated fingerprint and palm scanners have been employed on door access panels and laptop computer housings in the past for example where there is sufficient space to mount the scanners most tablet computing devices and touch screen mobile telephones are compact and do not have sufficient space to mount a dedicated fingerprint scanner or palm scanner. Further the touch screen technologies used in conventional tablet computing devices and mobile telephones are not of sufficiently high resolution to obtain a usable image of the skin patterns on a fingerprint or palm from which user can be distinguished. As a result the biometric techniques associated with fingerprint and palm scanning have not been widely adopted for tablet computing devices and touch screen mobile telephones.

Systems and methods for user identification based on biokinematic input are disclosed herein. The system may include a multi touch sensitive display including a sensor configured to receive biokinematic input including data representing detected positions of digit touches made by digits of a user in each of a series of successive time intervals during a defined identification gesture. The system may further include a user identification module executed by a processor of the computing device. The user identification module may be configured to receive the biokinematic input from the sensor and to compare relative positions of the digit touches and or relative rates of change in said positions of the digit touches to a stored user template of verified biokinematic data for the user. If a match is determined an indication that the user has been successfully identified may be displayed.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

Display may be a multi touch touch sensitive display including a sensor for detecting touch input. Display may employ a variety of display technologies for producing a viewable image. Thus the display may be configured as a liquid crystal display LCD or an organic light emitting diode OLED display comprised of a plurality of light emitting pixels for example. Display may also be a tabletop optical touch sensing display such as the MICROSOFT SURFACE display.

Sensor may be configured to receive biokinematic input including data representing detected positions of each of a plurality of digit touches made by a corresponding plurality of digits of a user. Sensor may be configured to receive the data in each of a series of successive time intervals during a defined identification gesture of the user. Further the plurality of digit touches of the defined identification gesture may include at least one palm touch. Thus for example the defined identification gesture may be a palm fist transition gesture in which the user presents a clenched fist and transitions to an open palm on the multi touch display or alternatively presents an open palm and transitions to a clenched fist. Such a gesture will be discussed in greater detail with respect to below. It will be appreciated that this is merely one example of an identification gesture that may be used to distinguish between individuals by the computing device . Other identification gestures involving the hands palms fingers and or thumbs moving in various ways may also be used.

Sensor may be any one of a variety of touch sensors. For example sensor may be a capacitive or resistive multi touch sensor. In these embodiments sensor may be configured to detect touch on the top surface of display through changes in detected capacitance or resistance caused by each of a plurality of digit and or palm touches.

Alternatively other touch sensitive technologies may be employed. For example display may include optical sensors which may be positioned in each pixel of the display to sense light and output from these optical sensors may be processed to detect multiple touches on the top surface of the display. These optical sensors may be configured to sense visible light and infrared light in one example. For instance the optical sensor may be an active pixel sensor APS such as a complementary metal oxide semiconductor CMOS or any other APS configured to sense visible light and infrared light.

Computing device may include mass storage unit such as a hard drive. Mass storage unit may be in operative communication with display processor and memory unit via data bus and is configured to store programs that are executed by processor using portions of memory and other data utilized by these programs. For example the mass storage device may store a user identification module and associated database . The mass storage device may further store a program that requests identification be performed by the user identification module such as an application program an operating system component such as a login program or user authentication program or other program executing on the computing device. The user identification module and program may be executed by processor of computing device using portions of memory .

User identification module may operate in various different phases such as registration phase and identification phase for example. Each phase may be associated with different components of user identification module as described below.

The user identification module may be configured to receive biokinematic input from sensor . The biokinematic input originates from sensor sensing a moving body part of a user. To distinguish one user from another the user identification module may be configured to compare relative positions of a plurality of digit touches and or palm touches contained within the biokinematic input. It will be appreciated that touches from more fewer or other body parts may also be examined. Additionally or alternatively user identification module may be configured to compare relative rates of change in said positions of the plurality of touches over time.

The received biokinematic input may be compared to stored user template of verified biokinematic data for the user which may have been previously verified and saved by user identification module during a registration phase as discussed below. If a match between the biokinematic input and stored user template is determined display may display an indication that the user has been successfully identified.

As another example user identification module may be configured to measure the relative positions and or rates of change in said positions of the plurality of digit touches relative to at least one palm touch during the palm fist transition gesture. Then user identification module may compare the measured relative positions and or rates of change to stored user template to determine whether a match exists. To accomplish this user identification module may generate a template of user biokinematic data and compare the template to a stored user template representing biokinematic data.

The internal workings of user identification module will now be described with reference to a registration phase during which new users of computer device are registered with biokinematic input used to verify user identity and an identification phase during which users are identified and granted or denied access privileges in the manner described above. As illustrated user identification module may include a feature extractor template generator and matching engine which function as described in detail below.

During registration phase feature extractor may be configured to receive a first biokinematic input from sensor and extract user identifying features from the first biokinematic input. The user identifying features may be specific to each user that is a set of particular features may be associated with one user and may be different from the particular features of another user. Thus the particular features may be used to identify one user and distinguish that user from other potential users. The first biokinematic input may include relative positions of the plurality of digit touches and in some embodiments at least one palm touch and may include the relative rates of change in said positions of these touches. As explained above the first biokinematic input may include data from a series of successive time intervals during a defined identification gesture for example a palm fist transition.

Feature extractor may extract user identifying features using any number of techniques. For example feature extractor may process an image by filtering identifying an outline of a user s hand and or computing a centroid of one or more digit and or palm touches. It will be appreciated that the aforementioned examples may be used in combination or subcombination and may further include additional or alternative means for extracting user identifying features without departing from the scope of this disclosure. The feature extractor may send an output of extracted user identifying features to the template generator for further processing.

Continuing with the registration phase template generator may create a template of data characteristic to a user from the first biokinematic input received by feature extractor . Template generator may be configured to generate a user template including the user identifying features for given user and given identification gesture and store user template in a data store such as database . Storing such characteristic data for each user the user templates may be used to compare to biokinematic data received during a subsequent user identification phase and determine whether a match exists in order to identify the user.

Database may store a plurality of user templates for a plurality of users authorized to software or data on access computing device . In some embodiments different gestures classes may be used to register the various users and thus more than one user template may exist for each user. For example one class may be a palm fist transition gesture and another class may be a finger thumb pinch gesture and a separate user template may be stored for each authenticated user who has been registered to use the computing device .

Turning now to the user identification phase this phase may be implemented during any number of user authentication operations such as a login operation opening a protected folder opening a protected file accessing a protected program accessing a protected network or any other application where user authentication is desired. For example user identification module may be executed during a user authentication operation such as user login to a user session on computing device .

During user identification phase feature extractor may receive a second biokinematic input from sensor . The second biokinematic input may include relative positions of the plurality of digit touches and at least one palm touch and may include relative rates of change in said positions of these touches. Second biokinematic input may also include data for these touches from a series of successive time intervals during a defined identification gesture. For example user identification phase may be performed in a gesture based user login operation on a login screen such as a palm fist transition as described above.

The output of the feature extractor during the user identification phase may be sent to the matching engine . The matching engine may compare the second biokinematic input to stored user template which was created based on features extracted from the first biokinematic input in order to verify the biokinematic data of the user. In some embodiments the user may input a user name to computing device and the biokinematic input may be matched as described herein in order to verify the user s identity instead of or in addition to using a PIN number or password for example. If multiple templates for different gesture classes are available for a given user matching engine may recognize the second biokinematic input as belonging to a particular gesture class such as a palm fist transition and may therefore compare the second biokinematic input to stored user templates belonging to the same gesture class.

In other embodiments which are particularly useful where the total number of registered users of a computing device is small the user does not enter a user name but simply presents the identification gesture and the user identification module searches for a user template that matches the features extracted from the biokinematic input for the presented identification gesture.

Matching engine may determine whether a match exists between the features extracted from the second biokinematic data and the user templates. If a match exists the user is determined to have been successfully identified. Matching engine may employ any number of techniques to determine that a match exists. For example matching engine may compare a characteristic or combination of characteristics of the second biokinematic input corresponding to a plurality of digit and or palm touches to the area of touches corresponding to one or more user templates within a predetermined tolerance. The characteristic may be total area centroid length of each digit from tip to palm relative lengths of each digit from tip to palm as well as the rate of change of any of these characteristics over time during the gesture. Alternatively matching engine may compare such a characteristic or combination of characteristics of the second biokinematic input to a predetermined normal model for all users. In other words matching engine may be configured to calculate a deviation of the second biokinematic input from the predetermined normal model and determine if the deviation of the second biokinematic input matches within a predetermined threshold the deviation of a corresponding user template.

When a match is determined an indication of such an event may be displayed to the user. For example the indication may be a message outputted to graphical user interface of the display after a successful user login operation. In one embodiment the graphical user interface may include a login screen and the indication may be a message displayed on the login screen of successful login. Alternatively the indication may be cessation of the login screen being displayed to the user. Following display of a message and or cessation of a login screen the user may be granted access to program file folder application network operating system etc. on computing device .

It will be appreciated that biokinematic data may be received from the plurality of digit and or palm touches without the user hand making physical contact with the device. In other words the sensor of the device may be configured to receive biokinematic data from a user hand that is substantially close to the device. Alternatively the sensor may be configured to sense the hand position when the hand is positioned proximate and spaced apart from the display as is the case with optical sensors and some capacitive sensors for example.

Biokinematic input may be specific to a user because user hands may vary greatly in size relative position and relative rates of change between the plurality of digit touches and palm touches when the hand is moving during the identification gesture. Therefore such biokinematic input may be used as a virtual signature representative of a particular user and thereby creating a means for which authentication of a user may be verified.

At method proceeds to extract user identifying features. For example a plurality of digit touches and or palm touches made by a corresponding plurality of digits and or palms of a user as shown in may be extracted. User identifying features may be extracted in each of a series of successive time intervals.

At method proceeds by measuring the plurality of digit touches and or palm touches made by the user. For example biokinematic input corresponding to the palm fist transition gesture may be measured according to the relative positions and or relative rates of change of each of the plurality of digit touches and or palm touches.

During a registration phase as described above method may proceed to and may include generating a user template of the biokinematic input referred to as first biokinematic input in the context of above corresponding to the user palm fist transition gesture. Generating a user template may include verifying through additional steps that the first biokinematic input has a high integrity or repeatability. For example verifying may include a user repeating the same identification gesture more than once prior to the creation of the user template . As such the template generator may recognize distinctive patterns of the user with greater confidence.

At method proceeds by storing the user template acquired during the registration phase in a data store such as database of computing device which may then be used during other phases of the computing device . From the method loops back to to receive another biokinematic input during an identification phase of the method.

During the identification phase method repeats steps where biokinematic input corresponding to an identification gesture such as the palm fist transition gesture may be received as a second biokinematic input during a second pass through these steps. The method proceeds along the identification path to where the method compares the second biokinematic input to a stored user template of verified biokinematic data in the database. Comparing may include an analysis of the respective positions and or respective rates of change in a plurality of digit touches and or palm touches during at least a portion of the identification gesture such as the palm fist transition gesture as described above.

At method determines if a match between the second biokinematic input and the stored user template within a predetermined tolerance exists. If the answer to is YES method proceeds to and an indication may be outputted to the display in the form of a message to indicate that the user has been successfully identified. Alternatively the indication may be a cessation of a login screen being displayed to the user.

Method then proceeds to and the user is granted access to a program file folder application operating system etc. on the computing device. From the identification phase of the method ends.

If the answer to is NO method proceeds to and the user is denied access to the program file folder application operating system etc. on the computing device. From the identification phase of the method either ends. Alternatively in some embodiments the disclosed method may additionally display an indication to the user when a match does not occur and access is denied and or may present a GUI allowing the user to reenter biokinematic input to compare to user template to allow the user to correct any input errors that may have occurred the first time around.

It will be appreciated that method may include additional or alternative steps. As one example the method may include a mechanism for determining which phase e.g. registration phase or identification phase to operate in. Typically when the user identification module is called by an operating system component registering a new user account on the computing device the registration phase will be invoked. And when an operating system component such as a login program or when an application program call the user identification module the identification phase is invoked. When the user identification module is part of an application programming interface API suitable application programming interface function calls for each phase may be provided.

The above described systems and methods may be used to incorporate biokinematic based security for controlling access to software data or other functionality of a computing device. These systems and methods offers convenience to the user while having the advantage of being implementable without a dedicated fingerprint or palm scanner as featured on prior devices.

The terms module program and engine are used herein to refer to software that performs one or more particular functions when executed by a processor of a computing device. These terms are meant to encompass individual or groups of executable files data files libraries drivers scripts database records for example. The embodiments described herein show one example organization of these modules programs and engines however it should be appreciated that the functions described herein may be accomplished by differently organized software components.

It is to be understood that the configurations and or approaches described herein are exemplary in nature and that these specific embodiments or examples are not to be considered in a limiting sense because numerous variations are possible. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such various acts illustrated may be performed in the sequence illustrated in other sequences in parallel or in some cases omitted. Likewise the order of the above described processes may be changed.

The subject matter of the present disclosure includes all novel and nonobvious combinations and subcombinations of the various processes systems and configurations and other features functions acts and or properties disclosed herein as well as any and all equivalents thereof.

