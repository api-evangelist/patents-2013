---

title: Systems and methods for image guided surgery
abstract: Systems and methods for image guided surgery are disclosed herein. An example method can include: receiving a plurality of 2D projection images of an object at a plurality of projection angles during a first period of time; and receiving a position of an instrument relative to a tracking coordinate system during the first period of time. The method can also include registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function that defines a relationship between a coordinate system of the plurality of 2D projection images and the tracking coordinate system; receiving an adjusted position of the instrument relative to the tracking coordinate system during a second period of time that is subsequent to the first period of time; and estimating an adjusted position of the instrument relative to the plurality of 2D projection images using the transformation function.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183354&OS=09183354&RS=09183354
owner: CLEMSON UNIVERSITY
number: 09183354
owner_city: Clemson
owner_country: US
publication_date: 20130815
---
This application claims the benefit of U.S. Provisional Patent Application No. 61 683 386 filed on Aug. 15 2012 entitled SYSTEMS AND METHODS FOR IMAGE GUIDED SURGERY the disclosure of which is expressly incorporated herein by reference in its entirety.

Radiation exposure from medical imaging has dramatically increased in recent decades. The average per capita radiation dose from medical imaging in the U.S. has increased six fold over the last thirty years. This increase is of great concern to the public medical community and regulatory agencies and it has been identified as an important patient safety issue. Children have compounded risk associated with radiation exposure. The longer life expectancy of children as compared to adults provides a larger window of opportunity for expressing the damaging effects of ionizing radiation. In addition epidemiologic studies of exposed populations demonstrated that children are considerably more sensitive to the carcinogenic effects of radiation.

Fluoroscopy a form of medical radiation is used to guide millions of medical procedures each year. For example cardiac catheterizations are currently performed using fluoroscopy which requires constant visualization of catheter manipulation by exposing the patient to ionizing radiation. While these important medical procedures can be lifesaving the concomitant radiation exposure places the patient at risk for development of radiation induced disease.

Children with congenital heart disease CHD are especially vulnerable. Many therapeutic interventions for CHD patients have transition from open surgical procedures to minimally invasive catheter based procedures requiring fluoroscopic guidance. While this trend has many benefits it unfortunately results in excessive cumulative radiation exposure to children who often undergo multiple complex catheter procedures. Moreover recent studies in children with CHD who have undergone catheterization have demonstrated direct DNA evidence of long lasting chromosomal damage. This alarming evidence underscores the need for an alternative to ionizing radiation to guide cardiac catheterizations in children.

To date radiation dose reduction in cardiac catheterization has been aimed at modifying the existing technology to limit dose delivery. However this approach is inherently limited because fluoroscopy remains the principal imaging modality.

Systems and methods for image guided surgery are disclosed herein. The estimated position of an instrument relative to a plurality of projection images can be displayed to facilitate guidance of the instrument during the surgery. The systems and methods track the position of the instrument relative to a tracking coordinate system and estimate the position of the instrument relative to a coordinate system of the projection images. For example the position of the instrument can be tracked using an electromagnetic EM tracking system which uses a low strength magnetic field to track the position of miniaturized sensor coils embedded in the instrument. EM tracking has been used as an adjunct modality for guiding certain types of interventional procedures. However EM tracking has been limited to guiding procedure with respect to static reference images of a patient s anatomy e.g. MRI CT scan etc. acquired prior to the medical procedure. Using static reference images is a barrier to applying EM tracking for guidance of cardiology procedures because the dynamic nature of the heart renders the static reference images ineffective as an anatomic map. Thus for EM tracking to be useful in interventional cardiology the system should integrate real time catheter position into a dynamic anatomical image of the heart.

An example method for guiding an instrument during a medical procedure can include receiving a plurality of 2D projection images of an object at a plurality of projection angles and receiving a position of the instrument relative to a tracking coordinate system. The plurality of 2D projection images can be recorded and the position of the instrument can be received during a first period of time. The method can also include registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function that defines a relationship between a coordinate system of the plurality of 2D projection images and the tracking coordinate system receiving an adjusted position of the instrument relative to the tracking coordinate system during a second period of time that is subsequent to the first period of time and estimating an adjusted position of the instrument relative to the plurality of 2D projection images using the transformation function.

In some implementations the method can include continuously displaying the plurality of 2D projection images in a loop and displaying the estimated adjusted position of the instrument relative to the plurality of 2D projection images on the loop.

Additionally the plurality of 2D projection images can depict an actual position of the instrument relative to a patient s body during the first period of time.

In some implementations the first period of time is approximately 3 5 seconds. It should be understood that the first period of time can be any length of time. For example the first period of time can be long enough to provide an anatomic roadmap of the object for guidance during the procedure and short enough to reduce the amount of radiation exposure during the procedure.

Optionally the method can include receiving a cine loop including a plurality of 2D projection images of an object at a plurality of projection angles. For example the cine loop can be recorded by an imaging system. The cine loop can optionally be recorded prior to performing the medical procedure.

Additionally registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function according to the implementations discussed above can include receiving a position of the instrument relative to the tracking coordinate system at each of a plurality of fiducial markers identifying a corresponding position of each of the plurality of fiducial markers in at least one of the plurality of 2D projection images and performing a point based algorithm based on the position of the instrument relative to the tracking coordinate system at each of the plurality of fiducial markers and the corresponding position of each of the plurality of fiducial markers in the at least one of the plurality of 2D projection images to obtain the transformation function. The fiducial markers can be known points e.g. anatomic landmarks in both the 2D projection images and the physical space. In some implementations the point based algorithm includes performing a least squares fit based on a number of the plurality of fiducial markers.

Alternatively in other implementations registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function can include identifying a surface feature of the object relative to the tracking coordinate system identifying a corresponding surface feature of the object in at least one of the plurality of 2D projection images and performing a surface matching algorithm based on the surface feature relative to the tracking coordinate system and the corresponding surface feature in the at least one of the plurality of 2D projection images to obtain the transformation function.

In yet other implementations registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function can include identifying a volume feature of the object relative to the tracking coordinate system identifying a corresponding volume feature of the object in at least one of the plurality of 2D projection images and performing a volume matching algorithm based on the volume feature relative to the tracking coordinate system and the corresponding volume feature of the object in at least one of the plurality of 2D projection images to obtain the transformation function.

In some implementations the object is subject to periodic movement. For example the object can be a patient s organ such as the patient s heart.

In response to detecting patient movement during the medical procedure the method can further include receiving a plurality of updated 2D projection images of the object at a plurality of projection angles during a third period of time and registering the plurality of updated 2D projection images relative to the tracking coordinate system to obtain an updated transformation function that defines a relationship between a coordinate system of the plurality of updated 2D projection images and the tracking coordinate system. Optionally the method can include continuously displaying the plurality of updated 2D projection images in an updated loop receiving an adjusted position of the instrument relative to the tracking coordinate system during a fourth period of time that is subsequent to the third period of time estimating an adjusted position of the instrument relative to the plurality of updated 2D projection images using the updated transformation function and displaying the estimated adjusted position of the instrument relative to the plurality of 2D projection images on the updated loop.

In other implementations registering the plurality of 2D projection images relative to the tracking coordinate system to obtain a transformation function can include creating a 3D model image of at least a portion of the object based on the plurality of 2D projection images and registering the 3D model image relative to the tracking coordinate system to obtain a transformation function that defines a relationship between a coordinate system of the 3D model image and the tracking coordinate system. In these implementations estimating an adjusted position of the instrument can include estimating an adjusted position of the instrument relative to the 3D model image using the transformation function. The method can also include continuously displaying the 3D model image in a loop and displaying the estimated adjusted position of the instrument relative to the 3D model image on the loop.

In some implementations the plurality of 2D projection images can be biplane fluoroscopic images. Additionally the plurality of projection angles can include lateral and AP projections.

Optionally the method can include detecting the position of the instrument by sensing a change in a magnetic field and determining the position of the instrument relative to the tracking coordinate system of the magnetic field.

Alternatively the method can optionally include receiving a signal from the instrument at an optical sensor and determining the position of the instrument relative to the tracking coordinate system of the optical sensor.

In the implementations discussed above the instrument can be a catheter. Additionally the medical procedure can be an interventional cardiology procedure such as a valvuloplasty an angioplasty delivery of an occlusion device a valve replacement an atrial septostomy and a Fontan procedure.

It should be understood that the above described subject matter may also be implemented as a computer controlled apparatus a computer process a computing system an article of manufacture such as a computer readable storage medium or a system.

Other systems methods features and or advantages will be or may become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems methods features and or advantages be included within this description and be protected by the accompanying claims.

Unless defined otherwise all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. Methods and materials similar or equivalent to those described herein can be used in the practice or testing of the present disclosure. As used in the specification and in the appended claims the singular forms a an the include plural referents unless the context clearly dictates otherwise. The term comprising and variations thereof as used herein is used synonymously with the term including and variations thereof and are open non limiting terms. While implementations will be described for guiding a surgical instrument during a surgical procedure such as an interventional cardiology procedure it will become evident to those skilled in the art that the implementations are not limited thereto. For example it should be understood that the implementations described herein are applicable for guiding a surgical instrument during other types of surgical procedures.

Referring now to an example image guidance system IGS is shown. The IGS can include an imaging system a guidance computing device and an instrument tracking system . The IGS can be used guide an instrument during a medical procedure performed on a patient . It should be understood that the subject patient discussed herein can be human and non human mammals of any age. The imaging system can be an x ray system an ultrasound system or other type of imaging system. The imaging system is capable of imaging or capturing recording etc. a plurality of 2D projection images of an object at a plurality of projection angles. In the implementations discussed below the projection angle of each of the 2D projection images can be different. For example the imaging system can be a biplane fluoroscopic imaging system which is capable of imaging two perpendicular image planes. Additionally the imaging system can optionally be a flat panel biplane fluoroscopic imaging system. A flat panel biplane fluoroscopic imaging system eliminates the image intensifier. A biplane fluoroscopic imaging system is capable of imaging the XZ plane i.e. a lateral view and the YZ plane i.e. an AP view . It should be understood that the image planes are not limited to the XZ and YZ planes and that the image planes can be any two or more image planes. In a biplane fluoroscopic image the Z extent along the length of the imaged object is present in both perpendicular image planes which results in a 4D image of a 3D space i.e. an over determined problem exists .

As shown in the imaging system includes x ray sources A B and corresponding x ray detectors C D for imaging the at least two image planes. For example x ray source A and corresponding x ray detector C can image the XZ plane and x ray source B and corresponding x ray detector D can image the YZ plane. Although not shown in the x ray source A and the x ray detector C as well as the x ray source B in the x ray detector D can be fixed to a C arm for example. Thus the angular position of each C arm can be varied around a bed on which the patient is supported in order to obtain images at different projection angles. The 2D projection images can be communicated from the imaging system over a communication link to the guidance computing device . This disclosure contemplates the communication link is any suitable communication link. For example a communication link may be implemented by any medium that facilitates data exchange between the imaging system and the guidance computing device including but not limited to wired wireless and optical links. It should be understood that the imaging system is not limited to a biplane fluoroscopic imaging system. For example the imaging system can be any type of imaging system capable of imaging a plurality of 2D projection images of an object at a plurality of projection angles such as a 3D echocardiography system.

The IGS can also include an instrument tracking system . In some implementations the instrument tracking system can be an EM tracking system. An EM tracking system is capable of tracking the position of the instrument relative to a tracking coordinate system using a low intensity varying EM field. As used herein the position of the instrument is the position of the instrument relative to a coordinate system or the position and orientation of the instrument relative to the coordinate system. An example EM tracking system that can be used in the implementations discussed herein is the AURORA EM TRACKING SYSTEM of NORTHERN DIGITAL INC. NDI WATERLOO ONTARIO CANADA. In other implementations the instrument tracking system can be an optical tracking system. In an optical tracking system the position of the instrument can be tracked with regard to a tracking coordinate system by detecting signals e.g. infrared light emitted or reflected from markers embedded in the instrument. As shown in the instrument tracking system can include a magnetic field generator A that is capable of producing a low intensity varying EM field C around the patient . An instrument such as a catheter for example can include one or more sensors B such as sensor coils. The sensors B can optionally be 6 degree of freedom DOF sensors or other x DOF sensors such as 5 DOF sensors for example embedded in the instrument to allow validation of position shape and orientation of the instrument. By varying the EM field C currents i.e. electrical signals are induced in the sensors B of the instrument. The characteristics of the electrical signals depend on the distance and angle between the sensors B of the instrument and the magnetic field generator A. Additionally the electrical signals can be communicated from the instrument tracking system over a communication link to the guidance computing device . As discussed above a communication link may be implemented by any medium that facilitates data exchange between the instrument tracking system and the guidance computing device including but not limited to wired wireless and optical links. Using the instrument tracking system it is possible to sense a change in the EM field with the sensors B and then determine the position of the instrument relative to a tracking coordinate system of the EM field C. It should be understood that the instrument tracking system is not limited to an EM tracking system or an optical tracking system and can be another type of system for tracking the position of the instrument.

As discussed above the plurality of 2D projection images captured by the imaging system and the electrical signals detected by the instrument tracking system are communicated to the guidance computing device . As shown in the guidance computing device includes a display unit A a processing unit B and a memory C. As discussed in detail below it is possible to program the guidance computing device to estimate the position of the instrument e.g. a catheter which is tracked using the instrument tracking system relative to the plurality of 2D projection images imaged with the imaging system and then display the estimated position of the instrument relative to the plurality of 2D projection images on the display unit A. To estimate the position of the instrument relative to the plurality of 2D projection images the tracking coordinate system and the coordinate system of the 2D projection images are correlated via a transformation function in a process known as registration. It should be understood that there are a number of known methods for performing registration between the coordinate systems. For example the 2D projection images can be registered relative to the tracking coordinate system to obtain the transformation function that defines a relationship between the 2D coordinate system of the 2D projection images and the 3D coordinate system of the tracking coordinate system e.g. 2D 3D registration using a point based algorithm. In a point based algorithm corresponding points in each of the coordinate systems are identified the identified points are registered and the transformation function is then inferred.

For example fiducial markers or anatomic landmarks e.g. known points in the 2D projection images and the physical space can be used for the registration. The position of the fiducial markers in a coordinate system of the 2D projection images can be identified based on at least one of the 2D projection images. Additionally the instrument can be manipulated moved to each of the fiducial makers in the physical space such that the position of the instrument relative to the tracking coordinate system at each of the fiducial markers is detected i.e. by the instrument tracking system . Then a closed form least squares fit based on the number of fiducial markers can be performed i.e. a Procrustes analysis to obtain the transformation function. As discussed above the transformation function defines the relationship between the coordinate system of the 2D projection images and the tracking coordinate system. When registering biplane fluoroscopic images relative to the tracking coordinate system each of the 2D projection images can be registered with the tracking coordinate system. In other words a 2D 3D registration can be performed on each of the 2D projection images and the tracking coordinate system. It should be understood that the point based algorithm discussed above is only one example algorithm and that other algorithms point based or otherwise exist. For example it is possible to obtain the transformation function using surface or volume methods which will allow for a personalized fit between the 2D dimensional projection images and the physical space without requiring additional fiducial markers or anatomic landmarks. When using surface or volume methods corresponding surface or volume features are identified in the 2D projection images and the physical space. For example a surface feature can be identified in the physical space by swabbing a surface e.g. a heart wall with the instrument that is tracked using the instrument tracking system . Then a surface matching or volume matching algorithm is used to obtain the transformation function.

Alternatively to performing 2D 3D registration between the 2D projection images and the tracking coordinate system it is possible to create a 3D model image of at least a portion of an object captured in the plurality of 2D projection images and perform 3D 3D registration between a 3D coordinate system of the 3D model image and the tracking coordinate system. It should be understood that there are a number of methods for creating the 3D model image from at least two 2D projection images captured at different projection angles. In some implementations a 3D model image of a patient s organ e.g. the heart can be constructed based on the plurality of 2D projection images such as biplane fluoroscopic images or ultrasound images. This disclosure contemplates that a 3D model image of other organs can be created and that the disclosure should not be limited to 3D model images of the patient s heart which is only one example. Similarly to the processes discussed above with regard to 2D 3D registration 3D 3D registration can be performed between the coordinate system of the 3D model image and the tracking coordinate system using point based surface based or volume based algorithms to obtain a transformation function relating the coordinate systems.

Using the IGS it is possible to reduce and in some cases eliminate radiation exposure during a medical procedure such as an interventional cardiology procedure. For example the interventional cardiology procedure can optionally include but is not limited to valvuloplasty e.g. mitral aortic pulmonary and or tricuspid valvuloplasty pulmonary artery angioplasty with without stent implantation right ventricle to pulmonary artery conduit angioplasty with without stent implantation Blalock Taussig or other surgical shunt angioplasty with without stent implantation angioplasty of aortic coarctation with without stent implantation angioplasty of systemic venous obstruction with without stent implantation delivery of atrial septal defect occlusion devices delivery of patent ductus arteriousus occlusion devices delivery of ventricular septal defect occlusion devices percutaneous valve replacement e.g. mitral aortic pulmonary and or tricuspid percutaneous valve replacement atrial transeptal puncture balloon atrial septostomy occlusion of detrimental collateral vessels e.g. systemic to pulmonary arterial vessels arteriovenous malformations veno venous collaterals percutaneous closure of Fontan fenestrations and percutaneous creation of Fontan fenestrations. The object can be imaged with the imaging system at the plurality of projection angles. The imaging system can be a fluoroscopic imaging system an ultrasound imaging system or other type of imaging system. It should be understood that the IGS according to implementations discussed herein including an imaging system using radiation e.g. a fluoroscopic imaging system can reduce radiation exposure while the IGS including an imaging system not using radiation e.g. an ultrasound imaging system can eliminate radiation exposure. The object can be subject to periodic movement. In some implementations the object is a patient s organ such as the patient s heart which is subject to periodic movement. The plurality of 2D projection images can be captured during a first period of time. The first period of time can be a fixed period of time. For example the first period of time can be approximately 3 5 seconds. It should be understood however that the first period of time can be any length of time. Optionally the 2D projection images recorded during the first period of time can be a cine loop i.e. a sequence of 2D projection images recorded during the first period of time . Optionally the first period of time can be prior to performing the medical procedure. Alternatively or additionally the plurality of 2D projection images can optionally be captured by a medical professional e.g. a surgeon using a foot pedal to operate the imaging system which provides for hands free control. Additionally in some implementations the 2D projection images can depict an actual position of the instrument relative to the patient s body during the first period of time.

As discussed above prolonged radiation exposure during a medical procedure such as a cardiac catheterization especially in children can have long term negative effects. For example the fluoroscopy time during a simple cardiac procedure is typically about 5 minutes while the fluoroscopy time during an interventional cardiac procedure is typically about 20 minutes. However using the IGS it is possible to reduce exposure to radiation by estimating and displaying the position of the instrument relative to the 2D projection images which were captured during the first period of time. The first period of time can be substantially less than typical fluoroscopic imaging times during conventional procedures. In some implementations the plurality of 2D projection images can be displayed continuously in a loop. In other words the plurality of 2D projection images captured during the first period of time e.g. a 3 5 second period can be continuously replayed during the medical procedure without exposing the patient to additional radiation. The adjusted position of the instrument can be tracked during the medical procedure relative to the tracking coordinate system using the instrument tracking system . The adjusted position of the instrument can then be tracked during the medical procedure in a second period of time that is subsequent to the first period of time. Then using the previously obtained transformation function the adjusted position of the instrument relative to the 2D projection images can be estimated. Optionally the estimated adjusted position of the instrument relative to the 2D projection images can be displayed for example on the loop.

The instrument can be navigated during the medical procedure using the IGS because the plurality of 2D projection images captured during the first time period and displayed continuously in a loop serve as a dynamic anatomical roadmap. Additionally because the patient lies motionless during the medical procedure such as an interventional cardiac procedure the accuracy of repeating the loop as an anatomic map is preserved. Further even if unexpected patient motion occurs a plurality of updated 2D projection images of the object at a plurality of projection angles can be recorded using the imaging system . The updated 2D projection images can be recorded during a third period of time for example which can be substantially less than typical fluoroscopic imaging times during conventional procedures e.g. 3 5 seconds . Then in accordance with the processes discussed above the updated 2D projection images can be registered relative to the tracking coordinate system to obtain an updated transformation function. Thereafter the adjusted position of the instrument during a fourth period of time subsequent to the third period of time can be estimated using the updated transformation function and displayed relative to the updated 2D projection images which are continuously displayed in a loop. Thus using the IGS the patient is exposed to a fraction of the radiation the patient would have been exposed to during a conventional medical procedure when the IGS includes an imaging system using radiation and the patient is not exposed to radiation when the IGS includes an imaging system that does not use radiation.

Referring now to example images illustrating instrument positions are shown. is an image illustrating a position of the instrument e.g. a catheter on a fluoroscopic loop . As discussed above the position of the instrument is tracked using the instrument tracking system . Using the transformation function it is possible to estimate the position of the instrument relative to the plurality of 2D projection images e.g. a fluoroscopic loop . The position of the instrument can then be displayed on the fluoroscopic loop . Additionally is an image illustrating the position of the instrument e.g. a catheter on a 3D echocardiogram . Unlike static reference images the fluoroscopic loop and the 3D echocardiogram can act as dynamic anatomic roadmaps for performing image guided surgery.

Conventionally instrument tracking systems e.g. KNIFE typically provide for tracking and display of the tip of an instrument e.g. a catheter during the medical procedure. In other words a sensor e.g. sensor B of that is tracked by the instrument tracking system e.g. instrument tracking system of is provided only in the tip of the catheter. It should be understood that a catheter is provided only as one example of the instrument and that the instrument should not be limited to a catheter. However because the catheter can bend at one or more points along its extent the exact shape and pose of the catheter cannot be determined using the instrument tracking system alone. Instead a medical imaging technique such as fluoroscopy is used to display the shape and pose of the catheter which allows for easier navigation during the medical procedure. Using fluoroscopy to guide the catheter however increases the patient s exposure to radiation. This is undesirable in a number of circumstances.

As described above the instrument e.g. a catheter can include one or more sensors e.g. sensors B in that can be tracked using an instrument tracking system e.g. instrument tracking system in . Thus in some implementations the instrument can optionally include a plurality of sensors arranged along the extent of the instrument. For example when the instrument is a catheter the sensors can be provided along the entire extent of the catheter as opposed to only at a tip of the catheter for example at varying intervals along the extent of the catheter. This disclosure contemplates that the number of sensors can be selected to allow the shape and pose of the catheter to be estimated in addition to tracking the position of the catheter during the medical procedure while minimizing the number of sensors. By providing catheter shape and pose information for example in the form of an overlay on the 2D projection images e.g. the fluoroscopic loop it is possible to provide the clinician with the benefits of fluoroscopic catheter guidance but without exposing the patient to additional radiation. is an example of a catheter shape rendering estimated by tracking a plurality of sensors in the catheter with an image tracking system.

By tracking the position of a plurality of sensors in the catheter using the instrument tracking system the shape and pose of the catheter can be estimated during the medical procedure. By estimating the shape and pose of the catheter it is possible to display the shape of the catheter as well as the direction and angle of the catheter tip during the medical procedure. It should be understood that the location of each of the plurality of sensors within the catheter is known. Additionally images e.g. x ray images of the catheter can be captured. By comparing the shape of the catheter captured in the images and the tracked positions of each of the plurality of sensors an algorithm for estimating the shape and pose of the catheter can be determined. Alternatively or additionally 2D directional vectors of the catheter can be determined using the tracked position and orientation of each of the plurality of sensors of the catheter. This information can be used to allow a clinician to guide the catheter during the medical procedure using an overlay of the directional information on an image e.g. an x ray or an ultrasound image even using a single plane fluoroscopy image.

It should be appreciated that the logical operations described herein with respect to the various figures may be implemented 1 as a sequence of computer implemented acts or program modules i.e. software running on a computing device 2 as interconnected machine logic circuits or circuit modules i.e. hardware within the computing device and or 3 a combination of software and hardware of the computing device. Thus the logical operations discussed herein are not limited to any specific combination of hardware and software. The implementation is a matter of choice dependent on the performance and other requirements of the computing device. Accordingly the logical operations described herein are referred to variously as operations structural devices acts or modules. These operations structural devices acts and modules may be implemented in software in firmware in special purpose digital logic and any combination thereof. It should also be appreciated that more or fewer operations may be performed than shown in the figures and described herein. These operations may also be performed in a different order than those described herein.

Referring now to a flow diagram illustrating example operations for guiding an instrument using the image guidance system of is shown. At a plurality of 2D projection images of an object at a plurality of projection angles can be received. For example the 2D projection images can be captured by the imaging system and communicated to the guidance computing device as discussed above. In some implementations the 2D projection images are captured during a first period of time which can be substantially less than typical fluoroscopic imaging times during conventional procedures. At a position of the instrument relative to a tracking coordinate system is received. The position of the instrument can be detected by the instrument tracking system and communicated to the guidance computing device as discussed above. Then at the plurality of 2D projection images can be registered relative to the tracking coordinate system to obtain a transformation function that defines a relationship between a coordinate system of the plurality of 2D projection images and the tracking coordinate system. It should be understood that there are a number of algorithms for registering the coordinate systems. After obtaining the transformation function an adjusted position of the instrument relative to the tracking coordinate system is received at . The adjusted position of the instrument can be received during a second period of time that is subsequent to the first period. At an adjusted position of the instrument relative to the plurality of 2D projection images can be estimated using the transformation function. Optionally at the plurality of 2D projection images can be continuously displayed in a loop. For example the 2D projection images can be captured during the first period of time e.g. a 3 5 second period and continuously replayed displayed in a loop. Thereafter the estimated adjusted position of the instrument relative to the plurality of 2D projection images can be displayed on the loop at to guide the surgery.

When the logical operations described herein are implemented in software the process may execute on any type of computing architecture or platform. For example referring to an example computing device upon which embodiments of the invention may be implemented is illustrated. In particular the computing device and or the guidance computing device discussed above may be a computing device such as computing device shown in . The computing device may include a bus or other communication mechanism for communicating information among various components of the computing device . In its most basic configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as random access memory RAM non volatile such as read only memory ROM flash memory etc. or some combination of the two. This most basic configuration is illustrated in by dashed line . The processing unit may be a standard programmable processor that performs arithmetic and logic operations necessary for operation of the computing device .

Computing device may have additional features functionality. For example computing device may include additional storage such as removable storage and non removable storage including but not limited to magnetic or optical disks or tapes. Computing device may also contain network connection s that allow the device to communicate with other devices. Computing device may also have input device s such as a keyboard mouse touch screen etc. Output device s such as a display speakers printer etc. may also be included. The additional devices may be connected to the bus in order to facilitate communication of data among the components of the computing device . All these devices are well known in the art and need not be discussed at length here.

The processing unit may be configured to execute program code encoded in tangible computer readable media or non transitory computer readable media . Computer readable media refers to any media that is capable of providing data that causes the computing device i.e. a machine to operate in a particular fashion. Various computer readable media may be utilized to provide instructions to the processing unit for execution. Common forms of computer readable media include for example magnetic media optical media physical media memory chips or cartridges a carrier wave or any other medium from which a computer can read. Example computer readable media may include but is not limited to volatile media non volatile media and transmission media. Volatile and non volatile media may be implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data and common forms are discussed in detail below. Transmission media may include coaxial cables copper wires and or fiber optic cables as well as acoustic or light waves such as those generated during radio wave and infra red data communication. Example tangible computer readable recording media include but are not limited to an integrated circuit e.g. field programmable gate array or application specific IC a hard disk an optical disk a magneto optical disk a floppy disk a magnetic tape a holographic storage medium a solid state device RAM ROM electrically erasable program read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices.

In an example implementation the processing unit may execute program code stored in the system memory . For example the bus may carry data to the system memory from which the processing unit receives and executes instructions. The data received by the system memory may optionally be stored on the removable storage or the non removable storage before or after execution by the processing unit .

Computing device typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by device and includes both volatile and non volatile media removable and non removable media. Computer storage media include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media include but are not limited to RAM ROM electrically erasable program read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of computing device .

It should be understood that the various techniques described herein may be implemented in connection with hardware or software or where appropriate with a combination thereof. Thus the methods and apparatuses of the presently disclosed subject matter or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computing device the machine becomes an apparatus for practicing the presently disclosed subject matter. In the case of program code execution on programmable computers the computing device generally includes a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. One or more programs may implement or utilize the processes described in connection with the presently disclosed subject matter e.g. through the use of an application programming interface API reusable controls or the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s can be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and it may be combined with hardware implementations.

Intrinsic parameters of a fluoroscope e.g. principal point u0 v0 and focal length f can be estimated using an automated calibration technique. The example automated calibration technique described herein used fluoroscopic images of a 3D grid phantom built with known geometric constraints. For example the 3D grid phantom was constructed through the layering of several 10 cm 10 cm 0.3 cm acrylic sheets each sheet containing a different hole pattern cut by a laser milling machine i.e. VERSALASER 2.30 145 from UNIVERSAL LASER SYSTEMS INC. of SCOTTSDALE Ariz. . Lead BBs were placed in the holes at each layer to serve as markers for the calibration. Overall the design generated a 3D phantom with markers at varying locations in all three planes allowing for constrained volumetric marker capture of the fluoroscopic imaging volume. The phantom was imaged using a TOSHIBA BI PLANE INFINIX I SERIES fluoroscope with solid state detectors from TOSHIBA INC. of TAWARA SHI TOCHIGI KEN JAPAN and a ZIEHM IMAGING II C ARM from ZIEHM IMAGING of ORLANDO Fla. The fluoroscopic images were captured with the 3D phantom oriented to face the x ray source in both the anterior posterior AP and lateral LR planes for the bi plane fluoroscope. Position of the 3D phantom relative to the x ray source and detector were recorded along with the captured fluoroscopic images.

The example automated calibration of the fluoroscope used the captured fluoroscopic images recorded distances and the geometric design of the 3D phantom. is the original fluoroscopic image. Because each marker e.g. lead BB completely attenuates the x ray beam the markers are represented as dark circles on the captured image in . A binary mask was then created using a threshold value 5 lower than the maximum pixel value of the markers in . The binary mask is shown in . Connected component labeling was then used for the detections of the individual markers in the fluoroscopic image and the gray weighted centroid of each located marker was calculated. illustrates the connected component labels of the markers in . Each marker was then assigned a location identifier A F based on its location in the 3D phantom which is shown in . The location identifiers were assigned based on the calculated neighbor count of each marker as well the location identifier of those neighbors. Different colors were applied to signify different location assignments in . In other words the color assigned to marker A is different than the color assigned to each of markers B C D E and F. Additionally each centroid location was then given a depth A G based on the assigned location identifiers and the recorded distance from the x ray source which is shown in . Similar to different colors were applied to signify different depths in . In other words the color assigned to marker A is different than the color assigned to each of markers B C D E F and G.

In Eqns. 1 and 2 u v is the image point in pixels and X Y Z is the camera point in millimeters. Since the true values for X and Y are unknown for each point relative distances from other points can be used in determining the principal point u0 v0 and focal length f of the fluoroscope.

Assuming the marker in the top left corner of the 3D phantom to be the origin distances for each marker from the origin were found. Utilizing the calculated distances from the origin Dx and Dy in the x and y direction respectively the following sets of equations were used to find the fluoroscopic parameters using a multivariate linear regression in which the equation for each marker origin pair was used.

Eqns. 3 and 4 were used to find the location of an adjacent point in both the x and y axes respectively. Locations of points can also be found using Eqns. 5 and 6 . By substituting Eqns. 5 and 6 into Eqns. 3 and 4 a general form to calculate the unknown intrinsic parameters of the fluoroscope can be derived. 7 8 

Eqns. 7 and 8 were populated and used in the multivariate linear regression to find the maximum likelihood estimation of the fluoroscopic intrinsic parameters.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

