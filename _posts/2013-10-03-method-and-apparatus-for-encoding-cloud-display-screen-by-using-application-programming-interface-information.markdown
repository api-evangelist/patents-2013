---

title: Method and apparatus for encoding cloud display screen by using application programming interface information
abstract: A method and apparatus for implementing cloud computing by efficiently encoding a display screen between a cloud server and a client terminal. The method for encoding a cloud display screen in the cloud server, includes: acquiring region information of currently generated windows based on an application programming interface (API) function information of an Operating System (OS); extracting relative depth information between each of the currently generated windows from the OS; generating an encoding mode map in which an entire screen is divided into a plurality of blocks, based on the acquired region information and the extracted relative depth information; and encoding each of the plurality of blocks based on the generated encoding mode map.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09053526&OS=09053526&RS=09053526
owner: SAMSUNG ELECTRONICS CO., LTD.
number: 09053526
owner_city: 
owner_country: KR
publication_date: 20131003
---
This application claims the benefit of Korean Patent Application No. 10 2012 0110837 filed on Oct. 5 2012 in the Korean Intellectual Property Office the disclosure of which is incorporated herein in its entirety by reference.

Exemplary embodiments relate to techniques of encoding a screen and transmitting the encoded screen to a terminal in a server constituting a cloud system. More particularly exemplary embodiments relate to techniques of analyzing a region of a window displayed on a screen by using application programming interface API information processed by a kernel or Operating System OS and also encoding the screen by using depth information of the window.

Data encoding methods of the related art may be classified into lossy encoding methods and lossless encoding methods. When a region such as a text an icon etc. having a feature in which even a slight deterioration in image quality is conspicuous is compressed lossless encoding methods are generally preferred. When a region such as a photograph a moving picture etc. in which a pixel structure is complicated is compressed lossy encoding methods are preferred because a data loss is not conspicuous even though data may be lost.

However when a compound image including both a graphic element a text an icon a figure etc. and an image element a photograph a moving picture etc. is encoded in the related art the compound image is usually encoded using one algorithm. For example a moving picture or photographic image encoding algorithm such as H.264 MPEG 2 or JPEG or a graphic element suitable encoding algorithm may be uniformly applied. In addition when individual regions of a compound image are selectively encoded the compound image may be analyzed and encoding algorithms suitable for regions may be selectively applied according to the analysis result. In this case an image analyzing process is mandatory. For image analysis low level image processing is representatively used. A low level image processing technique of the related art analyzes a screen using statistical characteristic information of pixels and planarization or a gradient level of an image which are obtained by using pixel values acquired by scanning a region to be encoded.

In a related art cloud system a control signal input from a client terminal is processed by a server and a processing result is displayed on a screen of the client terminal. In many cases the client terminal does not have a separate Central Processing Unit CPU or a rendering tool. In this case the server encodes an image to be displayed and transmits the encoded image to the client terminal. However a cloud display screen is usually provided with a compound image including a text a graphic an image a moving picture etc.

If an encoding method of the related art is used for the cloud display screen regardless of image characteristics the encoding method may not be suitable. For example it is assumed that a documentation work is performed using a cloud terminal. When an image analysis is applied to a cloud display screen on which the documentation work is being performed text has a high probability to be analyzed as a text region because the text has a large pixel value difference. However if a related art image encoding algorithm is used image quality may be significantly deteriorated and readability of the text may decrease to a level at which it is difficult to perform the documentation work. Thus it is very important to apply an encoding algorithm suitable for each region by using an image analysis. However the low level image processing technique of the related art always has a false alarm probability and a missing alarm probability in region identification.

Exemplary embodiments may provide methods and apparatuses for efficiently encoding a cloud display screen according to characteristics of region information constituting the cloud display screen and transmitting the encoded data to a cloud terminal in a cloud server and decoding the encoded data and displaying the decoded data in the cloud terminal.

According to an aspect of the exemplary embodiments there is provided a method for encoding a cloud display screen in a cloud server including acquiring region information of currently generated windows based on an application programming interface API function information of an Operating System OS extracting relative depth information between each of the currently generated windows from the OS dividing an entire screen to a plurality of blocks based on the acquired region information and the extracted relative depth information and generating an encoding mode map in which an encoding mode is allocated to each of the plurality of blocks and encoding each of the plurality of blocks based on the generated encoding mode map.

The acquiring the region information may include designating an identifier to each of the currently generated windows and storing the region information of the currently generated windows corresponding to the identifiers. If at least one of the currently generated windows is finished the region information corresponding to the identifier of the at least one finished window may be deleted. The identifier may be a window handle.

The generating the encoding mode map may include determining an encoding algorithm to be applied to each of the plurality of blocks based on the acquired region information included in each of the blocks or if a plurality of pieces of region information are included in each of the plurality of blocks determining an encoding algorithm to be applied to each of the blocks based on a proportion of the plurality of pieces of region information constituting each of the blocks or determining an encoding algorithm to be applied to each of the blocks according to preset priorities of encoding algorithms corresponding to the plurality of pieces of region information included in each of the blocks.

The encoding each of the plurality of blocks may include encoding each of the plurality of blocks in an encoding method suitable for an encoding mode designated to each block according to a raster scan order.

According to another aspect of the exemplary embodiments there is provided a cloud server for encoding a cloud display screen including a region information acquisition device which acquires region information of currently generated windows based on an application programming interface API function information of an Operating System OS a depth information extractor which extracts relative depth information between each of the currently generated windows from the OS a screen region determiner which generates an encoding mode map in which an entire screen is divided into a plurality of blocks based on the acquired region information and the extracted relative depth information and an encoder which encodes each of the plurality of blocks based on the generated encoding mode map.

The region information acquisition device may designate an identifier to each of the currently generated windows and include a region storage unit which stores the region information of the currently generated windows corresponding to the identifiers. If at least one of the currently generated windows is finished the region information corresponding to the identifier of the finished window may be deleted.

The screen region determiner may determine an encoding algorithm to be applied to each of the plurality of blocks based on the acquired region information included in each of the blocks or determine an encoding algorithm to be applied to each of the plurality of blocks based on depth information included in the block or if a plurality of pieces of region information are included in each of the plurality of blocks determine an encoding algorithm to be applied to each of the blocks based on a proportion of the plurality of pieces of region information constituting each of the blocks or determine an encoding algorithm to be applied to each of the blocks according to preset priorities of encoding algorithms corresponding to the plurality of pieces of region information included in each of the blocks.

According to another aspect of the exemplary embodiments there is provided a cloud terminal for decoding a cloud display screen including a communication device which receives an encoded cloud display screen stream from a cloud server and a decoder which decodes the encoded cloud display screen stream wherein the encoded cloud display screen stream includes data encoded by an encoding algorithm which is selectively applied to a plurality of block units divided from the encoded cloud display screen.

The decoder may decode the encoded cloud display screen stream using a decoding algorithm corresponding to the encoding algorithm.

According to another aspect of the exemplary embodiments there is provided a method for encoding a cloud display screen in a cloud server including acquiring region information of a plurality of windows in units of identifiers based on an application programming interface API function information of an operating system OS acquiring relative depth information between the windows in the units of identifiers from the OS determining characteristics of a plurality of screen regions based on the acquired relative depth information and the acquired region information and encoding the cloud display screen based on the determined characteristics of the screen regions.

As used herein expressions such as at least one of when preceding a list of elements modify the entire list of elements and do not modify the individual elements of the list.

Thus the client terminal does not generally need a unit for performing separate computations. In other words like a computer monitor the client terminal may be formed by including only the least number of components required to display a computation result. Of course the client terminal may include a user input interface and a communication unit for generating and transmitting a control signal.

Several devices shown in e.g. the smart phone and the tablet PC include an internal computation processing device i.e. a processor. However these devices may not consume system resources of the processor at all or may rely on a cloud server for computation processing while using the system resources of the processor for another use. Devices having a communication unit and a display processing capability may function as a client terminal according to the exemplary embodiments.

Client terminals are classified into thin clients and zero clients. A classification criterion used depends on whether a client terminal includes computation processing capability or a rendering tool. This classification or naming may be changed in the future without limit according to the development of technology and a trend of the industry. A method suggested in the exemplary embodiments is particularly useful for zero client terminals not having a separate rendering tool. Of course the method suggested in the exemplary embodiments may be applied to other types of client terminals in terms of efficiency of system resources.

A user using the cloud system does not recognize that a client terminal has only a display device and an input device and computations related to an input of the user are processed by the cloud server . In other words the cloud system should process an input of the user such that the user does not recognize that the client terminal has only the display device and the input device and computations related to the input of the user are processed by the cloud server . Therefore the cloud system must satisfy a real time requirement that a computation result according to the input of the user is displayed in real time and must satisfy an image quality requirement that the user can easily recognize the displayed result.

However when a cloud display screen is encoded to provide sufficient readability a time consumed to perceive characteristics of the cloud display screen and encode the cloud display screen increases. In addition a time taken to transmit such generated screen information to a client terminal and decode the received screen information in the client terminal also increases. Thus the cloud system must satisfy the real time requirement.

When the cloud display screen is encoded to satisfy the real time requirement resolution may be lowered too much or readability may be lowered by applying an algorithm used for encoding an image or a moving picture to a region including a text. Thus the image quality requirement may be not satisfied.

In other words a method for encoding the cloud display screen is required to encode a screen to meet characteristics of regions constituting the cloud display screen and satisfy the real time processing result without image quality deterioration to a level which the user can detect. In particular the method must be able to be applied to a case where a screen is restored by using only a decoder corresponding to an encoder used in a server without a high level rendering function.

Although one cloud server and one client terminal are shown in a plurality of terminals may be connected to the cloud server . In addition if necessary the cloud server may process computations by being connected to another server an external data storage device etc.

The cloud server includes a controller an encoder a storage unit and a communication unit . The controller controls components constituting the cloud server and performs a function of processing a general work. In general the controller performs computations required according to a control signal received from the client terminal via the communication unit . Although the communication unit is shown as a single component the communication unit may include a receiver and a transmitter.

A computation result processed by the controller is encoded by the encoder to be suitable for display by the client terminal . In the specification a cloud display screen indicates a computation result before it is encoded. In other words an image obtained by decoding an encoded cloud display screen is displayed by the client terminal . It will be understood that the cloud display screen is the computation result before it is encoded which is displayed on a predetermined display device.

The client terminal may include a controller a decoder a communication unit an input interface and a display device . Although it is shown in that the input interface and the display device are externally connected to the client terminal the input interface and the display device may be formed in one body together with the client terminal e.g. a device such as a tablet PC.

The controller of the client terminal is different from the controller of the cloud server . The controller of the client terminal does not have to include a processor for performing computations. In other words the controller of the client terminal may perform only a function of controlling the decoder to decode an encoded cloud display screen received via the communication unit so that the decoded cloud display screen is displayed on the display device .

As a reference the OS used in the exemplary embodiments may provide an application programming interface API required to operate an application program executed by a corresponding client terminal. In other words examples of the OS may be the Windows series of Microsoft Linux Mac OS and iOS of Apple Bada OS of Samsung Android of Google Symbian of Nokia etc. In other words the API indicates an interface for controlling functions provided by the OS i.e. an interface for providing various functions such as a file control function a window control function an image processing function a character control function and a communication function control function. The API includes various functions to produce various applications using functions provided by the OS.

Referring to the cloud display screen includes a task bar a first window a second window and icons . It is assumed that the first window is generated by a PowerPoint application program and the second window is generated by an Internet application program.

As described above each application program outputs an output matter of the application program on a specific window and windows are displayed on a screen by overlapping each other. In other words a portion of the second window is hidden by the first window according to the overlapping. A portion of a basic background screen is also hidden by the first and second windows and .

Each application program uses an API function to output a processing result on a window allocated. For example the first window includes a title display bar region a menu icon region including menu icons a slide image region for showing slide thumbnails on the left side of the first window a contents region for outputting main content of a corresponding slide on the right side of the first window and a script region for showing a script of the corresponding slide. If it is assumed that the OS is Windows Windows uses an API function for outputting a text such as DrawText to output the text in the title display bar region or the script region . In other words by monitoring a text output function such as DrawText a location in the first window to which the text is output can be perceived.

To output a bitmap the OS may use an API function such as BltBlt. By monitoring the API function such as BltBlt a location in the first window to which the bitmap is output can be perceived. For example information that the bitmap is output to a specific part of the contents region of the first window may be acquired.

To set a window for outputting video in a video play program such as Media Player a function such as IvideoWindow put Owner or IMFVideoDisplayControl SetVideoWindow is used. By monitoring the function information regarding a window region in which the video is to be displayed may be obtained. Further an application program uses a function such as ImediaControl Run or IMFClockStateSink OnClockStart to play the video and uses a function such as ImediaControl Stop or IMFClockStateSink OnClockStop to stop the play of the video. By monitoring these functions information regarding a state of a video region may also be acquired. The state information may also be used to determine information regarding regions included in the window. In other words for a region set to output video if the present video is in a stop state instead of a play state the region may be determined as an image region instead of a video region.

Referring back to the first window the title display bar region and the script region of the first window may be determined as a text region and the menu icon region may be determined as an image region. In addition the slide image region may be compositively formed by a text region a graphic region excluding a text and an image region according to the contents output and the contents region may be compositively formed by a text region a graphic region excluding a text an image region and a video region according to the contents output.

The above description related to the first window is very simplified when compared with a window generated by an actual application program. For example when an API function is traced only a portion of the left side of the title display bar region may be determined as a text region. The menu icon region may be determined as a text region in which a name of each menu is shown and an image region in which menu icons are shown. Likewise the other parts forming the first window may also be more concretely determined. In other words information regarding regions forming a window acquired from API information related to the window generated by an actual application program i.e. region information of the window may include much more complicated and various regions than those shown in .

Furthermore a text region a graphic region excluding a text an image region and a video region are only illustrated for classifying regions. For example for the slide image region a portion in which images are actually shown is only rectangular regions and a region excluding the rectangular regions is filled with a background graphic. This region may be separately classified into for example a graphic region. Likewise a graphic a picture image an animation and so forth may also be applied to a wallpaper region.

Referring to the second window the second window is generated by a web browser application. Various pieces of content may be included in the second window . When an API function related to the second window is traced region information of the second window may be acquired as performed in the first window . However a portion of the second window is hidden by the first window and is not displayed. In other words to finally determine window region information of a cloud display screen displayed on the client terminal information regarding a relationship between windows overlapping each other is necessary. Information regarding the relationship between windows overlapping is depth information and will be described below.

The region information acquisition unit determines a characteristic of a corresponding region from API information generated from a window of each of the individual application programs and extracts information regarding windows displayed on the whole screen and information regarding regions belonging to each of the windows i.e. region information of each window which are collected through the regional characteristic determining process. In other words when an individual application program outputs a text in a specific region of a window using an API the specific region is determined as a text region based on this information. When an individual application program outputs a photograph or picture in a specific region of a window by using an API the specific region is determined as a picture region. When an individual application program plays video in a specific region of a window by using an API the specific region is determined as a video region. According to this process regions of all windows displayed on the whole screen are determined and the entire window information information regarding all regions belonging to each window and relationship information indicating which region information belongs to which window are stored. In other words information regarding regions forming each window is acquired by designating an identifier corresponding to the window and collecting and storing region information corresponding to the identifier. A detailed description of the identifier will be made below.

The depth information extractor extracts relative depth information between the windows and . For example if one window is displayed on a screen and a portion or all of another window is hidden by the window located at the front by overlapping the two windows have different depths. The depths of the two windows are set by starting from a window displayed on the forefront of the screen. In other words a window located at the rear is considered to be located at a relatively deeper place than the window displayed on the forefront of the screen. If two windows are displayed without overlapping each other both the two windows have the same depth information and are located at the forefront of a screen. The depth information extractor extracts depth information between windows displayed on a screen from among application programs being currently executed by the OS. In this case the depth information extractor may also extract coordinate information of each window. If a plurality of windows are generated by a single application program the plurality of windows are individually processed. Since the OS should have information regarding depths between windows to display the windows by overlapping each other the depth information extractor may acquire depth information by a method such as transmitting a specific function or command to the OS and acquiring a predetermined return value.

The whole cloud display screen is divided into a plurality of blocks. In the whole cloud display screen is divided into 16 16 i.e. 256 blocks. The number of divisions and a division method may be freely changed according to a resolution of a display device or a system performance. For example a screen may be divided into 128 128 i.e. 16384 blocks or 12 4 3 or 144 16 9 blocks in consideration of a display device having a resolution of 16 9. Of course the screen may be divided into an arbitrary number of blocks regardless of the resolution. In addition sizes of the blocks may be all the same or different from each other.

A shaded block among the divided blocks indicates a block filled with a region having one characteristic. For example the text region of the window located at the front is distributed in a region corresponding to a portion or total of 44 11 4 blocks. Only 18 shaded blocks of the 44 11 4 blocks are fully filled with a text region. In the same manner 4 blocks of the image region of the front window and 24 blocks of the video region of the front window are filled with only a video region. Similar to the shaded blocks when one block is filled with a region having one characteristic an encoding mode suitable for the characteristic of the region included in the block may be allocated to the block. For example encoding modes e.g. a text mode to a block fully filled with a text region an image mode to a block fully filled with an image region and a video mode to a block fully filled with a video region may be allocated to the blocks. This description may be applied to blocks belonging to the window located at the rear.

However one block may be not fully filled with one regional characteristic or may include two or more regional characteristics. For example a block includes an image region in only a portion and a block includes a text region and an image region in a portion. A method for encoding such a divided block may be determined according to how much of the divided block includes regions having different characteristics. For example an encoding mode may be determined based on which region is mostly included in a block. If a text region is mostly included in a specific block it is determined that the specific block is encoded in the text mode. The encoder may use a method including an encoding algorithm corresponding to the text mode e.g. a variable length encoding algorithm such as a run length encoding algorithm or a Huffman coding algorithm. Of course even for the text mode encoding may be performed using a lossy algorithm according to settings. As another example an encoding mode may be allocated to a block based on a region requiring an encoding mode having the least loss ratio from among characteristics of regions included in the block. In other words when a block includes text image and video regions even though the video region is distributed with the highest ratio it may be difficult to recognize a text by encoding the block in the video mode. In this case the block may be encoded in the text mode. The examples described above are merely examples in which an encoding mode is allocated to a block and the encoding modes described above may be allocated to individual blocks according to various criteria. For example when a block includes a plurality of regions an encoding mode such as the image mode or a graphic mode may also be uniformly allocated to the block.

The screen region determiner determines regional characteristics of the whole cloud display screen by using the depth information extracted by the depth information extractor and the region information acquired by the region information acquisition unit and generates an encoding mode map of block units so that the encoder improves a compression efficiency by reflecting the regional characteristics. If regions having a specific window identifier are all displayed regions having regard to the depth information the regions are determined according to a characteristic stored in region information of a corresponding window. However if the whole specific window is hidden by another window region information having an identifier of the specific window is ignored. If a portion of a region included in a specific window is hidden region information corresponding to a partially displayed portion is determined as a characteristic of the region.

After determining characteristics of all the screen regions an encoding mode map for screen encoding is generated in operation . The encoding mode map is a map in which regional characteristics are redefined in a predefined block unit e.g. 16 16 . If one block includes a plurality of regional characteristics an encoding mode is allocated to the block according to a predefined criterion. Other undetermined regions are encoded in a basic encoding mode predetermined by the encoder . For example the predetermined basic encoding mode may be allocated to regions of which characteristics are not determined in correspondence with the API. In operation the encoder encodes each block using an encoding algorithm corresponding to an encoding mode allocated to the block.

In other words in operation the encoder encodes each block using an encoding algorithm predefined according to an encoding mode allocated to the block in a raster scan order by using the encoding mode map generated by the screen region determiner . In other words all the screen regions are encoded using an encoding algorithm suitable for a text when the text mode is allocated an encoding algorithm suitable for a photograph region when a photograph mode is allocated an encoding algorithm suitable for a graphic when the graphic mode is allocated and an encoding algorithm suitable for a video when the video mode is allocated.

The controller may designate a corresponding identifier corresponding to a window to which region information of each individual application program belongs to the region information collected from the individual application program and collect and store region information corresponding to the corresponding identifier. In other words region information corresponding to a specific identifier is collected and stored as one group. Each group is identified by a window identifier. For example if a work window of an application program such as a word processor includes a picture region A and a text region B and an identifier of 0xFC909090 is designated to the work window the window having the identifier of 0xFC909090 includes the picture region A and the text region B. In a system coordinates and characteristic information of corresponding regions are stored and the contents indicating information included in the identifier of 0xFC909090 are recorded. If the OS is Windows by Microsoft a window handle designated by the system may be an identifier. A specific application program may have a plurality of windows and the number of windows may vary according to circumstances. When a plurality of windows exist a unique identifier is allocated to each window. Region information is classified based on an identifier of a window to which the region information belongs.

The region management unit manages region information stored in the system when an individual application program ends or newly starts. In other words when an application program newly starts an identifier of a newly generated window is set and a memory space for storing region information generated by the application program is secured. On the contrary if an application program or window being executed is finished region information stored based on an identifier corresponding to the finished window is deleted and a corresponding memory space is returned to the system.

Although the encoding mode map including 36 6 6 blocks is shown in the number of blocks and types of regions may be changed. In addition even for the same image regions encoding modes such as I1 I2 and I3 may be set for the image regions by segmenting the image regions to apply different compression algorithms having different loss ratios.

Once the cloud display screen is encoded based on the encoding mode map the encoded cloud display screen is transmitted to the client terminal in the form of a Transport Stream TS . In this case in the TS information regarding encoding modes of corresponding data may be included in a header and others forming the TS. The client terminal analyzes the received TS and displays a restored cloud display screen by applying decoding algorithms corresponding to the encoding modes to corresponding blocks. In this case the decoding may be performed in an order from a block on the left topmost corner to a block on the right bottommost corner as in a raster scan order. By applying this ordering method the client terminal may restore a cloud display screen thereon by sequentially restoring all regions from a region corresponding to the block on the left topmost corner even without a separate rendering tool.

According to the exemplary embodiments a cloud system classifies characteristics of regions in a screen at a high speed and encodes the screen according to the characteristics without performing a complex calculation of low level image processing. Accordingly a delay time and a compression efficiency are improved in communication between a server and a client to thereby provide a smooth cloud computing service supporting a graphic user interface GUI .

In addition a client terminal may efficiently restore a cloud display screen based on API information without including any separate rendering tool.

The block diagrams disclosed in the exemplary embodiments may be analyzed by one of ordinary skill in the art such that a circuit for implementing the principles of the exemplary embodiments is conceptually expressed. Similarly it may be understood by one of ordinary skill in the art that arbitrary flowcharts flow diagrams state transition diagrams and pseudo codes are substantially represented in a computer readable recording medium and indicate various processes that can be executed in a computer or processor regardless of whether the computer or processor is explicitly shown. Thus the embodiments can be written as computer programs and can be implemented in general use digital computers that execute the programs using a computer readable recording medium. Examples of the computer readable recording medium include storage media such as magnetic storage media e.g. ROM floppy disks hard disks etc. and optical recording media e.g. CD ROMs or DVDs .

Functions of various elements shown in the drawings may be provided by using not only software executable hardware in association with proper software but also exclusively hardware. When the functions are provided by a processor the functions may be provided by a single exclusive processor a single shared processor or a plurality of individual processors some of which can be shared. In addition the explicit use of the term processor or controller should not be analyzed as exclusively indicating software executable hardware and may implicitly include Digital Signal Processor DSP hardware a Read Only Memory ROM for storing software a Random Access Memory RAM and a non volatile storage device without any limitation.

In the claims of the specification an element expressed as a means for performing a specific function includes an arbitrary method for performing the specific function and this element may include an arbitrary format of software including firmware microcode etc. which are combined with a set of circuit elements for performing the specific function or a circuit suitable to perform software for performing the specific function.

In the specification an embodiment of the principles of the exemplary embodiments and various modifications of this expression indicate that a specific feature structure and characteristic related to the embodiment are included in at least one embodiment of the principles of the exemplary embodiments. Thus the expression in an embodiment and arbitrary other modifications disclosed in the entire specification do not necessarily indicate the same embodiment.

In the specification in a case of at least one of A and B the expression at least one of is used to include the selection of the first option A the selection of the second option B or the selection of the both options A and B. In addition a case of at least one of A B and C may include the selection of the first option A the selection of the second option B the selection of the third option C the selection of the first and second options A and B the selection of the second and third options B and C or the selection of the three options A B and C. Even when more options are listed this may be clearly extended and analyzed by one of ordinary skill in the art.

Exemplary embodiments have been particularly shown and described with reference to exemplary embodiments. All the embodiments and conditional examples disclosed throughout the specification are described to help one of ordinary skill in the art understand the principle and concept of the exemplary embodiments and it will be understood by one of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the exemplary embodiments as defined by the following claims. The exemplary embodiments should be considered in descriptive sense only and not for purposes of limitation. Therefore the scope of the exemplary embodiments is defined not by the detailed description of the exemplary embodiments but by the appended claims and all differences within the scope will be construed as being included in the exemplary embodiments.

