---

title: Integrating panoramic video from a historic event with a video game
abstract: A panoramic video of a real world event can be received. The video can include perspective data linked with a video timeline. A perspective view associated with a graphics of a video game linked with a game timeline at a first time index can be determined. The perspective data of the panoramic video can be processed to obtain a video sequence matching the perspective view associated with the graphics at a second time index. The video timeline and the game timeline can be synchronized based on a common time index of each of the timelines. The graphics and the video sequence can be integrated into an interactive content, responsive to the synchronizing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09251603&OS=09251603&RS=09251603
owner: 
number: 09251603
owner_city: 
owner_country: 
publication_date: 20131127
---
This application claims priority to provisional application No. 61 853 711 entitled System and Method for Stitching Videos Received from Multiple Unsynchronized Cameras filed Apr. 10 2013 as well as provisional application No. 61 854 397 entitled 360 Degrees Cameras filed Apr. 23 2013. Both provisional applications are hereby included in their entirety.

The present invention relates to the field of video game simulation and more particularly to integrating panoramic video from a historic event with a video game.

Many popular sporting events often have a video game tie in which can allow gamers and or sports enthusiasts to experience a video game simulation of a popular sporting event. Often times these video game simulations can take the form of football simulation games e.g. Madden NFL series and racing simulation games e.g. NASCAR Racing 2003 Season . That is these games attempt to recreate a realistic environment which can permit players to interact with computer controlled versions of their favorite team. Racing simulation games are quickly becoming favorites among sporting audiences and gamers alike. These games often offer a racing competition with various types of land air or sea vehicles. The games can typically offer players interaction with computer simulations of real world racing leagues and real world racing drivers. In general they can be distributed along a spectrum anywhere between realistic simulations to arcade racing games.

Many realistic simulations simulate real world vehicle constraints such as fuel usage damage tire wear and grip and suspension settings. The principal objective of these simulations is to create a sense of realism which draw players into the game. However these games often lack the realism of specific sporting events and occurrences of these sporting events. Consequently these games often quickly become dated and offer static gameplay. For example often times sports enthusiasts want the chance to make a decision for a racing driver during a critical point of a sporting event to see the outcome of their actions instead of the outcome of the driver s decision. That is players cannot experience and or replay their favorite sporting event moments within a simulation game.

One aspect of the present invention can include a system a computer program produce an apparatus and a method for integrating panoramic video from a historic event with a video game. A panoramic video of a real world event can be received. The video can include perspective data linked with a video timeline. A perspective view associated with a graphics of a video game linked with a game timeline at a first time index can be determined. The perspective data of the panoramic video can be processed to obtain a video sequence matching the perspective view associated with the graphics at a second time index. The video timeline and the game timeline can be synchronized based on a common time index of each of the timelines. The graphics and the video sequence can be integrated into an interactive content responsive to the synchronizing.

Another aspect of the present invention can include a method a computer program produce an apparatus and a system for integrating panoramic video from a historic event with a video game. A compositing engine can be configured to generate an interactive content comprising of a video game graphics and a video sequence. The graphics can be associated with a video game environment of a video game. The video sequence can be a portion of a panoramic video of a real world event. A data store can be able to persist the interactive content and or a panoramic video metadata.

The present disclosure is a solution for integrating video from real world cameras into a video game simulation environment. In the solution cameras within a real world environment can capture one or more videos of the environment and or environmental elements. For example a video camera mounted on a racing car can capture panoramic video of the car as the car races around a racing track during a racing event. In one embodiment the captured video can be processed and integrated with a video game. In the embodiment a composite environment can be created utilizing captured video to simulate event occurrences and or event environment. For example the disclosure can be utilized within a companion device as a second screen application e.g. custom content to enhance a live event viewing e.g. in a stadium at home in front of a television by an audience e.g. spectator . It should be appreciated that the video and game can be synchronized e.g. to each other to an external event etc enabling a cohesive user experience.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions.

These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Content can be a user interactive media which can enhance a user experience of an event . Content can include but is not limited to a video sequence a game element e.g. interactive graphics object and the like. Content can be associated with a point of view which can change during the course of user interaction and or viewing. The point of view can include a first person point of view a third person point of view and the like. It should be appreciated that the point of view can be a perspective based view e.g. first person perspective .

In one instance content can be presented within interface after event . In another instance content can be presented during event with an appreciable delay e.g. broadcasting delay network latency . That is user can experience customized interactive content which can enhance the viewing of event . It should be appreciated that the disclosure is not limited to viewing event and can include other embodiments in which user can utilize content to experience a realistic simulation of an event with user interactive characteristics. In one embodiment content can include an automotive racing content a racing simulation e.g. marine racing and the like. For example content can replicate a NASCAR racing championship event e.g. event in which the user can perform limited actions which can affect the content .

In scenario a video archive server can be communicatively linked to a data store . Data store can store sequence which can include one or more portions of panoramic video . In one instance sequence can include footage of real world objects traversing and or acting within an event . For example sequence can be a spectator reaction to an accident during event . In one embodiment sequence can be presented at an appropriate time during user interaction with content . For example when the user is operating a game element e.g. car and crashes into a computer controlled car a video sequence of an audience reaction can be presented within a picture in picture PiP window of interface .

Video game environment can include one or more game elements which can be extracted and presented within content . For example element can be superimposed upon a video sequence of car drifting around a street corner. It should be appreciated that environment and or element can be associated with one or more perspective point of views . For example environment can be a racing simulation with a third person view and a first person point of view depending on a user selection e.g. . In one embodiment sequence can be overlayed within environment permitting dynamic video content e.g. sequence to enhance gameplay of environment . In one instance element can be associated with a timeline of the game environment . That is element is synchronized with game environment .

In one instance sequence and element can be synchronized based on timing data e.g. an event timeline e.g. environment timeline event and the like. In one embodiment sequence can be utilized to recreate real world limitations. For example sequence can be utilized to replicate a pit stop in which a driver is unable to race during the pit stop. In one instance sequence can interrupt user interaction when a specific user action and or time marker is reached. In one configuration of the instance sequence can be utilized as a cut away to simulate an occurrence within event in which user is unable to perform actions. In another configuration of the instance user interaction can be suppressed. The interaction can resume when the sequence has ended.

It should be appreciated that the content can include a master timeline to which element and or sequence can be synchronized. In one embodiment user can adjust playback of video sequence utilizing the master timeline which can appropriately affect element .

In scenario event can be recorded utilizing panoramic camera . In one instance camera can be a three hundred and sixty degree camera with fixed directional lenses and a stitching lense mounted on the roof of a vehicle during event . For example during event a hood mounted panoramic camera can capture panoramic video of an event from the point of view of the vehicle . It should be appreciated that the disclosure can utilize multiple cameras to obtain panoramic video .

In one embodiment metadata within video can be utilized to determine an appropriate point of view for usage within content . In the instance the disclosure can appropriately match a point of view of content with a video sequence having a similar or identical point of view and vice versa. For example when content is of a driver s perspective e.g. element a video sequence of a first person perspective e.g. from the point of view of a driver in the same approximate view can be presented to show a realistic view from the point of view of car e.g. element . That is based on the point of view of content an appropriate sequence can be obtained and utilized e.g. . In essence the disclosure can approximately match a camera angle of video with a virtual camera angle of a game environment and vice versa.

Panoramic video can be a digital media with an elongated field of view. Video can be created from one or more cameras one or more lenses and or one or more videos. In one embodiment video can be an immersive video. In the embodiment immersive video can be a video recording of a real world scene environment where the view in every direction is recorded at the same time. During playback the viewer can control the viewing direction e.g. up down sideways zoom .

Video can include one or more frames metadata and the like. Video can undergo video processing which can prepare video for usage within content . For example processing can adjust the aspect ratio of frames to produce adjusted frames which are compatible with the aspect ratio of content or element . Processing can include but is not limited to distortion correction color correction object removal fidelity filtering object detection motion tracking semantic processing photogrammetry and the like. Distortion correction can include projection translations which permit the mapping of a video geometry to any coordinate system perspective and the like. Color correction can include specialized color balancing algorithms true color algorithms and the like. Object removal can utilize traditional e.g. texture synthesis multiple images and or proprietary technology to remove portions of background and or foreground objects within video . Fidelity filtering can be leveraged to control the aberration in video sequences e.g. high noise low light . Object detection can be utilized to track objects within video to select appropriate point of views for an object determine other objects obstructing the view of a tracked object and the like.

In one embodiment processing can include semantic processing which can be utilized to determine the content of video . In the embodiment video content metadata e.g. can be utilized to match game element with video to produce a meaningful content .

In one embodiment processing can include the creation of a three dimensional virtualized scene using stitching software such as MICROSOFT PHOTOSYNTH. In the embodiment multiple perspectives can be utilized to create a content which can permit user to view different point of views of interest.

It should be appreciated that the disclosure can utilize one or more regions of the panoramic video . In one instance video can be cropped to focus video sequence on relevant portions. For example video can be cropped to produce a five second video sequence e.g. of a lead car racing around a track which can be integrated into content in a realistic manner. It should be understood that the disclosure can utilize individual frames short sequences long sequences special effects and the like.

As used herein a video game can be an electronic game which involve human interaction with a user interface to generate visual feedback on a computing device within an environment . It should be appreciated that environment can be executed within a computing device e.g. device . Device can include but is not limited to a video game console handheld device tablet computing device a mobile phone and the like. Environment can include one or more user interactive elements . Elements can include but not limited to playable characters non playable characters environmental elements and the like. Environment can conform to any genre including but not limited to a simulation genre a strategy genre a role playing genre and the like.

In one instance content can be a secondary content which can permit a user to interact within an environment which resembles event . In the instance overlays can be utilized to skin the appearance of environment to appear similar to event . In one embodiment user can interact with event specific elements appearing within the content . For example a user can select a racing car within content e.g. which can be visually similar to vehicle to experience a simulation of driving the vehicle during event .

In one embodiment the disclosure can extract car shell templates from video which can enable the templates to applied within content . In the instance the exterior appearance of a vehicle within event can be extracted and applied appropriately to an element within content . For example a truck shell template of a trucks competing in a Camping World Truck Series event can be extracted from video to enable a car e.g. within a Sprint Cup Series content to appear as a truck from the Camping World Truck Series.

As used herein event can be a real world occurrence within a real world environment. For example event can be a racing event such as a National Association for Stock Car Auto Racing NASCAR racing championship event. Event can include but is not limited to real world participants e.g. human spectators and or objects e.g. vehicle . For example event can include racing cars travelling around a race track while spectators observe the race. Video can be collected before during and or after event occurrence.

In one embodiment camera can convey video wirelessly to a event server archive server broadcast server and the like. It should be appreciated that video can include data from multiple events from one or more segments of an event and the like. For example video can include video footage from multiple car races or multiple interval segments of a motorcycle race.

In one embodiment the disclosure can be a game mode a game modification e.g. game mod and the like. In one instance content can be a downloadable content such as a patch a content expansion pack and the like. For example the content can be accessible once a user reaches a game checkpoint of completes a game achievement.

It should be appreciated that the disclosure can utilize traditional and or proprietary mechanism to blend sequence and element within content . Mechanisms can include special effects and or post production mechanisms including but is not limited to compositing e.g. chroma keying layering and the like. It should be appreciated that content can include additional content and is not limited to game element and or video sequence .

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that the disclosure can shift pixels of sequence to appear appropriately within content . It should be appreciated that the disclosure is not limited to automotive racing can be utilized in the context of team sports athletics extreme sports and the like.

In one instance content can include two views a driver s and a spectator of a racing event. Each view can be a perspective view of a content which can include interactive and non interactive portions. In one embodiment content can be a video game application which can permit a user to select one or more computer based perspective views where the computer based perspective views e.g. can be generated utilizing video obtained from a past event. It should be appreciated that content is not limited to simultaneous views and can support an arbitrary number of perspective views.

In driver s view a game element and a video overlay can be presented. For example game element can be an interior of a car controlled by a user and overlay can show an approaching vehicle in the rear view mirror. In one instance video overlay and element can be synchronized to permit a realistic experience. For example as the car moves further away from the approaching vehicle the overlay can be scaled appropriately resulting in the appearance of speeding away from the vehicle. That is driver view can utilize a video sequence overlayed on a graphic element e.g. game element to create a simulated perspective view within content .

In spectator view a graphic overlay can be presented simultaneously with a video sequence in a third person perspective view. For example view can show a user controlled car e.g. positioned alongside other competing cars e.g. where the competing cars are a portion of a video sequence of a previously finished race. That is spectator view can utilize a graphic overlayed on a video sequence to create a perspective view within content .

Passenger view can be a perspective view of a game content. In one instance a video sequence from a passenger mounted camera can be utilized to enhance a computer based perspective view. In the instance a video sequence can be overlayed within the computer based perspective view. For example a video of a real world driver can be used to obscure a computer avatar within overlay to enhance the realism of the computer based perspective view.

In passenger view a picture in picture PiP feature of a game can be utilized to present a video overlay . In one instance overlay can be synchronized to the movement of a user interaction . In the instance overlay can utilize appropriate video sequences to improve the realism of a game experience. For example a video sequence of a driver and passenger leaning left can be presented within the PiP window when a user steers the car around a left hand corner quickly.

In one embodiment game data from a video game can be utilized to create a customized content. In the embodiment session data including but not limited to game scoring lap times routes and the like can be leveraged by the disclosure. For example a user can select saved games with a best lap time of a NASCAR track to visually compare performance against historic video of professional drivers racing on an identical track. It should be appreciated that collision detection between video sequences and game elements can be resolved utilizing traditional e.g. non colliding geometry bounding boxes and or proprietary techniques and the like. For example when a video sequence is detected to obscure a game element one or more opaque layers can be utilized to block the game element from being viewed in an appropriate manner.

In step an interactive content can be established within an interface of a computing session. The computing session can be executed within a companion device. In step if a video sequence is available for the content the method can continue to step else proceed to step . In step game element data can be determined. Data can include but is not limited to point of view data semantic data element geometry element texture and the like. In step a sequence can be selected based on perspective information obtained from game element data. In step the sequence and elements can be cohesively merged into the interactive content. In step if errors are detected in content the method can continue to step else proceed to step .

In step a user input can be received. In step if the input exceeds previously established constraints the method can return to step else continue to step . Constraints can be determined based on element data restrictions video sequence limitations user preferences system settings and the like. In step the content can be updated appropriately based on input. The content can be updated utilizing traditional and or proprietary video graphic algorithms. In step user specific views can be optionally generated. User specific views can include but is not limited to a first person perspective view e.g. player character view third person perspective view e.g. observer view and the like. In step the views can be optionally presented within the interface. In step if the session is terminated the method can continue to step else return to step . In step the method can end.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that method can be performed in real time or near real time. Further method can be performed in serial and or in parallel. Steps can be performed continuously during the computing session to enable a video sequence and game element to be seamlessly integrated as a point of view of interactive content changes. It should be appreciated that method can include additional steps which can permit the acquisition of additional event data e.g. footage semantic data during the session.

Content sever can be a hardware software entity for enabling interactive content . Server can include but is not limited to compositing engine interactive content data store and the like. Server functionality can include but is not limited to file serving encryption capabilities and the like. In one instance server can perform functionality to enable communication with game server server and the like. In one embodiment server can be a functionality of a pay per view subscription service.

Compositing engine can be a hardware software element for producing content . Engine functionality can include but is not limited to image processing video editing and the like. In one embodiment engine can be a functionality of a graphics framework. In one instance engine can determine one or more relevant portions e.g. dynamic content of content to be conveyed to device . In the instance relevant portions can be conveyed while non relevant portions e.g. static content can be omitted. That is engine can compensate for real world limitations including but not limited to network latency computing resource availability and the like. It should be appreciated that engine can perform caching functionality to enable real time or near real time content delivery and or presentation.

It should be appreciated that engine can allow for manual oversight and management of the functionality described herein. For example engine can permit an administrator to approve or reject a video and or a game element prior to use within content .

Video processor can be a hardware software entity for processing panoramic video . Processor functionality can include traditional and or proprietary functionality. In one embodiment processor can include pre processing functionality including but not limited to metadata analysis video acquisition and or filtering and the like.

Compositing handler can be a hardware software element for merging video and element into an interactive content . Handler can utilize traditional and or proprietary functionality to cohesively integrate video and element into an interactive content .

View renderer can be a hardware software entity for presenting a perspective view of interactive content . Renderer functionality can include but is not limited to environment analysis element analysis environment mapping analysis and the like.

Settings can be one or more rules for establishing the behavior of system server and or engine . Settings can include but is not limited to video processor options compositing handler settings view renderer options and the like. In one instance settings can be manually and or automatically established. In the embodiment settings can be heuristically established based on historic settings. Settings can be persisted within data store computing device and the like.

Interactive content can be one or more digital media which can permit user interaction to affect content state. Content can conform to traditional and or proprietary formats including but not limited to an ADOBE FLASH format a JAVA format and the like. That is content can be a Web based application. It should be appreciated that content is not limited to Web based platforms and can include desktop application platforms video game console platforms and the like. In one embodiment content can be access restricted e.g. pay per view age restricted based on one or more provider settings e.g. licensing restrictions and the like. In one instance content can be executed within a sandbox which can address potential security pitfalls without markedly decreasing performance of the content . It should be appreciated that content can include single player functionality multiplayer functionality and the like.

Data store can be a hardware software component able to persist content element video and the like. Data store can be a Storage Area Network SAN Network Attached Storage NAS and the like. Data store can conform to a relational database management system RDBMS object oriented database management system OODBMS and the like. Data store can be communicatively linked to server in one or more traditional and or proprietary mechanisms. In one instance data store can be a component of Structured Query Language SQL complaint database.

Computing device can be a software hardware element for collecting user input and or presenting content . Device can include but is not limited to input components e.g. keyboard camera output components e.g. display interface and the like. In one instance interface can be a Web based interface e.g. rich internet application media player . Device hardware can include but is not limited to a processor a non volatile memory a volatile memory a bus and the like. Computing device can include but is not limited to a desktop computer a laptop computer a mobile phone a mobile computing device a portable media player a Personal Digital Assistant PDA a video game console an electronic entertainment device and the like.

Game server can be a hardware software entity for executing game environment . Server can include but is not limited to virtual game world server a gateway server a game content server an e commerce server and the like. In one embodiment server can communicate with server to convey relevant game elements as requested by server . In one embodiment game server can be utilized to can convey perspective data to server and or engine . In one instance game server can be utilized to support multiplayer interaction with content .

Game environment can be one or more virtual environments associated with a video game. Environment can include but is not limited to game maps elements . Environment can include two dimensional environments three dimensional environments and the like. Environment can include static elements dynamic elements and the like.

Video archive server can be a hardware software entity for persisting and or conveying video . Server can execute a digital asset management software which can index video based on one or more criteria including but not limited to metadata user input e.g. keywords and the like.

Network can be an electrical and or computer network connecting one or more system components. Network can include but is not limited to twisted pair cabling optical fiber coaxial cable and the like. Network can include any combination of wired and or wireless components. Network topologies can include but is not limited to bus star mesh and the like. Network types can include but is not limited to Local Area Network LAN Wide Area Network WAN Virtual Private Network VPN and the like.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that one or more components within system can be optional components permitting that the disclosure functionality be retained. It should be understood that engine components can be optional components providing that engine functionality is maintained. It should be appreciated that one or more components of engine can be combined and or separated based on functionality usage and the like. System can conform to a Service Oriented Architecture SOA Representational State Transfer REST architecture and the like.

The flowchart and block diagrams in the illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

