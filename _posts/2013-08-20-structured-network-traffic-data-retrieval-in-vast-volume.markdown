---

title: Structured network traffic data retrieval in vast volume
abstract: A method and apparatus are disclosed herein for retrieving network traffic data. In one embodiment, a networking apparatus comprises a memory; a network device; and a processing unit coupled to the network device and the memory. The processing unit is operable to execute a data engine that performs bulk data transfers from the network device periodically into a data buffer in the memory and translates data received from the network device, based on a mapping definition, into a user defined format for export to one or more applications running on networking apparatus.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09442883&OS=09442883&RS=09442883
owner: PICA8, INC.
number: 09442883
owner_city: Palo Alto
owner_country: US
publication_date: 20130820
---
Embodiments of the present invention relate to the field of networking devices more particularly embodiments of the present invention relate to the transfer of network data from a network device to applications and file services requesting such data.

In today s networking environment network users including mega data centers enterprises and telecommunication companies require the traffic data from a networking device in order to optimize their applications. The network data in which the network users are interested includes port status traffic volume error rate and queue depth as well as other data statistics.

The traffic data is collected and stored in network devices such as network ASICs. When network users need the data they issue commands through one or more SNMP CLI or Web interfaces to retrieve the data from ASIC one data element at a time. This used to be acceptable but it cannot scale with the amount of data that generated from the devices today.

A method and apparatus are disclosed herein for retrieving network traffic data. In one embodiment a networking apparatus comprises a memory a network device and a processing unit coupled to the network device and the memory. The processing unit is operable to execute a data engine that performs bulk data transfers from the network device periodically into a data buffer in the memory and translates data received from the network device based on a mapping definition into a user defined format for export to one or more applications running on networking apparatus.

A networking apparatus for use in a network is described. In one embodiment the networking apparatus comprises a memory a network device and a processing unit coupled to the network device and the memory. The processing unit is operable to execute a data engine that performs bulk data transfers from the network device periodically into a data buffer in the memory and translates data received from the network device based on a mapping definition into a user defined format for export to one or more applications running on networking apparatus. In one embodiment a bulk data transfer is a transfer of all or a large amount of device e.g. ASIC data directly from the device to a memory of another device e.g. a CPU memory in one transaction by specifying a range of data to be exported through the bulk data transfer mechanism e.g. ASIC DMA mechanism as opposed to retrieving one data item at a time . In one embodiment the data includes ASIC data in counters for all physical switch ports L2 L3 tables and queues packet buffers of an ASIC. This data collection process can be repeated any number of times automatically to record a large amount of data for an application to process.

In one embodiment the data engine is operable to configure a bulk data transfer mechanism of the network device to stream data from the network device to the data buffer at a user specified time interval. In one embodiment the data engine when executing a streaming definition module receives a data object definition associated with data from the network device data buffer location information and a data streaming frequency from a user interface that is part of the data engine and programs the bulk data transfer mechanism based on this information. In one embodiment the data engine in response to the data object definition the data buffer location information and the data streaming frequency from the user interface translates data from the network device into physical table names counter names and register names. In one embodiment the data engine receives a mapping definition and includes a data mapper that uses the mapping definition to map data from the network device to the user defined format.

In one embodiment the bulk data transfer mechanism comprises a direct memory access DMA data transfer mechanism and the data buffer receives DMA transferred data. In one embodiment the user specified interval is received by the data engine from an application using a user interface.

In the following description numerous details are set forth to provide a more thorough explanation of the present invention. It will be apparent however to one skilled in the art that the present invention may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the present invention.

Some portions of the detailed descriptions which follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention also relates to apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but is not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMS EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine e.g. a computer . For example a machine readable medium includes read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices etc.

In one embodiment data engine comprises three layers and multiple interfaces that can be executed on one or multiple central processing units CPUs to control one or multiple network devices e.g. ASICs . The three layers are a data streaming layer a data mapping layer and a data presentation layer .

In one embodiment streaming layer comprises a streaming definition module a direct memory access DMA control module and DMA data buffer . In one embodiment DMA data buffer is part of a CPU memory.

Streaming definition module receives an ASIC data object definition a CPU DMA data buffer location and a streaming frequency from user interface module of presentation layer and then translates the provided information into parameters passed to the Application Program Interface of network device e.g. the ASIC . For example the data can be identified by physical table names counter names register names and ranges e.g. starting and ending register addresses or offsets for DMA control module to program the DMA bulk data transfer interface of network device .

DMA control module receives a streaming definition from streaming definition module and then configures a DMA data transfer mechanism of network device to stream data from network device to DMA data buffer module . In one embodiment DMA control module implements a DMA control loop that retrieves data from network device based on a user specified timing interval. Such a timing interval may be periodic. In one embodiment the DMA control configures the DMA transfer through ASIC Application Program Interface provided by the ASIC vendor Software Development Kit SDK . The data engine specifies the target ASIC data items e.g. counters tables FIFO registers address ranges e.g. starting and ending addresses transfer intervals and destination memory buffer address. The above configuration is set into the ASIC and the transfers are made based on the specified intervals.

DMA data buffer module is a buffer area in a memory e.g. a CPU memory managed by data engine to receive DMA transferred data from network device . In one embodiment DMA data buffer module is a shared memory accessible by data streaming layer and data mapping layer in a non blocking fashion such that both data streaming layer and data mapping layer can access DMA data buffer module at the same time.

In one embodiment data mapping layer comprises mapping definition module and data mapper module . Mapping definition module receives a user defined data format from user interface module of presentation layer for use in translating the raw data from network device into a user defined data format for data presenter of presentation layer to store or export at least portions of the data to one or more applications such as for example applications . In one embodiment the mapping reduces the amount of data to be transferred to applications or users by selecting a subset of ASIC data to be transferred to applications or users. In one embodiment by default all data are mapped to a default data model for data presenter of presentation layer to export the data to a file system interface to communicate with file system . In one embodiment mapping definition is a hierarchical data definition with name and value pairs is stored in data engine and is assessable by data mapper module .

Data mapper module maps the data from network device to a user defined format based on mapping definition . In one embodiment a default format based on a default data model is always generated.

In one embodiment data presentation layer comprises a user interface module and a data presenter module . User interface module receives a user input for mapping and streaming configuration and checks the syntax and semantics of the user input to ensure it is a correct specification. In one embodiment the user input is stored in internal data structure that is shared among internal modules of data engine . Data presenter module exports the mapped data in default format to file system e.g. Linux Virtual file system proc and presents data in a user defined format to user applications . In one embodiment data presenter module exports the data to a Linux Virtual file system using a proc interface which is a kernel driver interface and to a Linux application using a socket interface.

In one embodiment in operation a network device such as network device creates and stores data corresponding to network traffic that passes through it. The data corresponds to statistics regarding the data that passes through the network device. In one embodiment data corresponding to each port of the network device is stored in a memory in the network device. The data may be count values from counters keeping track of certain statistics such as the number of packets processed the number of packets dropped etc. Thus as packets come into the network device statistics are generated and stored in memory of the network device.

In one embodiment this data is logically grouped together even though it may be physically scattered in a memory in or accessible to network device . Locations in the memory of the network device may be mapped to each of the ports of the network device. In such a case counters and or statistics for each of the specific ports are stored in certain locations in the memory of the network device.

In one embodiment the data stored in network device is transferred to data streaming layer of data engine using a DMA bus interface as part of a bulk transfer operation. These bulk transfer operations occur repeatedly over time to stream the data from the network device to the data engine. In one embodiment this can occur in the time interval between minimum 10 milliseconds to a maximum of every 15 minutes.

Data mapper maps the data into a format based on the application e.g. application to which the data is being sent. The format may dictate that only certain information provided by network device is to be provided to the application. For example an application may only desire data from a subset of the counter values e.g. number of packets dropped at a particular port number of packets dropped at a particular flow etc. provided by network device . In such a case before data mapper maps the data one of applications identifies the data that it desires how often it wants the data and selects an action to be performed on the data. The action may be a recovery action generating a report performing certain analysis on the data etc. Note that the action selected by the application does not need to be specified to the data engine. The same information could be specified by one or more other applications.

In response to mapping the data data presentation layer obtains the data desired by the application and provides the data with the mapping specified by the application to an interface e.g. a IP interface a web interface a file interface etc. to present the mapped data to the applications and or the file system.

Referring to the process begins by processing logic receiving a mapping definition from an application via a first user interface of the data engine of data to be obtained from the network device and provided to the application processing block . In one embodiment the mapping definition specifies translation of network device data into a user defined data format.

Processing logic also receives a streaming definition from the application via a second interface of the data engine processing block . In one embodiment the streaming definition specifies data from the network device that is to be streamed via the data engine to the application and a streaming frequency indicating how often the data is to be streamed. In one embodiment the streaming definition comprises a data object definition and a data buffer location for the data buffer of the data engine. In one embodiment the first and second user interfaces are the same interface.

In response to the streaming definition processing logic receives a bulk transfer of a set of data created and stored on a network device using a control of the data engine responsive to the streaming definition processing block and stores the set of data in a data buffer of the data engine processing block . In one embodiment receiving the bulk transfer of a set of data created and stored on a network device is performed using a DMA data transfer mechanism and the set of data is received using a DMA bus interface of the data engine. In one embodiment the bulk transfer of the set of data is repeated periodically according to the time interval.

Thereafter responsive to the mapping definition processing logic presents mapped data corresponding to the set of data to the application via another interface processing block . In one embodiment the third interface comprises a TCP interface a web interface or a file system interface.

In one embodiment a data model for network device contains counters tables and registers. It is a hierarchical data model in which each data group consists of sub groups and individual data items. The model is described by a data definition language JSON. A sample data schema is provided below.

The data schema is used by the streaming definition module to identify data from network device that needs to be transferred by a DMA or other type of transfer to data engine . It is also used by mapping definition module to select the data to be mapped for the application.

In one embodiment a networking apparatus can have one more CPUs that execute the data engine to control one or multiple network devices e.g. ASICs directly or indirectly through intermediate CPUs. illustrate example configurations of such networking apparatuses.

In one embodiment CPU and ASICs are coupled to each other using a chassis based system. In an alternative embodiment the chassis includes multiple CPUs controlling multiple ASICs.

Bus allows data communication between central processor and system memory . System memory e.g. RAM may be generally the main memory into which the operating system and application programs are loaded. The ROM or flash memory can contain among other code the Basic Input Output system BIOS which controls basic hardware operation such as the interaction with peripheral components. Applications resident with computer system are generally stored on and accessed via a computer readable medium such as a hard disk drive e.g. fixed disk an optical drive e.g. optical drive a floppy disk unit or other storage medium.

Storage interface as with the other storage interfaces of computer system can connect to a standard computer readable medium for storage and or retrieval of information such as a fixed disk drive . Fixed disk drive may be a part of computer system or may be separate and accessed through other interface systems.

Modem may provide a direct connection to a remote server via a telephone link or to the Internet via an internet service provider ISP e.g. servers of . Network interface may provide a direct connection to a remote server such as for example servers of . Network interface may provide a direct connection to a remote server e.g. server of via a direct network link to the Internet via a POP point of presence . Network interface may provide such connection using wireless techniques including digital cellular telephone connection a packet connection digital satellite data connection or the like.

Many other devices or subsystems not shown may be connected in a similar manner. Conversely all of the devices shown in need not be present to practice the techniques described herein. The devices and subsystems can be interconnected in different ways from that shown in . The operation of a system such as that shown in is readily known in the art and is not discussed in detail in this application.

Code to implement the data engine operations described herein can be stored in computer readable storage media such as one or more of system memory fixed disk optical disk or floppy disk . The operating system provided on computer system may be MS DOS MS WINDOWS OS 2 UNIX Linux or another known operating system.

Whereas many alterations and modifications of the present invention will no doubt become apparent to a person of ordinary skill in the art after having read the foregoing description it is to be understood that any particular embodiment shown and described by way of illustration is in no way intended to be considered limiting. Therefore references to details of various embodiments are not intended to limit the scope of the claims which in themselves recite only those features regarded as essential to the invention.

