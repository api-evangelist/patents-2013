---

title: Verifying application data protection
abstract: A technique for verifying the safety of tenant data in a data center includes creating a topological map of storage constructs used for storing the tenant data within the data center. The topological map includes a logical storage device, a physical storage device, and a set of hardware structures disposed between the logical and physical storage devices. The constructs of the topological map are evaluated to generate an individual assessment of fault tolerance of each construct, and a set of rules are applied to generate an overall assessment of the safety of the tenant data. In an example, an administrator may operate this technique on a tenant application and generate a report for the tenant summarizing the results.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09021307&OS=09021307&RS=09021307
owner: EMC Corporation
number: 09021307
owner_city: Hopkinton
owner_country: US
publication_date: 20130314
---
Data centers commonly provide computational resources to their tenants in the form of online data storage and or data processing services. Tenants often store their valuable data and run their critical software applications at such data centers. Users of the software applications such as the tenants customers may then access the software applications over the Internet or some other network. In one example a tenant is an on line retail business operating a website hosted by the data center. The tenant purchases data storage and processing services provided through the data center and retail customers access the website to make their on line purchases over the Internet. In another example a tenant is an individual who stores his or her applications and or data e.g. files photos videos etc. at the data center which appears to the individual tenant to be in the cloud. 

Data centers commonly employ virtual machines to provide data processing services to their tenants. As is known a virtual machine is a software implementation of a physical computing machine which may appear on a network as a distinct computer but may in fact be one of multiple virtual machines running on a single server. Virtual machines are popular in data centers because they are readily transportable between physical servers and thus promote load balancing and the capability to failover from one physical server to another.

When tenants purchase computational resources from the provider of a data center the tenants often pay for and expect to receive a certain minimum level of service. Service level may be specified for a variety of performance related and or reliability related measures.

Virtual machines confer many benefits to data centers and their tenants but often make it difficult for tenants to know the exact physical locations where their valuable data are stored. Virtual machines store data on virtual disks but virtual disks are logical constructs that do not themselves reveal the underlying infrastructure of the data center involved in storing particular data. Thus with prior data center technology it is often difficult for tenants to know the locations of their data storage including whether their valuable data are safe.

Data centers are vulnerable to loss of tenant data due to data corruption disk drive failures path failures and other device failures for example. Data centers are also vulnerable to data loss in the event of natural disasters such as fires floods and earthquakes. In the highly virtualized environment of a data center what is needed is a way for tenants to be informed of the protection status and safety of their particular data.

In contrast with prior data center technology a technique for verifying the safety of tenant data in a data center includes creating a topological map of storage constructs used for storing the tenant data within the data center. The topological map includes a logical storage device a physical storage device and a set of hardware structures disposed between the logical and physical storage devices. The constructs of the topological map are evaluated to generate an individual assessment of fault tolerance of each construct and a set of rules are applied to generate an overall assessment of the safety of the tenant data. In an example an administrator may operate this technique on a tenant application and generate a report for the tenant summarizing the results.

Certain embodiments are directed to a method of verifying that data of a tenant application running in a data center is safe from data center failures. The method includes querying a set of data sources within the data center to identify a set of storage path constructs used by the tenant application for storing the data of the tenant application. The storage path constructs include a logical storage device used by the tenant application a physical storage device used by the tenant application and a set of hardware structures disposed between the logical storage device and the physical storage device used by the tenant application. The method further includes evaluating each of the set of storage path constructs to generate an assessment of fault tolerance of the respective storage path construct and applying a set of rules to the assessments generated across the set of storage path constructs to yield an overall assessment of the safety of the tenant application data.

Other embodiments are directed to computerized apparatus and computer program products. Some embodiments involve activity that is performed at a single location while other embodiments involve activity that is distributed over a computerized environment e.g. over a network .

Embodiments of the invention will now be described. It is understood that such embodiments are provided by way of example to illustrate various features and principles of the invention and that the invention hereof is broader than the specific example embodiments disclosed.

A technique for verifying the safety of tenant data in a data center includes creating a topological map of storage constructs used for storing the tenant data within the data center evaluating the fault tolerance of each storage construct in the topological map and applying a set of rules to generate an overall assessment of the safety of the tenant data.

In an example the disclosed technique may be implemented as a software program that performs a simulated data recovery drill on a tenant s application. Like a fire drill which may be performed to assess the preparedness for a fire of procedures personnel and equipment a data recovery drill assesses the extent to which a tenant s valuable data is or is not protected at a given point in time should a data center failure occur. The data center failure may range from an individual component failure to a catastrophic failure in which the entire data center becomes disabled.

The host computer i.e. the host operates a virtual machine which runs a tenant application . The virtual machine has a virtual disk for storing data of the tenant application i.e. tenant data. The virtual disk is not a physical disk but rather a logical representation of a disk or set of disks in memory of the host . Although only a single virtual machine is shown the host may operate a number of different virtual machines at any given time. Also it is understood that the host may be any type of computing device. In an example the host is a compute server blade installed in a chassis not shown of the data center environment . The data center environment will typically include many hosts like the host which may run the same tenant application or different tenant applications on behalf of the same tenant or different tenants.

The administrative computer hosts a recovery drill application and various data sources . In an example the recovery drill application is configured to query various elements of the data center environment including the data sources and to generate an assessment of the safety of tenant data. The data sources provide configuration information settings and performance information pertaining to the data storage system and may include for example administrative tools drivers and other programs. Any number of data sources may be provided and they may be located anywhere in the data center environment . The administrative computer may be any type of computing device. In one example the administrative computer is implemented as a server blade in the same chassis in which the host computer is housed or in a different chassis. In another example the administrative computer is itself a virtual machine which may be hosted by any physical computing device of the data center environment .

The network includes a variety of network components such as Internet Protocol IP switches routers and cables for example and forms an infrastructure for implementing a Local Area Network LAN or some other computing network within the data center environment . In an example the network is connected to the Internet for enabling communication with various remote users and with a redundant storage site e.g. a replication site . In some examples the network also includes components for Fibre Channel and or other block based protocols which enable the host to send SCSI Small Computer System Interface IO requests to the data storage system . Such requests may specify data reads and writes to particular LUNs Logical Unit Numbers i.e. logical disk volumes and particular offset ranges within the LUNs. The network may also convey IO requests from the host to the data storage system in a file based protocol such as NFS CIFS or SMB 3.0 for example.

The data storage system is seen to include a storage server a storage area network SAN and an array . In an example the SAN includes multiple switches for routing IO requests received from the storage server to the array . The array includes magnetic disk drives electronic flashdrives and or other non volatile storage media shown generally as storage devices through . It is understood that the data storage system may include any number of storage servers connected to the SAN and that any number of data storage systems may be provided within the data center environment .

The storage server includes a set of communication interfaces e.g. network interface cards SCSI adapters etc. a set of processors i.e. one or more processing chips and or assemblies memory and host bus adapters HBAs and . The HBAs and plug into a bus e.g. a PCI bus of the storage server and transmit IO requests down paths to the array as managed by the multipathing driver described below. The memory includes both volatile memory e.g. RAM and non volatile memory such as one or more disk drives solid state drives SSDs and the like.

The memory stores various software constructs. These include for example a replication manager and an IO stack . The IO stack includes the multipathing MP driver . It is understood that the memory typically includes many other software constructs which are not shown such as an operating system and various applications processes and daemons.

The replication manager manages replication of data stored on the array to local and or remote redundant storage sites. In an example the replication manager performs both synchronous replication and asynchronous replication. Synchronous replication operates by mirroring data writes sent to the array to the redundant storage as the writes are occurring i.e. in band with IO requests received by the storage server . By comparison asynchronous replication operates out of band with IO requests based on snaps of data objects stored in the array . For example the replication manager may asynchronously replicate a LUN realized on the array by identifying differences between consecutive snaps of the LUN and sending the differences to the redundant storage site for safekeeping.

The IO stack processes read and write IO requests arriving at the storage server . The IO requests may arrive in the form of block based IO requests e.g. specifying a LUN and an offset range or file based requests e.g. specifying a particular file system path and file name . The IO stack also provides caching services.

The MP driver performs multipathing operations to select particular paths SCSI ITLs or Initiator Target LUNs to be used for transmitting IO requests to the array . In an example the MP driver collects metrics pertaining to the status of different paths between the storage server and the array . As will be described the MP driver may also serve as a data source for the recovery drill application .

In operation the host runs the tenant application in the virtual machine and the tenant application performs reads and writes to the virtual machine disk . As the virtual machine disk is not a physical disk but rather a memory construct the read and write requests to the virtual machine disk are translated into read and write IO requests which the host sends through the network to the data storage system . The storage server processes the IO requests i.e. via the communication interfaces the IO stack and the HBAs and . The IO requests are sent via selected paths to the SAN and then to the array where they are further processed to perform actual read and write operations on the storage devices through

Asynchronously with the operation of the host and the data storage system an administrator of the data center environment may run the recovery drill application . In an example the administrator running the recovery drill application may specify a tenant application such as the tenant application as the object of the recovery drill. The recovery drill application proceeds to query one or more data sources e.g. one of more of the data sources the MP driver and or other data sources within the data center environment to identify storage path constructs involved in handling the data of the tenant application . The recovery drill application then evaluates the identified storage path constructs or some subset of the identified storage path constructs and generates an assessment of the fault tolerance of each respective storage path construct. The recovery drill application then applies a set of rules to the assessments to yield an overall assessment of safety of the tenant application data. The recovery drill application may generate one or more reports. In an example the reports specify the following 

In some examples evaluating the identified storage path constructs involves assessing the level of redundancy for each storage path construct. The recovery drill application may simulate failures of different storage path constructs and identifies the consequences of each such failure. The recovery drill application may also simulate the failure of the entire data center environment and to assess the ability to apply off site redundant clones and or snaps of the tenant data to fully restore the tenant data.

In an example the recovery drill application also performs an impact analysis to assess any data center failure from the perspective of business continuity. The recovery drill application takes into account financial operational and service impacts of any data center failure. Vulnerabilities and fault tolerance to single point failures are also assessed and reported.

In an example the recovery drill application evaluates each of the storage path constructs or a subset of the storage path constructs individually to generate an assessment of fault tolerance. Taking the storage path constructs of in order the recovery drill application may evaluate 

Rather than generating a single score for each storage path construct the recovery drill application may instead produce multiple scores for multiple factors. For example one factor may relate to safety in the event of a single point failure of the storage path construct assuming the data center environment is otherwise operational. Another factor may relate to safety in the event that the data center as a whole becomes unavailable such as might occur during a natural disaster.

Given the individual evaluations of the storage path constructs and or the recovery drill application applies a set of rules to the assessments generated across the storage path constructs or a subset thereof to yield an overall assessment of the safety of the tenant application data. The set of rules can be arbitrarily simple or complex. In one example the overall assessment is simply a sum e.g. a weighted sum of the single scores obtained from evaluating each of the storage path constructs and or . In another example multiple scores from each storage path construct are considered and combined using an algorithm that is optimized for accurately predicting disaster preparedness. The recovery drill application may thus be regarded for example as a mashup which combines data from multiple data sources i.e. the data sources as well as other data sources to create a new service for assessing tenant data safety and disaster preparedness.

The recovery drill application is seen to include a querying engine an evaluation engine a rules based assessment engine and a software interface such as a REST Representational State Transfer interface . The query engine is constructed and arranged to query a set of data sources within the data center environment to identify a set of storage path constructs used by the tenant application e.g. those shown in for storing the data of the tenant application . The evaluation engine is constructed and arranged to evaluate each of the set of storage path constructs e.g. as shown in to generate an assessment of fault tolerance of the respective storage path construct. The rules based assessment engine is constructed and arranged to apply the set of rules to the assessments generated across the set of storage path constructs to yield the overall assessment of the safety of the tenant application data. In addition the REST interface is constructed and arranged to communicate with the data sources as well as other data sources in other locations of the data center environment .

In an example each of the data sources also has a respective REST interface. The data sources may include for example the MP driver e.g. PowerPath a replication monitoring application e.g. AppSync a data protection advisor application e.g. DPA and a unified infrastructure manager e.g. UIM . PowerPath AppSync DPA and UIM are software products available from EMC Corporation of Hopkinton Mass. Other data sources may be provided as well such as a data source within the virtual machine a data source for monitoring the network and a data source for monitoring the SAN for example.

At step a set of data sources e.g. data sources as well as other data sources within the data center are queried to identify a set of storage path constructs e.g. those shown in used by the tenant application for storing the data of the tenant application . The storage path constructs include a logical storage device e.g. the virtual memory disk used by the tenant application a physical storage device e.g. used by the tenant application and a set of hardware structures e.g. the network storage server and SAN disposed between the logical storage device and the physical storage device used by the tenant application .

At step each of the set of storage path constructs is evaluated to generate an assessment of fault tolerance of the respective storage path construct. For example the storage constructs of or some subset thereof are each scored to produce an assessment of fault tolerance.

At step a set of rules is applied to the assessments generated across the set of storage path constructs to yield an overall assessment of the safety of the tenant application data. For example the scores may be combined to produce a weighted sum or a more complex algorithm may be applied as described in reference to .

A technique has been described for verifying the safety of tenant data in a data center. The technique includes creating a topological map of storage constructs used for storing the tenant data within the data center. The topological map includes a logical storage device a physical storage device and a set of hardware structures disposed between the logical and physical storage devices. The constructs of the topological map are evaluated to generate an individual assessment of fault tolerance of each construct and a set of rules are applied to generate an overall assessment of the safety of the tenant data. In an example an administrator may operate this technique on a tenant application and generate a report for the tenant summarizing the results.

As used throughout this document the words comprising including and having are intended to set forth certain items steps elements or aspects of something in an open ended fashion. Also as used herein and unless a specific statement is made to the contrary the word set means one or more of something. Although certain embodiments are disclosed herein it is understood that these are provided by way of example only and the invention is not limited to these particular embodiments.

Having described certain embodiments numerous alternative embodiments or variations can be made. For example although the virtual machine is shown and described as running on the host this arrangement is not required. For example the virtual machine may also be run directly on the storage server or an any other suitable computing machine. More generally it should be understood that the arrangement of the data center environment is merely illustrative and that the principles disclosed herein may be applied to a wide range of data center configurations.

Also although the data center environment is shown and described with reference to virtual machines this also is merely an example. Alternatively the host of the storage server may execute the tenant application directly i.e. without using a virtual machine. Thus rather than referring to a virtual machine disk the tenant application may instead refer simply to a LUN or to a file. Both LUNs and files may be considered to be logical storage path constructs as that term is used herein.

Further although features are shown and described with reference to particular embodiments hereof such features may be included in any of the disclosed embodiments and their variants. Thus it is understood that features disclosed in connection with any embodiment can be included as variants of any other embodiment whether such inclusion is made explicit herein or not.

Further still the improvement or portions thereof may be embodied as a non transient computer readable storage medium such as a magnetic disk magnetic tape compact disk DVD optical disk flash memory Application Specific Integrated Circuit ASIC Field Programmable Gate Array FPGA and the like shown by way of example as medium in . Multiple computer readable media may be used. The medium or media may be encoded with instructions which when executed on one or more computers or other processors perform methods that implement the various processes described herein. Such medium or media may be considered an article of manufacture or a machine and may be transportable from one machine to another.

Those skilled in the art will therefore understand that various changes in form and detail may be made to the embodiments disclosed herein without departing from the scope of the invention.

