---

title: Hardware enforced content protection for graphics processing units
abstract: A graphics processing unit (GPU) is configured to access a first memory unit according to one of an unsecure mode and a secure mode. The GPU may include a memory access controller configured to allow the GPU to read data from only an unsecure portion of the first memory unit when the GPU is in the unsecure mode, and configured to allow the GPU to write data only to a secure portion of the first memory unit when the GPU is in the secure mode.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08931108&OS=08931108&RS=08931108
owner: QUALCOMM Incorporated
number: 08931108
owner_city: San Diego
owner_country: US
publication_date: 20130218
---
This disclosure relates to techniques for graphics processing and more specifically to techniques for content protection.

Modern operating systems including open platforms e.g. Android or other open source platforms and closed platforms e.g. Microsoft Windows are not typically trusted in terms of protecting secure content which is streamed to or processed by such open platforms. While modern operating systems provide a level of security via the user kernel mode separation ultimately components of kernel mode both in closed platforms and particularly in open platforms do not provide a strong level of trust. Kernel mode drivers can easily be installed and a malicious kernel mode driver naturally bypasses the security boundary. Kernel mode hardware drivers in such open platforms are used to control the operation of hardware e.g. graphics processing units GPUs that may process secure content. However because such drivers are often open source and or not considered to be secure in relation to protected content they are more susceptible to alteration by third parties. Such alterations may cause the protected content e.g. digital rights managed DRM content that is streamed through or processed by the hardware controlled by such drivers to be stored in unsecure memories and copied. As such control of secure content on open platforms is often difficult.

In general this disclosure describes techniques for hardware enforced content protection for a graphics processing unit GPU . To control secure content on a hardware platform access to secure memory may be controlled by hardware such as a GPU.

In one example of the disclosure an apparatus for graphics processing comprises a graphics processing unit GPU configured to access a first memory unit according to one of an unsecure mode and a secure mode the GPU comprising a memory access controller configured to allow the GPU to read data from only an unsecure portion of the first memory unit when the GPU is in the unsecure mode and configured to allow the GPU to write data only to a secure portion of the first memory unit when the GPU is in the secure mode.

In another example of the disclosure a method of graphics processing comprises accessing with a graphics processing unit GPU a first memory unit according to one of an unsecure mode and a secure mode wherein accessing comprises allowing the GPU to read data from only an unsecure portion of the first memory unit when the GPU is in the unsecure mode and allowing the GPU to write data only to a secure portion of the first memory unit when the GPU is in the secure mode.

In another example of the disclosure an apparatus configured for graphics processing comprises means for accessing with a graphics processing unit GPU a first memory unit according to one of an unsecure mode and a secure mode wherein the means for accessing comprises means for allowing the GPU to read data from only an unsecure portion of the first memory unit when the GPU is in the unsecure mode and means for allowing the GPU to write data only to a secure portion of the first memory unit when the GPU is in the secure mode.

The details of one or more examples are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

This disclosure relates to techniques for graphics processing and more specifically to techniques for hardware enforced content protection for a graphics processing unit GPU .

Modern operating systems including open platforms e.g. Android or other open source platforms and closed platforms e.g. Microsoft Windows are not typically trusted in terms of protecting secure content which is streamed to or processed by such open platforms. While modern operating systems provide a level of security via the user kernel mode separation ultimately components of kernel mode both in closed platforms and particularly in open platforms do not provide a strong level of trust. Kernel mode drivers can easily be installed and a malicious kernel mode driver naturally bypasses the security boundary. Kernel mode hardware drivers in such open platforms are used to control the operation of hardware e.g. graphics processing units GPUs that may process secure content. However because such drivers are often open source and or not considered to be secure in relation to protected content they are more susceptible to alteration by third parties. Such alterations may cause the protected content e.g. digital rights managed DRM content that is streamed through or processed by the hardware controlled by such drivers to be stored in unsecure memories and copied. As such control of secure content on open platforms is often difficult. To address this problem this disclosure proposes a method and apparatus whereby access to secure memory is controlled by the hardware itself e.g. by a GPU .

Rather than controlling hardware access to secure or unsecure memory directly through driver code this disclosure proposes in one example using the graphics driver e.g. an open source unsecure driver to only place the GPU in either a secure mode or an unsecure mode. Once placed in the secure mode the GPU components that can read the secure memory are restricted to only making writes into the secure memory region. This prevents an untrusted driver from using the GPU to copy memory content from the secure memory region to an unsecure memory region.

In this secure mode the GPU can read both secure e.g. copy protected CP content as well as unsecure content e.g. content stored in an unsecured memory . In the unsecure mode the GPU is denied all access to secure memory. In this way even if the unsecure driver were altered to place the GPU in an unsecure mode the GPU itself would be prevented from reading any data from a secure memory. As such access to secure content in the secure memory is prevented.

In one example of the disclosure an apparatus for graphics processing comprises a graphics processing unit GPU configured to access a first memory unit according to one of an unsecure mode and a secure mode the GPU comprising a memory access controller configured to allow the GPU to read data from only an unsecure portion of the first memory unit when the GPU is in the unsecure mode and configured to allow the GPU to write data only to a secure portion of the first memory unit when the GPU is in the secure mode.

As illustrated in the example of computing device may include a user input interface a central processing unit CPU one or more memory controllers a system memory a graphics processing unit GPU a graphics memory a display interface a display and buses and . Note that in some examples graphics memory may be on chip with GPU . In some cases all hardware elements show in may be on chip for example in a system on a chip SoC design. User input interface CPU memory controllers GPU and display interface may communicate with each other using bus . Memory controllers and system memory may also communicate with each other using bus . Buses may be any of a variety of bus structures such as a third generation bus e.g. a HyperTransport bus or an InfiniBand bus a second generation bus e.g. an Advanced Graphics Port bus a Peripheral Component Interconnect PCI Express bus or an Advanced eXentisible Interface AXI bus or another type of bus or device interconnect. It should be noted that the specific configuration of buses and communication interfaces between the different components shown in is merely exemplary and other configurations of computing devices and or other graphics processing systems with the same or different components may be used to implement the techniques of this disclosure.

CPU may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause CPU to execute one or more software applications. The software applications that execute on CPU may include for example an operating system a word processor application an email application a spread sheet application a media player application a video game application a graphical user interface application or another program. Additionally CPU may execute a GPU driver for controlling the operation of GPU . The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad a touch screen or another input device that is coupled to computing device via user input interface .

The software applications that execute on CPU may include one or more graphics rendering instructions that instruct CPU to cause the rendering of graphics data to display . In some examples the software instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API an Open Computing Language OpenCL API a Direct3D API an X3D API a RenderMan API a WebGL API or any other public or proprietary standard graphics API. In order to process the graphics rendering instructions CPU may issue one or more graphics rendering commands to GPU e.g. through GPU driver to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

Memory controllers facilitate the transfer of data going into and out of system memory . For example memory controllers may receive memory read and write commands and service such commands with respect to memory system in order to provide memory services for the components in computing device . Memory controllers are communicatively coupled to system memory via memory bus . Although memory controllers are illustrated in as being a processing module that is separate from both CPU and system memory in other examples some or all of the functionality of memory controller may be implemented on one or any of CPU GPU and system memory . System memory may comprise one or memory units. The memory units may be divided physically e.g. separate physical disks or solid state memory units or may be divided by memory address range. In particular system memory may be divided into two or more memory units consisting of secure memory units and unsecure memory units. Secure memory units may utilize encryption and or other digital rights management DRM techniques to prevent access copying or deciphering of data stored thereon.

Memory controllers may also include one or more memory management units MMUs including an IOMMU i.e. input output MMU for controlling device access e.g. a GPU to system memory . The memory management units may implement a virtual memory system. The virtual memory space may be divided into a plurality of virtual pages. These virtual pages may be contiguous but the physical pages in system memory to which these virtual pages correspond may not be contiguous in system memory . Pages may be considered as the minimum units that an MMU may be able to manage.

Modern operating systems OS that run on central processing units CPUs typically use a virtual memory scheme for allocating memory to multiple programs operating on the CPU. Virtual memory is a memory management technique that virtualizes a computer system s physical memory e.g. RAM disk storage etc. so that an application need only refer to one set of memory i.e. the virtual memory . Virtual memory consists of contiguous address spaces that are mapped to locations in physical memory. In this way the fragmentation of physical memory is hidden from the applications which instead may interact with contiguous blocks of virtual memory. The contiguous bocks in virtual memory are typically arranged into pages. Each page is some fixed length of contiguous blocks of virtual memory addresses. Mapping from the virtual memory to the physical memory is often handled by a memory management unit MMU . Virtual memory space that is currently mapped to locations in physical memory is considered to be backed to physical memory.

The mapping of locations in virtual memory space to physical memory is stored with a translation lookaside buffer TLB . The TLB is used by the MMU to quickly translate virtual addresses to physical addresses. The TLB may be implemented as a content addressable memory CAM that uses a virtual memory address as an input and outputs a physical memory address. The MMU may then quickly retrieve the requested data using the output physical memory address.

Physical page may be stored across multiple memory units of system memory . For example physical page may encompass both memory unit A and memory unit N. In one example memory unit A is a secure memory unit and memory unit N is an unsecure memory unit. Memory unit A may store a portion of physical page indicated as portion A and memory unit N may store a portion of physical page indicated as portion B. As illustrated memory unit A stores section 0 and section 2 of physical page and memory unit N stores section 1 and section 3 of physical page .

The example of only includes two memory units for purposes of illustration but any number of memory units may be used. For instance referring back to GPU driver may transmit instructions that cause GPU to store pixel values or any other computed value and may transmit the virtual addresses for where the pixel value are to be stored. GPU in turn may request IOMMU to store the pixel values in accordance with the virtual addresses. IOMMU in turn may map the virtual addresses to physical addresses and store the pixel values in pages of system memory in an interleaving manner based on the physical addresses.

Returning to system memory may store program modules and or instructions that are accessible for execution by CPU and or data for use by the programs executing on CPU . For example system memory may store a window manager application that is used by CPU to present a graphical user interface GUI on display . In addition system memory may store user applications and application surface data associated with the applications. System memory may additionally store information for use by and or generated by other components of computing device . For example system memory may act as a device memory for GPU and may store data to be operated on by GPU as well as data resulting from operations performed by GPU . For example system memory may store DRM protected game content or decoded video produced by GPU . In this situation such DRM protected content is preferably stored in a secure memory unit of system memory . As other examples system memory may store other graphics data such as any combination of texture buffers depth buffers stencil buffers vertex buffers frame buffers or the like. System memory may include one or more volatile or non volatile memories or storage devices such as for example random access memory RAM static RAM SRAM dynamic RAM DRAM read only memory ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

GPU may be configured to perform graphics operations to render one or more graphics primitives to display . Thus when one of the software applications executing on CPU requires graphics processing CPU may provide graphics commands and graphics data to GPU for rendering to display . The graphics data may include e.g. drawing commands state information primitive information texture information etc. GPU may in some instances be built with a highly parallel structure that provides more efficient processing of complex graphic related operations than CPU . For example GPU may include a plurality of processing elements that are configured to operate on multiple vertices or pixels in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to draw graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than drawing the scenes directly to display using CPU .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry.

GPU may be directly coupled to graphics memory . Thus GPU may read data from and write data to graphics memory without using bus . In other words GPU may process data locally using a local storage instead of using other slower system memory. This allows GPU to operate in a more efficient manner by eliminating the need of GPU to read and write data via system bus which may experience heavy bus traffic. In some instances however GPU may not include a separate memory but instead utilize system memory via bus . Graphics memory may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

CPU and or GPU may store rendered image data in a frame buffer . Typically frame buffer would be allocated within system memory but may in some circumstances be an independent memory. Display interface may retrieve the data from frame buffer and configure display to display the image represented by the rendered image data. In some examples display interface may include a digital to analog converter DAC that is configured to convert the digital values retrieved from the frame buffer into an analog signal consumable by display . In other examples display interface may pass the digital values directly to display for processing. Display may include a monitor a television a projection device a liquid crystal display LCD a plasma display panel a light emitting diode LED array such as an organic LED OLED display a cathode ray tube CRT display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit. Display may be integrated within computing device . For instance display may be a screen of a mobile telephone or tablet computer. Alternatively display may be a stand alone device coupled to computer device via a wired or wireless communications link. For instance display may be a computer monitor or flat panel display connected to a personal computer via a cable or wireless link.

As shown in graphics processing pipeline may include a command engine a geometry processing stage a rasterization stage and a pixel processing pipeline . Each of the components in graphics processing pipeline may be implemented as fixed function components programmable components e.g. as part of a shader program executing on a programmable shader unit or as a combination of fixed function and programmable components. Memory available to CPU and GPU may include system memory that may itself include frame buffer . Frame buffer may store rendered image data.

Software application may be any application that utilizes the functionality of GPU . For example software application may be a GUI application an operating system a portable mapping application a computer aided design program for engineering or artistic applications a video game application or another type of software application that uses 2D or 3D graphics. Software application may also be an application that uses the GPU to perform more general calculations such as in a GPGPU application.

Software application may include one or more drawing instructions that instruct GPU to render a graphical user interface GUI and or a graphics scene. For example the drawing instructions may include instructions that define a set of one or more graphics primitives to be rendered by GPU . In some examples the drawing instructions may collectively define all or part of a plurality of windowing surfaces used in a GUI. In additional examples the drawing instructions may collectively define all or part of a graphics scene that includes one or more graphics objects within a model space or world space defined by the application.

Software application may invoke GPU driver via graphics API to issue one or more commands to GPU for rendering one or more graphics primitives into displayable graphics images. For example software application may invoke GPU driver via graphics API to provide primitive definitions to GPU . In some instances the primitive definitions may be provided to GPU in the form of a list of drawing primitives e.g. triangles rectangles triangle fans triangle strips etc. The primitive definitions may include vertex specifications that specify one or more vertices associated with the primitives to be rendered. The vertex specifications may include positional coordinates for each vertex and in some instances other attributes associated with the vertex such as e.g. color coordinates normal vectors and texture coordinates. The primitive definitions may also include primitive type information e.g. triangle rectangle triangle fan triangle strip etc. scaling information rotation information and the like. Based on the instructions issued by software application to GPU driver GPU driver may formulate one or more commands that specify one or more operations for GPU to perform in order to render the primitive. When GPU receives a command from CPU graphics processing pipeline decodes the command and configures one or more processing elements within graphics processing pipeline to perform the operation specified in the command. After performing the specified operations graphics processing pipeline outputs the rendered data to frame buffer associated with a display device. Graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode.

GPU driver may be further configured to compile one or more shader programs and to download the compiled shader programs onto one or more programmable shader units contained within GPU . The shader programs may be written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language etc. The compiled shader programs may include one or more instructions that control the operation of a programmable shader unit within GPU . For example the shader programs may include vertex shader programs and or pixel shader programs. A vertex shader program may control the execution of a programmable vertex shader unit or a unified shader unit and include instructions that specify one or more per vertex operations. A pixel shader program may include pixel shader programs that control the execution of a programmable pixel shader unit or a unified shader unit and include instructions that specify one or more per pixel operations. In accordance with some examples of this disclosure a pixel shader program may also include instructions that selectively cause texture values to be retrieved for source pixels based on corresponding destination alpha values for the source pixels.

Graphics processing pipeline may be configured to receive one or more graphics processing commands from CPU via graphics driver and to execute the graphics processing commands to generate displayable graphics images. As discussed above graphics processing pipeline includes a plurality of stages that operate together to execute graphics processing commands. It should be noted however that such stages need not necessarily be implemented in separate hardware blocks. For example portions of geometry processing stage and pixel processing pipeline may be implemented as part of a unified shader unit. Again graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode.

Command engine may receive graphics processing commands and configure the remaining processing stages within graphics processing pipeline to perform various operations for carrying out the graphics processing commands. The graphics processing commands may include for example drawing commands and graphics state commands. The drawing commands may include vertex specification commands that specify positional coordinates for one or more vertices and in some instances other attribute values associated with each of the vertices such as e.g. color coordinates normal vectors texture coordinates and fog coordinates. The graphics state commands may include primitive type commands transformation commands lighting commands etc. The primitive type commands may specify the type of primitive to be rendered and or how the vertices are combined to form a primitive. The transformation commands may specify the types of transformations to perform on the vertices. The lighting commands may specify the type direction and or placement of different lights within a graphics scene. Command engine may cause geometry processing stage to perform geometry processing with respect to vertices and or primitives associated with one or more received commands.

Geometry processing stage may perform per vertex operations and or primitive setup operations on one or more vertices in order to generate primitive data for rasterization stage . Each vertex may be associated with a set of attributes such as e.g. positional coordinates color values a normal vector and texture coordinates. Geometry processing stage modifies one or more of these attributes according to various per vertex operations. For example geometry processing stage may perform one or more transformations on vertex positional coordinates to produce modified vertex positional coordinates. Geometry processing stage may for example apply one or more of a modeling transformation a viewing transformation a projection transformation a ModelView transformation a ModelViewProjection transformation a viewport transformation and a depth range scaling transformation to the vertex positional coordinates to generate the modified vertex positional coordinates. In some instances the vertex positional coordinates may be model space coordinates and the modified vertex positional coordinates may be screen space coordinates. The screen space coordinates may be obtained after the application of the modeling viewing projection and viewport transformations. In some instances geometry processing stage may also perform per vertex lighting operations on the vertices to generate modified color coordinates for the vertices. Geometry processing stage may also perform other operations including e.g. normal transformations normal normalization operations view volume clipping homogenous division and or backface culling operations.

Geometry processing stage may produce primitive data that includes a set of one or more modified vertices that define a primitive to be rasterized as well as data that specifies how the vertices combine to form a primitive. Each of the modified vertices may include for example modified vertex positional coordinates and processed vertex attribute values associated with the vertex. The primitive data may collectively correspond to a primitive to be rasterized by further stages of graphics processing pipeline . Conceptually each vertex may correspond to a corner of a primitive where two edges of the primitive meet. Geometry processing stage may provide the primitive data to rasterization stage for further processing.

In some examples all or part of geometry processing stage may be implemented by one or more shader programs executing on one or more shader units. For example geometry processing stage may be implemented in such examples by a vertex shader a geometry shader or any combination thereof. In other examples geometry processing stage may be implemented as a fixed function hardware processing pipeline or as a combination of fixed function hardware and one or more shader programs executing on one or more shader units.

Rasterization stage is configured to receive from geometry processing stage primitive data that represents a primitive to be rasterized and to rasterize the primitive to generate a plurality of source pixels that correspond to the rasterized primitive. In some examples rasterization stage may determine which screen pixel locations are covered by the primitive to be rasterized and generate a source pixel for each screen pixel location determined to be covered by the primitive. Rasterization stage may determine which screen pixel locations are covered by a primitive by using techniques known to those of skill in the art such as e.g. an edge walking technique evaluating edge equations etc. Rasterization stage may provide the resulting source pixels to pixel processing pipeline for further processing.

The source pixels generated by rasterization stage may correspond to a screen pixel location e.g. a destination pixel and be associated with one or more color attributes. All of the source pixels generated for a specific rasterized primitive may be said to be associated with the rasterized primitive. The pixels that are determined by rasterization stage to be covered by a primitive may conceptually include pixels that represent the vertices of the primitive pixels that represent the edges of the primitive and pixels that represent the interior of the primitive.

Pixel processing pipeline is configured to receive a source pixel associated with a rasterized primitive and to perform one or more per pixel operations on the source pixel. Per pixel operations that may be performed by pixel processing pipeline include e.g. alpha test texture mapping color computation pixel shading per pixel lighting fog processing blending a pixel ownership text a source alpha test a stencil test a depth test a scissors test and or stippling operations. In addition pixel processing pipeline may execute one or more pixel shader programs to perform one or more per pixel operations. The resulting data produced by pixel processing pipeline may be referred to herein as destination pixel data and stored in frame buffer . The destination pixel data may be associated with a destination pixel in frame buffer that has the same display location as the source pixel that was processed. The destination pixel data may include data such as e.g. color values destination alpha values depth values etc.

Frame buffer stores destination pixels for GPU . Each destination pixel may be associated with a unique screen pixel location. In some examples frame buffer may store color components and a destination alpha value for each destination pixel. For example frame buffer may store Red Green Blue Alpha RGBA components for each pixel where the RGB components correspond to color values and the A component corresponds to a destination alpha value. Pixel values may also be represented by a luma component Y and one or more chroma components e.g. U and V . Although frame buffer and system memory are illustrated as being separate memory units in other examples frame buffer may be part of system memory .

General purpose shader may be any application executable on GPU to perform calculations. Typically such calculations are of the type that take advantage of the highly parallel structure of GPU processing cores including arithmetic logic units ALUs . An example general purpose shader may conform to the OpenCL API. OpenCL is an API that allows an application to have access across multiple processors in a heterogeneous system e.g. a system including a CPU GPU DSP etc. . Typically in an OpenCL conforming application GPU would be used to perform non graphical computing. Examples of non graphical computing applications may include physics based simulations fast Fourier transforms audio signal processing digital image processing video processing image post filtering computational camera climate research weather forecasting neural networks cryptography and massively parallel data crunching among many others.

Unsecure memory and secure memory may be any type of memory including one or more volatile or non volatile memories or storage devices. Example memory and storage devices include RAM SRAM DRAM ROM EPROM EEPROM Flash memory magnetic data media or optical storage media. Secure memory includes additional features not found in unsecure memory . For example secure memory may utilize encryption authentication and or other digital rights management techniques to prevent access to copying of or deciphering of data stored thereon.

GPU controls where data is read from and written to using memory access controller . Memory access controller is responsive to the mode GPU is operating under i.e. secure mode or unsecure mode and makes read write decisions based on the mode.

In one example the GPU memory mode is set by GPU driver operating on CPU . GPU driver may change the memory mode in GPU in several different ways. In one example GPU driver make directly write a value into a register in GPU that indicates to GPU which memory mode to use e.g. secure mode or unsecure mode . In another example GPU may include one or more instructions in a command stream executable by GPU that instruct GPU itself to write a certain value to a register that indicates which memory mode to use. In this way GPU driver may only select the memory mode that the GPU operates under and does not make any direct instructions that specifies which data is to be written to which memory. In this way even if GPU driver were altered to place GPU in an unsecure mode through the function of memory access controller GPU would prevent any read access from secure memory as memory access controller is only able to read from unsecure memory in the unsecure mode. Likewise even if GPU were altered to place GPU in a secure mode through the function of memory access controller GPU would prevent any write access to unsecure memory as memory access controller is only able to write to secure memory in the secure mode.

In one example memory controller accesses secure and unsecure memory units via secure and unsecure memory management unit MMU page tables respectively. In this example virtual address ranges are provided to GPU by GPU driver . The virtual address ranges include a range of virtual addresses for the secure memory and a range of virtual addresses for the unsecure memory. When placed in secure mode by GPU driver GPU would utilize the range of virtual addresses for the secure memory to perform reads and writes. GPU would also be able to use the range of virtual addresses for the unsecure memory to perform reads in the secure mode but not to perform writes. When placed in unsecure mode by GPU driver GPU would utilize the range of virtual addresses for the unsecure memory to perform reads and writes.

In one example memory access controller routes reads and writes to the appropriate memory units i.e. secure memory or unsecure memory by determining if the virtual address used in the read or write request are within an unsecure range of virtual memory addresses or within a secure range of virtual addresses. Based on the range determination memory access controller utilizes one of unsecure IOMMU or secure IOMMU .

Unsecure IOMMU is an IOMMU that is configured to map virtual memory addresses to physical memory addresses in unsecure memory . Secure IOMMU is an IOMMU that is configured to map virtual memory addresses to physical memory addresses in secure memory . Unsecure IOMMU performs the mappings to unsecure memory using an unsecure page table. The unsecure page table is a page table that maps a range of virtual memory addresses e.g. the range provided by GPU driver to locations in unsecure memory . Likewise secure IOMMU performs the mappings to secure memory using a secure page table. The secure page table is a page table that maps a range of virtual memory addresses e.g. the range provided by GPU driver to locations in secure memory . As depicted in unsecure IOMMU and secure IOMMU are part of a single IOMMU . In effect IOMMU becomes a secure IOMMU when it is operating with a secure page table and becomes an unsecure IOMMU when it is operating with an unsecure page table. In other examples unsecure IOMMU and secure IOMMU may be physically separate MMUs.

In one example of the disclosure both secure and unsecure page tables are provided to secure IOMMU and unsecure IOMMU by secure operating system OS executing on CPU . A secure OS is an OS that operates alongside a normal rich OS e.g. Apple iOS Google Android Microsoft Windows etc. . The secure OS provides security applications to protect and separate a secure kernel and any secure peripherals e.g. secure IOMMU from any code running on the rich OS e.g. GPU driver . An example of a secure OS is the TrustZone software made by ARM Holdings. In general a secure OS is considered to be much less susceptible to alteration and attack than software running on a rich OS including software such as graphics drivers. In accordance with the techniques of this disclosure only the secure OS is allowed to update the page tables for mapping virtual memory address ranges to physical memory addresses. As such any attempt to alter the graphics driver including the virtual address ranges provided by the driver will not result in secure content being stored in unsecure memory as only the secure OS provides the ultimate mappings to secure and unsecure memory.

In the example where both the secure and unsecure page tables are available at IOMMU i.e. IOMMU consists of both unsecure IOMMU and secure IOMMU GPU is able to read data from both unsecure memory and secure memory in secure mode. The other read write restrictions still apply. That is in secure mode writes are only made to secure memory by GPU and in unsecure mode both reads and writes by GPU are limited to unsecure memory .

In another example of the disclosure rather than having both a secure and unsecure IOMMU available to the GPU where data traffic is directed to either the secure or unsecure IOMMU via memory access controller only one IOMMU i.e. either unsecure IOMMU or secure IOMMU would be made available to GPU depending on the selected memory mode. That is if the memory mode is the unsecure mode secure OS only provides page table mappings for the unsecure IOMMU . In this situation the secure IOMMU would be unavailable. If the memory mode is the secure mode secure OS only provides page table mappings for the secure IOMMU . In this situation the unsecure IOMMU would be unavailable. This example of only having one IOMMU available per memory mode would provide a more simple implementation where both reads and writes were restricted per memory mode. That is only reads and writes to secure memory by GPU would be allowed in secure mode while only reads and writes to unsecure memory by GPU would be allowed in unsecure mode. This differs slightly from the approach described above where both IOMMUs may be available in that the secure mode would no longer allow for reads for unsecure memory .

Even when in secure mode there are some writes other than the ultimate output product of GPU which would be better for GPU to write to unsecure memory. These writes include the communication tokens between GPU and graphics driver . Such data includes timestamps and other ancillary data and control data such as counter data and query data. GPU uses memory e.g. unsecure memory to communicate such timestamps and data back to the driver. Since the graphics driver is untrusted the memory involved in the communication path needs to be unsecure e.g. unsecure memory . As one example when GPU reaches a certain point in processing GPU writes a timestamp sequential marker to memory. Graphics driver uses this information to determine how far the GPU has proceeded in a specific command stream. This determination for example allows graphics driver to release memory objects that GPU is operating on once GPU finishes. There are many other types of signaling and communication paths GPU uses memory writes for providing information to graphics driver . As another example graphics driver can request GPU to report performance counters after a drawcall. GPU then writes these performance counters to a memory location e.g. in unsecure memory specified by graphics driver .

To solve this exception to the general rule above that GPU does not write to unsecure memory in secure more GPU hardware may be modified such that certain hardware blocks are configured to have unsecure memory accesses while also not having access to data paths and caches that connect to or contain secure content when the GPU is running in secure mode.

Other hardware blocks of GPU may also be configured to only have access to unsecure memory. For example a primitive control PC unit and a visibility stream compressor VSC may be configured to only have access to unsecure memory. A PC unit controls how a primitive e.g. a triangle progresses or walks through a graphics pipeline e.g. graphics 3D processing pipeline of . A VSC is used in a tile based or deferred rendering scheme to compress and manage a visibility stream. In general it may be beneficial in some circumstances to avoid requiring certain hardware blocks to write to secure memory. Such circumstances include situations where hardware blocks are not writing secure content and when hardware blocks are writing control data needed by a graphics driver.

Other hardware blocks in store content to unsecure memory or secure memory based on the techniques described above. That is in unsecure mode data may only be read from or written to unsecure memory. No data may be read from secure memory in unsecure mode. In secure mode data may only be written to secure memory. No data may be written to unsecure memory in secure mode. However in secure mode in some examples data may be read from both secure memory and unsecure memory. These additional hardware blocks of GPU that may access memory according to the memory mode include vertex fetch decode VFD unit high level sequencer HLSQ vertex shader VS pixel shader PS and render backend RB . VFD is responsible for fetching vertex data at the request of PC . HLSQ controls the shader processors i.e. the programmable processors on the GPU that execute shader code populating the correct state for the job being executed and launching jobs into the shader processor. VS is a vertex shader executing on the shader processor. For example VS may include vertex shader code that executes geometry processing stage of graphics 3D processing pipeline of . PS is a pixel shader executing on the shader processor. For example PS may include pixel shader code that executes pixel processing pipeline of graphics 3D processing pipeline of . Render backend RB is responsible for writing and reading pixels for the depth buffer and stencil buffer.

When the GPU transitions from secure mode to unsecure mode there may be secure content remaining within the GPU s various caches memories and registers. In one example of the disclosure a mechanism is provided to clear and or invalidate the various storage units of GPU that may hold secure content before allowing an unsecure job using the unsecure memory mode to launch on the GPU. In this context clearing a memory means that data stored in the memory is erased and or allowed to be overwritten. In practice clearing may involve de allocating all memory addresses for the memory unit such that all data in the memory unit may be overwritten. In other examples clearing may involve overwriting all data in the memory unit e.g. with all 1 s or all 0 s such that any previously stored data is no longer available. If a memory unit is not cleared an unsecure job could copy the trailing remains of secure data to unsecure memory. This problem can be solved via secure software techniques hardware techniques or a combination of both techniques. Regardless the clearing and transition to unsecure may be an atomic operation since this operation is triggered by the unsecure driver. In this context an atomic operation includes the clearing of internal GPU memories together i.e. atomically with the transition back to unsecure mode. For example there must be a single command that does both changing modes and clearing internal memories otherwise malicious software could just perform the transition back to an unsecure mode and not execute the clearing operation.

In some examples it may not be necessary to clear all storage units of GPU when transitioning from secure mode to unsecure mode. Instead only a portion of the storage units need to be cleared to effectively prevent unauthorized access to secure content. As one example only have the content stored need be cleared. As another example every other chunk of data e.g. every other 32 bytes of data may be cleared.

In one example of the disclosure accessing the first memory unit includes allowing GPU to read data from only an unsecure portion of the first memory unit when GPU is in the unsecure mode and allowing GPU to write data only to a secure portion of the first memory unit when GPU is in the secure mode. In a further example of the disclosure accessing the first memory unit further includes allowing GPU to write data to only the unsecure portion of the first memory unit when GPU is in the unsecure mode and allowing GPU to read data from the secure portion and the unsecure portion of the first memory unit when GPU is in the secure mode. In the case that GPU is placed in the secure mode GPU writes data to the secure portion of the first memory unit by utilizing a secure memory management unit the secure memory management unit utilizing a secure page table containing address ranges for the secure portion of the first memory unit. In the case that GPU is placed in the unsecure mode GPU reads data from the unsecure portion of the first memory unit by utilizing an unsecure memory management unit the unsecure memory management unit utilizing an unsecure page table containing address ranges for the unsecure portion of the first memory unit. In another example of the disclosure GPU may be configured to write data to the unsecure portion of the first memory with a front end command processor regardless of whether the GPU is in the unsecure mode or the secure mode.

In one example of the disclosure reading and writing data according to a virtual memory address from a range of virtual memory address wherein the range of virtual memory addresses includes the first range of virtual memory addresses relating to entries in the secure page table utilized by the secure memory management unit and the second range of virtual memory addresses relating to entries in the unsecure page table utilized by the unsecure memory management unit. In further example of the disclosure a secure operating system e.g. secure OS may be configured to supply the secure page table to the secure memory management unit and the unsecure page table to the unsecure memory management unit.

In another example of the disclosure the secure operating system may be further configured to send an instruction from the secure operating system to a clear register of the GPU that causes the GPU to clear and invalidate at least some content from one or more internal memories when the GPU is transitioned from the secure mode to the unsecure mode. In another example of the disclosure the secure operating system may be configured to send an instruction from the graphics driver to a command stream register of the GPU that causes the GPU to clear and invalidate at least some content from one or more internal memories when the GPU is transitioned from the secure mode to the unsecure mode.

The above described solutions for clearing secure content from the GPU on a switch to unsecure mode are just examples. The transitioning of the GPU between secure and unsecure modes could be done in various manners. The simplest means would be an externally visible register e.g. MMIO that either a graphics driver or a secure driver surrogate could write as described above. This may require however a hard synchronization between driver and GPU hardware at the point in time the transition must happen.

It may be preferable to allow this switch to happen within the command stream that the driver presents to the GPU. This allows the driver to queue up large amounts of work including secure and unsecure jobs interleaved with each other. The preambles of these jobs would include a command to the GPU to switch into the mode required by the job in question. From an application point of view this would result in application GPU contexts that were either secure or unsecure.

In one or more examples the functions described above may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored as one or more instructions or code on an article of manufacture comprising a non transitory computer readable medium. Computer readable media may include computer data storage media. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices flash memory or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and Blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more DSPs general purpose microprocessors ASICs FPGAs or other equivalent integrated or discrete logic circuitry. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs e.g. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various examples have been described. These and other examples are within the scope of the following claims.

