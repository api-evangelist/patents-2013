---

title: System and method for discovering story trends in real time from user generated content
abstract: A method for identifying story trends includes identifying a set of words in a fixed size data stream based on a subword cache, and electronically determining at least one story trend associated with the set of words and electronically generating a story hash associated with the set of words. The method also includes storing the story hash in a story trend cache and updating the story trend cache according to the story hash, and retrieving one or more popular story topics according to the story trend cache. Machine readable media including program code that causes execution of a method for generating search results also are described.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09235635&OS=09235635&RS=09235635
owner: Yahoo! Inc.
number: 09235635
owner_city: Sunnyvale
owner_country: US
publication_date: 20130403
---
This application is a continuation of U.S. application Ser. No. 12 701 185 filed on Feb. 5 2010. The disclosure of this prior application from which priority is claimed is incorporated herein by reference for all purposes.

The present invention generally relates to discovering trending stories in real time from user generated content. More specifically the present invention are directed towards systems and methods for utilizing a multi tier most heavily used MHU cache environment for automatically identifying and ranking stories contain in user generated content such as real time data streams.

Emerging technologies focusing on user generated content have greatly increased the amount of data transmitted across the Internet on a daily basis. The growth of services allowing users to publish streams of data has allowed for expansive coverage of current events news topics and other data. However the explosive influx of user generated content provides significant problems in data analysis and aggregation. Furthermore this influx of data provides for novel issues in extracting relevant topics due to the diversity of language culture slang and various other factors that affect the semantics of user generated streams of data.

User generated data streams when aggregated allow for efficient discovery of hot news and trending topics. Previous efforts in aggregating user generated data streams have been to trend keywords in the data stream. This technique does not give a full view of why users are generating given keywords. The generated streams usually tend to break up the story depending on the user mood. For example user generated streams directed to the same topic may vary as follows 

Currently the trends in these user generated streams are surfaced as ebay announce deal sell skype because users write about the same topics differently. The current state of the art fails to cohesively analyze user generated streams to account for the variance in terminology used across a diverse data set. The present invention provides a solution allowing a system to intelligently parse and identify key trending topics and store topics or stories for subsequent analysis and retrieval.

The present invention is directed towards systems and methods for discovering story trends. The method of the present invention comprises receiving a data stream. In one embodiment receiving a data stream may comprise receiving a user generated data stream. In particular embodiments the data stream may be of a fixed size e.g. a fixed number of characters per user generated content .

The method then identifies a first plurality of words within the data stream and generates a second set of words wherein the second set of words comprises a plurality of words present in the data stream and present in a word cache. In one embodiment identifying a first plurality of terms within the data stream may comprise splitting the receiving data stream at the word boundary wherein identifying a first plurality of terms within the data stream further comprises ignoring a plurality of words shorter than a predetermined threshold.

The method then parses the second set of words and identifies a third set of words present within the second set and present within a subword cache. In one embodiment parsing the second set of words may comprise ignoring a plurality of words based on pre defined word characteristics wherein ignoring a plurality of words based on pre defined word characteristics comprises ignoring prepositions within the second set of words.

In one embodiment the method further comprises incrementing a counter in the word cache the counter being associated with an identified word within the second set of words. In alternative embodiments the method further comprises incrementing a counter in the subword cache the counter associated with an identified word within the third set of words.

The method generates a story hash based on the third set of words and stores the story hash and the third set of words. In one embodiment generating a story hash based on the third set of words may comprise generating a SimHash based on the third set of words. In an alternative embodiment the method may further comprise receiving a request for stories from a user calculating a hamming distance between identified story hashes and providing a plurality of stories to the user.

The present invention further comprises a system for discovering story trends. The system comprises a plurality of client devices and a plurality of data sources coupled to a network. The system further comprises a web server operable to receive and transmit data to and from the client devices and data sources. In one embodiment the web server may be further operable to receiving a request for stories from a user and provide a plurality of stories to the user.

The system further comprises a word parser operable to receive a data stream identify a first plurality of words within the data stream and generate a second set of words wherein the second set of words comprises a plurality of words present in the data stream and present in a word cache. In one embodiment the word parser is further operable to receive a user generated data stream. In alternative embodiments the word parser is further operable to split the receiving data stream at the word boundary and ignore a plurality of words shorter than a predetermined threshold.

The system further comprises a subword parser operative to parse the second set of words and identify a third set of words present within the second set and present within a subword cache. In one embodiment the subword parser is further operable to ignore a plurality of words based on pre defined word characteristics. In an alternative embodiment the subword parser is further operable to ignore prepositions within the second set of words.

In one embodiment the word parser is further operable to increment a counter in the word cache the counter being associated with an identified word within the second set of words. In an alternative embodiment the subword parser is further operable to increment a counter in the subword cache the counter being associated with an identified word within the third set of words.

The system further comprises a hash calculator operable to generate a story hash based on the third set of words a story cache operable to store the story hash and a story lookup table operable to store the third set of words associated with the story hash. In one embodiment the hash calculator is further operable to generate a SimHash based on the third set of words. In alternative embodiments the system may further comprise a hamming distance calculator operable calculating a hamming distance between identified story hashes.

In the following description reference is made to the accompanying drawings that form a part hereof and in which is shown by way of illustration specific embodiments in which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

Although illustrated as single discrete components alternative embodiments exist wherein the illustrated devices may be distributed across multiple hardware devices. Additionally the devices may be distributed geographically in addition to physically.

In the illustrated embodiment a plurality of client devices may be operative to transmit data through network to data sources and content provider . In one embodiment data sources may comprise third party data aggregators operative to receive data from client devices and store process and present the data to client devices . For example data sources and may be operative to receive data such as text strings submitted by a user such as status updates hyperlinks story titles etc. That is data may comprise an updated such as going to the movie indicating user status ebay to announce skype deal http example.com indicating news stories or various other discrete data. In alternative embodiments client devices may transmit real time data streams to content provider wherein content provider may store process and present data to other client devices 

In the illustrated embodiment content provider comprises the web server operative to handle incoming and outgoing web requests. Web server may comprise a combination of server hardware e.g. single or clustered servers comprising physical storage devices and server software e.g. Apache HTTP Server Microsoft IIS etc. .

Web server may be configured to actively crawl data sources to surface real time data streams wherein surfacing real time data streams comprises extracting the data streams from a large dataset such as the Internet. In one embodiment web server may be configured to access data from data sources via application programming interfaces API provided by data sources . Alternatively web server may surface data using techniques commonly known in the art of search engine indexing. In a further embodiment web server may be communicatively coupled to one or more application servers not shown operative to store executable software for surfacing of real time data streams.

Web server may transmit incoming data streams to word parser . In the illustrated embodiment of word parser splits the incoming data streams at the word boundary and ignores identified words that are shorter than a pre defined threshold for example but not limited in nature words shorter than three characters . In alternative embodiments word parser may remove commonly occurring words also known as stopwords. After the word parser identifies a plurality of words within the data stream the word parser queries the word cache to determine if the words have been previously identified.

In the illustrated embodiment word cache may implement a most heavily used MHU cache scheme wherein the most heavily identified words in the data stream are stored. For example word cache may store a plurality of terms and the number of times the term has been identified in an incoming data stream. In particular embodiments word cache may further store the word position of a given word that is the position of a word within a textual fragment. In one embodiment a MHU cache may comprise a plurality of fields including but not limited to an index value counter value and data value. The index value may uniquely identify a given data value in the cache while a counter value may be a constantly incremented and decremented value. The counter value may be incremented and decremented based on occurrences in a plurality of data streams. Additionally MHU cache may be configured to have a maximum size wherein only those values with the highest N counter values are kept while the data associated with the lowest counter values are discarded as other counter values are incremented.

After identifying a first list of words present within the word caches the word parser passes the first list to subword parser . In one embodiment the subword parser removes a plurality of words from the first list of parsed words. For example subword parser may remove all prepositions within the first list. Subword parser may first determine if the words are present within the subword caches . If the words are not present and space is available the subword parser may initialize a cache entry with a given word. Subword parser may then determine whether the parsed words appear within the subword caches . For each word found within the subword caches the subword parser may increment an identified count for the given word.

In particular embodiments word caches and subword caches may comprise similar or identical schemas. In particular both caches and may store a case insensitive word or term a position identifier and an increment counter. For example a word cache may utilize the following schema 

As illustrated in Tables 1 and 2 subword cache may comprise a pruned subset of word cache based on various textual metrics such as the exclusion of prepositions or other words.

After determining the relevant words in a data stream the subword parser transmits the filtered words to a hash calculator . Hash calculator is operative to generate a unique hash value for the filtered relevant terms. In one embodiment hash calculator uses a SimHash algorithm to determine the unique hash for a given word list. In certain embodiments the hash calculator may ignore the word position of a given word. In alternative embodiments hash calculator may include the word position when generating a hash value.

Hash calculator transmits the hashed data to story caches . In the illustrated embodiment story caches employ a similar structure to word caches and subword caches . In contrast to caches and story cache may be operative to store at least the hashed value of the identified word list and a counter value. Additionally hash calculator may transmit the hashed value and the associated word list to story lookup table .

Web server may additionally be operative to retrieve stories from story caches . Web server may transmit a request for stories to hamming calculator which in turn is operative to analyze hash values stored in story caches . In the illustrated embodiment hamming calculator calculates the hamming distance between stored hash values to merge related stories based on the proximity of the hash values. Alternatively web server may send requests directly to story caches which may indirectly request the hamming calculator to calculate a distance.

Hamming calculator may perform this merging at run time or on an ad hoc basis as entries are stored in story caches . Accordingly hamming calculator may retrieve a result set including the most popular story topics from story caches along with the associated human readable word list stored in story lookup table .

As described the above system of operates to identify the most popular story trends in a user generated content realm. Further detail and variations of the system methods are described with respect to .

In response to receiving data via the data stream the method splits the stream at the word boundary step and identifies words greater than a predetermined threshold. In one embodiment the method may identify only those words greater than three characters however other character threshold levels may be envisioned.

The method then selects an identified word step and for each word in the data stream determines if that word is present within a first level word cache step . In one embodiment the first level word cache may be of a fixed size e.g. fixed number of records . In this embodiment the method first determines if the word has been previously identified. If it has the method increments a counter associated with how many times the word has been found. If the word is not found the method may then determine if the word cache is full. If the word cache is not full the method may insert the word into the word cache. Alternatively if the word cache has been filled the method may determine if the word should replace an existing word within the word cache as discussed further herein.

If the method determines that the word is present within the word cache step the method then parses a subword list associated with the word step . In one embodiment the method may increment a word counter in a word cache if the word is identified in step . One embodiment of a method for parsing a subword list is described with respect to .

If the method determines that the word is not present in the word cache at the pointer location step the method decrements a word counter at the given pointer position step and increments the pointer . In one embodiment decrementing a word counter at a given position may comprise decrementing an integer value representing the number of times a given word has been identified at a position indicated by the pointer.

The method then determines if the decremented word counter results in a negative or zero value step . If the method has decremented the word counter to zero or below the method replaces the word step . If the counter is greater than zero the method continues to parse the incoming words step . In one embodiment replacing a word may comprise swapping the word value at the given pointer location and initializing the counter to one. After inserting a new word the method then initializes the subword list associated with the given word step .

The method first parses the data stream for subwords step . In the illustrated embodiment parsing a subword list may comprise removing a plurality of words from the data stream such as prepositions. Alternatively parsing the subword list may comprise other parsing techniques such as word replacement spell checking or other text parsing techniques known in the art.

The method then selects a given subword step and determines if the subword is present within a subword cache step . In one embodiment the method determines if a subword is present in the subword cache by determining that a subword at the same position in the stream exists within the subword cache. If the method determines that a subword is present within the cache the method adds the subword to a story word list and increments a counter associated with the subword in the subword cache step .

If the method determines that the subword is not present in the word cache at the pointer location step the method decrements a subword counter at the given pointer position step and increments the pointer . In one embodiment decrementing a subword counter at a given position may comprise decrementing an integer value representing the number of times a given word has been identified at a position indicated by the pointer.

The method then determines if the decremented subword counter results in a negative or zero value step . If the method has decremented the word counter to zero or below the method replaces the word step . If the counter is greater than zero the method continues to parse the incoming words step . In one embodiment replacing a subword may comprise swapping the word value at the given pointer location and initializing the counter to one.

The method determines if any subwords remain in the received subword list step . If subwords remain the method repeats steps and for the remaining subwords. After analyzing the received subwords the method generates a story hash for the identified story word list step . In one embodiment generating a story hash comprises generating a unique identifier for a given story word list. The story hash may ignore the word position of a given story word list. In alternative embodiments the story hash may include the word positions.

The method then determines whether the story hash has previously been included in a story cache step . If the story hash has not been stored within the story cache the method associates a sentence structure with the story word list step . In the illustrated embodiment associating a sentence structure with a story word list may comprise storing the story hash in a lookup table wherein the story hash has a one to one relationship with a particular sentence structure. The method at step may perform a similar operation as discussed with respect to steps and . That is the method may inspect a story hash entry at a given position. If the story hash is found the method may increment a story hash counter. If the story hash is not found the method may decrement a story hash counter. If the counter is less than or equal to zero the method may then replace and initialize a new story cache entry at a given position. For example a given hash value may be associated with a list of words and word positions. The method then inserts the story hash into the story cache and inserts the sentence structure into a story lookup table step . Additionally the method initializes a story counter to one.

If the method determines that the generated story hash has previously been identified the method identifies the story cache entry step and increments a story cache entry counter associated with the story hash step . In one embodiment incrementing a story cache entry counter may comprise incrementing an integer value associated with a story cache entry.

The method merges stories based on a hamming distance step . In one embodiment the method may merge stories at runtime based on a user request. In alternative embodiments the method may merge stories prior to receiving a request from a user. The method may employ various hamming distance algorithms known in the art to calculate the similarity between story cache entries. In this embodiment the method consolidates redundant story entries and provides a list of topical stories.

The method then identifies the top N stores step . In one embodiment the method may automatically determine the value of N. In alternative embodiments the method may utilize a statically determined value of N. For example the method may select the top ten most popular story topics in response to a user request. In alternative embodiments the method may utilize various other metrics to reduce the set of stories presented to a user. For example the method may analyze time and date characteristics of the retrieved stories to identify the newest or freshest stories identified by users.

The method then identifies human readable story data step and presents the human readable story data to a user step . In the illustrated embodiment the method may access a story lookup table that stores both the story hash values and textual representation of a topic e.g. a sentence describing the story .

As illustrated a user submits a piece of user generated content UGC containing the text Let s Go Yankees . The UGC may be parsed according to a predefined algorithm. For example the UGC may be stripped of capitalization and certain punctionation e.g. exclamation points periods colons etc. . As illustrated in the UGC is parsed to let s go yankees removing capitalization and exclamation points.

As previously discussed the UGC is then split at the word boundary to form discrete words from the UGC. The method selects those words greater than a predetermined threshold as previously discussed. In the illustrated embodiment the method selects words greater than three characters words let s and yankees . The method then inspects word cache to determine whether words or are present. Word is present within word cache so the associated counter with word is incremented at position 1.

As previously discussed a plurality of subword caches are associated with a word cache . Accordingly subword cache is associated with index 0 of word cache subword cache with index 1 and so forth. The method then parses the parsed words according to a predefined schema. In the illustrated embodiment the method selects all words that are not prepositions. In the illustrated embodiment the method would select each word 

The method then queries subword cache to determine which words are present within the subword cache . In the illustrated embodiment the method determines that words and are present within the word cache . The method accordingly increments the counters associated with the words at positions 3 and 0 respectively.

Based on the identification of words within subword cache the method identifies a story as go yankees . The method then generates a unique hash value associated with the story as previously described and inserts the hash within story cache and increments the associated counter. Additionally the method then stores the hash and associated story within a story lookup table if the story hash is stored in the story cache for the first time.

The presently described invention provides a novel system and method for surfacing real time data trends based on user generated content. By using a multi tier MHU system the present invention is able to more efficiently identify popular topics and trends within immense dense and rapidly changing data clouds such as the user generated content domain.

In software implementations computer software e.g. programs or other instructions and or data is stored on a machine readable medium as part of a computer program product and is loaded into a computer system or other device or machine via a removable storage drive hard drive or communications interface. Computer programs also called computer control logic or computer readable program code are stored in a main and or secondary memory and executed by one or more processors controllers or the like to cause the one or more processors to perform the functions of the invention as described herein. In this document the terms machine readable medium computer program medium and computer usable medium are used to generally refer to media such as a random access memory RAM a read only memory ROM a removable storage unit e.g. a magnetic or optical disc flash memory device or the like a hard disk or the like.

Notably the figures and examples above are not meant to limit the scope of the present invention to a single embodiment as other embodiments are possible by way of interchange of some or all of the described or illustrated elements. Moreover where certain elements of the present invention can be partially or fully implemented using known components only those portions of such known components that are necessary for an understanding of the present invention are described and detailed descriptions of other portions of such known components are omitted so as not to obscure the invention. In the present specification an embodiment showing a singular component should not necessarily be limited to other embodiments including a plurality of the same component and vice versa unless explicitly stated otherwise herein. Moreover applicants do not intend for any term in the specification or claims to be ascribed an uncommon or special meaning unless explicitly set forth as such. Further the present invention encompasses present and future known equivalents to the known components referred to herein by way of illustration.

The foregoing description of the specific embodiments so fully reveals the general nature of the invention that others can by applying knowledge within the skill of the relevant art s including the contents of the documents cited and incorporated by reference herein readily modify and or adapt for various applications such specific embodiments without undue experimentation without departing from the general concept of the present invention. Such adaptations and modifications are therefore intended to be within the meaning and range of equivalents of the disclosed embodiments based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance presented herein in combination with the knowledge of one skilled in the relevant art s .

While various embodiments of the present invention have been described above it should be understood that they have been presented by way of example and not limitation. It would be apparent to one skilled in the relevant art s that various changes in form and detail could be made therein without departing from the spirit and scope of the invention. Thus the present invention should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

