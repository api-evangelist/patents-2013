---

title: Determination of sequence frequency
abstract: A computer-implemented sequence analysis process is provided for determining frequency in an n-gram hash sequence of a symbolic string, such as a series of characters. The method includes initializing a hash table, creating a matrix, reading the present value in the sequence, determining whether the present value is unknown, inserting a value index into the hash table if unknown and identifying the value index otherwise, and incrementing a cell within the array. The hash table has a plurality of levels from one to n. The matrix includes first and second indices corresponding to an array of cells. The first index corresponds to an end of a prior value, while the second index corresponds to a start of a present value. The cell corresponds to the first index for the prior value and the second index for the present value.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09087295&OS=09087295&RS=09087295
owner: The United States of America as Represented by the Secretary of the Navy
number: 09087295
owner_city: Washington
owner_country: US
publication_date: 20130304
---
The invention described was made in the performance of official duties by one or more employees of the Department of the Navy and thus the invention herein may be manufactured used or licensed by or for the Government of the United States of America for governmental purposes without the payment of any royalties thereon or therefor.

The invention relates generally to determining n gram frequency in a sequence. In particular the invention relates to counting sequences of characters based on the de Bruijn graph.

The problem of counting frequency for n grams in a sequence is routine in text mining and genomic studies. However the process for calculating the frequency is more complex in terms of time. The typical algorithm requires a single pass to enumerate all the n grams in the sequence. For each term the algorithm then makes a second pass to count the matching next term for each occurrence in the sequence. Such an algorithm calculates the frequency of all n grams of length n and must be repeated for other lengths. This conventional algorithm has complexity of order O kn for k sets of n grams. Typically this algorithm is only executed a few times due to its complexity.

Conventional text miners limit themselves 1 to 5 length n grams because further analysis is just too expensive. Among genomic researchers the solution is to chop larger sequences into smaller sizes. That kind of analysis is called de novo . Literature in that field specifically states that de novo analysis is a work around the O n complexity of the algorithm. The de novo analysis limits the size of n so that complexity does not exceed real time constraints.

Conventional frequency determination techniques yield disadvantages addressed by various exemplary embodiments of the present invention. In particular an analysis process is provided using computer implementation for determining frequency in an n gram hash sequence of a symbolic string. The process includes initializing a hash table creating a matrix reading the present value in the sequence determining whether the present value is unknown inserting a value index into the hash table if unknown and identifying the value index otherwise and incrementing a cell within the array.

In various exemplary embodiments the hash table has a plurality of levels from one to n. The matrix includes first and second indices corresponding to an array of cells. The first index corresponds to an end of a prior value while the second index corresponds to a start of a present value. The cell corresponds to the first index for the prior value and the second index for the present value.

In the following detailed description of exemplary embodiments of the invention reference is made to the accompanying drawings that form a part hereof and in which is shown by way of illustration specific exemplary embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention. Other embodiments may be utilized and logical mechanical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

In accordance with a presently preferred embodiment of the present invention the components process steps and or data structures may be implemented using various types of operating systems computing platforms computer programs and or general purpose machines. In addition those of ordinary skill in the art will readily recognize that devices of a less general purpose nature such as hardwired devices or the like may also be used without departing from the scope and spirit of the inventive concepts disclosed herewith. General purpose machines include devices that execute instruction code. A hardwired device may constitute an application specific integrated circuit ASIC or a field programmable gate array FPGA or other related component.

Algorithm and accompanying data structure captures a sequence S of values e.g. textually symbolic characters and decomposes the sequence into a set of frequency charts depicting the frequency of occurrence for all sub sequences n length or smaller. Such a sub sequence is commonly referred to as an n gram in the field of text mining or k gram in the field of genomic sequencing. The value n represents an integer.

For the sake of standard terminology in this application such sub sequences shall be referred to as n grams. Also for the sake of standard form such sequences shall be depicted as letter characters although such a sequence may consist of text genetic base pairs events occurrences or other sequential data that might for convenience be depicted by a string of concatenated symbols. Recognizing always that an event or base pair may be represented by a letter any string of letters would represent a generic sequence. The exemplary algorithm executes through the whole sequence of characters S in O S time i.e. order absolute sequence and creates a set of k tables for 1 grams 2 grams . . . and k grams. Each matrix table corresponds to the frequency with which one n gram follows another to produce an n 1 gram. The resulting tables may be read one row or column at a time to extract frequency information.

Algorithm and accompanying data structure captures a sequence of values and decomposes the sequence into a set of frequency charts. Frequency analysis can then be performed on such charts as shown in to determine various statistical values. illustrates a matrix view with indices a b c d e for both rows and columns . The number of occurrences of some n gram can be determined by row sum. As an example the occurrence of character c in the third row is the sum of 0 7 1 2 1 or 11. By contrast the total occurrences of all the rows constitute the sum of 6 6 11 6 4 or 33. The proportional frequency of some n gram can be determined by row sum in proportion to total n gram frequency. As an example the proportional frequency of c is 11 33 or 33 . In other embodiments additional matrices at higher orders create more complex frequency calculations.

Algorithm and accompanying data structure captures a sequence of values and decomposes the sequence into a set of frequency charts. Bayesian probabilities can be calculated from these charts to predict behaviour determine the probability of a given input and to create a Bayesian network for other applications. Referring again to the chart shown in matrix view the occurrence of c is 11 but the occurrence of c precedes the occurrence of Ca cb cc cd and ce with various specific probabilities. Therefore one can determine that if c occurs then b is the most probable 64 likely follow on value. By contrast if ca was to occur such an occurrence would stand out as extremely unlikely and thereby draw attention to a potential anomaly. In other embodiments additional matrices at higher orders create more complex Bayesian logic thereby enabling predictive analysis of the final n gram based on a single 1 gram.

Due to the existence of this predictive analysis capability anomalous sequences are easily detected. The occurrence of a sequence acdae has a computable probability based on the given matrix. From the fact that c follows a with a probability of 0.5 d follows c with a probability of 0.18 a follows d with a probability of 0.33 e follows a with a probability of 0.125 the probability of the sequence acdae is calculated as 0.0038. By the same process the sequence cbdcb has a probability of 0.09. This would indicate that cbdcb occurs twenty three times more frequently than acdae rendering the latter an anomaly.

In a static analysis mode a sequence of known normal behaviour may be analyzed using the algorithm and accompanying data structure. From this one action static analysis can calculate predictive values for normal behaviour. Using this set of normal behaviour as a baseline a new sequence may be analyzed in order to determine the likelihood of each sub sequence. The outcome constitutes a mapping of the complete new sequence showing where anomalies occur their duration and when normal behaviour begins again.

In a static analysis mode and using the predictive values to create a Bayesian net one can create active resistance to undesirable outcomes. shows matrix views of a 1 gram table and a 2 gram table for a sequence gabddabadbgabdgabagada . As identified by the demarcated intersection or cell of row ba and column ad the sequence bad is shown to be undesirable in the second 2 gram table . In the course of the sequence processing if b occurs then there is a 40 chance of being followed by a . When ba occurs there is a 50 chance of being followed by ad . Thus there is a 20 chance of the undesirable outcome bad simply based on the occurrence of b . The system may feel that this is sufficiently low to permit the sequence to continue but once ba occurs the now 50 probability of bad is unacceptable. Such analysis allows the system to actively resist undesirable outcomes. Such calculations are easily made as part of a Bayesian net and may extend to many layers of complexity beyond this simple example.

In a dynamic analysis mode a stream of events may be processed without any foreknowledge of baseline behaviour. In this mode the matrix counters continually increment with each event and on a periodic basis appropriate for that system a matrix wide reduction may be effected. This reduction will prevent the counter from increasing without bounds and reduce or eliminate any lower order occurrences. The appropriate timing of such a reduction may be fine tuned for the system in question in order to reduce false positives.

In a dynamic analysis mode and using the frequency chart in its current state at any point in time one can apply the algorithmic process to detect anomalies. shows perspective plot views of a pair of dynamic contour graphs and . Through a perpetual build and reduce process the normal behaviour of the system might be represented by frequency counts denoted by increasing layers as indicated by the arrows .

Frequent sequences are reduced so that no behaviour stands out as in the graph . If however a spike in one behaviour was to occur that would become noticeable as in the graph . Especially where such behaviour is seen infrequently such analysis could be automated to trigger an alarm indicating an unusual event. Moreover the location of the spike would indicate exactly which sequence of events led to the alarm.

Algorithm and accompanying data structure may be adapted for parallel processing without loss of information. In the parallel processing form P sections of a large sequence may be processed individually from 1 grams up to n grams. The totals from the P frequency charts may be aggregated for a total value. As a final step the boundary conditions between the sections must be considered.

Thus the last and first n 1 values must be evaluated on such boundaries as shown in which shows a processing view involving up to 4 gram strings 410 and so the three values on that boundary are involved in additional 4 gram BADA ADAB and DABD that require processing. The upper sequence ends in boundary BAD and the lower sequence begins in boundary ABD . Thus by parallel processing P sequences of k length can be processed in k time with an additional smaller cost involving the individual boundaries. Such a process is not dissimilar to the Map Reduce paradigm favoured for large data sets.

Algorithm and accompanying data structure produce output which may be used to further analyze and understand the domain. B and C show perspective frequency graphs of 4 gram for a random deoxyribo nucleic acid DNA nucleotide sequence. illustrates a 4 gram unsorted graph . illustrates a 4 gram magnitude sorted graph . illustrates a 4 gram alphabetically sorted graph . These nucleotides are labeled for adenine for thymine for guanine and for cytosine. A frequency scale denotes the magnitude of the sequence occurrences denoted by spikes rising from the base of the graphs.

As shown by the unsorted graph a matrix of n grams exhibits a diagonal line that seems to indicate strong correlation of some form. This seeming correlation is in fact an artifact of the method of construction for the structure. Sorting by magnitude of row and column produces a much less predictable pattern such as the distributed convergence near the rightward edges of the magnitude sorted graph . This may be used to better understand the concept of frequency among n grams. One can demonstrate that some sorting criteria expose predictable patterns of behaviour that can be quite regular. In this example the alphabetical sorting graph exposes the predictable nature of feasible n gram joining . Similar techniques may be developed using large order data to find other regularities that have greater significance in the individual domain.

Using the current state of the art the process for calculating 1 grams is O n or quadratic time with an O k or linear memory requirements. The algorithm simply consists of two passes over the entire sequence. The first pass is to determine all the 1 grams found in the sequence let s say k. The second pass starts by initializing a k length array and then incrementing each counter as the 1 gram is encountered. Thus the algorithm is able to produce a k length array with k counts for k values.

This algorithm executes in quadratic time but during that interval the process only produces a count for one type of n gram. In order to produce significant data sets for higher order n grams the conventional process must be executed repeatedly at a quadratic cost for each new n gram set. Thus for a sequence is being analyzed for a maximum of M grams this process must be run M times for a total run time of O M n . In practice for M 5 such analysis becomes infeasible for large values of n.

Conventional algorithms in the current state of the art use only linear memory. This constitutes an advantage as conventional techniques inhibit allocation of additional memory that could be used for other purposes. Also the output is exactly fit to the size of the data. This feature is useful in post processing where any unused additional memory would require additional processing to interpret correctly. The exact size of this memory requirement comes at a cost in reduced flexibility which is a deficiency that exemplary embodiments remedy.

Among those in greatest need of a solution to this problem are genetic researchers who are conducting frequency counts on extremely large order sequences. In such a case the quadratic order of the algorithm becomes a burden and the processing of the entire sequence cannot be accomplished in reasonable time. Instead the sequence is divided into sections which are examined individually in what is called the de novo process. This process yields correct answers but is performed in this manner expressly for the purpose of defeating the O n time requirement.

In contrast using the exemplary algorithm and accompanying structure the process for calculated 1 grams is O n or linear time with an O k or linear memory requirement. The algorithm operates by starting with a k by k k k matrix where kis the assumed starting size of k. As each value in the sequence is processed the process either matches an existing value in kor the value is added to the set. When the set exceeds the size of k the size is doubled to kthe current matrix is copied into a new matrix of size k by k k k and the process continues. As a final step the exact k by k k k matrix may be coped once more so that no excess rows or columns exist where kis larger than k. Thus the algorithm is able to produce a sparse matrix of order k k which contains counts for all 1 grams and 2 grams. This is the most primitive step in the algorithm.

Note that exemplary embodiments of this technique improve upon the conventional state of the art by an order of magnitude in reducing time for completion. The artisan of ordinary skill can note that the process of copying the existing matrix repeatedly is an O k operation. For each increasing size of kthe previous order becomes irrelevant as the new order is larger. The cost for this operation however is miniscule compared with the total processing time. For exceptionally large orders of n the overall cost is still capped by O n so that these copy operations become trivial by comparison.

For example take the 4 gram table of base pairs. There are 4or 256 possible 4 grams all or some of which may exist in a large sequence. If the table starts out as 4 4 the table must be doubled in size a total of six times. The largest operation is 128or 16384 copy operations and the total number of copy operations is 21 840 or 133 of the O k estimate. The 133 of estimate holds true for all large copy operations. If the entire sequence is as large as 25 000 base pairs the O n processing time already exceeds the number of copy operations. In fact the average size of single human gene is only 3 000 values but some single genes are as large as 2.4 million base pairs and the total genome is 3.1647 billion base pairs. In a sequence of that size the copying operations represent less than 0.0007 of the total processing costs.

Also recall that in practice the conventional state of the art is limited to 5 grams in terms of feasible calculation time. Using the exemplary algorithm and accompanying structure one can calculate 1 grams 2 grams 3 grams 4 grams and 5 grams simultaneously within O n time. In practice this has been found to enable higher order analysis that has not been computationally accessible before. Presumably this aspect of exemplary embodiments can open new vistas of high order frequency data in the near future.

The total memory usage for this operation is order O k . While the doubling effect may result in a slightly larger than necessary matrix this does not exceed O 4k . Suppose that k is 101 and at some point the current matrix is k kwhere k 100. At some point the kelement must be added. In such an operation results in a 200 by 200 matrix when only a 101 by 101 matrix is required. This is a 40 000 10 201 or about 4 1 ratio as stated previously and thus O 4k . This is known to be within the same order as O k according to standard computational theory and thus represents a theoretical bound on memory space. As such this exceeds the state of the art by one order of magnitude.

Furthermore consider that such a matrix contains frequency counts for 1 grams and 2 grams. This means that 1 grams are represented by columns and 2 grams are represented by individual matrix cells. This is a property of de Bruijn graphs which are the basis for the accompanying structure. In the state of the art representing the latter data set would require additional memory. Thus the apparent order of magnitude disparity is reduced when one considers the next order of data contained in the structure.

One should note however that conventional techniques return exactly k values with no additional or excess memory being used. By contrast exemplary embodiments with the disclosed algorithm and k k structure contains cells for all k2 grams whether or not they are feasible. Infeasible 2 grams will be represented by a zero so that the structure may be a sparse matrix. In practice the sparcity of the matrix is domain specific. For example in genetics the frequency with which any base pair is followed by any other base pair is relatively uniform so that a 1 gram matrix is unlikely to contain any zeros much less be considered sparse. On the other side of the scale sequences of letters in English would show no occurrences of several sequences such as qj or xx creating a very sparse matrix of 1 grams. In each example the 2 gram values are represented in the O k memory. Depending on the domain therefore the matrix may be sparse. Consider therefore the best and worst case scenarios for the purpose of memory comparison.

For example evaluation of the sequence abcdabcdabcd . . . for 2 gram frequencies can be compared using conventional and exemplary methods. The conventional technique would use only four memory slots for the final result corresponding to the four occurring 2 grams. For the same data the exemplary process would require sixteen memory slots only four of which would be filled with data. Thus the matrix in only 25 full and is thereby inefficient in its memory usage. Such a sequence consists of k elements in the same order and possibly repeated multiple times. Therefore depending on the set of 1 grams this value can be even worse. The sequence above contained only five 1 grams. For the set of digits 0 1 2 . . . 9 the minimum theoretical efficiency is 10 . For the set of all single case characters a b c . . . z the minimum theoretical inefficiency is 3.8 . There is no lower bound given a sufficiently large set of 1 grams. This example represents a worst case scenario.

Suppose instead that the digits of the transcendental number are read as a sequence. This sequence is random and every possible 2 gram occurs with equal probability. There are ten digits and a hundred possible 2 grams. After a sufficiently large sequence has been examined the sparsity of the matrix drops and the memory usage to near 100 of the theoretical limit. For an alphabet of size A the matrix will be sparse with only A Aentries for 1 Asparsity. shows a perspective chart derived from the first thirty eight hundred digits of . The frequency scale extends in increments of five from zero to fifteen. No discernible pattern is apparent indicating random distribution of sequences. This is an example of the best case scenario.

Therefore as a summary of the comparison between conventional and exemplary techniques the disclosed process is faster by an order of magnitude and employs a comparable usage of memory. Depending on the domain in which the technique is applied the density of the matrices in the invention may vary which has an effect on memory efficiency. While in principle one can achieve a 100 memory efficiency in practice the efficiency is neither 100 nor very low.

The structure of the algorithm is derived from de Bruijn graphs shown in along with an overlap table in . This example operates with the domain of binary numbers i.e. the alphabet of 0 and 1 . shows the 1 gram graph based on nodes for zero and one having 2nodes with 2valid edges between them denoted by labeled arrows. shows all the 1 grams as nodes 0 and 1 . At this level the feasible connections between the 1 grams are represented by connections between the nodes. The valid edges are the only possible combinations of these two symbols. By inverting this graph each edge can be represented as a node for the 2 gram and additional 3 gram connections can be made. The resulting graph is the 2 gram de Bruijn graph in with nodes 00 as 01 as 10 as and 11 as .

Any 2 gram combination falls on one of those edges. The 2edges represent all possible 3 grams as any 3 gram combination would fall on one of those edges. The nodes correspond to and are labelled as the set of all possible 2 grams 00 01 10 11 . In the next level the 2 grams are represented as nodes. Just as in the previous level in feasible connections between 2 grams are representative of the next order or 3 grams. Again these connections correspond to and are labelled as the set of all possible 3 grams 000 001 010 011 100 101 110 111 . Using these values a set of nodes may be composed into the next level to produce the 3 grams with 4 gram connections and so forth.

Each level n has the following properties. Each valid n gram is represented by a single node. Each valid n 1 gram is represented by a single connection between two n grams. Each valid connection shows a unidirectional overlap between sequential n grams. shows overlays of two 2 gram nodes from 01 as to 11 as as a first path with a first joint and from 11 as to 01 as as a second path with a second joint . As can be seen in the first 2 gram node path shows overlap at the first joint with the end of the first node coinciding with the beginning of the second node and thus create a valid connection corresponding to 011 node . However the connection is unidirectional so that the second path does not show matching terminal values at the second joint between 11 node and 01 node and therefore cannot create a valid connection in the opposite direction.

The mathematical structure that accompanies the exemplary algorithm is based on the de Bruijn graphs but can also be displayed by matrices. are tabular matrix views corresponding to the nodes in the de Bruijn graphs provided in with each level being represented by a square matrix. shows a 2 2 matrix with 1 digit rows and columns . shows a 4 4 matrix with 2 digit rows and columns . In these tables and the value one in a cell represents a valid connection while the value zero in a cell represents an invalid connection. The arrows in the graphs correspond to the identified labels in the matrices for the valid connections. Note for example in the 2 gram table that reading horizontally the 00 node connects with the 01 node by arrow 001 identified in the second column and first row but the 01 node does not connect with the 00 node . Because of this the matrix tables are square allowing for all connections but are not symmetric thereby indicating the directed nature of the tables.

The individual rows and columns of the matrix correspond to the nodes of the graph. The intersection of a row with a column that forms a cell corresponds to the connections of the graph. The value one in the cell indicates that a valid connection exists between the row representing an n gram and the column representing the next. The value zero in the cell indicates that no valid connection exists. Note that the 2 gram matrix is fairly sparse with only 50 storage efficiency.

As another example of the correlation between the de Bruijn graph and the matrix representation described as follows. shows a graphical view and corresponding matrix for 1 grams based on the genetic nucleotides. These nucleotide nodes are labeled as in views for adenine for guanine for thymine and for cytosine . Each edge between them indicates a possible connection shown by arrows. In this example a solid thick edge represents node followed by node to denote sequence whereas a broken thick edge represents node followed by node to denote sequence . Thus the sequence would start at the node and follow the thick edges and to the node .

In a similar manner any sequence could be expressed as a pathway over the 1 gram de Bruijn graph. shows a matrix view of a table defined by rows and columns . A solid thick cell for the intersection of corresponds to the solid edge . A broken thick cell for the intersection of corresponds to the broken thick edge . Note that in this matrix table there are no zeros so this is 100 data efficient.

These matrices may be created for each of the levels one through n that are required in the output. Each layer tracks its own frequency counters and corresponds to the level above. As an example the sequence would be processed by first incrementing the block for and then the block for . In each case where the block has been incremented in the 1 gram matrix corresponding action would be taken in a corresponding 2 gram matrix. This 2 gram matrix not shown would include a row for and a column for and would subsequently be incremented in the intersection corresponding to . This process would proceed to update and increment values at each level upward through the hierarchy.

In addition to the matrix there are four additional structures which are necessary for each level in order to perform basic housekeeping tasks. shows an example structure corresponding to the matrix after processing the sequence . This includes a hash table with the character value key and its corresponding value index . The hash table is used to track the values corresponding to the matrix indices. In addition a list of parameters aids in accounting for progress and status. A last index i.e. most recent index encountered in the sequence a number of key indices in the hash table and a logical active state of that level.

The variable last index tracks the most recent preceding value that was processed. As indicated by the hash table the last value corresponds to the index one. Thus the index one appears for the last index . The number of indices held in the hash table is identified as four. That number also corresponds to the next matrix index making it a trivial process to add an additional index when required or to decide on resizing the matrix. The logic variable indicates whether the table is currently active. An inactive table i.e. false has not yet processed any values and must be activated when this occurs. Once activated i.e. true any additional processed values will require a corresponding action in the next highest table.

In summary the accompanying structure is a homogenous hierarchy which relates cell values at the nlayer with index values at the n 1layer. As shown in each layer has its own matrix hash table last index number variable and active variable . In order to simultaneously process all subsequences of size n or smaller the first layer tracks 1 grams the second 2 grams the third 3 grams and so on until the final nlayer tracks n grams.

The algorithm portion in exemplary embodiments is shown in as a flowchart . The process begins with parameterization of an input sequence i.e. digitally decomposing and ordering the characters or other symbolic representation in the sequence for input followed by an instantiation phase i.e. establishing the hash tables and matrices and setting select parameters to default values . A first query determines whether additional characters in the sequence remain. If affirmative the process continues to a first iteration loop in which a second query determines the last index L from one to n and begins to process the current value at operation . The process continues to a second iteration loop in which a third query determines whether the value of the input character is known i.e. the character having been previously encountered and recognized . If negative a fourth query determines whether the value exceeds the previously established hash table and matrix size.

If affirmative an expansion operation expands the matrix to include additional rows and columns and continues to operation . Otherwise the process skips operation and continues to operation to be unified with the alternative operational flow. The process continues to an insert index operation . Upon completion or if the third query is affirmative the process exits the second loop and continues to a find index operation . A fifth query determines whether the current level is active. If affirmative the process continues to a cell increment operation and returns to the second query .

The increment operation calculates the new index value which will be processed in the next level and assigns new last index value . Upon returning to the second query the level is incremented and the new value is processed. When the nlevel has been processed the second query exits the first loop and returns to the first query . If the fourth query is negative the process exits the first loop and proceeds to an activation operation to activate the index. The operation updates the last index value . The activate operation returns to the first query . Additionally when the second query completes the levels the process returns to the first query . When no further additional characters remain in sequence in the first query the operation is completed and terminates .

Additionally the algorithm portion in exemplary embodiments is shown in as instruction pseudocode . This instruction set can be broken into sub sections including parameterization lines 1 2 initialization lines 5 9 structure resizing lines 19 30 and processing lines 35 46 . Much of the code also falls into loops. There is an overarching loop lines 12 48 that repeats for each new value in the sequence. An inner loop lines 17 47 repeats operations for each level of the structure.

The algorithm may be parameterized to enable any maximum n gram length but in this example code the length is set as ten. This value affects the size of the structure and moderately alters the speed of execution. Obviously processing up to 5 grams will be faster than 500 grams. As noted before examples provided herein demonstrate the exemplary process for explanatory purposes rather than provide a practical example for solution. However in order for this to significantly alter performance the size of n must greatly exceed the size of the sequence itself. Similarly the starting kdimension of the hash table is a parameterized value but in this example code kis set as fifteen. This value also affects the efficiency of structure resizing as each resize is a geometric progression i.e. k 2 k 2 k 2 etc. yielding k 2k 4k . . . . While selecting an appropriate value for this size kcan be tailored to the specific task this only amounts to a multiplier on the basic progression of powers of two and thus has no permanent effect on performance.

The initialization phase creates the matrix hash table number last and active variables for each level. This process is fairly straight forward. One can expect that the default value for each matrix cell is zero. By the same token the number N of indices must be initialized to a default value of zero. The last index L has no such requirement as any prior value will be replaced and thus can be discarded. Active A is also required to initialize to the default value of false . The hash table has no initial content requirements. These values are required as part of initialization.

The two loops process each value from the sequence. The overarching loop reads in a single value i.e. a 1 gram from some form of data stream. The specific implementation is unimportant and may be chosen at the convenience of the system. That value stored temporarily on line 14 becomes the loop invariant for the inner loop . Upon the start of each iteration of the inner loop the variable value shall contain the n gram that will be represented in the column of the matrix at that level. The value is changed on line 44 of the pseudocode as part of the process corresponding to the increment operation . The joining operation operates to join or overlap the last and current values. Thus for the first iteration the value might be character a but in each subsequent iteration the value aggregates some portion based on the last values processed i.e. ab abc abcd etc. .

The structure resizing is triggered based on the number of indices used. This can only occur when a new key is discovered and so this is the first check on line 19 of the pseudocode . After that point the key must be added to the hash table and a new index added on line 30. In comparison with the size of the matrix the number of indices should always be smaller i.e. a 5index will be out of bounds on a 4 4 matrix . Thus if that bound is exceeded at line 21 the matrix must be resized. Lines 24 27 in structure resizing merely exhibit the calculation of current matrix size creation of a larger matrix copying the contents of the smaller matrix and storing the copy. Notes that the copying process is assumed and not shown in this pseudocode .

Whether an index is either new or otherwise the index is extracted from the hash table on line 33 and operation begins. Processing differs depending on the logic state of the active variable . An inactive hash table false has no last value and thus has no ability to calculate the operation on line 43. For this situation there is also no last value to aggregate on line 44. These actions are required of all active hash tables in order to pass the aggregate value up to the next level. The inactive layer must first become active true . The break statement on line 39 indicates that the inner loop will terminate early if an inactive table is found. Thus if any hash table has no aggregate value to pass on then there is naturally no need to proceed to the next level. Note that both active and inactive tables must update the last index value as shown in operations and .

In order to demonstrate the algorithm in operation an example has been prepared. This example processes a sequence S of letters corresponding to the word mississippi denoting the geographic place name . The structure is set up to process up to 3 grams and several relevant iterations are shown. These iterations were selected only to demonstrate the operation of the algorithm and are not exhaustive. As the algorithm progresses each level becomes active and then begins to store frequency data. Using the sequence S as defined the following states describe the first six iterations of the algorithm as an exemplary process.

Iteration 1 Processing m In this initial iteration the full operation of all levels is not visible. Even the changes performed on the variables may not be readily apparent. B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs for the first iteration. shows 1 gram parameter values with the last index set to zero corresponding to the index of the first key m number N incrementing to one and switching active A to true . further shows a hash table with filled row denoting 1 gram m and index zero and a matrix with m . Introduction of the 1 gram m activates the matrix albeit with no non zero cell. For convenience the matrix shows m as corresponding to the first row in the hash table . The matrix shows m substituting for zero in the first row in and column in .

The letter m is not found in the first 1 gram level hash table which in fact has been empty. Thus this character is added to the key and an index of zero is assigned in the row and the number of indices is advanced i.e. incremented from zero to one. The 1 gram level is activated thus switching the active state to true . Although not visually obvious the current index of zero corresponding to the index for the m character is stored under L for the last index . shows 2 gram parameter values hash table and matrix . No change has occurred from initial default settings and the hash table remains empty. shows 3 gram parameter values hash table and matrix . No change has occurred.

Iteration 2 Processing i B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after completing the second iteration. shows 1 gram parameter values with the last index set to one corresponding to the index of the second key i the index number N incrementing to two a hash table with filled row denoting 1 gram i and index one and a matrix with i . The letter i is not found in the first 1 gram level hash table and thus this character is added to the key and an index of one is assigned in the row such that the number of indices increments from one to two. For convenience the matrix shows i as corresponding to the second row in the hash table . The matrix shows i substituting for one in the first row in and column in . Moreover an occurrence of m followed by i is indicated by value one in the cell at the first row and second column.

The introduction of a second letter continues the process by activating a second 2 gram level. shows 2 gram parameter values with the last index set to zero an increment of number N to one and switch in active A to true for the 2 gram level. further shows a hash table with filled row denoting 2 gram mi and index zero to which the last index is set and a matrix with mi substituting for zero in the first row in and first column in . shows 3 gram parameter values hash table and matrix . No change has occurred.

For the second iteration the changes become more apparent. The 1 gram parameter values indicate that the level is active with two indices at and that the last index was set to one. The hash table has records of two 1 grams along with their corresponding index values. For convenience the matrix shows 1 where the corresponding index was found in the second row and second column. Also in matrix the increment in the cell with value one corresponds to a single occurrence of the 2 gram mi and resulting activation at of the 2 gram level.

The 2 gram parameter values indicate that the level is active at with a single index and that the last index was zero. The hash table has a record of the 2 gram mi at row and the corresponding index zero. For convenience the matrix shows the 2 gram mi where the corresponding index was added in the first row and first column. The sequence mi is not found in the second level hash table so this string is added to the key the index of zero is assigned in row and the 2 gram number of indices is incremented.

Iteration 3 Processing s B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after the third iteration. This is the first iteration that produces changes on each level. shows 1 gram parameter values with the last index being set to two corresponding to the index of the 1 gram s an increment of number N to three a hash table with filled row denoting 1 gram s and index two and a matrix with s substituting one in the third row and third column. For convenience the matrix shows s as corresponding to the third row in the hash table . Moreover an occurrence of i followed by s is indicated by value one in the cell at the second row and third column. The hash table has records of three 1 grams along with their corresponding index values.

The letter s is not found in the level one hash so this letter is added to the key the index of two is assigned in row and the number of indices is incremented from two to three. The level is active so the cell in matrix is incremented. The current index is stored as L . Note that the newly incremented value of N corresponds to the 2 gram is minus one and this aggregate value is processed at the next level.

The 2 gram is is not found in the level two hash so the 2 gram is added to the key the index of one is assigned in row and the number of indices is incremented. The hash table has a record of two 2 grams along with their corresponding index values. The 3 gram parameter values indicate that the level is active with one index and that the last index was zero. The hash table has a record of the 3 gram mis and its corresponding index zero.

Iteration 4 Processing s B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after the fourth iteration. shows 1 gram parameter values with no apparent changes a hash table with no changes and a matrix . A repeated occurrence of s is indicated by value one in the cell at the third row and third column. shows 2 gram parameter values with the last index incremented to two an increment of number N to three a hash table with filled row denoting 2 gram ss and index two and a matrix with ss substituting two in the third row and third column. The matrix shows ss as corresponding to the third row in the hash table .

Moreover an occurrence of is followed by ss is indicated by value one in the cell at the second row and third column. shows 3 gram parameter values with the last index set to one an increment of number N to two a hash table with filled row denoting 3 gram iss and index one and a matrix with iss substituting one in the second row and second column. The matrix shows iss as corresponding to the second row in the hash table . Also in matrix an occurrence of mis followed by iss corresponds to one occurrence of the 4 gram miss with the 2 gram end of the former coinciding with the 2 gram beginning of the latter as indicated by the value one in the cell at the first row and second column.

In this fourth iteration the tedium of reciting each step can be omitted. The 1 gram s is processed at the first level the 2 gram ss at the second level and the 3 gram iss at the third level. Note that 1 gram para meters indicate that there are only three indices because s already appears in the hash table. When that value was found no new record was added and the value N was not incremented. This corresponds to the pseudo code where a positive answer on line 19 causes resizing to be skipped. The effect on B and C is similar to those shown in previous iterations.

Iteration 5 Processing i B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after the fifth iteration. shows 1 gram parameter values with the last index reset to one that corresponds to the index value of letter i having repeated in the sequence S a hash table with no change as no new letter has been added and a matrix . An occurrence of s followed by i is indicated by value one in the cell at the third row and second column. shows 2 gram parameter values with the last index set to three corresponding to the 2 gram si an increment of number N from three to four an expanded hash table with added row denoting 2 gram si and index three and an expanded matrix with entries si 4 5 adding third fourth and fifth rows and columns. The matrix shows part of si 4 5 as corresponding to the fourth row in the hash table .

Moreover an occurrence of ss followed by si is indicated by value one in the cell at the third row and fourth column. shows 3 gram parameter values with the last index incremented to two an increment of number N to three a hash table with filled row denoting 3 gram ssi and index two and a matrix with ssi substituting two in the third row and third column. The matrix shows ssi as corresponding to the third row in the hash table . Also in matrix an occurrence of iss followed by ssi corresponds to one occurrence of the 4 gram issi as indicated by the value one in the cell at the second row and third column.

Again the description of this fifth iteration focuses only on events of note. The 1 gram i is processed at the first level the 2 gram si at the second level and the 3 gram ssi at the third level. Note that the first level already has this 1 gram so no change occurs in the hash table nor in the N parameter in values . However the 1 gram L parameter of last index sets to one corresponding to the 1 gram i . Note also that because si is the fourth 2 gram the hash table expands in size. The doubling in the dimension of the index creates a quadruple effect on the totals size of the matrix . Corresponding changes in the hash table and N parameter number indicate that there are now four indices instead of the previous three. The remaining changes to are consistent with those shown in previous iterations.

The 1 gram parameter values indicate that the level is active with three indices and that the last index was set to one. The hash table has records of three 1 grams along with their corresponding index values. Also in matrix the increment corresponds to an occurrence of the 2 gram si . The 2 gram parameter values indicate that the level is active with four indices and that the last index was three. The hash table has records of four 2 grams along with their corresponding index values. The matrix shows si where the corresponding index was found in the fourth column and fourth row. Also in matrix the increment in number corresponds to one i.e. first occurrence of the 3 gram ssi .

The 3 gram parameter values indicate that the level is active with three indices and that the last index was two corresponding to 3 gram ssi . The hash table has records of three 3 grams along with their corresponding index values. For convenience the matrix shows ssi where the corresponding index was found in the third column and third row. Also in matrix the increment for number corresponds to an occurrence of the 4 gram issi as denoted at cell .

Iteration 6 Processing s This is the last iteration that is shown in detail. B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after the sixth iteration. shows 1 gram parameter values with the last index set to two a hash table with no change and a matrix . Another occurrence of s followed by i is indicated by value two in the cell at the second row and third column incrementing the value from prior cell in that array position. shows 2 gram parameter values with the last index reset to one corresponding to repeated 2 gram is an increment of number N to four a hash table with no change and a matrix . An occurrence of si followed by is is indicated by value one in the cell at the fourth row and second column.

The 1 gram s is processed at the first level the 2 gram is at the second level and the 3 gram sis at the third level. Note that for both the first and second level these n grams have already been seen so there is no change in the hash tables or N parameters. However the 1 gram L parameter last index and 2 gram L last index parameter have been changed to indicate the last indices of two and one corresponding to s and is respectively. Note also that in 1 gram matrix increment of number is the first repeated occurrence of a 2 gram and thus a value greater than one in any matrix. Finally the increase of matrix is necessitated by the accommodation of a fourth index value. Again this doubling effect in the indices increases the matrix size by a factor of four. All other changes are consistent with what has been shown in previous iterations.

The 1 gram parameter values indicate that the level is active with three indices and that the last index was two corresponding to the 1 gram s in a repeat encounter. The hash table has records of three 1 grams along with their corresponding index values. Also in matrix the increment number corresponds to two occurrences of the 2 gram is . The 2 gram parameter values indicate that the level is active with four indices and that the last index is set to one corresponding to the sequence is again. The hash table has records of four 2 grams along with their corresponding index values. Also in matrix the increment number corresponds to one occurrence of the 3 gram sis denoted at cell .

The 3 gram parameter values indicate that the level is active with four indices and that the last index was three corresponding to the last 3 gram sis . The hash table has records of four 3 grams along with their corresponding index values. For convenience the matrix shows sis where the corresponding index was determined in the fourth column and fourth row. Also in matrix the increment of number corresponds to one occurrence of the 4 gram ssis as denoted at cell .

Although no additional iterations are described in detail here each additional iteration executes similarly. For each n gram either a new index will be assigned or an old one will be reused. The remembered value of the last index L leads to an increment of the matrix sometimes filling a zero space and sometimes increasing the count of certain n grams. Occasionally the required indices will exceed the size of a matrix and this causes expansion of the matrix.

Final Iteration Structure State B and C show tabular schematics of 1 gram 2 gram and 3 gram graphs after process completion. shows 1 gram parameter values with the last index reset to one corresponding to the last letter i in the sequence S an increment of number N to four a hash table with filled row denoting 1 gram p and index four and an expanded matrix with p 4 5 adding fourth through sixths rows and columns.

Occurrences of i followed by p of repeated p and of p followed by i are indicated by value one in cells at the second row and fourth column and at the fourth row and second and fourth columns. Another occurrence of s followed by i is indicated by value two in the cell at the third row and second column incrementing the value from prior cell in that array position. shows 2 gram parameter values with the last index set to six corresponding to ending 2 gram pi an increment of number N to seven and an expanded hash table with added rows denoting 2 grams ip pp and pi and respective indices four through six.

Single occurrences of ssi followed by sip of sis followed by iss of sip followed by ipp and of ipp followed by ppi correspond to respective occurrences of the 4 grams ssip siss sipp and ippi as indicated by the value one in cells at the third through sixth rows and respective fifth second sixth and seventh columns. Another occurrence of iss followed by ssi corresponds to a repeat occurrence issi as indicated by the value two in cell at the second row and third column incrementing the value from the prior cell in that array position.

Note that the 1 gram parameters indicate that there have been a total of four 1 grams and that the last one observed was at index one corresponding to i . The matrix has been enlarged since the sixth iteration and one additional index value has been added corresponding to the 1 gram p . Note that the 2 gram parameters indicate that there have been a total of seven 2 grams and that the last one seen was at index six corresponding to pi . Note that the 3 gram parameters indicate that there have been a total of seven 3 grams and that the last such string was at index six corresponding to ppi . The matrices and would have been expanded again to 12 12 but for convenience are shown here in the minimal form.

Note that the sequence contains eleven values but that the matrix of 1 grams indicates only ten values. This number actually corresponds to the number of 2 grams. With one exception one can accurately give the frequency of 1 grams by a summation of each row. Thus in matrix the 1 gram m appears only once 0 1 0 0 0 0 in the first row while the 1 gram s appears four times 0 2 2 0 0 0 in the third row. Note the exception that the summation indicates that the 1 gram i appears only three times 0 0 2 1 0 0 in the second row. This superficial indication is incorrect. This off by one fault occurs on each hash table and corresponds to the last value shown. Thus this may be corrected for by referring to the index stored in last index L or for large values may be ignored. In this example the error introduces a significant variance 25 for 1 grams but in a larger example that variance would be less significant.

Note also that there is a diagonal fill pattern in each matrix. This can be most readily seen in the third iteration where the matrix somewhat resembles the identity matrix and matrices and appear to be developing in a similar manner. However even this short example demonstrates that by the last iteration is asymmetric and no longer subject to the diagonal fill. The same is true but not as obvious for and which are nearly a diagonal fill but with some aberration in the pattern. This suggests that there is a law of diminishing return for high order n gram hash tables.

The selection of a maximum n gram size should be determined based on technical requirements of the application and the domain. For alphabets of size the potential size of the matrix size is . As long as the sequence is larger than the hash table will begin to deviate from the diagonal pattern. One may also consider that certain n grams sequences are infeasible further limiting that maximum matrix size. Obviously smaller alphabets and longer sequences may have significant data even at high orders of n although deviation from the diagonal pattern may be seen earlier.

The exact nature of this diminishing return has not yet been studied by the inventors and to their knowledge has not been investigated in research literature. This is primarily because such analysis was infeasible under the old computing paradigm being impossible using conventional state of the art and de novo methods to examine the results of large order n gram hash table for a large sequence.

The efficiency of storage for each matrix is related to this phenomenon. In this example the 6 6 matrix is 19 efficient and the 12 12 matrices and are each less than 5 efficient. Again this example is a very small one and one can observe that the smaller matrix is already becoming more efficient. For large order sequences that efficiency is likely to increase subject to the limitations discussed in Section II.

Exemplary executable code was produced from the pseudocode . The only significant difference in both structure and algorithm was an additional hash table which incorporated the index values as a key to find the corresponding text value. shows tabular listings from an executable version of the process algorithm for the aforementioned sequence S i.e. mississippi to a parse degree of three. This analysis yields the lists of values in formatted arrays after completion of the final iteration. The first table shows the 1 gram result analogous to matrix . The second table shows the 2 gram result analogous to matrix . The third table shows the 3 gram result analogous to matrix .

As noted in Section IV depending on the required output the matrix may be relatively larger than the actual data. The parameter N in each case serves as an actual limit to the data size. Similar to the process described in the pseudocode at lines 24 27 a new matrix of the exact N N dimensions may be created and the data may be copied into that matrix. In terms of the pseudocode such an action would occur after line 48. In terms of the flowchart such an action would occur just prior to Done .

As noted in Section VII the exemplary code added an addition hash table to the accompanying structure in order to map from indices to values. This alteration allowed the unification of two character sequences. For this domain this seemed a reasonable adaptation in order to execute the join method shown in psuedocode at line 44. Other similar adaptations may be necessary for other domains based on the concept of join in that domain. Such variants on the invention are to be expected and are idiosyncratic to the domain. They do not depart from the spirit of the embodiments.

While certain features of the embodiments of the invention have been illustrated as described herein many modifications substitutions changes and equivalents will now occur to those skilled in the art. It is therefore to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit of the embodiments.

