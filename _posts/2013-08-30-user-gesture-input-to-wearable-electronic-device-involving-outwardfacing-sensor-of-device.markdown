---

title: User gesture input to wearable electronic device involving outward-facing sensor of device
abstract: In one embodiment, a wearable apparatus includes a sensor, a processor coupled to the sensor, and a memory coupled to the processor that includes instructions executable by the processor. When executing the instructions, the processor detects by the sensor movement of at least a portion of an arm of a user; detects, based at least in part on the movement, a gesture made by the user; and processes the gesture as input to the wearable apparatus.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477313&OS=09477313&RS=09477313
owner: Samsung Electronics Co., Ltd.
number: 09477313
owner_city: Suwon
owner_country: KR
publication_date: 20130830
---
This application claims the benefit under 35 U.S.C. 119 e of U.S. Provisional Patent Application No. 61 728 765 filed 20 Nov. 2012 U.S. Provisional Patent Application No. 61 728 770 filed 20 Nov. 2012 U.S. Provisional Patent Application No. 61 773 803 filed 6 Mar. 2013 U.S. Provisional Patent Application No. 61 728 773 filed 20 Nov. 2012 U.S. Provisional Patent Application No. 61 773 813 filed 7 Mar. 2013 U.S. Provisional Patent Application No. 61 773 815 filed 7 Mar. 2013 U.S. Provisional Patent Application No. 61 773 817 filed 7 Mar. 2013 U.S. Provisional Patent Application No. 61 775 688 filed 11 Mar. 2013 U.S. Provisional Patent Application No. 61 775 687 filed 11 Mar. 2013 and U.S. Provisional Patent Application No. 61 775 686 filed 11 Mar. 2013 which are all incorporated herein by reference.

Mobile electronic devices provide a user with access to computing capabilities even as the user moves about various locations. Examples of mobile electronic devices include mobile phones media players laptops tablets PDAs or hybrid devices that include functionality of multiple devices of this type.

Mobile electronic devices may be part of a communication network such as a local area network wide area network cellular network the Internet or any other suitable network. A mobile electronic device may use a communication network to communicate with other electronic devices for example to access remotely stored data access remote processing power access remote displays provide locally stored data provide local processing power or provide access to local displays. For example networks may provide communication paths and links to servers which may host applications content and services that may be accessed or utilized by users via mobile electronic devices. The content may include text video data audio data user settings or other types of data. Networks may use any suitable communication protocol or technology to facilitate communication between mobile electronic devices such as for example BLUETOOTH IEEE WI FI 802.11a b g n ac or TCP IP.

Particular embodiments of an wearable electronic device include a stack up that allows some or all of the processing and display system to fit inside the body of the device which may be encompassed by an element such as an outer ring that provides at least one way for the user to interact with the device. In addition or the alternative particular embodiments may include external components incorporated into the band for additional functionality as described more fully herein. illustrates an example stack up of an wearable electronic device. As illustrated in some or all of the components of stack up may adopt the form of the device which is circular in the example of . Stack up may include a layer of protective glass or other suitable transparent solid material . Other components may be laminated to protective glass or be attached to base . In addition or the alternative protective layer may be mechanically connected to outer ring or any other suitable component of the body of the device. Directly beneath protective glass may be a touch sensitive layer . Touch sensitive layer may be composed of any suitable material and be of any suitable type such as for example resistive surface acoustic wave capacitive including mutual capacitive or self capacitive infrared optical dispersive or any other suitable type. Touch sensitive layer may be applied directly to protective glass laminated onto it or physically affixed to. Touch sensitive layer may be a fully two dimensional touch surface or may be composed of touch sensitive regions such as a number of capacitive buttons or areas. Touch sensitive layer may be connected to processor board via a flexible connector at the edge of the touch surface as described more fully herein

Below the touch sensitive layer may be a circular display which may be laminated or mechanically affixed to any of the preceding or forgoing layers. In particular embodiments lamination may reduce glare and improve display legibility by reducing internal reflections. As described more fully below display may have an outer inactive area that may be symmetric or asymmetric. Display may be positioned such that it is axially centered relative to protective layer for a visually symmetric presentation. Display may be of any suitable type such as for example light emitting diode LED organic light emitting diode OLED or liquid crystal display LCD . In particular embodiments display may be flexible. In particular embodiments display may be partially transparent. In particular embodiments display may be translucent.

Below display may be battery which in particular embodiments may be positioned so that base may be reduced in diameter without affecting the size of the battery. Battery may be of any suitable type such as for example lithium ion based. Battery may adopt the circular shape of the device or may adopt any other suitable shape such as a rectangular form as illustrated. In particular embodiments battery may float in the device e.g. may have space above below or around the battery to accommodate thermal expansion. In particular embodiments high height components such as for example haptic actuators or other electronics may be positioned in the additional space beyond the edge of the battery for optimal packing of components. In particular embodiments connectors from processor board may be placed in this space to reduce the overall height of the device.

Below battery may be processor board . Processor board may include any suitable processing components such as for example one or more processing units drive units sense units caches memory elements or integrated circuits. Processor board may include one or more heat sensors or cooling units such as e.g. fans for monitoring and controlling the temperature of one or more processor board components. In particular embodiments body of the device may itself act as the heat sink

Below the processor board may be an encoder encircled by one or more outer rings . As described more fully below encoder may be of any suitable type and may be part of outer ring or may be a separate component as illustrated in . In particular embodiments outer ring may provide the haptic feel of the detent of the outer ring or position sensing of the outer ring . When encoder is a mechanical encoder separate from the device body as illustrated in the encoder may support the outer ring . For example in particular embodiments encoder is mounted to base and the connections to base or to band may pass through some portion of the encoder such as for example the center of the encoder. In particular embodiments processor board and one or more layers above may be attached to a central post passing through encoder . The post may transfer mechanical forces on components of the device to the post which may allow components such as the processor board and the display to be supported by the post rather than by the encoder reducing strain on the encoder. In particular embodiments outer ring attaches to the moveable portion of the encoder via prongs or other suitable connections.

The device body may conclude with a base . Base may be stationary relative to the one or more rotatable components of the device such as outer ring . In particular embodiments base connects to band described more fully herein. Connections may be mechanical or electrical such as for example part of the circuitry linking wired communication components in band to processing board . In particular embodiments connectors are positioned to avoid the encoder and the anchor points for the bands. In particular embodiments band may be detachable from base . As described more fully herein band may include one or more inner connectors one or more optical sensing modules or one or more other sensors. In particular embodiments the interior of the device or portions of that interior may be sealed from the external environment.

While this disclosure describes specific examples of components in stack up of wearable electronic device and of the shape size order connections and functionality of those components this disclosure contemplates that a wearable device such as device may include any suitable components of any suitable shape size and order connected or communicating in any suitable way. As merely one example battery may be placed more toward the bottom of the stack up than is illustrated in . As another example the body of the device may take any suitable form factor such as elliptoid or disc like as illustrated by the example of tapered on one end as illustrated by the example of or beveled or rounded at one or more edges as illustrated by the example of illustrating beveled edge . illustrates additional example form factors of the device body such as for example bodies A E having a polygonal shape with a flat protective covering or display or a curved protective covering or display. As another example bodies A D have a partially curved shape with a flat protective covering or display or a curved protective covering or display. Bodies A C have a curved shape. One or more internal components of the device body such as for example one or more internal components may take any form factor suitable for the body in which they sit.

In particular embodiments the display of the device has a circular or elliptical form and houses a circular display unit such as for example an LCD display and an OLED display. The display unit may be mounted such that the visible area is centrally located within the display module. Should the display unit have an offset design one or more appropriate maskings may be used to obscure part of the display to produce a circular and correctly placed visual outline.

In particular embodiments a display module has an outer ring that is part of the user interface of the device. The outer ring may rotate while the band holds the bottom and inside part of the device stable. illustrates an example of a top view of the device s display relative to other device components. Outer ring may be attached to the front surface of device or it may be independent of front surface . In particular embodiments display does not rotate regardless of rotation of outer ring surrounding display . That may be achieved by attaching display to the portion of display module that is affixed to band or by programming displayed content to remain static while the display unit rotates. In the latter case displayed content is rotated such that the visual vertical axis of the image displayed by the display unit remains parallel to the band at all times.

A display module may additionally incorporate one or more sensors on or near the same surface as the display. For example the display module may include a camera or other optical sensor microphone or antenna. One or more sensors may be placed in an inactive area or of the display. For example illustrates device with a camera module placed coplanar with the battery below display with optical opening positioned under the clear section of display . Camera module may be placed between gird line connectors for display . Any camera or other suitable sensors may be placed coplanar with the display such as antenna of which is placed is inactive area . In addition or the alternative sensors may be placed below or above the display may be placed in any suitable location in or on the outer body of the device may be placed in any suitable location in or in the band of a device or any suitable combination thereof as described more fully herein. For example a front facing camera maybe placed under the display on the display or above the display.

In particular embodiments the packaging of a circular display includes an inactive area as illustrated in . In a traditional display row drive lines powering the display are routed to the nearest lateral edge then either routed down along the inactive areas or connected directly to the driver integrated chips along that edge. A number of approaches may be taken to reduce the amount of inactive area for the display. For example particular embodiments reduce the size of the inactive area by rerouting grid control lines powering the display to one edge of the display. illustrates grid control lines routed to one edge of display and connected to a connector routing the lines to the processing center of device . In that configuration inactive area may be minimized.

In particular embodiments all processing and RF components are located within the body of the device which may create a challenge in allowing RF signals to pass out of the device. The FPC board may additionally be attached to sides of the polygon where there is no connection to the display itself to allow the mounting of strip line stub ceramic or other antennae or other suitable sensors in the same plane as the display as illustrated in . As the antenna of is coplanar with the display interference from the dense mesh of wiring e.g. as illustrated in from the display is reduced.

In particular embodiments a display may be shielded from electromagnetic interference with the main processor board using a metal shield. In particular embodiments the metal shield may also be used as a heat sink for the battery and thus may improve charge or discharge rates for the battery.

In particular embodiments an wearable electronic device may include one or more outer elements which may be of any suitable shape about the device body. illustrates an outer element by an example outer ring about a display . Outer ring may be composed of any suitable material such as for example stainless steel or aluminum. In particular embodiments outer ring may be rotatable in one direction both directions or may be used in both configurations based on e.g. a switch. In particular embodiments one outer ring may rotate in one direction while a second outer ring rotates in the opposite direction. Outer ring may be coupled to base of the device by a retention ring . illustrates outer ring attached to base either by a Delrin ring A or by a sprint steel retention ring B. Springs or clips affix the rings to base . illustrate retention ring affixed to base via screws screwed into corresponding posts of base . The device may include fasteners spacers as illustrated in .

In particular embodiments detents or encoders which may be used interchangeably where suitable of an outer element may provide a user with haptic feedback e.g. a tactile click provided by for example a detent that allows the user to determine when the element has been moved one step or increment which may be used interchangeably herein. This click may be produced directly via a mechanical linkage e.g. a spring mechanism or may be produced electronically via a haptic actuator e.g. a motor or piezo actuator . For example a motor may provide resistance to motion of a ring such as for example by being shorted to provide resistance and unshorted to provide less resistance simulating the relative high and low torque provided by a mechanical detent system. As another example magnetic systems may be used to provide the haptic feel of a detent. For example a solenoid mechanism may be used to disengage the detent spring or escapement as needed. The spring or escapement provides the actual mechanical feedback. However this arrangement allows the device to skip a number of d tentes as needed while re engaging the detent at exact intervals to create the sensation of detents such as those that have changed size. As another example a rotatable outer element such as for example the outer ring may be magnetized such as by an electromagnetic used to attract the ring at detent positions increasing torque and simulating detent feedback. As another example a rotatable outer element may have alternating north south poles which repels and attracts corresponding magnetic poles in the device body. As another example a permanent magnet may be used to lock the ring in place when the electromagnet is not in use preventing freewheeling. As another example instead of an electromagnet an easily magnetizable ferromagnetic alloy may be used within a solenoid. This allows the electromagnetic field of the solenoid to reprogram the magnetic orientation of the core thus maintaining the effect of the magnetic actuation even when the solenoid itself is disengaged. While this disclosure provides specific examples of detents detent like systems and encoders this disclosure contemplates any suitable detents detent like systems or encoders.

In particular embodiments an encoder or detent may be used to determine the position of the outer ring relative to the device body. Particular embodiments utilize an encoder that is affixed to the device body as illustrated by encoder of . In particular embodiments the encoder is part of the inner surface of the outer ring itself as illustrated by printed optical elements in . In those embodiments the outer ring acts as the rotating part of the encoder directly. An optical encoder pattern is printed onto the inner surface and is read out by an optical module on the processing board. The encoder on the interior of the outer ring should have sufficient optical contrast for detectors and may be etched on the outer ring via e.g. printing or laser etching. The inner and outer rings may be environmentally sealed with a low friction ring such as for example ring of made of a material such as Teflon or Delrin that maintains a tight fit while preventing contaminants from entering the inner part of the device. In particular embodiments a lip on the inner ring may engage a similar lip on the outer ring allowing the two rings to be joined while still allowing free rotation. A larger lip at the bottom of the inner ring provides further sealing by deflecting environmental hazards from below. As illustrated in in particular embodiments sealing ring may fit into groove of the base which may include a grip area .

In particular embodiments a retention ring connecting the outer ring to the body of the device may have strain gages to detect pressure on the outer ring. As an example illustrates a retention ring connected to four strain gauges which are also connected to the inner body that are symmetrically placed around the ring. As used herein the four strain gauges may be an electronic component detecting strain. As a result of the symmetric placing normal motion or contact with the outer ring will place mostly asymmetric strain on the outer ring because the ring merely moves relative to the device in the plane of the ring and thus one end compresses and the opposite end elongates as illustrated by the top ring of . In contrast squeezing a larger portion of the outer ring will likely produce a symmetric strain on opposite pairs of strain gauges e.g. due to elongation of the ring under pressure . The relative difference in strain between the two pairs of strain gauges thus differentiates intentional squeezing of the outer ring from regular motion of or contact with the outer ring. While this disclosure describes specific examples of the number and placement of strain gauges in the retention ring this disclosure contemplates placement of any suitable number of strain gauges in any suitable component of the device to detect pressure on the component. As one example strain gauges may be placed on the band of the device or in the outer ring.

When strain is placed on a component containing strain gauges or any other suitable strain or pressure detection system the detected strain may result in any suitable functionality. For example when strain is placed on the outer ring such as for example by a user squeezing the outer ring feedback may be provided to the user. That feedback may take any suitable form such as tactile feedback e.g. vibration shaking or heating cooling auditory feedback such as beeping or playing a particular user defined tone visual feedback e.g. by the display of the device or any other suitable feedback or combination thereof. Functionality associated with squeezing a ring is described more fully herein and this disclosure contemplates any suitable functionality resulting from strain or pressure placed on and detected by any suitable components.

An wearable electronic device may be attached to a band to affix the device to the user. Here reference to a band may encompass any suitable apparatus for affixing a device to the user such as for example a traditional band that can be worn around the arm wrist waist or leg of the user as illustrated by way of example in a clip for affixing to a piece of clothing as illustrated by way of example in a necklace or bracelet configuration as illustrated by way of example in a keychain or other accessory configuration to secure the device for example in the user s pocket as illustrated by way of example in or any other suitable configuration. Each of those embodiments may include a camera located on the device on the band or on the body. illustrates various embodiments for wearing the device such as for example around a neck as illustrated in pinned to clothing such as for example the chest as illustrated by on a belt as illustrated in on an appendage such as for example an arm as illustrated in on the wrist as illustrated in or in a pocket as illustrated in . While this disclosure describes specific examples of bands and ways of affixing devices to a user this disclosure contemplates any suitable bands or ways of affixing a device to a user.

In particular embodiments sensors and corresponding electronics may be attached to a band where appropriate. For example the bands of may be suitable for housing an optical sensor. All illustrated particular embodiments may be suited for including a touch sensitive area. This disclosure contemplates any suitable bands including any suitable sensors or electronics such as for example communication components such as antennae environmental sensors or inertial sensors. In particular embodiments the band may be detachable from the device and may communicate remotely with the device when not attached to the device. In particular embodiments wiring associated with electrical components in the band may also be housed in the band for example to minimize the volume of the device or to minimize electromagnetic interference with internal device components. For example devices that may cause high levels of internal EMI for example camera or communication systems that may require additional volume for example battery or speaker that may require the environmental seal of the main body for example power data connector or that may require additional contact with the skin of the user for example biometric sensors may benefit by housing at least some of electronics in a band of the device. In particular embodiments when wiring is contained in a band a display module may be attached to the band such that electronic connections made to or via the band do not twist when the outer ring is rotated. The module may use a connector that is user removable such that the display module or device body can be removed and attached by the user at will. As an example attachment of a band to a device a band as illustrated in may be attached to the body by being placed over one or more posts and then affixed to those posts using fasteners e.g. screws . In particular embodiments in addition to fasteners and posts a retention plate may be used to secured the band to device as illustrated in . This disclosure contemplates any suitable interface between the band and the device. For example a USB interface may be provided between the band and the body of the device to for example communicate data between the device and the band or components of the device and components of the band. In particular embodiments an interface may enable a user of the device to easily detach attach or change the band of the device.

This disclosure contemplates any suitable structure for connecting a band as illustrated in to itself for example when worn by a user. For example illustrates example structures for fastening band having a camera module to a wearer of device . Fasteners may include one or more snaps holes and and corresponding components clasps or clips with push buttons . illustrates an example mechanism for affixing band to a wearer using clips and . Components insert in the cavity on the other side of components to fasten band . further illustrates example internal mechanisms for clips and . Component of clip corresponding to clip may include one or more magnetic portions which may be attracted to magnets in cavity . For example component may include a magnetic portion at its outer edge and a magnet of opposite polarity may be placed in front of spring to attract the magnet of component . Components may then fill cavity fastening clip to clip by coupling of the magnets. Once inserted components may be used to engage springs which force components out of cavity . Clip may be detached from clip . In addition to magnets on components and in cavity magnets may also be placed within clip for example to assist removal of clip when springs are engaged or to prevent components from sliding in and out of clip when not fastened to clip . For example one or more magnets may be placed in the center of clip equidistant from components and in the same plane as components attracting magnets of each component and thus the components themselves toward the center of clip .

In particular embodiments a band containing electrical components may also incorporate a traditional physical contact connector as illustrated by connector of . The connector may allow for connectivity with the device for example for charging system updates debugging or data transfer. Such a connector may be of the pogo variety or may be plated surfaces to which a charging cable can interface by contact. Such connectors may be plated in precious metals to prevent corrosion from exposure to moisture from the environment and the human body. In particular embodiments physical connectors may be used only for power and data may be transferred using short range communication modalities such as BLUETOOTH near field communication NFC technology or WI FI.

In particular embodiments a band may be used to house flexible batteries such as e.g. lithium based batteries to increase the energy storage of the device. As energy storage capacity may be tied to total volume batteries internal to the band increase the storage capacity for volume limited wearable devices without impacting the total size of the device body.

As described more fully below an wearable electronic device may include one or more sensors on or in the device. For example an wearable electronic device may include one or more optical sensors or depth sensors. Optical sensors may be placed in any suitable location such as for example on the face of the device on a band facing outward from the user s body on a band facing opposite the face on a band facing toward the user s body or any suitable combination thereof. illustrates a device with a band having an outward facing optical sensor . Placement of an optical sensor on the band may reduce the number of high frequency signals inside the case allowing for lighter shielding within the device body and thus weight and volume savings. illustrate example camera placements for different embodiments of an wearable electronic device. In particular embodiments electronics such as that for processing camera input may be located in the band as well for example in a volcano shape housing the camera as illustrated by housing in . In particular embodiments other sensors may be placed near an optical sensor such as for example in the same housing as the optical sensor on the band of the device. For example a depth sensor may be used in conjunction with an optical camera to enhance display or detection of a device s environment or to determine which object a user is pointing at or interacting with via a gesture.

In particular embodiments placement of an optical sensor on the band may be adjustable by the user within a predetermined range. In particular embodiments placement of an optical sensor on the band may be optimized such that the sensor is conveniently aimable by the user. For example as illustrated by if the user wears the device about the user s wrist optical sensor may be placed in an outward facing fashion such that the optical sensor aims outward from the user s body when the user s palm is roughly parallel to the ground.

In particular embodiments placement of an optical sensor may be such that the user may view the display of the device while the sensor is pointing outward from the user s body. Thus the user may view content captured by the optical sensor and displayed by the device without blocking the user s view of the physical scene captured by the sensor as illustrated by the viewing triangle in . A display of a device may have an associated viewing cone e.g. the volume within which the display can be reasonably viewed. In user 1 views a real trophy and 2 views an image of the trophy on display of device from within the viewing cone of display by aiming sensor at the real trophy. Sensor has an associated angle of view corresponding to a volume within which images can be reasonably captured by sensor . Note that in the example of sensor is placed such that the user can conveniently aim sensor outward while maintaining display of device in a direction facing the user and can do so without device blocking the user s view of trophy .

In particular embodiments an optical or depth sensor module which may be used interchangeably where appropriate may communicate with a device via a simple extension of the bus the optical sensor would use if it were directly mounted on the main printed circuit board PCB as illustrated in . In optical sensor transmits data over flexible printed circuits or wiring to an integrated control which in the example of is located in or on device which houses the main printed circuit board. illustrates the optical sensor integrated circuit on or in the optical sensor module which also houses optical sensor . Communication between the main printed circuit board of device and electronics in camera module occur via flexible printed circuit . The arrangement of may allow an integrated circuit to compress and otherwise process the data and send it via a method that requires fewer signal lines or that requires a smaller transfer of data. That may be beneficial since the band must flex when the user wears the device and thus a smaller number of lines may be desirable. Such an approach can reduce the number of lines to one or two signal lines and two power lines which is advantageous for packaging molding and reliability. In particular embodiments one or more of the electronics described above must be shielded to prevent electromagnetic interference from the long high frequency cabling. The use of a parallel bus is common is such cases and may require the use of a larger cable or FPC.

In one embodiment the camera control integrated circuit may be mounted directly on a small circuit board at the optical module as illustrated in . An wearable electronic device may include any suitable sensors. In particular embodiments one or more sensors or its corresponding electronics may be located on a band of the device in or on the body of a device or both. Sensors may communicate with each other and with processing and memory components through any suitable wired or wireless connections such as for example direct electrical connection NFC or BLUETOOTH. Sensors may detect the context e.g. environment or state of the device the user an application or another device or application running on another device. This disclosure contemplates an wearable electronic device containing any suitable configuration of sensors at any suitable location of the wearable electronic device. In addition this disclosure contemplates any suitable sensor receiving any suitable input described herein or initiating involved in or otherwise associated with the provision of any suitable functionality or services described herein. For example touch sensitive sensors may be involved in the transition between graphical user interfaces displayed on the device as described more fully herein. This disclosure further contemplates that functionality associated with the wearable device activation deactivation of sensors sensitivity of sensors or priority of sensor processing may be user customizable when appropriate.

Sensors may internally produce sensor data which may be simply filtered or reformatted by for example a detector or data conditioner. Raw data may be formatted to an uniform format by the data formatter for ingestion by the Application API. Recognizers may use numeric models such as decision trees heuristic models pattern recognition or any other suitable hardware software and techniques to detect sensor data such as gesture input. Recognizers may be enabled or disabled by the API. In such cases the associated sensors may also be disabled if the recognizer is not to receive data from the sensors or is incapable of recognizing the sensor data.

A device may incorporate a database of sensor outputs that allow the same detector to detect many different sensor outputs. Depending on the requests produced by the API a sensor priority decoder may suppress or pass through sensor output based on criteria supplied. The criteria may be a function of the design of the API. In particular embodiments recognizers may ingest the output of more than one sensor to detect sensor output.

In particular embodiments multiple sensors may be used to detect similar information. For example both a normal and a depth sensing camera may be used to detect a finger or both a gyroscope and a magnetometer may be used to detect orientation. When suitable functionality that depends on or utilizes sensor information may substitute sensors or choose among them based on implementation and runtime considerations such as cost energy use or frequency of use.

Sensors may be of any suitable type and as described herein may be located in or on a device body in or on a band or a suitable combination thereof. In particular embodiments sensors may include one or more depth or proximity sensors terms which may be used interchangeably herein when appropriate such as for example infrared sensor optical sensors acoustic sensors or any other suitable depth sensors or proximity sensors. For example a depth sensor may be placed on or near a display of a device to detect when e.g. the user s hand finger or face comes near the display. As another example depth sensors may detect any object that a user s finger in the angle of view of the depth sensor is pointing to as described more fully herein. Depth sensors also or in the alternative may be located on a band of the device as described more fully herein. In particular embodiments sensors may include on or more touch sensitive areas on the device body band or both. Touch sensitive areas may utilize any suitable touch sensitive techniques such as for example resistive surface acoustic wave capacitive including mutual capacitive or self capacitive infrared optical dispersive or any other suitable techniques. Touch sensitive areas may detect any suitable contact such as swipes taps contact at one or more particular points or with one or more particular areas or multi touch contact such as e.g. pinching two or more fingers on a display or rotating two or more fingers on a display . As described more fully herein touch sensitive areas may comprise at least a portion of a device s display ring or band. Like for other sensors in particular embodiments touch sensitive areas may be activated or deactivated for example based on context power considerations or user settings. For example a touch sensitive portion of a ring may be activated when the ring is locked e.g. does not rotate and deactivated when the ring rotates freely. In particular embodiments sensors may include one or more optical sensors such as suitable cameras or optical depth sensors.

In particular embodiments sensors may include one or more inertial sensors or orientation sensors such as an accelerometer a gyroscope a magnetometer a GPS chip or a compass. In particular embodiments output from inertial or orientation sensors may be used to activate or unlock a device detect one or more gestures interact with content on the device s display screen or a paired device s display screen access particular data or activate particular functions of the device or of a paired device initiate communications between a device body and band or a device and a paired device or any other suitable functionality. In particular embodiments sensors may include one or more microphones for detecting e.g. speech of a user or ambient sounds to determine the context of the device. In addition in particular embodiments a device may include one or more speakers on the device body or on the band.

In particular embodiments sensors may include components for communicating with other devices such as network devices e.g. servers or routers smartphones computing devices display devices e.g. televisions or kiosks audio systems video systems other wearable electronic devices or between a band and a device body. Such sensors may include NFC readers beacons BLUETOOTH technology or antennae for transmission or reception at any suitable frequency.

In particular embodiments sensors may include sensors that receive or detect haptic input from a user of the device such as for example piezoelectrics pressure sensors force sensors inertial sensors as described above strain stress sensors or mechanical actuators. Such sensors may be located at any suitable location on the device. In particular embodiments components of the device may also provide haptic feedback to the user. For example one or more rings surfaces or bands may vibrate produce light or produce audio.

In particular embodiments an wearable electronic device may include one or more sensors of the ambient environment such as a temperature sensor humidity sensor or altimeter. In particular embodiments an wearable electronic device may include one or more sensors for sensing a physical attribute of the user of the wearable device. Such sensors may be located in any suitable area such as for example on a band of the device or on base of the device contacting the user s skin. As an example sensors may include acoustic sensors that detects vibrations of a user s skin such as when the user rubs skin or clothing covering skin near the wearable device taps the skin near the device or moves the device up and down the user s arm. As additional examples a sensor may include one or more body temperature sensors a pulse oximeter galvanic skin response sensors capacitive imaging sensors electromyography sensors biometric data readers e.g. fingerprint or eye and any other suitable sensors. Such sensors may provide feedback to the user of the user s state may be used to initiate predetermined functionality e.g. an alert to take particular medication such as insulin for a diabetic or may communicate sensed information to a remote device such as for example a terminal in a medical office .

An wearable electronic device may include one or more charging components for charging or powering the device. Charging components may utilize any suitable charging method such as capacitive charging electromagnetic charging trickle charging charging by direct electrical contact solar kinetic inductive or intelligent charging for example charging based on a condition or state of a battery and modifying charging actions accordingly . Charging components may be located on any suitable portion of the device such as in or on the body of the device or in or on the band of a device. For example illustrates a charger with slot for connecting a charging component with the charger. For example slot may use friction mechanical structures such as latches or snaps magnetism or any other suitable technique for accepting and securing a prong from a charging component such that the prong and charger make direct electrical contact. illustrates prong on band utilizing pogo style connectors to create a circuit connection between charger and band through contacts . In particular embodiments prong may be on charger and slot of may be on the band or body of the wearable device. In particular embodiments contacts such as for example pogo style connectors may be on the body of the device which may be used to create a circuit between the band or the charger for charging the device. Charger of may be connected to any suitable power source such as for example power from an alternating current AC outlet or direct current DC power from a USB port on a computing device by any suitable wired or wireless connection.

Charger may be made of any suitable material such as acrylic and in particular embodiments may have a non slip material as its backing such as e.g. rubber. In particular embodiments charger may be affixed or attached to a surface for example may be attached to a wall as illustrated in . Attachment may be made by any suitable technique such as for example by mechanically magnetically or adhesively. In particular embodiments an wearable electronic device may be fully usable while attached to the charger. For example when a charging component is located on the body of the device the device may sit in the charger while a user interacts with the device or other devices communicate with the device.

As another example of a charging components in a wearable electronic device illustrate additional example chargers using e.g. inductive charger. As illustrated in a band may include one or more charging coils . As described above this disclosure contemplates charging coils or any other suitable charging component incorporated in or on the body of the device in alternative to or in addition to on the band of the device. A magnetic field generated by e.g. charging surface or charging surface passes through charging coil . Charging surface of may improve the density of the magnetic field through charging coil relative to charging surface and allows more precise placement than charging surface thus improving the charge transfer rate of the system. This disclosure contemplates that when suitable charging may power components on or on the body of the device components in or on the band or both.

In particular embodiments the band or device may implement an antenna for a wireless charging solution. Since wireless charging operates optimally in the absence of ferrous metals this allows a wider choice of materials for the body of the device while allowing improved wireless charging transfer capacity by allowing the coil to be held between the poles of a charging driver as described above rather than being simply coplanar to the driver. As described above and illustrated in the active band may also incorporate a traditional internal physical contact connector .

In particular embodiments a charging unit with an internal charge reservoir may be associated with a wearable electronic device. When plugged into the wall the charging unit can charge both an attached device and the charging unit s internal reservoir. When not plugged in the charging unit can still charge an attached device from its reservoir of power until that reservoir is depleted. When only the charger is connected to a power source without a device it still charges itself so that it can provide additional power for the device at a later point. Thus the charging unit described herein is useful with and without being plugged into a power source as it also can power any partially charged device for a while when a person is not able to connect to a power source for example when travelling on plane train station outdoors or anywhere a user might need charge for a device but does not have access to a power source. The device can be both in standby or in use while the charger charges the device and no modifications to the software or hardware of the target device is needed. Additional benefits of one or more embodiments of the invention may include reducing the number of items one must carry providing the benefits of both a charger and a power pack making charger useful to carry when on the move and reducing the number of cables and connectors one must carry to extend the battery life of their devices. This disclosure contemplates that such a charging unit may be applied to any suitable electronic devices including but not limited to an wearable electronic device.

As described above a charging unit can charge a device from the charging unit s internal charging reservoir even when not connected to an external power source and can charge itself a connected device or both when connected to an external power source. This disclosure contemplates any suitable scheme for allocating charge between the charging unit and device. Such allocation scheme may depend on the amount of charge internal to the device internal to the charging unit the amount of power being consumed by the device the charging capabilities of an external power source or any suitable combination thereof. In addition or the alternative charging threshold may determine which allocation scheme to use. For example one charging scheme may be used when the device is near full charge and the charging unit has little charge left and another may be used when the device has little charge left. illustrate example charging schemes for the charging unit and connected device. For example as illustrated in when a device gets connected to a charger as in step step determined whether the device is fully charged. If yes no further charging action is taken. If not step determines whether the charger is connected to an external power source such as for example line voltage. If so the device is charged from that external source in . If not step determines whether the charger has any power left and if so the device is charged from the charger s internal power source in step from line voltage rather than the charging unit s reservoir when the charging unit is connected to the line voltage. illustrates a similar decision tree. If a device is connected to a charger step that is connected to a power source step then step determines whether the device is fully charged and if not the device is charged from the power source the charger is connected to step . Similarly step determines whether the charger is fully charged and if not the charger unit is charged from the power source in step . In particular embodiments the allocation scheme used may be determined or customized by a user.

Continuing the example of when line voltage converter is not providing power charger regulator produces the appropriate charging voltage from the power on battery . Regulator may be always on or it may be switched on by connection to the device or the press of a button that indicates the user wishes to charge the device. Once activated regulator will charge the device until internal reserves are depleted. At that point some charge may still remain in battery to improve battery life but it will not be available to the user. The device may incorporate an emergency mode that allows access to some of this energy to gain a minimal amount of emergency usage time at the cost of battery lifetime. Regulator may continue to provide energy until either the device is unplugged or until the device only draws a minimal amount of energy indicating completion of charge. Finally charger regulator may include an on demand display that shows the amount of energy remaining in reserve to the user. Since displays generally use energy a button or other input may be used to trigger the display for a limited time. While illustrates an example internal architecture of an example charging unit this disclosure contemplates any suitable internal architecture of any suitable charging unit described herein and contemplates that such a charging unit may be of any suitable size and shape.

In particular embodiments functionality or components of the device such as e.g. sensors may be activated and deactivated for example to conserve power or reduce or eliminate unwanted functionality. For example a locked state detector detects when the device is inactivated and disables sensors as needed to conserve power while monitoring the sensor data for a gesture or other suitable input that may reactivate the device. A device may have one or more power modes such as sleep mode or fully active mode. As one example in particular embodiments the device is arm worn and a touch surface of the device may come in contact with objects and persons while in regular use. To prevent accidental activation an accelerometer or other inertial sensor in the body or band of the device can be used to gauge the approximate position of the device relative to the gravity of the Earth. If the gravity vector is detected towards the sides of the device e.g. the device is determined by at the user s side or the display is determined not to be pointed at the user the touch screen can be locked and display disabled to reduce energy use. When the gravity vector is determined to be pointing below the device e.g. the device is roughly horizontal resulting in a determination that the user is viewing or otherwise using the device the system may power up the display and enable the touch screen for further interactions. In particular embodiments in addition or in the alternative to the direction of the gravity vector waking or unlocking a device a rate of change of the direction or magnitude of the gravity vector may be used to wake or unlock a device. For example if the rate of change of the gravity vector is zero for a predetermined amount of time in other words the device has been held in a particular position for the predetermined amount of time the device may be woken or unlocked. As another example one or more inertial sensors in the device may detect a specific gesture or sequence of gestures for activating a display or other suitable component or application. In particular embodiments the encoder of the device is robust to accidental activation and thus can be left active so that the user may change between selections while bringing the device up to their angle of view. In other embodiments the encoder may be deactivated based on context or user input.

In addition or the alternative to power conservation particular embodiments may lock one or more sensors particular functionality or particular applications to provide security for one or more users. Appropriate sensors may detect activation or unlocking of the secure aspects of the device or of another device paired with or communicating with the wearable device. For example a specific gesture performed with the device or on a touch sensitive area of the device may unlock one or more secure aspects of the device. As another example particular rotation or sequence of rotations of a rotatable ring of the device may unlock one or more secure aspects of the device on its own or in combination with other user input. For example a user may turn a rotatable ring to a unique sequence of symbols such as numbers or pictures. In response to receiving the sequence of rotational inputs used to turn the rotatable ring the display may display the specific symbol s corresponding to each rotational input as described more fully herein. In particular embodiments the symbols used may be user specific such as e.g. user pictures stored on or accessible by the device or symbols pre selected by the user . In particular embodiments different symbols may be presented to the user after a predetermined number of unlockings or after a predetermined amount of time. The example inputs described above may also or in the alternative be used to activate deactivate aspects of the device particular applications or access to particular data. While this disclosure describes specific examples of user input unlocking secure aspects of a device this disclosure contemplates any suitable input or combination of inputs for unlocking any secure aspect of the device. This disclosure contemplates that input or other suitable parameters for unlocking secure aspects of a device or activating deactivating components of the device may be user customizable.

In particular embodiments an wearable electronic device may detect one or more gestures performed with or on the device. Gestures may be of any suitable type may be detected by any suitable sensors e.g. inertial sensors touch sensors cameras or depth sensors and may be associated with any suitable functionality. For example one or more depth sensors may be used in conjunction with one or more cameras to capture a gesture. In particular embodiments several depth sensors or cameras may be used to enhance the accuracy of detecting a gesture or the background associated with a gesture. When appropriate sensors used to detect gestures or processing used to initiate functionality associated with a gesture may be activated or deactivated to conserve power or provide security as described more fully above. As shown above illustrates an example sensor detection system and provides specific examples of gesture detection processing and prioritization. In particular embodiments specific applications may subscribe to specific gestures or to all available gestures or a user may select which gestures should be detectable by which applications. In particular embodiments gestures may include manipulation of another device while using the wearable device. For example a gesture may include shaking another device while aiming moving or otherwise utilizing the wearable device. This disclosure contemplates that where suitable any of the gestures described herein may involve manipulation of another device. While the examples and illustrations discussed below involve specific aspects or attributes of gestures this disclosure contemplates combining any suitable aspects or attributes of the gesture and sensor described herein.

In particular embodiments an wearable electronic device may detect one or more gestures performed with or on the device. Gestures may be of any suitable type may be detected by any suitable sensors e.g. inertial sensors touch sensors cameras or depth sensors and may be associated with any suitable functionality. For example one or more depth sensors may be used in conjunction with one or more cameras to capture a gesture. In particular embodiments several depth sensors or cameras may be used to enhance the accuracy of detecting a gesture or the background associated with a gesture. When appropriate sensors used to detect gestures or processing used to initiate functionality associated with a gesture may be activated or deactivated to conserve power or provide security as described more fully above. . As described more fully above illustrates an example sensor detection system and provides specific examples of gesture detection processing and prioritization. In particular embodiments specific applications may subscribe to specific gestures or to all available gestures or a user may select which gestures should be detectable by which applications. In particular embodiments gestures may include manipulation of another device while using the wearable device. For example a gesture may include shaking another device while aiming moving or otherwise utilizing the wearable device. This disclosure contemplates that where suitable any of the gestures described herein may involve manipulation of another device. While the examples and illustrations discussed below involve specific aspects or attributes of gestures this disclosure contemplates combining any suitable aspects or attributes of the gesture and sensor described herein.

In particular embodiments gestures may include gestures that involve at least on hand of the user and an appendage on which the device is worn such as e.g. the other wrist of the user. For example in particular embodiments a user may use the hand arm on which the device is worn to appropriately aim an optical sensor of the device e.g. a camera or depth sensor and may move or position the other arm hand fingers to perform a particular gesture. As described herein and illustrated in in particular embodiments the scene aimed at may be displayed on the device s display such that a user can view both the real scene the scene as displayed on the device and the user s hand arm fingers if in the angle of view of the. In particular embodiments the displayed scene may include the hands fingers arm used detected by the sensor and used to perform the gesture. illustrate example gestures in which the user aims an outward facing e.g. away from the body of the user sensor on the device e.g. on the band of the device as illustrated in the figures and moves or positions his other arm hand fingers to perform a gesture. For example in an outward sensor detects an object in the angle of view of the sensor an outward sensor which may be the same sensor detecting the object detects one or more fingers pointing at the object and when the pointing finger s are determined to be at rest a gesture is detected . Referring to raw gesture data captured by the outward facing camera can be conditioned and cleaned of noise and that data can be sent to the Heuristic Gesture Detector. The Gesture Priority Decoder processes the gesture data and determines when the gesture has been identified with sufficient certainty. When the gesture has been identified the gesture is sent to the Sensor Hub Driver which provides an API to the end applications and system controllers.

As examples of functionality associated with this gesture a camera may focus on the object the object detected and pointed at may then appear on the display information about that object may appear on the display and displayed content may be transferred to another device s display e.g. when the object is another device . illustrates an example gesture similar to the gesture of however the illustrated gesture includes the outward facing sensor detecting a tapping motion of the finger s e.g. that the finger s are moving away from the sensor . For example the gesture of may include detecting an object in the scene of a camera or other suitable sensor in step detecting the finger in the scene in step detecting a lack of lateral movement of the finger in step detecting the finger tip moving further away from the sensor in step and detecting a gesture in step . The gesture illustrated in may provide any suitable functionality. For example the tapped object may be selected from the objects displayed on the display screen.

In particular embodiments a gesture may include a motion of the wearable device such as for example by the arm wearing the device. The motion may be detected by any suitable sensors such as inertial sensors orientation sensors or any suitable combination thereof. illustrate example gestures involving detection of the gravity vector relative to the device e.g. pointing in the direction of the device face or pointing down through the base and detecting subsequent motion of the device relative to that gravity vector. For example may include detecting the gravity pointing downward through the face in step detecting acceleration of the device along the same axis as the gravity vector is pointing in step detecting that the acceleration of the device remains for some time step in step and detecting a gesture in step . is substantially similar to the gesture of except that the gravity vector points down through the base rather than the face in step . illustrates a gesture that uses a gravity vector to determine orientation position of the device for example that the device is not by the user s body. Motion of the device from the detected orientation such as for example perpendicular to the gravity vector may be detected resulting in a gesture. For example a detected gravity orientation may indicate that an arm is not by the side of the body in step a lateral acceleration of the device may be detected in step the acceleration may be detected for some time in step and a gesture may be detected in step . As indicate detecting an aspect of the motion e.g. duration of acceleration may trigger a gesture and ranges of an aspect ranges of duration of motion may each correspond to a different gesture. illustrate rotational motion of a device. As in detection of the initial orientation or position of the device may be part of the gesture detection. For example the gesture of may include detecting that the gravity vector indicates the arm is not by the side of the body in step detecting some rotational motion in step estimating that the radius of the rotational motion is large enough for elbow motion in step estimating the relative rotation in step and detecting a gesture in step . As another example the gesture of may include detecting that the gravity vector indicates the arm is not by the side of the body in step detecting some rotational motion in step estimating that the radius of the rotational motion is small enough for wrist motion in step estimating the relative rotation in step and detecting a gesture in step . As illustrated in a gesture may include estimating the type of rotation of the device such as for example rotation primarily from the shoulder rotation primarily from the elbow or any other suitable rotation. In addition or in the alternative to the radius of rotation a gesture may include detecting the amount of rotation duration of rotation radial acceleration of the rotation any other suitable aspect of the rotation or any suitable combination thereof.

Like for indicates a gesture involving detecting the initial orientation or position of the device. For example the gesture of may include detecting the gravity vector indicates that the arm is not by the side of the body in step detecting lateral acceleration of the arm along the axis of the arm in step detecting that the acceleration remains for some time in step and detecting a gesture in step . illustrates that a gesture may include motion of the device along the axis of the appendage wearing the device such as for example the acceleration of the device along that axis. The gesture may include an impact along the path of motion e.g. caused by the hand stopping or contacting an object and subsequent reversal of the motion. The back and forth motion may repeat until the motion stops or the hand returns to some position such as e.g. the user s side. In particular embodiments different gestures may be based on the number or frequency of the back and forth motion. For example the gesture of may include detecting the gravity vector indicates that the arm is not by the side of the body in step detecting that the hand is in motion in step detecting an impulse impact along the path of the motion in step detecting that the hand reversed motion along the same linear path in step repeating steps and as suitable detecting that the motion stops for some time in step and detecting a gesture in step .

In particular embodiments gesture may optionally include detecting some non motion or non orientation input. For example illustrate a gesture comprising detection of acoustics although the gestures illustrated do not require such detection. illustrates an acoustic output such as e.g. ringing from an incoming or outgoing telephone call or response followed by some motion of the device such as the device being brought to a user s face . For example an audio response or output is initiated in step upward motion is detected in step stopping of upward motion is detected in step the gravity vector is within a predetermined window in step and a gesture is detected in step . In particular embodiments a gesture may include detecting the gravity vector in a particular orientation or orientation window as illustrated. The gesture of may also include detecting the position of the user s hand fingers. As an example of functionality that may be associated with the gesture illustrated in if the fingers are brought near the ear or face in the position indicated the user may answer or place a telephone call. and steps illustrates an example gesture having similar attributes as those described for but involving different orientation of the user s hand fingers. illustrates an example gesture including acoustics generated by the user e.g. by the user snapping her fingers together which are detected by a microphone associated with the device. For example may include detecting a gravity vector indicating an arm is not by the side of the body in step detecting a motion with relatively high acceleration in step detecting a sudden change in one or more acoustic frequencies in step and detecting a gesture in step . As illustrated in the snap motion may be detected solely by the motion generated by the snap alone e.g. by the vibration of the user s hand skin or by some degree or rate of change of rotation due to the snap or may be detected by the combination of motion plus an auditory input generated by the snap. In particular embodiments the auditory confirmation must be detected within a predetermined time of the motion for the gesture to be detected.

In particular embodiments a gesture may include interacting directly with the body or band of a wearable device. For example illustrates a gesture involving contact with a touch sensitive area of a band worn about the user s wrist. The gesture may include detecting that the device is not in a locked state in step detecting an absence of touch on a band in step detecting touch on the band in step decoding the position of the ouch in step and detecting a gesture in step . illustrates that touches in multiple positions may be determined to be a single gesture such as for example to unlock a device or aspects of the device. The gesture may include detecting that the device is not in a locked state in step detecting an absence of touch on a band in step detecting touch on the band in step decoding the position of the ouch in step decoding an action in step and detecting a gesture in step . illustrates that a gesture may include contacting a touch sensitive area of a device and sliding across a touch sensitive area while maintaining contact with the device. The gesture may include detecting that the device is not in a locked state in step detecting an absence of touch on a band in step detecting touch on the band in step detecting movement of the touch point s in step decoding relative motion in step and detecting a gesture in step . In particular embodiments a gesture may include the duration of contact physical area of contact e.g. with one finger or two fingers the sequence of contact pressure generated by contact or any other suitable contact related attribute. While illustrate contact with a touch sensitive area on a band this disclosure contemplates that a gesture may involve contact on a touch sensitive area on any suitable location of the device such as the device band ring display or any suitable combination thereof. For example illustrate contact with touch sensitive areas on a ring of the device similar to the gestures of . For example a gesture may include detecting that the device is not in a locked state in step detecting lack of touch on a ring in step detecting touch on the ring in step and detecting a gesture in step . As another example a gesture may include detecting that the device is not in a locked state in step detecting lack of touch on a ring in step detecting touch on the ring in step detecting movement of the touch point in step decoding relative motion in step and detecting a gesture in step . illustrates a gesture involving multi touch contact with a touch sensitive area of a device face and detecting subsequent motion of the contact points caused by e.g. motion of the fingers contacting the touch sensitive area or by movement of the wrist hand on which the device is worn. The gesture may include detecting that the device is not in a locked state in step detecting lack of touch on a surface in step detecting at least two fingers touching the surface in step detecting movement of the touch points in step decoding relative motion in step and detecting a gesture in step . Motion of the wrist hand may be detected by e.g. inertial sensors in the device allowing the different ways of moving touch points to be two distinct gestures. illustrates a gesture involving initial contact with a device which may detected by one or more proximity sensors on or in the device or inertial sensors on or near the device. The gesture may involve detecting that the contact persists indicating that e.g. the user has put the device on. For example the gesture may include detecting no contact with the rear or band proximity sensor in step detecting contact by the proximity sensor in step detecting that the contact persists in step and detecting a gesture in step . The gesture of may unlock or power on a sleeping device or provide any other suitable functionality.

In particular embodiments a gesture may include contact with skin near the device. illustrates a gesture involving tapping on the skin near where the device is worn. The tapping may be detected by vibration sensors in the device. The tapping motion may be confirmed by e.g. one or more acoustic sensors detecting sound generated by the tapping gesture. For example the gesture may include detecting that the device is unlocked in step detecting motion with a relatively high acceleration in step detecting the sound of for example a tap in step matching the motion or sound to a pattern in step and detecting a gesture in step . illustrates a gesture involving swiping of the skin near the device which may be detected and confirmed by the sensors described in above. For example the gesture may include detecting that the device is unlocked in step detecting motion with a relatively high acceleration in step detecting the sound of for example a tap in step detecting the vibrations or sound of lateral movement on the skin in step matching the motion or sound to a pattern in step and detecting a gesture in step .

In particular embodiments gestures may involve detecting metaphoric gestures made by the hand not wearing the device. For example such gesture may be detected by e.g. any suitable front facing sensor on or near the display of the device oriented such that the hand not wearing the device is in the angle of view of the sensor. illustrates an example gesture involving a front facing sensor detecting motion of multiple fingers such as tapping of the fingers. For example the gesture may include determining that the device is in a predetermined orientation in step detecting a fingertip in step detecting motion of the fingertip in step or detecting a tap sound in step and detecting one or more gestures in steps and . illustrates an example gesture involving motion of a single finger. For example the gesture may include determining that the device is in a predetermined orientation in step detecting a fingertip in step detecting motion of the fingertip in step or detecting a tap sound in step and detecting one or more gestures in step . illustrates a gesture involving detecting movement of a hand holding an object detecting the motion of the object locking on to the object and then detecting subsequent motion of the object. As a specific example the gesture may include detecting that the device is in a predetermined orientation in step detecting a hand in step detecting motion of the hand in step detecting an additional object to be moving the hand in step locking on the object in step detecting motion of the object in step and detecting a gesture in step . For example an object may be a pen or other stylus like implement and the front facing sensor on the device may detect writing motions of the implement to e.g. generate store text on the device or on another device communicating with the wearable device. The example of may allow a user to generate drawings notes or other written content without actually generating written content on a display or other writing surface. As described more fully herein any suitable gesture or combination of gestures may be used to impact or initiate augmented reality AR functionality and may be used to perform tasks using AR functionality. For example the gestures of may used to capture a user s interaction with a virtual keyboard virtual mouse or virtual touchscreen and those interactions may generate input on the wearable device or any other suitable paired device. While this disclosure describes specific examples of metaphoric gestures and object detection and associated functionality this disclosure contemplates any suitable metaphoric gestures detection of any suitable objects and such gestures associated with any suitable functionality.

In particular embodiments a gesture may involve the entire appendage on which a device is affixed or worn. For example illustrate example gestures involving motion of the arm on which the device is worn. The gestures may include detecting the initial position of the arm e.g. via an accelerometer detecting the direction of the gravity vector detecting the motion of the device via the arm detecting the corresponding change in the gravity vector and detecting that the arm has stopped moving. Such gestures may also include detecting the duration of movement the amount of movement e.g. detecting a large radius of motion confirming that the entire arm has moved the acceleration of movement or any other suitable movement related attributes. As illustrated by gestures may involve detecting arm movements above the head to the front to the side to the back or down from an initially higher starting position. For example a gesture may include detecting a gravity vector indicating a hand is on the side of the body in step detecting upward movement of the hand in step detecting that the gravity vector indicates the hand is above the head in step detecting the hand stopping movement in step and detecting a gesture in step . As another example a gesture may include detecting a gravity vector indicating a hand is on the side of the body in step detecting upward and forward movement of the hand in step detecting that the gravity vector indicates the hand is horizontal in step detecting the hand stopping movement in step and detecting a gesture in step . As another example a gesture may include detecting a gravity vector indicating a hand is horizontal in step detecting the hand moving downward and backward in step detecting that the gravity vector indicates the hand is by the side in step detecting the hand stopping movement in step and detecting a gesture in step . As another example a gesture may include detecting a gravity vector indicating a hand is by the side of the body in step detecting the hand moving upward and backward in step detecting that the gravity vector indicates the hand is horizontal in step detecting the hand stopping movement in step and detecting a gesture in step . As another example a gesture may include detecting a gravity vector indicating a hand is by the side of the body in step detecting the hand moving upward and outward in step detecting that the gravity vector indicates the hand is horizontal in step detecting the hand stopping movement in step and detecting a gesture in step . In particular embodiments gestures may involve motion of the entire body rather than just of the appendage on which the device is worn.

In particular embodiments a user may interact with the device via a variety of input mechanisms or types including for example the outer ring touch sensitive interfaces e.g. the touch sensitive layer gestures performed by the user described herein or a speech interface e.g. including voice input and speech recognition for applications including text input communication or searching . Additionally in particular embodiments a user may interact with a graphical user interface presented on a circular display of the device via any of the input mechanisms or types.

A user of the wearable electronic device may interact with the device including e.g. a graphical user interface presented on the circular display by using the outer ring. In particular embodiments the outer ring may be touch sensitive such that a user s touch on one or more portions of the ring may be detected as an input to the device and interpreted causing one or more actions to be taken by the device e.g. within a graphical user interface of the device . As an example a touch sensitive outer ring may be a capacitive ring or inductive ring and a user of the device may perform any suitable touch gesture on the touch sensitive ring to provide input to the device. The input may for example include swiping the ring with one finger swiping the ring with two or more fingers performing a rotational gesture with one or more fingers or squeezing the ring. In particular embodiments the outer ring may be rotatable such that a physical rotation of the ring may serve as an input to the device. Additionally in particular embodiments the outer ring may be clicked e.g. pressed down or squeezed. Any of the embodiments of the outer ring may be combined as suitable such that the ring may be one or more of touch sensitive rotatable clickable or pressable or squeezable. Inputs from the different modalities of the outer ring e.g. touch rotation clicking or pressing or squeezing may be interpreted differently depending for example on the combination of the modalities of input provided by a user. As an example a rotation of the outer ring may indicate a different input than a rotation in combination with a clicking or pressing of the ring. Additionally feedback may be provided to the user when the user provides input via the outer ring including haptic feedback audio feedback or visual feedback described herein.

In particular embodiments a touch sensitive interface of the device e.g. the touch sensitive layer may accept user touch input and allow the device to determine the x y coordinates of a user s touch identify multiple points of touch contact e.g. at different areas of the touch sensitive layer and distinguish between different temporal lengths of touch interaction e.g. differentiate gestures including swiping single tapping or double tapping . Touch gestures described herein may include multi directional swiping or dragging pinching double tapping pressing or pushing on the display which may cause a physical movement of the display in an upward or downward direction long pressing multi touch e.g. the use of multiple fingers or implements for touch or gesturing anywhere on the touch sensitive interface or rotational touch gestures. illustrates an example of a user tapping a touch sensitive interface e.g. the touch sensitive layer to provide input to the device. The precise x y coordinates of the user s tapping may be determined by the device through input from the touch sensitive interface e.g. the touch sensitive layer . illustrates an example of a user performing respectively a clockwise rotational gesture a counter clockwise rotational gesture a vertical swipe gesture and a horizontal swipe gesture . illustrates an example of a user touching the display including a touch sensitive layer with multi touch sensing capability using respectively one two or three points of contact e.g. with one two or three fingers or implements simultaneously. illustrates an example of a user performing touch gestures having multiple points of contact with the touch sensitive interface. The user may in this example perform an expanding gesture a pinching gesture a clockwise rotational gesture or a counter clockwise rotational gesture with two fingers.

In particular embodiments a graphical user interface of the device may operate according to an interaction and transition model. The model may for example determine how modes including applications functions sub modes confirmations content controls active icons actions or other features or elements may be organized e.g. in a hierarchy within a graphical user interface of the device.

In one embodiment the graphical user interface GUI includes multiple top level screens that each correspond to a different mode or application or sub mode function confirmation content or any other feature of the device. Each of these applications may be on the same level of the hierarchy of the interaction and transition model of the GUI. illustrates an example layout of a hierarchy within the GUI in which multiple top level screens and each correspond to a different application and one of the top level screens the home screen corresponds to a clock. State transitions within the GUI may be events triggered by input from an input source such as the user of the device. An input from a user of the device or from another input source e.g. via any of the variety of input mechanisms or types including the outer ring touch sensitive interfaces gestures speech or sensors may cause a transition within the GUI e.g. from one top level screen to another . For example an input may cause the GUI to transition from the home screen e.g. the clock to an application e.g. 3 or 4 or from an application to another application. If the user rotates the outer ring to the right for example the GUI may transition from the home screen to Application 4 and if the user rotates the outer ring to the left the GUI may transition from the home screen to Application 3 . In yet other embodiments context e.g. as determined by sensors or other input sources on the device may cause the GUI to transition from the home screen to an application or from an application to another application.

In one embodiment the model may include operability for differentiation of the left and right sides in relation to the home screen. As an example one or more of the top level screens may be associated with modes or applications or other features in the hierarchy of the interaction and transition model of the GUI that are fixed e.g. always available to the user or contextual or dynamic e.g. available depending on context . The contextual screens may for example reflect the modes applications or functions most recently used by the user the modes applications or functions most recently added e.g. downloaded by the user ad hoc registered devices that may for example enter or exit the communication range of the device as it is used modes applications or functions that are favorites of the user e.g. explicitly designated by the user or modes applications or functions that are suggested for the user e.g. based on the user s prior activity or current context . illustrates an example layout of a hierarchy within the GUI in which contextual or dynamic applications and fixed applications are grouped separately with the left side in relation to the home clock screen including contextual applications and the right side including fixed applications. As an example Dynamic Application 01 may be the most recently used application and Dynamic Application 02 may be the second most recently used application and so forth.

In particular embodiments the top level of the hierarchy of the interaction and transition model of the GUI may include only faces and the next level of the hierarchy may include applications or any other features . As an example the top level of the hierarchy may include a home screen e.g. the clock and one or more faces each face corresponding to a different type of background mode or activity such as a wallpaper e.g. customizable by the user weather information a calendar or daily activity information. Each of the faces may show the time in addition to any other information displayed. Additionally the face currently displayed may be selected by the user e.g. via any suitable input mechanism or type or automatically change based on context e.g. the activity of the user . The faces to the left of the home screen may be contextual and the faces to the right of the home screen may be fixed. illustrates an example layout of a hierarchy within the GUI in which the top level of the hierarchy includes faces including clock face and the next level of the hierarchy includes applications .

In particular embodiments an input from a user of the device or an input from another input source e.g. via any of the variety of input mechanisms or types including the outer ring touch sensitive interfaces gestures speech or sensors or a context of use of the device may cause a transition within the GUI from a screen at one level of the hierarchy of the interaction and transition model of the GUI to a screen at another level of the hierarchy. For example a selection event or input by the user e.g. a touch or tap of the display voice input eye gazing clicking or pressing of the outer ring squeezing of the outer ring any suitable gestures internal muscular motion detected by sensors or other sensor input may cause a transition within the GUI from a top level screen to a screen nested one level deeper in the hierarchy. If for example the current screen is a top level screen associated with an application a selection event e.g. pressing the ring selects the application and causes the GUI to transition to a screen nested one layer deeper. This second screen may for example allow for interaction with a feature of the selected application and may in particular embodiments correspond to a main function of the selected application. There may be multiple screens at this second nested layer and each of these screens may correspond to different functions or features of the selected application. Similarly a back selection input or event by the user e.g. a double pressing of the outer ring or a touch gesture in a particular part of the display may cause a transition within the GUI from one screen e.g. a feature of a particular application to another screen that is one level higher in the hierarchy e.g. the top level application screen .

In particular embodiments an interaction layout may structure an interaction and transition model of a GUI of the device. An interaction layout may be applied to any suitable interaction model and need not be dependent on any specific type of motion or animation within a GUI of the device for example. Although specific examples of interaction layouts are discussed below any suitable interaction layout may be used to structure an interaction and transition model.

As one example a panning linear interaction layout may structure an interaction and transition model of a GUI of the device. In a panning linear type GUI elements or features within a layer may be arranged to the left and right of the currently displayed element or feature. User input such as a rotation of the outer ring in a clockwise or counterclockwise direction navigates within a single layer of the model hierarchy. As an example a rotation of the outer ring clockwise one rotational increment may display the element or feature to the right e.g. the next element and a rotation counterclockwise one rotational increment may display the element or feature to the left e.g. the previous element . In particular embodiments a fast rotation clockwise or counterclockwise may cause the GUI to perform accelerated browsing. In such an embodiment a single turn may cause the GUI to transition through multiple elements or features rather than a single element or feature as described herein. Different user input may navigate between layers e.g. either deeper layers or higher layers in the model hierarchy. As an example if the user touches or taps the touch sensitive layer of the display the GUI may transition one layer deeper in the model hierarchy e.g. confirming the user s selection or providing options related to the selection . Any suitable input by the user may cause the GUI to transition between layers in the model hierarchy either in place of or in addition to touch or tap based input.

As another example if the user presses a particular region of the touch sensitive layer of the display e.g. designated as a back button or if the user double taps the touch sensitive layer of the display the GUI may transition one layer higher in the model hierarchy e.g. to the previous layer . If for example the user performs a long press of the display or screen the GUI may transition back to the home screen e.g. a clock . Without additional user input the GUI may also transition back to the home screen after a pre determined period of time e.g. a timeout period . As described herein as a user begins for example to rotate the outer ring in a clockwise or counterclockwise fashion the GUI transitions within the same layer and the next user interface element or feature e.g. a breadcrumb icon in the same layer to the right or left respectively may begin to appear while the current user interface element or feature may begin to disappear.

As another example a panning radial or panning circular interaction layout may structure an interaction and transition model of a GUI of the device. In a panning radial type GUI elements or features in a layer may be arranged above and below the currently displayed element or feature. User input such as a rotation of the outer ring in a clockwise or counterclockwise direction navigates between layers of the model hierarchy. As an example a rotation of the outer ring clockwise one increment may cause the GUI to transition one layer deeper in the model hierarchy e.g. entering a particular application s layer or confirming selection of the application and a rotation counterclockwise one increment may cause the GUI to transition one layer higher in the model hierarchy e.g. exiting a particular application s layer to the previous layer . In particular embodiments a fast rotation clockwise or counterclockwise may cause the GUI to perform accelerated browsing as described herein. In such an embodiment a single rotational increment may cause the GUI to transition through multiple layers of the hierarchy rather than a single layer. Different user input may navigate within a single layer in the model hierarchy. As an example if the user touches or taps the touch sensitive layer of the display the GUI may transition to the next element or feature e.g. the element below the currently displayed element . As another example if the user presses a particular region of the touch sensitive layer of the display e.g. designated as a back button or if the user double taps the touch sensitive layer of the display the GUI may transition to a previous element or feature e.g. the element above the currently displayed element . If for example the user performs a long press of the display or screen the GUI may transition back to the home screen e.g. a clock . Without additional user input the GUI may also transition back to the home screen after a pre determined period of time e.g. a timeout period . As described herein as a user begins for example to rotate the outer ring in a clockwise or counterclockwise fashion the GUI transitions to a different layer and the next user interface element or feature e.g. in a different layer may begin to appear while the current user interface element or feature may begin to disappear. illustrates an example of the panning radial interaction layout. In this example GUI elements and are in the same layer of the interaction and transition model hierarchy of the panning radial type GUI. GUI elements A B and C are elements in a second deeper layer of the hierarchy and are sub elements of element . As before the first layer may include devices paired with the device element may represent an automobile element may represent a television element may represent a mobile phone element may represent a home thermostat. Element A may be a volume control element for the television element B may be a channel control element for the television and element C may be a picture control element for the television.

As yet another example an accordion type interaction layout may structure an interaction and transition model of a GUI of the device. In an accordion type GUI elements or features of multiple layers may be arranged in a circular list structure. For example rotating within the list structure e.g. by rotating the outer ring in a first direction past a screen associated with the last element or feature in that direction e.g. the last fixed application of the device may cause the GUI to transition to a screen associated with the last element or feature in a second direction e.g. the least recently used contextual application of the device . Continuing to rotate in the first direction may cause the GUI to transition through screens associated with contextual applications in reverse order e.g. from least recently used to most recently used . Similarly rotating in the second direction past the screen of the least recently used contextual application may cause the GUI to transition to the screen associated with the last fixed application and continuing to rotate in the second direction may cause the GUI to transition through the screens of the fixed applications in reverse order e.g. from the last fixed application to the first adjacent to the home screen . In an accordion type GUI the element or feature currently displayed may be expanded e.g. if selected by the user such that its sub elements or sub features may become part of the single layer list structure. In particular embodiments an element or feature with sub elements may indicate when displayed that it has sub elements through for example visible edges of the sub elements. User input such as a rotation of the outer ring in a clockwise or counterclockwise direction navigates within a single layer of the model which may include elements or features as well as sub elements or sub features of a selected element or feature. As an example a rotation of the outer ring clockwise one increment may display the element or feature to the right e.g. the next element and a rotation counterclockwise one increment may display the element or feature to the left e.g. the previous element . In particular embodiments a fast rotation clockwise or counterclockwise may cause the GUI to perform accelerated browsing. In such an embodiment a single rotational increment may cause the GUI to transition through multiple elements or features rather than a single element or feature. Different user input may cause the selection and expansion of an element or feature in the model. As an example if the user touches or taps the touch sensitive layer of the display the GUI may expand the displayed feature or element within the existing layer and transition to a sub element or sub feature. As another example if the user presses a particular region of the touch sensitive layer of the display e.g. designated as a back button or if the user double taps the touch sensitive layer of the display the GUI may collapse the expanded sub elements or sub features and transition to an element or feature in the list. If for example the user performs a long press of the display or screen the GUI may transition back to the home screen e.g. a clock . Without additional user input the GUI may also transition back to the home screen after a pre determined period of time e.g. a timeout period . As described herein as a user begins for example to rotate the outer ring in a clockwise or counterclockwise fashion the GUI transitions within the same layer and the next user interface element or feature e.g. a breadcrumb icon in the same layer to the right or left respectively may begin to appear while the current user interface element or feature may begin to disappear. illustrates an example of the accordion type interaction layout. In this example GUI elements and are in the same layer of the interaction and transition model of the accordion type GUI. Because element has been selected by the user GUI sub elements A B and C are expanded and also included in the list structure in the same layer of the model. Thus the GUI may transition from sub element C to either sub element B or directly to element . If however the user desires to collapse the sub elements e.g. through a back input such as tapping the screen associated with element again then the list structure will only include GUI elements and again.

In particular embodiments the GUI may navigate to a home screen based on input received by a user of the device. The user input may include for example pressing and holding e.g. a long press the touch sensitive layer pressing and holding the display pressing e.g. clicking and holding the outer ring squeezing and holding the outer ring covering the face e.g. the display of the device covering a particular sensor of the device turning the face of the device in a downward direction pressing a software button discussed herein pressing a hardware button on the device or shaking the device or any other suitable gesture . Any of these inputs or any variation of these inputs including for example shorter durations may be used as user inputs to go back within an interaction and transition model. illustrate examples of a back software button layout in the GUI. In receiving user touch input in the bottom portion of the display causes the GUI to confirm a selection or transition one layer deeper in the model hierarchy. Receiving user touch input in the top portion of the display causes the GUI to transition back or one layer higher in the model hierarchy. illustrates a similar layout with the back region including a breadcrumb icon to indicate to the user where navigating back will transition. In particular embodiments e.g. when the touch sensitive layer is operable to determine precise x y coordinates of a touch any region of the display may be designated as a back region a confirm select region or any other suitable functional region.

In particular embodiments the GUI of the device may display particular types of content including for example lists. illustrates an example of the GUI displaying a vertical list of items. An input from the user e.g. any suitable input mechanism or type may cause a selection frame of the GUI to move through elements of the vertical list. As an example if the user rotates right in a clockwise direction the selection frame may move from the top of the vertical list toward the bottom of the vertical list. Each rotational increment of the outer ring e.g. if the outer ring moves in discrete increments causes the selection frame to move one item within the list. In the example of as the user rotates the ring clockwise the displayed items of the list remain constant and the selection frame moves downward through items of the list. In other embodiments the selection frame may remain constant e.g. in the center of the display and items of the list may move upward or downward e.g. one item at a time depending on the direction of the ring s rotation. illustrates an example of the GUI displaying a horizontal list of items. An input from the user e.g. any suitable input mechanism or type may cause a selection frame of the GUI to move through elements of the horizontal list. As an example if the user rotates right in a clockwise direction the selection frame may move from the left of the horizontal list toward the right of the horizontal list. Each rotational increment of the outer ring e.g. if the outer ring moves in discrete increments causes the selection frame to move one item within the list. In the example of as the user rotates the ring clockwise the selection frame remains constant in the center of the display and items of the list move toward the left e.g. one item at a time in response to the clockwise rotation. In other embodiments the displayed items of the list remain constant and the selection frame moves left or right through items of the list depending on the direction of rotation of the outer ring.

In particular embodiments the GUI of the device may display vertically or horizontally continuous or substantially continuous content including for example charts or text. In particular embodiments an input from the user e.g. any suitable input mechanism or type may cause a selection indicator of the GUI to move through the continuous content. In other embodiments an input from the user may cause the content to move into and out of the display in a horizontal direction vertical direction or any other direction mapped to the user s input and the selection indicator if present may remain in a constant position . In the example of a temperature chart is displayed. As the user rotates the outer ring in a clockwise fashion the selection indicator remains in the center of the display and the content moves into the display from the right and out of the display toward the left. In the example of a portion of a larger piece of text is displayed. As the user rotates the outer ring in a clockwise fashion additional text enters the display from the bottom and exits the display toward the top. illustrate an example calendar application displayed in GUI of the device. In a user may click or press the outer ring indicated by arrow causing the GUI to display a circular menu with options Go Up Weekly the default setting Monthly and Daily. In the user may again click or press the outer ring indicated by arrow confirming selection of Weekly and causing the GUI to display the weekly view of the user s calendar.

In particular embodiments the GUI may display content that is of a size larger than the display. In such embodiments the GUI may scale or crop or otherwise shrink or fit the content so that all of the content may be displayed within the display at one time. In other embodiments the GUI does not alter the size of the content and instead provides the ability for the user to pan through the content one portion at a time for example using scrolling described herein .

In particular embodiments the device includes the circular display and the GUI includes circular navigation and menu layouts. This disclosure contemplates any shape for the display however and any suitable navigation or menu layout for the GUI. The menu layout may provide a user a visual indication of where the user is located within an interaction and transition model hierarchy of the GUI for example. The menu layout may also provide visual indicators that allow the user to differentiate between different types of menu items as well as show an overall view of menu options. Additionally the menu may be displayed over any suitable background or content of the device.

In particular embodiments the GUI may display both an item of reference or background content as well as an indication of an available action or function to be performed with respect to the reference or background content. illustrates example layouts within the GUI of reference content and contextual overlay actions or functions. Different types of layouts e.g. including those illustrated may be selected based on the different types of reference or background content presented for example to minimize obscuring the reference or background content. For example if the reference or background content is a picture of a person an overlay that does not obscure the center of the photo may be selected. In particular embodiments the perceptual brightness of the pixels of the reference or background content e.g. behind the overlay may be determined on a pixel by pixel basis. In cases where the contrast between the contextual overlay and the reference or background content e.g. an image is too low e.g. based on a pre determined threshold a blurred drop shadow that pushes the underlying colors in the opposite direction may be used. An example algorithm may include determining the pixels under the overlay reducing their saturation taking the inverse of the visual brightness e.g. such that colors remain the same but the brightness is selected to produce contrast blur and create a composite between the underlying reference or background content and the overlay. illustrate examples of contextual overlays composed with background or reference content here images captured by a camera of the device . As illustrated the contextual overlay may allow the user to perform actions or functions e.g. deleting an image or sharing an image searching for coffee searching for restaurants or making a location a favorite location provide confirmation to the user e.g. that an image has been shared or provide any other type of information to the user. In particular embodiments contextual overlays may be used anywhere within a menu layout of a GUI except for the top level of the interaction and transition model hierarchy.

In particular embodiments icons displayed in the GUI of device may optimize the energy or battery usage of the device. As an example an icon may include primarily black background with the icon itself being composed of thin white strokes. This may allow for the amount of white color on the display screen to be very low allowing for reduced energy consumption of the display while the GUI is used. The icons displayed in GUI may also include real time notifications. For example a mobile phone icon may include a notification with the number of new voicemails an e mail icon may include a notification with the number of new e mails a chat icon may include a notification with the number of new chat messages and a telephone icon may include a notification with the number of missed calls. In particular embodiments the GUI of the device only displays colors other than black and white for user generated content e.g. pictures files contacts notifications or schedules . Other information including menu items may be displayed in black and white.

In particular embodiments as the GUI transitions from one element e.g. feature content item or icon to another e.g. upon receiving input from a user the GUI may display visual transition effects. These transition effects may depend for example on the type of input received from a user of device. As an example a single touch on the display may trigger particular transition effects while a rotation of the outer ring may trigger a different potentially overlapping set of transition effects.

In particular embodiments a user s touch input on the touch sensitive layer may trigger transition effects including center oriented expansion directional sliding and scaling in or out. illustrates center oriented mode or function expansion or scaling up. illustrates center oriented mode or function collapsing or scaling down. illustrates center oriented scaling up of an icon. illustrates center oriented scaling down of an icon. illustrates an example of center oriented icon scaling up with a twisting motion. illustrates an example of center oriented icon scaling down with a twisting motion. illustrates an example of center oriented unfolding and expansion outward of an icon. illustrates an example of center oriented folding and collapsing inward of an icon. illustrates an example of text vertically sliding into the display where the text is revealed by unmasking illustrates an example of text horizontally sliding in from the left to the right of the display. illustrates an example of text horizontally sliding in from the left to the right of the display within a masked region e.g. a contextual overlay . illustrates a horizontal slide transition from right to left for content or an icon. illustrates a horizontal slide transition from right to left with fading effects the icon or content exiting the screen fades out gradually once it reaches the screen s border and the icon or content entering the screen fades in gradually as it crosses the screen s border. illustrates an example of a horizontal slide transition from right to left with scaling effects the content or icon exiting the screen is shrunk down and the content or icon entering the screen is scaled up to full size.

In particular embodiments a user s rotation of the outer ring may trigger visual transition effects including zooming directional sliding blurring masking page folding rotational movement and accelerated motion. illustrates an example of a transition in response to a low acceleration rotation of the outer ring. In this example a single rotational increment may correspond to a single item such that one turn e.g. rotational increment counterclockwise causes the next element e.g. icon or content item to enter the screen from the left toward the right and no scaling of elements occurs. together illustrate an example of a transition in response to a high acceleration rotation of the outer ring. In this example a single turn e.g. rotational increment counterclockwise causes the GUI to pan quickly through multiple elements which may scale down in size enter the screen from the left and exit the screen from the right until the user stops turning the ring. When the user stops turning the outer ring the element may scale up to normal size and a single icon or content item may fill the display. illustrates an example of a transition within the GUI in which content is zoomed in in response to rotation of the outer ring. illustrates an example of a transition within the GUI in which a first screen folds over in an animation resulting in a second screen e.g. for the next feature or content item being displayed to the user.

In particular embodiments the GUI of the device may include a physical model that takes into account motion of the user and produces visual feedback reflecting the user s movements. As an example once there is activation input e.g. in the form of a particular gesture by the user the user s motion may be continuously tracked through input from one or more of the sensors of the device. The visual feedback may reflect the user s motion in the user interface while the underlying content stays still so that gestures may be registered and parallax may be used to distinguish between UI features or controls and underlying content. In particular embodiments the physical model may include a generalized spring model with damping. In such a model items may be arranged in layers. Deeper layer may have a stiffer spring in the physical model holding items in place. This may cause bottom layers of the user interface to move slightly when the device is moved while top layers may move more creating a sense of parallax. Additionally the spring model may include damping which causes motion to lag creating a more fluid smooth motion. illustrate an example of using a physical model in the GUI. The user wears the device on her arm. Once the user moves her arm in a downward fashion the icon displayed on the screen e.g. a light bulb moves in a manner reflecting the user s movement. The underlying content e.g. the background image on the screen does not move however. This type of floating icon or menu item may for example be helpful when the display is of a size that does not allow for many icons or menu items to be displayed simultaneously due to visual crowding. Additionally this type of floating behavior may also be used with notification means for presenting an event to the user.

In particular embodiments the GUI of the device may include faces as default screens or wallpapers for the device and these faces may be part of an interaction and transition model hierarchy e.g. in the top layer of the hierarchy or as a home screen . As described herein these faces may be changeable applications or modes that may automatically respond contextually to a user s activity. As an example the faces may change depending on the user s environment needs taste location activity sensor data gestures or schedule. The availability of a face or the transition in the GUI from one face to another may be determined based on contextual information. As an example if the user has an upcoming event scheduled in her calendar the face of the device may change to a calendar face that displays the upcoming event information to the user. As another example if the user is determined to be in the vicinity of her home e.g. based on GPS data the face of the device may change to a face associated with a home automation application. As yet another example if the user is determined e.g. based on various biometric sensors such as heart rate or arousal sensors or based on accelerometers to be moving vigorously the face of the device may change to a fitness mode showing the user s measured pulse calories burned time elapsed since the activity e.g. a run began and the time. Any suitable sensor data e.g. from sensors including biometric sensors focus sensors or sensors which may determine a user s hand position while driving a car may be used to determine a context and appropriate face to display to the user. The user s historical usage of the device e.g. a particular time of day when the user has used a fitness application such as in a fitness class may also determine which face is displayed on the device. As an example the device may anticipate the user s need for the fitness mode at the particular time of day when the user tends to exercise. Contextual faces may also be associated with the suppression of notifications e.g. if the user is determined to be driving or if the device is not being worn or a change in how notifications are expressed e.g. visually or audibly . In particular embodiments the faces of the device need not be associated with any application on the device and may be wallpapers or backgrounds on the display of the device. Faces may be dedicated to specific channels of information e.g. calendar feeds health or activity feeds notifications weather feeds or news . As an example a severe weather notification or alert received e.g. from a weather feed may cause the weather face to be displayed on the display along with the notification. Faces may display the time e.g. in analog or digital format regardless of the type of face. The faces may be customizable by the user. The user s customizations or tastes may be input explicitly by the user e.g. to management software on the device or a paired device or learned directly by the device e.g. using sensor and usage data to create a model over time . illustrates example faces including an analog watch an analog watch with a circular menu layout a health mode face and a weather face . illustrates an example set of faces for the device in which calendar and appointment information is displayed.

In particular embodiments the device may be worn on a limb of a user without obscuring the user s face and without requiring the user to hold the device and may include augmented reality AR functionality. This AR functionality may be based on the use of body motion for aiming a camera of the device which may allow for aiming with higher accuracy due to a user s sense of proprioception. This type of system may allow the user of the device to view an object in the real world at the same time that the user views a version of the object e.g. captured by a camera of the device on the display. An example of this AR capability is illustrated in . Such an AR system may allow for see through capability using an aligned camera and sensor on opposite sides of a user s limb. Various AR applications may be enabled by this type of arrangement described herein. In particular embodiments applications may be designed specifically for the device to allow for immediate opportunistic use. Additionally a delegation model may be provided on the device allowing for the use of external resources to improve the breadth of applications available to run on the device while incurring less or no penalty in terms of processing requirements or energy use. In particular embodiments the device may control or be controlled by other devices e.g. nearby devices discovered via a network and communicatively paired with the device . This type of control may be achieved via proximity gestures or traditional interfaces. Pairing may be achieved using a variety of technologies including a camera of the device discussed in further detail herein.

In particular embodiments if the device does not have the capability to calculate features of interest itself the device may capture an image transfer the image to a communicatively coupled device e.g. a nearby device such as a phone or personal computer or to an Internet based service where the features of interest may be calculated remotely. Once the features of interest are determined an Internet based service or local data catalog may be consulted for additional information about a recognized object. If information is found the relevant data may be displayed to the user on the device along with the recognized feature.

The device may in particular embodiments have a small form factor and be constrained in terms of available memory processing and energy. A delegation model may allow the device to delegate portions of one or more processing tasks e.g. tasks related to AR functionality to nearby devices e.g. phone or personal computer or to network or Internet based services for example. As an example for delegable tasks the application requiring the task provides the system e.g. a kernel of an operating system of the device with characteristics or a profile of the task including the task s latency sensitivity processing requirements and network payload size. This may be done for each delegable subtask of the overall delegable task. Since tasks are often pipelined contiguous chunks of the task pipeline may be delegated. The system may in particular embodiments take measurements of or build a model of one or more characteristics of the device. Characteristics of the device may include static properties of the device e.g. properties of hardware components of the device including total memory installed maximum CPU speed maximum battery energy or maximum bandwidth of a network interface. Characteristics of the device may also include dynamic properties of the device e.g. operating properties of the device including available memory current CPU capacity available energy current network connectivity availability of network based services a tally of average user behavior among one or more users or a predicted or expected processing time of a task e.g. given a particular usage scenario . In particular embodiments the device may have a model that incorporates previous and current measurements of device characteristics to aid in determining future device behavior. Based on the task characteristics or profile and these measurements or models as well as based on whether the task may be executed on the device the system may delegate or not delegate one or more portions of the task or task pipeline. For example if the available memory on the device cannot support the processing of a task e.g. playing a video one or more portions of the task may be delegated. As another example if the CPU capacity of the device cannot support processing a task e.g. if the CPU is running at capacity due to its existing load one or more portions of the task may be delegated. As another example if a battery level of the device is low and the battery is not expected to provide energy to the device for as long as the expected processing time of the task one or more portions of the task may be delegated. As another example if the network connectivity of the device is low or non existent one or more portions of the task may not be delegated e.g. if the device also has enough available memory CPU capacity and energy . As another example if one or more network based services are available to the device e.g. cloud based services for processing and the device has suitable network connectivity e.g. good available bandwidth one or more portions of the task may be delegated. As another example if a user of the device typically e.g. historically delegates the playing of videos one or more portions of the task of playing a video may be delegated. As another example if a predicted processing time of the task e.g. predicted based on a model incorporating previous and current measurements of device characteristics is beyond a certain threshold e.g. several minutes the task may be delegated. Any suitable characteristics of the device e.g. static or dynamic properties in any suitable combination may be used to determine whether to delegate a task. Furthermore any suitable characteristics of a task of the device e.g. including a task profile or characteristics of the task including latency sensitivity processing requirements or network payload size may be used to determine whether to delegate a task either alone or in conjunction with device characteristics. Additionally any model of the device e.g. device behavior may be used either alone or in conjunction with device or task characteristics may be used to determine whether to delegate a task. In particular embodiments devices paired with the device may also include a delegation model such that the paired device e.g. a phone performs the same steps delegating tasks based on its own models of energy connectivity runtime requirements and feasibility. The delegated task may be processed or run to completion on the paired device e.g. phone and the results of processing the delegated task may be returned to the device. In particular embodiments the device may operate in standalone mode e.g. without delegating any processing tasks when it does not have any network connectivity or when no paired devices are in range of the device. Once the device regains connectivity or when a device is paired with the device delegation of tasks may resume.

An example algorithm of a delegation model of the device is illustrated in . In this example a delegable task process begins on the device . The system of the device performs a power use analysis and prediction based e.g. on the user s historical energy usage and the expected time until a charge of the device . Based on this the system determines at step whether there is sufficient charge remaining for the required uptime of the delegable task. If sufficient charge remains the system of the device may increase the power usage and process the delegable task on the device itself . If however the device does not have sufficient charge for the required uptime the device may query a paired device e.g. a phone to determine the energy status of the paired device . If in the example of a phone there is sufficient charge remaining on the phone for the required uptime the task may be processed on the phone . If however there is not sufficient charge on the phone the system may determine at step if the device has connectivity to an Internet based e.g. cloud or other network based service. If not the device may delegate the process to the phone . If there is connectivity the device may delegate the process to the cloud where the task is processed and the results later returned to the device. In particular embodiments delegable tasks may be delegated by the device in a divided fashion to one or more paired devices e.g. mobile phones or personal computers or network Internet services. That is delegable sub tasks of a delegable task or process may be delegated by the device to different locations.

It is contemplated by this disclosure that a delegation model for a particular the device or for a family or range of devices may be dynamic or contextual. As an example a delegation model may take into account available memory CPU capacity and available energy of a particular the device or a family of devices factors which may all change over time. The delegation model may also take into account the availability of network or cloud based services and the capacity of each as well as network connectivity e.g. bandwidth and latency which may also change over time. For example with reference to according to a first delegation model which may e.g. be applicable for devices manufactured in the next year most processing may be evenly divided between the device and a paired device e.g. smartphone with only a small amount of delegation to a server of a cloud based service. According to a second delegation model which may e.g. be applicable for devices manufactured in a three year timeframe most processing may be handled locally by the device e.g. due to predicted advances in memory CPU and energy capacity in a small form factor . In this second model some processing may be delegated to a server e.g. more than in the first delegation model due to improved network connectivity and only a small amount of delegation may occur to the locally paired device. According to a third delegation model which may e.g. be applicable for devices manufactured in a five year timeframe all or almost all processing tasks may be evenly divided between the device and a server of a cloud based service with no or almost no processing being delegated to a locally paired device. Any number of delegation models may be created as the factors taken into account by a delegation model are dynamic. As an example all or almost all tasks may be performed locally on the device according to one delegation model and all or almost all tasks may be delegated by the device in another delegation model.

The device may choose to delegate functionality to a paired processing rich device e.g. phone computer tablet television set top box refrigerator washer or dryer or to the Internet based on the energy reserves or connectivity bandwidth to each of these locations. For example a device with a powerful processor may delegate to the paired device when low on energy or it may choose to delegate to the Internet service when the paired device does not have sufficient power reserves. Likewise the system of the device may choose to process locally if the connection to the Internet is showing higher latency to reduce the size of the data transfer.

In particular embodiments an entire application or a portion of an application may be delegated by a user of the device to a paired device or vice versa. This may occur on a per application basis. When the application on a target device e.g. a television is to be delegated to the device the target device may send a request over the paired connection possibly via an intermediary device such as a smartphone or personal computer to load the application on the device. The device may then act as a client to a server running on the paired device e.g. television . Similarly an application running on the device may be delegated to the paired device e.g. a video playing on the device may be delegated to playing on a paired television . For example if the device is running a first application and a user of the device wants to interact with a second application the device may automatically delegate a task of the first application to be processed by another device e.g. a paired television .

In particular embodiments a camera or other optical sensor of the device may be used to recognize any gestures performed by the user e.g. in the space between the camera and a target in the real world . These gestures may for example be used to act upon the data presented e.g. the real world target such as a sign including text or may be used to point to particular items upon which augmented reality functions may be performed. For example the user may point to a word on a sign causing the device to translate it and display the translation to the user. illustrates two examples of images captured by a camera of the device. In one example a truck and the hand of a user of the device are both within the angle of view of a camera of the device and displayed by the device shown at . As such gestures performed by the user upon the truck may be recognized by the device and processed by device to provide for example AR functionality. In the second example only the truck is within the angle of view of the camera shown at and as such gestures performed by the user are not captured or recognized by the device. Gesture recognition may also be delegated by the device.

In particular embodiments objects or images may be recognized by the device when they are within the frame of view of a camera of the device. As described herein there may be multiple ways for the device to recognize an object. As one example a gesture performed by the user e.g. a pointing gesture indicating a particular object may enable AR functionality on the device and cause the device to recognize the object. As another example automatic object recognition may occur when for example the user positions the camera for a certain amount of time on a particular object e.g. a section of text . As a third example object recognition or AR functionality may be enabled explicitly by the user when for example the user taps or touches the display or e.g. clicks the outer ring when the camera of the device has captured an object of interest. Global object recognition may in some instances be computationally intensive and error prone. As such in particular embodiments a limiting set e.g. the pages of a magazine or catalog or a catalog of a particular type of object such as plant leaves or book covers may be applied to improve accuracy. There exist a number of choices for calculation of feature vectors from images which the designer of the system for the device may select from. In some instances the conversion of feature vectors between different approaches may be computationally expensive so that the choice of the database of possible matches is replicated on the device. The calculation of feature vectors may be delegated as described herein.

In particular embodiments barcodes of various types may be recognized by the device. These barcodes may be used to query Internet based services for additional data as well as options to purchase review or bookmark the barcoded item for future review. While two dimensional barcodes may generally be read directly the system of the device may offer an addition close focus mode for particularly small or one dimensional barcodes to improve recognition rate. Should the system lack the ability to decode the barcode it may simply focus the camera take a picture and delegate recognition to a remote service as described herein. illustrate an example of barcode recognition mode. The device may be pointed at an item A recognize the item B display additional information obtained from the Internet about the item C and provide the user an interface to purchase the item D .

In particular embodiments the device may perform translation. Translation functionality may be divided into two portions optical character recognition OCR and translation of recognized characters words or phrases. OCR may be completed on the device or delegated e.g. to a paired processing device to reduce the amount of data to be translated by the device. Simple word translations may be performed on the device or delegated e.g. to a paired processing device . As with other functionality described herein part or all of the recognition or translation process may be delegated as needed. The user may optionally use a gesture to indicate the word to be translated as shown in e.g. the word Warning . Since individual words may be circumscribed by white space the system may segment the word before attempting translation. Additionally if the device can perform OCR with low latency it may show the text to the user so that the user knows when the device is targeting and correctly recognizing the correct text. If automatic OCR is enabled then the device may automatically identify images in the angle of view of an outward facing camera and present on the device display information about the identified images. If automatic translation is enabled then the device may automatically translate text in the angle of view of the outward facing camera and present the translated text on the device display.

In particular embodiments a pairing and control model for the device may include the following characteristics. The device may function as the host for an application that interacts with or controls one or more functions of a remote device e.g. an appcessory such as a controllable thermostat . A smartphone or other locally paired device which may have previously been the host for the application may now function merely as a local target device to which the device may delegate certain functions related to the interaction or control of the remote device e.g. longer range wireless connectivity to the remote device sending commands to the remote device receiving data from the remote device or processing tasks . Control of the remote appcessory device may be done by the device using any suitable means including for example visual means e.g. using the camera or motion based gestures. In other embodiments the locally paired smartphone may continue to function as the host for the application that interacts with the remote appcessory but the device may provide some or all of the user interface for data input and output to and from the application e.g. a light version of the application hosted by the smartphone . For example the user may control the application using the device but the smartphone may still function as the host of the application.

In particular embodiments the device may be operable with one or more services. These services may fall in categories including security energy home automation and control content sharing healthcare sports and entertainment commerce vehicles and social applications.

Example security applications include the following. The device may authenticate a user who is wearing the unlocked device to another device near the user e.g. paired with the device . The device may be unlocked with a code entered by the user using any suitable input including for example rotating the outer ring of the device. As an example while a user rotates or presses or clicks the outer ring the display may show alphanumeric or symbolic data corresponding to the rotation or press or click by the user. If for example the user rotates the outer ring one rotational increment in a clockwise direction or e.g. clicks or presses the outer ring once the display may show the user a 1 and if the user rotates the outer ring two rotational increments e.g. within a certain period of time such as a millisecond in a clockwise direction or e.g. clicks or presses the outer ring twice the display may show the user a 2. In particular embodiments the display of alphanumeric or symbolic data corresponding to a rotation or press or click by the user may allow the user to unlock the device using the metaphor of a combination lock. The device may also be unlocked using biometric data e.g. by skin or bone signatures of the user .

In an example energy application the device may automatically display information about the energy consumption of the room or other location in which the user is located. The device may also be able to display information about the energy consumption of other paired devices and update all of this information dynamically as the user changes location.

In an example home control application the user may select and directly control paired home control devices using for example rotation of the outer ring or a gesture input.

The user may use gestures to control the sharing or transfer of content to or from the device e.g. transferring video playing on the device to a paired television as described herein . Additionally auxiliary information e.g. movie subtitles may be provided on the device for content shown on another larger device e.g. television screen playing the movie .

The device may automatically determine a healthcare context e.g. if the user is exercising or sleeping . When it determines this context the device may open applications corresponding to the healthcare context e.g. for recording heart rate during exercise movement during exercise duration of exercise pulse oximetry during exercise sleep patterns duration of sleep or galvanic skin response . The device may for example measure a user s health related data e.g. heart rate movement or pulse oximetry and send some or all of this data to a paired device or a server. Although illustrated in the healthcare context the determination of a relevant context e.g. based on a user s behavior opening of corresponding applications recording of data or transmission of this data may be applicable in any suitable context.

The device may assist in sports related applications such as for example automatically assessing a golf swing of the user and suggesting corrections.

In a commercial setting the device may automatically identify a product e.g. using RFID NFC barcode recognition or object recognition when the user picks up the product and may provide information about the product e.g. nutrition information source information or reviews or the option to purchase the product. Payment for the product may for example be accomplished using visual barcode technology on the device. In particular embodiments the device may be used to pay for a product using NFC RFID or any other suitable form of short distance communication. During payment the user s information may for example be authenticated by the device which may detect the user s biometric information e.g. bone structure or skin signature . The device may also automatically provide an indication to the user e.g. a vibration when the user is near a product on her shopping list e.g. stored in the device or another list e.g. a wish list of the user s friend .

The device may function as a key for unlocking or turning on one or more vehicles. The user may for example enter a code using the outer ring to unlock or turn on the vehicle e.g. using NFC technology as described earlier. In particular embodiments both user biometric information and a code entered by the user may be required to unlock the car allowing for enhanced security for a car based application. Additionally the device may include profiles for one or more users each profile containing vehicle settings e.g. temperature or seat position . As another example biometric information of a particular user may be used not only to unlock the device but also to determine which user profile to load during the car s operation. The proximity of the device to the vehicle may automatically cause the vehicle to implement the vehicle settings of the profile of the user. The device may also be operable for GPS navigation either directly on the device or when paired with and controlling a phone for example .

The device may access and operate in conjunction with a service that provides support for mixed reality games or massively multi player reality based games. This functionality may for example include registration management of user data e.g. user profiles and game related data such as levels completed or inventories of supplies and management of accomplishment lists. The functionality of the device and the service may also include management of connectivity e.g. concentrator functionality that handles fragile wireless communication channels and provides a unified API to third party game servers.

The device may access and operate in conjunction with a service that allows a user of the device to publish locations check ins or other location based data that allows various services to access a consistent reservoir of the most current information regarding the position and status of the user. As an example the user of the device may find friends using similar devices. The service and device together may handle status updates profile management application access permissions blacklists or user to user access permissions. The service may be a trusted and centralized touchpoint for private data. By combining access to a unified location service energy and battery life may in particular embodiments be conserved. In particular embodiments certain functionality tokens may be made available based on the position of the user. An application may for example check on the device to see if this token is available and act accordingly. On the server side APIs may allow developers to see use of the tokens or allow for redemption. In particular embodiments information may be distributed by the device to other users e.g. a single other user or in broadcast mode to multiple users .

The device may access and operate in conjunction with a service that provides a unified polling interface that allows devices to receive and send polls. The device and service together may manage distribution lists scoring criteria and poll availability frames both temporal and geographic for example . This service may be exposed on the device and on a server such that third parties may use APIs to write applications and receive results back via online APIs.

In particular embodiments the device may access and operate in conjunction with a service that provides optimizations for the presentation of text images or other information on a circular display of the device. As an example a web site may be rendered or formatted for display on a computer monitor but a service may customize the rendering and formatting for a smaller circular display by emphasizing images and truncating text. The customized rendering and formatting may for example be a task delegable among the device and one or more servers or locally paired devices. This service may also include news or advertising services.

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC such as for example a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server a tablet computer system or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines span multiple data centers or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes a processor memory storage an input output I O interface a communication interface and a bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source such as for example another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory where appropriate and this RAM may be dynamic RAM DRAM or static RAM SRAM where appropriate. Moreover where appropriate this RAM may be single ported or multi ported RAM. This disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include a hard disk drive HDD a floppy disk drive flash memory an optical disc a magneto optical disc magnetic tape or a Universal Serial Bus USB drive or a combination of two or more of these. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touch screen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication such as for example packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN body area network BAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN such as for example a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network such as for example a Global System for Mobile Communications GSM network or other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCIe bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein a computer readable non transitory storage medium or media may include one or more semiconductor based or other integrated circuits ICs such as for example field programmable gate arrays FPGAs or application specific ICs ASICs hard disk drives HDDs hybrid hard drives HHDs optical discs optical disc drives ODDs magneto optical discs magneto optical drives floppy diskettes floppy disk drives FDDs magnetic tapes solid state drives SSDs RAM drives SECURE DIGITAL cards or drives any other suitable computer readable non transitory storage media or any suitable combination of two or more of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

Herein or is inclusive and not exclusive unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A or B means A B or both unless expressly indicated otherwise or indicated otherwise by context. Moreover and is both joint and several unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A and B means A and B jointly or severally unless expressly indicated otherwise or indicated otherwise by context.

The scope of this disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments described or illustrated herein that a person having ordinary skill in the art would comprehend. The scope of this disclosure is not limited to the example embodiments described or illustrated herein. Moreover although this disclosure describes and illustrates respective embodiments herein as including particular components elements feature functions operations or steps any of these embodiments may include any combination or permutation of any of the components elements features functions operations or steps described or illustrated anywhere herein that a person having ordinary skill in the art would comprehend. Furthermore reference in the appended claims to an apparatus or system or a component of an apparatus or system being adapted to arranged to capable of configured to enabled to operable to or operative to perform a particular function encompasses that apparatus system component whether or not it or that particular function is activated turned on or unlocked as long as that apparatus system or component is so adapted arranged capable configured enabled operable or operative.

While this disclosure describes particular structures features interactions and functionality in the context of a wearable device this disclosure contemplates that those structures features interactions or functionality may be applied to used for or used in any other suitable electronic device such as for example a smart phone tablet camera or personal computing device where appropriate.

