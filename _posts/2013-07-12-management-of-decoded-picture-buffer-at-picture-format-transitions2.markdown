---

title: Management of decoded picture buffer at picture format transitions
abstract: In one method embodiment a method of processing of a bitstream is disclosed. The method may include receiving by a processing device a bitstream comprising a first portion of compressed pictures encoded at a first encoding level, the first portion of compressed pictures corresponding to a first picture resolution; determining a ratio of a picture size of at least one picture of the first portion of the compressed picture and a picture size of the largest picture encoded at the first encoding level; determining a first number of picture buffers for processing of the first portion of the compressed pictures, wherein the first number of picture buffers are determined based on the determined ratio; and mapping the first number of picture buffers in a memory allocated for decoding of bitstream.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09602817&OS=09602817&RS=09602817
owner: Cisco Technology, Inc.
number: 09602817
owner_city: San Jose
owner_country: US
publication_date: 20130712
---
This application claims the benefit of U.S. Provisional Application No. 61 670 607 filed Jul. 12 2012 and is also related to U.S. patent application Ser. No. 13 939 177 filed Jul. 10 2013 entitled Support for Variable Number of Picture Buffers in Decoded Picture Buffer which is assigned to the same assignee as the present application and expressly incorporated herein in their entirety by reference.

In network systems such as subscriber television systems a Digital Home Communication Terminal DHCT otherwise known as the set top box is capable of providing video services connected to the subscriber television system and is typically located at the user s premises and connected to the subscriber television system such as for example a cable or satellite network. The DHCT includes hardware and software necessary to provide digital video services to the end user with various levels of usability and or functionality. One of the features of the DHCT includes the ability to receive and decompress a digital video signal in a compressed format wherein such compression may be in accordance with a video coding specification such as the Advanced Video Coding AVC standard and the resulting coded video streams are referred to herein as bitstreams. New video coding specifications generally have a rich set of compression tools and can exploit temporal redundancies among pictures in more elaborate and comprehensive ways than prior video coding standards. Such advanced features also impose challenge in management of resources such as the decoded picture buffer in memory contains pictures yet to be output when the picture resolution of pictures to be decoded changes.

In one method embodiment a method of processing a bitstream at a processing device is disclosed. The method includes receiving at the processing device the bitstream comprising a first Coded Video Sequence CVS having a first picture resolution and a second CVS having a second picture resolution where the first coded picture of the second CVS is the first coded picture in the bitstream after the last coded picture of the first CVS allocating by the processing device an amount of memory corresponding to a maximum number of frame buffers of a Decoded Picture Buffer DPB herein called MaxDpbSize such that the value of MaxDpbSize equals a first number and each of the first number frame buffers in the DPB corresponds to a maximum frame buffer size for storing a respective decoded picture having a maximum picture resolution sizing by the processing device each frame buffer of the DPB in units corresponding to a maximum coding block size determining by the processing device a first frame buffer size corresponding to the first picture resolution and determining by the processing device a second number for the value of MaxDpbSize according to the magnitude of the first frame buffer size in relation to the magnitude of the maximum frame buffer size. The method further comprises of determining by the processing device a second frame buffer size corresponding to the second picture resolution and determining by the processing device a third number for the value of MaxDpbSize according to the magnitude of the second frame buffer size in relation to the magnitude of the maximum frame buffer size and responsive to determining by the processing device that the third number is different than the second number determining whether to output or not to output pictures in the DPB.

Disclosed herein are various example embodiments of Video Processing VP systems and methods collectively referred to herein also as a VP system that convey and process a bitstream and auxiliary information delivered in corresponding to or associated with the bitstream.

The Advanced Video Coding H.264 AVC standard is known as ITU T Recommendation H.264 and ISO IEC International Standard 14496 10 also known as MPEG 4 Part 10 Advanced Video Coding AVC . Similarly to earlier video coding standards a video coding specification provides the syntax and semantics for the bitstream that enable the decoding process for error free bitstreams.

A bitstream may include a plurality of successive coded video sequences CVS each CVS having a sequence of one or more coded pictures. The input to a video encoder is a sequence of pictures and the output of a video decoder is also a sequence of pictures. A picture may either be a frame or a field. A frame may comprise of a matrix of luma samples and corresponding chroma samples. A picture may be partitioned into contiguous non overlapping blocks of luma samples and their corresponding blocks of chroma samples for encoding purposes. Each of the contiguous non overlapping blocks in their coded form may be called a Coding Tree Unit CTU or alternatively a coding block. A bitstream may include plural coding block sizes according to the video coding specification of which the maximum coding block size among the plural coding block sizes is considered the worst case coding block size. The worst case coding block size may also be referred to as the Largest Coding Unit LCU .

A picture may be further partitioned to one or more slices each including an integer number of coded blocks i.e. CTU ordered consecutively in raster scan order. In one embodiment each coded picture is coded as a single slice.

A video encoder outputs a bitstream of coded pictures corresponding to the input sequence of pictures. The bitstream of coded pictures is the input to a video decoder which outputs a sequence of pictures corresponding to the decoded version of the coded pictures of the input bitstream.

In a video coding specification such as AVC H.264 each network abstraction layer NAL unit in the bitstream has a NAL unit header that includes a NAL unit type. Each coded picture in the bitstream corresponds to an access unit comprising one or more NAL units.

A NAL unit can identify with its NAL unit type a respectively corresponding type of data such as a Sequence Parameter Set SPS a picture parameter set PPS an SEI Supplemental Enhancement Information or a slice which consists of a slice header followed by slice data i.e. coded picture data . The SPS may contain Video Usability Information VUI . A coded picture includes the NAL units that are required for the decoding of the picture. One or more of the above mentioned parameter sets such as the SPS may contain auxiliary information referred in one or more of the embodiments herein.

The bistream produced by a video encoder consists of one or more coded video sequences CVS . Each Coded Video Sequence CVS corresponds to a Random Access Point RAP that enables entering the bitstream at that point. The CVS consists in decoding order of a first picture called a RAP picture which corresponds to an intra coded picture followed by other pictures up to but not including the first picture of the next CVS. Each CVS corresponds respectively to a set of parameters such as an SPS and one or more PPS required to decode the coded pictures in the CVS. Certain parameters of the bistream are only allowed to change at the start of a CVS. The picture resolution which as an example can be expressed by pic width in luma samples pic height in luma samples is only allowed to change at the start of a CVS.

In one embodiment the picture decode rate is controlled via a specified clock tick specified by the parameters corresponding to the respective CVS. In an alternate embodiment the picture output rate is controlled via the clock tick specified by the parameters corresponding to the respective CVS.

The bitstream syntax of the video coding specification indicates whether or not a particular coded picture is a reference picture for inter prediction of any other picture. Consequently a picture not used for prediction a non reference picture is not marked as used for reference by the video decoder and when it is no longer needed for output the video decoder can further mark it as no longer needed for output so that the corresponding frame buffer of the Decoded Picture Buffer DPB it occupies can be re used by a subsequent decoded picture.

In accordance with the video coding specification a decoded picture is either a reference picture or a non reference picture. A decoded non reference picture is marked as not needed for reference a video decoder. The video decoder further marks a decoded reference picture that resides in the DPB as not needed for reference after it is no longer needed for reference for the decoding of other coded pictures in the bitstream. Likewise the video decoder marks a decoded picture as not needed for output when the picture has been output or in accordance with one embodiment after the last output instance of the decoded picture. The markings are performed in order to free up the consumption or occupancy of frame buffers of the DPB such as when the picture residing in a respectively corresponding frame buffer of the DPB is marked as not needed for reference and marked as not needed for output .

A decoded picture may occupy a frame buffer of the DPB because it is used as a reference in inter prediction by one or more subsequent coded pictures or because its output time is later than its decode time.

In accordance with the HRD the frame buffer of the DPB occupied by a first decoded picture becomes available i.e. freed up to store a subsequent decoded picture i.e. a second decoded picture upon the first decoded picture being marked as not needed for reference and not needed for output. 

The definition of the output of a picture in a video coding specification such as ITU H.264 a.k.a. as MPEG 4 AVC or ISO IEC 14496 Part 10 typically refers to the time that picture is output from the DPB and not necessarily the time that the picture is presented or displayed in a visual surface or emitting light device such as display monitor or television.

Any two consecutive CVS in a bitstream may correspond to two respective video sources with different picture resolutions such as at a transition between a broadcast video program and a commercial. As in AVC H.264 a video coding specification may include a no output of prior pics flag that when set not equal to one would allow a change to the respective values of pic width in luma samples and pic height in luma samples in the second of two consecutive CVS.

The maximum picture resolution may be referred herein as MaxPicSize. Furthermore the largest picture size and maximum picture size herein mean the same and may further referred to the picture size that corresponds to MaxLumaFS.

In one method embodiment a processing device receives a bitstream comprising a first CVS having a first picture resolution and a second CVS having a second picture resolution where the first coded picture of the second CVS is the first coded picture in the bitstream after the last coded picture of the first CVS. Upon receiving the bitstream the processing device allocates an amount of memory corresponding to a maximum number of frame buffers of the DPB herein called MaxDpbSize where the value of MaxDpbSize equals MaxPicDpbSize which is a positive integer such as six. When MaxDpbSize is equal to MaxPicDpbSize i.e. the first number each of the frame buffers in the DPB correspond to a maximum frame buffer size for storing a decoded picture having a maximum picture resolution MaxPicSize. The processing device sizes each frame buffer of the DPB in units corresponding to a maximum coding block size such as when the maximum coding block size among plural coding block sizes equals or corresponds to a 64 64 luma sample block. Upon receiving a first auxiliary information corresponding respectively to the first CVS said first auxiliary information corresponding to the first picture resolution the processing device determines a first frame buffer size corresponding to the first picture resolution such first frame buffer size in units corresponding to the largest coding block size e.g. 64 64 . The processing device further determines a second number for the value of MaxDpbSize according to the magnitude of the first frame buffer size in relation to the magnitude of the maximum frame buffer size.

Upon receiving a second auxiliary information corresponding respectively to the second CVS said second auxiliary information corresponding to the second picture resolution. The processing device determines if the second picture resolution is different to the first picture resolution and responsive to the second picture resolution being different than the first picture resolution the processing device determines a second frame buffer size corresponding to the second picture resolution such second frame buffer size in units corresponding to the largest coding block size e.g. 64 64 . The processing device further determines a third number for the value of MaxDpbSize according to the magnitude of the second frame buffer size in relation to the magnitude of the maximum frame buffer size.

In one embodiment the second number is different than the first number MaxPicDpbSize. In an alternate embodiment the second number equals the first number. In yet another embodiment neither the second number or third number is equal to the first number i.e. MaxPicDpbSize .

Responsive to determining by the processing device that the third number is different than the second number the processing device determines whether to output or not to output the decoded pictures in the DPB such decoded pictures in the DPB.

In one embodiment the auxiliary information corresponding respective to the second CVS of two consecutive CVS may signal a change in picture resolution for the coded pictures in the second CVS such picture resolution change being with respect to the picture resolution corresponding to the coded pictures in the first CVS of the two consecutive CVS. Effectively this corresponds to a change in picture resolution from the last coded picture of the first CVS to the first coded picture in a second CVS that immediately follows the first CVS. For instance the native picture resolution of a video signal corresponding to a television service may be different than the picture resolution of the coded pictures in one or more CVS corresponding to a commercial segment. The auxiliary information may be included in the bistream in advance of the change in the picture resolution. The VP system may based on the picture resolution and a level of encoding associated with the bitstream determine the value of MaxDpbSize based on the ratio of the DPB s frame buffer size required to store the decoded pictures with a first picture resolution and the maximum frame buffer size as described previously . The MaxDpbSize is determined to enable transition from one picture resolution to another picture resolution in two consecutive CVS without having to deallocate and reallocate the memory allocated for the DPB.

MaxDpbSize is influenced according to the largest or maximum picture size in terms of total number of pixels in the spatial picture resolution carried among the coded pictures of a bitstream expected by a decoder compliant to the video coding specification which is therefore according to the maximum picture resolution corresponding to a specified level of the video coding specification. In a particular bitstream encoded at a given encoding level the largest picture size among plural alternate picture resolutions may correspond to a main picture resolution. Alternate picture resolutions may be inserted or provided in certain segments or intervals in the bitstream. For instance an advertisement segment may be inserted at a device such as a splicing device.

One benefit of variable number of picture buffers in the DBP is that their corresponding memory management at the VP device may be facilitated. For instance de allocation and reallocation of linearly allocated memory for MaxDpbSize equal to MaxPicDpbSize according to the embodiments specified herein allow for changing picture resolution gracefully without having to deallocate and reallocate the memory corresponding to the DPB.

Certain embodiments disclosed herein address the allocation of memory corresponding to the DPB that is required for a video decoder to be compliant to a specified level which is according to its maximum picture resolution resulting in memory allocated for MaxPicDpbSize. Further according to the largest or maximum picture size among the plural alternate picture sizes the allocation of memory is such that a fixed amount of linear memory for the DPB is allocated by the a compliant decoder such as one in VP device for the particular encoding level and hence to support the level s maximum or largest picture resolution. Thus the amount of memory may be allocated and reserved as available for processing e.g. decoding coded pictures of a bitstream based on the largest picture size. The largest picture size and maximum picture size herein mean the same and may be further referred to the picture size corresponding to MaxLumaFS.

For a CVS of the bitstream having a smaller picture resolution the same memory allocation may persist. For such portions with smaller picture sizes than the largest picture size among the plural anticipated picture resolutions memory is not de allocated and re allocated.

Auxiliary information corresponding to each respective CVS of the bitstream is provided prior to a change of picture resolution with respect to the immediately prior CVS. Furthermore the auxiliary information for a respective picture resolution may not change throughout the bitstream yet it may not correspond to the maximum picture size i.e. be a smaller picture resolution . Furthermore MaxDpbSize may or may not be equal to MaxPicDpbSize. For instance when the auxiliary information is provided periodically it may be provided prior to the first picture of each successive CVS in the bitstream and yet the picture resolution may not change. Similarly the picture resolution in one embodiment may change but not equal to the maximum picture resolution of the level yet memory for the DPB is allocated according to the maximum picture size and the maximum frame buffer size of the DPB always affects the determination of MaxDpbSize.

In one embodiment the VP device implements the DPB as a circular buffer of linear allocated memory for instance such as when implemented using DDR memory. Units of memory may be allocated in accordance to the worst case coding block or region such as corresponding to a 64 by 64 luma sample region which corresponds to 4 Kbytes when samples are 8 bits. Chroma Cr and Cb samples may be allocated separately but similarly. The linear memory may be demarcated at boundaries corresponding to the start of each frame buffer in the DPB. Each picture stored in the DPB corresponds to a decoded picture used as reference picture or a picture yet to be output

Note that throughout this specification frame buffer of the DPB and picture buffer of the DPB mean the same unless otherwise specifically stated.

In one embodiment a maximum amount of linear memory required for a bitstream encoded at a encoding level may correspond to a number of picture buffers in the DPB also referred to as MaxDpbSize in this disclosure corresponding to a maximum picture size for the encoding level. The disclosure provides a mechanism to increase MaxDpbSize for pictures smaller than the maximum picture size as a function of units of 64 64 samples maximum number of reorder pictures sample rate. The disclosure may further provide a mechanism for mapping in linear memory of the smaller pictures DPB picture buffers to the DPB picture buffers corresponding to the maximum picture size.

As an example some applications may require transitioning between two CVS in a bitstream that have different picture sizes but have the same fixed picture rate for output or a different sample rate. As an example such applications may also require support to and from a CVS at twice the fixed picture rate or sample rate when the picture size is less than or equal to half the maximum picture size.

To support transitions from a first picture resolution to a second picture resolution in two consecutive CVS of the bitstream the maximum amount of linear memory required for MaxPicDpbSize consists of the maximum number of DPB frame buffers of size equal to MaxPicSize and the DPB picture buffers of MaxPicSize are consecutive in linear memory without discontinuity between them. A compliant decoder allocates an amount of memory for the DPB according to MaxDpbSize equal to MaxPicDpbSize. The linear memory corresponding to MaxPicDpbSize is demarcated at the boundaries that start each of the consecutive DPB picture buffers of MaxPicSize. The demarcated boundaries may be different depending on the DPB picture buffer pointer allocation. The DPB linear memory may be broadly classified in two different models based on whether the allocated linear memory wraps around from the end to the start. In a first model also referred to as a circular buffer model the end of the linear memory corresponds to the end of the frame buffer of the DPB corresponding to MaxPicSize and wraps around to the start of the linear memory which corresponds to the start of a different DPB frame buffer of MaxPicSize. In a second model also referred to as non circular buffer model the end of the linear memory corresponds to the end of the DPB picture buffer of MaxPicSize and the memory does not wrap around to the start of the linear memory.

For decoder conformance the MaxDpbSize may be implied by MaxLumaPR maximum rate of decoded luma samples . In some embodiments the MaxDpbSize is implied by a maximum rate of output luma samples such as when the rate of output luma samples equals the value of MaxLumaPR for the applicable level of the video coding specification and the rate of decoded luma sample is less than MaxLumaPR. The later case may manifest when pictures are output more than once e.g. when fixed pic rate flag 1 and the coded picture rate in a CVS is less than the output picture rate .

The disclosed derivation of MaxDpbOccupancy the maximum number of pictures in the DPB which are yet to be output at the time of transition is based on respective parameter or variable values of any two consecutive CVSes namely the clock tick value picture size and the value of fixed pic rate flag. MaxDpbOccupancy is always less than or equal to the maximum number of reordered pictures num reorder pics defined for the first of the two consecutive CVS.

In one embodiment since the DPB stores reference picture or pictures which are yet to be output and includes a picture buffer for the current decoded picture MaxReorderNum num reorder pics for the level s the MaxPicSize is equal to the MaxPicDpbSize minus one. Unlike the prior coding specifications the MaxReorderNum num reorder pics is not equal to the MaxDpbSize because the MaxDpbSize includes the current decoded picture.

In one embodiment when the fixed pic rate flag 1 in the two consecutive CVS the no output of prior pics flag if present is according to its value and is not inferred. Unless otherwise noted the no output of prior pics flag is present and is equal to zero. In a first scenario by considering transition from a first CVS with pictures of MaxPicSize to a second CVS the MaxDpbOccupancy at the time of transition and MaxDpbSize for the second of the two consecutive CVS is disclosed. In a second scenario by considering transition from the second CVS to the first CVS with pictures of MaxPicSize the MaxDpbOccupancy at the time of transition is disclosed. The MaxDpbSize for the second CVS with pictures of MaxPicSize is MaxPicDpbSize.

In one embodiment the picture buffers are mapped to the larger consecutive DPB picture buffers of MaxPicSize in the demarcated linear memory that corresponds to the level s MaxPicDpbSize. The picture buffer demarcation can change depending on the DPB picture buffer pointer allocation. Constraints on the MaxDpbOccupancy in both of the above transitions is obtained by considering the DPB pictures in the preceding CVS that are yet to be output and the size of the DPB picture buffers and their respective mapping within the demarcated picture buffers of MaxPicSize in the linear memory corresponding to the level s MaxPicDpbSize and the value of clock tick must be the same for any two consecutive CVSes except for a CVS with a picture size less than or equal to half of MaxPicSize when the clock tick may be half or equal to the clock tick of the other CVS. Otherwise the value of the no output of prior pics flag must be set equal to 1 by the splicer. A decoded picture intended to be output should be honored either by outputting the picture or a corresponding blank picture. Otherwise CPB issues may manifest eventually.

In one embodiment the ratio between the picture size of the pictures of a CVS and the picture size of the largest picture at the encoding level may be classified in four ranges. As an example the following four different picture sizes may be considered in relation to the level s MaxPicSize during transition from one CVS to another a less than or equal to 0.5 MaxPicSize b greater than 0.5 MaxPicSize but less than or equal to 0.667 MaxPicSize c greater than 0.667 MaxPicSize but less than or equal to 0.75 MaxPicSize and d greater than 0.75 MaxPicSize but less than or equal to 1.0 MaxPicSize.

The tables below Table 1 and Table 2 may provide a maximum limit on the DpbOccupancy the MaxDpbOccupancy at the time of transition from CVS with pictures of size MaxPicSize to CVS with pictures of sizes mentioned above. These two tables also provide respective MaxDpbSize for the second of the two consecutive CVSes.

The tables below Table 3 and Table 4 may provide a maximum limit on the DpbOccupancy MaxDpbOccupancy at the time of transition from CVS with pictures of sizes mentioned above to CVS with pictures of sizes MaxPicSize. These two tables also provide respective MaxDpbSize for the second of the two consecutive CVS and is fixed at MaxPicDpbSize.

As disclosed previously ratios between the picture size of the pictures of a CVS and the picture size of the largest picture at the encoding level of the CVS may be classified in four ranges. The first of the four ranges may include the ratio in a range of less than or 0.5 i.e. ratio of the picture size is in a range of less than or equal to 0.5 MaxPicSize . When the ratio for pictures of the first CVS falls in this range two picture buffers for the first CVS may be mapped into one picture buffer of the second CVS i.e. a demarcated MaxPicDpbSize picture buffers of MaxPicSize . Thus a number of picture buffers for the CVS may be calculated as MaxDpbSize 2 MaxPicDpbSize

To allow a transition from a CVS with pictures of MaxPicSize consideration may be given to the worst case occupation of DPB picture buffers each of size equal to MaxPicSize in the linear memory that corresponds to MaxPicDpbSize. The following is obtained MaxDpbOccupancy MaxPicDpbSize 1 when DPB is either a circular or a non circular buffer

To allow a transition back to the CVS with pictures of MaxPicSize consideration may be given to the worst case occupation of DPB picture buffers each of size equal to 0.5 MaxPicSize in the linear memory that corresponds to MaxPicDpbSize. The following is obtained MaxReorderNum MaxPicSizeDpb 1 when DPB is either a circular or a non circular buffer

The second of the four ranges may include the ratios in a range of greater than less than or 0.5 and less than or equal to 0.667 i.e. ratio of the picture size is in a range of greater than 0.5 MaxPicSize but less than or equal to 0.667 MaxPicSize . In the second scenario three consecutive picture buffers may be mapped into each respective set of two consecutive picture buffers of 1.0 MaxPicSize to obtain MaxDpbSize floor 3 MaxPicDpbSize 2 MaxReorderNumLimit MaxPicDpbSize 1

The third of the four ranges may include the ratios in a range of greater than less than or 0.667 and less than or equal to 0.75 i.e. ratio of the picture size is in a range of greater than 0.667 MaxPicSize but less than or equal to 0.75 MaxPicSize . In the third scenario four consecutive picture buffers may be mapped into each respective set of three consecutive picture buffers of 1.0 MaxPicSize to obtain MaxDpbSize floor 4 MaxPicDpbSize 3 

The fourth of the four ranges may include the ratios in a range of greater than less than or 0.75 and less than or equal to 1.0 i.e. ratio of the picture size is in a range of greater than 0.75 MaxPicSize but less than or equal to 1.0 MaxPicSize . In the fourth scenario each respective picture buffer is mapped into a corresponding respective picture buffer of 1.0 MaxPicSize MaxDpbSize MaxPicDpbSize

In one embodiment when the fixed pic rate flag equals zero in one of both of the two consecutive CVS the no output of prior pics flag if present is according to its value and may not be inferred. Unless otherwise noted the no output of prior pics flag may be assumed to be present and equal to zero. The value of clock tick must be the same for any two consecutive CVS except for a CVS with a picture size less than or equal half of MaxPicSize when the clock tick may be half or equal to the clock tick of the other CVS. Otherwise the value of the no ouput of prior pics flag must be equal or inferred equal to 1. The respective MaxDpbSize and maximum number of reorder pictures may be provided for two different picture sizes in relation to the level s MaxPicSize 

In the first case when the picture size is in a range of less than or equal to 0.5 MaxPicSize two picture buffers may be mapped into each of the respective demarcated MaxPicDpbSize picture buffers of MaxPicSize to obtain MaxDpbSize 2 MaxPicDpbSize

In the first case when the picture size is in a range of greater than 0.5 MaxPicSize but less than or equal to 1.0 MaxPicSize each respective picture buffer is mapped into a corresponding respective picture buffer of MaxPicSize to obtain MaxDpbSize MaxPicDpbSize

In one embodiment fixed picture rate may refer to either a fixed rate of picture fields or a fixed rate of frames where the frames correspond to progressive pictures. In another embodiment fixed picture rate may refer to a fixed rate of frames that may comprise of every two consecutive pairs of fields either a top field and a corresponding bottom field paired consistently throughout the bitstream or a bottom field and a corresponding top field paired consistently throughout the bitstream. The type of pairings may be switched at the start of a CVS in the bitstream. In yet another embodiment fixed picture rate may refer to a rate of pictures that are either field or frames both treated as progressive pictures for coding purposes but for output purposes a field inferred as a top or bottom field each corresponding respectively to the set of every other spatial line implied by top and bottom and a frame as a progressive frame of consecutive lines.

This disclosure proposes a mechanism which provides plural MaxDpbSize values such as four values corresponding to four different positive integers for luma picture sizes equal to a factor of 0.5 0.667 0.75 and 1.0 of the maximum luma picture size MaxLumaFS with the amount of linear memory fixed for all four MaxDpbSize values. The amount of linear memory for any picture size may be constant and equal to the level s MaxLumaFS. Any picture sized in 64 64 luma sample increments may be provided with a MaxDpbSize value that corresponds to the closest but larger of the four respective luma picture sizes. Furthermore the MaxDpbSize is limited when the luma picture size changes in the bitstream providing means to output DPB pictures yet to be output since memory allocated for the DPB does not have to be deallocated when the picture resolution changes. In one embodiment the option to allow output pictures yet to be output may limit changes in luma sample rate or may require a fixed picture rate through the two consecutive coded video sequences where a change in picture size occurs.

Herein MaxLumaFS may denote a level s maximum luma picture size LumaFS may represent a luma picture size less than or equal to MaxLumaFS MaxLumaPR may denote the maximum luma sample rate LumaPR may represent a luma sample rate less than or equal to MaxLumaPR MaxPicDpbSize may be the MaxDpbSize corresponding to MaxLumaFS and MaxMem may represent the maximum amount of linear memory implied from the MaxPicDpbSize consecutive buffers of equal size each corresponding to the MaxLumaFS of the level.

In one embodiment every LumaFS value may correspond to the smallest number of 64 horizontal units and 64 vertical units that respectively encompass the width and height of the luma samples of the picture. The size of each DPB buffer may correspond to 64 64 luma sample increments. Note that the 64 by 64 units may correspond to luma samples and furthermore to the largest block size among plural block sizes such block sizes corresponding to the blocks in the grid of blocks mapped onto each picture for the purpose of coding.

When LumaFS is not equal to a factor of 0.5 0.667 0.75 and 1.0 of MaxLumaFS the consecutive DPB buffers of equal size in MaxMem that correspond to LumaFS are a larger number of 64 64 units than the actual LumaFS. The benefit in exchange is that a decoder may not have to perform memory de allocation or reallocation since each DPB buffer is demarcated by a pointer to the start of the buffer and the end by the LumaFS increment. In one embodiment LumaFS corresponds to a value that equals a multiple of 64 64 units. The number of luma samples in pictures is used for purposes of deriving MaxDpbSize but the chroma samples in a picture are respectively implied.

Embodiments of the present disclosure may be generally implemented as part of a subscriber television system such as a Digital Broadband Delivery System DBDS or Cable Television System CTS . For example a Subscriber Television System STS and its operation will be described initially with the understanding that other conventional data delivery systems are within the scope of the preferred embodiments of the present disclosure. shows a block diagram view of a Subscriber Television System STS which is generally a high quality reliable and integrated network system that is preferably capable of delivering video audio voice and data services to Digital Home Communication Terminals DHCT . Although depicts a high level view of a CTS it should be appreciated that a plurality of subscriber television systems can tie together a plurality of regional networks into an integrated global network so that DHCT users can receive media content provided from anywhere in the world.

Further it will be appreciated that the STS shown in is merely illustrative and should not be construed as implying any limitations upon the scope of the preferred embodiments of the present disclosure. For instance subscriber television systems also included within the scope of the embodiments of the disclosure include systems not utilizing physical structured cabling for transmission such as but not limited to satellite systems. Further transmission media included within the scope of the preferred embodiments of the disclosure include but are not limited to Hybrid Fiber Coax HFC optical satellite Radio Frequency RF Frequency Modulated FM and microwave. Further data provided from the headend to the DHCT and programming necessary to perform the functions discussed below will be understood to be present in the STS in accordance with the description below.

The STS preferably delivers broadcast video signals as digitally formatted signals in addition to delivering traditional broadcast analog video signals. Furthermore the system can preferably support one way broadcast services as well as both one way data services and two way media content and data services. The two way operation of the network preferably allows for user interactivity with services such as Pay Per View programming Near Video On Demand NVOD programming according to any of several known NVOD implementation methods View On Demand VOD programming according to any of several VOD implementation methods and interactive applications such as Internet connections.

The STS also provides the interfaces network control transport control session control and servers to access media content from media content services and distributes media content to DHCT users. As shown in a typical STS comprises a head end hub an HFC access network and DHCT . It should be appreciated that although a single component e.g. a head end is illustrated in a STS can feature a plurality of any one of the illustrated components or may be configured with alternative embodiments for any one of the individual components or with yet other additional components not enumerated above.

Media content provided by one or more content providers not shown is communicated by the content providers to one or more head ends . From those head ends the media content is then communicated over a communications network that includes a plurality of HFC access networks only one HFC access network is illustrated . The HFC access network typically comprises a plurality of HFC nodes each of which may serve a local geographical area. The hub connects to the HFC node through a fiber portion of the HFC access network . The HFC node is connected to a tap which in one implementation is connected to a Network Interface Unit NIU which is connected to a Digital Home Communication Terminal DHCT . In other implementations the HFC node is connected directly to a DHCT . The NIU when implemented is normally located at a user s property and provides a transparent interface between the HFC node and the users internal wiring. Coaxial cables are typically used to couple nodes taps and NIU because the electrical signals can be easily repeated with radio frequency RF amplifiers. As the high level operations of many of the functions of a Subscriber Television System STS are well known to those of ordinary skill in the art further high level description of the overall STS of will not be contained herein.

As depicted in the STS can simultaneously support a number of transmission signal types transmission rates and modulation formats. The ability to carry analog and digital signals over a large bandwidth are characteristics of a Hybrid Fiber Coax HFC Network typically employed in a STS as in the STS of . As will be appreciated by those of ordinary skill in the art analog and digital signals in HFC networks can be multiplexed using Frequency Division Multiplexing FDM which enables many different types of signals to be transmitted over the STS to the DHCT . Typically a STS using HFC supports downstream i.e. in the direction from the headend to the DHCT frequencies from 50 MHz to 870 MHz whereas upstream frequencies i.e. in the direction from the DHCT to higher levels of the system are in the 5 MHz to 42 MHz band. Generally the RF bandwidth spacing for analog and digital services is 6 MHz. Furthermore for a typical 870 MHz system in the U.S. a possible downstream RF spectrum subdivision plan uses 6 MHz spaced frequency subdivisions or spans within the 50 MHz to 550 MHz band for analog video transmission signals and within the 550 MHz to 870 MHz range for digital transmission signals. The Analog Transmission Signals ATS shown in are typically broadcast in 6 MHz frequency subdivisions typically referred to in analog broadcasting as channels having an analog broadcast signal composed of analog video and analog audio and include Broadcast TV Systems Committee BTSC stereo and Secondary Audio Program SAP audio.

Referring again to the downstream direction transmission signals having been multiplexed and in embodiments using Frequency Division Multiplexing FDM are often referred to as in band transmission signals and include Analog Transmission Signals ATS and Digital Transmission Signals DTS also known as Digital Transport Signals . These transmission signals carry video audio and data services. For example these transmission signals may carry television signals Internet data or any additional types of data such as Electronic Program Guide EPG data. Additionally as will be appreciated by those of ordinary skill in the art additional data can be sent with the analog video image in the Vertical Blanking Interval VBI of the video signal and stored in DHCT memory or a DHCT local physical storage device not shown . It should be appreciated however that the amount of data that can be transmitted in the VBI of the analog video signal is typically significantly less than data transmitted in a DTS.

Like the ATS the DTC each occupies 6 MHz of the RF spectrum. However the DTS are digital transmission signals consisting of 64 or 256 Quadrature Amplitude Modulated QAM digital signals formatted as MPEG 2 transport streams allocated in a separate frequency range. As will be described in more detail below the MPEG 2 transport stream enables transmission of a plurality of DTS types over each 6 MHz RF spacing as compared to a 6 MHz ATS. The three types of digital transport signals illustrated in include broadcast digital transmission signals carousel digital transmission signals and on demand transmission signals .

MPEG 2 transport may be used to multiplex video audio and data in each of these Digital Transmission Signals DTS . However because an MPEG 2 transport stream allows for multiplexed video audio and data into the same stream the DTS do not necessarily have to be allocated in separate 6 MHz RF frequencies unlike ATS . On the other hand each DTS is capable of carrying multiple broadcast digital media content instances multiple cycling data carousels containing broadcast data and data requested on demand by the subscriber. Data is formatted such as in Internet Protocol IP mapped into MPEG 2 packets and inserted into the multiplexed MPEG 2 transport stream. Encryption can be applied to the data stream for security so that the data may be received only by authorized DHCT. The authorized DHCT is provided with the mechanisms to receive among other things additional data or enhanced services. Such mechanisms can include keys that are required to decrypt encrypted data.

Each 6 MHz RF subdivision assigned to a digital transmission signal can carry the video and audio streams of the media content instances of multiple television TV stations as well as media content and data that is not necessarily related to those TV media content instances as compared to one TV channel broadcast over one ATS that consumes the entire 6 MHz. The digital data is inserted into MPEG 2 transport streams carried through each 6 MHz frequency subdivision assigned for digital transmission and then de multiplexed at the subscriber DHCT so that multiple sets of data can be produced within each tuned 6 MHz frequency span or subdivision.

Although broadcast in nature the carousel DTS and on demand DTS offer different functionality. Continuing with the broadcast DTS and carousel DTS typically function as continuous feeds for indefinite time whereas the on demand DTS are continuous feeds sessions for a limited time. All DTS types are capable of being transmitted at high data rates. The broadcast DTS carry typical data comprising multiple digitally video encoded and formatted TV source signals and other continuously fed data information. The carousel DTS carry broadcast media content or data that is systematically broadcast in a cycling fashion but updated and revised as needed. Thus the carousel DTS serve to carry high volume data such as media content and data and possibly other data at high data rates. The carousel DTS preferably carry data formatted in directories and files by a Broadcast File System BFS not shown which is used for producing and transmitting data streams throughout the STS and which provides an efficient means for the delivery of application executables and application media content and data to the DHCT as will be described below. Media content and data received by the DHCT in such manner can then be saved in the DHCT memory and or transferred to the DHCT storage device for later use. The on demand DTS on the other hand can carry particular information such as coded video and audio pertaining to subscriber requested media content instance preview and or media content instance descriptions as well as other specialized data information.

The User to Network Download Protocol of the MPEG 2 standard s DSM CC specification Digital Storage Media Command and Control provides the data carousel protocol used for broadcasting data from a server located at headend or elsewhere. It also provides the interactive download protocol for reliable downloading of data from a server possibly the same server to an individual DHCT through the on demand DTS. Each carousel and on demand DTS is defined by a DSM CC session. Therefore some of the basic functionality reflected in the DHCT when the DHCT does not have a local physical storage device is somewhat similar to a networked computer i.e. a computer without a persistent storage device in addition to traditional set top box functionality as is well known to those of ordinary skill in the art. A DHCT with a storage device reduces data access latency when the data is stored in the local physical storage device ahead of time.

Also shown in are Out Of Band OOB signals that provide continuously available two way signaling to the subscribers DHCT regardless of which in band signals are tuned to by the individual DHCT in band tuners as described below. The OOB signals consists of a Forward Data Signal FDS and a Reverse Data Signal RDS . The OOB signals can comply to any one of a number of well known transport protocols but preferably comply to either a DAVIC 1.1 Transport Protocol with FDS of 1.544 mega bits per second Mbps or more using Quadrature Phase Shift Keying QPSK modulation and an RDS of 1.544 Mbps or more using QPSK modulation or to a DOCSIS Transport Protocol with FDS of 27 Mbps using 64 QAM modulation and a RDS of 1.544 Mbps or more using QPSK modulation or 16 QAM modulation. The OOB signals provide the two way operation of the network which allows for subscriber interactivity with the applications and services provided by the network. Furthermore the OOB signals are not limited to a 6 MHz spectrum but generally to a smaller spectrum such as 1.5 or 3 MHz.

In a typical system the programming services and other information from content providers can be distributed according to a variety of mechanisms. The input signals may be transmitted from sources to the headend via a variety of transmission paths including satellites not shown and terrestrial broadcast transmitters and antennas not shown . The headend can also receive content from a direct feed source via a direct line . Other input sources from content providers include a video camera analog input source or an application server . The application server may include more than one line of communication. One or more components such as analog input source input source video camera and application server can be located external to the headend as shown or internal to the headend as would be appreciated by one having ordinary skill in the art. The signals provided by the content or programming input sources can include a single media content instance i.e. individual instances of media content such as an episode of a television show a movie or web page etc. or a multiplex that includes several media content instances.

The headend generally includes one or more receivers that are each associated with a content source. Video encoders such as encoder are included for digitally encoding at least some local programming or a real time feed from video camera or the like. Video encoder outputs the respective coded video and audio streams corresponding to the analog audio video signal received at its input. For example video encoder can output bitstreams Packetized Elementary PES Streams or transport streams compliant to the syntax and semantics of the transport portion of the ISO MPEG 2 standard systems specification respectively. The PES or transport streams may be multiplexed with input signals from switch receiver and control system . The multiplexing logic processes the input signals and multiplexes at least a portion of the input signals into transport stream .

Analog input source can provide an analog audio video broadcast signal which can be input into modulator . From modulator a modulated analog output signal can be combined at combiner along with other modulated signals for transmission into transmission medium . Alternatively analog audio video broadcast signal from analog input source can be input into modulator . Alternatively analog audio video broadcast signal can be input directly from modulator to transmission medium . The analog broadcast media content instances are transmitted via respective Radio Frequency RF channels each assigned for transmission of an analog audio video signal such as NTSC video as described in association with .

The switch such as Asynchronous Transfer Mode ATM switch provides an interface to an application server . There can be multiple application servers providing a variety of services such as a Pay Per View service including Video On Demand VOD a data service an Internet service a network system or a telephone system. Service and content providers may download content to an application server located within the STS . The application server may also be located within the headend or elsewhere within the STS such as in a hub . The various inputs into the headend are then combined with the other information from the control system which is specific to the STS such as local programming and control information which can include among other things conditional access information. The headend contains one or more modulators to convert the received transport streams into modulated output signals suitable for transmission over the transmission medium through the network . Each modulator may be a multimodulator including a plurality of modulators such as but not limited to QAM modulators that radio frequency modulate at least a portion of the transport streams to become output transport streams . The output signals from the various modulators or multimodulators are combined using equipment such as a combiner for input into the transmission medium which is sent via the in band delivery path to subscriber locations not shown . In band delivery path can include DTS and ATS as described with . In one example the server also provides various types of data to the headend .

The control system enables the television system operator to control and monitor the functions and performance of the STS . The control system interfaces with various components via communication link in order to monitor and or control a variety of functions including the frequency spectrum lineup of the programming for the STS billing for each subscriber and conditional access for the content distributed to subscribers. Information such as conditional access information is communicated from the control system to the multiplexing logic where it is multiplexed into a transport stream .

Among other things the control system provides input to the modulator for setting the operating parameters such as selecting certain media content instances or portions of transport streams for inclusion in one or more output transport streams system specific MPEG table packet organization and or conditional access information. Control information and other data can be communicated to hub and DHCT via an in band delivery path or via an out of band delivery path .

The out of band data is transmitted via the out of band FDS of transmission medium by means such as but not limited to a Quadrature Phase Shift Keying QPSK modem array . Two way communication utilizes the RDS of the out of band delivery path . Hub and DHCT transmit out of band data through the transmission medium and the out of band data is received in headend via out of band RDS. The out of band data is routed through router to an application server or to control system . The out of band control information includes such information as a pay per view purchase instruction and a pause viewing command from the subscriber location to a video on demand type application server located internally or external to the headend such as application server as well as any other data sent from the DHCT or hub all of which will preferably be properly timed. The control system also monitors controls and coordinates all communications in the subscriber television system including video audio and data. The control system can be located at headend or remotely.

The transmission medium distributes signals from the headend to the other elements in the subscriber television system such as a hub a node and subscriber locations . The transmission medium can incorporate one or more of a variety of media such as optical fiber coaxial cable and hybrid fiber coax HFC satellite direct broadcast or other transmission media.

The DHCT further preferably includes at least one processor for controlling operations of the DHCT an output system for driving the television display and a tuner system for tuning into a particular television channel or frequency to be displayed and for sending and receiving various types of data or media content to and from the headend . The DHCT may include in other embodiments multiple tuners for receiving downloaded or transmitted media content. Tuner system can select from a plurality of transmission signals provided by the subscriber television system. Tuner system enables the DHCT to tune to downstream media and data transmissions thereby allowing a user to receive digital or analog media content delivered in the downstream transmission via the subscriber television system. The tuner system includes in one implementation an out of band tuner for bi directional Quadrature Phase Shift Keying QPSK data communication and a Quadrature Amplitude Modulation QAM tuner in band for receiving television signals. Additionally a receiver receives externally generated information such as user inputs or commands from an input device or other devices.

According to another embodiment of the disclosure a telephone modem not shown in the DHCT can be utilized for upstream data transmission and a headend hub or other component located upstream in the STS can receive data from a telephone network corresponding with the telephone modem and can route the upstream data to a destination internal or external to the STS such as an application data server in the headend or content provider.

The DHCT includes signal processing system which comprises demodulating system and transport demultiplexing and parsing system herein demultiplexing system to process broadcast media content and or data. One or more of the systems of signal processing system can be implemented with software a combination of software and hardware or preferably in hardware. Demodulating system comprises functionality for RF signal demodulation either an analog transmission signal or a digital transmission signal. For instance demodulating system can demodulate a digital transmission signal in a carrier frequency that was modulated among others as a QAM modulated signal. When tuned to a carrier frequency corresponding to an analog TV signal transmission demultiplexing system is bypassed and the demodulated analog TV signal that is output by demodulating system is instead routed to analog video decoder . Analog video decoder converts the analog video signal i.e. the video portion of a media content instance that comprises a video portion and an audio portion received at its input into a respective non compressed digital representation comprising a sequence of digitized pictures and their respective digitized audio. Presented at the input to analog video decoder is an analog video signal such as NTSC video comprising of audio and video. In one implementation the video consists of a sequence of fields spaced apart at approximately one sixtieth of a second. A pair of consecutive fields constitutes a picture. The odd field contains the odd numbered lines of the picture and the even field contains the even numbered lines of the picture. Analog video decoder outputs the corresponding sequence of digitized pictures and respective digitized audio. Each picture is a two dimensional entity of picture elements and each picture element contains a respective set of values. A picture element value comprises luminance and chrominance information that are representative of brightness and color information at the spatial location of the picture element within the picture.

Digitized pictures and respective audio output by analog video decoder are presented at the input of compression engine . Digitized pictures and respective audio output by analog video decoder can also be presented to an input of media engine via an interface not shown dedicated for non compressed digitized analog video and audio such as ITU 656 for display on TV . Compression engine is coupled to localized memory preferably DRAM for input and processing of the input digitized pictures and their respective digitized audio. Alternatively compression engine can have its own integrated memory not shown . Compression engine processes the sequence of digitized pictures and digitized audio and converts them respectively into a bitstream of one or more coded video sequences or video streams and an audio compressed stream or audio bitstream respectively. The audio and video bitstreams are produced in accordance with the syntax and semantics of respective audio and video coding specifications so that they can be interpreted by respectively compliant video decoder and audio decoder for decompression. Each bitstream consists of a sequence of data packets containing a header and a payload. Each header contains a unique program identification or PID associated with the respective compressed stream or bitstream.

Compression engine multiplexes the audio and video compressed streams into a transport stream such as an MPEG 2 transport stream for output. In one embodiment compression engine can preferably compress audio and video corresponding to more than one program in parallel e.g. two tuned analog TV signals and to multiplex the respective audio and video compressed streams into a single transport stream. Output of compressed streams and or transport streams produced by compression engine is input to signal processing system . Parsing capabilities within signal processing allow for interpretation of sequence and picture headers for instance annotating their locations within their respective compressed stream for future retrieval from storage device . A compressed analog media content instance e.g. TV program episode or show corresponding to a tuned analog transmission channel can be output as a transport stream by signal processing and presented as input for storage in storage device via interface as will be described below. The packetized compressed streams can be also output by signal processing and presented as input to media engine for decompression by video decompression engine and audio decompression engine for its display on TV as will be described below.

Demultiplexing system can include MPEG 2 transport demultiplexing. When tuned to carrier frequencies carrying a digital transmission signal demultiplexing system enables the separation of packets of data corresponding to the compressed streams of information belonging to the desired media content instances for further processing. Concurrently demultiplexing system precludes packets in the multiplexed transport stream that are irrelevant or not desired such as packets of data corresponding to compressed streams of media content instances of other media content signal sources e.g. other TV channels from further processing.

Parsing capabilities of demultiplexing system include reading and interpreting the received transport stream without disturbing its content such as to interpret sequence and picture headers for instance to annotate their locations within their respective compressed stream for future retrieval from storage device . Thus the components of signal processing system are capable of QAM demodulation forward error correction and demultiplexing transport streams and parsing packetized elementary streams and elementary streams. A compressed media content instance corresponding to a tuned carrier frequency carrying a digital transmission signal can be output as a transport stream by signal processing and presented as input for storage in storage device via interface as will be described below. The packetized compressed streams can be also output by signal processing and presented as input to media engine for decompression by video decompression engine and audio decompression engine as will be described below.

One having ordinary skill in the art will appreciate that signal processing system will preferably include other components not shown including memory decryptors samplers digitizers e.g. analog to digital converters and multiplexers among others. Further other embodiments will be understood by those having ordinary skill in the art to be within the scope of the preferred embodiments of the present disclosure including analog signals e.g. NTSC that bypass one or more elements of the signal processing system and are forwarded directly to the output system . Further outputs presented at corresponding next stage inputs for the aforementioned signal processing flow may be connected via accessible memory in which the outputting device stores the output data and the inputting device thereafter inputs the output data written to memory by the respective outputting device. Outputting and inputting devices include analog video decoder compression engine media engine signal processing system and components or subcomponents thereof. Further it will be understood by those having ordinary skill in the art that components of signal processing system can be spatially located in different areas of the DHCT . Further it will be understood by those having ordinary skill in the art that although the components of signal processing system are illustrated as being in communication with an incoming signal from the communications interface the signal may not necessarily be in the order shown for all signals.

The DHCT also includes media engine which includes digital video decoder also known as video decompression engine and digital audio decoder also known as audio decompression engine and other digital signal processing components not shown as would be appreciated by those having ordinary skill in the art. For example demultiplexing system is in communication with tuner system and processor to effect reception of digital bitstreams digital compressed audio streams and data streams corresponding to one or more media content instances to be separated from other media content instances and or streams transported in the tuned transmission channel and to be stored in a first part not shown of DRAM of DHCT assigned to receive packets of one or more media content instances. Other dedicated memory may also be used for media content instance packets.

Furthermore while conducting this process demultiplexing system demultiplexes and separates desired compressed streams from the received transport stream without disturbing its content. Further parser parses i.e. reads and interprets compressed streams such as to interpret sequence headers and picture headers and deposits a transport stream carrying compressed streams of a media content instance into DRAM . Processor causes transport stream in DRAM to be transferred to the storage device via interface . Under program control by processor the demultiplexing system in communication with the digital video decoder storage device and processor effect notification and or transfer of received packets of one or more compressed streams corresponding to one or more media content instances from a first part of DRAM to a second part not shown of DRAM assigned to the digital video decoder and the digital audio decoder . Alternatively media engine can have access to a dedicated localized DRAM not shown . Upon demultiplexing and parsing the transport stream carrying one or more media content instances signal processing system outputs to DRAM ancillary data in the form of a table or data structure not shown comprising the relative or absolute location of the beginning of certain pictures in the compressed media content instance for convenience in retrieval during future operations.

In one implementation compression engine can output bitstreams containing CVS that are packetized elementary streams PES inside a transport stream such as according to the syntax and semantics of the ISO MPEG 2 standard systems specifications. The bitstreams output by compression engine corresponding to a first media content instance are deposited in local memory for compression engine and routed to demultiplexing system . Demultiplexing system parses i.e. reads and interprets the transport stream generated by compression engine without disturbing its content such as to interpret picture headers and deposits the transport stream into DRAM . Processor causes transport stream in DRAM to be transferred to the storage device . While parsing the transport stream demultiplexing system outputs to memory ancillary data in the form of a table or data structure not shown comprising the relative or absolute location of the beginning of certain pictures in the compressed media content stream for the first media content instance for convenience in retrieval during future operations. In this way random access operations such as fast forward rewind and jumping to a location in the compressed media content instance can be attained.

In another implementation according to a plurality of tuners a respective number of analog video decoders and a respective number of compression engines the aforementioned compression of analog video and audio is performed and routed to hard disk of the storage device simultaneously for a respective number of analog media content instances. Alternatively a single compression engine with sufficient processing capabilities can serve to compress more than one analog media content instance.

The DHCT may also include one or more wireless or wired interfaces also called communication ports for receiving and or transmitting data to other devices. For instance the DHCT may feature USB Universal Serial Bus Ethernet for connection to a computer IEEE 1394 for connection to media content devices in an entertainment center serial and or parallel ports. The user inputs may be for example provided by an input device including a computer or transmitter with buttons or keys located either on the exterior of the terminal or by a hand held remote control device or keyboard that includes user actuated buttons.

In one implementation the DHCT includes system memory which includes FLASH memory and dynamic random access memory DRAM for storing various applications modules and data for execution and use by the processor . Basic functionality of the DHCT is provided by an operating system that is primarily stored in FLASH memory . Among other elements the operating system includes at least one resource manager that provides an interface to resources of the DHCT such as for example computing resources. Also included within operating system is one or more device drivers that provides operating instructions to an internal or external storage device such as storage device and peripheral devices not shown. For example device driver provides operating instructions to the storage device controller of the storage device to effect among other functions read and or write operations to the hard disk of the storage device .

One or more programmed software applications herein referred to as applications or application clients are executed by utilizing the computing resources in the DHCT . The applications may be resident in FLASH memory or downloaded into DRAM . Applications stored in FLASH memory or DRAM are executed by processor e.g. a central processing unit or digital signal processor under the auspices of the operating system . Data required as input by an application is stored in DRAM or FLASH memory and read by processor as need be during the course of the application s execution. Input data may be data stored in DRAM by a secondary application or other source either internal or external to the DHCT or possibly anticipated by the application and thus created with the application at the time it was generated as a software application in which case it is stored in FLASH memory . Data generated by an application is stored in DRAM by processor during the course of the application s execution. DRAM also includes application memory that various applications may use for storing and or retrieving data.

An application referred to as navigator is also resident in FLASH memory for providing a navigation framework for services provided by the DHCT . The navigator registers for and in some cases reserves certain user inputs related to navigational keys such as channel increment decrement last channel favorite channel etc. The navigator also provides users with television related menu options that correspond to DHCT functions such as for example blocking a channel or a group of channels from being displayed in a channel menu.

The FLASH memory also contains a platform library . The platform library is a collection of utilities useful to applications such as a timer manager a compression manager a configuration manager an HTML parser a database manager a widget toolkit a string manager and other utilities not shown . These utilities are accessed by applications via Application Programming Interfaces API as necessary so that each application does not have to contain these utilities. Two components of the platform library that are shown in are a window manager and a Service Application Manager SAM client .

The window manager provides a mechanism for implementing the sharing of the screen regions and user input. The window manager on the DHCT is responsible for as directed by one or more applications implementing the creation display and de allocation of the limited DHCT screen resources. It allows multiple applications to share the screen by assigning ownership of screen regions or windows. The window manager also maintains among other things a user input registry in DRAM so that when a user enters a key or a command via the remote control device or another input device such as a keyboard or mouse the user input registry is accessed to determine which of various applications running on the DHCT should receive data corresponding to the input key and in which order. As an application is executed it registers a request to receive certain user input keys or commands. When the user presses a key corresponding to one of the commands on the remote control device the command is received by the receiver and relayed to the processor . The processor dispatches the event to the operating system where it is forwarded to the window manager which ultimately accesses the user input registry and routes data corresponding to the incoming command to the appropriate application.

The SAM client is a client component of a client server pair of components with the server component not shown being located on the headend preferably in the control system . A SAM database i.e. structured data such as a database or data structure in DRAM includes a data structure of services and a data structure of channels that are created and updated by the headend . Herein database will refer to a database structured data or other data structures as is well known to those of ordinary skill in the art. Many services can be defined using the same application component with different parameters. Examples of services include without limitation and in accordance with one implementation presenting television programs available through a WatchTV application pay per view events available through a PPV application digital music not shown media on demand available through an MOD application and an interactive program guide IPG . In general the identification of a service includes the identification of an executable application that provides the service along with a set of application dependent parameters that indicate to the application the service to be provided. As a non limiting example a service of presenting a television program i.e. media content instance could be executed by WatchTV application with a set of parameters specifying the HBO to view HBO or with a separate set of parameters to view CNN. Each association of the application component tune video and one parameter component HBO or CNN represents a particular service that has a unique service I.D. The SAM client also interfaces with the resource manager as discussed below to control resources of the DHCT .

Application clients can also be downloaded into DRAM at the request of the SAM client typically in response to a request by the user or in response to a message from the headend . In this example DRAM includes a Media On Demand application MOD an e mail application PVR application and a web browser application . It should be clear to one with ordinary skill in the art that these applications are not limiting and merely serve as examples for this present embodiment of the disclosure. Furthermore one or more DRAM based applications may be resident as an alternative embodiment in FLASH memory . These applications and others provided by the subscriber television system operator are top level software entities on the network for providing services to the user.

In one implementation applications executing on the DHCT work with the navigator by abiding by several guidelines. First an application utilizes the SAM client for the provision activation and suspension of services. Second an application shares DHCT resources with other applications and abides by the resource management policies of the SAM client the operating system and the DHCT . Third an application handles situations where resources are only available with navigator intervention. Fourth when an application loses service authorization while providing a service the application suspends the service via the SAM the navigator will reactivate an individual service application when it later becomes authorized . Finally an application client or application is designed to not have access to certain user input keys reserved by the navigator i.e. power channel volume etc. .

The MOD client application provides the user with lists of available media content titles for each media content instance to choose from and with media content instances requested by the user. The MOD client application provides media content instances to the user by engaging preferably in a direct two way IP Internet Protocol connection with VOD content servers not shown that would be located in one embodiment in the headend .

An executable program or algorithm corresponding to an Operating System OS component or to a client platform component or to an application client or to respective parts thereof can reside in and execute out of DRAM and or FLASH memory . Likewise data input into or output from any executable program can reside in DRAM or FLASH memory . Furthermore an executable program or algorithm corresponding to an operating system component or to a client platform component or to an application client or to respective parts thereof can reside in FLASH memory or in a local storage device such as storage device connected to DHCT and be transferred into DRAM for execution. Likewise data input for an executable program can reside in FLASH memory or a storage device and be transferred into DRAM for use by an executable program or algorithm. In addition data output by an executable program can be written into DRAM by an executable program or algorithm and be transferred into FLASH memory or into a storage device. In other embodiments the executable code is not transferred but instead functionality is effected by other mechanisms.

The DHCT includes at least one storage device to provide storage for downloaded media content. PVR application described in greater detail below in cooperation with the operating system and the device driver effects among other functions read and or write operations to the storage device . Herein references to write and or read operations to the storage device will be understood to mean operations to the medium or media of the storage device unless indicated otherwise. The device driver is a software module preferably resident in the operating system . The device driver under management of the operating system communicates with the storage device controller to provide the operating instructions for the storage device . As conventional device drivers and device controllers are well known to those of ordinary skill in the art further discussion of the detailed working of each will not be described further here. Storage device is preferably internal to DHCT coupled to a common bus through a communication interface preferably an Integrated Drive Electronics IDE or Small Computer System Interface SCSI although IEEE 1394 or USB among others can be used. Alternatively the storage device can be externally connected to and thus removable from the DHCT via a communication port implemented as IEEE 1394 or USB or as a data interface port such as a SCSI or an IDE interface. In one implementation under the auspices of the real time operating system executed by processor and in coordination with the PVR application client transmitted media content herein understood to also refer to other types of data in addition to or instead of media content instances are received in DHCT via communications interface and stored in a temporary cache not shown in memory . The temporary cache is implemented and managed to enable media content transfers from the temporary cache to storage device or in concert with the insertion of a newly arriving media content into the temporary cache. In one implementation the fast access time and high data transfer rate characteristics of the storage device enable media content to be read from the temporary cache in memory and written to storage device in a sufficiently fast manner. Orchestration of multiple simultaneous data transfer operations is effected so that while media content is being transferred from the cache in memory to storage device new media content is received and stored in the temporary cache of memory .

Processor in communication generally with device driver and storage device controller and demultiplexing system effect retrieval of compressed bitstreams compressed audio streams and data streams corresponding to one or more media content instances from storage device . Retrieved streams are deposited in an output cache in storage device and transferred to memory and then processed for playback according to mechanisms that would be understood by those having ordinary skill in the art. In some embodiments the media content instances are retrieved and routed from the hard disk to the digital video decoder and digital audio decoder simultaneously and then further processed for eventual presentation on a display device or other device.

Storage device can be an optical storage device or a magnetic storage device among others and is preferably a hard disk drive. Storage device comprises storage for media content that can be written to for storage and later read from for retrieval for presentation. The storage device preferably includes at least one hard disk and a controller which receives operating instructions from the device driver and implements those instructions to cause read and or write operations to the hard disk . The operating system in cooperation with the device driver communicates with the storage device controller to format the hard disk causing the hard disk to be divided radially into sectors and concentric circles called tracks .

The PVR application provides for media content recording functionality by enabling the temporary writing to and if requested more permanent recording to the storage device . Through mechanisms explained below media content received into the TSB will have a temporary recording designation. That is media content stored in clusters of the TSB will have a temporary residence. This receiving of media content into the TSB for temporary residence will also be referred to as buffering. The media content stored in the TSB will either be deleted i.e. its associated management file record will be deleted and the clusters storing the media content will be configured as writeable for eventual write operations that overwrite the media content within those dusters or retained through election by the user as a permanent recording. A permanent recording will be understood to mean media content that is stored for an extended period of time as decided by the user. Permanent recordings are stored in non buffer clusters i.e. not in clusters of the TSB that are not used for the TSB in instances when the user elects in advance to make a scheduled recording of a media content instance that has not yet been tuned to at the DHCT . A permanent recording can also be achieved by selecting a media content instance stored in the TSB and designating the media content instance as permanent. As will be described below this designation can occur in one implementation by selecting the desired content via a user interface screen. The PVR application responds by flagging the associated management file as permanent. This designation for the desired media content instance is relayed to the device driver and or operating system which effects the removal of the associated dusters from the TSB . Thus permanent recordings will preferably be more permanent than media content in the TSB and permanent recordings can eventually be deleted from the disk space typically at the explicit request of a user as one example. This deletion occurs in one implementation by configuring the associated non buffer dusters as writeable and thus eventually available for the TSB or scheduled recordings.

Media content may be transmitted or downloaded from a remote location such as for example a remote server located in the head end or from a home communication network or from other consumer electronic devices. In accordance with the preferred embodiment the PVR application manages buffer space or a Time Shift Buffer TSB of downloaded media content instances or programs content and or data at the application level for each tuner. Hence each tuner in tuner system has a respective TSB . Note that buffering is understood to mean temporarily receiving media content resulting either from reception of a broadcast digital channel or a digital compressed version of a broadcast analog channel and or data into the buffer space or TSB of the storage device . In one embodiment buffering for a digital compressed video program or media content instance results from a sourced video program instance and its associated audio signal that originated as an analog video signal received in DHCT as a broadcast TV program instance received via network communication interface . Such analog video signals are compressed into digital form by the encoder or other digitizing hardware or software in DHCT as explained above.

Having described various embodiments of VP system it should be appreciated that one VP method embodiment illustrated in can be broadly described receiving at the processing device the bitstream comprising a first Coded Video Sequence CVS having a first picture resolution and a second CVS having a second picture resolution where the first coded picture of the second CVS is the first coded picture in the bitstream after the last coded picture of the first CVS allocating by the processing device an amount of memory corresponding to a maximum number of frame buffers of a Decoded Picture Buffer DPB herein called MaxDpbSize such that the value of MaxDpbSize equals a first number and each of the first number frame buffers in the DPB corresponds to a maximum frame buffer size for storing a respective decoded picture having a maximum picture resolution sizing by the processing device each frame buffer of the DPB in units corresponding to a maximum coding block size determining by the processing device a first frame buffer size corresponding to the first picture resolution and determining by the processing device a second number for the value of MaxDpbSize according to the magnitude of the first frame buffer size in relation to the magnitude of the maximum frame buffer size determining by the processing device a second frame buffer size corresponding to the second picture resolution and determining by the processing device a third number for the value of MaxDpbSize according to the magnitude of the second frame buffer size in relation to the magnitude of the maximum frame buffer size and determining by the processing device a second frame buffer size corresponding to the second picture resolution and determining by the processing device a third number for the value of MaxDpbSize according to the magnitude of the second frame buffer size in relation to the magnitude of the maximum frame buffer size .

In another VP method embodiment illustrated in can be broadly described as receiving by a video receiving by a processing device a first portion of compressed pictures of a bitstream the first portion of compressed pictures corresponding to a first picture resolution the first portion of the compressed pictures comprising at least one picture compressed at a first encoding level determining by the processing device a first number of picture buffers in a Decodable Picture Buffer DPB for decoding the first portion of the compressed pictures receiving by the processing device a second portion of compressed pictures of the bitstream the second portion of compressed pictures corresponding to a second picture resolution the second portion of the compressed pictures comprising at least one picture compressed at the first encoding level determining a second number of picture decode buffers in the DPB for decoding the second portion of the compressed pictures wherein the second number of picture decode buffers are determined based on a ratio of picture sizes of pictures from the first portion and the second portion and mapping the first number of picture buffers in a memory allocated corresponding to the second number of picture buffers .

Any process descriptions or blocks in flow charts or flow diagrams should be understood as representing modules segments or portions of code which include one or more executable instructions for implementing specific logical functions or steps in the process and alternate implementations are included within the scope of the present disclosure in which functions may be executed out of order from that shown or discussed including substantially concurrently or in reverse order depending on the functionality involved as would be understood by those reasonably skilled in the art. In some embodiments steps of a process identified in using separate boxes can be combined. Further the various steps in the flow diagrams illustrated in conjunction with the present disclosure are not limited to the architectures described above in association with the description for the flow diagram as implemented in or by a particular module or logic nor are the steps limited to the example embodiments described in the specification and associated with the figures of the present disclosure. In some embodiments one or more steps may be added to the method described in either in the beginning end and or as intervening steps and that in some embodiments fewer steps may be implemented.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations merely set forth for a clear understanding of the principles of the VP systems and methods. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. Although all such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims the following claims are not necessarily limited to the particular embodiments set out in the description.

