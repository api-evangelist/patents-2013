---

title: Method, apparatus, and computer-readable medium for data tokenization
abstract: An apparatus, computer-readable medium, and computer-implemented method for data tokenization are disclosed. The method includes receiving, at a database network router, a database access request directed to a tokenized database, the tokenized database containing one or more tokenized data values, applying one or more rules to the request, rewriting the request based on at least one of the one or more rules, such that data values being added to the database will be tokenized data values, and data values received from the database will be non-tokenized data values, and transmitting the rewritten request to the database.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09336256&OS=09336256&RS=09336256
owner: Informatica LLC
number: 09336256
owner_city: Redwood City
owner_country: US
publication_date: 20130315
---
Large amounts of data are stored in databases such as enterprise databases. Much of this data includes confidential or otherwise sensitive information. As a result enterprises often utilize tokenization to hide the values of potentially sensitive data in their databases. This tokenization process can consist of replacing the data values in a database with token values. The token to data value relationship may be stored in a vault which may be encrypted to prevent unauthorized access and ensure that only permitted users may access the real values of the tokens in the database. Alternatively rather than storing the real data values in the token vault the token vault may be used to extract a real data value that is embedded in a token via a decryption process.

When an authorized user wishes to access the data in the database from an application that application has the responsibility of identifying the authorized user and replacing the tokens with the real values. Additionally if an authorized user wishes to add new data to the database the application has the responsibility of tokenizing the new data prior to adding it to the database. This places additional burdens on the application and requires the application to be in communication with the token vault as well as the database. For example if the user enters a data value to add to the database the application first has to tokenize the data value then add the token to data values relationship to the vault and then transmit the tokenized data value to the database.

As a result of being responsible for most of the tasks related to tokenization the application must be heavily customized in order to integrate the particular tokenization Application Programming Interface API used by each database provider and cannot be utilized with the APIs of other database providers or tokenization providers.

While methods apparatuses and computer readable media are described herein by way of examples and embodiments those skilled in the art recognize that methods apparatuses and computer readable media for data tokenization are not limited to the embodiments or drawings described. It should be understood that the drawings and description are not intended to be limited to the particular form disclosed. Rather the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the appended claims. Any headings used herein are for organizational purposes only and are not meant to limit the scope of the description or the claims. As used herein the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Applicants have discovered a system for moving the tokenization responsibilities out of the application and to an intermediary node that reduces required resources and simplifies implementation. This change would allow database providers to utilize any application with their tokenized database without having to customize the application to meet the needs of the particular tokenization API. Additionally the intermediary node could be utilized to serve multiple database providers with different tokenization technologies.

Referring to an exemplary apparatus for performing the above mentioned tasks and tokenizing data is shown according to a disclosed embodiment. The database network router DNR serves as the above mentioned intermediary node between the application and the tokenized database . The database communicates directly with token vault through the use of a DNR software agent running on the database which parses and executes commands received as part of database access requests from the DNR . Through the use of the DNR and the DNR software agent the application can be decoupled from the database and the burden of integrating tokenization APIs and performing tokenization or de tokenization functions can be shifted to the DNR and the DNR software agent . Additionally by removing the tokenization and de tokenization functions from the application multiple tokenization vendors or companies can utilize the DNR and a DNR software agent as the interface between their own databases and applications.

An example of how the DNR can be used with multiple databases is shown in . Applications A B and C may be executing on different client machines not shown and may be associated with three different tokenized databases A B and C. A DNR software agent running on each of the databases A B and C communicates with each of the respective token vaults A B and C. Of course a separate token vault is not required for each database. For example the databases B and C can use the same tokenization scheme and can share a single token vault.

The DNR can receive or intercept a request from application A and based on the application client machine user credentials request destination request contents or some other parameter determine that the request is associated with database A. The request can then be processed in accordance with the rules associated with database A as will be described below and forwarded on to the database A. At the database A the DNR Agent A may determine that some data value needs to be tokenized or some tokenized value needs to be de tokenized at which point it can communicate with the token vault A to perform the appropriate operation prior to returning any results to the DNR and eventually to the Application A.

With reference to a method of handling database access requests by the DNR of a disclosed embodiment will now be described. At step the DNR receives a database access request from an application. The request can be directed to a target database and re routed to the DNR or the request can be intercepted by the DNR. Alternatively the request can be sent to the DNR but specify a destination database. Many variations are possible for receiving the database access request at the DNR.

The database access request can include any type of request including a data retrieval request a data update request a data insert request a data delete request or other similar database access requests. Additionally the language of the request can include any type of database query language including Structured Query Language SQL Contextual Query Language CQL XQuery YQL Datalog OQL RDQL and many others.

At step the DNR can apply one or more rules to the request. These rules will be discussed in greater detail below but can include rules relating to the proper handling of different types of database access requests request routing tokenization rules and the like. After applying the rules the request can be rewritten at step based on at least one of the one or more of the rules. For example the request can be rewritten to add one or more commands to the database access request which will be parsed and executed by the DNR agent running on the database. Additionally one or more parameters can be passed to the DNR agent with the commands to instruct the DNR agent on how to handle the data that is passed with the commands. For example parameters can specify specific tokenization schemes to use authorization of a particular user or machine whether the command should be ignored or whether false values should be returned.

After the request is rewritten using one or more rules the rewritten request can be transmitted to the destination database at step . The actual transmission of the rewritten request can also be based on one or more rules. For example the destination database may be a distributed database striped across a plurality of repositories. The DNR may apply a rule to the database access request or its contents to determine which one of the repositories the request should be forwarded to. Similarly if the DNR is routing requests for multiple different databases with different tokenization schemes the DNR may need to apply rules to determine the correct database to send the rewritten request to. Alternatively if the DNR intercepts a request that already specifies a destination database the DNR can simply transmit the rewritten request to that destination database.

For example filter terms may include non tokenized data that requires tokenization after it is passed to the DNR agent executing on the database. However the tokenization API may specify that a new token should not be created for data values that are passed as filter data values but rather that the token value if one exists should be looked up in a token vault. As discussed further below the filter terms rules can be used to insert a parameter into a tokenization command that lets the DNR agent know that it should tokenize a passed value but that it should not create a new token in the process.

Tokenization API rules relate to the different rules that are used for retrieving data from or sending data to tokenized databases having a variety of tokenization schemes. For example a first request may be directed to a first database that uses a first tokenization algorithm to tokenize all data values stored therein and a second request may be directed to a second database that uses a second tokenization algorithm to tokenize only sensitive data stored therein. So for example if the DNR receives a data retrieval request directed to the second database it can consult the associated tokenization API rules for that database and determine whether or not the requested data is stored in token format. If it is then the DNR can insert a de tokenize command into the request and if it is not then the de tokenize command is unnecessary.

Tokenization API rules can specify what types of data or data fields should be tokenized. For example one tokenization API may specify that all data should be tokenized while another tokenization API may specify that only data fields that contain personal or confidential information should be tokenized.

Incomplete request rules will also be discussed in greater detail below and can be applied when the DNR receives a request that is missing specific fields or any other necessary information.

Authorization rules and security rules can be used to determine whether the user machine or session associated with the user has sufficient credentials to carry out the request as well as to specify what actions to take in different situations where the user does not have sufficient credentials. For example in a consumer transactions database security rules may state that only each consumer should be able to view their own credit card information in de tokenized format. If a system administrator requests a list of transactions with all related fields security rules may be utilized to return the fields which are not protected in de tokenized format and return the associated credit card numbers in token format. Alternatively the security rules can be utilized to instruct the database to return fake or fictive numbers for each credit card number. Fictive values can be generated using some algorithm or can be selected from a pool of fictive values. Authorization rules may be used to implement different levels of access for different types of users. For example only an administrator may have the requisite permissions to update insert or delete records in the database while all other users may have permission only to run queries.

Finally as discussed earlier routing rules may be utilized to determine where to forward requests. Routing rules can be as simple as a rule that records the destination database address of an intercepted requested and forwards the re written request to that address.

Although all the rules are discussed in the framework of the DNR it is understood that some or all of the functionality of the rules can be implemented by the DNR software agent running on the database. For example if a user is not authorized to make a request that assessment may be made at the DNR which can insert a not authorized token or message into the rewritten request which is sent to the database. At the database the DNR software agent can read the not authorized token and determine that no action should be taken in response to the request. Additionally as will be understood by one of ordinary skill in the art not all of these rules are required to carry out the method of data tokenization disclosed herein.

Sample database also includes a DNR software agent which implements the commands that are parsed from rewritten requests received via the DNR . The DNR agent executing on sample database is in communication with sample token vault which contains the data values corresponding to the token values in the sample tokenized database .

The DNR receives database access requests from one or more applications and after processing rewriting the requests forwards the relevant rewritten requests to sample tokenized database . Of course DNR can be in communication with multiple tokenized databases not shown and multiple applications at one time and limited components are shown for illustration and clarity only.

The DNR enables a user not shown who is using application to enter and transmit a database access request directed to the sample tokenized database without the application being responsible for the tokenization or de tokenization. The user can enter database requests the way they ordinarily would be entered and the application can forward them to the DNR which handles all tokenization and de tokenization related processing.

The operation of different types of requests and specific examples of each request will now be described with reference to table XYZ in sample tokenized database and sample token vault . Although the language in the examples conforms to SQL it is provided for illustration only and any query language can be utilized.

If the DNR receives a data retrieval request directed to sample tokenized database it first loads the appropriate rule set for data retrieval requests. After loading the appropriate rule set it evaluates the data retrieval request and re writes it so that after it is sent to the sample tokenized database the values to be retrieved are returned in de tokenized form.

If this query were run on table XYZ in the sample tokenized database without modification the result set that would be returned would be 

Of course this is not the information that the user presumably wants to retrieve with such a query. When the DNR receives this query the appropriate rule set is used to rewrite the query to 

The deToken function indicates to the DNR agent executing on the sample tokenized database to de tokenized the retrieved values before transmitting the result set back to the DNR . So using the example of the re written query the sample database will execute the re written query to retrieve the token values in the Name column and the DNR agent will transmit those token values to the sample token vault to retrieve the actual values which will then be passed back to the DNR .

Although the deToken function is shown taking only one parameter this is only for the sake of clarity. The deToken function can take multiple parameters. For example the deToken function can take a parameter including the DNR origin signature for verification so that the DNR agent cannot be accessed directly. The function can take a parameter relating to a particular tokenization scheme that is being used or include a parameter with information relating to a particular user session such as a user session identification stamp. The function can also include security data relating to what type of values should be returned as is discussed in greater detail with regard to fictive values.

So the result set that will be transmitted back to the user at application when the query passes through DNR and is re written prior to being sent to sample tokenized database will be as follows 

The deToken function can be selectively applied based on security or permissions considerations and can pass one or more additional variables to the sample database . These variations will be discussed with reference to the security and fictive values features further below.

If the DNR receives a data update request directed to sample tokenized database it first loads the appropriate rule set for data update requests. After loading the appropriate rule set it evaluates the data update request and re writes it so that after it is sent to the sample tokenized database the values to be added to the tokenized database are in token format and the appropriate token to data relationships are stored in the sample token vault.

The Tokenize function can indicate to the DNR agent executing on the sample tokenized database to create a token value for the update data. Although the Tokenize function is shown taking only one parameter this is only for the sake of clarity. The Tokenize function can take multiple parameters. For example the Tokenize function can take a parameter including the DNR origin signature for verification so that the DNR agent cannot be accessed directly. The function can take a parameter relating to a particular tokenization scheme to be used or include a parameter with information relating to a particular user session such as a user session identification stamp. The function can also include security data relating to what type of values should be returned as is discussed in greater detail with regard to fictive values.

When the DNR agent receives the Tokenize function it can create a new token for the data value passed in the function if one does not already exist. Additionally the DNR agent can then update the relevant portions of table XYZ with the tokenized data value according to the update request specifications and send the token to data value relationship to the sample token vault for storage. Of course in practice many update commands will include a where clause to indicate which portions to update. These will be discussed in greater detail with respect to filter values. The Tokenize function can optionally also include a parameter that indicates to the DNR agent whether the token value generated from the data value should be added to the token vault.

Referring now to the sample token vault is shown at two times at time T 0 before receiving the update request and at time T 1 after receiving the update request. Additionally table XYZ is also shown at the two times T 0 and T 1 .

Using the example of the specific update request discussed above the changes to both the table XYZ and the token vault will be discussed. Since the update request included a data value which does not already have a corresponding token the new SSN number 421 66 4567 a new token value needs to be generated for the value. The DNR agent generates the new token T5 using the appropriate tokenization rule. The tokenization rule can be pre loaded onto the DNR agent during installation or received at some point after from the token vault database or other appropriate source.

After generating the token T5 corresponding to the new number 421 66 4567 the new token and associated data value are stored in the sample token vault . Additionally all of the SSNs for each of the records in table XYZ are updated with the new token T5. As discussed above this is because the update request did not include a where limitation.

Similar to the deToken function the Tokenize function can be selectively applied based on security or permissions considerations or can pass one or more additional variables to the sample database. These variations will be discussed with reference to the security and fictive values features further below.

Insert data requests are handled similarly to update data requests in that the Tokenize function is utilized for the new data. So for example if a user wanted to add a record to table XYZ the record including the social security name of a person with the name Jackson the insert request could be written as follows 

After this request is intercepted by the DNR and re written to include the Tokenize command it can be sent to the sample tokenized database as INSERT INTO TABLE XYZ VALUES Tokenize Jackson Tokenize 162 97 2441 

This will alert the DNR agent running on the sample tokenized database to create new token values for each of the new data values and update the database and token vault accordingly.

Referring to the result of the insert command listed above is shown. Table XYZ at time T 0 represents the table prior to the insert data request being sent to the database and table XYZ at time T 1 represents the table after the insert data request is sent. Similarly token vault at time T 0 shows the token vault prior to the insert data request being sent to the database and token vault at time T 1 shows the token vault after the insert data request is received at the database. Table XYZ at time T 1 and sample token vault at time T 1 show the addition of two new tokens T5 and T6. These two new tokens correspond to the new data values Jackson and 162 97 2441.

Many requests may include filter terms. That is terms which reduce or filter the scope and size of the data set to which the request applies. Using the earlier example of table XYZ in a user may have the last name of someone and be interested in retrieving their Social Security Number but not the SSN s of every person in the table. If the person whose SSN they are looking for has the name Miller they would normally transmit the following query to the database to retrieve the SSN of Miller 

Of course if this query were transmitted as is to the tokenized table XYZ in the tokenized database the name Miller would not be found and it would return no results since this query is intended for a non tokenized database. In order to be compatible with the tokenized database the query would be re written by the DNR as 

The first change to the request is in the insertion of the deToken function as is discussed above with regard to data retrieval requests. The second change to the request is the insertion of the Tokenize function for the filter data value Miller . This alerts the DNR agent running on the database to look up the token value corresponding to Miller and then use that token value as a filter when selecting SSNs.

In this case the token value corresponding to Miller is T1 so the query will result in the selection of the tokenized SSN corresponding to T1 which is T3. The DNR agent will then apply the deToken function to T3 to generate the SSN 045 22 1246 which is returned to the user.

Optionally the Tokenize function may pass a parameter which indicates whether it associated with an insert data value update data value or a filter data value. This may useful to the DNR agent in determining whether a new token is required to be generated for the data value. For example when the Tokenize function is used with an insert data value or update data value the DNR agent may check the token vault to see if a token value exists for the data value and generate a new token value if one does not exist. When the Tokenize function is used with a filter data value the DNR agent may determine that a new token does not need to be generated as the filter data values are used to filter a selected set of data values and are not added to the data tables. In this situation the DNR agent can just look up the appropriate token value corresponding to the filter data value in the token vault and if a token value does not already exist the DNR agent can correctly determine that no records correspond to that filter data value since a token would have had to have been created for the data value if it was inserted or added to the table earlier. Alternatively the Tokenize function can be used to create token values for all passed data values that do not already have an associated token value.

In addition to being used with data retrieval commands filters can be utilized with updates to the data values stored in the database. For example referring to table XYZ in a user may wish to update the SSN associated with the name Sanchez. To do so they could transmit the request 

If the database was not tokenized this would change the SSN associated with the name Sanchez to 123 45 6789. However since the database is tokenized the request must be re written by the DNR as 

The rewritten request instructs the DNR agent to make a new token for the new data value to be added to the database and to add the token value where the name is equal to the token value T2. As before the token value corresponding to the name Sanchez is determined by the DNR applying the same tokenization rules as are used by the DNR Agent.

The DNR may handle and re write additional types of database access requests that are not specifically enumerated here. For example the user can submit a delete request for a specific data record. Of course when deleting a record no tokenization or de tokenization is required but the DNR can optionally pass the data by re writing the request to add a removeToken function which tells the DNR agent to remove not only the record but the token to data relationship from the token vault. Additional types of requests and parameters that can be adapted by the DNR to a tokenized database can include for example select distinct and order by modifiers.

The DNR may have one or more rules for dealing with incomplete requests. Referring to the DNR may receive a database access request at step and assess whether the request is an incomplete request at step . Incomplete requests can be classified as requests which are determined by one or more rules to be lacking necessary information. Using the earlier example of Table XYZ in the request may be 

In this example the asterisk or star operator is used to indicate that the user wants to select all possible fields in Table XYZ. However in order to properly utilize the deToken function the list of actual column names may be required. Therefore the DNR may determine at step that the request is incomplete and proceed to step where it sends out a request for the missing data. The request can be sent to the database the DNR agent on the database or some other repository which tracks the column names. Additionally the missing information may also be stored in some memory on the DNR itself.

So in the above example the DNR will request a list of all columns that appear in Table XYZ at step . This would result in the column identifiers for Name and SSN being received at the DNR. At step the DNR verifies that there is not any additional missing information and if so proceeds to step . If there is still missing information then the DNR can send another request to the same or a different source for the missing information.

At step the DNR proceeds to re write the database access request not only according to the request based rules but also to incorporate the missing information that has been retrieved. So in the above example the request can first be re written as 

This ensures that the data values in table XYZ and not the token values are returned to the user. After the query is re written it is sent to the database at step .

Referring to a DNR security process for preventing unauthorized access to a database will now be described. The process may be implemented as one or more security rules that are applied at the DNR as discussed earlier. After the request is receive at step the DNR determines whether the user is authorized to make the request at step . This can include determining whether the user is authorized to make any requests such as checking for an unauthorized system user as well as checking whether the user is authorized to make a particular kind of request such as an update request. So for example a user who has read only privileges may be authorized to make a select request but not an update request. In other situations the user may be determined to be lacking authorization to access the database in any way.

If the user does not have authorization to make the request at step a security action may be performed by the DNR. The security action can be selected from a variety of possible security actions. For example the DNR may rewrite the request to set a flag which tells the database to disregard the request if it is an update or insert or to return fictive values if it is a select request. For example the Tokenize function can be configured to pass multiple variables one of them being a fictive values flag such as Tokenize value fictive value . So if the user is not authorized to make updates and has entered an update request such as 

This will inform the DNR agent that the values in the Tokenize function are fictive and that the update should be ignored. Similarly if the request is a select request the deToken function can pass a fictive values flag. So if a user is unauthorized and has entered a select request such as 

This would alert the DNR that fictive values should be returned in response to the select request rather than the real de tokenized values. This can be accomplished in many ways. For example a random number generator can use the token value as a seed to generate a fictive value to the return to the user. The fictive value flags in the deToken or Tokenize functions can default to false but can be changed to true when an unauthorized user is detected.

In addition to having a fictive values flag in the Tokenize and deToken functions a fictive value function can be utilized to pass the data values. For example rather than a deToken function being used to pass the data value a returnFictiveValue function can be used to tell the DNR agent to return a fictive value in response to the data request.

Furthermore fictive values are not the only way of dealing with unauthorized users or requests. The deToken function can include a flag which tells the DNR agent to return an empty or NULL value when a user is unauthorized or to return a token value instead of a de tokenized value. Additionally the DNR can utilize the security rules to block an update insert or select request when the user is unauthorized. Many variations are possible.

If the user does have authorization to make the request at step the DNR determines whether there are any protected data fields in the request. For example a table in a database may contain several data fields and one or more of them may be restricted to only a subset of the users that have access to the database or the table. So in the previous example of table XYZ the field Name can be a regular data field accessible to all users whereas the data field SSN can be restricted a subset of users such as administrators. Different authorization levels may be utilized with different types of data fields and the number of authorization levels is not limited to two but may include many tiers of authorizations and associated data fields in a database.

If there are no protected data fields then at step the request is processed as it normally would be for an authorized user. If there are protected data fields then at step the DNR examines user authorization levels for each protected data field and determines whether the user has authorization to access that data field in the way that is specified by the request. This may be accomplished by comparing the permissions authorizations of the user with the permissions authorization required to perform the function indicated by the request on the protected data field. For example a protected data field may have a requirement that in order to view any of the data the user must have level 5 authorization. If a requesting user has lower than level 5 authorization then they will be determined to lack authorization for the request on the protected data field. Similarly the same protected data field may have a requirement that in order to edit any of the data the user must have level 7 authorization. In that situation even a level 5 user who had view access would not be able to successfully change the data in the protected data field. So using the earlier example of table XYZ a request that stated SELECT SSN FROM Table XYZ may be permitted whereas a request of UPDATE Table XYZ SET SSN 123 45 6789 by the same user may be unauthorized. Of course authorization does not have to be organized in levels. For example authorization can be organized according to a user role condition or any other basis for distinguishing between an authorized access and an unauthorized access.

If the user is deemed to not have authorization to access a particular protected data field then the DNR can perform a security action for that protected data field at step . This security action may be similar to the security actions described at step including the fictive values flags but can apply specifically to the protected data fields that the user is not authorized to access. So in the example of table XYZ if a user has authorization to access the Name field but not the SSN field and submits the request 

This re written request tells the DNR that the deToken function for the Name field should not return fictive values but the actual de tokenized Name values and the deToken function for the SSN field should return fictive values. Additionally as stated earlier the security action for the unauthorized data field can also include return NULL values for that field returning token values instead of deTokenized values or blocking that portion of the request.

At step the DNR determines whether there are additional protected data fields and if so returns to step for additional determinations and processing. If there are no further protected data values then the processing of the remainder of the request continues as normal at step .

As used in the security process described above authorization can refer to many different types of security credentials and authorization schemes. For example authorization may be based on certain machine identifiers and not specific users authorizations may be based on the network information of the machine from which the request is received authorization schemes such as different levels of permissions or privileges may be used as well as security tokens certificates or other forms of authentication or authorization. Additionally although the fictive value flag is discussed as being set to false as the default the flag may be set to true as the default e.g. the default value may assume an unauthorized user or request and may be modified to false when the request authorization is confirmed. Many variations are possible and the security rules are not limited to the specific examples of authentication and authorization disclosed herein.

In addition to receiving and passing data values to the database the DNR can also receive and pass security tokens or credentials to the database. The DNR may receive a security token with the request from the application. The security token can be a credential such as a password or a certificate or some other data which allows the DNR to verify the user and verify that the user is authorized.

The DNR can authenticate or otherwise verify the security token or credential prior to re writing and send the request to the database. If the security token is valid the DNR can utilize flags similar to the fictive value flags discussed earlier to indicate to the DNR agent that the request is secure and authorized. For example the Tokenize or deToken function may pass two parameters one being the data value and the other indicting the validity of the security token such as Tokenize data value valid security credential .

This security token flag can also be passed in addition to the fictive value flag in some situations. For example if the security token associated with a user is valid but the user has inadequate permissions to access a particular data field then two flags can be passed in addition to the data value in a Tokenize or deToken function.

The security flag can be used by the database or the DNR agent executing on the database to determine how to handle the request. For example if a deToken function is received with the security flag set to false then the de tokenization step may be omitted resulting in token values being returned to the user. Similarly if a Tokenize function is received with the security flag set to false then the DNR agent can ignore the function instead of tokenizing the data value passed with it. So a deToken function such as deToken Name fictive value valid security credential can return fictive values for Name if the security credentials are valid but the user does not have adequate permissions to retrieve Names and not return any values if the security credentials are invalid.

Additionally the security token credentials received at the DNR can be passed to the DNR agent as an argument in one of the functions. In this scenario an assessment of the validity of the security tokens credentials can be made directly at the DNR agent rather than at the DNR.

One or more of the above described techniques can be implemented in or involve one or more computer systems. illustrates a generalized example of a computing environment . The computing environment is not intended to suggest any limitation as to scope of use or functionality of a described embodiment.

With reference to the computing environment includes at least one processing unit and memory . The processing unit executes computer executable instructions and may be a real or a virtual processor. In a multi processing system multiple processing units execute computer executable instructions to increase processing power. The memory may be volatile memory e.g. registers cache RAM non volatile memory e.g. ROM EEPROM flash memory etc. or some combination of the two. The memory may store software implementing described techniques.

A computing environment may have additional features. For example the computing environment includes storage one or more input devices one or more output devices and one or more communication connections . An interconnection mechanism such as a bus controller or network interconnects the components of the computing environment . Typically operating system software or firmware not shown provides an operating environment for other software executing in the computing environment and coordinates activities of the components of the computing environment .

The storage may be removable or non removable and includes magnetic disks magnetic tapes or cassettes CD ROMs CD RWs DVDs or any other medium which can be used to store information and which can be accessed within the computing environment . The storage may store instructions for the software .

The input device s may be a touch input device such as a keyboard mouse pen trackball touch screen or game controller a voice input device a scanning device a digital camera remote control or another device that provides input to the computing environment . The output device s may be a display television monitor printer speaker or another device that provides output from the computing environment .

The communication connection s enable communication over a communication medium to another computing entity. The communication medium conveys information such as computer executable instructions audio or video information or other data in a modulated data signal. A modulated data signal is a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired or wireless techniques implemented with an electrical optical RF infrared acoustic or other carrier.

Implementations can be described in the general context of computer readable media. Computer readable media are any available media that can be accessed within a computing environment. By way of example and not limitation within the computing environment computer readable media include memory storage communication media and combinations of any of the above.

Of course illustrates computing environment display device and input device as separate devices for ease of identification only. Computing environment display device and input device may be separate devices e.g. a personal computer connected by wires to a monitor and mouse may be integrated in a single device e.g. a mobile device with a touch display such as a smartphone or a tablet or any combination of devices e.g. a computing device operatively coupled to a touch screen display device a plurality of computing devices attached to a single display device and input device etc. . Computing environment may be a set top box personal computer or one or more servers for example a farm of networked servers a clustered server environment or a cloud network of computing devices.

Having described and illustrated the principles of our invention with reference to the described embodiment it will be recognized that the described embodiment can be modified in arrangement and detail without departing from such principles. It should be understood that the programs processes or methods described herein are not related or limited to any particular type of computing environment unless indicated otherwise. Various types of general purpose or specialized computing environments may be used with or perform operations in accordance with the teachings described herein. Elements of the described embodiment shown in software may be implemented in hardware and vice versa.

In view of the many possible embodiments to which the principles of our invention may be applied we claim as our invention all such embodiments as may come within the scope and spirit of the following claims and equivalents thereto.

