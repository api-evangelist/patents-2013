---

title: Augmented reality presentation
abstract: Described are methods and systems of providing an augmented experience on a user device to facilitate user interaction with one or more virtual items. An augmented image comprising an actual object and a virtual item is generated and presented in a user interface. The user interface allows the user to lock a relative position of the virtual item as presented, such that the user may appear to “move” the virtual item. The user interface may also provide sizing information of the virtual item relative item to the actual object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09165318&OS=09165318&RS=09165318
owner: Amazon Technologies, Inc.
number: 09165318
owner_city: Reno
owner_country: US
publication_date: 20130529
---
A wide variety of physical items are available for acquisition through various online merchants. Some of these items are available in several different sizes. For example hand tools may be sized for a particular grip rings for a particular size finger bracelets for a wrist hats for a head a shoe for a foot and so forth.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

As mentioned above a wide variety of physical items are available for acquisition through various online merchants. These items may be available in different sizes. For example hand tools may be sized for a particular grip rings for a particular size finger bracelets for different sizes of wrists hats for different head sizes shoes for different foot sizes and so forth. Traditionally customers use an actual item or a proxy item such as a ring sizing tool to test the fit. Furthermore many users may have difficulty judging the appearance of the item as worn or used without the actual item. Providing the actual item or the proxy item to the user imposes logistical issues particularly in the case of an online merchant. In the traditional situation the user is shipped an actual item for sale and returns the actual item if the fit or appearance is unsatisfactory. This increases shipping costs delays and may result in an unsatisfying user experience. Instead of or in addition to shipping the actual item a storefront may be maintained to provide access to samples of the actual items. However maintaining the storefront imposes logistical issues and corresponding costs as well.

This disclosure describes techniques and devices configured to facilitate presentation to a user of virtual items representative of actual items. A user device presents on a display an augmented image that includes an image of an actual object and a generated image of a virtual item. The generated image of the virtual item is based on information gathered from the actual item. In one implementation the actual object may be the user s hand while the virtual item may be an ornamental finger ring ring . These techniques may be applied to other actual objects and virtual items. For example the actual object may be a window pet appliance alcove or recess and so forth while the virtual item may be a window covering pet accessory appliance and so forth.

In some situations bandwidth may be limited between the user device and a server storing details about the virtual item. To facilitate low latency generation of the image of the virtual item distributed item data may be sent to the user device. The distributed item data includes common data and compact data. The common data such as information about materials texture map data and so forth may be preloaded or previously stored on the user device. For example the common data may include information which is indicative of the visual characteristics of gold platinum silver diamonds garnet ruby various cuts or geometries of gemstones and so forth. The common data may be transferred when a higher bandwidth connection is available such as a Wi Fi connection as compared to a wireless wide area network WWAN such as 3G or 4G using a Universal Serial Bus USB connection when coupled to a host device and so forth.

The user device may request the compact data from a server or another device. The compact data contains one or more references to at least a portion of the common data which has been previously stored on the user device. For example the compact data referring to an actual item made of gold would include a reference to the gold in the common data rather than including the descriptive data for gold. The user device generates the image of the virtual item using compact data received from a server in conjunction with the common data. By using the compact data details for a wide variety of virtual items may be quickly transferred to the user device. Continuing the example the compact data transferred to the user device may comprise references to circular ring elliptical shank cross section shank made of gold smooth finish no setting . Rather than transferring a large file containing three dimensional point data representative of the actual item a relatively smaller piece of compact data containing references to the common data is transferred. This significantly reduces the time required to transfer to the user device allowing the user to quickly browse through and see information on many different virtual items.

Furthermore use of the common data and the compact data reduces overall storage requirements on the user device for large numbers of different virtual items. For example as the user starts to browse a variety of different wedding rings compact data describing several hundreds or thousands of wedding rings may be quickly downloaded and stored. The compact data in combination with the common data may then be used to generate the image of the virtual item for presentation in a user interface.

The user interface may present the augmented image and provide for user controls that allow for manipulation of the virtual item. The user interface may present an initial pose or orientation of the actual object such as a silhouette of a hand in a particular orientation for the user to mimic. Use of this initial pose may impose boundaries as to possible positions minimizing processing resources used in determining the pose of the actual object generating the virtual image and so forth.

The user interface may be configured such that the image of the virtual item tracks or follows at least a portion of the actual object in the augmented image. For example the image of the virtual item representative of the ring may follow the user s hand movements such that the image of the virtual item appears to remain positioned on the proximal phalanx bone of a left hand ring finger.

The user may wish to change apparent placement of the virtual item on the image of the actual object. Continuing the example the user may wish to move the image of the virtual item representative of the ring to the intermediate phalanx bone of the left hand ring finger. In some implementations the user may activate a lock control which in turn initiates a position lock function. In one implementation the lock control may be a specified position at a left side a right side or a left and right side of the touch sensor which is accessible by the user s left thumb or right thumb respectively. For example while the user s thumb activates the lock control the virtual item remains in a fixed location within the augmented image while the actual object such as the user s hand may be moved around to reposition the apparent location of the virtual item with respect to the user s hand.

The user interface may also be configured to provide feedback to the user about the fit of the virtual item with regard to the actual object. This feedback may be provided based on information about the physical measurements of the actual object as well as the physical measurements of the actual item represented by the virtual item. In one implementation the user device may be configured with a three dimensional sensor configured to acquire three dimensional data about the actual object. This data may be used to determine the physical measurements of the actual object such as a portion of the user s finger and indicate whether a virtual item having a particular size such as a ring will fit.

By providing these functions with the user interface the user experience in acquiring actual items is improved. The user is readily able to see the augmented image showing the actual object and the virtual item readily manipulate the virtual item and determine where and whether the virtual item will fit. Once satisfied the user may place an order for delivery of the actual item.

Physically close or proximate to the actual object is a user device . The user device may comprise a tablet computer personal computer electronic book eBook reader television in vehicle entertainment system gaming console smartphone wearable computing device and so forth.

The user device may include a display device or display . The display is configured to present images to a user. A camera may be configured to acquire image data of the actual object . A three dimensional 3D sensor is configured to acquire 3D data about one or more objects in a sensor field of view such as the actual object . For example the 3D data may be descriptive of the user s hand. The 3D data may comprise a depth map point cloud vector mapping and so forth.

The user device may include a touch sensor or other input device such as a button keypad joystick and so forth. In some implementations the display and the touch sensor may be combined into a touchscreen.

A user interface module is configured to provide a user interface on the user device . This user interface may comprise a graphical user interface such as depicted here. The user interface module is configured to process inputs such as those made to the touch sensor and provide corresponding outputs to the user such as on the display . For example the user interface may present images of several rings available for purchase. The user interface module may present controls various information such as information about sizing pricing customer reviews purchase controls and so forth.

An augmented image generation module is configured to access distributed item data and generate an augmented image including images of one or more virtual items combined with an image of the actual object . The distributed item data comprises information indicative of or descriptive of virtual items . The virtual items are based on actual items. For example the virtual item may comprise a representation of a ring while the actual item is the ring. The actual item may also include a wrist bracelet an ankle bracelet a watchband an armlet a toe ring a hand tool a hat and so forth. The distributed item data is discussed in more detail below with regard to .

The augmented image may appear to be a composite of the image of the actual object and image of the virtual item . The augmented image generation module may be configured to track motion of the actual object and maintain the image of the virtual item in a consistent relative position. For example the image of the virtual item representative of a ring may follow the user s hand movements such that the image of the virtual item appears to remain positioned on the proximal phalanx bone of a left hand ring finger of the user. This tracking may include maintaining relative orientation. The augmented image generation module may be configured such that as the user rotates or otherwise changes the orientation of the actual object the orientation of the virtual item changes. For example where the actual object comprises a hand as the hand is turned over such that the palm faces the camera the underside of the ring shank may be visible rather than a setting of the ring.

The tracking may be set to snap the position of the virtual item to the image of the actual object within a threshold value. The threshold value may be fixed or dynamically adjustable. For example the threshold value may be fixed at 5 millimeters mm such that when the relative position of the virtual item is brought to within 5 mm of the actual object the virtual item begins tracking with the actual object . The threshold value may be expressed as a linear function exponential function logarithmic function and so forth.

The augmented image generation module may work in conjunction with the user interface module . For example data received from touches on the touch sensor may be provided to the augmented image generation module to modify the augmented image .

The user interface module may provide the user interface with a lock control . The user may wish to change apparent placement of the virtual item with respect to the image of the actual object . For example the user may wish to move the image of the virtual item representative of the ring from one position on a finger to another. The lock control is configured to initiate a position lock function. When the position lock function is active the virtual item remains in a fixed location within the augmented image while the actual object may be moved relative to the virtual item . Said another way when the position lock function is engaged the position of the virtual item on the display may remain relatively constant. In some implementations while the position is fixed the orientation may change. For example as a user rotates their hand the virtual item may also rotate.

In some implementations the position lock control may be positioned in the user interface to be actuated by a thumb of the user. For example the position lock control may be positioned at a left side a right side or a left and right side of the touch sensor that is accessible by the user s left thumb or right thumb respectively. In this arrangement the user may readily use one hand to manipulate or be the actual object while the other hand is able to activate the position lock control as desired. The positioning of elements in the user interface may be based at least in part on an orientation of the actual object . For example when a left hand appears in the image data the position lock control may be positioned on the right side of the user interface . Likewise the user interface may be mirrored and flipped horizontally such that when a right hand appears in the image data the position lock control may be positioned on the left side of the user interface . The user device may be configured to couple to one or more networks . The network may comprise a public network private network local area network wide area network and so forth. For example the user device may be configured to couple to a 3G WWAN which in turn provides access to the Internet.

The user device may use the network to communicate with one or more servers such as the item server . The item server is configured to maintain information about one or more of the virtual items . For example the item server may provide a catalog of virtual items available from an online merchant. The item server provides an item data module . The item data module may be configured to respond to requests for information about the virtual items and provide distributed item data or a portion thereof to the user device . The item data module may also be configured to process 3D data about the actual item. The item data module may use the 3D data to generate the distributed item data which is representative of the virtual item . For example a device having a 3D sensor may send the 3D data of the actual item to the item server . In another implementation the 3D data may be based on computer aided design CAD data manufacturing specifications and so forth. For example the 3D data may be derived from 3D CAD files and a bill of materials indicating the composition of the various components. The item data module may use this 3D data to generate the distributed item data . The distributed item data is discussed in more detail below with regard to .

The item server may send the distributed item data to the user device using the network . The augmented image generation module of the user device then generates the augmented image including the image of the virtual item .

The distributed item data may comprise common data and compact data . The common data comprises information that may be applicable to a plurality of different virtual items . As shown in this figure by way of illustration and not as a limitation where the virtual items are rings the common data may include information about those rings. Ornamental rings worn as jewelry include several components including the shank setting gallery and so forth. The shank is the portion of the ring that wraps around at least a portion of the user s finger when worn and may also be known as a band. The setting is the portion of the ring other than the band usually having some sort of stone or detailed ornamental portion. The gallery supports the setting typically acting as a bridge or structure between the shank and the setting.

The material data includes a material identifier . The material identifier may comprise a number or string that uniquely identifies a particular grouping of material data associated with a particular material. The material data may include one or more of material appearance material characteristics and so forth. The material appearance provides information as to visual characteristics of the material such as color luster reflectivity internal reflectance and so forth. The material characteristics may include elastic modulus thermal conductivity density and so forth. Other characteristics about the material may also be provided. The material data may describe metals alloys wood minerals plastics ceramics and so forth. For example the material data may describe a particular type of gold a particular precious stone or a type of leather.

The texture map data includes a texture map identifier . The texture map identifier may comprise a number or string that uniquely identifies a particular grouping of texture map data associated with a particular texture map. The texture map data may include texture data such as a bitmap raster image color surface contour pattern and so forth. In some implementations the texture map data may include information associated with tactile presentation such as surface roughness or texture resiliency and so forth. For example where the user device includes a haptic output device a texture of the virtual item may be presented for the user to feel.

The setting data includes a setting identifier . The setting identifier may comprise a number or string that uniquely identifies a particular grouping of setting data . The setting data may include one or more of a stone material identifier a stone cut gallery geometry gallery texture gallery material identifier and so forth. The stone material identifier provides information on a stone or other central feature in particular the material of the stone. The stone material identifier may refer to the material data described above. The stone cut may refer to data indicative of the cut or geometry of the stone such as point cut table cut Mazarin cut Old European Cut polished ellipsoid and so forth. As above in some implementation the stone cut may comprise an identifier configured to refer to a table or other data structure containing predetermined information about various stone geometries. The gallery geometry similarly characterizes the structure of the gallery if any. The gallery texture is descriptive of the ring s gallery and may refer to the texture map data . The gallery material identifier is descriptive of the material from which the gallery of the ring is made and may refer to the material data .

The compact data is configured to refer at least in part to the common data described above. By referring to the common data the overall size of the compact data is significantly reduced compared to repeating or encoding the information sufficient to render the virtual item on the user device .

The compact data may comprise one or more physical measurements . These physical measurements may include specific dimensions of one or more of a shank radius shank inner diameter shank outer diameter shank thickness setting size and so forth. For example the physical measurements may designate the shank inner diameter as 17 mm. In some implementations the physical measurements may be provided with a bilateral tolerance value such as plus or minus 0.5 mm.

The compact data may include a shank cross section descriptor . The shank cross section descriptor comprises data indicative of a particular cross sectional shape of the shank along a radial line such as elliptical round square square with chamfered edges and so forth. The shank cross section descriptor may comprise one or more vectors equations outlines and so forth.

The compact data includes references to one or more pieces of the common data . For example the compact data associated with a ring may include one or more of a shank material identifier configured to correspond to the material data a texture map identifier configured to correspond to the texture map data or a setting identifier configured to correspond to the setting identifier . Using this technique the compact data may be reduced to a very small parcel of data in most cases.

In some implementations the common data for one or more portions of the virtual item may be unavailable. In these implementations more detailed information may be included in the compact data . For example for a gold ring having a gallery with a previously unrecorded geometry the compact data may include information directly descriptive of the gallery geometry but use references to the common data such as the material data for gold.

While the common data and the compact data are described in relation to rings the data may be descriptive of other items such as bracelets hats shoes hardware household appliances and so forth. For example the compact data may encode virtual items such as tools appliances and so forth.

A view of the system following the preload such as while shopping is also depicted. The compact data is provided to the user device . The augmented image generation module uses the compact data in conjunction with the common data to generate an image of the virtual item . The item server may send compact data after receiving a request from the user device . In another implementation the item server may send the compact data without request. For example the compact data may be sent for virtual items that are featured in an advertised special.

The relatively small size of the compact data relative to the common data or relative to the 3D data reduces network data transmission costs reduces latency and so forth. This may improve the overall user experience.

In some implementations the common data may be updated over time. For example additional updates to the common data may be transmitted periodically to the user device .

Depicted in a first view is a finger selection control . The finger selection control is configured to allow the user to select a particular finger upon which the virtual item is to be presented. For example the user may have selected to place the virtual item on the left hand ring finger. The finger selection control may provide a listing of fingers for selection or may initiate an automatic recognition of the user s fingers. During automatic recognition the image data may be processed to identify a particular finger of the user. In another implementation automatic recognition may involve the user positioning their hand in a particular configuration. For example the user may extend a desired finger away from the palm while the remaining fingers are not extended.

An item selection control allows the user to select from among one or more available virtual items available to present in the augmented image . A size control allows the user to input a preferred or default ring size. For example the user may activate the size control to specify an initial ring size of 6 .

The user interface may present an initialization prompt . As shown here in the first view the initialization prompt may include a silhouette or outline of a left hand with the palm apparently facing away from the camera . A lock control may also be provided. The lock control is configured to activate deactivate a position lock function. The operation of the position lock function is discussed below in more detail. In the first view the lock control is off . While the lock control is depicted on one side of the display in some implementations the lock control may be available on either side or both sides of the display simultaneously. The lock control may be configured to be accessible to the thumb of the user while holding the user device .

In some implementations an acquire 3D data control may be presented. This control may be used to activate or deactivate gathering of 3D data by the 3D sensor of the actual object . For example the user may activate the acquire 3D data control to gather information about the actual object such that measurements for making sizing recommendations may be gathered.

The second view of the user interface depicts presentation of the augmented image generated by the augmented image generation module . As described above the augmented image combines images of the actual object obtained from the camera with images of the virtual item generated from the distributed item data . As shown here in the augmented image the image of the ring virtual item appears to be on the ring finger of the user s left hand positioned around the user s proximal phalanx bone.

The user interface may also provide other controls such as a fit selection control . The user may use this control to input a preference as to how loose or tight they prefer a ring to fit. For example as depicted here the user set the fit selection control to provide a snug fit intermediate between tight and loose.

The augmented image generation module may be configured to track the apparent motion of the actual object in the image data acquired by the camera . As illustrated in a third view the image of the virtual item is depicted as tracking with actual object of the user s hand. For example as the user moves their hand to the left or rotates the hand so the palm is facing the camera the virtual item moves and rotates to match. In this way the user may virtually interact with the virtual item .

As also shown in the third view in some implementations the user may be presented with information indicating the fit of the selected size. Continuing the example above the user has specified using the size control a ring size of 6 . However based on the 3D data of the user s hand the measured size of the ring finger at that position is determined to be a ring size of 8 . Based on this determination a prompt or indication may be provided in the user interface . The prompt may be one or more of textual output such as depicted here graphical output audible output or haptic output. For example graphical output may include an element in the user interface that changes color based on a relative difference in size between the actual object and the virtual item . This prompt may indicate that the select ring size will not fit suggest an alternative size and so forth. For example a border around the augmented image may be configured to change color based on fit with green indicating a typical fit yellow indicating a snug fit and red indicating a tight fit of the ring at a particular position on the user s hand. In the third view a textual prompt is shown indicating the fit of the ring phrased as a recommendation that a size 8 ring would be a better fit in the situation depicted.

The user may wish to change the apparent position in the augmented image of the virtual item with respect to the actual object . For example the user may wish to see an augmented image with the ring around the intermediate phalanx bone of the left hand ring finger.

A fourth view depicts the lock control as engaged activating the position lock function. For example the user s right thumb may activate the lock control . The position lock function fixes or locks an apparent position of the generated image of the virtual item to a particular point within the augmented image such that the image of the virtual item remains stationary while the actual object moves within the augmented image . The position lock function disables the tracking such that the user may change the apparent position of the actual object such as by moving their left hand or moving the user device while the apparent position on the display of the image of the virtual item remains fixed. As illustrated here the user has moved their hand such that the virtual item is now proximate to the intermediate phalanx bone of the user s left hand. Once at the desired relative position the user may deactivate the lock control . For example the user may remove their right thumb from the lock control . Once deactivated the virtual item resumes tracking relative to the current position on the actual object .

The position of the lock control may vary based on one or more of orientation of the user device selected finger and so forth. For example the user may have instead chosen the right ring finger using the finger selection control . Based on this selection the user interface module may present the lock control on the left side of the display proximate to the user s left thumb.

At a first position the image data depicts the actual object and the corresponding augmented image with the virtual item apparently around the proximal phalanx bone of a left hand ring finger. In the second position the user s hand has moved apparently down and to the left in the image data . For example the user may have moved their hand or shifted the position of the user device . Because the lock is off as illustrated in the corresponding augmented image the virtual item continues to track with the portion of the user s left hand corresponding to the proximal phalanx bone. As the apparent motion continues as illustrated by the third position the apparent position in the augmented image of the actual object and the image of the virtual item have both changed compared to the first position .

To provide for tracking of the actual object one or more tracking points on the actual object may be identified in the one or more images. For example particular points along the edge of the actual object may be identified based on an edge detection function or a particular feature such as a skin wrinkle freckle or other marking may be designated as a tracking point.

At a first position the image data depicts the actual object and the corresponding augmented image with the virtual item apparently around the proximal phalanx bone of a left hand ring finger. In the second position with the lock control engaged the user s hand has moved apparently down and to the left in the image data . For example the user may have moved their hand or shifted the position of the user device . Because the lock is activated as illustrated in the corresponding augmented image the virtual item remains in a fixed location within a frame of the augmented image . Said another way when the lock control is engaged the virtual item no longer tracks with the actual object . In some implementations the lock may be based on a particular point of the virtual item such as an exterior point geometric center center of mass and so forth. As the apparent motion continues as illustrated by the third position the apparent position in the augmented image of the actual object has changed compared to the first position while the apparent position of the ring virtual item is around the intermediate phalanx of the user s left hand. Should the user deactivate the lock the tracking of the virtual item with the actual object would resume.

The I O interface s may couple to one or more I O devices . The I O devices may include input devices such as the camera the 3D sensor the touch sensor a microphone a button accelerometer magnetometer gyroscope and so forth. The I O devices may also include output devices such as the display audio speakers haptic output devices and so forth. The display may comprise an electrophoretic display projector liquid crystal display interferometric display light emitting diode display and so forth. In some embodiments the I O devices may be physically incorporated with the user device or may be externally placed.

The user device may also include one or more communication interfaces . The communication interfaces are configured to provide communications between the user device other devices the item server routers access points servers and so forth. The communication interfaces may include devices configured to couple to one or more networks including personal area networks PANs local area networks LANs wireless local area networks WLANs wireless wide area networks WWANs and so forth.

The user device may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the user device .

As shown in the user device includes one or more memories . The memory comprises one or more computer readable storage media CRSM . The CRSM may be any one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium a mechanical computer storage medium and so forth. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the user device .

The memory may include at least one operating system OS module . The OS module is configured to manage hardware resource devices such as the I O interfaces the I O devices the communication interfaces and provide various services to applications or modules executing on the processors . Also stored in the memory may be one or more of the following modules. These modules may be executed as foreground applications background tasks daemons and so forth.

A communication module is configured to support communication with the item server or other devices using the network . The communication module may be configured to encrypt or otherwise protect the data transferred between the item server and other devices. For example hypertext transport protocol secured HTTPS or transport layer security TLS may be supported. The communication module may also be configured to facilitate transfer of the distributed item data from the item server to the user device .

As described above the user interface module is configured to provide the user interface . This user interface may comprise one or more of a graphical user interface an audible user interface or a haptic user interface. The user interface module is configured to process inputs such as those made to the touch sensor and provide corresponding outputs to the user such as on the display using audio speakers and so forth. For example the user interface module may interpret a touch on a particular area of the touch sensor as being an activation of the lock control .

The augmented image generation module is configured to access the distributed item data and generate an augmented image . As described above the augmented image includes images of one or more virtual items combined with an image of the actual object acquired by the camera .

Other modules may also be present. For example application modules may be present to provide eBook readers browsers calculators word processors spreadsheets slideshow presenters drawing programs and so forth.

The memory may also include a datastore to store information. The datastore may use a flat file database linked list tree executable code or other data structure to store the information. In some implementations the datastore or a portion of the datastore may be distributed across one or more other devices including servers network attached storage devices and so forth.

As depicted here the datastore may store one or more of the image data the 3D data or the distributed item data . Other data may also be stored. For example the other data may include user preferences configuration files and so forth.

The item server may include one or more processors configured to execute one or more stored instructions. The processors may comprise one or more cores. The item server may include one or more I O interface s to allow the processor or other portions of the item server to communicate with other devices. The I O interfaces may comprise I2C SPI USB RS 232 and so forth.

The I O interface s may couple to one or more I O devices . The I O devices may include input devices such as one or more of a keyboard mouse and so forth. The I O devices may also include output devices such as one or more of a display audio speakers haptic output devices and so forth. In some embodiments the I O devices may be physically incorporated with the item server or may be externally placed.

The item server may also include one or more communication interfaces . The communication interfaces are configured to provide communications between the item server and the user devices routers access points servers and so forth. The communication interfaces may include devices configured to couple to one or more networks including PANs LANs WLANs WWANs and so forth.

The item server may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the item server .

As shown in the item server includes one or more memories . The memory comprises one or more CRSM. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the item server .

The memory may include at least one OS module . The OS module is configured to manage hardware resource devices such as the I O interfaces the I O devices the communication interfaces and provide various services to applications or modules executing on the processors . Also stored in the memory may be one or more of the following modules. These modules may be executed as foreground applications background tasks daemons and so forth.

A communication module is configured to support communication with the user devices routers and so forth using the network . In some implementations the communication module may support encrypted communications. For example HTTPS or TLS may be supported.

A user interface module may be configured to provide one or more application programming interfaces. The user interface module may also provide data configured to provide the user interfaces on the user devices such as Hypertext Markup Language HTML files. The user interface module is configured to accept inputs and send outputs using the I O interfaces the communication interfaces or both.

The item data module may be configured to provide distributed item data or a portion thereof to the user device . The item data module may also be configured to process the 3D data about the actual item that the virtual item represents to generate the distributed item data . For example a device such as the user device may send the 3D data of an actual item to the item server . Other data may also be sent such as image data of the actual item manually input information and so forth. For example the user adding the virtual item may manually specify the material of a ring as 24 k gold indicate the gemstone is a topaz and so forth. The item data module may use the 3D data image data manual input and so forth to generate the distributed item data .

Other modules may also be present. For example an order fulfillment module may be configured to support placement of an order for a selected virtual item .

The memory may also include a datastore to store information. The datastore may use a flat file database linked list tree executable code or other data structure to store the information. In some implementations the datastore or a portion of the datastore may be distributed across one or more other devices including servers network attached storage devices and so forth.

As depicted here the datastore may store one or more of the 3D data or the distributed item data . Other data may also be stored. For example the other data may include manually input information about the actual item such as material composition type of gemstone and so forth.

Block accesses 3D data indicative of an actual item to be presented as a virtual item . In some implementations the actual item may comprise a piece of jewelry such as a ring. This acquisition may be from a 3D sensor such as present in the user device or a dedicated sensing platform. The 3D data may comprise a depth map point cloud vector mapping and so forth. The 3D sensor may include one or more devices such as an optical time of flight sensor comprising an emitter and a detector camera a structured light sensor comprising a structured light emitter and a camera a stereovision sensor comprising a plurality of cameras an interferometer comprising a coherent light source and a detector or a camera having a coded aperture. In other implementations other devices configured to generate 3D data may be used. The 3D sensor may be configured to provide 3D data with a resolution of less than one millimeter. For example in a depth map the 3D sensor may be able to resolve a 1 mm relative difference between two adjacent pixels in the depth map. In other implementations higher or lower resolutions may be used.

Block acquires a plurality of images of the actual item from a plurality of orientations. For example pictures may be taken of the actual item from several different points of view.

Block characterizes one or more portions of the actual item such as a shank of the ring. This characterization may be based at least in part on one or more of the 3D data at least a portion of the plurality of images or manual input. For example the 3D data may indicate that the ring shank has an elliptical cross section which the user may confirm via manual input. This characterization may result in generating the shank cross section descriptor described above.

Block characterizes one or more materials of the actual item. For example the composition of the ring may be characterized and associated with the material data . This characterization may be based at least in part on one or more of at least a portion of the plurality of images or manual input. Continuing the example the user may manually enter that the ring shank is made of 24 k gold. In another implementation based on information in the image the material may be recognized such as jade.

Block characterizes a texture map of the actual item. Continuing the example a texture map for the ring may be determined from the texture map data . This characterization may be based at least in part on one or more of the 3D data at least a portion of the plurality of images or manual input. For example the image data may be used to select the texture map data corresponding to jade.

Block characterizes one or more particular structures of the actual item. For example where the actual item comprises a ring the setting may be characterized. This characterization may be based at least in part on one or more of the 3D data at least a portion of the plurality of images or manual input. For example the geometry of the setting may be compared with those previously stored in the setting data to determine a match. When such a match is located in the setting data the corresponding setting identifier may be stored in the compact data .

Characterization may include pattern matching image recognition heuristic analysis machine learning and so forth. For example the color and albedo of a material may be compared with previously entered material data to characterize a smooth surface that is yellow and has a high albedo as comprising gold. In some implementations where the characterization is uncertain information indicative of a confidence in the characterization may be presented. For example the user interface may include a prompt which says this ring appears to be made of gold or brass but the merchant has not confirmed this. In some implementations where the characterization is made using a known good party such as a third party lab this characterization may be indicated. For example information indicating identification and characterization by the Gemological Institute of America may be presented in the user interface .

Where the characterization fails to result in a corresponding match with preexisting information in the common data that characterization may be added to the common data . For example a new gallery geometry may be added.

Block generates a plurality of physical measurements associated with the actual item. For example the plurality of physical measurements may include one or more of overall height overall width overall thickness inner diameter of a ring shank exterior diameter of a ring shank mass and so forth. The physical measurements may be based on one or more of the 3D data other instruments such as a scale manual input and so forth.

Block stores compact data . As described above with regard to the compact data for a ring may comprise one or more of the plurality of images the characterization of the shank of the ring the characterization of the one or more materials of the ring the characterization of the texture map of the ring the characterization of the setting or the one or more of the physical measurements.

In some implementations a first server or other device may be configured to generate the compact data while a second server or other device may be configured to distribute the compact data to the user device . For example a wholesale merchant may build the compact data for a particular virtual item and upload that compact data to a catalog maintained by a retail merchant. The wholesale merchant may send the compact data to the server of the retail merchant. The retail merchant server may then be configured to distribute the compact data to one or more of the user devices .

In some implementations the item data module or another module may be configured to receive a request for compact data . Based at least in part on that request the compact data may be sent to the user device . The user device may receive the compact data . The augmented image generation module of the user device may then generate an augmented image comprising an image of the actual object such as at least a portion of the one or more user s fingers and a generated image of the virtual item such as the ring. The image of the virtual item is based at least in part on the compact data .

Block sends the common data to the user device . For example the communication module of the item server may establish a connection with the communication module of the user device . Once established the common data or a portion thereof may be transferred.

Block receives a request for data on one or more virtual items such as rings or other jewelry. In one implementation the request may originate from the user device . In another implementation the request may originate from another device or service such as an advertising campaign server coordinating presentation of advertisements for a particular gold ring.

Based on the request block accesses the compact data associated with the one or more virtual items . Continuing the example the compact data associated with the particular gold ring being advertised may be retrieved from the data store .

Block sends the compact data to the user device . In some implementations the compact data may be embedded or otherwise encoded in another document. For example a popup advertisement may include the compact data for the virtual item featured in that advertisement.

Block acquires or accesses 3D data indicative of an actual object . For example the 3D sensor may scan the actual object to acquire the 3D data or a previously stored set of 3D data may be retrieved.

Block acquires one or more images of the actual object using a camera having a field of view. The one or more images may be stored as image data .

Block determines one or more tracking points on the actual object based on the one or more images. For example particular points along the edge of the actual object may be identified based on an edge detection function or a particular feature such as a skin wrinkle freckle or other marking may be designated as a tracking point. The tracking may be based at least in part on the threshold value which may be used to provide for a snap function of the virtual item relative to the actual object in the image data . The threshold value may be fixed or dynamically adjustable. For example the threshold value may dynamically vary based at least in part on the actual dimensions of a portion of the actual object as determined by the 3D data such that a larger actual object has a larger snap distance.

Block receives selection of a virtual item for virtual presentation. For example the user may activate the item selection control in the user interface to pick a particular ring to present.

Block accesses distributed item data associated with the virtual item . For example the compact data and the corresponding pieces of the common data may be retrieved.

Block generates an image of the virtual item based on the distributed item data and the one or more tracking points. The one or more tracking points may be used to specify a particular orientation for the virtual item to appear in. For example where the one or more tracking points indicate the back of the user s hand is facing towards the camera and where the virtual item comprises a ring the setting of the ring may be presented instead of the bottom of the shank.

Block generates a first augmented image comprising the image of the actual object and the image of the virtual item . Block presents the first augmented image using one or more display devices . Block may determine or detect a first motion of the actual object in the field of view of the camera . For example the user may begin to move their hand in front of the camera .

Block generates a second augmented image comprising the image of the actual object now moved and the image of the virtual item such that the virtual item moves based at least in part on the one or more tracking points. Block presents the second augmented image using one or more display devices . Continuing the example to the user the ring virtual item appears to be following the original point on their hand while the hand moves.

Block receives user input indicative of activation of a position lock function. For example the user may have placed a thumb on the lock control . The touch sensor may detect the user input of the thumb touch at the position of the lock control . As described above the lock control may be placed at a specified position at a left side a right side or a left and right side of the touch sensor which is accessible by the user s left thumb or right thumb respectively.

Block fixes at a fixed position the image of the virtual item in an image frame as presented by the one or more display devices . For example if the virtual item is presented with a center point located at coordinates in the displayed image the fixed position would be .

Block detects or determines a second motion of the actual object in the field of view of the camera . For example now that the lock control is activated the user may continue movement of their hand.

Block generates a third augmented image comprising the image of the actual object and the image of the virtual item such that the position of the image of the virtual item within the image frame as presented by the one or more display devices remains fixed at the fixed position. Continuing the example while the user s hand appears to move around in the user interface the virtual item remains with a center point at coordinates . In one implementation the pose or orientation of the virtual item may remain locked. In another implementation the pose or orientation of the virtual item may continue to be updated based at least in part on the change in pose or orientation of the actual object . For example an apparent orientation of the virtual item in the augmented image may vary based at least in part on motion of the actual object while the position of the virtual item remains locked or constant. Block presents the third augmented image using one or more display devices .

As described above in some implementations the augmented image generation module may be configured to provide additional functions. These additional functions may include performing one or more of the following.

The user may choose to disengage the position lock function by removing their thumb from the lock control or providing another user input. In some implementations the position lock function may automatically disengage after a predetermined interval of time change in orientation or position of the actual object beyond a predetermined threshold and so forth.

Upon disengagement of the position lock function the image of the virtual item subsequently begins tracking with the actual object as the actual object moves within the augmented image . As a result the relative position between the image of the virtual item and the image of the actual object remains constant.

One function may provide indication of fit such as described above with regard to . One or more blocks may acquire the 3D data of at least a portion of the actual object . Based on the 3D data one or more physical measurements of the actual object may be determined. One or more physical measurements of the virtual item may be accessed. Based on the one or more physical measurements of the actual object and the physical measurements of the virtual item an indication of fit of the virtual item relative to the actual object may be generated.

Another function may provide a suggestion as to size. One or more blocks may acquire the 3D data of at least a portion of the actual object . Based on the 3D data one or more physical measurements of the actual object may be determined. One or more physical measurements of a plurality of sizes of the virtual item may be accessed. Based on the one or more physical measurements of the actual object and the physical measurements of the different sizes of virtual item one or more suggested sizes are generated.

Those having ordinary skill in the art will readily recognize that certain steps or operations illustrated in the figures above can be eliminated or taken in an alternate order. Moreover the methods described above may be implemented as one or more software programs for a computer system and are encoded in a computer readable storage medium as instructions executable on one or more processors.

The computer readable storage medium can be any one of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium and so forth. Separate instances of these programs can be executed on or distributed across separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art will readily recognize that the techniques described above can be utilized in a variety of devices environments and situations.

Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art and it is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

