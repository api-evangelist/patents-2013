---

title: Visual information processing allocation between a mobile device and a network
abstract: An illustrative mobile device includes a data storage configured to at least temporarily store visual information and at least one processor that is configured to determine whether to request visual information processing from a network with which the mobile device may communicate. The processor is configured to determine a mobile device condition and a network condition. The processor determines a type of feature from the visual information to use for classification based on the determined mobile device and network conditions. The processor is configured to classify the visual information based on the determined type of feature and determine a confidence indicator based on the classification. The processor determines whether to request visual information processing from the network based on the determined confidence indicator.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08913838&OS=08913838&RS=08913838
owner: Alcatel Lucent
number: 08913838
owner_city: Boulogne-Billancourt
owner_country: FR
publication_date: 20130228
---
This disclosure generally relates to processing visual information. More particularly without limitation this disclosure relates to allocating a visual information processing task to a mobile device or a network.

Object recognition techniques have been used for a variety of purposes. Recent developments have resulted in including object recognition capabilities on mobile devices such as mobile phones. Object recognition capability on a mobile device provides enhanced features such as an intelligent virtual assistant for locating information on the Internet based on visual data that represents an object.

Object recognition techniques can be used to classify an image or video frame for example into a predefined category. One drawback with many object recognition techniques is that they require a significant amount of computing. Using traditional techniques may result in quickly using up available battery power if the computing task is completed by a processor on a battery powered mobile device. Additionally computation on a mobile device may be slow which introduces latency into the object recognition process.

Although assigning the computing functions for object recognition to a network with which the mobile device is associated may save the battery power of the mobile station or may provide quicker results it does not come without a cost. The amount of data transfer associated with the network performing the object recognition tasks can place a burden on the network force a user to purchase a more expensive data plan or both.

An illustrative mobile device includes a data storage configured to at least temporarily store visual information and at least one processor that is configured to determine whether to request visual information processing from a network with which the mobile device may communicate. The processor is configured to determine a mobile device condition and a network condition. The processor determines a type of feature from the visual information to use for classification based on the determined mobile device and network conditions. The processor is configured to classify the visual information based on the determined type of feature and determine a confidence indicator based on the classification. The processor determines whether to request visual information processing from the network based on the determined confidence indicator.

An illustrative method of allocating a visual information processing task between a mobile device and a network with which the mobile may communicate includes determining a mobile device condition and a network condition of a network with which the mobile device may communicate. A type of feature from the visual information to classify is determined based on the determined network condition and mobile device condition. The visual information is classified based on the determined type of feature. The method also includes determining a confidence indicator based on the classification and determining whether to request visual information processing from the network based on the determined confidence indicator.

Various embodiments and their features will become apparent to those skilled in the art from the following detailed description of at least one example embodiment. The drawings that accompany the detailed description can be briefly described as follows.

A mobile device or method as described below facilitates allocating a computing task associated with processing visual information such as object recognition between a mobile device and a network with which the mobile device may communicate. The disclosed examples allow for avoiding draining the battery of a mobile device by allocating a visual information processing task to the network when the task would undesirably require a significant amount of a remaining charge on the battery. The disclosed examples also allow for avoiding burdening a network with large amounts of data transfer when it is not necessary to allocate a visual information processing task to the network.

The mobile device includes a plurality of modules that are configured to facilitate processing visual information. The modules may be realized as a portion of at least one processor of the mobile device or as software for example stored on a data storage of the mobile device .

The illustrated example includes at least one application module that allows for some visual information processing. For discussion purposes the application module includes at least one feature that uses or requires object recognition from visual information. The mobile device uses at least one of a variety of ways of recognizing when some visual information processing is desired or required.

A device monitor module is configured to determine condition of the mobile device that is indicative of whether the mobile device has capacity to complete the visual information processing task. In one example the determined condition is based on information such as a charge level of a battery of the mobile device . The device monitor module provides an indication of the mobile device condition to a quantizer module .

The device monitor module also determines a network condition of the network which is indicative of whether the current status of the network will allow for the network to efficiently or effectively communicate with the mobile device for carrying out the visual information processing task such as the computing necessary for object recognition. The network condition in one example is based on a network interface with the mobile device e.g. whether it is a Wi Fi 3G or 4G connection round trip time or latency information and a current data rage for example. The device monitor module provides an indication of the network condition to the quantizer module .

The quantizer module quantized the mobile device condition and the network condition respectively into a pre defined discrete level. The quantized conditions are provided to an indexer module which determines a processing model based on the mobile device condition and the network condition. In one example the indexer module has a plurality of predetermined processing modules that are associated with sets of quantized mobile device conditions and quantized network conditions. The indexer module in such an example determines which of the predetermined models has associated condition values that correspond to the quantized condition information determined by the device monitor module and the quantizer module .

The processing model includes at least one type of feature from the visual information to be classified. A classifier module extracts corresponding features from the visual information e.g. video frame or image file and performs a known type of classification. The result provided by the classifier module includes an indication of the classification of the visual information and a confidence indicator.

A predictor module determines a relationship between the confidence indicator from the classifier module and a classification threshold. In one example the classification threshold is part of the model that is corresponds to the values of the quantized mobile device and network conditions. The predictor module determines whether the confidence indicator from the classifier module indicates that the classification provided by the classifier module is sufficiently accurate to use the classified visual information as processed by the mobile station. If the confidence indicator reveals a sufficient accuracy associated with the classification based on the extracted features then no further processing is required from the network .

If on the other hand the confidence indicator reveals that the accuracy from the mobile device processing is insufficient to satisfy a desired accuracy level then the predictor module provides an indication that a cloud classifier module should process the extracted features for classification. The cloud classifier module is a highly accurate object recognition system in some examples. A known classification technique such as a multiple kernel learning MKL technique provides sufficient accuracy for object recognition. Although only one cloud instance of a cloud classifier module is illustrated in some examples more than one instance of the cloud classifier module may be utilized to parallelize the feature extraction and classification.

The processing models are configured to accommodate the current mobile device condition and the current network condition. For example the feature type and classification technique are specified in part to allow the processing at the mobile device to fit within constraints imposed by the current mobile device condition e.g. battery charge level . In some cases the achieved accuracy will correspond to a desired minimum accuracy level for a given type of feature. In other cases it will not which may be due to the mobile device not having enough power left for a more accurate classification or a different type of feature to be extracted. Utilizing the predetermined model allows for allocating the visual information processing task between the mobile device and the network in a manner that accommodates the condition of each.

The example of also includes a feature aggregator module associated with or part of the cloud network . The feature aggregator module pushes new feature functions to be profiled on the mobile device to a feature profiler module of the mobile device . The feature profiler module passively profiles new feature functions provided by the network according to their corresponding mobile device and network conditions and associated accuracy. In one example the feature profiler module runs in the background and can be executed whenever the battery charge level is sufficiently high or the mobile device is coupled with a source of electrical power e.g. plugged into a charger .

A model trainer module of the cloud network trains all the classifiers on the cloud. In this example each combination of a quantized mobile device condition and a quantized network condition has one classifier assigned to it as part of the processing model. The trained classifiers and the associated models are provided to the indexer module where they are available to be used on the mobile device . The model trainer module is used to predetermine the processing models and updates a listing of models with associated mobile device and network conditions whenever a new training data set or feature function becomes available to the network .

In the example of the middleware layer receives a request from one of the applications indicating a need for visual information processing. The middleware layer queries the device monitor module which provides an indication of the mobile device condition and the network condition as described above. The middleware layer includes the functionality of the indexer module mobile classifier module and predictor module as described above even though only the classifier module is specifically shown in to simplify the drawing . The middleware layer is configured to determine the processing model to use based on the mobile device condition and the network condition. That model dictates the type of features to be classified and the confidence indicator threshold. The middleware layer performs the feature extraction classification and confidence indicator determination. The middleware layer also determines whether processing by the network is needed based on the determined confidence indicator.

Providing a middleware layer may provide efficiencies in task division and assignment on the mobile device . For example the applications need not be configured for making any determinations regarding whether an object recognition task can be performed on the mobile device but instead only need to use the APIs exposed by the middleware layer .

The mobile device condition determined at and the network condition determined at are each quantized i.e. by the quantizer module as parameter values that are considered cost function values in one example. Distinct quantized levels are used in some embodiments. The quantized values are identified within a predetermined listing of pairings or sets of corresponding values with each set being associated with a particular processing model. The processing models are intended to establish a set of criteria to be used to accommodate the current mobile device and network conditions.

Establishing or determining the processing models in one embodiment is accomplished separate from the mobile device in the following manner which is summarized in the flowchart of . Considering an image as an example of visual information containing at least one object that should be identified the image may be treated as a two dimensional array of respective intensities at each pixel location. For simplicity assume that the image is grayscale. Any object recognition framework includes feature extraction and classification. Feature extraction includes transforming the image into a k dimensional vector which quite often is a local descriptor e.g. SIFT SURF HOG that provides scale rotation and illumination invariance. The extracted feature will be used in the classification step. For discussion purposes assume that there is training data comprising K classes of objects. Example known support vector machine SVM based frameworks e.g. Multiple Kernel Machine are known to achieve highest accuracy in object recognition. Each possible feature type has an associated kernel function e.g. gaussian chi squared spatial pyramid kernel etc. .

This embodiment includes profiling each feature function at based on the energy cost i.e. the mobile device condition and the test accuracy of the feature kernel combination. Candidate features are identified for each combination of quantized mobile device and network condition at . The candidate features are selected in this example so that the energy cost does not exceed the energy cost function corresponding to the mobile device condition and so that a maximum accuracy for those features may be achieved. In other words the feature profiling is intended to fit within the capabilities of the mobile while providing the best available accuracy under those constraints. One example includes using a known optimization problem such as the knapsack problem which can be solved efficiently in polynomial time.

Feature extraction may contribute to the majority e.g. approximately 90 of the classification cost. Therefore this embodiment includes optimizing the feature extraction step to provide a benefit on the classification cost.

The model trainer module of the network trains classifiers on each candidate feature set at by building a support vector based classifier on the training data. One example includes learning a kernel function which may be accomplished using known Multiple Kernel Learning MKL that is useful for object recognition problems. The classifier predicts its class label along with a confidence measure at . The confidence measure of this classifier is defined as the distance of the test data point from the margin mapped to the interval 0 1 via the sigmoid function. The confidence measure corresponds to the confidence indicator mentioned above.

The role of the predictor module will be to analyze the confidence score given as an output by the classifier in the last stage and predict whether to accept its class label as determined by the mobile classifier module or send the image to the cloud network for final classification. This classifier module is trained with the network cost function parameter i.e. the network condition indicator and learns a confidence indicator threshold. If the classification confidence is below that threshold the image processing will be requested from the cloud network . For these instances the final classification takes place on the network i.e. by the classifier module and the results are sent back to the mobile device . In some embodiments only a fraction of data points for which confidence is below the threshold are sent to the cloud network . The remaining processing tasks are completed on the mobile.

Referring again to given the predetermined processing models for each pairing or set of mobile device condition and network condition the indexer module determines the feature type to use for classification by identifying the processing model that corresponds to the current quantized mobile device and network conditions at . The mobile classifier module extracts the appropriate feature and classifies it at . The mobile classifier module also determines the confidence indicator at .

At the predictor module determines whether to request processing from the network based on a relationship between the confidence indicator determined at and the confidence threshold that is part of the processing model being used. In one example if the determined confidence indicator is equal to or more than the threshold the classification provided by the mobile classifier module is accepted for the processing task e.g. object recognition . If however the confidence indicator is below the threshold the predictor module requests processing from the classifier module of the network .

The disclosed examples facilitate using a mobile station s computing capabilities for visual information processing in a manner that avoids draining the mobile device s battery power or consuming all of the mobile s computing power or memory while having the benefit of obtaining a desired degree of accuracy. When needed processing from a network is requested but that is done on a limited basis to avoid unnecessarily burdening the network. The disclosed examples address the problem of how and where to process visual information e.g. perform object recognition using image or video data in a holistic manner from a computation and data splitting perspective.

The preceding description is illustrative rather than limiting in nature. Variations and modifications to the disclosed examples may become apparent to those skilled in the art that do not necessarily depart from the essence of the contribution to the art provided by the disclosed embodiments. The scope of legal protection can only be determined by studying the following claims.

