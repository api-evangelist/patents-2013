---

title: Dynamic load balancing in multiple video processing unit (VPU) systems
abstract: Systems and methods are provided for processing data. The systems and methods include multiple processors that each couple to receive commands and data, where the commands and/or data correspond to frames of video that include multiple pixels. An interlink module is coupled to receive processed data corresponding to the frames from each of the processors. The interlink module divides a first frame into multiple frame portions by dividing pixels of the first frame using at least one balance point. The interlink module dynamically determines a position for the balance point that minimizes differences between the workload of the processors during processing of commands and/or data of one or more subsequent frames.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08654133&OS=08654133&RS=08654133
owner: ATI Technologies ULC
number: 08654133
owner_city: Markham, Ontario
owner_country: CA
publication_date: 20130206
---
This application is a continuation of U.S. patent application Ser. No. 12 634 585 filed Dec. 9 2009 which is a continuation of U.S. patent application Ser. No. 11 139 893 filed May 27 2005 which issued as U.S. Pat. No. 7 649 537 on Jan. 19 2010 which are hereby incorporated by reference in their entirety.

Antialiasing System and Method U.S. application Ser. No. 11 140 156 filed on May 27 2005 which issued as U.S. Pat. No. 8 212 838 invented by Arcot J. Preetham Andrew S. Pomianowski and Raja Koduri 

Multiple Video Processing Unit VPU Memory Mapping U.S. application Ser. No. 11 139 917 filed on May 27 2005 which issued as U.S. Pat. No. 7 663 635 invented by Philip J. Rogers Jeffrey Cheng Dmitry Semiannokov and Raja Koduri 

Applying Non Homogeneous Properties to Multiple Video Processing Units VPUs U.S. application Ser. No. 11 140 163 filed on May 27 2005 which issued as U.S. Pat. No. 8 054 314 invented by Timothy M. Kelley Jonathan L. Campbell and David A. Gotwalt 

Frame Synchronization in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 140 114 filed on May 27 2005 invented by Raja Koduri Timothy M. Kelley and Dominik Behr 

Synchronizing Multiple Cards in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 139 744 filed on May 27 2005 invented by Syed Athar Hussain James Hunkins and Jacques Vallieres 

Compositing in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 140 165 filed on May 27 2005 which issued as U.S. Pat. No. 7 613 346 invented by James Hunkins and Raja Koduri and

Computing Device with Flexibly Configurable Expansion Slots and Method of Operation U.S. application Ser. No. 11 140 040 filed on May 27 2005 which issued as U.S. Pat. No. 7 539 801 invented by Yaoqiang George Xie and Roumen Saltchev.

Graphics and video processing hardware and software continue to become more capable as well as more accessible each year. Graphics and video processing circuitry is typically present on an add on card in a computer system but is also found on the motherboard itself. The graphics processor is responsible for creating the picture displayed by the monitor. In early text based personal computers PCs this was a relatively simple task. However the complexity of modern graphics capable operating systems has dramatically increased the amount of information to be displayed. In fact it is now impractical for the graphics processing to be handled by the main processor or central processing unit CPU of a system. As a result the display activity has typically been handed off to increasingly intelligent graphics cards which include specialized coprocessors referred to as graphics processing units GPUs or video processing units VPUs .

In theory very high quality complex video can be produced by computer systems with known methods. However as in most computer systems quality speed and complexity are limited by cost. For example cost increases when memory requirements and computational complexity increase. Some systems are created with much higher than normal cost limits such as display systems for military flight simulators. These systems are often entire one of a kind computer systems produced in very low numbers. However producing high quality complex video at acceptable speeds can quickly become prohibitively expensive for even high end consumer level systems. It is therefore an ongoing challenge to create VPUs and VPU systems that are affordable for mass production but have ever improved overall quality and capability.

Another challenge is to create VPUs and VPU systems that can deliver affordable higher quality video do not require excessive memory operate at expected speeds and are seamlessly compatible with existing computer systems.

All publications and patent applications mentioned in this specification are herein incorporated by reference to the same extent as if each individual publication or patent application was specifically and individually indicated to be incorporated by reference.

An improved system and method for video processing is described herein. Embodiments include a video processing system with at least one graphics processing unit GPU or video processing unit VPU . As used herein GPU and VPU are interchangeable terms. In various embodiments rendering tasks are shared among the VPUs in parallel to provide improved performance and capability with minimal increased cost. Respective VPUs in the system cooperate to produce a frame to be displayed. In various embodiments data output by different VPUs in the system is combined or merged or composited to produce a frame to be displayed. In one embodiment the system is programmable such that various modes of operation are selectable including various compositing modes and various modes of task sharing or load balancing between multiple VPUs.

The API can be any one of the available APIs for running video applications. The API communicates with a driver . The driver is typically written by the manufacturer of the video hardware and translates the standard code received from the API into a native format understood by the hardware. The driver allows input from for example an application process or user to direct settings. Such settings include settings for selecting modes of operation including modes of operation for each of multiple VPUs and modes of compositing frame data from each of multiple VPUs as described herein. For example a user can select settings via a user interface UI including a UI supplied to the user with video processing hardware and software as described herein.

In one embodiment the video hardware includes two video processing units VPU A and VPU B . In other embodiments there can be less than two or more than two VPUs. In various embodiments VPU A and VPU B are identical. In various other embodiments VPU A and VPU B are not identical. The various embodiments which include different configurations of a video processing system will be described in greater detail below.

The driver issues commands to VPU A and VPU B . The commands issued to VPU A and VPU B at the same time are for processing the same frame to be displayed. VPU A and VPU B each execute a series of commands for processing the frame. The driver programmably instructs VPU A and VPU B to render frame data according to a variety of modes. For example the driver programmably instructs VPU A and VPU B to render a particular portion of the frame data. Alternatively the driver programmably instructs each of VPU A and VPU B to render the same portion of the frame data.

When either or both of VPU A and VPU B finishes executing the commands for the frame the frame data is sent to a compositor . The compositor is optionally included in an interlink module as described more fully below. VPU A and VPU B cooperate to produce a frame to be displayed. In various embodiments the frame data from each of VPU A and VPU B is combined or merged or composited in the compositor to generate a frame to be rendered to a display . As used herein the terms combine merge composite mix or interlink all refer to the same capabilities of the IM and or compositor as described herein.

The API communicates with a driver . The driver is written specifically for the system and translates the standard code received from the API into a native format understood by the VPU components which will be explained more fully below.

In one embodiment the system further includes two VPUs VPU A and VPU B . The invention is not limited to two VPUs. Aspects of the invention as described herein would be workable with one VPU with modifications available to one of ordinary skill in the art. However in most instances the system would be less efficient with one VPU than with more than one VPU. Various embodiments also include more than two VPUs. Systems with more than two are workable with modifications available to one of ordinary skill in the art and in most instances would provide better efficiency than a system with two VPUs. In various embodiments VPU A and VPU B can be on one or more video cards that each includes a video processor and other associated hardware. As will be explained further below the invention is not so limited. For example more than one VPU can be resident on one card or board. However as referred to herein a VPU is intended to include at least a video processor.

VPU A and VPU B receive commands and data from the driver through respective ring buffers A and B . The commands instruct VPU A and VPU B to perform a variety of operations on the data in order to ultimately produce a rendered frame for a display .

The driver has access to a shared memory . In one embodiment the shared memory or system memory is memory on a computer system that is accessible to other components on the computer system bus but the invention is not so limited.

In one embodiment the shared memory VPU A and VPU B all have access to a shared communication bus and therefore to other components on the bus . In one embodiment the shared communication bus is a peripheral component interface express PCIE bus but the invention is not so limited.

The PCIE bus is specifically described in the following documents which are incorporated by reference herein in their entirety 

In one embodiment VPU A and VPU B communicate directly with each other using a peer to peer protocol over the bus but the invention is not so limited. In other embodiments there may be a direct dedicated communication mechanism between VPU A and VPU B . In yet other embodiments local video memory and may be shared which may eliminate the need for some of the communications between VPU A and VPU B .

VPU A and VPU B each have a local video memory and respectively available. In various embodiments one of the VPUs functions as a master VPU and the other VPU functions as a slave VPU but the invention is not so limited. In other embodiments the multiple VPUs could be peers under central control of another component. In one embodiment VPU A acts as a master VPU and VPU B acts as a slave VPU.

In one such embodiment various coordinating and combining functions are performed by an interlink module IM that is resident on a same card as VPU A . This is shown as IM enclosed with a solid line. In such an embodiment VPU A and VPU B communicate with each other via the bus for transferring inter VPU communications e.g. command and control and data. For example when VPU B transfers an output frame to IM on VPU A for compositing as shown in for example the frame is transferred via the bus .

In various other embodiments the IM is not resident on a VPU card but is an independent component with which both VPU A and VPU B communicate. One such embodiment includes the IM in a dongle that is easily connected to VPU A and VPU B . This is indicated in the figure by the IM enclosed by the dashed line. In such an embodiment VPU A and VPU B perform at least some communication through an IM connection . For example VPU A and VPU B can communicate command and control information using the bus and data such as frame data via the IM connection .

There are many configurations of the system contemplated as different embodiments of the invention. as described below illustrate just some of these embodiments.

The master VPU card includes an IM . In an embodiment in which VPU A and VPU B communicate via the bus each VPU processes frame data as instructed by the driver. As an example in the system is performing video processing in a scissoring load balancing mode as described below. Master VPU A generates an output and slave VPU B generates an output . The outputs and are input to the IM for compositing as described further below. In one embodiment the slave VPU B transfers its output to the IM via the buses and as shown by the dotted path . In one embodiment the slave VPU B transfers its output to the IM via the dedicated intercard connection as shown by the dotted path . The IM combines the outputs and to produce a frame for display. This frame is output to a display by the IM via a connector .

The master VPU card includes connectors and . The slave VPU card includes connectors and . Connectors and are connectors appropriate for the purpose of transmitting the required signals as known in the art. For example the connector is a digital video in DVI connector in one embodiment. There could be more or less than the number of connectors shown in the system .

In one embodiment the various configurations described herein are configurable by a user to employ any number of available VPUs for video processing. For example the system includes two VPUs but the user could choose to use only one VPU in a pass through mode. In such a configuration one of the VPUs would be active and one would not. In such a configuration the task sharing or load balancing as described herein would not be available. However the enabled VPU could perform conventional video processing. The dotted path from VPU card B to the display indicates that slave VPU B can be used alone for video processing in a pass through mode. Similarly the master VPU A can be used alone for video processing in a pass through mode.

The master VPU card also includes a receiver and a transmitter for receiving and transmitting in one embodiment TDMS signals. A dual connector is a DMS connector in an embodiment. The master card further includes a DVI connector for outputting digital video signals including frame data to a display. The master VPU card further includes a video digital to analog converter DAC . An interlink module IM is connected between the VPU A and the receivers and transmitters as shown. The VPU A includes an integrated transceiver labeled integrated and a digital video out DVO connector.

The slave VPU card includes two DVI connectors and . The slave VPU B includes a DVO connector and an integrated transceiver. As an alternative embodiment to communication over a PCIE bus not shown the master VPU card and the slave VPU card communicate via a dedicated intercard connection .

The system includes all of the multiple VPU also referred to as multiVPU functionality described herein. For example the master VPU A processes frame data as instructed by the driver and outputs processed frame data to the IM . The slave VPU B processes frame data as instructed by the driver and outputs processed frame data which is transferred to the IM for combining or compositing. The transfer is performed via the PCIE bus or via a dedicated inter VPU connection not shown as previously described with reference to system . In either case the composited frame is output from the IM to a display .

It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass through mode to perform video processing alone. This is shown for example by the dashed path which illustrates the slave VPU B connected to a display to output frame data for display. The master VPU A can also operate alone in pass through mode by outputting frame data on path .

The system includes all of the multiVPU functionality described herein. For example the master VPU A processes frame data as instructed by the driver and outputs processed frame data to the IM . The slave VPU B processes frame data as instructed by the driver and outputs processed frame data which is transferred to the IM for combining or compositing. The transfer is performed via the PCIE bus or via a dedicated inter VPU connection not shown as previously described with reference to system . In either case the composited frame is output from the IM to a display not shown .

It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass through mode to perform video processing alone. This is shown for example by the dashed path which illustrates the slave VPU B connected to an output for transferring a frame for display. The master VPU A can also operate alone in pass through mode by outputting frame data on path .

The configurations as shown herein for example in are intended as non limiting examples of possible embodiments. Other configurations are within the scope of the invention as defined by the claims. For example other embodiments include a first VPU installed on or incorporated in a computing device such as a personal computer PC a notebook computer a personal digital assistant PDA a TV a game console a handheld device etc. The first VPU can be an integrated VPU also known as an integrated graphics processor or IGP or a non integrated VPU. A second VPU is installed in or incorporated in a docking station or external enclosed unit. The second VPU can be an integrated VPU or a non integrated VPU.

In one embodiment the docking station is dedicated to supporting the second VPU. The second VPU and the first VPU communicate as described herein to cooperatively perform video processing and produce an output as described. However in such an embodiment the second VPU and the first VPU communicate via a cable or cables or another mechanism that is easy to attach and detach. Such an embodiment is especially useful for allowing computing devices which may be physically small and have limited video processing capability to significantly enhance that capability through cooperating with another VPU.

It will be appreciated by those of ordinary skill in the art that further alternative embodiments could include multiple VPUs on a single die e.g. two VPUs on a single die or multiple cores on a single silicon chip.

The IM includes a master input port that receives a DVO stream from a master VPU. The master VPU input can be from a TDMS receiver in a dongle configuration such as those shown in systems and . The master VPU input can alternatively come from a master VPU on a master VPU card in a multi card configuration as shown for example in systems and . A synchronization register receives the DVO data from the master VPU.

The IM further includes a slave input port that receives a DVO stream from a slave VPU. The slave VPU input can be from a TDMS receiver in a dongle configuration such as those shown in systems and or a card configuration as in systems and . The slave VPU input can alternatively come from a slave VPU on a super VPU card configuration as shown for example in systems and . The IM includes FIFOs on the slave port to help synchronize the input streams between the master VPU and the slave VPU.

The input data from both the master VPU and the slave VPU are transferred to an extended modes mixer and to a multiplexer MUX . The IM is configurable to operate in multiple compositing modes as described herein. When the parts of the frame processed by both VPUs are combined either by the extended modes mixer or by selecting only non black pixels for display as further described below the entire frame is ready to be displayed.

Control logic determines which compositing mode the IM operates in. Depending on the compositing mode either the extended modes mixer or the MUX will output the final data. When the MUX is used control logic including a black register and a MUX path logic and black comparator determines which master or slave pixel is passed through the MUX . Data is output to a TDMS transmitter or a DAC .

The black register is used to allow for control algorithms to set a final black value that has been gamma adjusted.

In one embodiment the inter component communication among the VPUs and the IM includes I2C buses and protocols.

Operating modes including compositing modes are set through a combination of I2C register bits and TMDS control bits as shown in Table 1.

There are two separate data paths through the IM according to an embodiment. The two input pixel streams from the respective VPUs are either processed through the MUX in pass through mode or standard interlink modes or through the mixer in extended modes. In one embodiment the extended modes include a super antialiasing mode or SuperAA mode as described in copending U.S. patent application Ser. No. 11 140 156 titled Antialiasing System and Method which is hereby incorporated by reference in its entirety.

In the MUX just one pixel from either VPU A or VPU B is selected to pass through and no processing of pixels is involved. In the extended modes mixer processing is done on a pixel by pixel basis. In the SuperAA mode for example the pixels are processed averaged together and reprocessed. In one embodiment the processing steps involve using one or more lookup tables to generate intermediate or final results.

The selection between the MUX path and the mixer path is determined by I2C register bits and control bits. For example the mixer path is selected if 

The output port configuration is split into two parts. The DAC is driven across a 24 bit single data rate SDR interface. The TMDS is driven with a double data rate DDR interface a 12 pin interface for TMDS single link and a 24 pin interface for TMDS dual link. The I2C control bit registers determines this configuration.

There are three primary pixel clock domains. Both the master and slave inputs come in on their own separate domains. The IM uses the DVO clock domain for all internal paths and the final output. The DVO clock is generated by the active input port in pass through mode and from the master input clock in interlink mode.

The master input bus data and control goes through a synchronizer as it passes into the DVO clock domain imparting a 2 4 clock delay. The slave input bus data and control goes into a FIFO which is synchronized on its output to the DVO clock domain. The outputs of both paths are routed to a MUX or extended modes mixer which then outputs a single bus width data output.

In slave pass through mode the slave FIFO is set into pass through mode while in interlink mode it is used as a standard FIFO. For slave pass through mode the control bits go through the FIFO with the pixel data. In interlink mode sAFR MAS goes through with the data and the control bits are ignored from the slave input port.

I Os that use DDR clocking are split into double wide buses e.g. 12 bit DDR input becomes 24 bits internally . This is to avoid having to run the full clock speed through the IM.

In one embodiment there is one FIFO on the IM located on the slave channel. Twenty four 24 bits of pixel data flow through the FIFO in single TMDS mode and 48 bits of data flow through the FIFO in dual TMDS mode. The slave port s control bits are also carried through this FIFO when in pass through mode slave path. When in interlink mode the control bits are ignored and instead of the control bits the sAFR MAS bit is carried through in parallel with the pixel data.

When in single link TMDS mode CONTROL BITS Dual Link Mode bit 0 the extra 24 bits of data for dual link are not clocked to conserve power.

On power up the FIFOs should be set to empty. FIFOs are also cleared when the ENABLE INTERLINK bit toggles to 1 or if the CONTROL ONESHOTS FIFO Clear bit is set to 1.

The slave FIFO has two watermarks registers FIFO FILL FIFO STOP . The IM drives the SlavePixelHold pin depending on how full the FIFO is and the values in these registers. If the slave FIFO has FIFO FILL or fewer entries in use the SlavePixelHold should go low. If the slave FIFO has FIFO STOP or more entries in use the SlavePixelHold should go high.

 Load balancing refers to how work is divided by a driver for processing by multiple system VPUs. In various embodiments the processed data output by each VPU is composited according to one of multiple compositing modes of the IM also referred to herein as interlinking modes and compositing modes . The IM supports numerous methods for load balancing between numerous VPUs including super tiling scissoring and alternate frame rendering AFR all of which are components of Blacking . These modes are described below. is a diagram illustrating various load balancing modes performed by the system as described. Frame data from various VPUs in the system is processed according to a load balancing mode and composited in a compositor as described herein to generate a displayable frame. Alternative embodiments of the IM may use any of the compositing modes in any combination across any number of VPUs.

For Super Tiling software driver control determines the tile size and alternates between image data and black tiles so that between the master and slave VPUs each frame is fully painted. The IM passes through the non black pixels image data creating a super tiling type split between the master and slave inputs. The tile sizes can be dynamically adjusted every pair of master and slave frames if desired. Super Tiling may divide a display screen into a chess board pattern for which each square tile is 32 32 pixels for example. The image tiles are rendered on a first VPU of a multi VPU system while the black tiles are rendered on a second VPU. Super Tiling provides fine grain load sharing for pixel processing within a frame of rendering a more even distribution of pixel load relative to other load balancing methods and less complex driver implementation.

Scissoring divides a display screen into two parts and this division can be horizontal or vertical. While a horizontal split may be more convenient when considering software implementation and data transfer flexibility a vertical split may provide better load balancing. In the context of multiple VPUs scissoring provides optimization opportunities in the direction of parallelizing data transfers with 3D rendering. Scissoring also supports methods in which the slave VPU which performs the majority of data transfers does less work than the master VPU thereby facilitating dynamic load balancing schemes between the master and the slave VPUs.

Scissoring includes both Vertical Split Screen Blacking Control and Horizontal Split Screen Blacking Control. With Vertical Split Screen Blacking Control the drivers determine which side of a frame are output from the master and slave VPU so that between the two VPUs every frame is completely painted. The part of a frame that each VPU does not handle is cleared to black by the drivers. The IM then interlinks the two frames as a vertical split between the master and slave VPU. The split does not have to be an even split of the screen e.g. 50 rendered by each VPU and can be dynamically adjusted for every pair of master and slave frames.

Under Horizontal Split Screen Blacking Control the software drivers determine which upper or lower section of a frame are output from the master and slave VPU. The drivers then clear to black the portions that will not hold valid frame buffer data and the IM mixes the inputs as a horizontal split of the inputs. The split does not have to be an even split of the screen e.g. 50 rendered by each VPU and can be dynamically adjusted for every pair of master and slave frames.

Alternate Frame Rendering AFR performs load balancing at a frame level. A frame as referred to herein includes a sequence of rendering commands issued by the application before issuing a display buffer swap flip command. AFR generally passes each new frame through to the output from alternating inputs of the IM . One VPU renders the even numbered frames and the other VPU renders the odd numbered frames but the embodiment is not so limited. The AFR allows performance scaling for the entire 3D pipeline and avoids render to texture card to card data transfers for many cases.

The IM of an embodiment may perform AFR under Manual Control Manual Control with automatic VSync switching or Blacking Control. When using Manual Control the drivers manually select an input of the IM for a frame after the next VSync. Using AFR using Manual Control with VSync switching and following a next vertical blank the IM chooses the input coupled to the master VPU as the output source and then automatically toggles between the master and slave VPU inputs on every VSync. Using Blacking Control the drivers alternate sending a fully painted frame versus a cleared to black frame from the master and slave VPUs the IM toggles between the master and slave frames as a result.

As described above with reference to the IM merges streams from multiple VPUs to drive a display. The merging of streams uses Manual AFR compositing and Blacking compositing but is not so limited. Both Manual AFR and Blacking compositing support AFR which includes switching the IM output alternately between two VPU inputs on a frame by frame basis. The Blacking with both horizontal screen split and vertical screen split includes a variable split offset controlled by the IM. The Blacking with Super Tiling includes a variable tile size controlled by the IM.

The control logic including the black register and MUX path logic and black comparator determines the compositing mode of the IM by controlling the MUX to output a frame line and or pixel from a particular VPU. For example when the TMDS control bits select AFR Manual compositing as described herein the IM alternately selects each VPU to display alternating frames. As such system drivers not shown determine the VPU source driven to the output. By setting the xAFR MAS control bit high the MUX of an embodiment couples the master input port master VPU output to the IM output on the next frame to be displayed. In contrast by setting the xAFR MAS control bit low the MUX couples the slave input port slave VPU output to the output on the next frame to be displayed.

The AFR AUTO bit of the TMDS control bits enables automatic toggling that causes the IM output to automatically switch or toggle between the master and the slave inputs on every VSync signal. When the AFR AUTO bit is asserted the IM begins rendering by coupling to the IM output the input port selected by the xAFR MAS bit. The IM automatically toggles its output between the master and slave inputs on every VSync signal thereby ignoring the xAFR MAS bit until the AFR AUTO bit is de asserted. The IM thus automatically controls the display of subsequent frames or lines alternately from each VPU.

The AFR Manual mode may also control a single VPU to drive the IM output by setting the AFR MAN ON bit to an asserted state. In contrast to coupling the IM output alternately between two VPUs for each frame AFR MAN ON hit sets the IM output path according to the state of the xAFR MAS bit and does not toggle the output between multiple VPUs for subsequent frames or pixels.

The IM of an embodiment supports more advanced merging of streams from multiple VPUs using Blacking compositing. The MUX path logic and black comparator when operating under Blacking controls the MUX so as to provide the IM output from one of multiple VPUs on a pixel by pixel basis. The decision on which pixels are to be displayed from each of a number of VPUs generally is a compare operation that determines which VPU is outputting black pixels. This is a fairly efficient and flexible method of intermixing that allows the drivers to tune the divisions and the blacking can be done by clearing memory to black once per mode set up and then leaving it until the mode is changed.

The Blacking generally receives a data stream from each of a first VPU and a second VPU and compares a first pixel from the first VPU to information of a pixel color. The Blacking selects the first pixel from the first VPU when a color of the first pixel is different from the pixel color. However Blacking selects a second pixel from the second VPU when the color of the first pixel matches the pixel color. The first pixel of the data stream from the first VPU and the second pixel of the data stream from the second VPU occupy corresponding positions in their respective frames. The Blacking thus mixes the received digital video streams to form a merged data stream that includes the selected one of the first and second pixels.

The drivers e.g. referring to driver of video processing system corresponding to the IM select Blacking compositing by deactivating the AFR Manual mode at the IM. Deactivation of the Blacking mode is controlled by asserting the AFR MAN ON bit of the TMDS control bits . The drivers also set up the frame buffers by setting any pixel of a VPU to black when another one of multiple VPUs is to display that pixel. This is similar in effect to a black chroma key affect but the embodiment is not so limited. If the pixels of all VPUs coupled to the IM are black the IM couples the pixel output from the master VPU to the IM output.

The IM uses the pixel clock and internal control lines to selectively couple an input port to the IM output on a pixel by pixel basis. In an example system having two VPUs the MUX path logic and black comparator performs compare to color operations so that output pixels from a first VPU output are compared with the contents of the black register to determine if the output pixels are a particular color. In an embodiment the compare to color operations are compare to black operations but the black color may be configurable to any pixel color. If the output pixels are black then the MUX path logic and black comparator controls multiplexer to output pixels non black from the second VPU. When the IM determines the output pixels from the first VPU are not black then the MUX path logic and black comparator controls multiplexer to output the pixels from the first VPU.

Other compositing strategies are available and are not limited by the IM . For example extended interlink modes are also available that go beyond the load sharing usage of the Manual AFR and Blacking modes. These modes while not the standard interlinking used for pure speed gains by sharing the processing between multiple VPUs enhance the system quality and or speed by offloading functionality from the VPUs to the IM . As one example of an extended mode the IM of an embodiment supports the SuperAA mode previously referred to in addition to the Manual AFR and Blacking modes.

The multiple VPU systems described herein provide numerous mechanisms for distributing the workload across the VPUs. These load balancing methods include AFR Scissoring and Super Tiling. The Scissoring mode divides the display into some number of portions or parts where the screen can be split horizontally or vertically using a balance point or split point . In a system having two VPUs for example the VPU scissor functionality controls the rendering during horizontal splitting so that one VPU renders only to the top portion and the other VPU renders only to the bottom portion of the screen. Similarly VPU scissor functionality controls the rendering during vertical splitting so that one VPU renders only to the left portion and the other VPU renders only to the right portion of the screen.

Scissoring modes typically use static balance points that do not change as applications run on the host system. These static balance points may lead to poor performance if the rendering load is not split evenly across the two portions of the screen. While a static balance point can be chosen using application detection this will not help applications which vary the rendering load while running.

The multiple VPU system of an embodiment uses Dynamic Load Balancing DLB as an improvement to scissoring mode that allows the balance point to vary as applications are running to produce an optimal or near optimal split of the rendering load between the VPUs. The DLB dynamically determines an appropriate balance point or split point of the screen and moves or adjusts the balance point per frame so as to approximately equalize the processing e.g. pixel processing workload of rendering each portion of the display screen. An IM control algorithm controls the DLB of an embodiment without a direct connection between the VPUs thereby supporting multiple VPUs that each has no knowledge of other VPUs that may be supporting the host system.

The multiple VPU system provides DLB without a direct connection between the VPUs. Instead each VPU writes a specific identifier to a location in memory at such time as the VPU completes rendering of a current frame. Upon completion of rendering operations for the current frame a determination is made as to which of the multiple VPUs completed rendering operations last based on the identifier read from the memory. Thus the VPU corresponding to the identifier in memory following rendering of a current frame is the VPU that last finished rendering operations for that frame.

In various embodiments the identifier could be stored anywhere in the system accessible by all the VPUs in the system including a system memory location.

Table 2 is an example sequence of commands submitted to the multiple VPU system during frame rendering under an embodiment.

Rendering using DLB selects a compositing mode and initializes the DLB based on information of a detected application running on the host system. Initial instructions from the driver to each VPU specify via the corresponding scissor register which region of the screen is to be rendered by that VPU. The scissor register subsequently controls the VPU to only draw to the appropriate portion of the screen. The remaining region of the screen is set to black at the end of the frame but before the image is sent to the compositor.

The components of an embodiment may initialize the balance point via writing of a variable to the scissor registers corresponding to the VPUs as in a static scissoring mode but are not so limited. The variables written to the scissor registers referred to as the percent on master variables represent a percentage of a frame that is rendered by the VPU that corresponds to the scissor register holding the percent on master. The value of the percent on master variable is converted to a number of scan lines to be rendered by the corresponding VPU. The balance point may be set for example so that the master VPU renders 50 of the display and the slave VPU renders the remaining 50 of the display. In another example the balance point may be set so that the master VPU renders 55 of the display and the slave VPU renders the remaining 45 of the display.

Components of the multiple VPU system e.g. system driver dynamically initialize or adjust the balance point for rendering a frame based on information of the rendering of one or more earlier frames. In so doing the driver for example reads a pre specified location e.g. register in system memory to which the VPUs write their respective identifiers in order to determine the last VPU to finish rendering a particular frame. The VPU to last finish rendering will have its processing load reduced on subsequent frames the next frame the control algorithm generates as a result of the driver moving the balance point to reduce the portion of the rectangle rendered by the last finishing VPU. The adjustment of processing load is accomplished by providing different scissor rectangles to each different VPU so that each VPU renders a different portion of the screen. The DLB thus allows for adjustment of how much is rendered with each VPU by adjusting the scissor registers on a per frame basis.

In an embodiment the balance point is adjusted for a frame using information of rendering operations from two 2 frames earlier in the processing chain. This allows the system driver and or other components to work in parallel by having the driver generate rendering commands for frame N 2 while frame N is being rendered.

In adjusting the balance point components of the multiple VPU system look back two 2 frames earlier which may include several command buffers. This number of frames allows the system to look backwards in the frame processing chain without having to stop and wait for the VPUs to finish rendering the current frame. The DLB therefore allows the control algorithm and VPU hardware to overlap in terms of frame rendering so the control algorithm is generating commands for one frame frame N 1 in advance of the VPU rendering frame N rendering the commands. In DLB after the control algorithm generates frame N 1 it looks at the results from rendering of frame N to determine any adjustment in balance point needed during rendering of frame N 2 .

Upon completion of frame N rendering operations the system memory is read to determine the last of the multiple VPUs to complete rendering operations for frame N. The last VPU to complete rendering operations corresponds to the identifier read from system memory as described herein. The balance point is adjusted or changed for frame N 2 in order to reduce the number of pixels or portion of the frame rendered by the last VPU to finish rendering of frame N. The balance point of an embodiment is adjusted in increments of one percent 1 of at least one of the display height horizontal balance point display width vertical balance point number of lines and number of pixels however alternative embodiments may use any percentage of these parameters. This balance point may then be rounded to a VPU family specific pixel boundary.

In embodiments where VPUs are not rendering to shared memory if an event occurs which requires the rendering from the VPUs to be merged mid frame for example glCopyTexSubImage or other render to texture operation copying the image of VPU A to VPU B and copying the image of VPU B to VPU A resulting in both VPUs having the full image following the copy the balance point of an embodiment is reset to the original balance point to which the system was initialized. When events occur requiring the rendering from each VPU to be merged mid frame both VPUs need to complete rendering of the image in order to continue processing that frame e.g. a scene that includes a mirror displaying some or all of a screen image . These events typically include rendering of a type of effect that requires all rendered information of a frame. This resetting is performed because the mid frame merging or copying of data from multiple VPUs is generally fastest when the balance point is set so as to reduce the processing expense of transferring data across the PCIE bus.

The driver of an embodiment may be configured to control the slave VPU to render a smaller portion of the screen in a multiple VPU configuration. Consequently an embodiment renders the smaller portion of the data e.g. based on pixel count on the slave VPU in order to reduce the amount of data transferred across the PCIE bus at the end of a frame. For example when the balance point is moved so that the master VPU is rendering a smaller portion of the display area than the slave VPU components of the multiple VPU system may swap the display regions rendered by the master and slave VPUs. Therefore when a position of the balance point has the master VPU rendering 49 and the slave VPU rendering 51 of the display the driver swaps the display portions between the VPUs. Following the swap the master VPU renders the 51 of the display rendered by the slave VPU in the previous frame while the slave VPU now renders the 49 of the display previously rendered by the master VPU.

In this first frame rendering the slave VPU will be the last to finish processing the frame and writing its identifier to system memory because the slave VPU is processing more pixels the area of the triangle bottom portion B processed by the slave VPU is larger than the area of the triangle top portion A . As a result of finishing last the DLB adjusts the balance point for a subsequent frame via the scissor register settings as described above. The new balance point reduces the number of lines rendered by the slave VPU by 1 50 1 49 while increasing the number of lines rendered by the master VPU by 1 50 1 51 .

In the next frame rendering the slave VPU will again be the last to finish processing the frame and writing its identifier to system memory because the slave VPU is still processing more pixels. As a result of finishing last the DLB adjusts the balance point for a subsequent frame via the scissor register settings as described above. The new balance point reduces the number of lines rendered by the slave VPU by 1 49 1 48 while increasing the number of lines rendered by the master VPU by 1 51 1 52 . The DLB operations continue as described above.

In the first frame rendering the slave VPU will be the last to finish processing the frame and writing its identifier to system memory because the slave VPU is processing more pixels the area of the triangle left portion L processed by the slave VPU is larger than the area of the triangle right portion R . As a result of finishing last the DLB adjusts the balance point for a subsequent frame via the scissor register settings as described above. The new balance point reduces the number of lines rendered by the slave VPU by 1 50 1 49 while increasing the number of lines rendered by the master VPU by 1 50 1 51 .

In the next frame rendering the slave VPU will again be the last to finish processing the frame and writing its identifier to system memory because the slave VPU is still processing more pixels. As a result of finishing last the DLB adjusts the balance point for a subsequent frame via the scissor register settings as described above. The new balance point reduces the number of lines rendered by the slave VPU by 1 49 1 48 while increasing the number of lines rendered by the master VPU by 1 51 1 52 . The DLB operations continue as described above.

When DLB is used in systems having more than two VPUs the driver continues to adjust the balance point based on information of the last VPU to write its identifier to a location in system memory. The portion of the rendering taken from the last VPU to write in these embodiments is evenly distributed among the other VPUs of the system but is not so limited.

Referring again to the IM supports multiple input modes and single or dual link TMDS widths depending on the input connectivity. The IM also includes counters that monitor the phase differences between the HSyncs and VSyncs of the two inputs. The counters may include a pixel frame counter to assist in matching the clocks on the two input streams.

With reference to Table 3 in one embodiment the IM has three counters . Each counter increments the master pixel clock and uses one of the VSyncs for latching and clearing.

If a read of an I2C counter is occurring the update to that register is held off until after the read is completed. If a write of the register is occurring then the read is delayed until the write is completed. Read delays are only a few IM internal clocks and therefore are transparent to software.

The IM may be used in a number of configurations as described above. In one configuration referred to herein as a dongle the IM receives two separate TMDS outputs one each from two separate VPUs and brings them onto the dongle through two TMDS receivers. The separate receivers then output two DVO streams directly into the IM of the dongle. The IM mixes the two received inputs into a single output stream. The output DVO signals from the IM are then fed either to a TMDS transmitter or through a DAC both of which drive out through a standard DVI I connector on the dongle.

In another configuration referred to herein as an on card configuration the IM receives two streams of DVO signals directly from two VPUs that reside on the same card as the IM . This on card configuration does not use TMDS transmitters or receivers between the VPUs and the IM in contrast to the dongle configuration. The IM mixes the two received inputs into a single output stream. The output DVO signals from the IM are then fed either to a TMDS transmitter or through a DAC both of which drive out through a standard DVI I connector for example.

The input streams received at the IM inputs are referred to herein as the master input and the slave input and are received from the master and slave VPUs respectively. The master and slave VPUs may be on two separate cards or on a single super card. Either VPU can function as the master or slave VPU.

The master VPU is used as the primary clock to which the slave is synchronized synced . The master clock is not adjusted or tuned other than the normal card initialization process. The slave VPU is adjusted to run slightly ahead of the master VPU to allow for synchronization and FIFO latencies. The slave VPU uses a larger FIFO in order to compensate for variances between the pixel clock rates of the two VPUs while the master VPU path uses a shallow FIFO to synchronize the master input clock domain to the internal DVO clock domain. Flow control between the master and slave VPUs includes initial synchronization of the two VPUs and then ongoing adjustments to the slave VPU to match the master VPU. The flow control includes clock adjustments via a pixel hold off signal generated by the IM or driver action in response to counters within the IM .

The IM as described above supports numerous operational modes including Pass through Mode and various Interlink Modes as illustrated in Table 1. These operational modes are set through a combination of I2C register bits and the TMDS Control Bits as described herein.

Pass through Mode is a mode in which an input of the IM is passed directly through to the output monitor . The input port used is chosen at power up by the initial toggling of an I2C clock. The path can be changed again by switching an ENABLE INTERLINK register from 1 back to 0 and then toggling the I2C clock of the desired port.

Interlink Modes include numerous modes in which the IM couples inputs received from the master and slave VPUs to an output in various combinations. Dual VPU Interlink Modes of an embodiment include but are not limited to Dual AFR Interlink Mode and Dual Blacking Interlink Mode.

Dual VPU Interlink Modes are modes in which both VPUs are being used through manual AFR control or through blacking modes. Both IM ports are output continuously during operations in these modes.

Dual AFR Interlink Mode includes modes in which the source of the IM output is alternated between the two input ports. It can either be done manually by the IM drivers or automatically once started based on VSync. Control of the Dual AFR Interlink Mode includes use of the following bits states AFR MAN ON low AFR AUTO high or low AFR MAS used to control which card is outputting at the time or to set the first card for the Auto switch .

Dual Blacking Interlink Mode includes modes in which both VPUs output in parallel and the IM forms an output by selecting pixels on a pixel by pixel basis by transmitting black pixel values for any pixel of any VPU that should not be output. Control of the Dual Blacking Interlink Mode includes use of the following bit state AFR MAN ON high.

AFR MAN ON is sent across the master TMDS Control Bit bus on bit no 2. It is clocked in with mClk one clock before the rising edge of mDE after the rising edge of mVSync. The action in response to it takes place before the first pixel of this mDE active period hits the MUX. Other than this specific time there is no direct response to AFR MAN ON .

When AFR MAN ON is active LOW and ENABLE INTERLINK is set to 1 and the ExtendedModes bit is 0 then the path set by the pixel MUX is controlled by the xAFR MAN bits as described below.

The I2C register reflects the result after the resulting action occurs. It does not directly reflect the clocked in bit.

AFR AUTO is sent across the slave TMDS Control Bit bus on bit no 2. It is clocked in with sClk timings and then synced to mClk. It is latches in the clock before mDE goes high after the rising edge of mVSync. The action in response to it then occurs before the first pixel associated with the active mDE hits the MUX and only if AFR MAN ON is low on the same latching point.

When AFR AUTO and AFR MAN ON are active and ENABLE INTERLINK is set to 1 and extended interlink modes are not active then the path set by the pixel MUX is initially set to the master path. The path is then automatically toggled on every rising edge of mDE after the rising edge of mVSync until AFR AUTO is deasserted.

The I2C register reflects the result after the resulting action occurs. It does not directly reflect the clocked in bit.

The mAFR MAS is set from the master port on mLCTL and sAFR MAS is set from the slave port on sLCTL . These two bits control which path is set by the pixel MUX when in Interlink mode manual AFR control.

The mAFR MAS is clocked directly in with mCLK. The sAFR MAS is clocked in with sCLK and then synced to mCLK. The bits are latched on the rising clock edge before the rising edge of mDE. Both latched bits then go into a logic block which detects a bit changing state. Depending on an I2C register bit either after the rising edge of a VSync or an HSync if a bit is detected as having its state changed the logic sets the pixel MUX when in AFR MANUAL Interlink mode to match the path of the toggled bit. The MUX will not change during AFR MANUAL interlink mode at any other time.

Unlike the other control bits the I2C register reflects the individual synchronized bits going into the MUX control logic block clocked in with MClk and not the bits after the sync state.

Regarding data and control paths in the IM of an embodiment the Dual VPU Interlink Mode works in routing modes that include pass through dual single input AFR Manual interlink and dual input Blacking Interlink. These routing modes describe which of the data and control lines from the two receivers get transmitted out of the IM via the transmitter or DAC. Table 4 chows the data control and clock routing by muting mode of the IM under an embodiment.

The clock is the pixel clock the internal control lines are the lines that connect between the TMDS transmitter and receivers and IM and the external control lines are lines that are not processed by the TMDS circuitry such as I2C and Hot Plug. The Slave pixel hold off signal goes directly between the IM and the Slave DVI VSync pin.

Pass Through occurs when using the IM in single VPU Mode and before the drivers set up the IM and VPUs for the dual VPU mode. At power up the IM defaults the MUX to pass all data and control lines directly from the master VPU to the output of the IM . As soon as the IM sees one of the input TMDS I2C clocks toggling it sets the MUX to pass that specific channel to the output. This includes the clock and all control signals whether it is from the master or slave VPU. This allows the IM to connect the default video card of the system directly through to the monitor during power up BIOS operation even before the drivers are aware of existence of the IM .

In the Dual VPU Interlink Mode once the drivers are loaded the drivers can detect if the IM exists and if there are one or two connections to the IM . The detection is done by reading the I2C ID register of the IM through the port of each VPU. The drivers can determine which discovered connection is the master and which is the slave by the value of bit of the IM ID register read on each port.

If only one connection is found the IM is left in Pass through mode. If two connections are found to the IM the driver then takes over the screen control setting the MUX of the IM to output from the master port with the VPU connected to the master port as the master VPU. The clock is driven from this port until the power is lost or one of the input connections to the IM is broken.

The MUX of an embodiment is set by mechanisms that include Pass Through initial states AFR Manual Control and Blacking Control. These modes and the particular controls for each are set through the TMDS CNTR bits with the IM responding on the next vertical blanking period. The master slave switch AFR MAS can latch in occur on either the next HSync or the next VSync depending on the I2C control bits setting.

In addition to using TDMS control registers the drivers also control and monitor the IM functionality using I2C control registers.

I2C registers are used for control and monitoring that does not need to happen every frame or faster. The registers can be available through both the master and slave ports of the IM.

For more dynamic control the I2C control registers are used to set different multiVPU modes and to manually switch the IM data path.

In one embodiment of a video processing system inter integrated circuit communication for the IM is accomplished using an Inter Integrated Circuit I2C bus. I2C is a bus typically used to connect integrated circuits ICs . I2C is a multi master bus which means that multiple ICs can be connected to the same bus and each one can act as a master by initiating a data transfer.

The two input I2C buses each feed through the DVI master and slave input ports into the dongle and directly into the IM on two separate channels.

Either of VPU A or VPU B can access the ID registers directly through respective input ports without concern for I2C bus ownership.

The IM has one set of registers which are I2C accessible at a particular I2C device address. All other addresses are passed through the IM onto the I2C output port.

The master ID register and the slave register each have the same internal address but are accessible only from their own respective I2C buses slave or master .

Other than an IM xxx ID registers offset and the I2C Reset register the I2C bus is arbitrated on an I2C cycle by cycle basis using a first come first served arbitration scheme.

For read cycles of the multi byte registers the ownership is held until the last byte is read. Software drivers insure that all bytes are fully read in the bottom to top sequence. If all bytes are not fully read in the bottom to top sequence the bus may remain locked and the behavior may become undefined.

For accesses that are passed through the IM to external devices the IM does not understand page addressing or any cycle that requires a dependency on any action in a prior access cycles that extend for more than one I2C stop bit . Therefore a register bit CONTROL BITS  Bit I2C LOCK is added. The software sets this register bit if a multi I2C access is needed. When this register bit is set the bus is given to that port specifically until the bit is unset at which time the automatic arbitration resumes. In a case where both ports try to set this bit then the standard arbitration method determines which gets access and a negative acknowledgement NACK signal is sent to let the requester know it was unsuccessful.

A specific I2C Reset register is used in a case of the I2C bus becoming locked for some unexpected reason. Any read to this register regardless of I2C bus ownership will always force the I2C state machines to reset and free up the I2C bus ownership reverting back to the automatic arbitration.

For the other I2C registers the I2C bus ownership is dynamically arbitrated for on a first come first served fashion. The input port accessing the other registers first with a clock and start bit gets ownership for the duration of the current I2C cycle that is until the next stop bit . For multiple byte read registers counters on the IM the ownership is maintained from the first byte read until the final byte of the register has been read.

If an I2C access starts after the bus has been granted to another input port then a negative acknowledgement NACK signal is sent in response to the access attempt. The data for a read is undefined and writes are discarded.

The IM supports single non page type I2C accesses for accesses off of the IM . To allow for locking the I2C bus during multiple dependent type I2C cycles if an input port sets an I2C LOCK bit I2C CONTROL  bit to 1 the I2C bus is held in that port s ownership until the same port sets the same bit back to 0. This register follows the same first come first served arbitration protocol.

If the I2C RESET register is read from either port no arbitration or ownership is required then the I2C state machine is reset and any I2C ownerships are cleared.

The VPU card could be part of the system for example. The VPU card includes a master VPU an IM a DVI transmitter and optional DVI transmitter. There are three I2C buses master slave and interlink as shown entering and existing the IM . In one embodiment the interlink I2C bus is a continuation of the master I2C bus or slave I2C bus depending on which bus is first accessed.

All IM I2C registers are available to either the slave or master I2C ports. Standard NACK responses are used if the I2C bus is currently in use by the other path. An IM device ID is an exception and can be accessed by either port at the same time.

In order to optionally verify that an I2C cycle has completed successfully all write registers are readable back. Since the I2C registers on the IM do not time out this matches the current method of I2C accesses used on various conventional video cards. The read back should not be necessary to verify writes.

The IM I2C resets its state machine not shown every time it gets a stop bit. This occurs at the start and end of every I2C cycle according to known I2C protocol.

A CONTROL ONESHOTS register not shown has a different behavior from the other read write registers. Once written to the IM latches its results to internal control bits. The CONTROL ONESHOTS registers themselves are cleared on the next read of this register allowing for confirmation of the write .

The internal copies of the CONTROL ONESHOTS bits are automatically cleared by the IM once the IM has completed the requested function and the CONTROL ONESHOTS register corresponding bits are cleared. The IM does not re latch the internal versions until the I2C versions are manually cleared.

The IM has one set of registers which are I2C accessible. The IM MASTER ID and IM SLAVE ID registers have the same internal address but are accessible only from their own I2C bus e.g. slave or master .

In order to verify that an I2C cycle has completed successfully all write registers must also be readable back to verify the updated values. Since the I2C registers on the IM do not time out this is consistent with conventional methods of I2C accesses used on various existing video cards. If needed the read back should not be necessary to verify the writes.

The IM I2C also resets its state machine every time it gets a stop bit. This happens as per I2C protocol at the start and end of every I2C cycle.

The CONTROL ONESHOTS register has a different behavior from the other read write registers. Once written to the IM latches its results to internal control bits. The CONTROL ONESHOTS are cleared on the next read of this register allowing for confirmation of the write .

The internal copies of the CONTROL ONESHOTS bits are automatically cleared by the IM once the IM has completed the requested function and the CONTROL ONESHOTS register corresponding bits are cleared.

In a dongle configuration such as in systems and for example the TMDS control bits are transmitted through the TMDS interface into the IM. The software driver sets the registers within the VPU for the desired control bit values and the results arrive at the TMDS receivers on the dongle and are latched into the IM. The AFR MAN ON and AFR AUTO are latched on the rising edge of the TMDS VSync. No pixel data is being transmitted at this time. AFR MAS is latched in on the rising edge of either HSync or VSync depending on the setting in the I2C Control Bits register bit .

If the interlink mode is not enabled I2C register set then the bits will be ignored until it is enabled and will take place on the next VSync.

If the interlink mode is enabled then the affect occurs on the very next pixel data coming out of the IMs after the VSync or HSync as is appropriate.

If in pass thru modes the Syncs used are from the active path. If in AFR MANual or blacking interlink modes then the Syncs used are always from the master path.

Aspects of the invention described above may be implemented as functionality programmed into any of a variety of circuitry including but not limited to programmable logic devices PLDs such as field programmable gate arrays FPGAs programmable array logic PAL devices electrically programmable logic and memory devices and standard cell based devices as well as application specific integrated circuits ASICs and fully custom integrated circuits. Some other possibilities for implementing aspects of the invention include microcontrollers with memory such as electronically erasable programmable read only memory EEPROM embedded microprocessors firmware software etc. Furthermore aspects of the invention may be embodied in microprocessors having software based circuit emulation discrete logic sequential and combinatorial custom devices fuzzy neural logic quantum devices and hybrids of any of the above device types. Of course the underlying device technologies may be provided in a variety of component types e.g. metal oxide semiconductor field effect transistor MOSFET technologies like complementary metal oxide semiconductor CMOS bipolar technologies like emitter coupled logic ECL polymer technologies e.g. silicon conjugated polymer and metal conjugated polymer metal structures mixed analog and digital etc.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in a sense of including but not limited to. Words using the singular or plural number also include the plural or singular number respectively. Additionally the words herein hereunder above below and words of similar import when used in this application refer to this application as a whole and not to any particular portions of this application. When the word or is used in reference to a list of two or more items that word covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above description of illustrated embodiments of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. The teachings of the invention provided herein can be applied to other systems not only for the system including graphics processing or video processing as described above.

For example a video image produced as described herein may be output to a variety of display devices including computer displays that display moving pictures and printers that print static images.

The various operations described may be performed in a very wide variety of architectures and distributed differently than described. As an example in a distributed system a server may perform some or all of the rendering process. In addition though many configurations are described herein none are intended to be limiting or exclusive. For example the invention can also be embodied in a system that includes an integrated graphics processor IGP or video processor and a discrete graphics or video processor that cooperate to produce a frame to be displayed. In various embodiments frame data processed by each of the integrated and discrete processors is merged or composited as described. Further the invention can also be embodied in a system that includes the combination of one or more IGP devices with one or more discrete graphics or video processors.

In other embodiments some or all of the hardware and software capability described herein may exist in a printer a camera television handheld device mobile telephone or some other device. The video processing techniques described herein may be applied as part of a process of constructing animation from a video sequence.

The elements and acts of the various embodiments described above can be combined to provide further embodiments. These and other changes can be made to the invention in light of the above detailed description.

All of the U.S. patent applications cited herein are hereby incorporated by reference in their entirety.

In general in the following claims the terms used should not be construed to limit the video processing method and system to the specific embodiments disclosed in the specification and the claims but should be construed to include any processing systems that operate under the claims to provide video processing. Accordingly the video processing method and system is not limited by the disclosure but instead the scope of the video processing method and system is to be determined entirely by the claims.

While certain aspects of the method and apparatus for video processing are presented below in certain claim forms the inventors contemplate the various aspects of the method and apparatus for video processing in any number of claim forms. For example while only one aspect of the method and apparatus for video processing may be recited as embodied in computer readable medium other aspects may likewise be embodied in computer readable medium. Accordingly the inventors reserve the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the method and apparatus for video processing.

