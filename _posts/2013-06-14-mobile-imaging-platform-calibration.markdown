---

title: Mobile imaging platform calibration
abstract: Mobile platforms are used to capture an area using a variety of sensors (e.g., cameras and laser scanners) while traveling through the area, in order to create a representation (e.g., a navigable set of panoramic images, or a three-dimensional reconstruction). However, such sensors are often precisely calibrated in a controlled setting, and miscalibration during travel (e.g., due to a physical jolt) may result in a corruption of data and/or a recalibration that leaves the platform out of service for an extended duration. Presented herein are techniques for verifying sensor calibration during travel. Such techniques involve the identification of a sensor path for each sensor over time (e.g., a laser scanner path, a camera path, and a location sensor path) and a comparison of the paths, optionally after registration with a static coordinate system, to verify that the continued calibration of the sensors during the mobile operation of the platform.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09430822&OS=09430822&RS=09430822
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09430822
owner_city: Redmond
owner_country: US
publication_date: 20130614
---
Within the field of computing many scenarios involve a scanning of a mobile platform provided to travel through an area and capture a representation of the area. For example an automobile equipped with one or more cameras may be driven through a road network of a city while capturing images of the city which are later stitched together to form a navigable pictorial tour of the city. As another example a scan of the area using laser scanners of various types such as light detection and ranging lidar scanners may result in the capturing of spatial information about the area that enables a three dimensional reconstruction of the geometry of the area. These and other techniques may be utilized to capture and reconstruct various types of representations of an area.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

With many mobile platforms the scanning devices aboard the platform are precisely calibrated in a controlled setting before entering an area for scanning. Such calibration may be performed e.g. in order to verify that the images of the area are captured by cameras and or lidar devices with a precisely calibrated orientation such that reconstruction of the captured area such as stitching together images captured by images with different orientations may produce accurate results. However the precise calibration achieved in a controlled setting may be difficult to maintain for extended periods of travel. If a physical jolt causes a sensor device to become significantly misaligned the mobile platform may have to return to the controlled setting. Such recalibration may leave the platform out of service for an extended duration and may be expensive to perform with acceptable precision. Additionally failure to detect a miscalibration may result in extensive capturing of data that results in errors e.g. misaligned stitching of panoramic images or three dimensional reconstruction resulting in significant errors and data corruption and or the discarding of an extensive data set that is unusable for reconstruction.

Presented herein are techniques for verifying the calibration of the sensors of a mobile platform during traveling. In accordance with these techniques a mobile platform comprising at least one laser scanner at least one camera and a location sensor e.g. a global positioning system GPS receiver an inertial measurement unit IMU and or a radio triangulation device may travel through an area while capturing data with each sensor over time e.g. capturing images with the cameras capturing a laser scan of the area with the laser scanners and capturing the location of the platform with the location sensor . For each sensor a sensor path may be identified comprising a detected path of the sensor while the platform moves through the area. As a first example the laser scanner may generate a laser scanner path by comparing the laser scans captured at successive periods of time e.g. a first lidar point cloud indicating the distance of the platform from a fixed object such as a building at a first time and a second lidar point cloud indicating the distance of the platform from the same object at a second time and may determine the laser scanner path comprising a sequence of translations and orientations of the platform over time. The images captured at various intervals may be compared e.g. a fixed tie point may be identified in different locations in two consecutive images and image evaluation techniques may be utilized to determine the perspective points within the area where each image was captured resulting in a determination of the camera path as a sequence of translations and orientation changes over a period of time. Similarly the locations detected by the location sensor may be detected to identify a location sensor path of the location sensor over time.

Upon identifying the laser scanner path the camera path and the location sensor path the platform may compare these paths to verify the maintenance of the calibration of the sensors. In an embodiment the coordinate system of each sensor is registered with a static coordinate system and the translation and orientation changes between each pair of points in a first sensor path of a first sensor of the platform may be compared with the corresponding translations and orientation changes between each pair of points in a second sensor path of another sensor of the platform. Matching comparisons may verify the continued calibration of the sensors while mismatches e.g. discrepancies in the detected translation and orientation change of the platform over time may indicate that at least one sensor has become miscalibrated. Additionally a three way comparison of the laser scanner path with the camera path the laser scanner path with the location sensor path and the camera path with the location sensor path as well as comparisons among paths of equivalent sensors e.g. comparing a first camera path detected by a first camera and a second camera path detected by a second camera may identify the miscalibrated device. By performing such calibration checking using the computation and comparison of paths for each device the techniques presented herein may enable periodic and or continuous verification of maintained calibration even while the platform continues to travel and or a faster and more accurate technique for detecting a miscalibration which may reduce inefficiencies caused by the miscalibration. These and other uses of such calibration techniques may be included in many embodiments of the techniques presented herein.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

A platform may combine the capturing of images using one or more cameras and the capturing of lidar data and lidar point clouds to generate a robust representation of the area . Additionally the platform may utilize the location sensors to detect the path of the platform over time which may inform the reconstruction process.

However the accurate representation of an area based on the capturing of various types of data using a variety of sensors mounted on the mobile platform may be diminished by miscalibration. For example the reconstruction of data from multiple sensors may significantly depend on presumptions of the position and or orientation of the sensor with respect to the platform and other sensors. A miscalibration of one or more sensors may arise e.g. due to a physical jolt of the sensor and or mobile platform . Reconstructing the area with a variance between the presumed orientation and the actual orientation of the sensor may result in visual artifacts distortions and other forms of corruption. As a first example if one or more cameras of a camera set is miscalibrated the images automatically stitched together from the cameras may exhibit gaps spherical aberration missing areas or jarring transitions between image borders. As a second example if one or more laser scanners is miscalibrated the geometry of the reconstruction of the area may be distorted in size shape or relationships between detected surfaces of objects . As a third example if the location sensor is miscalibrated then the reconstruction may indicate inaccurate locations for the depictions of images and or three dimensional object reconstruction and or mismatch among images and or three dimensional object reconstructions if the calibration of the location sensor changes over time.

In order to avoid these problems mobile platforms are often calibrated in a controlled setting with high precision. For example the respective sensors may be carefully mounted on the platform carefully oriented to a high degree of precision and affixed in the orientation through strong mechanical brackets. However the calibration process may be expensive and protracted and a sensor that is subjected to a physical jolt while the platform is traveling may result in a recall of the platform to the controlled setting for recalibration possibly entailing a high cost of recalibration and or leaving the platform out of service for a potentially extended duration. Alternatively if the physical jolt is not detected the platform may capture a large set of data that is later determined to be corrupted and or misaligned or if undetected may corrupt the automated reconstruction of the area based on the captured data.

As a first example for respective cameras of the platform a sequence of images may be captured at various times . Using image processing and machine vision techniques it may be possible to extrapolate from the images the travel of the platform over time. For example for a particular pair of adjacent images in the sequence one or more tie points may be identified e.g. fixed points in the area that are visible in a first position of the first image captured at a first time and in a second position of the second image captured at a second time . Comparing the offset of the tie point from the first image to the second image may enable a determination of the translation and or orientation change of the platform between the first time and the second time . A collective evaluation of all of the images may enable a mapping such determinations to locations in the area and the identification of a camera path of the camera traveling throughout the area while mounted on the platform .

As a second example a laser scanner may periodically scan the area while the platform travels therethrough and may capture lidar data at various times . The identification of lidar point clouds in respective sets of lidar data may enable the determination of the sizes shapes orientations and distances of objects from the laser scanner at the time . Additionally a comparison of a first lidar point cloud in a first set of lidar data captured at a first time and a second lidar point cloud in a second set of lidar data captured at a second time may enable a determination of the translation and or orientation change of the laser scanner between the first time and the second time . Performing such comparative evaluation of sets of lidar data across the sequence of captured laser scans may enable the determination of the locations and orientations of the laser scanner over time and the identification of a laser scanner path indicating the movement of the laser scanner over time while the platform travels through the area .

As a third example monitoring the locations detected by a location sensor of the platform at a variety of times may enable the detection of a sequence of locations of the platform while traveling through the area and which may be represented as a location sensor path .

In view of these different techniques of detecting a sensor path of the sensor mounted on the platform while traveling through the area it may be possible to perform a comparison of the sensor paths. If the comparison indicates a match among the camera paths of the at least one camera the laser scanner paths of the at least one laser scanner and the location sensor path of the location sensor the comparison may verify the calibration of the sensors of the platform . However if one or more of the comparisons fails to produce a match a miscalibration may be detected. It may also be possible to determine which sensor is miscalibrated e.g. if all of the sensor paths match except for one camera path of one camera that does not match any of the other sensor paths the camera may be presumed to be miscalibrated . The platform may then either be serviced to recalibrate or replace the miscalibrated sensor may continue traveling through the area while capturing data from all but the miscalibrated sensor s and or may continue capturing data about the area from all of the sensors but noting the divergence in calibration in order to adjust the data captured by that sensor. In this manner the platform may verify maintained calibration and or detect and adapt to miscalibration while the platform is traveling through an area in accordance with the techniques presented herein.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. Such computer readable media may include e.g. computer readable storage media involving a tangible device such as a memory semiconductor e.g. a semiconductor utilizing static random access memory SRAM dynamic random access memory DRAM and or synchronous dynamic random access memory SDRAM technologies a platter of a hard disk drive a flash memory device or a magnetic or optical disc such as a CD R DVD R or floppy disc encoding a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein. Such computer readable media may also include as a class of technologies that are distinct from computer readable storage media various types of communications media such as a signal that may be propagated through various physical phenomena e.g. an electromagnetic signal a sound wave signal or an optical signal and in various wired scenarios e.g. via an Ethernet or fiber optic cable and or wireless scenarios e.g. a wireless local area network WLAN such as WiFi a personal area network PAN such as Bluetooth or a cellular or radio network and which encodes a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein.

An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In one such embodiment the processor executable instructions may be configured to implement a system for verifying the calibration of the sensors of a platform traveling through an area such as the exemplary system of . In another such embodiment the processor executable instructions may be configured to perform a method of verifying a calibration of the sensors of a platform such as the exemplary method of . Some embodiments of this computer readable medium may comprise a computer readable storage medium e.g. a hard disk drive an optical disc or a flash memory device that is configured to store processor executable instructions configured in this manner. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary system of and the exemplary method of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized.

As a first variation of this first aspect the techniques presented herein may be utilized with many types of platforms including vehicles traveling in the area such as automobiles and bicycles traveling on a roadway or airplanes helicopters and unmanned aerial vehicles UAVs traveling in an airspace individuals moving in an area such as a motion capture area and projectiles moving in a space such as ballistics. Such platforms may also be operated in whole or in part by humans present in or near the platform or remotely monitoring the platform and in whole or in part by automated navigation techniques.

As a second variation of this first aspect the techniques presented herein may be utilized with many types of cameras including monochromatic and polychromatic visible light cameras infrared cameras and ultraviolet cameras. Such cameras may also include a variety of lenses such as orthogonal fisheye spherical and polarized lenses imagers such as digital imagers recording to removal media or fixed internal storage film based cameras and videocameras various shutter and exposure speeds including high speed cameras time lapse cameras and extended exposure cameras for low light imaging and focusing and imaging techniques such as tilt shift and high dynamic range.

As a third variation of this first aspect the techniques presented herein may be utilized with many types of laser scanning techniques such as visible near infrared or infrared near ultraviolet or ultraviolet light. Various wavelengths of lidar signals may present various properties that may be advantageous in different scenarios such as passage through various media e.g. water or air of varying humidity sensitivity to various forms of interference and achievable resolution. Additionally such laser scanning techniques may involve various types of lidar emitters and or lidar detectors such as various types of lasers and photometric detectors. Such equipment may also be utilized in the performance of other techniques e.g. lidar equipment provided for range detection in vehicle navigation systems may also be suitable for the classification of moving and stationary objects and may be applied to both sets of techniques concurrently or in sequence.

As a fourth variation of this first aspect the techniques presented herein may be utilized with many types of location sensors including global positioning system GPS receivers inertial measurement units IMUs radio triangulation devices and compasses.

As a fifth variation of this first aspect the techniques presented herein may be utilized with platforms deployed to capture data for many types of representations such as navigable panoramic tours of the area three dimensional reconstruction of objects comprising the area identification of objects located in the area such as people vehicles flora and fauna monitoring of the electromagnetic spectrum and the generation of maps of the area . Those of ordinary skill in the art may devise many such scenarios wherein the techniques presented herein may be advantageously utilized.

A second aspect of the techniques presented herein relates to the manner of comparing the sensor paths generated by the techniques.

As a first variation of this second aspect before the sensor paths are captured the sensors and platform may be calibrated in a controlled setting. As one such example calibration may be achieved by positioning the platform relative to a fixed position of at least one target in a fixed area comparing a first detected position of the target by at least one laser scanner with the fixed position of the target relative to the platform and comparing a second detected position of the target by the camera with the fixed position of the target relative to the platform . The comparisons of the sensor paths may then be performed in view of the calibration of the laser scanner s the camera s and the location sensor s with the platform .

As a second variation of this second aspect the comparison of sensor paths to verify the calibration may be performed at various times with respect to the capturing of the area by the platform . As a first such example the comparing and verification of calibration may be performed while the platform is traveling through the area . As a second such example the comparing and verification of calibration may be performed after the capturing of the area by the platform i.e. in post processing the captured representation of the area . For example the platform may be configured to upon capturing a laser scan of the area store the laser scan upon capturing an image of the area store the image and upon detecting a location of the platform store the location of the platform . The comparing may then be performed after the platform has traveled through the area by retrieving stored laser scans images and locations and comparing the laser scanner path and the camera path with the location sensor path to verify the calibration of the platform while the platform was traveling through the area .

As a third variation of this second aspect the comparison to verify the calibration of the sensors may be performed in a three way manner e.g. by comparing the laser scanner path of at least one scanner with the camera path of at least one camera by comparing the laser scanner path with the location sensor path of at least one location sensor and by comparing the camera path with the location sensor path . Additionally if multiple sensors of a particular sensor type are included in the platform comparisons may be made among multiple sensors of the same type e.g. comparing a first camera path of a first camera with a second camera path of a second camera .

As a fourth variation of this second aspect the comparison to verify the calibration of the sensors may involve a registration of the respective sensor paths with a platform independent coordinate system. For example a comparison between a first path of a first sensor and a second path of a second sensor may be achieved by registering the first path with a platform independent coordinate system to produce a registered first path registering the second path with the platform independent coordinate system to produce a registered second path and comparing the registered first path and the registered second path. In an embodiment the platform independent coordinate system may comprise a static coordinate system e.g. the ground of the area .

As a fifth variation of this second aspect the comparison to verify the calibration may be performed among captured representations of the area by different sensors at the same time . For example a location sensor may be configured to perform a detection of a location of the platform at a location detection frequency e.g. once per second . One or more laser scanners may be configured to capture laser scans of the area in a manner that is synchronized with the time of the detection of the location of the platform by the location sensor and or one or more cameras may be configured to capture images of the area in a manner that is synchronized with the time of the detection of the location of the platform by the location sensor . Alternatively the laser scanner and or camera may capture representations of the area more frequently than the location sensor but may be timed to include a capturing at the same time as the location sensor e.g. at a frequency that is a multiple of the frequency of the location sensor .

As a sixth variation of this second aspect the device may be configured to detect and compensate for missing data objects that were not captured by one or more sensors. For example upon detecting a missing data object that a sensor failed to capture at a selected time e.g. a missing laser scan captured by the laser scanner a missing image captured by the camera and or a missing location detected by the location sensor the device may interpolate the missing data object at the selected time using various interpolation techniques e.g. a quaternion interpolation .

A third aspect that may vary among embodiments of the techniques presented herein relates to the manner of generating the laser scanner path of a laser scanner .

As a first variation of this third example the laser scanner may comprise a lidar scanner configured to generate the laser scan as a lidar point cloud . The identification of the laser scanner path may then be achieved by comparing a first lidar point cloud captured at a first time and a second lidar point cloud captured at a second time to identify a movement of the lidar scanner between the first time and the second time . In an embodiment the movement evaluation is performed as an iterative closest point evaluation of the first lidar point cloud and the second lidar point cloud . Additionally the evaluation of the first lidar point cloud may involve identifying a first orientation of the laser scanner at the first time the evaluation of the second lidar point cloud may involve identifying a second orientation of the laser scanner at the second time and identifying the movement may involve comparing the first orientation and the second orientation of the laser scanner to identify a rotation and a translation of the laser scanner between the first time and the second time .

As a second variation of this third example an embodiment may be configured to identify the location sensor path of the location sensor by identifying between the first time and the second time a rotation and a translation of the location sensor and to compare the rotation and the translation of the laser scanner between the first time and the second time with the rotation and the translation of the location sensor path between the first time and the second time . Additionally the comparison of the first lidar point cloud and the second lidar point cloud may involve recomparing the first lidar point cloud and the second lidar point cloud in view of the comparison of the laser scanner path and the location sensor path . In some such embodiments an iterative approach may be utilized to compare the lidar point clouds and the synchrony with the locations detected by the location sensor until achieving a convergence. These and other techniques may be utilized to identify the laser scanner path in accordance with the techniques presented herein.

A fourth aspect that may vary among embodiments of the techniques presented herein relates to the manner of identifying the camera path of a camera attached to the platform while traveling through the area .

As a first variation of this fourth aspect the comparison of images may involve many image processing and or machine vision techniques using such estimation techniques as perspective parallax and scale. One such technique involves identifying a tie point that is visible in a first image captured at a first time and also in a second image captured at a second time and comparing a first position of the tie point in the first image with a second position of the tie point in the second image to identify the movement of the camera between the first time and the second time . Another such technique involves from the images generating a reconstruction of the area e.g. a three dimensional model and for respective images captured at a time identifying the position of the camera within the reconstruction at the time e.g. the point of perspective projection or vantage within the three dimensional model where a captured image matches the perspective of the actual image . In an embodiment a photogrammetric bundle adjustment technique is applied to refine the coordinate space of the reconstruction to orient the images therewithin thus enabling the generation of an accurate camera path for comparison with the sensor paths of the other sensors to verify the calibration of the platform . Those of ordinary skill in the art may devise many such techniques for generating the camera path in accordance with the techniques presented herein.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various areas.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB Firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

