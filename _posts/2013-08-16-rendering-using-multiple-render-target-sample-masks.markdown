---

title: Rendering using multiple render target sample masks
abstract: One embodiment sets forth a method for transforming 3-D images into 2-D rendered images using render target sample masks. A software application creates multiple render targets associated with a surface. For each render target, the software application also creates an associated render target sample mask configured to select one or more samples included in each pixel. Within the graphics pipeline, a pixel shader processes each pixel individually and outputs multiple render target-specific color values. For each render target, a ROP unit uses the associated render target sample mask to select covered samples included in the pixel. Subsequently, the ROP unit uses the render target-specific color value to update the selected samples in the render target, thereby achieving sample-level color granularity. Advantageously, by increasing the effective resolution using render target sample masks, the quality of the rendered image is improved without incurring the performance degradation associated with processing each sample individually.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09396515&OS=09396515&RS=09396515
owner: NVIDIA CORPORATION
number: 09396515
owner_city: Santa Clara
owner_country: US
publication_date: 20130816
---
The present invention generally relates to graphics processing and more specifically to rendering using multiple render target sample masks.

A graphics processing pipeline performs the collection of processing steps performed to transform 3 D images into rendered 2 D images. As part of transforming a 3 D image the image is divided into a two dimensional array of pixels each representing a different image location. The dimensions of this two dimensional array of pixels defines the resolution of the rendered 2 D image. Since the viewer s ability to resolve images may exceed the resolution of the rendered 2 D image visual artifacts produced during the rendering may reduce the realism of the 2 D image. For example if an edge of a triangle is not aligned with a vertical or horizontal line of pixel locations the edge will exhibit a jagged stair step appearance in the rendered 2 D image. Various techniques may be used to reduce the appearance of such errors and visual artifacts e.g. smooth the appearance of jagged edges thereby improving the realism of the rendered images.

One approach to improving the realism of rendered images is through multisampling operations. In multisampling each pixel is subdivided into samples and a pixel shader included in the graphics processing pipeline processes each pixel individually. For each pixel the pixel shader computes a sample color value at each the covered samples i.e. the set of samples that are covered by a particular graphics primitive . Subsequently the pixel shader resolves these sample colors into a single pixel color value. Finally the single pixel color value is broadcast to each of the covered samples which results in the same color value being assigned to each sample in the pixel that is covered by the graphics primitive. The raster operations units also include in the graphics processing pipeline then uses the single pixel color associated with this graphics primitive to update the overall pixel color. One limitation to this approach is that the quality of the image may still be unacceptably low.

For example suppose that a pixel were to include four samples that were all covered by a first triangle a graphics primitive . Further suppose that two left most samples were covered by blue portions of the first triangle and the two right most samples were covered by yellow portions of the first triangle. As part of rendering the first triangle the pixel shader would assign a green color a mixture of blue and yellow to each of the four samples. By resolving the sample colors in this fashion per sample information would be lost. For instance information that the two left most samples were covered by blue portions of the first triangle would longer be available. Suppose further that a second triangle were to be subsequently rendered on top i.e. at a depth closer to the viewer of the first triangle. And suppose that the two right most samples were covered by blue portions of the second triangle but the two left most samples were not covered by the second triangle. As part of rendering the second triangle the pixel shader would assign a blue color to the two right most samples but would not assign a color to the two left most samples. The ROP unit would then update the overall pixel color to consider both the contributions of the first triangle and the second triangle. Consequently the final processed color of the pixel would be a mixture of the green color and the blue color. However after the addition of the second triangle the color values at each of the sample locations included in the pixel would be blue in the 3 D image. Thus using multisampling to create the rendered 2 D image would distort the true color of the 3 D image.

Another approach to improving the realism of rendered images is supersampling. In supersampling the pixel shader computes an individual color value for each sample and does not resolve the sample color values into a single pixel color value. One drawback to supersampling is that the pixel shader processes each sample individually thus the entire pixel shading calculation is performed per sample. In particular time consuming operations performed by the pixel shader such as texture fetches are performed per sample. Typically the majority of the execution time required during rendering is spent performing pixel shading operations. Consequently supersampling can lead to inefficiencies in the graphics processing pipeline and reduce the rendering frame rate. The reduced rendering frame rate may be unacceptable for many graphics based software applications such as video games.

As the foregoing illustrates what is needed in the art is a more effective technique to improve the realism of rendered images.

One embodiment of the present invention sets forth a method for updating samples included in render targets. The method includes receiving a first render target related to a first surface receiving first pixel data related to a first pixel included in the first surface computing a first color value based on the first pixel data creating a first composite mask based on a first coverage mask and a first render target sample mask where the first coverage mask is associated with the first surface and the first render target sample mask is associated with the first render target and updating a first sample included in the first render target and associated with the first pixel based on the first color value and the first composite mask.

Other embodiments of the present invention include without limitation a computer readable storage medium including instructions that when executed by a processing unit cause the processing unit to implement aspects of the techniques described herein as well as a system that includes different elements configured to implement aspects of the techniques described herein.

One advantage of implementing the disclosed techniques is that the realism of rendered 2 D images may be improved without incurring the dramatic efficiency reduction associated with processing each sample individually. Consequently software applications that exceed acceptable execution times or produce unacceptable results using prior art techniques may produce acceptable results without exceeding acceptable execution times using the disclosed techniques.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details.

As shown the parallel processing subsystem is coupled to a local parallel processing PP memory . The parallel processing subsystem and the parallel processing memory may be implemented using one or more integrated circuit devices such as programmable processors application specific integrated circuits ASICs or memory devices or in any other technically feasible fashion. As shown the parallel processing subsystem communicates with the rest of computer system via the communication path which connects to the memory bridge or in one alternative embodiment directly to the CPU . The connection of the parallel processing subsystem to the rest of the computer system may also be varied. In some embodiments the parallel processing subsystem is implemented as an add in card that can be inserted into an expansion slot of the computer system . In other embodiments the parallel processing subsystem can be integrated on a single chip with a bus bridge such as the memory bridge or the I O bridge . In still other embodiments some or all elements of the parallel processing subsystem may be integrated on a single chip with the CPU . In one embodiment the communication path is a PCI Express link. Other communication paths may also be used.

In one embodiment the parallel processing subsystem incorporates circuitry optimized for graphics and video processing including for example video output circuitry and constitutes a graphics processing unit GPU . In another embodiment the parallel processing subsystem incorporates circuitry optimized for general purpose processing while preserving the underlying computational architecture described in greater detail herein. In yet another embodiment the parallel processing subsystem may be integrated with one or more other system elements in a single subsystem such as joining the memory bridge the CPU and the I O bridge to form a system on chip SoC .

In operation the CPU is the master processor of the computer system controlling and coordinating operations of other system components. In particular the CPU issues commands that control the operation of the parallel processing subsystem . Those commands may originate within a software application resident in the system memory and executing on the CPU . Advantageously the parallel processing subsystem may execute commands asynchronously relative to the operation of the CPU . A graphics application programming interface API is also resident in the system memory . The graphics API includes calls and libraries that expose parallel processing subsystem functionality to application developers. Among other things the graphics API enables application developers to tailor the software application to optimize the way the parallel processing subsystem functions. In general the software application issues calls to the graphics API to produce a desired set of results using components include in the parallel processing subsystem . In alternate embodiments the graphics API may be replaced with any software program that exposes parallel processing subsystem functionality. For example the graphics API may be replaced with a different general purpose API. Further the graphics API may be configured to inter operate with one or more additional software stacks.

The parallel processing subsystem may be provided with any amount of parallel processing memory and may use the parallel processing memory and the system memory in any combination. The parallel processing subsystem may transfer data from system memory and or the local parallel processing memory into internal on chip memory process the data and write result data back to system memory and or the local parallel processing memory where such data can be accessed by other system components including CPU or another parallel processing subsystem . As shown the parallel processing subsystem includes a memory management unit MMU . The MMU among other things translates pages in one or more virtual address spaces to pages in a physical address space. To ensure optimal memory efficiency the software application may issue calls to control and coordinate some of the memory related operations of the MMU .

It will be appreciated that the system shown herein is illustrative and that variations and modifications are possible. The connection topology including the number and arrangement of bridges the number of CPUs and the number of parallel processing subsystems may be modified as desired. For instance in some embodiments the system memory is connected to the CPU directly rather than through a bridge and other devices communicate with the system memory via the memory bridge and the CPU . In other alternative topologies the parallel processing subsystem is connected to the I O bridge or directly to the CPU rather than to the memory bridge . In still other embodiments the I O bridge and the memory bridge might be integrated into a single chip instead of existing as one or more discrete devices. Large embodiments may include two or more CPUs and two or more parallel processing subsystems . The particular components shown herein are optional for instance any number of add in cards or peripheral devices might be supported. In some embodiments the switch is eliminated and the network adapter and the add in cards connect directly to the I O bridge .

One or more streaming multiprocessors not shown included in the parallel processing subsystem may be configured to perform the functions of one or more of the vertex shader the geometry shader and the pixel shader . The functions of the data assembly unit the primitive assembly unit the rasterizer and the ROP unit may be performed by other processing engines within the parallel processing subsystem . Alternatively the graphics processing pipeline may be implemented using dedicated processing units for one or more functions. In alternate embodiments the graphics processing pipeline may be configured with an expanded or reduced set of functionality. Further the functionality of the graphics processing pipeline may be implemented in any technically feasible manner by any combination of general or specialized processing units included in the parallel processing subsystem.

The components included in the parallel processing pipeline e.g. the data assembly unit etc. may access data that is stored in any accessible memory e.g. the parallel processing memory the system memory etc. in any combination. Typically a component included in the graphics processing pipeline reads input data from one or more memory buffers stored in accessible memory processes the input data to produce output data and stores the resulting output data in one or more memory buffers. A subsequent component included in the parallel processing pipeline may read this resulting output data as input data for the subsequent component. The subsequent component processes the data and stores output data in one or more memory buffers and so on.

The data assembly unit is a processing unit that collects vertex data for high order surfaces primitives and the like and outputs the vertex data including vertex attributes to the vertex shader . The vertex shader is a programmable execution unit that is configured to execute vertex shading programs lighting and transforming vertex data as specified by the vertex shading programs. For example the vertex shader may be programmed to transform the vertex data from an object based coordinate representation object space to an alternatively based coordinate system such as world space or normalized device coordinates NDC space.

The primitive assembly unit is a processing unit that receives processed vertex data from the vertex shader and constructs graphics primitives e.g. points lines triangles or the like for processing by the geometry shader . The geometry shader is a programmable execution unit that is configured to execute geometry shading programs processing graphics primitives received from the primitive assembly unit as specified by the geometry shading programs. The geometry shader may be programmed to perform well known per primitive operations such as clipping. In addition the geometry shader may be programmed to subdivide the graphics primitives into one or more new graphics primitives and calculate parameters such as vertex attribute or plane equation coefficients that are used to rasterize the new graphics primitives. In some embodiments the geometry shader may also add or delete elements in the geometry stream. The geometry shader outputs the parameters and new graphics primitives to the rasterizer .

The rasterizer is a processing unit that scans the new graphics primitives and outputs fragments and coverage data to the pixel shader . Each of the fragments contain pixel data which may include raster pixel coverage raster position depth complexity or interpolated vertex attributes such as texture coordinates and opacity. Additionally the rasterizer may be configured to perform z culling and other z based optimizations. The pixel shader is a programmable execution unit that is configured to execute pixel shading programs processing fragment data received from the rasterizer as specified by pixel shading programs. For example the pixel shader may be programmed to perform operations such as perspective correction shading blending and the like to produce color data that is output to the raster operations unit . Fragments may be shaded at pixel sample or other granularity depending on the programmed sampling rate.

The raster operations unit is a processing unit that can perform near and far plane clipping and generally performs raster operations such as stencil z test blending and the like and outputs pixel data as processed graphics data . In some embodiments the raster operations unit is configured to compress z or color data that is written to memory and decompress z or color data that is read from memory. Together the rasterizer the pixel shader and the raster operations unit represent the fragment processing domain of the parallel processing subsystem . The raster operations unit may be used to operate on individual pixels or small squares of pixels and the pixel shader may be programmed to iterate across groups of pixels. Further the pixel shader and the raster operations unit may be configured to treat samples as pixels.

The software application of issues calls to the graphics API also of to convey data to various components included in the graphics processing pipeline . For instance the software application may issue calls to the graphics API to convey vertex primitive attributes to the data assembly unit . In addition the software application uses the graphics API to configure various components in the parallel processing pipeline such as the pixel shader . In particular the software application may configure the graphics processing pipeline to process multiple render targets. Typically each pixel shader is configured to output a single color value. In contrast as part of processing multiple render targets one or more pixel shaders are configured to output a separate color value to each render target. The pixel shaders may be configured to process fragments at pixel sample or other granularity depending on the programmed sampling rate. As outlined previously herein performing pixel shading for each sample individually instead of performing pixel shading for each pixel individually improves the quality of rendered 2 D images. However performing pixel shading for each sample individually noticeably reduces the efficiency of the graphics processing pipeline compared to performing pixel shading for each pixel individually.

Advantageously the graphics API the pixel shader and the ROP unit are configured to extend the concept of multiple render target rendering to emulate pixel shading for each sample individually while performing pixel shading for each pixel individually. More specifically the graphics API includes calls or libraries that enable the software application to specify a different render target sample mask for each render target. Each render target sample mask is configured to allow coverage to proceed to the associated render target for one or more samples included in the pixel. In addition the pixel shader is configured to output a different per pixel color value to each of the render targets. The ROP unit is configured to use the render target sample masks as part of determining which samples included in the render targets to update and which samples to leave unchanged.

The software application may also configure the MMU of to map the addresses in the range of virtual address space corresponding to each of the multiple render targets to the same addresses in a physical address space. In other words the software application may configure the multiple render targets to write to the same addresses in physical memory. Advantageously mapping the multiple render targets to the same physical memory enables the pixel shader to process pixels individually but output a separate color for each sample included in the pixel to a single surface in physical memory. For example suppose that each pixel were to include four samples and the software application were to specify four different render targets. In addition suppose that the software application were to direct the MMU to map each of the four render targets to the same location in physical memory. Further suppose that the software application were to specify four different render target sample masks each associated with a different render target. Finally suppose that each render target sample mask were configured to allow coverage to proceed to the associated render target for one sample. In such a scenario if the pixel is fully covered then the ROP unit would update the color values of every sample included in the pixel using a different color value to update each sample. In alternate embodiments the software application may alias each render target to the same range of addresses in a virtual space. Again the render targets would map to the same location in physical memory and the software application would be able to perform per sample color shading of a pixel without configuring the pixel shader to process each sample individually.

In some alternate embodiments the pixel shader not the ROP unit may be configured to use the render target sample masks to determine which samples included in the render targets to update and which samples to leave unchanged. In other alternate embodiments the pixel shader may generate the render target sample masks as outputs sent to the ROP unit thereby allowing the pixel shader to independently vary the samples covered in each render target. In yet other alternate embodiments the pixel shader may receive the render target sample masks as inputs and may use the render target sample masks to filter samples thereby reducing the time required for shading computations. Further the pixel shader may iterate upon pixels and filter samples during any iteration.

In other alternate embodiments the render target sample masks may be generated in any technically feasible fashion. For example the render target sample masks may be automatically generated by the parallel processing subsystem based on the render target index of the currently drained shaded quad. In particular a programmable fixed function block included in the graphics processing pipeline could be configured to reconcile shaded quads and assign proper coverage before the samples are written to memory. For example the block could perform a bit wise i.e. on a bit by bit basis logical AND operation of the raster coverage for quads or pixels corresponding to render target 1 with 0b0001 a logical AND operation of the raster the coverage for quads or pixels corresponding to render target 2 with 0b0010 and so on using subsequent powers of 2.

Within the graphics processing pipeline the pixel shader processes each pixel individually and is configured to process pixel data as specified by a pixel shading program. Notably the pixel shader is configured to output a separate render target per pixel colors to each of the multiple render targets. In general the pixel shader outputs a separate color value to a number N of render target per pixel colors where N 1. Herein multiple instances of like objects are denoted with reference numbers identifying the object and hyphenated numbers identifying the instance where needed. Because the number N of render target per pixel colors equals the number N of multiple render targets the number of render target per pixel colors equals the number of samples included in each pixel. In alternate embodiments the number of render targets and consequently the number of render target per pixel colors may not equal the number of samples. In some embodiments the number of render targets divided by the number of samples is an integer so that each render target represents an equal fraction of each pixel. In an alternate embodiment the Graphics API provides the software application a means to specify the ratio of samples per render target.

The pixel shader computes a single color value for each render target per pixel colors . However each render target per pixel colors stores color values for each sample included in the pixel corresponding to pixel data . Consequently the pixel shader is configured to broadcast the single color value to each of the covered samples included in the render target per pixel colors . For instance suppose that the pixel shader or rasterizer were to determine that the pixel corresponding to pixel data was fully covered at this point in the rendering process. The pixel shader would broadcast the computed color value to all of the samples included in the render target per pixel colors . In contrast suppose that the pixel shader or rasterizer were to determine that one or more samples included in the pixel were not covered at this point in the rendering process. The pixel shader would broadcast the color value to only the covered samples included in the render target per pixel colors . The pixel shader or rasterizer may be configured to determine the sample coverage in any technically feasible fashion. For instance the pixel shader may determine the sample coverage by examining the raster coverage performing a depth test and so on.

Advantageously the pixel shader is configured to perform shading operations separately for each sample included in the pixel corresponding to the pixel data . Further the pixel shader is configured to output each of the resulting per sample color values to a different render target as render target per pixel colors . More specifically the pixel shader outputs the color value associated with a first sample included in the pixel to render target per pixel colors . The pixel shader outputs the color value associated with a second sample included in the pixel to render target per pixel colors and so on. Also advantageously computations in the pixel shader can be shared across samples because one pixel shader generates multiple sample color values but some computations are needed for all the sample color values.

The ROP unit receives the render target per pixel colors determines render target RT filtered per pixel colors and writes surface per sample colors . In general the ROP unit may be configured to perform a variety of filtering operations involving bit masks. In particular the ROP unit uses render target sample masks to filter the render target per pixel colors . The ROP unit applies a different render target sample mask to each render target. The ROP unit is configured to further filter the samples based on a coverage mask that does not differ between the multiple render targets. The coverage mask may be computed in any technically feasible fashion and typically includes raster pixel coverage Z test results alpha test results stencil test results and post pixel shader coverage mask data.

For each render target the ROP unit creates a render target specific composite mask by performing a bit wise AND of the coverage mask with the render target sample mask associated with the render target. Subsequently the ROP unit uses the composite mask to determine which of the samples included in the render target to update based on data included in the associated render target per pixel colors . For instance suppose that the render target specific composite mask were to include a logical 1 at the location corresponding to a particular sample. The ROP unit would update the location included in a render target filtered per pixel colors corresponding to the sample using the color value included in the associated render target per pixel colors . Further suppose that the render target specific composite mask were to include a logical 0 at the location corresponding to a particular sample. The ROP unit would not update the location included in the render target filtered per pixel colors corresponding to the sample. In alternate embodiments the ROP unit may perform any type and number of logical operations with the render target sample masks to create render target specific composite masks.

The ROP unit stores the render target filtered per pixel colors as processed graphics data of in a buffer included in memory accessible to the ROP unit . For instance the ROP unit may store the processed graphics data in a frame buffer not shown included in the parallel processing memory . The MMU of is configured to map the virtual address ranges corresponding to each of the multiple render targets to the same address range in a physical address space thereby creating a surface that includes surface per sample colors . More specifically in operation the MMU maps the render target filtered per pixel colors to the same addresses in physical memory such as the same addresses in the frame buffer. Notably the render target sample masks ensure that multiple colors are not aliased to the same sample location in physical memory. Through address manipulation the MMU effectively creates a single composite surface that includes the surface per sample colors by causing the render targets to alias to one surface. Advantageously because all of the render target filtered per pixel colors are mapped to the surface per sample colors the graphics processing pipeline performs per sample color shading while executing the pixel shader only once per pixel.

It will be appreciated that the parallel processing subsystem shown herein is illustrative and that variations and modifications are possible. In particular the graphics processing pipeline may be configured to perform fragment shading operations at various sampling rates using any combination of multiple render target sample masks . More specifically in alternate embodiments the pixel shader may be configured to compute and output color values at any level of granularity. For example suppose that the pixel were to include four samples and the pixel shader were configured to output to two render targets. Further suppose that the pixel shader were configured to compute a single color associated with samples and and a different color value associated with samples and . In such a scenario the pixel shader would output a single color value to the render target per pixel colors corresponding to samples and and a different color value to the render target per pixels colors corresponding to samples and . Again the pixel shader would update each of the covered samples included in each render target per pixel colors with a render target specific color.

In some embodiments the sampling rate may be configured to vary across the surface based on the type of lighting computation or level of detail. For instance suppose that the software application were to configure the multiple render target sample masks and a pixel shading program to compute per sample specular lighting color values per pixel diffuse lighting color values and per pixel ambient lighting color values. Further suppose that the software application were to configure the graphics processing pipeline to combine the specular lighting color values the diffuse lighting color values and the ambient lighting color values to produce overall per sample color values. The number and complexity of the pixel shading computations performed by the pixel shader would be reduced while retaining important sample specific color information.

In other embodiments the software application could use multiple render target sample masks to perform traditional multisample rendering with each sample stored in a separate surface. In such an embodiment the software application would specify a separate render target and associated render target sample mask for each sample. The software application would also specify that each render target maps to a separate physical memory. Further for the case of the coverage mask having more samples than the surface per sample colors has per sample for each render target the ROP unit would apply an additional logical OR reduction on the corresponding bits of the associated target specific composite mask to compute a sample coverage bit. If the sample coverage bit were to equal a logical 1 then the ROP unit would update the associated render target. If the sample coverage bit were to equal a logical 0 then the ROP unit would not update the associated render target. Thus each render target would include only the color values associated with a single sample location. Advantageously for operations such as screen space ambient occlusion the resulting memory locality of sample data would enable more efficient memory access.

As shown the coverage mask specifies that all of the samples included in three of the four pixels are covered. The coverage mask also specifies that only the left and right samples included in the bottom left pixel are covered. As also shown each of the render target sample masks through selects a single sample included in the pixel. The render target sample mask 0b0001 selects the left sample included in each pixel. The render target sample mask 0b0010 selects the top sample included in each pixel. The render target sample mask 0b0100 selects the bottom sample included in each pixel. The render target sample mask 0b1000 selects the right sample included in each pixel.

The ROP unit of creates a render target specific composite mask by performing a logical bit wise AND of the coverage mask with the render target sample mask . The ROP unit then uses the render target specific coverage mask to determine which of the render target per pixel colors of to use to update render target filtered per pixel colors . Consequently the ROP unit updates the left sample of each of the pixels included in the render target filtered per pixel colors . The ROP unit does not update the top bottom and right samples of any of the pixels included in the render target filtered per pixel colors .

Similarly the ROP unit updates the top sample of three of the four pixels included in the render target filtered per pixel colors using the corresponding color values included in render target per pixel colors . The ROP unit does not update the left bottom and right samples of any of the pixels included in the render target filtered per pixel colors . Nor does the ROP unit update any of the samples in the bottom left pixel included in the render target filtered per pixel colors .

The ROP unit updates the bottom sample of three of the four pixels included in the render target filtered per pixel colors using the corresponding color values included in render target per pixel colors . The ROP unit does not update the left top and right samples of any of the pixels included in the render target filtered per pixel colors . Nor does the ROP unit update any of the samples included in the bottom left pixel included in the render target filtered per pixel colors .

The ROP unit updates the right sample of each of the four pixels included in the render target filtered per pixel colors using the corresponding color values included in render target per pixel colors . The ROP unit does not update the left top and bottom samples of any of the pixels included in the render target filtered per pixel colors .

Advantageously the MMU of is configured to map the virtual address ranges corresponding to each of the render target filtered per pixel colors through to the same address range in a physical address space. Thus together the render target filtered per pixel colors through form the surface per sample colors . Each of the render target filtered per pixel colors through may include a different color value for each pixel. Consequently the surface per sample colors may include a different color for each sample included in each pixel. Notably for a 2 by 2 array of pixels the surface per sample colors could include sixteen different colors one per sample per pixel. For instance the four samples in the top right pixel represented by the surface per sample colors could be green red yellow and purple. As shown the render target sample masks through ensure that multiple colors are not aliased to the same sample location in physical memory. Again the pixel shader does not process each sample individually but the effective resolution of the resulting surface per sample colors corresponds to the granularity of a sample.

As shown a method begins at step where the software application defines a set of render targets and associated render target sample masks for a surface. At step the software application aliases all of the render targets associated with the surface to point to the same physical addresses. At step the software application send surface data to the parallel processing subsystem for rendering by the graphics processing pipeline . At step for each render target the pixel shader computes per pixel color values. More specifically the pixel shader processes each pixel individually but outputs different color values to each render target as render target per pixel colors . Advantageously the pixel shading program executed by the pixel shader may be configured to compute color values per sample and subsequently output the color value of each sample to a separate render target. Consequently the graphics processing pipeline may be configured to preserve sample level color granularity without incurring the loss of efficiency associated with processing each sample individually.

At step for each render target the ROP unit creates a composite mask based on the render target sample mask associated with the render target and the coverage mask . As outlined previously herein the render target sample masks enable the software application to specify which samples included in the render target are eligible for updating. For instance to achieve per sample granularity the software application could use the render target sample masks to specify a single eligible sample for each render target. Further the software application could structure each render target sample mask to select a different eligible sample within the associated render target. At step for each render target the ROP unit uses the color values included in the associated render target per pixel colors to update each sample in the associated render target filtered per pixel colors that is not masked by the composite mask. At step the MMU maps the virtual addresses of the render targets representing the render target filtered per pixel colors to the same physical addresses. Because each of the render targets may represent a separate sample by mapping the render targets in this fashion through address manipulation the MMU effectively creates a single composite surface that includes the surface per sample colors by causing the render targets to alias to one surface. Advantageously the render target sample masks ensure that multiple colors within the one surface are not aliased to the same sample location in physical memory.

In sum 2 D images may be more efficiently and realistically rendered by using multiple render target sample masks. In one implementation a runtime API is configured to expose additional pixel shading functionality within the graphics processing pipeline. In operation the additional functionality enables a software application to create multiple render target sample masks to flexibly direct the granularity of shading calculations. For example the software application configures the pixel shader to process each pixel individually but to output sample specific color values. More specifically for each surface the software application defines a set of render targets and associated render target sample masks. Both the number of render targets and the number of render target sample masks equal the number of samples included in a pixel. Further each sample mask is configured to cover a different sample and filter all of the other samples. In addition the software application aliases all of the render targets to point to the same physical addresses. The software application then sends the surface data to the parallel processing system for rendering by the graphics processing pipeline.

Within the graphics processing pipeline upon receiving a pixel the pixel shader calculates a single unique per target color value for each of the render targets. For example if there were four render targets then the pixel shader would calculate four different color values a different color value for each of the render targets. Subsequently for each render target a ROP unit performs a logical AND operation of the coverage mask with the render target sample mask creating a per target composite mask. The ROP unit then updates the samples included in each render target based on the associated per target color value and the per target composite mask. Consequently for each render target the ROP unit has to update a maximum of one sample per pixel. Finally the MMU maps the virtual addresses of the render targets to the same physical addresses thus creating a multi sample surface.

Advantageously by configuring the pixel shader to output sample specific color values the disclosed techniques enable software applications to increase the realism of rendered 2 D images compared to prior art approaches such as multisampling. Again the pixel shader does not process each sample individually. Consequently software applications that exceed acceptable execution times using prior art techniques e.g. supersampling may produce acceptable results without exceeding acceptable execution times using multiple target render masks. In particular software applications may use various combinations of render targets and associated render target masks to vary the shading rate thereby tuning the rendering quality and execution speed. For instance software applications may vary the shading rate based on lighting component e.g. specular diffuse etc. level of detail surface location and so on.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored.

The invention has been described above with reference to specific embodiments. Persons of ordinary skill in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

