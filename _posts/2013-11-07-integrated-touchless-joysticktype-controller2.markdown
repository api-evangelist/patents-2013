---

title: Integrated touchless joystick-type controller
abstract: Techniques are described to furnish a touchless joystick-type controller in a portable electronic device. The techniques may be implemented within an electronic device that comprises one or more sensors configured to detect a target at a distance from the sensor and provide a signal in response thereto. The signal is received in response to the sensor detecting a target within a field of view of the sensor. A position of the target relative to a point of reference is then determined based on the signal. Movement of the target may be tracked based on changes in the determined position relative to the point of reference. In embodiments, the target comprises a thumb or a finger of a hand of a user of the electronic device and the determined position to furnish a joystick-type control input.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09582078&OS=09582078&RS=09582078
owner: Maxim Integrated Products, Inc.
number: 09582078
owner_city: San Jose
owner_country: US
publication_date: 20131107
---
The present application claims priority under 35 U.S.C. 119 e to U.S. Provisional Application Ser. No. 61 840 921 entitled INTEGRATED TOUCHLESS JOYSTICK TYPE CONTROLLER filed on Jun. 28 2013 which is herein incorporated by reference in its entirety.

Touchscreens are common in portable electronic devices such as smartphones and tablets. A touchscreen allows a user of the portable electronic device to enter data and control functions of the device by touching the screen with one or more fingers a stylus or the like. The touchscreen enables the user to interact directly with displayed information. A user can for example input a command by touching the screen in a predetermined pattern to cause the device to perform a corresponding function.

Touchscreens when implemented with gaming applications are used to input commands for controlling the game. A user can progress through a game by touching visual representations of characters objects and so forth displayed on the screen in order to manipulate them.

Techniques are described to furnish a touchless joystick type controller in a portable electronic device. In one or more embodiments the techniques may be implemented within an electronic device that comprises one or more sensors e.g. one or more multisegmented proximity sensors or gesture sensors configured to detect a target at a distance from the sensor and provide a signal in response thereto. The signal is received in response to the sensor detecting a target within a field of view of the sensor. A position of the target relative to a point of reference is then determined based on the signal. Movement of the target may be tracked based on changes in the determined position relative to the point of reference. In embodiments the target comprises a thumb or a finger of a hand of a user of the electronic device and the determined position to furnish a touchless joystick type control input such as a joystick control input a thumbstick control input a D pad control input or the like.

This Summary is provided solely to introduce subject matter that is fully described in the Detailed Description and Drawings. Accordingly the Summary should not be considered to describe essential features nor be used to determine scope of the claims.

One drawback of using the touchscreens of portable electronic devices such as smartphones tablets and so forth with gaming applications is the inability of the touchscreen to furnish appropriate controls. Unlike physical game controllers such as a joystick touchscreens often do not permit sufficiently fine motor control to fully implement a game s functionality. Additionally dedicating a portion of the touchscreen to accept a user s touch input reduces the portion of the display that is available for viewing the game s visual information. This limitation is a significant drawback for a portable electronic device with limited screen size compared to a stationary electronic device employing a dedicated display and game controllers. Moreover since the touchscreen overlays the display of the portable electronic device the display of visual information on the display can be obstructed by the user s hand and or fingers. For example a user touching the screen to move a character can obstruct his or her view of visual information proximate to the user s finger.

Touchscreens may also fail to furnish sufficient controls for many gaming applications. Typically touchscreens provide only two dimensional controls e.g. x y controls . However many gaming applications require three dimensional controls e.g. x y z controls . Further many gaming applications require additional controls to provide increased functionality such as field of view controls controls providing game functions and so forth. Implementing such controls further reduces the portion of the display that is available for viewing the game s visual information.

Gesture detection and recognition can provide new and more intuitive human machine interfaces HMIs for electronic devices in comparison to other interfaces. Gesture recognition can be used to interpret human gestures via mathematical algorithms. Although gestures can originate from any bodily motion or state detecting and interpreting face or hand including fingers gestures can enable users to interact more naturally with electronic devices than keyboards mice or touchscreens.

Accordingly techniques are described to furnish a touchless joystick type controller. In one or more implementations the techniques may be implemented within a portable electronic device such as a smartphone or tablet computer. The portable electronic device comprises one or more sensors e.g. a multisegmented proximity sensor or gesture sensor that may be positioned generally adjacent to the ends of the device on either side of the display of the device. The sensors are configured to detect a target at a distance from the sensor and to provide a signal in response thereto. A position of the target relative to a point of reference such as the center of the sensor is then determined based on the signal. Movement of the target may be tracked based on changes in the determined position relative to the point of reference. In embodiments the target comprises a thumb or a finger of a hand of a user of the electronic device and the determined position to furnish a joystick type control input such as a D pad control input a thumbstick control input a joystick control input and so forth.

The present techniques may be employed in gaming and screen navigation applications in portable e.g. hand held devices electronic devices that employ gesture sensors. The techniques thus facilitate the integration of gaming controller track pointer functionality e.g. functionality similar to that furnished by controllers employed by Microsoft Xbox 360 gaming systems Microsoft Corporation Redmond Wash. Sony PlayStation gaming systems Sony Electronics Inc. San Diego Calif. Wii gaming systems Nintendo of America Inc. Redmond Wash. and so forth into such devices without the addition of mechanical controls such as joysticks thumbsticks or D pad controls. The techniques thus may augment touchscreen inputs and or may allow motor control to be moved off screen without the need of additional mechanical hardware.

As discussed herein the sensors are configured to detect a target e.g. a thumb or a finger of a hand of a user of the electronic device at a distance from the sensor and provide a signal in response thereto. A position of the target relative to a point of reference is then determined based on the signal. In embodiments the point of reference may comprise a center of the sensor . However the point of reference may be any chosen point of reference. For example it is contemplated that the point of reference may be other points on the face of the sensor other points on or within the housing e.g. on the front surface back surface sides or ends of the portable electronic device a point in space proximal to the portable electronic device and so forth. It is to be apparent that a sensor may implement a first point of reference when operating independently and a second point of reference when operating with one or more other sensors e.g. in a networked fashion if two sensors are used to track a target. The sensors can be configured so that a target does not obscure observation of the display during detection. For example one or more of the sensors can be oriented so that the thumb of the user does not substantially block the display when the user is manipulating the touchless joystick type controller.

Motion of the target e.g. a thumb or a finger of a hand of a user of the electronic device may be tracked based on changes in the determined position relative to the point of reference. In embodiments motion of a target may be tracked in two dimensions e.g. parallel to the front surface back surface sides or ends of the housing or in three dimensions e.g. parallel and or perpendicular to the front surface back surface sides or ends of the housing .

The determined position of the target may be processed as discussed herein to furnish a touchless joystick type control input to the portable electronic device . The determined position may be used to determine an attribute such as distance associated with the target a motion of the target a direction of the target acceleration of the target or a gesture. The attribute can correspond to a function to be performed responsive to receipt of one or more signals associated with the attribute. For instance a swipe gesture can result in the processor changing a field of view for a gaming application.

Example joystick type control inputs include but are not limited to D pad control inputs thumbstick control inputs joystick control inputs combinations thereof and so forth. The joystick type control inputs may be furnished to applications e.g. gaming applications executed by the processor of the electronic device as discussed below in the descriptions of . In embodiments sensors are positioned proximate to the ends of the housing on either side of the display to furnish dual touchless joystick type controllers. Sensors may also be positioned along the sides and or ends of the housing to allow the user to grasp the portable electronic device using both hands and manipulate multiple touchless controls e.g. joystick thumbstick D pad buttons in a fashion similar to that of a hand held controller employed by a gaming system e.g. Microsoft Xbox 360 gaming systems Sony PlayStation gaming systems Wii gaming systems and so forth . For example the sensor may be positioned in an ergonomically efficient manner to permit manipulation of the virtual joystick without interfering with a user viewing the display.

In embodiments respective ones of the sensors shown in may be synchronized with other sensors to allow one sensor to receive data from another sensor . This synchronization may be used to augment the position and or motion detection functionality and generation of the joystick type control input by adding functionality such as stereoscopy or triangulation to improve the overall performance of the sensors in comparison to operating independently. For example in one embodiment synchronization may be used to implement a touchless optical mouse type input with the target e.g. a user s finger being used to furnish a touchless variant of a mouse input to control and maneuver a mouse cursor displayed by the display without requiring that the user touch the display touchscreen . When coupled with a secondary input such as a touchless joystick type control input as described above this touchless optical mouse input can be used to emulate a WASD mouse input which is used in a variety of gaming applications.

In embodiments the configuration of sensors employed to furnish touchless joystick type control inputs can be used in tandem with swipe based gesture sensor inputs e.g. swipe up across pinch expand etc. . Thus one sensor may be used to detect both the position of a first target e.g. a thumb of the hand of a user used to furnish a joystick type input and the motion of a second target e.g. a finger of the hand of a user used to furnish a hand swipe . These inputs may but need not be concurrent. For example the sensor can be configured to switch between two operating modes based upon either a user command or based upon the context of the input.

In this manner differentiation of gestures based upon actions on performed over one sensor versus actions on performed over multiple sensors may be furnished. As shown in a gesture performed over across a first e.g. left or bottom sensor A only can be interpreted differently from the same gesture performed over across a second e.g. right or top sensor B or a gesture performed over both sensors A B. For example a gesture performed over one sensor e.g. sensor A may be associated with one attribute while a gesture performed over two sensors e.g. sensors A and B may be associated with a different attribute and for example result in a different function. Moreover differentiation of gestures can be combined with tandem usage of swipe gestures and target position tracking e.g. to furnish joystick type control inputs into complex gestures.

In the electronic device is illustrated as including a processor and a memory . The processor provides processing functionality for the electronic device and may include any number of processors micro controllers or other processing systems and resident or external memory for storing data and other information accessed or generated by the electronic device . The processor may execute one or more software programs which implement the techniques and modules described herein. The processor is not limited by the materials from which it is formed or the processing mechanisms employed therein and as such may be implemented via semiconductor s and or transistors e.g. electronic Integrated Circuits ICs and so forth.

The memory is an example of non transitory device readable storage media that provides storage functionality to store various data associated with the operation of the electronic device such as the software program and code segments mentioned above or other data to instruct the processor and other elements of the electronic device to perform the techniques described herein. Although a single memory is shown a wide variety of types and combinations of memory may be employed. The memory may be integral with the processor stand alone memory or a combination of both. The memory may include for example removable and non removable memory elements such as Random Access Memory RAM Read Only Memory ROM Flash memory e.g. a Secure Digital SD card a mini SD card a micro SD card magnetic memory optical memory Universal Serial Bus USB memory devices and so forth. In embodiments of the electronic device the memory may include removable Integrated Circuit Card ICC memory such as memory provided by Subscriber Identity Module SIM cards Universal Subscriber Identity Module USIM cards Universal Integrated Circuit Cards UICC and so on.

As shown in and discussed above in the description of the electronic device includes one or more sensors . In embodiments the sensors may comprise gesture sensors that are capable of differentiating the direction of movement of a target . In embodiments the gesture sensors are configured to track the position of a target relative to a point of reference e.g. the center of the sensor itself instead of detecting motion. By tracking the position of a target relative to the center of the sensor it is possible to emulate with some quantization the functionality of a joystick type device such as a joystick thumbstick or D Pad on a gaming controller.

In embodiments as shown in respective ones of the sensors may employ a photosensor photodetector array . The photosensor photodetector array may be configured in a variety of ways. For example the photosensor photodetector array may comprise an array of photosensor diodes e.g. photodiodes phototransistors and so forth. In embodiments the sensors are configured to light reflected off a target to determine the target s position. In the previous example a source of light such as illumination source can be associated with the sensor or another sensor . In implementations the sensors are capable of detecting light and providing a signal in response thereto. Thus a sensor may provide a signal corresponding to the light intensity incident upon each photodetector within the array by converting light into current and or voltage based upon the intensity of the detected light which is then processed by a control circuit to furnish an output that may be interpreted by the processor of the electronic device to furnish control inputs to applications executed by the processor . For example when the sensor is exposed to light multiple free electrons may be generated in the photosensor photodetector array to create a signal comprised of electrical current. The signal may correspond to one or more characteristics of the detected light. For example the characteristics may correspond to but are not necessarily limited to the position of the detected light with respect to the sensor the intensity e.g. irradiance etc. of the light incident upon the sensor how long the light is incident on the sensor an orientation of the light incident upon the sensor and so forth.

The sensors can be configured to detect light in one or both of the visible light spectrum and the near infrared light spectrum. As used herein the term light is used to refer to electromagnetic radiation occurring in the visible light spectrum and or the near infrared light spectrum. For instance as referenced herein the visible light spectrum visible light includes electromagnetic radiation occurring in the range of wavelengths from about three hundred ninety nanometers 390 nm to approximately seven hundred fifty nanometers 750 nm . Similarly as referenced herein the near infrared light spectrum infrared light includes electromagnetic radiation that ranges in wavelength from about seven hundred nanometers 700 nm to three microns 3 m . In implementations Complementary Metal Oxide Semiconductor CMOS fabrication techniques are used to form the photodetector arrays of the sensors .

In implementations respective ones of the sensors are configured to detect gestures in multiple orientations with respect to the orientation of the sensor e.g. right to left left to right top to bottom bottom to top diagonally across the photodetector etc. . Thus the sensor may comprise a multisegmented sensor e.g. a sensor employing a segmented photodetector array that includes an array of individual photodetectors provided in a single package . The sensor may include a lens configured to focus and transmit the light incident on the photodetector array . For example as a target e.g. an object such as a finger of a user s hand passes through the field of view of the segmented photodetector array the target reflects light. The lens is configured to collimate the light incident upon the lens . The collimated light is then furnished to the photodetectors where each individual photodetector may provide a signal that is out of phase with the other photodetectors of the segmented photodetector array as the target passes over the respective individual photodetectors.

In one or more implementations of the present disclosure as shown in the sensor may include a photodetector array that employs one or more microlens which are disposed on the photodetector array over one or more of the photodetectors. The microlens are configured to focus and to transmit light e.g. electromagnetic radiation incident thereon to one or more of the photodetectors. In embodiments a microlens may be coupled with e.g. disposed over a single photodetector to collimate light incident on the microlens onto the photodetector. In other embodiments a microlens may be coupled with e.g. disposed over multiple photodetectors to collimate light incident on the microlens onto the photodetectors. In one or more implementations the microlens may be a glass lens a plastic lens a spherical lens an aspherical lens a Fresnel type lens or the like.

Representative multisegmented sensors suitable for use in implementation of the techniques discussed herein are disclosed in U.S. Published Patent Application No. 2012 0280107 entitled OPTICAL GESTURE SENSOR USING A SINGLE ILLUMINATION SOURCE and or U.S. patent application Ser. No. 14 048 219 entitled GESTURE SENSING DEVICE which are herein incorporated by reference in their entireties.

While the sensors have been described with some specificity as including a number of photodiodes arranged in an array these configurations are provided by way of example only and are not meant to be restrictive of the present disclosure. Thus sensors in accordance with the present disclosure may include but are not necessarily limited to an active pixel sensor e.g. an image sensor including an array of pixel sensors where each pixel sensor is comprised of a light sensor and an active amplifier a Charge Coupled Device CCD a Light Emitting Diode LED reverse biased to act as a photodiode an optical detector that responds to the heating effect of incoming radiation such as a pyroelectric detector a Golay cell a thermocouple and or a thermistor a photoresistor Light Dependent Resistor LDR a photovoltaic cell a photodiode e.g. operating in photovoltaic mode or photoconductive mode a photomultiplier tube a phototube a phototransistor and so forth. Further the sensors described are provided by way of example only and other sensors can be used to detect gestural motions including a proximity sensor that emits a beam of electromagnetic radiation e.g. infrared light and so forth.

As shown in the sensors may include or operate in cooperation with an illumination source configured to generate light e.g. near infrared light and or visible light within a limited spectrum of wavelengths. The illumination source may be used to illuminate an object proximal to the electronic device such as the target allowing the photodetector array of the sensor to more easily and or accurately detect the object. In an implementation the photodetector array of the sensors is configured to detect light e.g. light reflected from an object proximate to the device generated and emitted from the illumination source . Thus the photodetector array may be configured to detect light within a limited spectrum of wavelengths. For example the illumination source may generate a light occurring in a first spectrum of wavelengths and the photodetector array may be configured to detect light only occurring within the first spectrum of wavelengths. In implementations the illumination source may comprise a light emitting diode LED a laser diode a vertical cavity surface emitting laser VCSEL or another type of light source. Although a sensor can detect reflected light from an illumination source associated with the sensor in additional embodiments a first sensor may detect light from an illumination source associated with another sensor .

It should be noted that for the purposes of the present disclosure the term light when used with detect sense convert determine and so forth should not be construed as limited to the detection or conversion of the presence or absence of light e.g. above or below a particular threshold or to detecting or converting a spectrum of wavelengths to a single measurement representative of overall light intensity e.g. irradiance within the spectrum. Thus the detection and or conversion of the presence of light within the context of the present disclosure may be used to refer to detecting and or converting the presence or absence of light e.g. above or below a particular threshold detecting and or converting a spectrum of wavelengths to a single measurement representative of overall light intensity within the spectrum as well as to detecting and or converting multiple frequencies within a range of possible frequencies such as detecting and or converting intensities of radiation separately in two or more subsets of wavelengths within a spectrum as well as for individual frequencies such as colors of light and so forth.

As noted the electronic device includes a display to display information to a user of the electronic device . In embodiments the display may comprise an LCD Liquid Crystal Diode display a TFT Thin Film Transistor LCD display an LEP Light Emitting Polymer or PLED Polymer Light Emitting Diode display an OLED Organic Light Emitting Diode display and so forth which may be configured to display text and or graphical information such as a graphical user interface and so forth. The display can be backlit via a backlight so it can be viewed in the dark or other low light environments.

As shown in the display can be provided with a touchscreen that overlays the display area for entry of data and commands. In embodiments the touch screen can comprise a capacitive touchscreen a resistive touchscreen a surface acoustic wave touchscreen an infrared touchscreen optical imaging touchscreens dispersive signal touchscreens acoustic pulse recognition touchscreens combinations thereof and the like. Capacitive touchscreens can include surface capacitance touchscreens projected capacitance touchscreens mutual capacitance touchscreens and self capacitance touchscreens. In implementations the touchscreen is configured with hardware to generate a signal to send to a processor and or driver upon detection of a touch input and or a hover input. As indicated herein touch inputs include inputs gestures and movements where the input e.g. a finger of the user contacts the screen . Hover inputs include inputs gestures and movements where the input does not contact the screen but are detected proximal to the screen .

The electronic device may further include one or more Input Output I O devices e.g. buttons a keypad and so on . In an implementation the sensors may be configured as a further I O device . For example one or more of the sensors may detect light representing gestures corresponding to a desired operation associated with the electronic device . Additionally the I O devices may comprise one or more audio I O devices such as a microphone speakers and so on.

The electronic device may include a communication module representative of communication functionality to permit electronic device to send receive data between different devices e.g. components peripherals and or over one or more networks. Communication module may be representative of a variety of communication components and functionality including but not necessarily limited to an antenna a browser a transmitter and or a receiver a wireless radio a data port a software interface and or a driver a networking interface a data processing component and so forth. The one or more networks are representative of a variety of different communication pathways and network connections which may be employed individually or in combination to communicate among the components of the electronic device . Thus the one or more networks may be representative of communication pathways achieved using a single network or multiple networks. Further the one or more networks are representative of a variety of different types of networks and connections that are contemplated including but not necessarily limited to the Internet an intranet a satellite network a cellular network a mobile data network wired and or wireless connections and so forth.

Examples of wireless networks include but are not necessarily limited to networks configured for communications according to one or more standard of the Institute of Electrical and Electronics Engineers IEEE such as 802.11 or 802.16 Wi Max standards Wi Fi standards promulgated by the Wi Fi Alliance Bluetooth standards promulgated by the Bluetooth Special Interest Group a 3G network a 4G network an LTE network and so on. Wired communications are also contemplated such as through USB Ethernet serial connections and so forth. The electronic device through functionality represented by the communication module may be configured to communicate via one or more networks to receive various content from one or more content repositories e.g. an Internet provider a cellular data provider etc. . A variety of content may be communicated examples of which include but are not necessarily limited to web pages gaming applications applications services music photographs video email service instant messaging device drivers instruction updates and so forth.

The portable electronic device is further illustrated as including functionality to determine position. For example the mobile electronic device can receive signal data transmitted by one or more position data platforms and or position data transmitters examples of which include the Global Positioning System GPS satellites. More particularly the portable electronic device can include a GPS module that can manage and process signal data received from GPS satellites via a GPS receiver. The position determining module is representative of functionality operable to determine a geographic position through processing of the received signal data. The signal data can include various data suitable for use in position determination such as timing signals ranging signals ephemerides almanacs and so forth.

The GPS module can also be configured to provide a variety of other position determining functionality. Position determining functionality for purposes of discussion herein can relate to a variety of different navigation techniques and other techniques that can be supported by knowing one or more positions. For instance position determining functionality can be employed to provide position location information timing information speed information and a variety of other navigation related data. Accordingly the GPS module can be configured in a variety of ways to perform a wide variety of functions. For example the GPS module can be configured for outdoor navigation vehicle navigation aerial navigation e.g. for airplanes helicopters marine navigation personal use e.g. as a part of fitness related equipment and so forth. Accordingly the GPS module can include a variety of devices to determine position using one or more of the techniques previously described.

The GPS module for instance can use signal data received via the GPS receiver in combination with map data that is stored in the memory to generate navigation instructions e.g. turn by turn instructions to an input destination or Point of Interest POI show a current position on a map and so on. The GPS module can include one or more antennas to receive signal data as well as to perform other communications such as communication via one or more networks described in more detail above. The GPS module can also provide other position determining functionality such as to determine an average speed calculate an arrival time and so on.

Although a GPS system is described and illustrated in relation to it should be apparent that a wide variety of other positioning systems can also be employed such as other global navigation satellite systems GNSS terrestrial based systems e.g. wireless phone based systems that broadcast position data from cellular towers wireless networks that transmit positioning signals and so on. For example positioning determining functionality can be implemented through the use of a server in a server based architecture from a ground based infrastructure through one or more sensors e.g. gyros odometers and magnetometers use of dead reckoning techniques and so on.

The portable electronic device can further include a motion sensor module that represents functionality to determine various manual manipulation of the device . The motion sensor module can be configured in a variety of ways to provide signals to enable detection of different manual manipulation of the portable electronic device including detecting orientation motion speed impact and so forth. For example the motion sensor module is representative of various components used alone or in combination such as an accelerometer gyroscope velocimeter capacitive or resistive touch sensor and so on.

The portable electronic device can include an integrated camera that is configured to capture media such as still photographs and or video by digitally recording images using an electronic image sensor. Media captured by the camera can be stored as digital image files in memory and or sent to a processor for interpretation. In embodiments the digital image files can be stored using a variety of file formats. For example digital photographs can be stored using a Joint Photography Experts Group standard JPEG file format. Other digital image file formats include Tagged Image File Format TIFF Raw data formats and so on. Digital video can be stored using a Motion Picture Experts Group MPEG file format an Audio Video Interleave AVI file format a Digital Video DV file format a Windows Media Video WMV format and so forth. Exchangeable image file format Exif data can be included with digital image files to provide metadata about the image media. For example Exif data can include the date and time the image media was captured the location where the media was captured and the like. Digital image media can be displayed by the display and or transmitted to other devices via a network e.g. via an email or MMS text message .

The electronic device may employ an operating system which is storable in memory and executable by the processor . The operating system is representative of functionality to control operation of the electronic device and facilitate execution of applications by the processor . The applications may comprise software storable in memory and executable by the processor e.g. to perform a specific operation or group of operations to furnish functionality to the electronic device . Example applications include cellular telephone applications instant messaging applications email applications gaming applications navigation map applications and so forth.

The operating system includes a user interface . The user interface is representative of functionality to control the display of information and data to the user of the electronic device via the display . In some implementations the display may not be included as a part of the electronic device and may instead be connected externally using USB Ethernet serial connections and so forth. The user interface may provide functionality to allow the user to interact with one or more applications of the electronic device by providing inputs via the I O devices . For example the user interface may cause an Application Programming Interface API to be generated to expose functionality to an application to configure the application for display by the display or in combination with another display. In embodiments the API may further expose functionality to configure the application to allow a user to interact with an application by providing inputs via the I O devices . For example a user may provide hand gestures proximate to the sensors corresponding to a desired operation associated with an application . For instance as discussed herein below a user may use a thumb of his her hand to perform touchless joystick operations over a sensor to control indicia e.g. a gaming character displayed via the display by a gaming application may perform a finger swipe proximate to the sensor to transition between various display pages showing various applications within the display and so forth.

As shown in the electronic device may include a gesture recognition module . In the illustrated embodiment the gesture recognition module is depicted as a software application that is storable in memory and executable by the processor . However it is contemplated that the gesture recognition module or portions thereof can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. The gesture recognition module represents functionality to track and or to recognize an attribute such as a gesture performed within the field of view of one or more of the sensors . The gesture recognition module is also configured to recognize the type of gesture performed.

As discussed herein the sensors are configured to detect a target e.g. a thumb or a finger of a hand of a user of the electronic device at a distance from the sensor and provide a signal in response thereto. The gesture recognition module includes functionality to determine the position of the target relative to a point of reference based on the signal. In embodiments the point of reference may comprise a center of the sensor as shown in . However the point of reference may be any chosen point of reference. For example it is contemplated that the point of reference may be other points on the face of the sensor other points on or within the housing e.g. on the front surface back surface sides or ends of the portable electronic device a point in space proximal to the portable electronic device and so forth. The point of reference for a sensor may vary based on whether it is synchronized with another sensor. For example a center of a sensor may be used when the sensor is operating independently while a mid point between two sensors is used when the sensors is operating with another sensor.

The gesture recognition module may further include functionality to track motion of the target e.g. a thumb or a finger of a user s hand based on changes in the determined position relative to the point of reference. In embodiments motion of a target may be tracked in two dimensions e.g. parallel to the front surface back surface sides or ends of the housing of the portable electronic device or in three dimensions e.g. parallel and or perpendicular to the front surface back surface sides or ends of the housing .

In embodiments the gesture recognition module includes functionality to synchronize one or more of the sensors shown in with others of the sensors to allow one sensor to receive data from another sensor . This synchronization may be used to augment the position and or motion detection functionality and generation of the joystick control input by adding functionality such as stereoscopy or triangulation to improve the overall performance of the device . In further embodiments different functions are accessed depending on whether the sensors are synchronized.

In embodiments the gesture recognition module employs synchronization to implement a touchless optical mouse input with the target being a touchless variant of a mouse cursor displayed by the display . When coupled with a secondary touchless joystick control input as described below this touchless optical mouse input can be used to emulate a WASD mouse input which may be provided to and used by one or more of the applications e.g. a gaming application .

The electronic device may include a joystick type control module . The joystick type control module which in embodiments may be part of the gesture recognition module or which may be a separate module includes functionality to cause the determined position of the target which may be a thumb or a finger of a hand of a user of the electronic device to be processed to furnish a touchless joystick control input e.g. one of a D pad control input or a joystick control input to the operating system user interface and or other applications of the electronic device which may be executed by the processor of the electronic device . In embodiments such as the embodiment illustrated in sensors are positioned proximate to the ends of the housing on either side of the display .

In embodiments the joystick type control module may include functionality to furnish in combination with the configuration of sensors described in the discussion of touchless joystick control inputs used in tandem with swipe based gesture sensor inputs e.g. swipe up across pinch etc. which may be furnished by the gesture recognition module . For example the joystick type control module represents functionality that causes one sensor to detect the position of a first target e.g. a thumb of the hand of a user used to furnish a joystick input while the gesture recognition module represents functionality that detects the motion of a second target e.g. a finger of the hand of a user used to furnish a hand swipe . These inputs may be but need not be concurrent and the sensor may be configured to switch between two operating modes based upon either a user command or based upon the context of the input.

In this manner differentiation of gestures based upon actions performed over one sensor versus actions performed over multiple sensors may be furnished. For example a gesture performed over across a first e.g. left or bottom sensor only can be interpreted differently by the gesture recognition module from the same gesture performed over across a second e.g. right or top sensor or both sensors . Moreover differentiation of gestures by the gesture recognition module can be combined with tandem usage of swipe gestures and position tracking e.g. to furnish joystick control inputs into complex gestures.

In the illustrated embodiment the joystick type control module is depicted as a software application that is storable in memory and executable by the processor . However it is contemplated that the joystick type control module or portions thereof can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations.

As noted in embodiments the sensors may comprise a multisegmented proximity sensors or gesture sensors that are capable of differentiating the direction of a signal. The joystick type control module provides functionality to track the position of the target e.g. a thumb or a finger of a hand of a user of the electronic device . As noted the joystick type control module may furnish functionality to track the position of the target relative to a point of reference such as the center of a sensor e.g. a point on the outer face of a sensor at the center .

In embodiments the volume of space over one or more sensors is divided into at least two distinct regions. For example in embodiments a volume of space over a sensor is divided into a number N of distinct regions wherein N is the number of unique directional channels in the sensor. illustrates an example volume of space over a sensor of the electronic device shown in wherein the volume is divided into four 4 regions. In the embodiment shown the four regions comprise quadrants located at cardinal directions with respect to the center of the sensor e.g. a North region an East Region a South region and a West region . In other embodiments the volume of space may have twice the number 2N distinct regions with the extra regions being defined as the overlaps of two neighboring regions. illustrates an example volume of space over a sensor of the electronic device shown in wherein the volume is divided into eight 8 regions. In the embodiment shown the eight regions comprise octants located at cardinal directions with respect to the center of the sensor e.g. a North region a Northeast region an East Region a Southeast region a South region a Southwest region a West region and a Northwest region . In further embodiments the volume of space over a one dimensional sensor may be divided into only two regions such as for example East and West or North and South.

In embodiments the position of the target can be determined relative to a zero axis defined with respect to the center of the sensor . show each embodiment respectively. illustrates an example volume of space over a sensor of the electronic device shown in wherein the position of the target is determined relative to a zero axis defined with respect to the center of the sensor . For example a polar coordinate system may be defined where the zero axis is positioned at an angle of zero 0 degrees with angles measured counterclockwise e.g. ninety 90 degrees one hundred eighty 180 two hundred seventy 270 degrees and so on.

The joystick type control module includes functionality to determine the position of the target by determining that the target is positioned in a first region of the at least two regions based on the signal received from one or more of the sensors . The joystick type control module may further include functionality to track movement of the target based on determining that the target is moved from the first region to a second region of the at least two regions based on the signal received from one or more of the sensors . Thus one or more sensors may track the position of a target emulating the function of a joystick type input device on a conventional gaming controller. In this manner a user can manipulate his her finger or thumb as if he she was operating a joystick but without physically contacting the sensor.

For example a sensor may detect the presence of a user s thumb positioned in the East Region of the volume of space over the sensor as shown in and output a signal characteristic of the detection of a target in this position. The joystick type control module may process the signal and furnish a signal e.g. to an application the operating system etc. that is equivalent to a thumbstick or D pad controller being pulled to the right.

Similarly a sensor may detect the presence of a user s thumb positioned in the Southwest Region of the volume of space over the sensor as shown in and output a signal characteristic of the detection of a target in this position. The joystick type control module may process the signal and furnish a signal e.g. to an application the operating system etc. that is equivalent to a thumbstick being pulled to the bottom left.

In a further example a sensor may detect the presence of a user s thumb as a continuous position with respect to the center of the sensor with the position of the target being reported as an angle relative to a zero axis as shown in . In this manner the distance of the target from the point of reference the center of the sensor may be distinguished allowing for granularity in the position determination by the joystick type control module such as how far the joystick or thumbstick is pulled. 

The outputs of the gesture recognition module and or the joystick type control module as described herein can be used in conjunction with the sensors to furnish touchless control inputs for a variety of applications that may be implemented by the electronic device e.g. stored in memory and executed by processor . For example as discussed the gesture recognition module and or the joystick type control module can provide control inputs that simulate one dimensional 1D controls such as a button or switch two dimensional 2D controls such as a D pad controller or thumbstick three dimensional 3D controls such as a clickable thumbstick to a gaming application for manipulation or control of indicia that is caused to be displayed by the application . In embodiments such gaming applications may employ other inputs such as touch inputs from the touchscreen inputs from I O devices orientation tilt motion inputs from the motion sensor module and so forth which may be used in conjunction with the control inputs furnished by the gesture recognition module and or the joystick type control module to furnish integrated control of the gaming environment. However it should be recognized that the control inputs furnished by the gesture recognition module and or the joystick type control module can be used by a variety of applications which are not necessarily gaming applications . For example the gesture recognition module and or the joystick type control module can provide control inputs for manipulating a map or moving map that is caused to be displayed by a navigation or mapping application which may also employ location position information received from the GPS module communication module and so forth. Similarly the gesture recognition module and or the joystick type control module can provide control inputs for manipulating the user interface of the operating system to for example place receive telephone calls send receive text messages manipulate send receive organize email manipulate Internet content e.g. webpages and other content control camera applications that control operation of the camera e.g. control zoom focus edit tag etc. edit documents spreadsheets databases manipulate content such as audio or video content stored in memory e.g. stored music movies audiobooks etc. or received via the communication module streamed music movies audiobooks etc. and so forth. A variety of other applications are possible.

Generally any of the functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. The terms module and functionality as used herein generally represent software firmware hardware or a combination thereof. The communication between modules in the electronic device of can be wired wireless or some combination thereof. In the case of a software implementation for instance the modules represent executable instructions that perform specified tasks when executed on a processor such as the processor of the electronic device of . The software program code can be stored in one or more tangible device readable storage media an example of which is the memory associated with the electronic device of .

The following discussion describes methods that may be implemented in an electronic device for furnishing a touchless joystick type controller. Aspects of the methods may be implemented in hardware firmware or software or a combination thereof. The methods are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference may be made to the electronic device of . The features of techniques described below are platform independent meaning that the techniques may be implemented on a variety of commercial electronic device platforms having a variety of processors.

The signal from the sensor in response to the sensor detecting a target within a field of view of the sensor is received Block and processed to determine a position of the target relative to a point of reference based on the signal Block . For example as described in the discussion of a position of the target relative to a point of reference e.g. the center of a sensor is then determined based on the signal. Motion of the target may be tracked based on changes in the determined position relative to the point of reference.

In embodiments the volume of space over one or more sensors is divided into at least two distinct regions. For example in the embodiment shown in a volume of space over a sensor is divided into a number N of distinct regions wherein N is the number of unique directional channels in the sensor. In other embodiments as shown in the volume of space may have twice the number 2N distinct regions with the extra regions being defined as the overlaps of two neighboring regions. In further embodiments the volume of space over a one dimensional sensor may be divided into only two regions such as for example East and West or North and South. In additional embodiments the position of the target can also be determined relative to a zero axis defined with respect to the center of the sensor. The position of the target may be ascertained by determining that the target is positioned in a first region of the at least two regions based on the signal received from one or more of the sensors .

A joystick type control input may then be provided based on the determined position Block . For example a sensor may detect the presence of a user s thumb positioned in the West Region of the volume of space over the sensor as shown in and output a signal characteristic of the detection of a target in this position. The signal may be processed to furnish a signal e.g. to an application the operating system etc. that is equivalent to a thumbstick or D pad controller being pulled to the left. Similarly a sensor may detect the presence of a user s thumb positioned in the Northeast Region of the volume of space over the sensor as shown in and output a signal characteristic of the detection of a target in this position. The signal may be processed to furnish a signal e.g. to an application the operating system etc. that is equivalent to a thumbstick being pulled to the top right. In a further example a sensor may detect the presence of a user s thumb as a continuous position with respect to the center of the sensor with the position of the target being reported as an angle relative to a zero axis as shown in . In this manner the distance of the target from the point of reference the center of the sensor may be distinguished allowing for granularity in the position determination by the joystick type control module such as how far the joystick or thumbstick is pulled. This for example can permit fine motor control sufficient for use with a gaming application. In embodiments an attribute is determined based on the position from the sensor signal and a function is provided that corresponds to the attribute e.g. a gesture.

Although the subject matter has been described in language specific to structural features and or process operations it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

