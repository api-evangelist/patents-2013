---

title: System and method for efficient swap space allocation in a virtualized environment
abstract: A technique for efficient swap space management creates a swap reservation file using thick provisioning to accommodate a maximum amount of memory reclamation from a set of one or more associated virtual machines (VMs). A VM swap file is created for each VM using thin provisioning. When a new block is needed to accommodate page swaps to a given VM swap file, a block is removed from the swap reservation file and a block is added to the VM swap file, thereby maintaining a net zero difference in overall swap storage. The removed block and the added block may be the same storage block if a block move operation is supported by a file system implementing the swap reservation file and VM swap files. The technique also accommodates swap space management of resource pools.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09524233&OS=09524233&RS=09524233
owner: VMware, Inc.
number: 09524233
owner_city: Palo Alto
owner_country: US
publication_date: 20130305
---
Virtualized computing environments provide tremendous efficiency and flexibility for systems operators by enabling computing resources to be deployed and managed as needed to accommodate specific applications and capacity requirements. As virtualization systems mature and achieve broad market acceptance demand continues for increased consolidation of virtual machines VMs on host server systems to enable on going efforts to reduce operating costs. Over commitment of resources such as memory and processing resources enables a high degree of consolidation. Process migration from a source host server system to a target host server system is a key feature that enables flexibility in managing rapidly growing numbers of VMs within virtualized computing environments. VMware s vMotion product enables process migration between host server systems.

A host virtualization system commonly known as a hypervisor an example of which is VMware s ESX Server product executes on a host server system to manage resident VMs and to provide certain services to the resident VMs such as managing host server system resources for each VM. For example a VM that executes as a guest on the hypervisor may be configured to present a guest physical memory space to a guest operating system. To the guest operating system the guest physical memory space may be indistinguishable from a memory space provided by physical machine memory such as a physical memory subsystem comprising dynamic random access memory DRAM . However each guest physical memory space is actually a distinct virtual memory space that is assigned to a corresponding VM and managed by the host virtualization system. At least a portion of a given guest physical memory space may be mapped to and reside within host physical memory machine memory . Each guest physical memory space is typically backed to a swap file within a file system provided by the host virtualization system. The file system may reside within a mass storage system coupled to the host server system. Because other processes may allocate space on the mass storage system each swap file is pre allocated to avoid swap failure. The swap file is conventionally pre allocated using thick provisioning to accommodate swapping of all unreserved guest physical memory where the unreserved guest physical memory represents the physical memory allocated to the VM in excess of the physical memory reserved for that VM.

Each guest physical memory space typically resides within a corresponding swap file with at least a portion of the guest physical memory space mapped to and residing within machine memory. The host server system implements memory over commitment when configured to execute a set of VMs having a total guest physical memory space that is larger than available machine memory. To manage guest physical memory usage for a given VM memory entitlement parameters are typically applied to the VM. Memory entitlement parameters include a memory reservation that reserves a minimum machine memory space for the VM a memory limit that sets a maximum machine memory usage for the VM and a memory share for setting priority of machine memory usage between VMs. These entitlement parameters may also be applied to a resource pool RP e.g. a pool of hardware resources made available by a cluster of host server systems to control memory entitlements for the resource pool sibling VMs within the RP or sibling RPs. Guest physical memory size is a memory entitlement parameter that indicates an amount of guest physical memory space for a VM. Guest physical memory size conventionally determines the size of a corresponding swap file used to back the guest physical memory.

The hypervisor employs a strict admission control policy to ensure that the total of all memory reservations for all executing VMs does not exceed available physical system memory. To enforce this policy the hypervisor does not over commit the memory reservation entitlement parameter. The hypervisor also determines and reserves swap space required to back all unreserved guest physical memory for a given VM. If the VM s guest physical memory size or memory reservation entitlement parameters change the hypervisor re computes swap space requirements and may expand a given swap space to ensure that each powered on VM always has adequate backing store space in either machine memory or an associated swap file. In certain settings the hypervisor may be configured to store each VM guest physical memory space in a different swap file for greater efficiency during process migration and for data isolation between VMs.

Although a swap file or a collection of swap files may be conventionally configured to pre allocate adequate backing store capacity for the combined VM s guest physical memory space such conventional techniques require significant storage capacity leading to storage and process migration inefficiencies. Therefore what is needed in the art is a more efficient technique for managing swap space in a virtualized environment.

One or more embodiments disclosed herein provide methods for managing swap file capacity within a computing system having a plurality of virtual machines VMs each with guest physical memory backed by machine memory of the computer system and a corresponding thinly provisioned VM swap file.

A method for swapping out contents of a page of guest physical memory from the machine memory to a thinly provisioned VM swap file according to one embodiment includes the steps of determining that the thinly provisioned VM swap file needs additional capacity to store the contents of the page moving a storage block from a thickly provisioned swap reservation file to the VM swap file and storing the contents of the page to the moved storage block.

A method for swapping out contents of a page of guest physical memory from the machine memory to a thinly provisioned VM swap file according to another embodiment includes the steps of determining that the thinly provisioned VM swap file needs additional capacity to store the contents of the page allocating a storage block to the thinly provisioned VM swap file from a pool of free storage blocks storing the contents of the page to the allocated storage block and deleting a storage block from a thickly provisioned swap reservation file.

Further embodiments of the present invention include without limitation a non transitory computer readable storage medium that includes instructions that enable a computer system to implement one or more aspects of the above methods as well as a computer system configured to implement one or more aspects of the above methods.

Mass storage system comprises one or more underlying storage media devices such as magnetic hard disk drives solid state drives or any suitable mass storage media devices that provide persistent storage. Mass storage system may present a networked file system or a block based unit of storage such as a storage area network SAN logical unit number LUN which may then be used to generate a file system by host server system .

Interconnect couples host server system to mass storage system enabling communication. Interconnect may implement Ethernet Fibre Channel FC serial attached small computer systems interconnect SAS serial attached advanced technology attachment SATA or any other technically feasible data networking technology. Interconnect may implement direct attachment packet switching packet routing or any combination thereof and may comprise one or more physically distinct devices.

A portion of data residing in guest physical memory may be mapped to allocated machine memory which comprises a portion of machine memory residing within host server system . A memory reservation establishes a minimum capacity of allocated machine memory for a given VM . At least a portion of data residing in guest physical memory in excess of the memory reservation may be mapped to VM swap file residing in mass storage system . Swap space isolation is achieved by maintaining a separate VM swap file per VM .

When sufficient machine memory capacity is available all guest data comprising guest physical memory for a given VM may reside entirely within allocated machine memory . When total guest physical memory for all executing VMs exceeds total machine memory capacity of host server system then host server system is over committed for memory and at least a portion of guest physical memory data is stored within one or more VM swap files . Guest physical memory associated with each VM is organized as a plurality of pages residing in allocated machine memory a corresponding VM swap file or a combination thereof. A given page may be swapped between allocated machine memory and the corresponding VM swap file. In the embodiments described herein a swap reservation file is also used to reserve storage for VM swap files associated with a given host server system . It should be recognized that page swapping may also occur in situations where host server system is not over committed for memory e.g. when the size of a VM s allocated memory space is greater than an upper limit on the memory size that has been pre defined for that VM.

Swap reservation file is allocated using thick provisioning which results in storage of a predetermined capacity reserved within mass storage system . This capacity may be increased as needed assuming additional space is available within mass storage system by expanding swap reservation file . Each VM swap file on the other hand is implemented using thin provisioning such that storage space is allocated as data is written to the VM swap file. It should be recognized that in a conventional setting this form of on demand allocation is not suitable for swap files because additional on demand capacity within mass storage system may not be available when needed to write a page to the VM swap file. A failed page swap resulting from such situations may cause an associated VM to catastrophically fail. Embodiments of the present invention ensure available capacity via thick provisioning of swap reservation file which is allocated to accommodate at least a total swap capacity for the operation of all VMs associated with a given host server system.

Two different embodiments are discussed in greater detail below regarding the use of the storage capacity of swap reservation file by the individual swap files of VMs . In one embodiment a host file system accommodates the moving of allocated blocks between swap reservation file and individual thinly provisioned VM swap files . In a second embodiment where moving of a block between files is not accommodated by the host file system individual thinly provisioned VM swap files are allocated blocks from a free pool and swap reservation file is shrunk in size by the same amount.

The sizing of swap reservation file is now described using Equations 1 5 shown below. Each VM swap file requires at most a size Sdefined as a difference between guest physical memory size Sand a memory reservation size S for a corresponding VM as given below in Equation 1. Eq. 1 

Prior to execution the VM is allocated a portion of machine memory equal to the memory reservation size and a corresponding VM swap file is configured using thin provisioning to have a file size defined by Equation 1. In many practical usage scenarios actual swap space required by the VM is a fraction of guest physical memory size . When sufficient machine memory is available actual swap space required by the VM may be zero. During normal operation of the VM if guest physical memory utilization exceeds a memory reservation size for the VM then additional machine memory is allocated to the VM if available. If the additional machine memory is not available pages of guest physical memory are swapped out and stored within the VM swap file to free up the needed space in machine memory.

One property of memory allocation for virtualization software is that total virtualization overhead S plus kernel overhead S plus user overhead S is configured to be less than available total machine memory or a size of physical random access memory S available to virtualization software . This property is stated below in Equation 2. 

If the VMs are not over committed in memory see and none of the VM s have pre defined memory size limits that are smaller than their actual memory allocation swap reservation file does not need to be provisioned otherwise swap reservation file is provisioned to accommodate all memory requirements beyond available guest physical memory see . This sizing policy for swap reservation file is expressed below in Equation 3. Here swap reservation file is sized according to S which is referred to herein as a swap reservation with over commitment SROC . MAX 0 Eq. 3 

It should be recognized that the total memory reservation for all VMs P is bounded by Sand given below in Equation 4 as a sum of individual VM memory reservations S . Summation index i refers to a particular VM. Eq. 4 

Equation 4 is enforced by virtualization software by guaranteeing the availability of sufficient free machine memory for a memory reservation of S i as a condition of powering ON a new VM.

In addition total guest physical memory S from Equation 3 is defined below in Equation 5 as a sum of guest physical memory sizes S i for corresponding VMs. Eq. 5 

As described previously to guarantee swap capacity for all VMs in cases where total guest physical memory exceeds available machine memory swap reservation file is configured using thick provisioning. When a VM swap file needs additional space a block is moved from swap reservation file to the VM swap file to accommodate the additional space needed for saving the contents of one or more pages being reclaimed from allocated machine memory . In the example given herein block is first moved via move operation from swap reservation file to VM swap file to provide storage capacity for page . After block is added to VM swap file write operation may be executed to store the contents of page to a page within block . In one embodiment the block move operation is implemented by modifying the metadata of the swap reservation file and the VM swap file such that a pointer to the moved block is deleted from the metadata of the swap reservation file and added to the metadata of the VM swap file.

Under certain circumstances a block of storage may be moved back from VM swap file to swap reservation file . For example over time blocks within swap file may become fragmented as a result of certain pages being invalidated. In such cases pages may be compacted from one set of blocks into a smaller set of blocks thereby freeing certain blocks. The freed blocks may be returned to swap reservation file .

It should be recognized that swap reservation file may be allocated to include additional blocks of storage to account for allocation granularity differences between pages and blocks. For example if each of four total VMs needs a maximum of one page of storage for their corresponding VM swap file then swap reservation file would be configured with a single block. However the first VM swap file to receive the one block would starve the other VM swap files. In such a scenario and in general an additional block may be allocated per VM within swap reservation file to account for granularity differences between a block and a page.

Method begins in step where the virtualization software determines that one or more pages of allocated machine memory associated with a VM should be reclaimed and the contents therein stored within the VM s swap file. Pages of machine memory may be reclaimed to accomplish a variety of system goals and in response to various system events and operating conditions. For example pages of machine memory may be reclaimed in preparation of powering on a new VM to reduce machine memory utilization or in preparation for process migration. Furthermore different reclamation techniques may be implemented such as ballooning explicit swapping and the like. Various reclamation goals and techniques may be implemented without departing the scope and spirit of the present invention.

If in step the VM swap file needs additional space to accommodate the pages to be reclaimed then the method proceeds to step . In step the virtualization software requests that one or more blocks within the swap reservation file be moved to the VM swap file. In one embodiment the storage capacity of the moved blocks corresponds to at least the amount of storage required to store the pages of allocated machine memory. It should be recognized that as a result of the move operation the metadata of the VM swap file and the metadata of the swap reservation file are updated such that a pointer to the moved block is added to the metadata of the VM swap file and deleted from the metadata of the swap reservation file. In step the virtualization software writes the contents of the pages to be reclaimed to the VM swap file. The method terminates in step . Returning to step if the VM swap file does not need additional space then the method proceeds directly to step .

Method requires an underlying file system to support thick provisioning and thin provisioning as well as a block move operation to move storage blocks between the swap reservation file and one or more VM swap files. VMware s Virtual Machine File System VMFS is one example of a commercial file system that supports moving storage blocks between files. Specifically VMFS includes a set of application programming interfaces APIs to enable explicit block move operations between files.

When the swap storage requirements for a VM shrink one or more blocks may be moved from the VM swap file back to the swap reservation file. Swap storage requirements may shrink for various reasons such as pages being released from use by an application or when pages are swapped out of the VM swap file and back into allocated machine memory. One challenge in moving a block from the VM swap file to the swap reservation file is that the block generally becomes internally fragmented by finer grain page access to the block. Normal paging activity may result in a given block storing some pages that actually back guest physical memory some other pages that have been swapped back into allocated machine memory and some pages that have been released and are no longer valid. It should be recognized that only a block that is backing no pages of guest physical memory may be moved from the VM swap file to the swap reservation file. Normal paging activity may cause a plurality of blocks to become sufficiently fragmented that an equivalent storage space of one or more entire blocks is unnecessary and represents an overall loss of swap space. To avoid a situation where fragmented blocks create an effective loss of overall swap space the virtualization software executes block compaction either as a continuous process or in response to implementation dependent triggers. Block compaction comprises copying pages of backed guest physical memory in a source block to a target block for consolidation within the VM swap file. Copied pages may be marked invalid within the source block. Once no valid pages reside within the source block the source block may be moved back to the swap reservation file. At this point pages within the source block are no longer available for swapping however a new block may be moved from the swap reservation file and allocated to the VM swap file if additional pages need to be subsequently saved to the VM swap file.

While certain file systems such as VMware s VMFS file system support file block move operations for moving blocks from one file to another file some file systems may not support this operation. For example network file system NFS does not have support for file block move operations. An alternative embodiment that does not require file block move operations is described below in conjunction with .

In the example described herein when a VM swap file needs additional space to save the contents of page block is allocated to the VM swap file from a file system free pool which may be implemented as a bitmap of free blocks of storage. After block is allocated write operation may be executed to store the contents of page to a page allocated within block . If write operation succeeds a block e.g. block is returned to file system free pool from swap reservation file as a result of which the size of swap reservation file decreases by one block.

If file system free pool is empty when VM swap file needs an additional block an existing block within swap reservation file is allocated to store page . In the example described herein block is allocated to store page and metadata for page within a corresponding page directory is updated to indicate that page is residing within swap reservation file rather than VM swap file .

As described previously in VM swap file may be compacted to free one or more blocks of storage and the size of swap reservation file increased accordingly. In addition swap reservation file may be allocated to include additional blocks of storage to account for allocation granularity differences between pages and blocks.

Method begins in step where the virtualization software determines that one or more pages of allocated machine memory associated with a VM should be reclaimed and the contents therein stored in the VM s swap file. Pages of machine memory may be reclaimed to accomplish a variety of system goals and in response to various system events and operating conditions. For example pages of machine memory may be reclaimed in preparation of powering on a new VM to reduce machine memory utilization or in preparation for process migration. Furthermore different reclamation techniques may be implemented such as ballooning explicit swapping and the like. Various reclamation goals and techniques may be implemented without departing the scope and spirit of the present invention.

In step the virtualization software attempts to write the contents of the reclaimed pages to the VM swap file. It should be recognized that because the VM swap file was created using thin provisioning within the mass storage system new blocks would be added to the VM swap file on an as needed basis from file system free pool . There is however no guarantee that a write attempt will succeed because the file system free pool may be empty i.e. mass storage system is full when the write attempt is actually performed and there may be no free pages within the VM swap file.

If in step the write attempt to the VM swap file succeeded then the method proceeds to step where the virtualization software determines whether or not the VM swap file had to be provisioned additional blocks for the write. If in step it is determined that more space had to be provisioned for the write the method proceeds to step where the virtualization software instructs the mass storage system to release a corresponding number of blocks in the swap reservation file. If in step it is determined more space was not provisioned for the write the method terminates in step .

Returning to step if the write attempt to the VM swap file does not succeed then the method proceeds to step where the virtualization software writes the contents of reclaimed machine memory pages to an available block in the swap reservation file and updates the metadata for the reclaimed pages to indicate that the pages are residing within the swap reservation file rather than the VM swap file. Accordingly when a VM is migrated the swap state of the pages of the VM s guest physical memory are checked to locate the page in machine memory an associated VM swap file or the swap reservation file to ensure all pages of VM s guest physical memory are migrated.

A bottom up traversal of the resource pool graph may be used to determine a swap reservation file requirement for root node from swap reservation limits of all of its child nodes where a swap reservation limit for a node represents the maximum amount of reclaimable machine memory for that node. The bottom up traversal computes swap reservation limits for leaf nodes then each parent of a leaf node and so forth until a swap reservation limit may be computed for the root node based on swap reservation limits for all the child nodes of the root node. At each node a swap reservation limit is computed according to method discussed below in . The swap reservation limit for the root node represents a maximum amount of reclaimable machine memory for the corresponding RP.

Method begins in step where the virtualization software determines that a swap reservation limit SRL should be calculated for the RP. A swap reservation limit SRL for a root node of an RP defines the RP s contribution to the size of the swap reservation file. The SRL for the RP may need to be calculated for various reasons. For example the SRL for an RP may be calculated in response to the virtualization software determining that swap reservation file needs to be resized. This may occur for example when new VMs are powered on or powered off or when memory entitlement parameters are changed. If in step the selected RP node is a VM node then the method proceeds to step .

If in step the VM node has an enforced memory limit ML attribute then the method proceeds to step where a swap reservation limit SRL is set to a guest physical memory size GMS for the VM node minus the ML attribute for the VM node. Having calculated the SRL for the RP node method terminates in step .

Returning to step if the VM node does not have an enforced ML then the method proceeds to step where SRL is set to zero. Having set the SRL for the RP node method terminates in step .

Returning to step if the selected RP node is not a VM node then the method proceeds to step . If in step the RP node has an enforced resource pool memory limit RPML attribute then the method proceeds to step where the SRL is set to the RPML.

Returning to step if the RP does not have an enforced RPML then the method proceeds to step where the SRL is set to a sum of child node SRLs. Child node SRL values may be recursively computed using a bottom up tree traversal of child RP nodes.

Method may be recursively executed on an arbitrary RP node tree or sub tree to compute a corresponding SRL.

Method begins in step where the virtualization software determines that the size of a swap reservation file such as swap reservation file should be calculated. This may occur for example when a VM is powered on or powered off or when a memory entitlement changes for a VM or RP. In step the virtualization software calculates using method an SRL for the root RP which is at the root of every VM node and user created RP node. In step the virtualization software calculates an SROC for the host server system. The SROC for the host server system is given by Equation 3. In step the virtualization software determines the size of the swap reservation file as the maximum of the root RP s SRL calculated in step and the SROC calculated in step . In one embodiment additional blocks may be allocated to the swap reservation file to account for allocation granularity differences between file block size and guest physical memory page size. Method terminates in step .

In certain alternative embodiments two or more mass storage systems are used as data stores to back guest physical memory for VMs residing on the same host server system . In such embodiments a swap reservation file is created within each of the two or more mass storage systems to act as a block reservation pool for VM swap files residing on the same mass storage system.

Techniques for optimizing the size of one swap reservation file in conjunction with plural VM swap files were described above in configurations having one data store for VM swap files and swap reservation file . These techniques may be generalized for configurations having multiple data stores such that there is a swap reservation file per data store. In such a system for each VM v linked to a given data store the reclaimable memory associated with that VM is computed as the difference between the VM s guest physical memory size S v and a machine memory reservation for that VM S v . The swap reservation size for each data store is then computed as MIN Eq. 6 where SR swap reservation computed at the root group of the resource tree computed by considering only those VMs which are linked to the given datastore .

It should be recognized that the swap reservation size computed by Equation 6 may be increased to account for the granularity differences between pages and blocks described above.

In sum a technique for efficiently managing swap space within a virtualized computing system is disclosed. The technique involves creating a swap reservation file using thick provisioning to accommodate a maximum amount of memory reclamation from a set of one or more associated VMs each with an associated VM swap file created using thin provisioning. When a new block is needed to accommodate more page storage within a given VM swap file a block is removed from the swap reservation file and a block is added to the VM swap file thereby maintaining a net zero difference in overall swap storage. The removed block and the added block may be the same storage block if a block move operation is supported by a file system implementing the swap reservation file and VM swap files. The technique also accommodates swap space management of resource pools.

One advantage of the embodiments is that swap space is more efficiently allocated and utilized in a virtualization system that supports both efficient process migration and swap space isolation.

The technique for efficient swap space management described above is applied to processes running in virtualized computer systems. The same technique may be applied to processes running in a non virtualized computer system. In such cases a thinly provisioned swap file is provided per process and a thickly provisioned swap file is provided per data store.

The various embodiments described herein may employ various computer implemented operations involving data stored in computer systems. For example these operations may require physical manipulation of physical quantities usually though not necessarily these quantities may take the form of electrical or magnetic signals where they or representations of them are capable of being stored transferred combined compared or otherwise manipulated. Further such manipulations are often referred to in terms such as producing identifying determining or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations. In addition one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system. Computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive network attached storage NAS read only memory random access memory e.g. a flash memory device a CD Compact Discs CD ROM a CD R or a CD RW a DVD Digital Versatile Disc a magnetic tape and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although one or more embodiments of the present invention have been described in some detail for clarity of understanding it will be apparent that certain changes and modifications may be made within the scope of the claims. Accordingly the described embodiments are to be considered as illustrative and not restrictive and the scope of the claims is not to be limited to details given herein but may be modified within the scope and equivalents of the claims. In the claims elements and or steps do not imply any particular order of operation unless explicitly stated in the claims.

In addition while described virtualization methods have generally assumed that virtual machines present interfaces consistent with a particular hardware system persons of ordinary skill in the art will recognize that the methods described may be used in conjunction with virtualizations that do not correspond directly to any particular hardware system. Virtualization systems in accordance with the various embodiments implemented as hosted embodiments non hosted embodiments or as embodiments that tend to blur distinctions between the two are all envisioned. Furthermore various virtualization operations may be wholly or partially implemented in hardware. For example a hardware implementation may employ a look up table for modification of storage access requests to secure non disk data.

Many variations modifications additions and improvements are possible regardless of the degree of virtualization. The virtualization software can therefore include components of a host console or guest operating system that performs virtualization functions. Plural instances may be provided for components operations or structures described herein as a single instance. Finally boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention s . In general structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements may fall within the scope of the appended claim s .

