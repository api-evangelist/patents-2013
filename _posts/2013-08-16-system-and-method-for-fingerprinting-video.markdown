---

title: System and method for fingerprinting video
abstract: Disclosed are various embodiments of generating video fingerprints. Scene changes can be detected in a video and a video fingerprint generated based upon a time at which the scene change occurs as well as time intervals between the scene changes relative to adjacent scene changes. A video can be captured and analyzed by comparing scene changes detected in the video to those described by the video fingerprint.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09185338&OS=09185338&RS=09185338
owner: BROADCOM CORPORATION
number: 09185338
owner_city: Irvine
owner_country: US
publication_date: 20130816
---
This application is a continuation of U.S. application Ser. No. 13 334 201 entitled SYSTEM AND METHOD FOR FINGERPRINTING VIDEO and filed on Dec. 22 2011 which is hereby incorporated herein by reference in its entirety.

Video fingerprinting is useful for various purposes. A video fingerprint refers to a way in which a video can be uniquely identified relative to other videos in a collection or corpus of many videos. Video fingerprinting systems and methods in the art often lack robustness in the sense that they fail to identify clips edited versions and or even full versions of a video that have been compressed or fail to comprise a bitwise match of a reference video. Prior art video fingerprinting systems and methods may also fail to match a video under analysis to a reference video if the video quality has been degraded or otherwise altered.

Embodiments of the disclosure are generally related to generating a fingerprint associated with a video as well as identifying a video by comparing a fingerprint associated with the video to a reference fingerprint. Video fingerprinting is a general technique to identify and extract characteristic features of a video enabling the video to be uniquely identified by its resulting fingerprint. A video fingerprint generated according to embodiments of the disclosure is highly compressed compared to video itself meaning it generally consumes much less data than the video to which it corresponds. As will be described below the video fingerprinting method disclosed herein is a symmetric process meaning the process of identifying a reference fingerprint associated with a video is a similar process as that of generating the video fingerprint itself.

In the context of the present disclosure systems implementing the video fingerprinting process described herein can be employed to facilitate identifying an unknown video or video clip retrieving metadata associated with a video from a database e.g. title genre name of director year filmed names of actors etc. classifying or identifying a video for the purposes of digital rights management DRM tracking the distribution of unauthorized or illegal content video search engines content aware advertising identifying a user s viewing choices and or habits for sharing with others identifying duplicate video clips in a large database synchronized retrieval of closed caption data and or other applications as can be appreciated.

Accordingly reference is now made to which illustrates a representation of a video to illustrate the theory of operation of the video fingerprinting technique according to an embodiment of the disclosure. The depicted embodiment illustrates a portion of a video represented over time.

The video fingerprinting technique disclosed herein involves detection of scene changes that occur in a video. As shown in the scene changes s s s s s s s etc. occur at various points in time in the video. Scene changes in a video source can be detected using various systems and methods known in the art. Accordingly in order to generate a video fingerprint according to an embodiment of the disclosure the various scene changes in a video can be detected as well as a time e.g. relative to a starting point in the video in the video at which each of the scene changes occur. Additionally the time difference e.g. an amount of time number of frames etc. between successive scene changes is also detected. These time differences are represented in in the non limiting example of a video by t t t t t and t. Accordingly a video fingerprint associated with the video is based upon at least two pieces of information which include a time in the video associated with each of the scene changes as well as a time difference between successive scene changes.

Reference is now made to which illustrates one representation of a video fingerprint associated with a video according to an embodiment of the disclosure. It should be appreciated that the depicted video fingerprint is but one example of a video fingerprint and that other representations embodying the same or similar data can be employed consistent with this disclosure. In the depicted example the video fingerprint can represent a reference fingerprint of a video. Accordingly the video fingerprint can be associated with a video identifier that uniquely identifies a video with which the fingerprint is associated. Any other identifying information associated with a video can also be associated with the identifier and or the fingerprint that can be provided in various applications. For example as noted above various metadata can also be associated with the video which can be stored in the same or a different database that can be indexed by the video identifier and or the fingerprint .

The video fingerprint can include a representation of a table that comprises at least three types of data. A scene start time of at least a subset of the scene changes in the video can be associated with at least two time differences between scene changes that are subsequent to the particular scene change. In other words the fingerprint associates a scene change with a pairing of time intervals between the next two successive scene changes as shown. Accordingly in the depicted example the first entry in the table of the video fingerprint associates a scene change start time swith tand t which represent a time difference between the scene change occurring at time sin the video and the next two scene changes in the video Sand S.

The fingerprint also associates a particular scene change with additional time difference or interval pairings that represent potential missed scene change detections. In the second entry in the depicted example fingerprint the scene change start time sis also associated with a time difference pairing of tand t t which represents a pairing of time intervals to the next two successive scene changes if detection of scene change sis missed. In other words this pairing of time intervals represents the time interval to scene changes sand s which accounts for the possibility that the scene change at sis missed. Similarly in the third entry in the depicted example fingerprint the scene change start time sis also associated a time difference pairing of t tand t which represents a pairing of time intervals to next two successive scene changes if detection of scene change sis missed. Additionally the video fingerprint table can include similar entries for successive scene changes.

Accordingly to process a video and attempt to identify a reference video fingerprint such as one in the depicted example of a computing device can generate a table by detecting scene changes in the video and measuring a scene change start time as well as time intervals to the next two successive scene change for each detected scene change. The computing device can then attempt to match the generated table with a reference video fingerprint which can be stored in a database or other data store.

The video fingerprinting process as well as the process of matching a video profile to a reference video fingerprint can be conducted on any portion of the video . For example a video profile representing a clip of a reference video can be generated and compared to the reference video fingerprint to determine whether a match exists. To illustrate a video profile for a clip representing a few minutes from any portion of a reference video can be generated and matched according to the time at which scene changes occur and the intervals between them. Additionally the first scene change in a video profile may not necessarily correspond to the first scene change in a reference video signature but instead may correspond to a scene change that occurs after many previous scene changes in the reference video.

In the depicted example of a video profile represented by the table of it is shown that similar to the reference video fingerprint the table also includes the detected scene start times of the scene changes in the video being associated with at least two time differences between scene changes that are subsequent to the particular scene change. In other words the table representing a video profile also associates a scene change with a pairing of time intervals between the next two successive scene changes as shown. In this way even if a device generating a video profile correctly detects each and every scene change in a video under analysis a match can be found with a reference video fingerprint even in the event that the reference video fingerprint may lack entries for certain scene changes i.e. the reference video fingerprint missed a scene change . The video profile can also allow a match to be found against a reference video fingerprint that includes false positive scene change entries. In other words the process of generating a video fingerprint as well as generating a video profile that is used to match against a video fingerprint are symmetric with respect to one another to account for potential errors in the reference video fingerprint and or the video profile. This is illustrated in further detail in and discussed hereinbelow.

Additionally the scene start time in each entry of the table can increase the confidence of a match. Scene start times are measured relative to the time when video analysis is initiated. In other words a scene start time of a video under analysis may not represent an absolute scene start time but a time in a video clip at which a scene change occurs relative to the beginning of a video clip which can differ from the scene start time in a reference video as measured from the beginning of the reference video.

Accordingly the scene start time values are not meant to be treated in an absolute sense. Relative differences between the start times of corresponding interval pairings are meaningful. For example a difference between s in the table and sin the reference video signature can be compared to a difference between s in the table and sin the reference video signature to determine if this difference is consistent. Therefore a marked consistency in the relative scene start time differences between entries in the table relative to the reference fingerprint may increase a confidence score associated with a match. In the depicted example a confidence score of a match between the example video fingerprint shown in and a video profile represented by the table can be increased due to the similarity of time differences between each of the scene start times.

In some embodiments a confidence score can be generated that corresponds to a likelihood of a match between a table and a reference video fingerprint . It should be appreciated that scene change detection whether tracked in terms of a frame number and or running time in a video may not result in an exact match between entries in a table and a reference video fingerprint . Accordingly such a confidence score can be based at least upon an amount error or difference between entries in a table and video fingerprint . In some embodiments a reference video fingerprint that yields the smallest error and or difference between entries in the table and fingerprint can be identified as a match.

Reference is now made to which illustrate a video profile corresponding to the video shown in . In the example of a computing device generating a video profile corresponding to the video has missed a scene change occurring at time s in the video. In this example despite the fact that a scene change detection is missed by a computing device generating the table the reference video fingerprint can still be matched with the video profile corresponding to the table because the reference video fingerprint contains entries that take into account potential missed scene change detections. Accordingly as shown in the table represents a video profile generated in an attempt to identify a video fingerprint with which the video matches. Because the scene change occurring at time s in the video was missed the table does not include an entry corresponding to a scene starting at time s The reference video fingerprint can still be matched with the table shown in despite the fact that the scene change was missed because of the entries taking into account potential missed detection of scene changes.

To illustrate show the matching entries in the reference video fingerprint and the table corresponding to the video profile. Entry in the reference video fingerprint constitutes a match with entry in the table . Additionally entry in the reference video fingerprint constitutes a match with entry in the table and so on. Accordingly despite the fact that detection of scene change swas missed the profile corresponding to the table can still be matched with the reference video fingerprint .

Reference is now made to which illustrate an alternative example of a video profile corresponding to the video shown in . In the example of a computing device generating a video profile corresponding to the video has detected a false positive scene change. In other words a scene change has been detected at a time within the video where the reference video fingerprint does not reflect a corresponding scene change. In this false positive scene change is denoted by f. In the example of because a false positive scene change was detected at time f the table corresponding to the video profile associated with the video includes an additional series of entries corresponding to the false positive scene change fthat are not included within the reference video fingerprint . In some situations the video profile may correctly reflect the scene changes while the reference video fingerprint contains a missed scene change which would result in a similar situation. However due to the symmetric nature of the algorithm described herein the video profile corresponding to the table can still be matched to the corresponding reference video fingerprint .

To illustrate show the matching entries in the reference video fingerprint and table corresponding to the video profile. Entry in the reference video fingerprint constitutes a match with entry in the table . Additionally entry in the reference video fingerprint constitutes a match with entry in the table and so on. Accordingly despite the fact that a false positive scene change fwas detected the profile corresponding to the table can still be matched with the reference video fingerprint . Additionally it should be appreciated that a video profile that may include various combinations of false positives and or missed scene change detections can be matched with a reference video fingerprint by employing the process described herein.

Additionally while the process described above can account for potential missed scene detections either in a reference video and or video under analysis the error robustness can be improved by extending the video fingerprint to associate more than two time intervals and the associated permutations of additional intervals to account for missed scene change detections. In other words rather than limiting the video fingerprint to a pairing of time intervals associated with the next two scene changes the video fingerprint can be extended to associate a scene change with the next three four or any number of subsequent scene changes. In such a scenario each scene change in the video fingerprint would be associated with the time interval to the next X scene changes where X is any positive integer. The scene change would also be associated with the time intervals associated with the various permutations of potential missed scene change detections consistent with the example described above in .

Therefore embodiments employing the video fingerprint and matching processes consistent with the above can result in computationally efficient fingerprint generation and matching with compact video fingerprints for efficient transmission and storage. Additionally systems and methods employing such a scheme can be capable of identifying a short segment or clip of a reference video. By relying on detection of scene changes as well as a time interval between subsequent scene changes the process is also noise resistant and can account for encoding differences between a reference video and video under analysis. Encoding differences can result due to transcoding video being captured via a video camera e.g. mobile device smartphone tablet computing system laptop computer misaligned framing camera shake and or variations in frame rate between a reference video and video under analysis The process is also resistant to differences in picture quality between a reference video and video under analysis. Such picture quality characteristics can include but are not limited to sharpness contrast brightness hue saturation scaling etc.

Reference is now made to which illustrates an embodiment of at least one computing device in which an embodiment of the disclosure can be implemented. The depicted configuration of a computing device can be one in which a video fingerprint corresponding to a video is generated according to the methodology described above. The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. For example a plurality of computing devices together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be distributed among many different geographical locations.

For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above. The computing device may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer a laptop computer a personal digital assistant a cellular telephone set top box music players mobile computing device tablet computer systems game consoles or other devices with like capability.

The data stored in the data store includes for example video data associated with various videos for which video fingerprints as well as metadata can be associated as well as potentially other data about videos indexed by a system according to an embodiment of the disclosure. An entry corresponding to a particular video can be indexed by a video identifier that uniquely identifies the video. It should be appreciated that the data store can represent a relational or non relational database or other data storage system that can also be executed in a dedicated computing system that is accessible to the computing device via a network.

In the example of the computing device can execute a video fingerprinting application which can receive a video as an input and generate a video fingerprint as described above. In other words the video fingerprinting application can generate a reference video fingerprint associated with the video . In this sense the video can be indexed by its video fingerprint and or a video identifier based upon a video fingerprint generated by the video fingerprinting application that is based upon detected scene changes within the video as well as time intervals between the various scene changes. In some embodiments the video fingerprinting application can contain logic that facilitates identification of scene changes within a video . In other embodiments the video fingerprinting application can rely on scene change logic provided by an application programming interface that accesses external software and or hardware logic that facilitates scene change detection.

Accordingly in an alternative depiction of a computing device executing the video fingerprinting application is shown. In the example of the video fingerprinting application can receive a video and generate a video profile as described above in reference to . In other words the video fingerprinting application can identify scene changes as well as intervals between scene changes in the video to generate the video profile . Accordingly the video fingerprinting application can determine whether a video corresponding to video data in the data store matches the video profile and return a video identifier for the corresponding video.

It should be appreciated that in some embodiments a video profile can be generated by a client device that is viewing and or capturing a video with at least a portion of the video profile generated by a client device submitting a request to the video fingerprinting application to find a matching video. For example a client device such as a mobile device that is capturing a video for which it desires a matching video to be located can provide a partial video profile that includes a list of times in the video at which scene changes are detected. Accordingly the video fingerprinting application can determine time intervals between successive scene changes corresponding to each identified scene change as described with reference to . The video fingerprinting application can then identify a matching video in the data store by identifying a video fingerprint that matches the video profile with the highest degree of confidence.

Referring next to shown is a flowchart that provides one example of the operation of a portion of the video fingerprinting application to generate a video fingerprint according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the video fingerprinting application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

In one embodiment to generate a reference video fingerprint corresponding to a video in box a plurality of scene changes are detected within the video. As noted above scene changes can be detected using a scene change detection API that provides access to hardware and or software logic facilitating scene change detection. In box the time at which scene changes occur in the video are detected. In box the video fingerprinting application can detect a time interval between adjacent scene changes in the video. Finally in box the video fingerprinting application can generate a video fingerprint based upon the time at which scene changes occur and a time interval between adjacent scene changes where the fingerprint also takes into account the potential for missed or false positive detection of scene changes as described above.

Referring next to shown is a flowchart that provides one example of the operation of a portion of the video fingerprinting application to identify a reference video fingerprint with which a video profile is matched in a database or other repository of video fingerprint data according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the video fingerprinting application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

First in box can detect scene changes in a video as well as identify a time at which scene changes occur in the video in box . In box time intervals between adjacent scene changes are determined. In box a video profile that describes the time at which scene changes occur as well as the time interval between subsequent scene changes is generated. In box the video fingerprinting application identifies whether a reference video fingerprint matches the generated video profile. As noted above some or all the functionality described pertaining to identification of a reference video fingerprint corresponding to a video may be performed in a client. Additionally in some embodiments a client device may record a video source with an integrated video camera and submit the video and or scene change data from the video to a computing device executing the video fingerprinting application which can determine if the video matches a reference video fingerprint. In other embodiments the video fingerprinting application can scan a corpus of videos and analyze scene change properties of the videos to identify potential matching reference video fingerprints in a database. It should be appreciated that many other variations applying the process of generating and matching a video fingerprint can be employed consistent with the present disclosure.

With reference to shown is one example of a computing device that comprises a computer server or equivalent device according to an embodiment of the present disclosure. The computing device may include one or more processor circuits having a processor and a memory both of which are coupled to a local interface . In this respect the local interface may comprise for example a data bus with an accompanying control address bus as can be appreciated.

Stored on the memory and executable by the processor are various components such as an operating system video fingerprinting application and other applications or data. In addition it is understood that many other components may be stored in the memory and executable by the processor s . Also such components may reside in a memory that is external from the computing device as can be appreciated.

As set forth above a number of components are stored in the memory and are executable by the processor . In this respect the term executable refers to a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor or source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor . An executable program may be stored in any portion or component of the memory including for example random access memory read only memory a hard drive compact disk CD floppy disk or other memory components.

The memory is defined herein as both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives floppy disks accessed via an associated floppy disk drive compact discs accessed via a compact disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

In addition the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any one of the memories or between any two of the memories etc. The processor may be of electrical optical or of some other construction as can be appreciated by those with ordinary skill in the art.

The operating system is executed to control the allocation and usage of hardware resources such as the memory and processing time in the computing device . In this manner the server operating system serves as the foundation on which applications depend as is generally known by those with ordinary skill in the art.

Although the functionality of various components are described above with respect to such as for example the video fingerprinting application as being embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware the functionality of these components can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates programmable gate arrays PGA field programmable gate arrays FPGA or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowchart of show the functionality and operation of functionality implemented on the computing device . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in the flowcharts may be executed concurrently or with partial concurrence. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also where the functionality of the disclosed systems is expressed in the form of software or code it can be embodied in any computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the functionality may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the network page for use by or in connection with the instruction execution system.

The computer readable medium can comprise any one of many physical media such as for example electronic magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives or compact discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present invention are merely possible examples of implementations merely set forth for a clear understanding of the principles of the invention. Many variations and modifications may be made to the above described embodiment s of the invention without departing substantially from the spirit and principles of the invention. All such modifications and variations are intended to be included herein within the scope of this disclosure and the present invention and protected by the following claims.

