---

title: System and method of transmitting content from a mobile device to a wireless display
abstract: A method of transmitting content to a wireless display device is disclosed. The method may include receiving multimedia data, encoding the multimedia data, and writing encoded multimedia data into a first predetermined memory location of a shared memory. Further, the method may include encapsulating the encoded multimedia data and writing encapsulation data into a second predetermined memory location of the shared memory. The method may also include calculating error control encoding and writing the error control encoding into a third predetermined memory location of the shared memory. Further, the method may include transmitting the encoded multimedia data, the encapsulation data, and the error control encoding to the wireless display device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08929297&OS=08929297&RS=08929297
owner: QUALCOMM Incorporated
number: 08929297
owner_city: San Diego
owner_country: US
publication_date: 20130305
---
The present Application for Patent is a Divisional of U.S. patent application Ser. No. 12 500 475 SYSTEM AND METHOD OF TRANSMITTING CONTENT FROM A MOBILE DEVICE TO A WIRELESS DISPLAY filed Jul. 9 2009 and granted as U.S. Pat. No. 8 406 245 on Mar. 26 2013 and assigned to the assignee hereof and hereby expressly incorporated by reference herein.

The present invention generally relates to the operation of mobile devices and more particularly to systems and methods for transmitting audio video content from a mobile device to a wireless display.

In a wireless display system a composite image displayed on embedded primary display of a mobile device may be streamed in real time to an external display wirelessly. Audio presented at the speaker on the device may also be streamed in real time to the speakers associated with the external display device. Usage scenarios include concurrent presentation of video and graphics on multiple displays including touch screen displays. During transmission latencies can interrupt the data flow and cause a poor user experience.

Therefore what is needed is an improved system and method for transmitting audio video content from a mobile device to a wireless display.

A method of transmitting content to a wireless display device is disclosed. The method may include receiving multimedia data encoding the multimedia data and writing encoded multimedia data into a first predetermined memory location of a shared memory. Further the method may include encapsulating the encoded multimedia data and writing encapsulation data into a second predetermined memory location of the shared memory. The method may also include calculating error control encoding and writing the error control encoding into a third predetermined memory location of the shared memory. Further the method may include transmitting the encoded multimedia data the encapsulation data and the error control encoding to the wireless display device.

Additionally the method may further include determining at least one of a channel bandwidth a packet error rate and a desired latency. Also the method may include calculating at least one of a video packet size transport header characteristics and a corresponding length and an outer coding rate and a corresponding medium access control MAC header length. In a particular aspect the video packet size the transport header characteristics and the corresponding length and the outer coding rate and the corresponding MAC header length may be determined at least partially based on the channel bandwidth the packet error rate and the desired latency.

The method may also include allocating a first memory address length for a MAC header allocating a second memory address length for a transport header allocating a third memory address length for a video packet and writing coded video data into the predetermined memory locations of the shared memory. The method may further include obtaining metadata from a video encoder preparing headers for one or more coded video data segments creating parity data for the one or more coded video data segments and inserting the parity data at the end of the one or more coded video data segments.

In another aspect a wireless device is disclosed and may include means for receiving multimedia data means for encoding the multimedia data and means for writing encoded multimedia data into a first predetermined memory location of a shared memory. Further the wireless device may include means for encapsulating the encoded multimedia data and means for writing encapsulation data into a second predetermined memory location of the shared memory. Also the wireless device may include means for calculating error control encoding and means for writing the error control encoding into a third predetermined memory location of the shared memory. Further in this aspect the wireless device may include means for transmitting the encoded multimedia data the encapsulation data and the error control encoding to the wireless display device.

In yet another aspect a wireless device is disclosed and may include a processor. The processor may be operable to receive multimedia data encode the multimedia data and write encoded multimedia data into a first predetermined memory location of a shared memory. Moreover the processor may be operable to encapsulate the encoded multimedia data and write encapsulation data into a second predetermined memory location of the shared memory. The processor may also be operable to calculate error control encoding and write the error control encoding into a third predetermined memory location of the shared memory. Further the processor may be operable to transmit the encoded multimedia data the encapsulation data and the error control encoding to the wireless display device.

In still another aspect a computer program product is disclosed and may include a computer readable medium. The computer readable medium may include at least one instruction for receiving multimedia data at least one instruction for encoding the multimedia data and at least one instruction for writing encoded multimedia data into a first predetermined memory location of a shared memory. Further the computer readable medium may include at least one instruction for encapsulating the encoded multimedia data and at least one instruction for writing encapsulation data into a second predetermined memory location of the shared memory. The computer readable medium may also include at least one instruction for calculating error control encoding and at least one instruction for writing the error control encoding into a third predetermined memory location of the shared memory. Moreover the computer readable medium may include at least one instruction for transmitting the encoded multimedia data the encapsulation data and the error control encoding to the wireless display device.

In yet another aspect a method is provided for wirelessly transmitting data from a mobile device to a display device. The method includes the steps of 1 receiving in the mobile device first data to be included in a first packet 2 receiving in the mobile device second data to be included in a second packet 3 allocating locations of a memory buffer in which to store an encoded version of the first data an encoded version of the second data a first transport header data associated with the encoded version of the first data a second transport header data associated with the encoded version of the second data a first Media Access Control MAC header data associated with the first data and a second MAC header data associated with the second data wherein the locations are allocated such that the first encoded data first transport header data and first MAC header data are stored in contiguous memory locations and the second encoded data second transport header data and second MAC header data are stored in contiguous memory locations and 4 storing the first encoded data first transport header data and first MAC header data in contiguous memory buffer locations and the second encoded data second transport header data and second MAC header data in contiguous memory locations.

In yet another aspect a method is provided of wirelessly transmitting data between a mobile device and a display device. The method includes the steps of 1 receiving data in the mobile device 2 including the received data in transmission control protocol TCP segments and 3 forwarding the TCP segments to the display device prior to application layer processing of the received data by the mobile device.

In yet another aspect a system is provided for wirelessly transmitting data from a mobile device to a display device. The system includes 1 means for receiving in the mobile device first data to be included in a first packet 2 means for receiving in the mobile device second data to be included in a second packet 3 means for allocating locations of a memory buffer in which to store an encoded version of the first data an encoded version of the second data a first transport header data associated with the encoded version of the first data a second transport header data associated with the encoded version of the second data a first Media Access Control MAC header data associated with the first data and a second MAC header data associated with the second data wherein the locations are allocated such that the first encoded data first transport header data and first MAC header data are stored in contiguous memory locations and the second encoded data second transport header data and second MAC header data are stored in contiguous memory locations and 4 means for storing the first encoded data first transport header data and first MAC header data in contiguous memory buffer locations and the second encoded data second transport header data and second MAC header data in contiguous memory locations.

In yet another aspect a system is provided for wirelessly transmitting data between a mobile device and a display device. The system includes 1 means for receiving data in the mobile device 2 means for including the received data in transmission control protocol TCP segments and 3 means for forwarding the TCP segments to the display device prior to application layer processing of the received data by the mobile device.

In yet another aspect a computer program product comprising computer readable medium is provided. The computer readable medium includes code for wirelessly transmitting data from a mobile device to a display device which includes 1 code for causing first data to be included in a first packet to be received in the mobile device 2 code for causing second data to be included in a second packet to be received in the mobile device 3 code for causing locations of a memory buffer to be allocated in which to store an encoded version of the first data an encoded version of the second data a first transport header data associated with the encoded version of the first data a second transport header data associated with the encoded version of the second data a first Media Access Control MAC header data associated with the first data and a second MAC header data associated with the second data wherein the locations are allocated such that the first encoded data first transport header data and first MAC header data are stored in contiguous memory locations and the second encoded data second transport header data and second MAC header data are stored in contiguous memory locations and 4 code for causing the first encoded data first transport header data and first MAC header data to be stored in contiguous memory buffer locations and the second encoded data second transport header data and second MAC header data to be stored in contiguous memory locations.

In yet another aspect a computer program product comprising computer readable medium is provided. The computer readable medium includes code for wirelessly transmitting data between a mobile device and a display device which includes 1 code for causing data to be received in the mobile device 2 code for causing received data to be included in transmission control protocol TCP segments and 3 code for causing the TCP segments to be forwarded to the display device prior to application layer processing of the received data by the mobile device.

In yet another aspect a method of wirelessly receiving data from a mobile device in a display device is provided. The method includes the steps of 1 receiving in the display device a first packet 2 receiving in the display device a second packet 3 allocating locations of a memory buffer associated with the display device in which to store encoded data from the first packet encoded data from the second packet transport header data from the first packet transport header data from the second packet Media Access Control MAC header data from the first packet and MAC header data from the second packet wherein the locations are allocated such that the encoded data transport header data and MAC header data from the first packet are stored in contiguous memory locations and the encoded data transport header data and MAC header data from the second packet are stored in contiguous memory locations and 4 storing the encoded data transport header data and MAC header data from first packet in contiguous memory buffer locations and the encoded data transport header data and MAC header data from the second packet in contiguous memory locations.

In yet another aspect a system for wirelessly receiving data from a mobile device in a display device is provided. The system includes 1 means for receiving in the display device a first packet 2 means for receiving in the display device a second packet 3 means for allocating locations of a memory buffer associated with the display device in which to store encoded data from the first packet encoded data from the second packet transport header data from the first packet transport header data from the second packet Media Access Control MAC header data from the first packet and MAC header data from the second packet wherein the locations are allocated such that the encoded data transport header data and MAC header data from the first packet are stored in contiguous memory locations and the encoded data transport header data and MAC header data from the second packet are stored in contiguous memory locations and 4 means for storing the encoded data transport header data and MAC header data from first packet in contiguous memory buffer locations and the encoded data transport header data and MAC header data from the second packet in contiguous memory locations.

In yet another aspect a computer program product comprising computer readable medium is provided. The computer readable medium includes code for wirelessly receiving data from a mobile device in a display device which includes 1 code for causing a first packet to be received in the display device 2 code for causing a second packet to be received in the display device 3 code for causing allocation of locations of a memory buffer associated with the display device in which to store encoded data from the first packet encoded data from the second packet transport header data from the first packet transport header data from the second packet Media Access Control MAC header data from the first packet and MAC header data from the second packet wherein the locations are allocated such that the encoded data transport header data and MAC header data from the first packet are stored in contiguous memory locations and the encoded data transport header data and MAC header data from the second packet are stored in contiguous memory locations and 4 code for causing the encoded data transport header data and MAC header data from first packet to be stored in contiguous memory buffer locations and the encoded data transport header data and MAC header data from the second packet to be stored in contiguous memory locations.

The word exemplary is used herein to mean serving as an example instance or illustration. Any aspect described herein as exemplary is not necessarily to be construed as preferred or advantageous over other aspects.

In this description the term application may also include files having executable content such as object code scripts byte code markup language files and patches. In addition an application referred to herein may also include files that are not executable in nature such as documents that may need to be opened or other data files that need to be accessed.

The term content may also include files having executable content such as object code scripts byte code markup language files and patches. In addition content referred to herein may also include files that are not executable in nature such as documents that may need to be opened or other data files that need to be accessed.

As used in this description the terms component database module system and the like are intended to refer to a computer related entity either hardware firmware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a computing device and the computing device may be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers. In addition these components may execute from various computer readable media having various data structures stored thereon. The components may communicate by way of local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems by way of the signal .

In this description the terms communication device wireless device wireless telephone wireless communications device and wireless handset are used interchangeably. With the advent of third generation 3G wireless technology more bandwidth availability has enabled more electronic devices with wireless capabilities. Therefore a wireless device could be a cellular telephone a pager a PDA a smartphone a navigation device or a computer with a wireless connection.

Referring initially to a wireless display system is shown and is generally designated . As shown the wireless display system may include a host system and a client system . The host system may be a wireless device such as a mobile telephone a portable digital assistant PDA or some other mobile device. The client system may be a wireless display a wireless overhead projector or some other wireless display device.

As shown the host system may include a video decoder a scaler frame interpolator and an embedded display . A reconstructed picture buffer may connect the video decoder to the scaler frame interpolator . Further a display buffer may connect the scaler frame interpolator to the embedded display . As indicated in the scaler frame interpolator may receive a signal form a graphics processing unit GPU . Further the scaler frame interpolator may receive an overlay image.

For example the WD MAC protocol unit may write a first MAC header into the common buffer . Thereafter the WD transport encapsulator may write a first transport header into the common buffer . Moreover the WD video encoder may write a first coded video data segment into the common buffer such that the first MAC header first transport header and first coded video segment are written into contiguous locations of the common buffer . Additionally the WD MAC protocol unit may write an Nth MAC header into the common buffer . Following the Nth MAC header the WD transport encapsulator may write an Nth transport header into the common buffer . Thereafter the WD video encoder may write an Nth coded video data segment into the common buffer such that the Nth MAC header Nth transport header and Nth coded video data segment are written into contiguous locations of the common buffer .

As shown in a modulator may be connected to the common buffer . The modulator may include an inner coding module . The inner coding module may be a digital module. The modulator may also include a radio frequency RF module . In a particular aspect the modulator may receive a stream of data from the common buffer . For example the modulator may receive one or more MAC headers one or more transport headers one or more coded video data segments or a combination thereof. As depicted in an antenna may be connected to the modulator . The antenna may be used to transmit data from the modulator e.g. the data received from the common buffer .

In a particular aspect the WD video encoder may include a memory management unit . The WD transport encapsulator may also include a memory management unit . Further the WD MAC protocol unit may include a memory management unit . In this aspect the memory management units may be used to map the physical address locations and pointers to the common buffer into contiguous virtual address space as seen by each of these components for ease of implementation.

Still referring to the client system may include a demodulator . The demodulator may include an inner coding module e.g. a digital inner coding module. The demodulator may also include an RF module . Further an antenna may be connected to the demodulator . The demodulator may receive data from the modulator via transmission between the antennas . For example the demodulator may receive one or more MAC headers one or more transport headers one or more coded video data segments or a combination thereof from the common shared buffer within the host system .

As shown in a common buffer may be connected to the demodulator . The common buffer may be also considered a shared buffer. Moreover the common buffer may be a memory from which one or more elements described below read data. As shown the demodulator may transmit data into the common buffer . For example the demodulator may transmit a first MAC header into the common buffer . Thereafter the demodulator may transmit a first transport header into the common buffer . Moreover the demodulator may transmit a first coded video data segment into the common buffer . Additionally the demodulator may transmit an Nth MAC header into the common buffer . Following the Nth MAC header the demodulator may transmit an Nth transport header into the common buffer . Thereafter the demodulator may transmit an Nth coded video data segment into the common buffer after the Nth transport header . In a particular aspect the data within the common buffer of the client system corresponds to the data within the common buffer of the host system . For example the client device may be adapted to allocate contiguous locations e.g. predetermined locations of the common buffer in which to store e.g. write the first MAC header first transport header and first coded video data segment and to store such data in the contiguous locations of the common buffer . Similarly the client device may be adapted to allocate contiguous locations of the common buffer in which to store the Nth MAC header Nth transport header and Nth coded video data segment and to store such data in the contiguous locations of the common buffer . The locations may be allocated based on a predetermined channel bandwidth and packet error rate PER .

As indicated in a reconstructed picture buffer may be connected to the WD video decoder . Further a display processor may be connected to the reconstructed picture buffer . A display buffer may be connected to the display processor . An external display may be connected to the display buffer .

In a particular aspect the WD MAC protocol unit may include a memory management unit . The WD transport parser may also include a memory management unit . Further the WD video decoder may include a memory management unit . In this aspect the memory management units may be used to map the physical address locations and pointers from the common buffer into contiguous virtual address space for each of these components.

In a particular aspect a composited image is an image to be rendered for a simple extension to the external display . The composited image may be the input to the WD system i.e. elements through and elements therein. Wireless extensions such as HDMI USB RGB or a combination thereof may provide a relatively simple manner of carriage of the appropriate encapsulated data over a wireless protocol.

In the wireless display WD chain described above the common buffer may be configured to accommodate encoded data received from the WD video encoder transport headers for encapsulation of the coded data and the MAC protocol headers for outer coding from the WD MAC protocol unit . Depending on one or more of the required channel bandwidth PER and latency e.g. desired latency the video packet size the transport header characteristics and the corresponding length and or outer coding rate and corresponding MAC header length may be calculated. The appropriate memory addresses for the MAC header followed by transport header followed by the video packet may be allocated for length based on those calculations. The WD video encoder may directly write coded video data in the assigned areas of the common buffer concurrently which fragments the coded data on the fly and eliminates the need for separate buffers at the transport and MAC layers where fragmentation of data bitstream in video packets occurs. The WD transport encapsulator may obtain metadata such as NALU length start and end points in the buffer from the video encoder and may prepare the headers for the coded video data segments. The WD MAC protocol unit may create the parity data for the coded video data segments and insert the parity data at the end of the coded video data segments .

In a particular aspect the latency of the wireless display system may be measured from the output of the display processor i.e. the scaler frame interpolator of the host system to the input of the display buffer on the external display of the client system . This delay is indicated as DelayWD in . The encoding delay may be minimized through the appropriate number of slices per frame based on the resolution and the frame rate. Table 1 below indicates slice structures coding overheads and encoding latencies for various resolutions and frame rates.

Table 1 indicates various resolutions. Further for example the Table 1 indicates that encoding one 1 macroblock MB row as one slice may minimize the encoding latency to 33 ms 30 1.11 ms. The coding overhead to encode a frame into multiple slices is shown in the second to last column. Since lower latency and higher quality is more important than compression efficiency an overhead of 20 25 may be accommodated in the large bandwidths support by a wireless display physical layer PHY . For example VGA 30 fps requires 2 Mbps for a good quality compression. Further up to 5 Mbps may be supported in ultra wide band transmission UWB . In addition the use of multiple slices may improve error resilience and may enable unequal error protection by using higher outer inner code rates for intra frame slices I slices versus predicted frame slices P slices within a frame especially in conjunction with intra refresh.

In a particular aspect the interleaving depth may be managed based on the PDU MTU size and channel error requirements. For example a size of 1K bits to a maximum of 4K bits per inner code packet may reduce delay introduced in interleaving and may provide sufficient time diversity and error protection. The packet lengths may be large enough for effective turbo coding or even low density parity check LDPC coding. Data rates or throughput of 5 Mbps to 400 Mbps may be provided on WPAN networks used as wireless links for wireless displays. For a bitrate of 5 Mbps at inner code lengths of 1K bits the interleaving latency is 1 5000 0.2 ms. This may be considered the worst case latency for the present system. Moreover for 20 Mbps the latency may drop to 0.05 ms. For HD resolutions inner code lengths of 4 Kbits may be used and the latency for 50 Mbps for 1080p60 may drop to 4 50 000 or 0.08 ms. Accordingly a maximum interleaving latency of 0.2 ms may be provided by the present system. RF propagation delays may be less than 200 microseconds. Maximum RF propagation delays may be 500 600 ns of propagation delay plus 75 microseconds of multipath delay due to rms delay spread.

In a particular aspect the WD video decoder does not have to wait for an entire slice to be received before start of decoding. As such the decoding latency may be less than the encoding latency i.e. the maximum encoding latency of 1.11 ms. The display processor in the external display may introduce an additional latency based on the number of pixel lines of image are required for post processing. Typically this is 16 lines corresponding to 1 row of MBs. Hence an additional latency of 1.11 ms may be possible. This includes partial updates for rendering. The latencies for the entire wireless display system are summarized in Table 2 below.

The common buffer architecture described herein substantially eliminates data transfers and as such memory bandwidth requirements are substantially reduced. Accordingly power consumption is also substantially reduced. Additionally physical memory space is substantially reduced. Latencies are also substantially reduced since the WD video encoder the WD transport encapsulator and the WD MAC protocol unit may be tightly coupled through pipelined processing. The delay on the transmit chain may be reduced to the encoding delay plus the interleaving delay within the modulator .

In a particular aspect the WD video encoder the WD transport encapsulator the WD MAC protocol unit the WD MAC protocol unit the WD transport parser the WD video decoder or a combination thereof may act as means for executing one or more of the method steps described herein.

Referring to a general method of processing multimedia data within a wireless device is shown and is generally designated . For clarity the method is described in conjunction with a shared memory having a plurality of predetermined memory locations .

Commencing at block multimedia data may be received e.g. within a WD host application. At block the multimedia data may be encoded and written into a predetermined memory location e.g. by a WD video encoder. At block the encoded data may encapsulated and written into another predetermined memory location e.g. by a WD transport encapsulator. In a particular aspect the encapsulated encoded data may be written into the shared memory in a memory location after the encoded multimedia data.

Moving to block error control encoding may be created and written into yet another predetermined memory location e.g. by a WD MAC protocol unit. The error control encoding may be written into the shared memory in a memory location after the encapsulated encoded data. At block the data may be transmitted over a wireless link. In a particular aspect the data may be transmitted in the following order encoded multimedia data encapsulated encoded data and error control encoding. After block the method may end.

Moreover at block a memory address length for the MAC header may be allocated. At block a memory address length for the transport header may be allocated. Further at block a memory address length for the video packet may be allocated.

At block coded video data may be written into the assigned areas of a shared memory buffer. Thereafter at block metadata from a video encoder may be obtained. At block headers for the coded video data segments may be prepared. Further at block parity data for the coded video data segments may be created. At block the parity data may be inserted at the end of the coded video data segments. The method may then end.

In a particular aspect the applications processor may include a video encoder a video decoder and an audio decoder . The video decoder and the audio decoder may be connected to the modem . The applications processor may also include a display processor e.g. a mobile display processor MDP that may be coupled to the video decoder . Additionally the applications processor may include an audio processor . The audio processor may be connected to the audio decoder .

As depicted the WD host device may include a WD audio video encoder . The WD audio video encoder may be connected to the Display processor and the audio processor within the applications processor . The WD host device within the mobile station modem may also include a WD transmitter . In particular the WD transmitter may include a MAC layer and a PHY layer.

As further indicated in the wireless display system may further include a WD client connected to mobile station modem via a wireless channel . Specifically the channel is connected to the WD transmitter within the WD host . Further the channel is connected to a WD receiver within the WD client . The WD receiver may include a MAC layer and a PHY layer. also indicates that the WD client may include a WD audio video decoder connected to the WD receiver . The WD audio video decoder may be connected to a display processor and one or more speakers . The display processor may be connected to a display .

In the wireless display system multimedia data may be received at the mobile station modem e.g. via the modem over a radio network. For example the radio network may be a cellular network such as third generation CDMA 3G CDMA 1x UMTS GSM GPRS EDGE or a combination thereof. Further the radio network may be a broadcast network such as terrestrial digital television DTV ISDB T S DMB Mobile TV or a combination thereof. The radio network may be a wireless local area network WLAN such as 802.11b g n WiFi or a combination thereof. In another aspect the radio network may be a wireless personal area network WPAN such as USB W USB. In yet another aspect the radio network may be a WBAN such as BT near field communications NFC for applications that may include conversational video e.g. video telephony and video conferencing or a combination thereof. The radio network may also be a video on demand VOD network that may include pseudo streaming or streaming video Internet protocol television IPTV internet video or a combination thereof. The multimedia data may be received via a stored medium or the multimedia data may be live streaming content such as that provided by broadcast e.g. DTV mobile TV or a combination thereof. Multimedia data may also be received in uncompressed format via image video sensors for camera camcorder applications.

In a particular aspect the WD host may be configured as an application within the mobile station modem . The WD host may call the audio decoder the video decoder the display processor or a combination thereof for any audio visual AV processing needs. The WD host may run on a central processing unit CPU e.g. within the application processor of the mobile station modem . Further the WD host may also configure an available W PAN modem to act as a wireless display modem.

Referring now to an exemplary non limiting aspect of a WD host is shown and is generally designated . As shown the WD host may include a WD PHY layer . The WD PHY layer may include a transmitter. Further the WD PHY layer may provide inner coding to the video data. The WD host may also include a WD MAC layer . In a particular aspect the WD MAC layer may provide outer coding to the video data. Also the WD PHY layer and the WD MAC layer may operate as described elsewhere herein.

Further as shown the WD host may include a WD network layer . The WD network layer may include a WD transport layer a WD CAS layer and a WD service layer . In a particular aspect the WD transport layer may operate as described elsewhere herein. The WD CAS layer may provide encryption to WD coded data segments. The encryption may be optional and an additional delay or latency may be incurred depending on the complexity of the encryption algorithm used. Since compression may provide a higher level of security than uncompressed data a simple scrambling algorithm may be utilized in order minimize latency incurred due to the encryption.

As indicated in the WD service layer may provide service discovery. Service discovery may occur during the initialization of a WPAN link for a wireless device WD . Service discovery may also occur when any service contention occurs over ultra wide band UWB since UWB is typically an unlicensed band. In a particular aspect service discovery may not introduce any noticeable latency during transmission from the wireless device to a wireless display.

In a particular aspect channel information may be provided to the WD video encoder and the WD video encoder may use the channel information to select appropriate values for rate control parameters rate adaption parameters error resilience parameters or a combination thereof. The channel information may include available bandwidth for data transmission expected PER MTU PDU size of the PHY layer or a combination thereof. The available bandwidth may be a value that accounts for overhead due to outer coding inner coding or a combination thereof. The PER may be determined at least partially based on a signal to noise ratio SNR .

In a particular aspect a WD transport protocol provided by the WD transport layer may be an existing protocol that includes one or more error robustness features. Alternatively the WD transport protocol provided by the WD transport layer may include a new protocol specifically designed for low latency.

Referring to an exemplary non limiting aspect of a WD client is shown and is generally designated . As shown the WD client may include a WD PHY layer . The WD PHY layer may include a receiver. Further the WD PHY layer may provide inner coding to the video data. The WD client may also include a WD MAC layer . In a particular aspect the WD MAC layer may provide outer coding to the video data. Also the WD PHY layer and the WD MAC layer may operate as described elsewhere herein.

As shown the WD client may include a WD PHY layer . The WD PHY layer may include a receiver. Further the WD PHY layer may provide inner coding to the video data. The WD client may also include a WD MAC layer . In a particular aspect the WD MAC layer may provide outer coding to the video data. Also the WD PHY layer and the WD MAC layer may operate similar to the WD PHY layer and the WD MAC layer described in conjunction with .

As shown the WD client may include a WD network layer . The WD network layer may include a WD transport layer a WD CAS layer and a WD service layer . In a particular aspect the WD transport layer may operate similar to the WD transport layer described in conjunction with . The WD CAS layer may provide encryption to WD coded data segments. The WD service layer may provide service discovery.

In a particular aspect channel error information may be provided to the WD video decoder and the WD video decoder may apply the channel error information to error detection recovery concealment or a combination thereof. The channel error information may include PER error distribution error control flags or a combination thereof. The PER may include an instantaneous PER an average PER a burst length or a combination thereof. The error control flags may be inserted into the coded data in the form of user defined slices e.g. SEI to indicate a start of an error a length of an error or a combination thereof.

The WD client may be an application that runs on a WD receiver that may be hosted on a MSM or a dedicated client application on a processor within a WD receiver modem. The WD client may utilize display processing functionality e.g. a video decoding engine available within an external display.

After the input is read at from the display buffers at block the method may proceed to block and a color space conversion may be performed. Specifically the image data may be converted to a YUV format e.g. YUV 4 2 0. At block a scaler routine may be performed. Further at block a frame interpolator FI routine may be performed. The scaler routine and the frame interpolator routine are described below in conjunction with .

Returning to the description of the method after the scaler and frame interpolation routine SFR is performed the method may continue to block and a WDE video encoder may encode the video data. At the same time at block a WDE audio encoder may encode audio data e.g. PCM audio samples from the MDP . From block and block the method may proceed to block and the video data may be processed in the lower layers of the WD host. Thereafter the method may end.

Referring to a scaler and frame interpolation routine SFR designated is shown. The scaler and frame interpolation may be the scaler and frame interpolation routine described in conjunction with .

Commencing at block the image resolution the aspect ratio the native frame rate Nfps or a combination thereof may be read. In a particular aspect the native frame rate may be twenty four frames per second 24 fps twenty five frames per second 25 fps or thirty frames per second 30 fps . Further in a particular aspect the native frame rate may be determined from deinterlace and inverse telecine detection logic in the MDP described above.

Returning to the description of the method at decision step the WD host may determine whether the resolution Res is less than or equal to QVGA. If not the method may proceed to block and the WD host may retain the original resolution and aspect ratio. Thereafter the method may end. If the resolution is less than or equal to QVGA the method may continue to block and the video data i.e. each image thereof may be upsampled cropped padded or a combination thereof to a resolution corresponding to VGA.

Moving to decision step the WD host may determine if the frame rate FPS is less than or equal to the native frame rate. If not the method may end. Otherwise if the frame rate is less than or equal to the native frame rate the method may proceed to block and the WD host may perform frame interpolation in order to interpolate the frame rate to the native frame rate. Thereafter the method may end.

In a particular aspect the MDP may be configured for VGA or higher resolution output. Or the MDP may be configured for a default resolution frame rate and refresh rate for 7 K and above. In another aspect the scaler and frame interpolation routine may be executed as part of a WD profile in the MDP and the scaler and frame interpolation functions may be performed within the MDP. In still another aspect the scaler and frame interpolation routine may be executed within the WD host and the scaler and frame interpolation functions may be performed within the WD host.

Referring to a WD video encoder is shown and is generally designated . As illustrated the WD video encoder may include a source . The source may provide raw video to one or more downstream components within the WD video encoder . A scalability module may be connected to the source . A simple maximum entropy ME module may be connected to the scalability module . Further a simple mode decision module may be connected to the simple ME module and an error resilience module may be connected to the simple mode decision module .

As further shown in a rate control module may be connected to the error resilience module . A rate adaption module may be connected to the rate control module . Additionally a bitstream engineering module may be connected to the source the scalability module the error resilience module and the rate adaption module .

In a particular aspect the simple ME module may not include any B slices in order to provide low latency encoding. The simple ME module may utilize a single reference picture for simplified buffer management error resilience error recovery or a combination thereof. Also the simple ME module may provide a motion search that is optimized with cache for fixed search range e.g. 64 and pixel reads.

The simple mode decision module may utilize intra frames and inter frames. For intra frames a 16 16 mode may be used. Further an 8 8 mode may be used. Also a 4 4 mode may be used. In a particular aspect the simple mode decision module may not utilize rectangular modes or planar modes. The simple mode decision module may utilize four simple 4 4 modes out of 9 modes. Inter frames may be used for early high accuracy skip detection. Also inter frames may be used for relatively fast encoding and decoding in order to achieve relatively low latency. In a particular aspect parts or all of P frames in a temporal enhancement layer may be dropped to match video bitrate with instantaneous channel bandwidth to accommodate higher FEC i.e. outer and inner coding rate to mitigate deep fades or loss of channel bandwidth to higher priority service in UWB.

In a particular aspect the WD video encoder may perform a light weight or low complexity compression and the WD video encoder may achieve compression ratios of 5 1 to 25 1. In a particular aspect resolutions and frame rate from VGA 30 fps to 1080p60 may be coded at bitrates from 4 Mbps to 300 Mbps i.e. the range of data throughput for UWB. The WD video encoder may provide visually lossless compression for high image quality. Any compromises in quality may result in a poor user experience. Low complexity encoding may be utilized in order to reduce power consumption. Relatively complicated predictions may not be used given the moderate compression ratio requirements. Low latency encoding may be achieved using multiple slices frame with or without control of slice size bytes slice as described earlier.

In a particular aspect error resilience may be achieved by using selective refresh in order to minimize hiccups in transmission and to maintain a transparent user experience. Given light compression slice or picture redundancies and intra refreshes yield a more seamless recovery than macroblock MB refresh. As such depending on the channel PER and random access needs a redundant slice intra coded may be introduced at periodic intervals. It may be appreciated that even when large bandwidths are available such as in millimeter wave bands uncompressed video may not be resilient to errors compared to lightly compressed but resilient video. For example by adding appropriate redundancy with loss in compression intra frames may have orders of magnitude higher entropy compared to subsequent P frames. Also an increase in group of pictures GOP length but suitably multiplexed in a redundant intra frame may be used for error recovery when primary intra frame is corrupted.

Referring now to a GOP structure for error resilience and acquisition is shown and is generally designated . The GOP structure may be utilized by the error resilience module within the WD video encoder . As shown the GOP structure includes an i frame followed by a series of p frames that terminate at a random access point RAP aka an acquisition point. A unit of time e.g. one second may elapse from the i frame to the RAP . An acquisition GOP may follow the acquisition point . The acquisition GOP may include a plurality of p frames . The acquisition GOP may be followed by a series of p frames that may end after a number N of seconds. N indicates the end of the sequence.

Returning to the description of the WD video encoder the rate control module within the WD video encoder may perform a constant bitrate CBR type operation to minimize delays that may be introduced due to sharp fluctuations in instantaneous bitrate. The rate adaption module may perform rate adaption in order to fit the slices into the pre assigned address space within the common buffer described above. The size in the buffer may be based on the MTU PDU sizes determined during service discovery initialization channel contention or a combination thereof.

The scalability module may provide scalability that is primary temporal in order to cater to video having a frame rate of sixty frames per second 60 fps . Two prediction chains may be used with zero GOP or scene based GOP. For example if a first row of MBs were identified as intra during simple ME provided by the simple ME module the entire frame may be coded as intra provided a minimum GOP length was achieved in the previous GOP. As shown in a multiple slice structure may also be adapted for scalability.

Referring now to an exemplary non limiting aspect of a WD audio encoder is shown and is generally designated . As shown the WD audio encoder may include a source that may provide one or more pulse code modulation PCM samples to one or more downstream components within the WD audio encoder . illustrates that an audio scalability module may be connected to the source . Further a low delay low complexity audio encoder may be connected to the audio scalability module . An error resilience module may be connected to the low delay low complexity audio encoder .

In a particular aspect the audio scalability module may provide stereo audio data in one bitstream and additional channels e.g. 5.1 in separable bitstreams. Further scalability may be optional supported through packaging of multi channel audio data into separable bitstreams that may be identified at a transport layer.

In a particular aspect audio bitrate is not a concern. As such the low delay low complexity audio encoder may utilize high bitrate high quality encoding such as advanced audio coding low complexity AAC LC . The error resilience module may introduce redundancy e.g redundant frames where interpolation or error concealment fails.

As depicted in the WD audio encoder may output coded audio bitstreams and metadata for smart encapsulation e.g. a scalable bitstream for on the fly adaption based on display capabilities.

A CPB formulator module may be connected to the base entropy decoder and the enhanced entropy decoder . Further an inverse prediction module may be connected to the CPB formulator module . As illustrated an error recovery module may be connected to the bitstream buffer and the inverse prediction module . An inverse quantization inverse transformation module may be connected to the inverse prediction module . Moreover a reference reconstruction picture buffer may be connected to the inverse prediction module and the inverse quantization inverse transformation module . A display processing module may be connected to the reference reconstruction picture buffer and a display may be connected to the display processing module .

In a particular aspect one or more display parameters may be input or otherwise provided to the bitstream buffer . The display parameters may include a resolution value a refresh rate a frame rate an input format support or a combination thereof. Error information from one or more lower layers in the WD client may be provided to the error recovery module . The error recovery module may replace one or more corrupted network abstraction layer NAL units with redundant NAL units. Alternatively the error recovery unit module may skip the corrupted NAL units. The error recovery module may also provide one or more error concealment flags to the inverse prediction module . The CPB formulator module may combine a base image from the base entropy decoder with an enhanced image from the enhanced entropy decoder to form a single image of decoded slice MB data.

In a particular aspect bitstreams provided by a WD host to a WD client may be designed for sequential decoding and buffer management for out of order decoding may not be utilized. Additionally error concealment flags from error indicators embedded within the bitstream may override decoding for a current frame and force error concealment either simple copy or substitution of redundant slices in place of erroneous slices.

Referring to a third aspect of a wireless display system is depicted and is generally designated . As shown the system may include a mobile station modem . The mobile station modem may include a modem an application processor and a WD server . The modem may include a MAC layer and a PHY layer . The application processor may include an application layer and a transport layer . The transport layer within the application processor may be connected to the MAC layer within the modem . As shown the WD server may include an application layer a transport layer a MAC layer and a PHY layer . The application layer within the WD server may be connected to the application layer within the application processor . Further the transport layer within the WD server may be connected to the transport layer within the application processor .

In order to avoid the decoding of content received at the WD host i.e. the WD server and reduce latency and power content may be intercepted at the transport layer on the receive chain of the application processor prior to the application layer within the application processor processing such as content video or audio decoding.

The application layer within the WD server may communicate with all multimedia applications on the mobile station modem e.g. via Open Interface or an application programming interface API . Application specific transport packets e.g. MediaFLO may be repackaged to WD transport packets. In a particular aspect audio video synchronization may be maintained through the appropriate mapping of time stamps. Additionally media from an output of an MDP may be transmitted to the display as demanded by the application or when power is not critical on a mobile device e.g. when the mobile device is being charged. WD packets may be delivered over WD MAC PHY to the WD client on the external display where transport packets are parsed. Video data may be sent to a WD video decoder and audio may be sent to a WD audio decoder. The display processor on or within the display device may further process the decompressed video to fit the display device . This process may include error recovery. Intensive computational operations and power intensive operations may be shifted from a battery powered mobile device to a wall powered display .

One or more aspects of the present disclosure provide a low latency e.g. desired latency scalable architecture for wireless display that is power efficient for handhelds. Further the coding methods described herein satisfy rate adaptation error resilience recovery and scalability requirements. Larger bandwidths on WPAN networks e.g. UWB may be used to encode at larger bitrates and provide higher quality and improved error robustness through appropriate random access and refresh mechanisms. The use of B frames may be eliminated and a progressive P frame mode may be used to pipeline encoder and decoder operations to reduce end to end latency and complexity. The selection of video packets size e.g. NALU length may be adapted to meet outer and inner coding rates block lengths in order to reduce overhead and increase bitrate. One or more of the systems disclosed herein may be streamlined in order to support a systematic pipelined flow of data through the application transport and MAC PHY layers in order to reduce latency.

Additionally in a particular aspect the systems disclosed herein are transparent to means of reception of content. In other words media may be received over any of many possible means including conversational e.g. video telephony VOD pseudo streaming stored medium broadcast e.g. DTV mobile TV or a combination thereof. A single content interface format may simplify processing at a WD host. Further processing requirements at a display may be simplified if MDP is used to modify media to fit display requirements.

Other aspects described herein may minimize the amount of video processing and data transfers over a memory bus. Accordingly a low power low cost low delay solution that is optimized for mobile devices may be provided. This may enable a mobile device to forward multiple received media content to external display which may present it in various forms customizable by user or application developer. One or more aspects herein may prevent additional generation s of compression in order to minimizing the impact on the quality of experience as related to a user experience related to audio visual quality. An information exchange or a negotiation may not be required to fit the data to display characteristics. Display adaptations may be carried out at a display processor. Further error resilience at a transport layer may be provided through simple duplication of the appropriate payload.

In a particular aspect near field communication NFC may be used to establish a WD peer to peer communication link between a mobile device and a wireless display. In such an aspect the mobile device and the wireless display may include an NFC reader. NFC may be used for the exchange of encryption keys and WD channel setup information. Such information may include frequency and initial bandwidth for all available short range high speed wireless links. A prioritization protocol running on both mobile and display may decide which of the available common links will be used for the peer to peer connection. A follow on NFC exchange may be performed if the primary decision by the protocol fails. In fact multiple NFC exchanges may be performed. Following a successful decision a peer to peer connection may be established between the mobile device and the wireless display as per the channel parameters dictated by the protocol.

Once the WD channel is established the WD session may commence and the mobile device may deliver content to the wireless display over the WD channel or link. Follow on bandwidth and channel re establishment negotiations may occur over this link. Current links e.g. W VGA W HDMI Wireless USB and future links e.g. WirelessHD may be included in the list of available high speed links on the mobile device and the wireless display. The most suitable link may be selected by the WD prioritization protocol.

It is to be understood that the method steps described herein need not necessarily be performed in the order as described. Further words such as thereafter then next etc. are not intended to limit the order of the steps. These words are simply used to guide the reader through the description of the method steps.

In one or more exemplary aspects the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that can be accessed by a computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also any connection is properly termed a computer readable medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of medium. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

Although selected aspects have been illustrated and described in detail it will be understood that various substitutions and alterations can be made therein without departing from the spirit and scope of the present invention as defined by the following claims.

