---

title: Multimodal portable communication interface for accessing video content
abstract: A portable communication device has a touch screen display that receives tactile input and a microphone that receives audio input. The portable communication device initiates a query for media based at least in part on tactile input and audio input. The touch screen display is a multi-touch screen. The portable communication device sends an initiated query and receives a text response indicative of a speech to text conversion of the query. The portable communication device then displays video in response to tactile input and audio input.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09348908&OS=09348908&RS=09348908
owner: AT&T Intellectual Property I, L.P.
number: 09348908
owner_city: Atlanta
owner_country: US
publication_date: 20130719
---
This application is a continuation of U.S. patent application Ser. No. 13 569 722 filed Aug. 8 2012 which is a continuation of U.S. patent application Ser. No. 12 283 512 filed Sep. 12 2008 which issued as U.S. Pat. No. 8 259 082 on Sep. 4 2012 all of which are incorporated by reference herein in their entirety.

The present invention relates generally to wireless devices and more particularly to multimodal wireless devices for accessing video content.

As portable electronic devices become more compact and the number of functions performed by a given device increase it has become a significant challenge to design a user interface that allows users to easily interact with a multifunction device. This challenge is particularly significant for handheld portable devices which have much smaller screens than desktop or laptop computers. The user interface is the gateway through which users receive content and facilitate user attempts to access a device s features tools and functions. Portable communication devices e.g. mobile telephones sometimes called mobile phones cell phones cellular telephones and the like use various modes such as pushbuttons microphones touch screen displays and the like to accept user input.

These portable communication devices are used to access wide varieties of content including text video Internet web pages and the like. Increasingly very large volumes of content are available to be searched. However the current portable communication devices lack adequate support systems and modalities to allow users to easily interface with the portable communication devices and access desired content.

The present invention generally provides methods for accessing media with a portable communication device. In one embodiment the portable communication device has a touch screen display that receives tactile input and a microphone that receives audio input. The portable communication device initiates a query for media based at least in part on tactile input and audio input. The touch screen display is a multi touch screen. The portable communication device sends an initiated query and receives a text response indicative of a speech to text conversion of the query. The query may be initiated by a user input such as a button activation touch command or the like. The portable communication device then displays video in response to tactile input and audio input.

These and other advantages of the invention will be apparent to those of ordinary skill in the art by reference to the following detailed description and the accompanying drawings.

At least one embodiment of the present invention improves the user experience when accessing large volumes of video content. Mobile video services e.g. Internet Protocol Television IPTV allows instant access to a wide range of video programming in a variety of usage contexts. Discussed below are systems that leverage the capabilities of modern portable communication devices to allow users to express their intent in a natural way in order to access the video and or related content. Multimodal user interfaces could be used in systems for accessing video described by both traditional electronic program guide EPG metadata as well as enhanced metadata related to the content. As used herein metadata and or enhanced metadata is information related to media such as closed caption text thumbnails sentence boundaries etc.

In a specific embodiment portable communication device uses Wi Fi to talk to an Access Point not shown which is connected to the Internet. That is the only wireless connection is to the Access Point. Portable communication device fetches a web page from multimodal portal or media processing engine web servers over IP. Alternatively portable communication device uses the cellular network EDGE which is second generation wireless or 3G which is third generation wireless to access the Internet.

Multimodal portal and or media processing engine are all connected via IP such as a wired network or series of networks. A browser such as the browser on the portable communication device gets the web page via the URL from a web server e.g. at multimodal portal and or media processing engine . The URL that the portable communication device goes to actually corresponds to a proxy server that routes the domain directory from the open Internet to a domain directory inside a network firewall so that a web page can be developed within the firewall.

Effectively multimodal portal runs the proxy to route the traffic to a web server which could be in multimodal portal or could be in media processing engine . In a specific embodiment a static html page is retrieved that contains javascript. That javascript does all the work in handling the logic of the static web page. In at least one embodiment only one page is used but different views or anchors to the same page are shown. The javascript talks to the speech plugin which sends the audio to the multimodal portal . The javascript gets the recognized speech back and shows it on the html page. Then AJAX is used to call the natural language understanding and database API to get the understanding and database results. When a user clicks on a TV icon on the details page as shown on the portable communication device it loads a different page that has the logic to send video to the display device .

Media search and retrieval system depicts an exemplary system for use in serving media content to a mobile device. One of skill in the art would recognize that any appropriate components and systems may be used in conjunction with and or in replacement of the herein described media search and retrieval system . For example media systems as described in related U.S. patent application Ser. No. 10 455 790 filed Jun. 6 2003 and U.S. patent application Ser. No. 11 256 755 each of which incorporated herein by reference may be used as appropriate.

Media archive is in communication with media processing engine . Media processing engine is also in communication with one or more media sources and content database . Content database may contain one or more models for use in the media search and retrieval system namely a speech recognition model and a natural language understanding model.

In a specific embodiment the portable communication device client gets automatic speech recognition ASR back and sends that to understanding logic via an AJAX call. The understanding comes back and the portable communication device client parses it to form the database query also via AJAX. Then the portable communication device gets a list of shows that meet the search criteria back. Alternatively the portable communication device gets ASR understanding and database results all in one communication from multimodal portal without having the portable communication device client make those two AJAX calls. Multimodal portal may still send back intermediate results.

In at least one embodiment the static html page comes from a web server not shown in but that could be in multimodal portal or media processing engine . The proxy server on multimodal portal routes the traffic to this web server. For simplicity the ASR and NLU are described herein as coming from multimodal portal and the database query goes to media processing engine . One of skill in the art would recognize that other network arrangements may be used.

Speech recognition may be performed in any specific manner. For example in at least one embodiment speech recognition functions described herein are performed as described in related U.S. patent application Ser. No. 12 128 345 entitled System and Method of Providing Speech Processing in User Interface filed May 28 2008 and incorporated herein by reference in its entirety.

Portable communication device may be any appropriate multimedia communication device such as a wireless mobile or portable telephone. For example portable communication device may be an iPhone BlackBerry SmartPhone or the like. Components features and functions of portable communication device are discussed in further detail below specifically with respect to .

Media processing engine receives a query from portable communication device . Media archive is any appropriate storage and or database for storing requested media. The requested media is received at the media archive from the media processing engine . Accordingly media processing engine is any appropriate computer or related device that receives media from the media sources and generates media clips segments chunks streams and or other related portions of media content. Media generation chunking and or segmenting may be performed in any appropriate manner such as is described in related U.S. patent application Ser. No. 10 455 790 filed Jun. 6 2003 incorporated herein by reference. Media sources may be any appropriate media source feeds such as channel feeds stored channel content archived media media streams satellite e.g. DirecTV feeds user generated media and or web content podcasts or the like. In alternative embodiments other databases may be used as media sources . For example media sources may include a database of movies in a movies on demand system a business e.g. restaurant etc. directory a phonebook a corporate directory or the like. Though discussed herein in the context of searching for and or displaying video based on content title genre channel etc. one of skill in the art would recognize that other available databases may be used as media sources . Accordingly search terms and or displays e.g. as queries etc. may include different speech recognition models understanding models and button labels and or information for actors directors cuisine city employee information personnel information corporate contact information and the like.

Multimodal portal may be any appropriate device server or combination of devices and or servers that interfaces with portable communication device regarding speech to text conversion. That is multimodal portal performs speech to text conversion processes in accordance with features of the present invention discussed below. To accomplish such conversion multimodal portal receives speech from portable communication device to convert speech to text. Accordingly multimodal portal may include componentry for automatic speech recognition. In at least one embodiment this automatic speech recognition is a web based application such as one using the Watson automatic speech recognition engine. Multimodal portal may also include componentry for natural language understanding. Of course automatic speech recognition and or natural language understanding may also be performed at another location such as a web server not shown or media processing engine . For simplicity it is described herein as being performed at multimodal portal but in some embodiments is performed elsewhere.

The automatic speech recognition and natural language understanding use models based on information e.g. show title genre channel etc. from content database . In at least one embodiment models are used that correspond to inputs e.g. requests queries etc. from portable communication device . For example as will be discussed further below with respect to method of a speech input on portable communication device may be in response to a specific request type and an appropriate model to address that request type may be employed at multimodal portal and or content database .

In a specific example a title button discussed below with respect to may be pressed on portable communication device and speech corresponding to a user input title may be sent to multimodal portal a title model at multimodal portal may address the user input speech based on title information from the content database . The model recognizes the speech input from portable communication device and returns the recognized title to portable communication device for display. A user may then initiate a search e.g. by pressing a search button which sends the title to the language understanding component which parses the exact title and executes a query to be issued to media processing engine using that exact title.

In the same or alternative embodiments other models may be used that correspond to genre channel content time or other categories.

Display device may be any appropriate device for displaying media received from media processing engine . In some embodiments portable communication device is used to initiate and or control display of media at display device . That is display device may be a television computer video player laptop speaker audio system digital video recorder television streaming device and or any combination thereof. In at least one example display device is a television and or related equipment using Windows Vista Media Center to receive and display media content from portable communication device .

Portable communication device may be any appropriate multimedia communication device such as a wireless mobile or portable telephone. For example portable communication device may be an iPhone BlackBerry SmartPhone or the like. One of skill in the art would recognize that myriad devices could be modified and improved to incorporate the features of and perform the functions of portable communication device . For example an iPhone could be modified to include a speech application or widget that would enable the iPhone to be used as portable communication device .

Portable communication device has a touch screen display in a housing . Portable communication device also includes a microphone . In at least one embodiment Portable communication device has additional modal inputs such as thumbwheel and or one or more buttons . In at least one embodiment a button may be a walkie talkie e.g. push to talk style button. In such an embodiment speech entry may be performed by pressing the button speaking into the microphone and releasing the button when the desired speech has been entered. Such an embodiment would simplify user input by not requiring touch screen display or other tactile entry both before and after speech input. Any other appropriate inputs may also be used.

Touch screen display may be any appropriate display such as a liquid crystal display screen that can detect the presence and or location of a touch e.g. tactile input within the display area. In at least one embodiment display is a multi touch screen. That is display is a touch screen e.g. screen table wall etc. or touchpad adapted to recognize multiple simultaneous touch points. Underlying software and or hardware of portable communication device discussed below with respect to enables such a display .

Housing may be any appropriate housing or casing designed to present display and or other inputs such as microphone thumbwheel and or buttons .

The additional modal inputs microphone thumbwheel and or buttons may be implemented using any appropriate hardware and or software. One of skill in the art would recognize that these general components may be implemented anywhere in and or on portable communication device and the presentation in is for representative depiction. Other inputs and or locations for inputs may be used as necessary or desired.

Portable communication device contains devices that form a controller including a processor that controls the overall operation of the portable communication device by executing computer program instructions which define such operation. The computer program instructions may be stored in a storage device e.g. magnetic disk FLASH database RAM ROM etc. and loaded into memory when execution of the computer program instructions is desired. Thus applications for performing the herein described method steps such as those described below with respect to method are defined by the computer program instructions stored in the memory and or storage and controlled by the processor executing the computer program instructions. The portable communication device may also include one or more network interfaces for communicating with other devices via a network e.g. media search and retrieval system . The portable communication device also includes input output devices e.g. microphone thumbwheel buttons and or a remote receiver such as a Bluetooth headset etc. that enable user interaction with the portable communication device . Portable communication device and or processor may include one or more central processing units read only memory ROM devices and or random access memory RAM devices. One skilled in the art will recognize that an implementation of an actual computer for use in a portable communication device could contain other components as well and that the portable communication device of is a high level representation of some of the components of such a portable communication device for illustrative purposes.

According to some embodiments of the present invention instructions of a program e.g. controller software may be read into memory such as from a ROM device to a RAM device or from a LAN adapter to a RAM device. Execution of sequences of the instructions in the program may cause the portable communication device to perform one or more of the method steps described herein. In alternative embodiments hard wired circuitry or integrated circuits may be used in place of or in combination with software instructions for implementation of the processes of the present invention. Thus embodiments of the present invention are not limited to any specific combination of hardware firmware and or software. The memory may store the software for the portable communication device which may be adapted to execute the software program and thereby operate in accordance with the present invention and particularly in accordance with the methods described in detail above. However it would be understood by one of ordinary skill in the art that the invention as described herein could be implemented in many different ways using a wide range of programming techniques as well as general purpose hardware sub systems or dedicated controllers.

Such programs may be stored in a compressed uncompiled and or encrypted format. The programs furthermore may include program elements that may be generally useful such as an operating system a database management system and device drivers for allowing the portable communication device to interface with peripheral devices and other equipment components. Appropriate general purpose program elements are known to those skilled in the art and need not be described in detail herein.

Display includes a speak button . In at least one embodiment speak button is implemented by processor of and when speak button is touched or otherwise activated initiation and or termination of procurement of speech from a user is enabled. That is when speak button is touched or otherwise activated speech recording is begun and or ended. One of skill in the art would recognize that speak button location and depiction is exemplary.

Display also includes a text button . Text button allows the user to enter text to the right of the button to build the entire query. The user then touches the text button to send the query to the understanding component. In at least one embodiment if a user uses a one step speak button operation the recognition result shows up in a text button text field .

Display also includes a search button . Search button takes the input from the content button title button genre button and channel button and builds a string to send to the understanding component. In at least one embodiment content button title button genre button and channel button may be pressed by a user as a touch button. This tactile input may initiate a speech recording may cause a pull down list to be displayed and or may otherwise provide information to and or collect information from a user. Conventional web browsing and or searching may be engaged by content button title button genre button and channel button such as enabling text and or speech entry displaying lists and or any other appropriate feature.

For example a user may touch content button title button genre button and or channel button and the labels of the button will change to STOP. The user speaks and then touches the content button title button genre button and channel button again e.g. touches the button labeled as STOP and the label goes back to its original label e.g. content title genre channel .

The recognition result gets filled into a corresponding text field e.g. each of content button title button genre button and channel button may have its own associated text field similar to text field or pull down. If use speak button the text in text field will be filled in with the recognition or the user can type in text. In one example if a user entered Evening News using the speak button then the text field associated with title button is filled in with the actual exact title corresponding to the Evening News The Late Evening News and Commentary for example. Anything input via speech or otherwise will be used to build the string sent to the understanding component which then can be used to build the actual database query such as with a query API to media processing engine that returns the result in XML which is parsed by the portable communication device . In another implementation the exact title is filled into the text field next to title button after the understanding data is parsed since it will contain the exact title genre channel etc.

Display may display a GUI designed specifically for media searching. This GUI may be based off a traditional Internet browser e.g. Safari Firefox Chrome etc. that includes a speech plug in. In other embodiments the speech plug in may be an application used in coordination with display and or processor of .

In coordination with display buttons and or touch buttons e.g. content button title button genre button and or channel button audio can be recorded. A user touches a button e.g. button touch buttons etc. to speak and touches the same button to stop speaking. In some embodiments associated audio file is sent to the multimodal portal for recognition. In other embodiments audio is streamed to the multimodal portal and a response is sent to portable communication device after endpointing so the user does not need to touch a button to stop the recording. The detection of silence after the spoken query will indicate that the user is finished. As discussed above the information associated with the recorded or streamed speech is then used to populate and or suggest populations for text field associated with content button title button genre button and or channel button .

In step a graphical user interface is sent to and displayed on portable communication device . The GUI may be a display as shown above in . That is the GUI may be a web page for display on a browser on portable communication device as described above.

In step information is received from the portable communication device . In at least one embodiment the information is received at multimodal portal . In at least one embodiment the information is audio input entered at the portable communication device using microphone in response to activating speak button . That is in response to a command e.g. a tactile input using display or button etc. audio is received at microphone and recorded. In an alternative embodiment information entered using another mode such as using a keyboard displayed on display is received with or in addition to the audio. In the embodiment shown in the information is a request based on use of speak button for a particular title genre channel time or content. That is the information is an audio recording of what the user would like to look up. Of course any other appropriate entry may be used. For example an artist actor directory keyword content time theme etc. may be entered as audio and or using text. In this way any type of media e.g. video audio text etc. may be accessed. In the example in a user activates speech recording associated with the Title section e.g. using a touch button associated with the Title section using a button etc. and speaks the words Evening News into the microphone .

For each piece of information to be received such as time keyword content etc. a separate touch button can be enabled on display . In the same or alternative embodiments other commands may be entered in conjunction with tactile and or audio commands without the used of additional buttons. A word or phrase may then be entered by touching the touch button associated with each keyword time content etc.

In step if the information is an audio recording the audio e.g. speech is converted to text. In the example in the audio of the word Evening News is forwarded to multimodal portal and the speech is converted to text.

In step recognition e.g. speech converted into text of the information received in step is returned to portable communication device .

In step a request for further information is received from portable communication device based on the returned recognition. As described above the recognition result may be sent back to multimodal portal to retrieve more information.

In step additional information is sent to the portable communication device . In some embodiments the additional information is the result of a database query which in this case could display the list of programs that satisfy the database query or the additional information could be the detailed information about a particular program.

In embodiments in which the recognition is initially sent back to the portable communication device portable communication device may issue a request e.g. as a result of user input or without input to receive information about the recognized speech. Iterative refinement of the search may be enacted at any point in method to require and or prompt user to enter more information by tactile input by speech input or by a combination of both tactile and speech input.

In at least one embodiment arrays are used at multimodal portal to map the different ways titles genre and channels are displayed on portable communication device . This array could be loaded from the content description database when the portable communication device loads the application page before the user interacts with it. This is used to coordinate common search terms with their complete information. For example if the query issued in step is a title Jay Leno an array maps to the complete title The Tonight Show with Jay Leno. 

In the example in the title The Late Evening News and Commentary is returned as a title to portable communication device based on an initial search for Evening News . This return may be based on an array or other lookup as discussed above.

In some embodiments after the returned information is displayed a subsequent request may be made by portable communication device to retrieve more information based on the received recognition as in steps and above. In the example of the recognition Evening News is sent back to the multimodal portal . Information related to the query Evening News is looked up as described above and the complete title The Late Evening News and Commentary is displayed in the query results section for the user. In some embodiments the user may be prompted with various options e.g. via dynamically generated pull down menus related to the returned information. For example if multiple content descriptions could be related to the original query choices of titles genres shows times etc. may be displayed for the user on display .

In step a request for media is received. In some embodiments the query is in response to a further user input such as a tactile command e.g. touching search button or further audio input using microphone . In alternative embodiments the query for media is made automatically after receiving the recognition in step . The query for media is made from portable communication device to multimodal portal . The query for media includes the information that was returned in step . That is information e.g. title genre channel etc. related to the original speech input that was found in steps and is sent to multimodal portal which accesses media processing engine to retrieve appropriate media.

In the same or alternative environments after the returned information is displayed in step details of the returned information may be displayed on display . An example of such a detail display is shown below in .

In step media is received at the portable communication device . Media may be sent using any available method. In some embodiments clips segments chunks or other portions of video audio and or text are sent to portable communication device . In alternative embodiments video audio and or text are streamed to portable communication device .

Media sent to portable communication device in step may be acquired directly from media sources or from media processing engine as appropriate. This media may be directly displayed on display .

In step media is sent to another media device such as display device . This display is in response to an input by a user at display . An example of a link to display video on another media device e.g. display device is shown below in . The media is sent to the other media device e.g. display device from media sources or from media processing engine as appropriate.

The method ends at step . In this way multimodal input including speech input may be used for media searching access and display in coordination with existing portable communication devices e.g. Apple s iPhone and or video archiving systems e.g. AT T s Miracle System .

The above described method may also be used to allow a portable communication device to be used as a television and or computer remote control to control a digital video recorder DVR or to perform other similar functions. That is the display may be configured using an appropriate GUI to represent a remote control for a television or DVR. In this way multimodal input including speech input may be used for controlling television viewing and recording as well as searching for shows to display or record.

The foregoing Detailed Description is to be understood as being in every respect illustrative and exemplary but not restrictive and the scope of the invention disclosed herein is not to be determined from the Detailed Description but rather from the claims as interpreted according to the full breadth permitted by the patent laws. It is to be understood that the embodiments shown and described herein are only illustrative of the principles of the present invention and that various modifications may be implemented by those skilled in the art without departing from the scope and spirit of the invention. Those skilled in the art could implement various other feature combinations without departing from the scope and spirit of the invention.

