---

title: Systems and methods for media personalization using templates
abstract: Systems and methods for generating edited media. In an embodiment, one or more media assets are received. A theme template comprising one or more entries is retrieved, and the entries are populated with the received media assets to generate one or more composite media products. The media assets may comprise both static and dynamic media assets from multiple data sources. For instance, the dynamic media assets may be user-supplied, whereas the static media assets are retrieved from a structured database and remain the same for a given theme template.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09277198&OS=09277198&RS=09277198
owner: NEWBLUE, INC.
number: 09277198
owner_city: San Diego
owner_country: US
publication_date: 20130131
---
This application claims the benefit of priority under 35 U.S.C. 119 e of U.S. Provisional Application Ser. No. 61 593 231 filed Jan. 31 2012 and entitled Systems and Methods for Media Personalization Using Templates and of U.S. Provisional Application Ser. No. 61 593 239 filed Jan. 31 2012 and entitled Systems and Methods for Authoring Theme Templates for Media Personalization and of U.S. Provisional Application Ser. No. 61 593 244 filed Jan. 31 2012 and entitled Systems and Methods for Personalized Media Delivery all of which are incorporated herein by reference in their entirety as if set forth in full.

The embodiments described herein generally relate to the fields of media processing and network communication systems and more specifically to systems and methods for personalizing media using a communication network.

With the explosion of social networking cloud storage and computing faster network speeds and smart phones and tablets with video capability people are capturing and sharing video in greater and greater amounts. Thus it is not uncommon for mom or dad to capture a video of their child being dropped off at school participating in an activity or just running around the house with their smart phone and then immediately email the video to friends and family or post it on a social networking page. Often however the quality of these videos is not very good. For instance the image is choppy and bounces around there is little or no audio etc. In addition the video is not very professional looking. For example there is no title introduction sound track etc. which are all things if done well that can make even impromptu videos such as those described above compelling to even an uninterested observer. Without these elements while the video may be interesting and meaningful for mom and dad it may not be of interest to anyone else.

As a result there are applications available that will allow a user to edit a video and generate much more refined productions in which some of the choppiness is smoothed out filtering is applied to enhance the video quality sound effects are applied and synchronized with the images a theme can be applied etc. But often these tools require a larger investment of time than the average user is willing to commit. Unfortunately the conventional resources required to perform such editing do not allow for quick easy editing that can produce a more interesting and professional video. Further conventional devices used to capture video or to share video over the Internet are often resource constrained. For example such devices may be limited by processing capability power or other resources. As a result the video typically will lack editing or other features that would greatly improve the quality of the shared video.

Accordingly in an embodiment a system for generating edited media is disclosed. The system comprises at least one hardware processor and at least one executable software module that when executed by the at least one hardware processor receives at least one media asset retrieves at least one theme template comprising at least one entry and populates the at least one entry of the at least one theme template with the at least one media asset to generate one or more composite media products.

According to an embodiment a method for generating edited media is also disclosed. The method comprises receiving at least one media asset retrieving at least one theme template comprising at least one entry and populating the at least one entry of the at least one theme template with the at least one media asset to generate one or more composite media products.

Systems and methods media for personalization and sharing of media are presented. In one embodiment the present method and tool or system allows a user to take a video clip that was just shot e.g. with a mobile device and turn it into something personalized and polished and to route the polished product to desired destinations quickly and easily. For example in some implementations the tool or system allows or enables a user to apply a video tag also referred to as a Personalization to media from any device. Further the system allows a user to modify and configure a video tag from any device. The user can also preview the modified video in real time. As a result a user can quickly and easily generate a polished video preview it and share it with friends or post it to a social networking page.

As used herein a video tag video tag template theme theme template production or production template includes a set of instructions to personalize media. In one embodiment the video tag defines a set of effects to apply to a video along with embellishments such as music and title style. The video tag defines the process for producing a video clip in a particular style and also includes options for user modification. In general a video tag represents a configuration that can include a sequence of images video clips titling sounds effects transitions mixing etc. to wrap the video clip into a complete and polished video.

As noted above in some circumstances the devices used to capture video or to share video over the Internet are resource constrained. For example a mobile phone or other device may be limited by processing power bandwidth battery power or other resources when editing and sharing video. In one embodiment a client application is provided to the user of a resource constrained device that facilitates video personalization without excessive consumption of resources. A corresponding application is provided on for example a server to perform portions of the video customization and sharing. As described below this advantageously facilitates sophisticated media personalization despite resource constrained user devices.

In other circumstances a user may use multiple devices to capture video. For example a user may have a cell phone capable of capturing video as well as another mobile device with similar capture capabilities. A user may have a set of preferences for personalizing video regardless of the device used to capture the video. In one embodiment systems and methods are provided for making a user s personalization and sharing settings available across multiple devices. In other circumstances systems and methods are provided to take simple video and convert it into a fully polished and personalized production. Various combinations of the embodiments described herein are possible.

Turning now to a block diagram of networked computer systems for personalizing and sharing media is shown. The networked computer systems include a user device a network and a server . The user device is communicatively coupled to the network . The server is also communicatively coupled to the network . The user device and server communicate via the network .

In one embodiment the user device is a machine with the ability to communicate over the network . For example in one embodiment the device is a personal computer with a network connection such as an Internet connection or a wireless device such as a mobile telephone or a personal digital assistant with access to a wireless network. The user device comprises an application module . As described in greater detail below the application module operates in conjunction with the server to accomplish the media personalization and sharing described herein.

It will be understood that conventional devices such as those described above with respect to device often include great hardware for video compression so they can squeeze a large amount of video data through the network . Therefore such devices are often optimized for transcoding of the video which often makes the process of compressing video uploading it to a server where it can be processed recompressed and downloaded to device faster than processing the video on the device but also allows more sophisticated processing as described below.

For example in one embodiment the application module is configured to access media such as a video stored on the device . The application module is configured to upload this media to the server via the network . The application module is also configured to receive input from a user of the device in the form of customization options. The application module transmits this input to the server . In some embodiments the application module receives media from the server that are previews of what the personalized media will look like once it is fully processed. The application module displays these previews to the user of the device . The user can provide additional input to the application module based on the previews. The application module then sends the additional input to the server via the network . In some embodiments this process of receiving previews presenting the previews to the user and sending additional input to the server continues at the application module until the user is satisfied with the personalized media. After receiving an indication of acceptance the application module is configured to transmit an indication of the acceptance to the server . In some embodiments the application module also solicits input from the user on how the personalized media should be shared. The application module transmits this input on how the personalized media is to be shared or published e.g. to Facebook Youtube or other Internet sites. Other examples of the operation of the device and the application module are described in greater detail below.

In one embodiment the server is a computer system with a network connection such as a server a personal computer or other device capable of performing the processes described herein and communicating over a network. The server comprises a transformer module . As described in greater detail below the transformer module operates in conjunction with the application module in order to accomplish the media personalization and sharing described herein.

It will be understood that server is intended to be representative of the resources needed to carry out and implement the systems and methods described. As such server can comprise multiple servers routers processors databases storage devices applications APIs programs user interfaces etc. as needed or required by a particular implementation. Moreover it will be understood that many if not all of these resources can reside in the cloud.

In one embodiment the transformer module receives media such a video clip from the user device as well as an indication of one or more customization options. The transformer module processes the media according to the customization options. In some embodiments the transformer module also generates previews of the personalized media and transmits the previews to the user device . These previews can be provided in real time or near real time as described below. The transformer module receives additional feedback from the user device in response to the transmitted previews and further processes the media responsive to the feedback. In some embodiments the transformer module generates and transmit new previews to the user device based on the feedback. In some embodiments after one or more of these feedback cycles the transformer module receives an indication of an acceptance of the media personalization. The transformer module then shares personalized media according to input received from the device . Other examples of the operation of the server and the transformer module are described in greater detail below.

In one embodiment the network comprises a communication network such as the Internet a local area network a wide area network a virtual private network a telephone network a cellular network a direct connection a combination of these networks or another type of communication network.

Advantageously the systems operate in conjunction to allow resource constrained devices to perform sophisticated user controlled media personalization and to share the personalized media.

The network interface transmits and receives messages via the network . For example the network interface transmits media such as videos to the server via the network and receives previews from the server via the network . The storage is a tangible computer readable medium. It stores for example media such as videos and instructions for causing the processor to perform the functionality described with respect to the application module and the device .

The user interface comprises an interface for presenting information to a user of the device or for receiving input from a user or both. For example the user interface may comprise a touch screen for presenting previews to a user and for accepting input regarding personalization options related to the media being personalized. Other types of devices that communicate information to a user or receive information from a user may also be used. The media capture device comprises a device such as a camera or microphone that captures media. The captured media can be stored in the storage and processed by the processor as described herein. Examples of a user device in this case a mobile user device are illustrated in .

In one embodiment the user account storage stores account records or information for individual users. These account records can be unique for each user. These account records can include one or more video tags associated with a user s account. As noted above a video tag or video tag template is a set of instructions to personalize media. In one example the video tag defines a set of effects to apply to a video along with embellishments such as music and title style. video tags define the process for producing a video clip in a particular style and also include options for user modification. A user account can have one or more video tags associated with it in the user account storage . The set of effects for a particular video tag can have default settings for various settings. Users can modify the default settings for default video tags and thereby create modified or customized video tags. Advantageously by providing default settings users can quickly select and apply a video tag. At the same time by allowing users to customize or modify video tags a high degree of personalization is provided. In general modified video tags are video tags that have been changed in any manner from a default state by a user. Preset storage includes a plurality of preset video tags having their default values. The account associated video tags can include preset video tags modified versions of the preset video tags or both.

In addition each user account record can contain additional information. In one embodiment this additional information can include records that are used for billing. In one particular example the Account record includes information on the minutes of processing applied to media uploaded by a user associated with the account to facilitate usage based billing. In another embodiment the account record for a user contains rules for sharing or propagating the personalized media. These rules can include information such as where to send or place the media e.g. Youtube Facebook etc. In one embodiment these rules are set based on input received from the user device . For example in one embodiment the user selects and identifies where the videos are transmitted and posted. The rules can include information for sending media to services. This information can include account identifiers passwords file format descriptions or other information. In one embodiment a setup wizard or other program runs on the user device in order to walk a user through the configuration of different settings and collect user input for such rules. In one embodiment the types of information collected and stored by the user device and transmitted to the transformer module depend in part on the intended destination for the media e.g. Youtube or other website. In some embodiments the account record also contains other information such as nicknames photos personalized media or un edited media.

The storage is a tangible computer readable medium that stores information for use by the other components of transformer module . In one example the storage stores unprocessed media from user devices partially processed media such as previews and fully processed media such as personalized media that will be shared. In one embodiment the storage also stores instructions for causing the transformer module and its elements e.g. via the processor to perform the functionality described herein with respect to the transformer module and the server .

The processor is configured to process received media according to the information in a video tag as well as other input received at the transformer module from a user device . For example the processor takes one or more media files e.g. videos and other user input e.g. selection of a video tag received by the transformer module and uses them to create personalized media e.g. video file based in part on the instructions in the selected video tag.

The network interface transmits and receives information over a network such as the network . For example the network interface receives unedited media from the user device and transmits personalized media to video sharing sites .

As described in more detail below in one embodiment a transformer module implemented in a server is used to apply a video tag to media to generate personalized output. The transformer module manages a database of users and video tags and . A remote application module communicates with the transformer module via a network to process a video clip. The remote application module sends the transformer module the video clip or other media with instructions for processing e.g. video tag selection and one or more desired destinations.

For the purpose of explanation one embodiment of the communication between the application module and transformer module will now be described. In this example the application module communicates with the transformer module via Hypertext Transfer Protocol HTTP Hypertext Transfer Protocol Secure HTTPS or any appropriate protocol over the network . This communication link can be a wireless or wired connection or both. The Application module logs into user account module to access the user s private set of video tags and account information . The Application module downloads video tag choices from transformer module from the user account module e.g. video tags or the public video tag list e.g. video tags provided by preset storage or both.

Next via the Application module the user chooses a media a video tag and selects some options including typing in a name for the clip. Application module uploads the media video clip bitmaps sounds etc. and user choices to the transformer module . Processor uses the selected video tag and user selected options to control the creation of a finished video. In one embodiment a single video is used to create the finished video. In some embodiments two or more videos can be used in creating the finished video. In one embodiment creating the finished video comprises applying one or more effects to the video. In general an effect or filter may be an operation that is applied to the frames in a video in order to impart a particular look or feel. For example a stabilization or smoothing effect may be applied to the frames in the video. In one embodiment effects may be distinguished from transitions that are designed to alter the way in which a video begins or ends or the way in which one video moves into another video. A sample of effects may be viewed at www.newbluefx.com.

Continuing on transformer module posts the finished video to user selected video sharing and social networking sites . As described above the video sharing and social networking sites can have different formats and require different information when receiving uploaded videos. The transformer module can use information in the user account e.g. rules for propagating the finished videos when posting the finished video. In another embodiment the transformer module can store information about the requirements and interface for uploading video to different sites or services. Additionally the video or a link to the video can be sent to other by email text message etc. In other embodiments the user application can collect rules for sharing the media along with the selection of a video tag and transmit the rules along with the video tag selection.

In an embodiment a production file is an XML file or other format file that carries information used by the processor to assemble a video project. In one embodiment the production file is an intermediate file representing a video tag with all of the options and variables replaced for example with user and or default selections. Options and variables are described in greater detail below. The production file can be generated by a parser operating on a video tag. In one embodiment the production file can be generated after a first pass of a parser through a video tag. In general a production file is a specific plan for creating a video that comprises instructions for the processor on how to assemble the video.

In one embodiment a production file includes one or more video and or audio tracks. Within each track in time order are segments which include an input source a trim point a start time relative to the end of the previous segment a duration one or more plugin effects and one or more transitions. The input source can be a media file reference such as a sound effect a video clip a photo or other reference. The input source can also be a software media generator such as a titler background surface or other generator. The duration can identify a specific length or be set by the length of the media. Plugin effects are referenced by name and include settings. Transitions are referenced by name and include transitions for transitioning into the segment with settings and transitioning out to the next segment with settings.

In one embodiment the video tags or video tag templates and are XML or other format files that are similar to production files. However in video tags one or more of the strings within it have been replaced by unique tokens. These tokens are placeholders for option strings. video tags also include one or more option sets. In one embodiment an option set includes a category name e.g. Title Style and a series of option presets. In one embodiment the option presets include a set of tokens that match tokens in the production and for each token the string or data to replace it with. In some embodiments this string can be a simple preset name or a block of XML or other information. For example the replacement text can be just a simple string. In another embodiment a complex block of text can be used. In some embodiments an XML attribute can be used. An attribute can be just one parameter. An attribute can also be a set of parameters. For explanation as described below an effect may be applied to a segment of the media. A string representing the effect can comprise a block of text that includes nested attributes for each parameter. video tags also include external variable definitions. External variable definitions include a token identifier ID and a name e.g. Title. 

The intro slide segment media is a bitmap picture with some effects applied to it. t is preceded and followed by transition section . One of the option sets contains information for used by the processor to control the transitions in and out of the segment. This means that choosing different options chooses different preset transition choices.

The title segment is generated by a titling plugin. Underlying the title segment is a second track which generates the background. A variable contains the information for the actual name in the title segment . This configuration allows the application module to set the title with a text string. Additionally an external option set contains information used by the processor to set some effects on the clip to achieve a particular look. This is an external option set because this can be used to manipulate the look in different video tags. Because it is external to the video tag it appears to be just another external variable.

The video clip segments are from one or more video files. These are the file or files that the whole video tag was designed to turn into a work of art. For example effects e.g. FX can be applied by the processor to the contents of a video clip such that the video clip is modified by the effects. Since the actual file choice is determined by the user the variable provides a mechanism to set the name of the file externally. In one example the transformer module uses video tag of one or more media clips and optionally some commands from a user and generates a finished video.

For example a particular production file may comprise multiple videos and other media that are overlaid or mixed and displayed or rendered at the same time. These can be blended through the process of compositing. The processing engine can be a powerful video compositor that blends multiple overlaying video tracks. Many of these video tracks can incorporate an alpha channel that defines transparency and opacity. Where the track is transparent the underlying image can be seen through it. The underlying image can be another video track a photo etc. The titles can work the same way in that each title can be generated by software that creates an image that has letters with alpha transparency around them so the letters can be overlaid on photographs videos etc.

In order to illustrate the functionality of the systems described herein one example of the operation of the networked systems is described. Via the user interface on the user device the user chooses a video tag from a set of available video tags. As described above with respect to the video tags can be selected from the user s private video tags or a public video tag list . In other embodiments the video tag may come from any source. For example the video tag may be generated by the user selected from pre existing lists or shared with other users.

The video tag provides options in several categories. The user chooses an option by name or icon via the user interface. The video tag also includes named variables. These represent data that are input directly into the project by the user via the user interface. Two examples are the title text and the file name of the video clip. In some embodiments there are also options that are stored in an external options file that are used to set one or more variables in the video tag. In one example an external options file contains an options set that sets the background color and title font. By storing the options as a separate file the file and its options can be used for multiple video tags. In one embodiment the external option files are stored on the server . In one example the user selects an option via the user interface. The selected option is mapped to the destination video tag as one or more variables. In another example a user selects an external option set such as the external option set of via the user interface. The external option set establishes the look of the video by providing a set of FX presets to choose from.

Once input corresponding to the video tag options and variables has been collected by the application module the input is transmitted to the transformer module of the server . The processor of the transformer module then parses the input. Parsing creates a project file dynamically by substituting options and variables for all tokens. In one embodiment the parsing is done as a search and replace operation by the processor. For example for each token in the video tag the equivalent token in a variable or option is located and the string or data for the token is substituted with the variable or option information.

In one embodiment the processor applies variables after options. This allows a variable to be embedded with an option. For example this allows a set of choices for a media file the options including one option to provide your own media file which in turn is managed with a variable. As described above in one embodiment a variable is user defined. Variables can be combined with options. For example instead of choosing a predetermined string a user can also provide one. In another example instead of selecting one of a plurality of media choices e.g. bitmaps or sound files the user may have the choice to provide the file as well. Similarly a choice of a combination of title font and overlaid effect is an option. A choice to set the bitmap for the title from a preset list is an option while entering a new file is a variable. Selecting the video clip to be processed is a variable.

After parsing the user input and creating the project file the processor can create the personalized media. In one example the processor takes the project file and converts it into a time stamped sequential list of media segments. In some embodiments the parsing is performed concurrently with the processing described here. Thus the step of creating the project file at the processor is optional in some embodiments.

Each segment represents a portion of media to use. The segments include one or more of a track a start time a duration a starting offset a source indication e.g. a file or generator plugin with parameters a transition in including duration an indication of the transition plugin to use and a parameter preset to use a transition out including duration an indication of the transition plugin to use a parameter preset to use and a destination and one or more effects including an effect plugin to use and a parameter preset to use .

In one embodiment in the case of a video file the processor creates one frame of the resulting personalized media at a time. While one embodiment of this process is described it will be appreciated that other processes may be used to achieve similar outputs. For each frame or time stamp of the personalized media the processor performs the following steps.

First the processor identifies each segment that is active at the particular time stamp or frame. Second the active segments are sorted by track such that highest ordered or numbered track is handled first. This sets the order for compositing. Third the processor initializes a blank master frame buffer and a blank master audio buffer. Fourth for each active video segment the processor obtains the media for the frame e.g. video audio or image uploaded from the application module and places the media in a frame buffer. The processor then applies one or more effects from the effect list to the media applies any transition in or transition out that overlaps with the frame and alpha blends the buffer onto the master frame buffer. Fifth for each active audio segment the processor obtains the media for the frame and places the media in an audio buffer. The processor then applies one or more effects from the effect list to the media applies any transition in or transition out that overlaps with the frame and adds the audio to the master audio buffer. Sixth the processor writes the master video and audio frames to an output file stream.

Various optimizations of this process are possible. For example where the frames are processed in order it is beneficial to the current effects and inputs as the processor may reuse all or part of the effects for proximate frames. In order to implement some effects the processor may need time access to the source media. For example in some embodiments stabilization requires that the processor have access to a range of source frames in order to calculate motion vectors. To support this in one embodiment the transformer module stores the input stream in storage such as a FIFO buffer which provides random access to any individual frames within the FIFO. Thus the processor can access frames directly from the FIFO for any effect which needs this access.

In one embodiment as the file is written out to the destination file it is immediately queued for transfer to the destination location. Because the file is sequentially written this file transfer can start immediately before the entire file has been processed.

As described above processing video effects on many devices can be prohibitively expensive in terms of time and resource consumption. For example excessive CPU usage results in high power consumption running down the battery. Also the time delay of waiting for results keeps the device unavailable for other use. In addition even without constrained computational resources configuration of video processing can be problematic. There are complicated steps required in setting up effects processing. Further it can be very slow to develop processing tools that work on a diverse range of devices. For example complex video effects applications that run native on the device require rewrites for every implementation. Further implementing new effects and effect presets to be performed on user devices would require updating and downloading significant amounts of data. Also allowing native code to run inside a browser as a plugin or executable file e.g. exe on the device presents a risky choice to user. For these reasons and the reasons described above it is desirable to have a tool or system that allows a user to choose a video choose and preview options and send it off to be processed remotely and delivered quickly and easily. Additionally it is desirable to have the impact on phone usability minimized.

Certain embodiments relate to methods and systems for media processing selection and preview. As discussed herein embodiments of the invention make it easy with a video enabled device to quickly choose a video and arrange to have it processed personalized and uploaded to video sites with a few quick steps. For example a user can shoot a video clip assign the clip a name quickly choose processing and personalization options and send the clip off to be processed remotely. Advantageously embodiments disclosed herein facilitate cost effective development of a tool that works to facilitate media personalization on a wide range of devices. Further the tool has a low impact on the performance of the user device while providing a hassle free experience for the user. In addition modifications adding new effects can be implemented on the server making the update process transparent and simple for users.

For purposes of explanation the functionality of the application module and its interface with a user and with the server will be described in greater detail below. As described above the application module can run on a wide range of devices e.g. a mobile phone or web browser application . In one embodiment in order to facilitate media personalization the application module first presents the user with a set of available videos to choose from. Next the application module allows the user to select one or more options for editing the video. These options can include trim information e.g. start and end points within a video. The options can also include a video tag. For example the video tag may include a logo and the application module may allow the user to modify logo parameters such as the image used for the logo the type style of the logo transitions into and out of the logo clip as well as the title style and animation. The options selected by the user via the application module can also include one or more effects to apply to the media. After the user makes the selections the application module sends the video and selections to the transformer module over the network to create the personalized video.

In order to make the process visually stimulating and easy to use in one embodiment the application module provides visual feedback via the user interface of the user device during the process of collecting user input and in some embodiments as the video is being processed. The application module receives sets of options that can be selected by the user as well as previews or examples of how the various options look and sound when implemented with the uploaded media.

In one example the application module uploads media clips to the server . For example as shown the application module uploads a video clip to server and uploads a thumbnail image of the video clip to server . In one embodiment the user may initiate the upload process. However in some embodiments the application may extract the thumbnail without user direction and may schedule the uploading of video and thumbnails without further user input.

The application module sets variables and options for the video tag based on user input. As described above the video tag can be thought of as a template. The video tag has information variables and option choices that can be selected by a user. As described herein the video tag may be processed and turned into a production file which is a definition of how to assemble a final video clip.

The application module requests a preview thumbnail and or video clip. The server creates preview thumbnails and or video previews and which it streams back to the application module . In general a thumbnail may be a low resolution version of a still frame or video clip. The requested thumbnail allows the user to what the processing will look like with the added effect without the CPU and time overhead of processing in full resolution. In one embodiment a single frame is used as a thumbnail to show how a particular look will appear. In other cases a thumbnail comprises a video clip to illustrate the look over time e.g. to preview a transition choice.

In one embodiment server also downloads new option choices an option set related to the new preview media and provides the new option choices to the application module . The option sets can be provided as separate files or embedded in video tag files.

The application module integrates options and preview media into the user interface UI and displays the previews and choices and to the user. The user makes a choice via the user interface of the application. The application module sends the choice to the server e.g. sets variables and options for the video tag and requests new previews . This cycle of previews and additional inputs can continue until the user is satisfied with the final personalized media product.

In one implementation the server includes a transformer module . This transformer module takes a video tag file and feeds media and parameters into it to then generate output either in the form of image thumbnails or preview video clips. It should be appreciated that the present system and method are not limited to video and photos for input or output. Other media types such as sound files apply equally well.

In one embodiment after receiving the selection data the server immediately starts creating a preview clip. Generally this is a small format preview file that can be generated and streamed in real time. While still processing the server starts begins a download process to transfer the preview to the application module for immediate viewing.

The application module saves the modified video tag design. In one embodiment the user can assign the video tag a new name. The application module uploads the final changes to the video tag along with the new name and any attached media e.g. sound effects or photos. Server merges the uploaded changes into the original video tag definition and adds it to the user s database so that the user can reuse the video tag later.

In one embodiment application module creates a menu with the preview set of thumbnails. The user chooses a look from the menu. Application module stores the choices and uploads the choices to the server. It is also possible to modify a look. For example a user can change the parameters of the effect applied to the video to create a particular look.

Each effect can have a set of named preset configurations. In general a preset configuration is a particular configuration for an effect s parameters. In one embodiment each effect has a set of parameters that can be manipulated to change the behavior of the effect. For example an effect that creates a glow might have a parameter to control the brightness of the glow and another parameter to control the color. In some embodiments there are between 4 and 10 parameters per effect. Each effect may be provided a set of these presets each with a name.

In one embodiment to facilitate modifying the looks application module requests preset thumbnails from server for the look. Server runs preset effects over the thumbnails and downloads the thumbnails to the application module . The user chooses a preset and modifications. Application module stores the user s choice and uploads the choices to the server . The user can also assign a modified look and a new name via the application module . Application module uploads the final changes to the look along with the name. Server merges the uploaded changes into the original look definition and adds it to the user s database.

After all modifications and user input the user can indicate a final acceptance of the editing options via the application module . This acceptance is stored by the application module and transmitted to the server to indicate that it should process the video. Once the acceptance is indicated if the video has not been uploaded yet the application module also starts sending the video stream to the server . In addition if not previously sent the application uploads the file name and destination trim points video tag selection which may be encapsulated in a MyVideo Tag chunk e.g. text in XML that chooses a particular video tag with options and variables look selection which may be encapsulated in a MyLook chunk and information on where to publish the final product which may be encapsulated in a MyUploads chunk .

In some cases it is desirable to start processing the video stream shortly after the application module starts transmitting the video to the server . This enables immediate creation of preview clips or final renderings even if the file is not completely uploaded. However in some embodiments the server cannot process the stream unless it has the necessary header information. In certain files such as some MP4 files this header information may be placed in a location other than the head of the file e.g. at the tail .

Other embodiments of the systems and methods described above provide enhancements for the process of previewing video at the user device. In some embodiments a motion stabilization effect is performed effectively with two passes. In one example the first pass of the two is to perform motion analysis. This first pass can be far more CPU intensive because in some embodiments the processor analyzes adjacent frames to calculate motion vectors translation scale and rotation between the frames. The second pass is a playback render pass where the processor uses this information from the first pass to shift the images so that the video is smooth. In one embodiment rather than performing both passes multiple times the processor is configured to perform the motion analysis once soon after the video is uploaded. The results of the motion analysis can then be used multiple times by the processor for playback render passes associated with different previews and with the final video product. By doing the complex first pass once per video computing resources at the server are conserved and latency in generating previews is reduced.

In another embodiment the processor is configured to use different resolutions for previews and final products. In particular in one embodiment the processor is configured to generate previews that have a lower resolution that the final product. This results in better download time of the previews that can appear to be in real time to a user. In addition by generating lower resolution previews the server conserves computing resources. In one embodiment the processor is configured to receive an uploaded video clip and to generate an intermediate clip having a lower resolution based on the uploaded video. This intermediate low resolution clip is then used by the processor for generating previews. Once all modifications have been made based on the previews the processor applies the final selections of the user to the original full resolution video to generate the final output.

The parameters that can be manipulated for lowering the resolution of the preview can include depending on the embodiment frame width and height compression bit rate and the actual frames per second FPS . For example if the normal FPS is 30 and preview is generated at 15 FPS then any effects only need to be applied half as frequently cutting processing in half.

In another embodiment it is desirable to begin generating previews before the entire video clip has been uploaded. To accomplish this the processor is configured to start a transcode process as soon as the file starts uploading from the user device to the server . In one embodiment this transcode operation is requested by the application module . Along with the request the application module provides the server with information regarding the format for the transcode or other information.

In some embodiments these optimizations can be combined. For example in one embodiment the processor is configured to initiate a transcode as soon as a video clip begins uploading from a user device. In some embodiments this transcode is one to many in that it renders out multiple streams simultaneously each stream having a different file format with different data. For example one output can be for motion analysis while another output can be used for low resolution preview generation. In one embodiment this transcode process runs synchronously with the uploaded video so as soon as a new block comes in the output streams of data are prepared. In this embodiment the streams can all be read before the file is closed. This makes it possible for the processor to provide the user device with a preview video render before the upload of the video is completed. In this situation the preview render will not play all the way through the end of the clip but it can work with everything that has been uploaded and processed up to the time the preview is provided.

In another embodiment the server and transformer module implement a scheduling process for processing and personalizing media. Advantageously the scheduling process ensures that the user experience is optimal even when there is heavy loading on the server . Where multiple servers implement the functionality described with respect to the server this also allows optimization of server resource allocation so that excess resources are not wasted and so that the servers can respond to spikes in activity without significant delay involved in waiting for new servers to spin up. In one embodiment the transformer module implements a scheduling queue combined with priority assignments to ensure that higher priority renders can override lower priority work.

In one embodiment every render request from a user device is assigned a time stamp and a processing priority by the server transformer module . The transformer module places render requests in a queue. The transformer module organizes the queue first by priority and then by time stamp. Where multiple servers are used each cloud instance allows a fixed number of processing requests simultaneously. In one embodiment the fixed number is a function of how many cores the instance has. For example a server with 8 core processors might support 16 concurrent processes. This ratio can be adjusted to tune for optimal performance.

In order to implement the scheduling process the transformer module assigns different priority levels to different types of tasks. In one embodiment communications between the user device and server are given the highest priority. The next highest priority or high is given to the creation of a video clip for immediate playback e.g. where a user pressed the play button on the interface for the application module . The next highest priority or medium priority is given to the initial upload transcode process that generates the intermediate files for playback and motion analysis. The lowest priority or low priority is given to final rendering for publication and sharing.

By assigning priorities in this manner the transformer module ensures that the real time behavior that is necessary for a favorable user experience continues even when the servers are maxed out and waiting for new servers to come on line. During these peak periods the final renders end up running in the background or queued for later until the log jam is over.

In another embodiment the server also performs load balancing between a plurality of servers that implement the functionality described with respect to the transformer module. The server performs load balancing by assigning application module sessions to different servers. When a new application module session starts the server selects a server for the session based on one or more of CPU usage and processing queues for various servers. The selected server is assigned the session. In some embodiments the server also requests a new server instance when it sees processing activity exceed a threshold. In some embodiments this threshold is based on CPU usage processing queues or both. However as a new server instance can take anywhere from minutes to an hour to come on line the scheduling process described above allows the servers to ensure that high priority work continues while lower priority jobs get delayed.

Continuing at step the application module trims and transcodes the media for upload. This is an optional step that can be performed based on the device that hosts the application module . For example in one embodiment if the device does not have the ability to open a trimmer natively then the application module forces the duration of the clip to a reasonable limit. In another embodiment the application module waits to create a trimmer at a step described below. As shown at at this point the media is at its final resolution but is highly compressed.

Continuing at step the application module uploads the media to the server . As discussed above if the media format puts header information at the end the application module transmits the last header information of the media file to the server first. The server receives the end header of the video and writes it to the end of the file so the file is now full length but with empty data for the entire file except for the very end. The server then reads the end block to access the format data which includes the total media length and any other necessary information. After resolving the header issue the application module starts transmitting the video from the start. This uploading process can continue in the background while other steps are performed. The server starts receiving the video storing it in the file sequentially up to the end block.

Continuing at step the server transcodes the media to multiple formats. In one embodiment the server immediately starts a transcode process while the file is still being uploaded. In one embodiment the transcode process runs as a medium priority thread and reads the source file once but generates one or more output data files simultaneously. In one embodiment the type of output files generated is determined based on input from the application module that requests particular kinds of files. As the source file comes in the transformer module reads each frame at a time and passes each frame to one or more writers each of which uses the image data to generate an output file. Output file types include an intermediary preview transcode a motion analysis file and thumbnail files .

The intermediary preview transcode is a low resolution low frame rate version of the original file. This temporary file is used to create previews quickly. It is optimized to be streamed from the server from hard disk with low CPU usage. In one embodiment the output transcode is implemented by the transformer module as a video file writer that converts the image to a lower resolution and writes it to the output stream. This video format can be exactly the frame rate and resolution of the previews that it will be used to generate. However it can be low compression since it is on a local drive such that bandwidth is not an issue.

The motion analysis file stores the motion vectors frame by frame. To create this file the transformer module compares successive frames looking for motion rotation and scale changes. It also looks for rolling shutter distortion. The output file is simply a set of motion vectors one for each frame.

Thumbnail files are a series of JPEG or other format files that are written out at intervals determined by the application module . These thumbnails can then be streamed back down to the application module to be used in a trimmer. Note that this is primarily used for devices that require the thumbnails such as devices that use Flash. The iPhone for example may not use these thumbnails. In one embodiment if the application omitted a trimmer previously it starts reading the thumbnail files as they become available and displays them for use in selecting trim points.

Continuing at step the server creates preview renders and downloads the previews to the application module . After beginning to upload the media the application module is immediately able to start using the transcoded files to perform different operations in real time. Each of these files can be read from start to current upload point so the application does not need to wait for a full upload before the user can start making choices and previewing them. For example the application module can begin to use the downloaded previews to implement a trimmer. In one embodiment the trimmer provided by the application module downloads thumbnails dynamically and draws them in a strip. Although the thumbnails progressively fill over time the operation of setting the points can still proceed. This just sets start and end points which will be used in the final render. The application module can also use the preview to implement an effects preview. The server uses the transcoded file to generate a preview to view the effect in real time as applied to the clip. The clip is downloaded to the application module and shown to the user. Similarly the server can generate video tag previews that take the user s choices for photo text and style. The preview can be downloaded and shown to the user via the application module . This generates a preview to view what it might look like. The server can also generate a final project preview. This is used to let the user see what the entire clip looks like but in lower resolution.

In more detail an effects preview can be generated by the server . The server uses the transcoded file to generate a preview to view the effect in real time as applied to the clip. In particular a user clicks on the play button on the user interface of the application module . The application module sends the instruction to the server to create a new render using the preview transcode as input with the selected effect applied. In one embodiment the instruction is used to generate an XML production file by the server . In some embodiments response times for previews are important for user satisfaction. Accordingly the effects preview generation is assigned a high priority by the server . In some embodiments because the transcoded input and the output render are both low resolution the processing engine is able to create the file in real time. If stabilization is required the transformer module also applies this in the render pass. The transformer module uses the analysis data from the first pass to calculate how to move the image to compensate for jitter.

After this processing begins the server starts to stream the preview to the application module immediately. Because of the low resolution of the input and output the server is able to stream in real time. The application module starts playing the streamed media immediately. To the user the behavior is identical to clicking on a video player showing a previously rendered video. There is some latency from each of the stages but it can be remarkably close to the time required to start a static file playing over the Internet. However it can only play up to the current upload point then it stops.

The server may also generate a video tag preview. In this preview the server takes the user s choices for photo text and style and generates a preview to view what it might look like. As discussed above the user enters a name for the Tag using the application module . The application module uploads the text to the server . The user also chooses a picture for the media using the application module . The application module uploads an image e.g. a JPEG file to the server . The user chooses a video tag style to use via the application module and the user clicks on the Play button on the application s user interface. The application sends the instructions to the server to create a new render using the video tag project file with user s name and image. In some embodiments this render also incorporates the start of the uploaded video so the transition can be demonstrated. In some embodiments the application requests the render in sufficiently low resolution for real time response. At the server the render starts as a high priority process and the server immediately starts streaming to the application for playback.

The server can also generate a final project preview. In some embodiments this occurs when a user clicks on the play button in the application user interface. In response to an indication of the selection by the user from the application module the server generates the final production file but with the preview i.e. lower resolution. The server starts writing the file as a high priority process. Once processing begins the server starts to stream the file back to the application . Once the application module begins to receive the stream it begins playback.

Continuing at step the server generates the final render. Via the application user interface a user chooses to publish the video clip. The server responds to an indication from the application module of this selection by generating the final render in high resolution that will be published to the destination e.g. Facebook Youtube etc. The final render is queued by the server as a low priority process. In addition if there are other renders in the queue ahead of it the final render waits. After requesting the final render the application module does not need to provide any additional input and can leave the session. Eventually the render request makes it to the head of the queue and is assigned to a processor which starts the job as a priority process so that it will only run when higher priority requests are not actively processing. When the render is finished the server sends to the video file to the destination e.g. Youtube Facebook etc. and then notifies the user that the video has been published.

It should be appreciated that the transformer module and or processor module can reside on a cloud server a local computer or other device. All peripheral devices including a monitor or display and input output devices can be used by the user to perform such editing as needed. Additionally in embodiments where the transformer module and or processor module reside on a cloud server communication links such as wireless or wired connections e.g. a network connection are provided so that the user can access the transformer module and or processor module from the cloud server from the user s local computer or other device e.g. via application module .

In fact in certain embodiments the cloud server can make decisions about what materials to make available to a user including intros e.g. the personality tag templates effects destinations for posting and video clip to use in the intro or outro such that. for example a partner promotion can be substituted. This information can be dynamically collected based on different inputs. For example in certain implementations the user can inform the server with the GPS location. This can be done automatically. In other words the user s device can have a GPS circuit included in it or can get GPS assisted coordinates from the network . This information can then be sent to the cloud server and can influence what video tag selections are made available to the user. For example the cloud server can then determine that the user is at a specific location like a theme park convention center movie theatre etc. and provide e.g. intros and titles based on where the user is located.

There can also be a mechanism on the client device for identifying special promotions with third parties for example typing in a special code scanning a bar code or Q code etc. The cloud server can also check the time location or both and determine whether there is a promotion that is at a specified time location or both. Further information in the database that was collected elsewhere can be used to determine special promotions or other information. For example a user may have been signed up through a promotion with a partner which can be flagged on the back end.

The cloud server can also be configured to track certain information such as which intros and effects the client uses each time the client creates a video. With this information the cloud server can track usage statistics and correlate these usage statistics with other user demographics etc. This can be used to constantly update promotions titles videos and other effects. This can also be used to determine which types of effects and intros to create next which ones to recommend which ones to charge a premium for etc. This information can also be reported to promotion partners potentially for revenue generation e.g. invoicing for the number of intros used.

Also because the server manages what each user has available it is easy to integrate mechanisms for monetizing via the selling of effects intros and other items. For example many effects and intros can be offered as free. New effects and intros can dynamically show up in the client device labeled premium. When the user chooses a premium effect or intro it can be previewed but must be purchased e.g. through an in application purchasing mechanism in order to use. Once purchased the database records that the user has the rights to this material. This right can move with the user to all devices in the account. The user can have the option to purchase a subscription which enables use of all premium content. This simply sets a flag in the user account allowing use of all materials.

In an embodiment theme templates can be stored by the transformer module either associated with a user account or as a preset . Theme templates are simply one implementation of video tag templates and can be offered in addition to other types of video tag templates. For instance a theme template can comprise an XML or other format file. As with video tags a theme can be used to create media such as videos which may be a composition of a plurality of media elements.

Theme template comprises one or more static media assets which do not change from instantiation to instantiation. In other words each product created using the theme template will contain the same static media assets. These static media assets may comprise theme specific video images text e.g. title name location city name etc. or other media. For instance if the theme template is related to an amusement park the theme specific static media assets may include a logo of the amusement park or images of the amusement park.

Theme template also comprises placeholders for dynamically provided e.g. user provided media. When a finished product is created from the theme template these placeholders will be filled in or populated with dynamically provided content which may differ between instances of products created from the template . For instance this dynamically provided content may comprise videos images text e.g. title name location city name etc. or other media which are user specific or session specific e.g. personal to the user or customer . For example continuing with the amusement park scenario above the dynamically provided content may comprise videos or images of a visitor of the amusement park e.g. on a rollercoaster . Thus if two videos are created for two different visitors to the park e.g. by the amusement park operators for sale to the visitors the theme specific media assets may be identical between the two videos whereas the session specific content will differ since it is visitor specific.

A compositing engine or module on server can be configured to collect the static media content from structured data source and the dynamic content from session data source e.g. which may be the user or a system device or database associated with the user . This content both the static and dynamic content are composed according to the theme template e.g. placeholders in the theme template to render a final product such as a composed video or image file.

In an embodiment during the creation of the final product additional media may selected for inclusion in the product using a data structure. For instance the theme template may comprise or access a data structure comprising fields which determine what media to add to specific locations in the template . The sources for this media can be specific e.g. a specific video image or text string or indirect. An example of a specific media could be a product photograph.

As an example of indirect media location information such as an address or the name of a city can be provided e.g. as a static or dynamic asset from data sources or or another data source . The compositing module can use the location information to insert a map of the location into the composed product. For example the compositing module may interface with an internal or external map rendering application e.g. Google Maps which accepts the location information as an input and returns a map or satellite image of the area surrounding the location potentially with an indication of the location on the image.

The fields of the data structure may also comprise parameters in addition to media. For example one field might specify a color that is used to set colors for various text strings or backgrounds. Another field might provide a text string which can be painted with the specified color. Another field might comprise a numeric value which can be translated into a control to set the intensity of a video effect parameter. A person having skill in the art will understand that the fields can comprise additional elements capable of being incorporated into a rendered media product.

In an embodiment the theme template comprises a data structure which specifies for population into a composed product one or more of the following 

In an embodiment when a composed product is requested using a specified theme template the compositing module 

As an example the compositing module or engine can be used to populate a theme template with images and text from an individual s Twitter account Facebook account or other social networking site. In this manner personalized themes can be automatically generated without requiring preparation of the content by the user.

It is also possible using embodiments of this system to create read structured data from a database and for each item create a unique video without any user intervention. For example the compositing engine can be interfaced with a used vehicle ecommerce site to build a video about each vehicle in inventory by consulting inventory data to build full videos customized to each car. In this example assets for each customized video could include 

Notably there is no requirement that direct user input of media is required. Thus it is possible to have a series of videos generated automatically by scanning through a database e.g. of vehicle or other product inventories .

In an embodiment a comprehensive tool kit for designing video or theme templates to be used with server or in the cloud is provided. The tool kit includes elements to author test and manage themes as well as to manage user accounts and authorize videos for publishing.

In such an embodiment theme templates can comprise video templates which define the sequential ordering of media into a video and or media rich web page or other interactive media templates. Support for web page or other interactive media templates allows for embedding and combining various elements e.g. images videos sounds text and finished rendered video from a video or other theme as separate elements in an interactive viewer. In an embodiment there is no need for a user to create a format for the interactive media page since existing standards e.g. Flash HTML5 etc. can be used.

The theme builder comprises a video authoring tool. The tool may be a plugin which is operable with a non linear editing system NLE . Alternatively the tool can be implemented as a stand alone application. In either case the theme builder may be executed on a user device or on server which may comprise one or more cloud resources.

Theme builder comprises a set of tools for designing testing and publishing a complete theme. Specifically theme builder may allow a user for instance through a user interface to 

Theme previewer provides a tool for testing whether a theme works as intended. Theme previewer may be provided as a server side or cloud based application or as a client application executing on a user device for example using an API which may be a common API used by other cloud clients e.g. Vibop . Theme previewer includes controls for all theme defined user variables including any number of video clips images text strings and other media elements. These user can assign media and values to these variables and then preview the result.

Theme manager enables a user to manage the user s theme templates once that have been created and posted to server . Theme manager may comprise an administrative tool which allows a user via a user interface to control the availability attributes assignments etc. of the managed theme templates. In an embodiment theme manager comprises one or more of the following functions 

Interactive page designer can reside on a user device as a client application or on server . In an embodiment interactive page designer can comprise any third party authoring tool capable of defining a rich media page and posting it to the cloud e.g. server . Typically interactive page designer will comprise a Flash or HTML5 authoring tool. In a preferred embodiment of interactive page designer a plugin addition to the authoring tool allows the assignment and previewing of theme generated media in the media page and provides an option to post the authored media page which may comprise a web page to the cloud e.g. server .

Content manager comprises a web applications that in an embodiment tracks users users access to content provides previews and provides authorization for videos that require monitoring. According to an embodiment content manager provides one or more of the following functions 

Publish manager manages and or determines the destination s available for publishing of media generated by each application. In an embodiment publish manager provides one or more of the following functions 

In an embodiment the disclosed systems and methods can be used to provide delivery of personalized media to end consumers. One major problem that has long differentiated video from photographic services is the relative ease with which photographs can be converted into tangible products e.g. at amusement parks on cruise ships etc. . For instance photographs can be easily incorporated into photographic albums coffee mugs t shirts and other tangible merchandise. Although video can be delivered for instance on a digital video disc DVD or other optical disc storage medium such mediums are severely limiting and uninspiring.

The disclosed systems and methods can be used to create customer experiences that are immediate and valuable. For instance the product can me made immediately available to the customer e.g. via the customer s mobile device tablet computer laptop computer desktop computer or other device or possession. An option can also be provided to the customer to deliver the product to another destination as well. This is particularly important in settings in which a service has collected videos and photographs e.g. amusement park rides zoos cruises events etc. and aims to sell these items to visitors for instance as they leave. This can also apply to online video photography services that store photographs and videos for customers and have the desire to deliver a finished product to the customers.

In one embodiment a finished video is delivered to the customer. In this implementation media is collected and a theme template such as those described in detail above is used to create a final video. The final video is then delivered to the customer s device e.g. mobile device tablet PC laptop PC desktop PC etc. . In this embodiment 

The finished complete video can then be promoted at a sales point where the visitor customer may easily view or preview it. The sales point can be a kiosk or a web page provided by a web service. If the customer decides to buy the final video product he or she can be told that it will be delivered to the user s device e.g. mobile device tablet PC laptop PC desktop PC etc. . Alternatively or additionally upon purchase the service can email a download link for the product to the user s email or other account. The user can then download and immediately possess the video product or choose to retrieve it later . Further options can include posting the video product to the customer s Facebook Youtube or other account forwarding the video product or a link to the video product to friends etc.

According to a more sophisticated embodiment a fully interactive media storybook can be delivered to the customer. In this embodiment in addition to creating a media product e.g. comprising photographs videos sounds etc. an interactive media page can be generated. In this embodiment 

The finished interactive site may comprise a complete interactive story of a visit or event which can be promoted at a sales point. The customer may be permitted to easily view and interact with the site at a kiosk which may comprise a touchscreen or other input and display devices and a browser application. If the customer decides to purchase the product they can be told that it will be delivered to them in the form of a link which may comprise a dedicated URL. Upon purchase the URL or other reference to the interactive site can be emailed or otherwise sent to the customer or customer s email address or other account.

After purchasing the interactive site or access to the interactive site the user can interact with the interactive site through the URL and can also forward the URL or other reference to friends and family or post it on a social network site e.g. Facebook Google etc. . The interactive site may stay live on the server hosting the site e.g. server which may comprise a web service forever or for a specified amount of time e.g. a specified number of days months or years which may be agreed to in as part of a purchase contract.

Those of skill will appreciate that the various illustrative logical blocks modules and algorithm steps described in connection with the embodiments disclosed herein can often be implemented as electronic hardware computer software or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the design constraints imposed on the overall system. Skilled persons can implement the described functionality in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the invention. In addition the grouping of functions within a module block or step is for ease of description. Specific functions or steps can be moved from one module or block without departing from the invention.

The various illustrative logical blocks and modules described in connection with the embodiments disclosed herein can be implemented or performed with a general purpose processor a digital signal processor DSP application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor can be a microprocessor but in the alternative the processor can be any processor controller microcontroller or state machine. A processor can also be implemented as a combination of computing devices for example a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The steps of a method or algorithm described in connection with the embodiments disclosed herein can be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module can reside in RAM memory flash memory ROM memory EPROM memory EEPROM memory registers hard disk a removable disk a CD ROM or any other form of machine or computer readable storage medium. An exemplary storage medium can be coupled to the processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium can be integral to the processor. The processor and the storage medium can reside in an ASIC.

The above description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the invention. Various modifications to these embodiments will be readily apparent to those skilled in the art and the generic principles described herein can be applied to other embodiments without departing from the spirit or scope of the invention. For example while the present invention has been described as encompassing a method and tool or system for personalizing media it should be understood that the tool can be implemented as electronic hardware computer software or combinations of both. Thus it is to be understood that the description and drawings presented herein represent a presently preferred embodiment of the invention and are therefore representative of the subject matter which is broadly contemplated by the present invention.

In accordance with an implementation a transformer module is implemented on a web server. The transformer module is used to apply a video tag to media to generate personalized output. The transformer module manages a database of users and video tags. A remote application module invokes the transformer module to process a video clip. The remote application module sends the video clip or other media to the transformer module with instructions for processing video tag choice and one or more desired destinations.

