---

title: Data quality checking and automatic correction
abstract: Data is checked against data quality rules and a corresponding report is generated. The report is provided to an entity, which may be a subscriber. Data correction schema is used to correct stored data. The data quality rules or the data correction schema may be amended or modified according to user input, which may be a subscriber entity. The subscriber or another entity may be billed for data quality or correction services as performed. A budget value may limit the scope or intensity of the data quality services that are performed, as well.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09262451&OS=09262451&RS=09262451
owner: Amazon Technologies, Inc.
number: 09262451
owner_city: Reno
owner_country: US
publication_date: 20130701
---
Data warehouses server farms and the like receive store and provide data to and from one or more entities. Inventory control accounting e commerce merchandising and a host of other endeavors generate vast amounts of information that are stored and put to various uses. The accuracy of such data is paramount to the reliability of and confidence in actions that use the data.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

There are numerous circumstances in which an entity generates data and information related to its respective activities or interests. Often that data is needed for future use such as performance analytics record keeping inventory control financial accounting government regulatory compliance and so on. In one example a corporate structure includes numerous business entities having respective functions. Therein data may be generated by one entity and reported to or summarized for another entity within the corporation. Alternatively an entity may later review or analyze the information it generates thus operating as both a source and a recipient of the data as well.

In another example data produced or provided by one entity is stored in a data warehouse. Data is then extracted from the stored data and processed before provision to another entity. In still another example data from a plurality of source entities is sold in total summarized or otherwise processed and provided to a paying subscriber entity. A myriad of other examples of data sourcing storing processing provisioning or reporting are also contemplated.

Accuracy of data is important to the accuracy and reliability of future uses of that data. Such future uses may be the direct reporting or review of the original data itself the synthesizing of other data or metadata using the original data statistical or heuristic operations performed on the original data and so forth. Therefore data that is without errors or omissions data elements that are consistent with predefined sets or definitions numeric data values that fall within a predefined range and other parameters or characteristics are germane to future success.

In one example one or more entities respectively provide data to a data warehouse service for storage such as provided by a data warehouse server. The data warehouse server is considered in the singular for clarity but in fact may comprise one or more servers or storage devices configured to communicate with other entities by way of a network or networks. The data warehouse server may be configured to perform any number of processes on the data or generate any number of reports by way of analyzing the data. The data warehouse server may in turn provide the stored data in whole or in part to one or more other entities to the source entity or entities or provide one or more reports to various entities and so on.

In the present example the data warehouse server may also copy or mirror the data in whole or in part to a data quality service such as provided by a data quality server. The data quality server is configured to check or compare the mirrored data against a set of data quality rules. The data quality rules may be defined by a user or users a system administrator a source or consumer entity of the data a third party subscriber for data quality services or another entity. The data quality rules can include any suitable characteristics values functions formatting or syntactical definitions ranges or limitations for testing the accuracy of the mirrored data.

Non limiting examples of data quality rules include a predefined numerical range within which a data value must lie that a data value must be an integer that a textual name or string must be part of a predefined set that a data element is not a null or zero value that a data value is consistent with a mathematical expression that a date must lie within a predefined or calculable chronological range and so on. Different data quality rules or sets can be used for checking different types of data or data originating from or provided to respectively different entities or in accordance with other distinctions or purposes.

Such a data quality server is configured to check the mirrored data in accordance with the corresponding data quality rules and generate a report or reports commensurate with the results. The one or more reports are then provided to an entity or entities in accordance with a data quality services agreement in accordance with internal quality assurance policies or as determined by other practices or procedures.

In another example at least some of the mirrored data is automatically corrected by the data quality server in accordance with one or more data correction schema. A data correction scheme is definable by a user or users an administrator or another entity. Non limiting examples of data correction schemes or operations include conversion of non whole numbers into integer values the heuristic selection of a closest match name or string from a predefined set the substitution of various punctuation or other characters within a string in accordance with a predefined syntax substituting a default value for an inconsistent or out of range data value or element and so forth. Other data correction schemes operations substitutions or logical or heuristic functions may also be used.

The data quality server may then provide the corrected data to the data warehouse server for substitution in place of the erroneous data for storage or both. One or more reports may be generated and provided in view of the data correction operations as well. A cost allocation service such as provided by a cost allocation server may be used to receive information indicative of data quality or data correction operations performed by the data quality server. The cost allocation server can then calculate one or more billing values and provide these to respective entities.

Data quality checking or data correction operations may be selectively performed or limited in scope according to a predefined entity budget. For example a subscriber entity may have predefined a set of hierarchical data quality rules based upon those data characteristics of descending importance or priority to them. This same subscriber entity has also defined a specific budget amount e.g. in dollars governing or capping data quality services or reporting to be provided on a weekly basis. Thus the data quality server checks newly received mirrored data against the corresponding data quality rules in a selective and hierarchical manner so as to stay within the predefined budget amount. In this example fewer than all of the data quality rules may be used if the new mirrored data is of sizable quantity in order to remain within the budget. The corresponding report or reports and the billing amount are then provided to the subscriber entity in accordance with the weekly cycle of the service agreement.

Data quality checking or correction may therefore be performed toward in house quality assurance as directed by corporate policy toward greater third party confidence in the data and so forth. Data quality services may also be billed accordingly so that cost recovery is a part of the overall system perhaps to the point of profitability. Greater confidence in the data and reports or products derived from the data may be realized as contemplated herein.

The entities are respectively configured to provide communicate or exchange entity data and with each other or other entities by way of one or more networks . The networks may include the Internet or access thereto local area networks LANs wide area networks WANs and so on. Other entities or devices respectively being the same as or differing from any of the entities can also be connected to communicate with each other or other entities by way of the network s .

The system also includes one or more data warehouse servers . For simplicity and clarity the data warehouse server is referred to hereinafter in the singular. However one having ordinary skill in the art can appreciate that any suitable number of data warehouse servers may be used in a cooperative parallel or redundant manner. The data warehouse server is configured to receive the entity data from the entities collectively referred to as consolidated data . The consolidated data may be stored within the data warehouse server . The consolidated data may also be provided in whole or in part from the data warehouse server to one or more of the entities or another entity or entities. Thus the data warehouse server provides or performs data storage and retrieval services.

A data quality server is configured to communicate with the data warehouse server and with the entities or with other devices or entities. Such communication may be by way of the one or more network s or by other suitable pathways. The data warehouse server is configured to copy or mirror the received consolidated data or any of the entity data in whole or in part and provide mirrored data to the data quality server .

The data quality server includes a data checking module . The data checking module may include any suitable resources such as electronic circuitry machine readable program code stored on a computer readable storage media CRSM or other constituency. The data checking module is configured to check or compare the mirrored data against one or more data quality rules stored within the data quality server .

A reporting module of the data quality server is configured to use results provided by the data checking module to generate one or more reports. The reports are then provided as data quality reporting to one or more of the entities or another entity or entities. The reporting module may include any suitable resources such as electronic circuitry machine readable program code stored on a CRSM or other elements or constituency.

A data correction module of the data quality server is configured to automatically correct or modify some or all of the mirrored data using one or more data correction schema . Corrected data is provided back to the data warehouse server where it is substituted for the corresponding erroneous or unmodified data within the consolidated data stored in addition to the consolidated data or used for other purposes. The data correction module may include any suitable resources such as electronic circuitry machine readable program code stored on a CRSM or other elements or constituency. The data quality server therefore performs various services including data quality checking reporting or data correcting or any suitable combination of these.

User interfaces may be respectively presented to the users of the entities so as to define or modify the data quality rules to define or modify the data correction schema and so forth. In one example a user of the entity selects or defines parameters within the reporting module for a data quality report to be received on a weekly basis. In another example a user of the entity defines several rules or parameters stored within the data quality rules . In yet another example a user of the entity defines a complete correction scheme stored within the data correction schema . Non limiting examples of such user interfaces are described and illustrated hereinafter.

A cost allocation server is configured to use a cost allocation module to calculate one or more billing amounts in accordance with the actions performed by the data quality server . The one or more billing values are provide to one or more of the entities pursuant to respective data quality service agreements corporate operating standards or other established practices or governance. The cost allocation server therefore performs cost of service calculation and billing services.

Individual servers are depicted for clarity of illustration and not by way of limitation. It is understood that more than one computing device may provide the various services and functionalities described above. For example the data quality services may be provided by a plurality of servers configured in a distributed computing environment.

The figures in this disclosure are illustrative. In some instances various features have been exaggerated in size for clarity of illustration. The figures are not necessarily to scale and may not necessarily be proportionate with one another.

The data warehouse server includes a datastore . The datastore may use a flat file database linked list tree or other data structure to store the information. In some implementations the datastore or a portion of the datastore may be distributed across one or more other devices including other warehouse servers network attached storage and so forth. The datastore includes the consolidated data as described in a non limiting manner below.

Product identifier data is stored within the consolidated data . The product identifier data includes respective identification numbers or ID codes for one or more items of merchandise offered for sale. For example the entity offers for sale at least some of the items identified by the product identifier data . The entity may be a business unit within a corporate structure and a source of at least some of the product identifier data . The product identifier data may be used in some instances to define a set of ID codes against which data may be quality checked.

Ordered quantities data is also stored within the consolidated data . The ordered quantities data includes respective quantities ordered for each of the merchandise items identified by the product identifier data . For example the ordered quantities data may include respective quantities for each of 4 different merchandise items sold through the entity in a recent sales transaction. The ordered quantities data may be used for example to generate historical or statistical sales data for the entity .

The consolidated data further includes product sources data . The product sources data includes respective names addresses contact information or other data for sources of the merchandise items of the product identifier data . For example the product sources data may indicate the company name address telephone number e mail address website or other contact information for each of 2 different sources e.g. manufacturers or importers of a particular item of merchandise sold by the entity . The product sources data may be used for example to define a set of source names against which data may be quality checked.

The consolidated data also includes ordering entities data . The ordering entities data includes entity names identifier numbers or other information specifically identifying various entities. The ordering entities data may also identify one or more of the merchandise items of the product identifier data that a particular entity is authorized to sell or purchase or both . For example the ordering entities data may specifically name the entity and specify 25 different merchandise items that the entity is authorized to sell or place orders for . The ordering entities data may be used for example to verify that a particular entity is authorized to order a specific item of merchandise during data quality checking.

Product options data is also stored within the consolidated data . The product options data may include various optional characteristics such as sizes colors materials or finishes and so on correlated to respective merchandise items of the product identifier data . For example the product options data may indicate that a particular ballpoint pen is available with rosewood titanium or gold plated body construction and in either blue or black ink.

Customer list data is also stored within the consolidated data . The Customer list data may include names and contact information for all costumers that have placed orders through any of the entities identified in the ordering entities data . For example the customer list data may include names addresses electronic payment information or other data for each of 97 different customers that have placed orders by way of entity .

The datastore may also include a data mirroring module . The data mirroring module is configured to mirror or copy some or all of the consolidated data as the mirrored data provided to the data quality server . In one instance the data mirroring module is configured to mirror new data as it arrives or nearly so from one or more source entities e.g. . In another example the data mirroring module is configured to track or flag new data as it arrives and then periodically provide that new data to the data quality server .

For instance such new data may be copied mirrored once per hour twice per day in response to an entity request or in accordance with other scheduling or procedures. Other data provisioning schemes can also be performed by the data mirroring module . The data mirroring module may include any suitable resources such as electronic circuitry machine readable program code stored on a CRSM and so forth. The datastore may also include other data . The other data may include other suitable data types or information used or generated during operations of the data warehouse server .

In another example the entity receives or consumes data within the consolidated data . Specifically the entity audits and reviews sales performance information within the same corporate structure as the entity . The entity therefore receives one or more reports that summarize the data types within the consolidated data . At least some of the data sought by the entity is generated or provided by the entity . Therefore the entity is a source of data and the entity is a recipient of data each having complimentary roles in the example depicted in the view . Countless other scenarios involving respective entities and data sourcing receiving relationships are also contemplated.

A first body or packet of data designated as data is provided to the data warehouse server in an operation . For example the entity provides the data e.g. entity data related to respective customer orders for merchandise items sold in an online e commerce environment i.e. Internet website to the data warehouse server . The operation is depicted as continuous over a period of about 3 hours in the interest of clarity. Alternatively the operation may be performed as the provision of a plurality of data packets data bursts over the depicted time period.

Shortly after the beginning of the operation the data warehouse server begins mirroring the data to the data quality server in an operation . In the present example the data warehouse server copies the entity data defining the data in whole or in part to the data quality server as mirrored data . The newly received mirrored data is stored as needed in the data quality server in preparation for or contemporaneous with data quality checking operations.

A brief time after the beginning of the operation the data quality server begins checking the quality of the data in an operation . In the present example the data checking module uses one or more of the data quality rules as applicable to compare against the data that is being received via the operation . It is noted that a contemporaneous operations period is defined by a time span during which respective portions of the operations and are performed simultaneously.

That is the data may be mirrored to the data quality server as or immediately after it is received by the data warehouse server and the data may be checked against applicable data quality rules as or immediately after it is received by the data quality server . Eventually the data quality checking of the data is complete and the operation is ended.

The reporting module generates one or more reports corresponding to the data quality checking of the operation as an operation . The operation begins at some time during the operation and as a result a report or reports may be generated and provided in the event that data quality problems or issues are detected. The one or more reports are provided to one or more entities such as the entity which is concerned with sales performance auditing. For example if the operation detects a data quality problem in the data the reporting module may be configured to provide a corresponding report immediately in accordance with data quality rule prioritization or other criteria. The timely nature of such data quality reporting may serve to reduce or eliminate corrective or remedial efforts that might otherwise be required.

A second body of data designated as data is then provided to a data warehouse server in an operation . For example the entity provides entity data defining the data which is related to other respective customer orders for merchandise items to the data warehouse server . The operation is depicted as being continuous over a time span but may be performed as the provision of plural discrete data packets or bursts over that time period.

Just after the beginning of the operation the data warehouse server begins mirroring the data to a data quality server in an operation . In the current example the data warehouse server mirrors the data in whole or in part to the data quality server as other mirrored data . The newly received mirrored data i.e. data is stored in the data quality server in preparation for data quality checking.

Soon after the beginning of the operation the data quality server begins checking the data quality of the data in an operation . In the present example the data checking module uses one or more applicable rules of the data quality rules to compare against the data as received by way of the operation . Thus at least some of the respective operations and are being performed simultaneously.

Sometime after the operation begins a system administrator accesses the data quality server in order to modify some portion of the data quality rules that are applicable to the data . For example the system administrator may wish to define a rule enabling verification that merchandise order quantities e.g. fall within a definable range. In another example the system administrator may wish to define a rule verifying that product identifiers e.g. are all elements within a predefined set. The system administrator thus makes these or other modifications to the data quality rules accordingly as an operation .

The operation is performed simultaneously with a portion of the operation . A first portion of the data is checked against the data quality rules in an original condition as when the operation began. A second portion of the data is checked against the modified data quality rules after the operation is complete. Therefore the data quality checking of the operation provides results stemming from 2 different quality rule sets. The data checking module provides these results mixed as they potentially may be to the reporting module .

As depicted all or a majority of the respective operations are performed prior to a close of business day . Therefore in the illustrated example the data and the data may be received stored mirrored quality checked and reported on in whole or in large part during regular business hours. It is contemplated herein that such operations provide data quality checking measures that are timely in nature and do not require performance during late night hours or similar scenarios.

Since the data quality checking may be performed immediately in response to receipt of that data from a source entity quality reporting may be done and corresponding actions may be taken before errors omissions or other problems result in costly remedial measures. Moreover legal liability that may result from the use or sale of defective data may be minimized or avoided through the prompt checking reporting or corrective actions contemplated herein.

The report template includes a product identifier validation option. The product identifier validation option includes or is defined by respective Yes and No checkboxes. The user is required to select either Yes or No with No being a default automatic selection. If the user selects Yes the product identifier validation option causes the corresponding report to indicate Valid or Invalid based on whether or not a particular product identifier e.g. is an element of a predefined set of product identifiers. The user may make their selection within the product identifier validation option by mouse click display touch or gesturing or another suitable input technique.

An order quantity checking option is also included in the report template . The order quantity checking option includes respective Yes and No checkboxes with No being a default selection for purposes of example. If the user selects Yes then a number of other selectable or definable parameters apply as described below. For purposes of example the user has selected Yes within the order quantity checking option.

A lesser or equal to max allowable option includes a single selection checkbox. If the user selects the lesser or equal to max allowable option the report will indicate Valid or Invalid based on whether or not an ordered quantity e.g. is less than or equal to a predefined maximum allowable value for that particular item of merchandise. The lesser or equal to max allowable option may be useful for example with respect to certain items of merchandise having relatively limited inventory or where manufacturer supply time is extended or long backorder periods are a problem. Thus a merchant may be alerted to order more corresponding merchandise now or soon in an effort to avoid customer disappointment or cancelled orders.

A null zero value not permitted option includes a single checkbox. If the user selects the null zero value not permitted option the report will indicate Valid if an ordered quantity is neither zero nor left blank null . Otherwise Invalid is indicated on the report. The null zero value not permitted option may be useful for example to alert the entity that an order has been placed by a customer that is incomplete with respect to desired quantity of a merchandise item. In another example an option analogous to the null zero value not permitted option may be used to alert an entity that a customer has failed to include a shipping address and so forth.

A must be integer value option includes a single checkbox. If the user selects the must be integer value option the report will indicate Valid if an ordered quantity is some integer value that is a whole number. Otherwise Invalid is indicated on the report. The must be integer value option may be useful for example to alert the entity that an order placed by a customer has an ambiguous quantity specified for an item of merchandise item such as 1.2 pairs of denim jeans.

A within the range of selection includes input boxes for defining lesser and greater i.e. lower and upper values of a numerical range respectively. If the user provides valid lesser and greater values in the respective input boxes then a valid range has been defined for checking an ordered quantity against. As depicted the user has specified a range of 1 to 20 units as Valid for the ordered quantity and a data value outside of the range of the selection would be indicated as Invalid on the report.

A selection made below option includes a pull down menu. The pull down menu of the option can include one or more respective values sets or ranges as predefined by the user or another entity such as a system administrator. If the user selects the selection made below option the user then also selects a specific entry predefined within the pull down menu. The report will indicate Valid if the ordered quantity is consistent with the pull down menu selection otherwise the report will indicate Invalid .

While not depicted in the interest of clarity other pull down menus may be used for making other user input selections in other respective templates or user interfaces. For example a pull down menu may provide a listing of predefined data quality rule sets and their respective values and parameters. Thus a single selection made from such a pull down menu may fully define a data quality report. Other uses or operations may also be made by way of pull down menus.

The report template also includes a product source validation option. The product source validation option includes respective Yes and No checkboxes with No being a default selection. If the user selects Yes the product source validation option causes the corresponding report to indicate Valid or Invalid based on whether or not a particular product source e.g. is an element of a predefined set of such source or manufacturers. The product source validation option may be useful for example when a customer may order a product such as a set of screwdrivers from any of 3 different sources. The product source validation option may then alert the entity that a customer has specified an ambiguous or unlisted source name for their merchandise order.

An ordering entity validation option is also provided. The ordering entity validation option includes respective Yes and No checkboxes with No being a default selection. If the user selects Yes the ordering entity validation option causes the corresponding report to indicate Valid or Invalid based on whether or not a particular entity e.g. is authorized to order or broker an order by another for a particular item of merchandise. The ordering entity validation option may then alert the entity that they are lacking authorization to order the respective merchandise item.

The user interface also includes an additional options control . The additional options control may be configured to cause another report generation template to be presented or additional matter or another page of the report template to be presented to the user . Other matter selections or options related to user generation of a data quality report or reports may also be provided in response to an actuation of the additional options control .

The OAR page includes a learn how to create a data quality report option. User actuation of the option causes the data quality server to present another user interface or sequence of pages providing tutorial information on how to define or generate a data quality report such as for example using the report template described above. Such tutorial information can include textual information audio visual presentations rendered or animated teaching displays and so on. The user may actuate the option control by way of mouse clicking display touch or other gesturing and so forth.

The OAR page also includes a view or select predefined data quality reports option. User actuation of the option causes the data quality server to present one or more predefined data quality report templates for selection by the user . For example the user can quickly select a first report or set or reports to be used during data quality checking while being new and relatively unfamiliar with report options generation or the value or significance of data quality checking. Thus the option gets the user up and running quickly with respect to data quality reporting perhaps providing inspiration toward defining their own data quality checking or reporting criteria.

A learn more about data analytics option is also included. The option causes the data quality server to provide tutorial information regarding how data is analyzed during quality checking operations. For example the user may be shown that certain types of numerical data are only meaningful as integer values and that fractional or irrational values are ambiguous. In another example the user may be instructed that all valid product code numbers are constructed according to a predefined format or syntax. In this way the user may gain greater insight as to possible data quality checking methods or reporting options.

A recommend reports for me option is included on the OAR page . The recommend reports for me option causes the data quality server to present one or more predefined reports or optional criteria for reporting to the user . The data quality server may use the data checking module or another resource to perform a comprehensive content analysis of the mirrored data previously received from or of interest to the user i.e. the entity associated therewith . The data quality server may use the results of the analysis to identify reporting criteria or predefined reports including such criteria to be presented to the user .

The OAR page includes a my budget for services selection input box for defining a dollar value input by the user and a remaining dollar value display box. The monetary value entered by a user in the my budget for services selection box may set a cap or upper limit on the number or intensity of data quality checking services performed or the detail or particular features included within a corresponding report. As depicted the user has input an amount of one thousand dollars to define a budget cap for overall data quality checking and reporting services of which six hundred forty dollars remain for the present budget period. Other budgetary definition or management schemes may also be used.

For example the user may define a first budget amount to be applied to the data quality checking e.g. application of data quality rules and a second budget amount to be applied to data quality reporting e.g. detail or content of the report s . In another example the user may define a single budget amount and percentages allocated for respective services such as two thousand dollars total with 60 allocated for data quality checking and 40 allocated for data quality reporting.

A budget applies per option includes Weekly Monthly and Agreement checkboxes. The user is required to select one of the boxes no default applies to the option and the respective checkboxes are mutually exclusive. The selection made for the option determines how the budget amounts specified in the selection box is applied. As indicated for example the one thousand dollar budget previously specified by the user will be applied each month. Thus data quality services provided each month for the user or entity corresponding thereto will be limited to 1000 in scope or intensity.

A use prioritized data quality rules option includes a single checkbox. Selection of the option causes the data checking module to apply the data quality rules in a ranked or hierarchical manner during mirrored data quality checking on behalf of the user so as to remain with the corresponding budget amount e.g. 1000 per month . The data quality rules germane to the user may be previously ranked in order of significance or the data checking module may apply a general rule ranking policy.

In this way the user may remain within a periodic operating budget while still getting the benefit of data quality checking even if the degree or rigor of such checking may vary from one reporting period to the next. Each report received by the user or corresponding entity may indicate which rules or criteria were checked against the mirrored data thus informing the user of the scope of that report. The user may be incentivized to increase their budget amount if reports suggest that present levels of data quality checking are inadequate.

The OAR page also includes a define my entity or business type selection. The selection includes 6 respective predefined choices including a retailer option an industrial processing option a manufacturing option a corporate business unit option a technical services option and a default other option. The 6 respective options allow the user to select the one that is the most descriptive of their function or interest.

For example the reporting module may be configured to use the selection to identify particular data quality rules or reporting criteria that are of significance to the user and present that information as a recommendation. In another example the reporting module may be configured to prioritize or rank the data quality rules or reporting criteria based on the selection . Other uses or operations based on the selection may also be performed.

The OAR page also includes a learn how to set data correction schema option. The option causes the data quality server to provide tutorial information regarding how data may be automatically corrected by way of the data correction module and the data correction schema . For example the user may be shown that certain data are relevant only as integer values and may be automatically truncated to zero decimal points i.e. the fractional value removed to define corrected data values. In another example the user may be instructed that all non alphanumeric characters i.e. various punctuation or other marks in a string may be replaced with dashes e.g. in the interest of formatting or convention. In this way the user may develop their own automatic data correction processes or understand what predefined data correction options are available.

A view my service level agreement option is also provided by the OAR page . The option causes the data quality server to present a corresponding service level agreement or agreements to the user . Services options terms and other details of an agreement or agreements between the user and the ownership or administrative entity of the data quality server may be reviewed. The OAR page may further include numerous other options or links to information or tutorials. For example an option may allow a user to view data quality rules that are presently i.e. actively being used or are frequently applied. In another example an option may present information or a dashboard display of actions presently being performed by a data quality service e.g. the data quality server . Other options or informational links may also be used.

An order record includes 4 respective data types or elements corresponding to a customer order for merchandise. For example the order record may include entity data provided by the entity to the data warehouse server . The data warehouse server may mirror the order record contents as mirrored data provided to the data quality server . Other operations or data exchanges using the order record are also possible.

The order record includes identifier data . The identifier data includes or is defined by a merchandise number SKU number or other information to specifically identify the particular item ordered by a customer. The order record also includes quantity data . The quantity data is an integer value of the number of units or package counts of the merchandise item of the identifier . As depicted the customer has ordered count of the merchandise item identified as REC 001 987 AC. For purposes of example the merchandise item REC 001 987 AC is a replacement dust filter for an air conditioning unit.

The order record also includes source data . The source data identifies or names the particular manufacturer brand or supplier of the merchandise ordered by the customer. As depicted in the example the customer has cited or input the name TRANS GLOBAL MANUFACTURING as the source data . The order record further includes entity data . The entity data identifies the name of the entity through which the customer placed their order. For example the entity may be a business unit identified as the INDUSTRIAL SERVICES DIVISION within a corporation and is the entity through which the costumer placed their order.

Data quality rules keyed to product rules include 3 different subsets of information keyed to respective data elements of the particular merchandise item of the order record . Thus the rules pertain to the merchandise item identified as REC 001 987 AC. In one example the rules define at least a portion of the data quality rules of the data quality server . The rules may be stored or used within another server or entity as well.

The rules include quantity rules . The quantity rules include 4 different statistical or predefined values against which the quantity data value may be checked. As depicted historical minimum and maximum orders of 1 and 30 respectively have been placed for the merchandise item. Additionally the average per order quantity for the merchandise item is 25. Furthermore a rule sets the maximum allowable per order quantity at . Thus the first 3 values of the quantity rules are statistically derived from historical customer order data and are potentially or likely subject to change over time while the last value may be established or modified in accordance with company policy administrative decisions or other factors.

The rules include source rules which include 3 different specific names or brands against which the source data entry may be checked. In particular the 3 named sources include TRANS CANADA MANUFACTURING INDIA PRODUCTS EXPRESS and IOWA TECHNOLOGIES. The list of names within the source rules may be modified over time as sources are added or removed and so on. For purposes of example the 3 named sources define at present the only sources for the merchandise item REC 001 987 AC.

The rules include entity rules which include 4 different specific entity names against which the entity data entry may be checked. As depicted the 4 named entities each of which being a business unit within the same corporation include INDUSTRIAL SERVICES DIVISION COMMERCIAL SUPPLY DIVISION ACADEMIC SUPPLY DIVISION and FEDERAL CONTRACT SERVICES DIVISION. The list of names within the entity rules may be modified over time as sources are added or removed and so on. For purposes of example the 4 named entities are at present the only entities authorized to place orders for the merchandise item REC 001 987 AC.

The data checking module of the data quality server may check the data elements against the rules . In a present example the identifier data checks Valid because the particular merchandise item REC 001 987 AC is cited verbatim within the data quality rules and includes its own subset of rules . Next the quantity data checks Valid because the particular value is lesser than the maximum allowable per order quantity of 40. Furthermore the value is consistent with the present historical minimum and maximum but is less than the per order daily average.

However the source data checks Invalid because the cited product source name TRANS GLOBAL MANUFACTURING is not verbatim an element of the source rules . The ordering customer may have intended to cite or enter TRANS CANADA MANUFACTURING based on partial text heuristics or similar reasoning. Nonetheless the source data is Invalid for purposes of the present illustration.

Finally the entity data checks Valid because the cited entity name INDUSTRIAL SERVICES DIVISION is authorized to order the merchandise item REC 001 987 AC in accordance with the entity rules . That is the entity data entry is a verbatim element of the entity names listing of the entity rules . The data checking module then provides the results of the data checking operation just performed as well as the data values to the reporting module .

The reporting module may generate one or more reports using the checking results just received from the data checking module . For purpose of example the reporting module may generate a data quality report in accordance with the particular user options and inputs illustrated within the report template . Other reports having respectively varying information or indications may also be generated and provided.

Accordingly the data quality report indicates that product identifier as provided in order record is Valid . That is the merchandise item REC 001 987 AC is specifically known and may be ordered by the customer. The data quality report further indicates for purposes of example that the product identifier is a Priority 1 matter of concern. That is the validity of the identifier data is of greatest concern in accordance with applying the data quality rules in a prioritized manner e.g. for a particular user e.g. .

For example the user may rank the respective data elements by varying degrees of importance because errors or inconsistencies in those respective data elements give rise to problems or issues of differing severity. In contrast a different user may rank the data elements differently because of other concerns or responsibilities. Thus the data quality rules may be applied in accordance with user specific priorities and the corresponding report or reports reflect or indicate those priorities accordingly. Furthermore the user may be billed in accordance with the priorities that they define. For example if the user prioritizes all of the respective data elements as Priority 1 then data quality checking and data quality reporting may be more rigorous and the corresponding prices of services may be higher than under a hierarchy of lower priorities.

The data quality report also indicates that the quantity ordered in the order record is Valid . Specifically the ordered quantity of 16 does not violate any of the applicable rules nor trigger further inquiry. Additionally the quantity falls within the range of 1 to 20 specified as valid per the selection . The data quality report further indicates that the quantity ordered is also a Priority 1 concern.

The data quality report indicates that the product source specified in the order record is Invalid . The invalid indication corresponds to the fact that the cited source name TRANS GLOBAL MANUFACTURING is not a listed source for the merchandise item. The data quality report indicates that the product source is a Priority 2 level of concern. In the present example the validity of the source data is of relatively significant concern but lesser so than data having a Priority 1 level.

The data quality report further indicates that the ordering entity provided in the order record is Valid . Again the ordering entity INDUSTRIAL SERVICES DIVISION is authorized to order or broker orders for the merchandise item REC 001 987 AC. The data quality report indicates that the ordering entity is a Priority 3 concern deemed to be of lesser significance than respective Priority 1 or Priority 2 data.

The data quality report may be provided to an entity or entities in accordance with a service level agreement internal auditing practice and so on. For example the data quality report may be provided to the user by way of a user device associated with or defining the entity .

The data quality server may include one or more I O interface s to allow the processor s or other portions of the data quality server to communicate with user devices or other resources of the respective entities with the data warehouse server with the cost allocation server and so on. The I O interfaces may comprise Inter Integrated Circuit I2C Serial Peripheral Interface SPI Universal Serial Bus USB RS 232 and so forth.

The I O interface s may couple to one or more I O devices . The I O devices may include input devices such as one or more of a keyboard mouse and so forth. The I O devices may also include output devices such as one or more of a display audio speakers haptic output devices and so forth. In some embodiments the I O devices may be physically incorporated with the data quality server or may be externally placed.

The data quality server may also include one or more communication interfaces . The communication interfaces are configured to provide communications between the data quality server user devices or resources of the entities routers access points other servers and so forth. The communication interfaces may include devices configured to couple to one or more networks including PANs LANs WLANs WANs and so forth.

The data quality server may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the data quality server .

The data quality server includes one or more memories . The memory comprises one or more CRSM. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the data quality server .

The memory may include at least one operating system OS module . The OS module is configured to manage hardware resource devices such as the I O interfaces the I O devices the communication interfaces and provide various services to applications or modules executing on the processors . Also stored in the memory may be one or more of the following modules. These modules may be executed as foreground applications background tasks daemons and so forth.

A user interface module may be configured to provide one or more application programming interfaces. The user interface module may also provide data configured to provide the user interfaces or or other user interfaces to the entities or to other entities or user devices. Such user interfaces may be encoded as hypertext markup language HTML files extensible markup language XML files or in another suitable format or language. The user interface module is configured to accept inputs and send outputs using the I O interfaces the communication interfaces or both.

A communication module is configured to support communication with the entities the data warehouse server the cost allocation server routers and so forth using one or more networks . In some implementations the communication module may support encrypted communications. For example hypertext transport protocol secured HTTPS or transport layer security TLS may be supported.

The memory may also include one or more application modules . The application modules may be configured or modified and selectively used or provided to other entities as needed or requested. Thus the data quality server can be updated or enhanced as new application modules are generated existing application modules are amended or improved and so on.

The memory may also include the data checking module . The data checking module may include any resources not limited to machine readable program code stored on a CRSM or other constituency. As described above the data checking module is configured to check the mirrored data against the one or more data quality rules or subsets of such rules e.g. stored within the data quality server .

The memory may also include the reporting module which is configured to use results data or other information from data checking module to generate one or more reports. Such one or more reports are provided by way of the data quality reporting to respective ones of the entities or to another entity or entities. The reporting module may include any resources not limited to machine readable program code stored on a CRSM or other constituency.

The memory may also include the data correction module as is configured to automatically correct some or all of the mirrored data using the data correction schema . Resulting corrected data may be provided back to the data warehouse server where it may substituted in place of corresponding erroneous data within the consolidated data or stored or used in other ways. The data correction module may include any suitable resources such as without limitation machine readable program code stored on a CRSM or other constituency.

Other modules may also be present. In one implementation a billing or cost allocation module may be configured to calculate billing values in accordance with various operations performed by the data quality server . Such values can be calculated per user e.g. or service subscriber budget amounts e.g. in accordance with in house price structures or polices as defined in respective service agreements and so on. In another implementation a translation module may be configured to provide translation of viewable content messages or both enabling directed interaction of a group of users which use different languages. Other modules or functionalities may also be implemented.

The memory may also include a datastore to store information. The datastore may use a flat file database linked list tree executable code or other data structure to store the information. In some implementations the datastore or a portion of the datastore may be distributed across one or more other devices including servers network attached storage devices and so forth.

The datastore may store the mirrored data the data quality rules the data correction schema or any combination of these as respectively previously described. Other data may also be stored. For example the other data may include one or more service agreements between the owner or administrator of the data quality server and the respective responsible parties of the entities or or with other entities or service subscribers.

Block receives entity data from the entity at a data warehouse service. For example the entity data may be data and information corresponding to a customer order for an item or items of merchandise such as the respective data of the order record . The entity data is thus provided to the data warehouse server .

Block mirrors the received entity data to a data quality service such as executing on one or more data quality servers . In the present example the received entity data is thus mirrored or copied as mirrored data that is received and stored in the data quality server . Therefore 2 identical copies of the order record now exist 1 copy that is stored within the data warehouse server and 1 copy that is stored as at least a portion of the mirrored data within the data quality server .

Block checks the mirrored data against the data quality rules . In the present example the data checking module checks or compares the just received mirrored data against one or more of the data quality rules that are applicable thereto. For instance the checking may indicate that respective data and are Valid and that the data is Invalid per the rules that are part of the data quality rules .

Block generates the data quality report per a user defined template . In the present example the reporting module receives the respective Valid and Invalid indications derived at block from the data checking module as well as the actual data . The reporting module then uses the Valid Invalid indications the data and the selections and inputs made to the report template so as to generate the data quality report . In particular the reporting module causes the data quality report to indicate that the order quantity i.e. quantity data value is In Range in accordance with the selection as well as being Valid .

Block provides the data quality report to the requesting entity . In the present example the data quality report is provided by way of data quality reporting to the entity for review or use by the user associated therewith.

Block generates corrected data in accordance with the data correction schema . In the present example the data correction module generates one or more elements of corrected data using applicable operations or functions of the data correction schema . For instance the source data was erroneously provided as TRANS GLOBAL MANUFACTURING by way of the order record . The data correction schema may be configured to determine that TRANS CANADA MANUFACTURING is the correct source name by way of a heuristic or best match replacement function. The data correction module then automatically replaces the source data with the name or string TRANS CANADA MANUFACTURING.

Block provides the corrected data to the data warehouse service. In the present example the corrected source data having the replacement string TRANS CANADA MANUFACTURING is provided as corrected data from the data quality server to the data warehouse server . Thus the source data of the order record is automatically corrected and communicated back to the data warehouse server for storage in place of or in addition to the original data of the order record .

Block bills the entity for data quality services. In the present example the data quality server provides information regarding the data quality checking and correction services just performed to the cost allocation server . In turn the cost allocation module calculates a billing value in accordance with the information as well as a cost structure defined by a service level agreement corporate policy and so forth. The billing value may be stored for later use in a periodic billing cycle provided or transmitted to the entity or other entities now or used for other purposes.

Block receives entity data from the entity at a data warehouse service. For example the entity data may be a corpus or packet of information corresponding to an order for several items of merchandise in an online e commerce environment. The packet of information may be designated as data and received by the data warehouse server as the operation . The data is also being mirrored as the operation to the data quality server contemporaneous with or nearly so its reception from the entity .

Block checks a first portion of the data against the data quality rules . In the present example the data checking module checks one or more of the data quality rules against a first portion of the data as part of the operation . The data checking of the operation may determine if respective data elements are valid or invalid comply with formatting syntactical or numerical protocols are elements found within predefined lists or sets and so on.

Block changes one or more of the data quality rules in accordance with user input. In the present example a system administrator for instance the user accesses the data quality server and modifies one or more of the data quality rules at least some of the modified rules being applicable to the data . The data quality rule modification is performed as the operation . An initial portion of the operation continues contemporaneous with the operation using the pre modified data quality rules .

Block checks a second portion of the data against the modified data quality rules . In the present example the data checking module checks one or more of the modified data quality rules against a second or remaining portion of the data as part of the operation . Thus the modified data quality rules are put to use immediately within the operation as soon as the operation is complete.

The use of the modified data quality rules will or should in at least some instances yield different data checking results than that of the pre modified data quality rules . That is the first portion of data resulted in a first set of data checking results and the second portion of the data resulted in a second set of data checking results that may differ from the first. These potentially mixed results are accumulated throughout the operation .

Block generates a data quality report using the mixed data quality results. The reporting module receives the potentially mixed data quality results from the data checking module and generates a data quality report e.g. accordingly. The data quality report may be provided to the entity by way of the data quality reporting . A reader or user e.g. of the data quality report just generated may compare the results of first portion relative to the second portion of the data and evaluate the significance benefits or the contrary of the modified data quality rules over the original data quality rules.

In one example the modified data quality rules may cause the report to indicate validity invalidity based on a new formatting rule applied to product identifier data a quality check not previously performed. If data checking performed using the modified rule indicates that some appreciable portion of the mirrored data including data received over the last few months is non compliant with established formatting policy immediate investigative or corrective actions may be warranted.

In another example the modified data quality rules may cause the report to indicate validity invalidity based on a new minimum annual order quantity that is greater than some previous such value. Checking the historical mirrored data using the new minimum annual order quantity may indicates that a particular sales entity e.g. has fallen behind in their sales metric for a corresponding item of merchandise. Countless other determinations may also be made and the overall effectiveness and benefits of data checking may be improved by way of new or modified data quality rules.

Those having ordinary skill in the art will readily recognize that certain components steps or operations illustrated in the figures above can be eliminated taken in an alternate order or otherwise rearranged. Moreover the methods described above may be implemented as one or more software programs for a computer system and are encoded in a computer readable storage medium as instructions executable on one or more processors.

The CRSM can be any one of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium and so forth. Separate instances of these programs can be executed on or distributed across separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art readily recognize that the techniques described above can be utilized in a variety of devices environments and situations.

Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art and it is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

