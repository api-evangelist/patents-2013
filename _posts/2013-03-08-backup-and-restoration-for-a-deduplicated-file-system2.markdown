---

title: Backup and restoration for a deduplicated file system
abstract: The disclosed techniques that can use deduplication information on a source computer platform to improve the process of performing data backups or restoration from/to the computer platform. In one example aspect, a data backup operation can re-use some of the work already done by a source computer's deduplication system. For example, a storage operation could read a deduplication database on the source computer platform to determine the duplicativeness of a given data chunk being transferred to a backup storage system, without having to perform computations such as data chunk hashing and comparison with previously generated hashes. The technique may additionally or alternatively reuse hashes generated by the source computer during deduplication of the data file on the source computer's file system during deduplication at the external backup storage system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633022&OS=09633022&RS=09633022
owner: Commvault Systems, Inc.
number: 09633022
owner_city: Tinton Falls
owner_country: US
publication_date: 20130308
---
The present application claims priority to and the benefit of U.S. Provisional Application No. 61 746 744 filed Dec. 28 2012 which is hereby incorporated herein by reference in its entirety.

Computer systems contain large amounts of information. This information includes personal information such as financial information customer client patient contact information business information audio visual information and much more. This information also includes information related to the correct operation of the computer system such as operating system files application files user settings and so on. With the increased reliance on computer systems to store critical information the importance of protecting information has grown. Traditional storage systems receive an identification of a file to protect and then create one or more secondary copies such as backup files containing the contents of the file. These secondary copies can then later be used to restore the original data should anything happen to the original data.

Traditional storage system often perform data redundancy reduction before storing backup data. Data redundancy reduction may use valuable system resources.

The system described herein provides techniques that can use deduplication information on a source computer platform to improve the process of performing data backups or restoration from to the computer platform. In one example aspect a data backup operation can re use some of the work already done by a source computer s deduplication system. For example a storage operation could read a deduplication database on the source computer platform to determine the duplicativeness of a given data chunk being transferred to a backup storage system without having to perform computations such as data chunk hashing and comparison with previously generated hashes. Some embodiments may additionally or alternatively reuse hashes generated by the source computer during deduplication of the data file on the source computer s file system during deduplication at the external backup storage system.

Some data backup storage systems reduce redundancy in data before storing the data on backup storage such as a tape or a hard disk array. Deduplication is one of the several techniques used for reducing data redundancy. A typical deduplication operation processes a data file to be stored as a sequence of multiple overlapping or non overlapping packets typically having a fixed size. For every next data packet a determination is made about uniqueness or duplicativeness of the data packet by matching the bit pattern with previously seen bit patterns. Often the determination of duplicativeness is performed on a hash value of the data packet instead of the packet itself. The use of hash value based duplication matching may reduce computational complexity. As an illustrative example in a backup process a file may be split into 32 Kbyte data packet and a 64 byte hash value may be computed for each 32 Kbyte data packet. Several techniques are well known to select a hashing algorithm that guarantees unique or almost unique cryptographically unique one to one correspondence between a data packet and a corresponding hash value. Duplication determination may be performed on the 64 byte hash values instead of the 32 Kbyte packets thereby providing significant computational savings. A data packet whose hash value matches with a previously seen hash value is stored as simply a stub e.g. a pointer to the previous occurrence of the same pattern i.e. same data packet . A data packet whose hash value does not match with any of the previously seen hash values may be stored and the corresponding new hash value is added to a table of hash values for future comparisons. Because some data packets e.g. 32 Kbyte packets may be replaced with a stub e.g. a 32 byte pointer during storage significant storage space savings can be achieved.

Broadly and in general terms a data deduplication operation thus uses computational resources for determining hash values for data blocks or data chunks to be backed up and resources for determining uniqueness or duplicativeness of a data block data chunk . In addition deduplication operations also use storage resources to maintain a database of unique data chunks hash values and a database of pointers together called a deduplication record linking backed up data to the unique data chunks. The resources used during the data deduplication operation could be e.g. processor resources program execution memory storage resources data bandwidth resources etc.

Similarly when restoring data from a backup data archive to a file system the backup system may need to restore decompress or rehydrate file data from deduplicated format to its native non deduplicated version. For example a restoration process may access a backed up data chunk determine whether the data chunk is unique or deduplicated e.g. by looking up the deduplication record and rehydrate the data chunk on the file system accordingly.

The inventors have noticed that many new computer operating systems have begun using de duplication to natively store data files production data as further explained below on the source computer. For example operating systems OS such as Solaris and Windows 8 store user files in a proprietary deduplicated format. While the use of deduplication provides benefits to the source computer by reducing the amount of storage space needed to store the file system the deduplication format is typically kept unknown or transparent from a user or another application that is running on the operating system. For example the only way an application e.g. a backup operation can gain read write access to files stored by the operating system may be after the files are rehydrated by the operating system. In other words at the application layer or from the viewpoint of a non OS process or module a deduplicated native file system looks no different than when the file system is not deduplicated.

The present system provides several techniques that can be used by a backup or a restoration process to detect whether a source file system is natively stored in a deduplicated format and to benefit from the deduplication used on the source file system. For example presently disclosed techniques can be used to improve a backup operation by reducing the computing bandwidth and storage resources used by the backup or restoration operation thereby benefitting from the work performed by a client computer s OS in deduplicating the data to be backed up. In some implementations the disclosed techniques can re use the uniqueness duplicativeness information about data chunks available from the source file system thereby eliminating a backup storage system having to perform similar computations. A backup operation may be able to re use hash values computed by the deduplication engine of the OS during its own deduplication process. The backup system may be able to restore files from a backup archive to a computer by only transferring unique data chunks and updating deduplication database on the computer thereby significantly reducing data bandwidth used during data restoration operation.

In one exemplary aspect a disclosed method of backing up data from a source file system of a computer device to a backup data storage system includes checking whether a source file is stored on the source file system in a deduplicated format. when the checking indicates that the source file is stored in a deduplicated format then a block size value used to store the source file in the deduplicated format is determined. Without a file read write assistance from an operating system running on the computer device a local deduplication database is accessed to determine a location of a first data chunk of the source file stored in the deduplicated format on a local storage device. The source file is backed up by accessing and selectively transferring the first data chunk and successive data chunks of the source file by transferring a given data chunk if the local deduplication database indicates that the given data chunk was not deduplicated and transferring a deduplication record without transferring the given data chunk if the local deduplication database indicates that the given data chunk was deduplicated. When the check indicates that the source file is stored without deduplication on the computer device then the source file is backed up by transferring data chunks of the source file to the backup data storage system and performing deduplication on the data chunks of the source file.

In another exemplary aspect a computer program product comprising a computer readable medium having instructions stored thereon is disclosed. The instructions when executed by a processor cause the processor to implement the above described method.

In yet another exemplary aspect techniques for implemented a method of restoring data from a data storage system to a source file system that can store files in a deduplicated format are disclosed. A block size value used to restore a copied file in the deduplicated format is determined. For each data chunk of the copied file if the data chunk was not previously transmitted during the restoration then the data chunk is transferred to the source file system and a deduplication database at the source file system is updated with a pointer a location where the data chunk is transferred to. If the data chunk was previously transmitted during the restoration then the deduplication database at the source file system is updated without transferring the data chunk with a deduplication entry.

Various examples of the invention will now be described. The following description provides certain specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant technology will understand however that the invention may be practiced without many of these details. Likewise one skilled in the relevant technology will also understand that the invention may include many other obvious features not described in detail herein. Additionally some well known structures or functions may not be shown or described in detail below to avoid unnecessarily obscuring the relevant descriptions of the various examples.

The terminology used below is to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific examples of the invention. Indeed certain terms may even be emphasized below however any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section.

Aspects of the technologies described herein may be practiced in an information management environment which will now be described while referencing . As shown in the environment includes multiple computing devices that execute numerous software applications to facilitate the operations of an organization or multiple affiliated organizations such as a household corporation or other business entity a non profit organization an educational institution or a governmental agency. The computing devices may include one or more servers such as mail servers file servers database servers print servers and web servers personal computers workstations or other types of fixed computing systems such as mainframe computers and minicomputers not shown . The servers may include network attached storage NAS filers.

The environment may include virtualized computing resources such as a virtual machine provided to the organization by a third party cloud service vendor or a virtual machine running on a virtual machine host operated by the organization. For example the organization may use one virtual machine A as a database server and another virtual machine B as a mail server. The environment may also include mobile or portable computing devices such as laptops tablet computers personal data assistants mobile phones such as smartphones and other mobile or portable computing devices such as embedded computers set top boxes vehicle mounted devices wearable computers etc.

Of course other types of computing devices may form part of the environment . As part of their function each of these computing devices creates accesses modifies writes and otherwise uses production copies of data and metadata that are typically stored in a persistent storage medium having fast I O times. For example each computing device may regularly access and modify data files and metadata stored on semiconductor memory a local disk drive or a network attached storage device. Each of these computing devices may access data and metadata via a file system supported by an operating system of the computing device.

The environment may also include hosted services that provide various online services to the organization or its constituent members e.g. the organization s departments employees independent contractors etc. such as social networking services e.g. Facebook Twitter Pinterest hosted email services e.g. Gmail Yahoo Mail Hotmail or hosted productivity applications or other hosted applications e.g. Microsoft Office 365 Google Docs Salesforce.com . Hosted services may include software as a service SaaS platform as a service PaaS application service providers ASPS cloud services and all manner of delivering computing or functionality via a network. As it provides services to users each hosted service may generate additional hosted data and metadata that is associated with each user. For example Facebook may generate and store photos wall posts notes videos and other content that are associated with a particular Facebook user s account.

The organization directly or indirectly employs an information management system to protect and manage the data and metadata used by the various computing devices in the environment and the data and metadata that is maintained by hosted services on behalf of users associated with the organization. One example of an information management system is the CommVault Simpana system available from CommVault Systems Inc. of Oceanport N.J. The information management system creates and manages non production copies of the data and metadata to meet information management goals such as permitting the organization to restore data metadata or both data and metadata if an original copy of the data metadata is lost e.g. by deletion corruption or disaster or because of a service interruption by a hosted service allowing data to be recovered from a previous time complying with regulatory data retention and electronic discovery e discovery requirements reducing the amount of data storage media used facilitating data organization and search improving user access to data files across multiple computing devices and or hosted services and implementing information lifecycle management ILM or other data retention policies for the organization. The information management system may create the additional non production copies of the data and metadata on any suitable non production storage medium such as magnetic disks magnetic tapes other storage media such as solid state storage devices or optical disks or on cloud data storage sites e.g. those operated by third party vendors . Further details on the information management system may be found in the assignee s U.S. patent application Ser. No. 12 751 850 filed Mar. 31 2010 entitled DATA OBJECT STORE AND SERVER FOR A CLOUD STORAGE ENVIRONMENT INCLUDING DATA DEDUPLICATION AND DATA MANAGEMENT ACROSS MULTIPLE CLOUD STORAGE SITES now U.S. Patent Publication Number 2010 0332456 which is hereby incorporated by reference herein in its entirety.

The information management system accesses or receives copies of the various production copies of data objects and metadata and via an information management operation such as a backup operation archive operation or snapshot operation creates non production copies of these data objects and metadata often stored in one or more non production storage mediums different than the production storage medium where the production copies of the data objects and metadata reside. A non production copy of a data object represents the production data object and its associated metadata at a particular point in time non production objects A C . Since a production copy of a data object or metadata changes over time as it is modified by an application hosted service or the operating system the information management system may create and manage multiple non production copies of a particular data object or metadata each representing the state of the production data object or metadata at a particular point in time. Moreover since a production copy of a data object may eventually be deleted from the production data storage medium and the file system from which it originated the information management system may continue to manage point in time representations of that data object even though a production copy of the data object itself no longer exists.

For virtualized computing devices such as virtual machines the operating system and applications A D may be running on top of virtualization software and the production data storage medium may be a virtual disk created on a physical medium such as a physical disk. The information management system may create non production copies of the discrete data objects stored in a virtual disk file e.g. documents email mailboxes and spreadsheets and or non production copies of the entire virtual disk file itself e.g. a non production copy of an entire .vmdk file .

Each non production object A C may contain copies of or otherwise represent more than one production data object. For example non production object A represents three separate production data objects C and C represented as C and respectively . Moreover as indicated by the prime mark a non production object may store a representation of a production data object or metadata differently than the original format of the data object or metadata e.g. in a compressed encrypted deduplicated or otherwise optimized format. Although shows that a single production data object e.g. C and its associated data object metadata e.g. Meta11 are represented by the contents of only a single non production object e.g. A the entire contents of a single production data object and or its metadata at a particular point in time may instead span across numerous non production objects. Also a single non production object may contain copies of or otherwise represent production data objects that originated from different computing devices.

Non production copies include backup copies archive copies and snapshot copies. Backup copies are generally used for shorter term data protection and restoration purposes and may be in a native application format or in a non native format e.g. compressed encrypted deduplicated and or otherwise modified from the original application format . Archive copies are generally used for long term data storage purposes and may be compressed encrypted deduplicated and or otherwise modified from the original application format. In some examples when an archive copy of a data object is made a logical reference or stub may be used to replace the production copy of the data object in the production storage medium . In such examples the stub may point to or otherwise reference the archive copy of the data object stored in the non production storage medium so that the information management system can retrieve the archive copy if needed. The stub may also include some metadata associated with the data object so that a file system and or application can provide some information about the data object and or a limited functionality version e.g. a preview of the data object. A snapshot copy represents a data object at a particular point in time. A snapshot copy can be made quickly and without significantly impacting production computing resources because large amounts of data need not be copied or moved. A snapshot copy may include a set of pointers derived from the file system or an application where each pointer points to a respective stored data block so collectively the set of pointers reflect the storage location and state of the data object at a particular point in time when the snapshot copy was created. In copy on write if a block of data is to be deleted or changed the snapshot process writes the block to a particular data storage location and the pointer for that block is now directed to that particular location. The set of pointers and or the set of blocks pointed to by a snapshot may be stored within the production data storage medium .

Non production copies of a data object or metadata may be distinguished from a production copy of a data object or metadata in several ways. First a non production copy of a data object is created to meet the different information management goals described above and is not directly used or modified by applications A D hosted services or the operating system . Second a non production copy of a data object is stored as one or more non production objects that may have a format different from the native application format of the production copy of the data object and thus often cannot be directly used by the native application or a hosted service without first being modified. Third non production objects are often stored on a non production storage medium that is inaccessible to the applications A D running on computing devices and hosted services . Also some non production copies may be offline copies in that they are not readily available e.g. not mounted tape or disk. Offline copies include copies of data that the information management system can access without any human intervention e.g. tapes within an automated tape library but not yet mounted in a drive and copies that the information management system can access only with at least some human intervention e.g. tapes located at an offsite storage site .

The information management system also generates information management data such as indexing information that permit the information management system to perform its various information management tasks. As shown in a computing device may include one or more data management agents that provide client side functions for the information management system.

The storage manager may be a software module or other application that coordinates and controls information management operations performed by one or more information management cells to protect and control copies of non production data objects and metadata. As shown by the dashed lines and the storage manager may communicate with some or all elements of the information management cell such as the media agents and computing devices to initiate and manage backup operations snapshot operations archive operations data replication operations data migrations data distributions data recovery and other information management operations. The storage manager may control additional information management operations including ILM deduplication content indexing data classification data mining or searching e discovery management collaborative searching encryption and compression. Alternatively or additionally a storage manager may control the creation and management of disaster recovery copies which are often created as secondary high availability disk copies using auxiliary copy or replication technologies.

The storage manager may include a jobs agent a management agent a network agent and an interface agent all of which may be implemented as interconnected software modules or application programs. The jobs agent monitors the status of information management operations previously performed currently being performed or scheduled to be performed by the information management cell . The management agent provides an interface that allows various management agents in multiple information management cells or in a global storage manager to communicate with one another. This allows each information management cell to exchange status information routing information capacity and utilization information and information management operation instructions or policies with other cells. In general the network agent provides the storage manager with the ability to communicate with other components within the information management cell and the larger information management system e.g. via proprietary or non proprietary network protocols and application programming interfaces APIs including HTTP HTTPS FTP REST virtualization software APIs cloud service provider APIs hosted service provider APIs . The interface agent includes information processing and display software such as a graphical user interface GUI an API or other interactive interface through which users and system processes can retrieve information about the status of information management operations or issue instructions to the information management cell and its constituent components. The storage manager may also track information that permits it to select designate or otherwise identify content indices deduplication databases or similar databases within its information management cell or another cell to be searched in response to certain queries.

The storage manager may also maintain information management data such as a database of management data and policies. The database may include a management index that stores logical associations between components of the system user preferences user profiles that among other things map particular information management users to computing devices or hosted services management tasks or other useful data. The database may also include various information management policies which are generally data structures or other information sources that each includes a set of criteria and rules associated with performing an information management operation. The criteria may be used to determine which rules apply to a particular data object system component or information management operation an may include 

As noted above each computing device may include one or more data management agents . Each data management agent is a software module or component that helps govern communications with other system components. For example the data management agent receives commands from the storage manager and sends to and receives from media agents copies of data objects metadata and other payload as indicated by the heavy arrows . Each data management agent accesses data and or metadata stored in a production data storage medium and arranges or packs the data and metadata in a certain format e.g. backup or archive format before it is transferred to another component. Each data management agent can also restore a production copy of a data object or metadata in a production data storage medium from a non production copy. A data management agent may perform some functions provided by a media agent which are described further herein such as compression encryption or deduplication. Each data management agent may be specialized for a particular application e.g. a specified data management agent customized to handle data generated or used by Exchange by Microsoft Corp. . Alternatively or additionally a more generic data management agent may handle data generated or used by two or more applications.

Each computing device may also include a data distribution and live browsing client module herein distribution client module . The distribution client module is responsible for inter alia associating mobile devices and or hosted service accounts with users of the information management system setting information management policies for mobile and other computing devices pushing data objects to a distribution module for distribution to other computing devices providing unified access to a user s data via an interface and providing live browsing features. The various functions of the distribution client module are described in greater detail herein.

A media agent which may be implemented as a software module conveys data as directed by the storage manager between a computing device or hosted service and one or more non production storage mediums . Each media agent may control one or more intermediary storage devices such as a cloud server or a tape or magnetic disk library management system to read write or otherwise manipulate data stored in a non production storage medium . Each media agent may be considered to be associated with a storage device and its related non production storage media if that media agent is capable of routing data to and storing data in the storage media managed by the particular storage device. A media agent may communicate with computing devices hosted services storage devices A D and the storage manager via any suitable communications path including SCSI a Storage Area Network SAN a Fibre Channel communications link or a wired wireless or partially wired wireless computer or telecommunications network including the Internet.

To perform its functions the media agent may include a media file system module a data classification module a content indexing module a deduplication module an encryption module a compression module a network module a distribution module and a media agent database . The media file system module is responsible for reading writing archiving copying migrating restoring accessing moving sparsifying deleting sanitizing destroying or otherwise performing file system operations on various non production storage devices of disparate types. The media file system module may also instruct the storage device to use a robotic arm or other retrieval means to load or eject certain storage media such as a tape.

The network module permits the media agent to communicate with other components within the system and hosted services via one or more proprietary and or non proprietary network protocols or APIs including cloud service provider APIs virtual machine management APIs and hosted service provider APIs . The deduplication module performs deduplication of data objects and or data blocks to reduce data redundancy in the cell. The deduplication module may generate and store data structures to manage deduplicated data objects such as deduplication tables in the media agent database . The encryption module performs encryption of data objects data blocks or non production objects to ensure data security in the cell. The compression module performs compression of data objects data blocks or non production objects to reduce the data capacity needed in the cell.

The content indexing module analyzes the contents of production copies or non production copies of data objects and or their associated metadata and catalogues the results of this analysis along with the storage locations of or references to the production or non production copies in a content index stored within a media agent database . The results may also be stored elsewhere in the system e.g. in the storage manager along with a non production copy of the data objects and or an index cache. Such index data provides the media agent or another device with an efficient mechanism for locating production copies and or non production copies of data objects that match particular criteria. The index data or other analyses of data objects or metadata may also be used by the data classification module to associate data objects with classification identifiers such as classification tags in the media agent database or other indices to facilitate information management policies and searches of stored data objects.

The distribution module may be a set of instructions that coordinates the distribution of data objects and indices of data objects. The distribution may occur from one computing device to another computing device and or from hosted services to computing devices . As a first example the distribution module may collect and manage data and metadata from hosted services or mobile devices . As another example the distribution module may synchronize data files or other data objects that are modified on one computing device so that the same modified files or objects are available on another computing device. As yet another example the distribution module may distribute indices of data objects that originated from multiple computing devices and or hosted services so a user can access all of their data objects through a unified user interface or a native application on their computing device. The distribution module may also initiate live browse sessions to permit communications between different computing devices so that the devices can interchange data and metadata or so the devices can provide computing resources such as applications to each other.

In various implementations the client computer may be e.g. a user s computer laptop tablet smartphone a file server or an e mail server and so on. The client computer may be embodied using any operating system e.g. Windows OS X Linux Solaris etc. and hardware platform e.g. x86 ARM etc. .

The file storage stores various files in directories. The stored files may be stored in fragmented or un fragmented formats. The file storage does not store files in de duplicated formats but store production data in native though fragmented or un fragmented formats. In the fragmented format a file may be stored in several smaller data chunks that are stored at non contiguous memory addresses that are linked together e.g. by a linked list of pointers to next fragments. In the un fragmented format a data file may be stored in contiguous memory locations as a single block of data.

In some implementations the file system may be a file system under Windows 7 or an earlier operating system released by Microsoft Corporation. These operating systems generally store user files and other data in a format that does not use de duplication. In such a format individual files are accessible on their own i.e. without a need to access data blocks that are commonly shared with other files stored on the file storage .

A data backup operation in the system may proceed as follows. The backup client module may be instructed to begin a data backup operation. The instruction may come from a user or from an automated scheduler e.g. once a week backup or other periodic instruction . The instruction may identify which files are to be backed up. For each file to be backed up the backup client may access the file by communicating with the file I O layer over the link e.g. software APIs obtaining the file possibly in smaller pieces and transferring the file over the communication link to the external backup system . The external backup system may perform a redundancy reduction operation such as the previously described deduplication operation and store the file on an external backup storage media. In this backup process a 10 Mbyte file e.g. will use 10 Mbytes of transfer bandwidth over the communication link .

However in system the module does not make available to other applications e.g. the backup client the deduplication information or provide other applications with access to the chunk store and the deduplication records . Therefore data backup or restoration operations in the system proceed similarly as described with respect to system . In other words without access to the deduplication information data transferred over the link during a backup or restoration operation will be equal to the total size of volumes or directories being backed up or restored because only rehydrated data is provided by the native deduplication control module . Also any deduplication performed by the backup storage system will be independent of any computations or records controlled by the native deduping control module .

At a check is made to find out whether a given file to be backed up is locally deduplicated on the source file system. If the file is not de duplicated then the traditional file I O e.g. by making file read write calls to the operating system of the client computer is used to perform data backup.

If it is determined at that a given local file to be backed up is locally stored in a deduplicated format then at the backup client module determines the deduplication block size used for the de duping format of the source file system operating system. In various implementations the block size may be determined using one or more of a variety of different techniques. For example in some implementations based on the operating system running on the client computer the backup client module may have a priori knowledge that a given block size is used for deduplication for all files stored in the chunk store . However some operating systems may use different data block sizes for deduplicating files based on file type or volume or the directory or the user who created the filed and so on. Therefore the backup client module in general may need to determine deduplication block size on a file by file basis.

When the information is available by making a query to the native deduping control module an API call may provide this information to the backup client module . As an example the API call may include a filename parameter that identifies a file for which the query is made. In response the deduping control module may provide a deduplication block size. The native deduping control module may also provide additional information such as a pointer to a location at which hash values and deduplication database for the file are stored.

Alternatively a variety of blind i.e. without assistance from the file system or the operating system running on the client computer approaches or processes may be taken. Using one such blind approach the backup client module may query a table that includes entries of operating system versions and corresponding rules used by the operating system in selecting deduplication data block size s for files. This table may be stored locally at the backup client module or externally at the backup system .

Another process is to use a same deduplication data block size of a file previously backed up from the same directory or of the same file type. For example the same data block size may be used for all text files and another data block size may be used for all image files and so on.

Another process is based on a trial and error method in which knowing a type of the file e.g. a spreadsheet or a presentation different deduplication data block sizes will be tried to access data from the chunk store and the data thus obtained may be compared with the expected byte pattern based on the file type to determine the most probable deduplication data block and then using the same during the backup operation.

Another process based on a trial and error approach first attempts to compress a file being tested using a given data compression algorithm e.g. zip or some other well known algorithm or technique . Based on how much compression is achieved the process may formulate an estimate of the length of deduplication. For example the process may assume an inverse relationship between the amount of compression that can be achieved and the deduplication data block size. That is a file that can be more compressed may be assumed to have a high value of block size e.g. 32 Kbytes than another file that does not get compressed as much e.g. 1024 bytes .

In some implementations when the backup client module is not able to determine with a sufficiently high degree of confidence what the deduplication data block size is it may revert back to accessing the file through the file i o layer using previously described backup process with respect to .

At the backup client module then locates the de duplicated data blocks or data chunks that make up the given local file to be backed up e.g. data chunks that are uniquely present in that file and data stubs . At the de duplicated data blocks are transferred to an external agent e.g. backup storage system for backup operation. After the transfer of the file is completed a local accounting database may be updated at to indicate that the given file was backed up.

To illustrate bandwidth savings achieved by a backup operation as described above a simplified example is given below. In this example a 64 Megabyte file is to be backed up to external backup storage. Without using de duplication information the file will be backed up by transferring 64 Mbytes of data over the communication connection e.g. element in or . Assume that the file is deduplicated using block size 32 Kbytes. Without de duplication the file will therefore have 2 000 data chunks each having 32 Kbyte lengths. After de duplication is performed it is determined that 400 of the 2 000 chunks occur more than once. Therefore in the deduplicated format the file may be stored as 1600 data chunks of 32 Kbytes each that uniquely occur in the file plus overhead information for the remaining 400 chunks that are duplicative. The overhead information may be stored in records which are 64 bytes long each. Therefore a 64 Mbyte file can be stored in the de duplicated format in 1600 32 Kbytes 400 64 bytes or 51.2256 Mbytes thereby reducing storage and transfer bandwidth needed for backup by almost 20 percent In practice greater savings can be obtained by selecting different values for the block size depending on the file type.

At the process receives a request for file restoration operation. The request may include information about which files to restore and where to restore them to. The request may be received from the storage manager noted above as part of a storage policy or storage schedule or from a user. The request may be received at the backup client module e.g. by a user or administrator of the client computer or at the backup storage system .

At the process makes a determination about whether to store the file in a deduplicated format. The backup storage system or the backup client module may make the determination in many different ways. For example backup metadata corresponding to the file being restored may have been saved during the backup operation e.g. process and may indicate whether the file was originally stored on the source file system in a deduplicated format. The same deduplication data block size as determined during the backup process may be used during restoration. As previously discussed the determination may also depend on file type target directory user owner of the file the version of the operating system on the client computer and so on.

At when the process determines that the file is not to be restored in a deduplicated format the file is restored to the client computer using file i o layer of the client computer as previously described.

At when the process determines that the file is to be restored in a deduplicated format as previously discussed the process determines the deduplication block size.

At the process transfers the file being restored e.g. over the link in the deduplication format. Various deduplication formats are described below with reference to .

At the process restores the file on the client computer and updates the local file system accordingly. For example all data chunks of the file are stored in the chunk store the deduplication records are updated if needed to correspond to the restored file e.g. hash values data block size etc. are added or corrected in the deduplication records . In addition the native deduplication control module may also be informed that the file is restored. In some implementations the native deduplication control module or the file i o layer may be informed through an API call that the restored file was recently modified thereby having the native deduplication control module run its own deduplication process.

As previously described the pointers P and P provide information to a receiving side about how to rehydrate the data chunk at that location from one of the data chunks that was previously transmitted to the receiving side. Depending on how the source file system had performed its deduplication the pointers may point to data chunks within the same file or the same group of files e.g. same directory or directories or all files selected for the backup operation or the same volume e.g. hard drive . The previously described client backup module may therefore perform an integrity check on the data stubs e.g. pointers being sent in the file transfer format to ensure that the pointers are pointing to data chunks that are also being sent to the backup system or may have previously been sent to the backup system.

As an illustrative example to highlight the importance of the integrity check consider for example a case in which a file was deduplicated by the source file system using hash computations and data chunk uniqueness over all files within the same directory. Therefore some of the pointers in the deduplicated format of the file may be pointing to data chunks in other files in the same directory. Now if only the file but not any other file in the directory is sent to the backup storage system at the backup storage system the pointers pointing to the other files cannot be used to recover the original data chunks in the file being backed up because the backup storage system does not have access to the other files.

For a data stub received at the hash calculation is skipped by the backup storage system because the presence of the data stub already indicates that the corresponding data chunk was previously sent to the backup storage system . At the backup storage system may adjust the pointer value from a format used by the client computer to a format used by the backup storage system . For example layout of the media on which the backup storage system stores the backed up file may be organized differently than the source file system and therefore the backup storage system may adjust the data stub to correctly point to the address or offset location on the media on which the file is being backed up. At the possibly modified pointer is stored in the deduplication records of the backup storage system and the corresponding data stub is stored in the storage media.

At the process checks whether a source file is stored on the source file system in a deduplicated format. In some implementations the check may be based on a priori knowledge that the operating system running on the computer device used a de duplication format for storing all its files. In some implementations when a first file in the source directory is checked and determined to be in a de duplicated format it is assumed that all other files in the source directory are also de duplicated. In some implementations when it is determined that a file in a directory is stored in a de duplicated format by the OS then it is assumed that all files in child directories listed in the directory are also stored in a de duped format.

In some implementations the process make may the check about whether or not a file is stored in a de duplicated format may be made without assistance from the operating system. Some operating systems may provide assistance e.g. in the form of application programmer interface API calls or pre publishing information about how to ascertain whether or not a given file is stored in the de duplicated format. A check without explicit assistance from the OS may be performed in a variety of ways. For example in some implementations a priori trial and error testing may be performed to devise a test strategy based on regular API calls to the OS e.g. comparing actual hard disk usage with the file size declared by the OS to see if there is a mismatch . In some implementation a file read operation may be performed by directly accessing a hard disk location and the data chunk read back may be tested against an expected bit pattern. For example as previously discussed an OS may make the hard drive location where the first data chunk of a file is stored but may only allow read write access transparently i.e. without revealing whether de duplication is performed by the OS . However the OS may also permit raw read writes from specific hard drive addresses. Also files of known types e.g. .doc files or .xls files typically have known or predicable headers and byte patterns and reading a known format file and testing for these patterns may reveal whether the data chunk includes file data or is in a de duplicated format e.g. contains a pointer .

At when the checking indicates that the source file is stored in a deduplicated format the process determines the block size value used to store the source file in the deduplicated format. The block size used for de duplication may be determined based on a priori knowledge about the operating system running on the computer. The block size used for de duplication may also be determined based on a trial and error approach as outlined above with respect to de duplication determination.

At without a file read write assistance from an operating system running on the computer device the process accesses a local deduplication database to determine a location of a first data chunk of the source file stored in the deduplicated format on a local storage device. The database may be read e.g. using a priori knowledge about where the database is located e.g. a memory location on a hard drive . Some operating systems may not provide API calls to be able to access the deduplication database directly. However the deduplication database may be stored at a specific location for a given file or directory or volume.

At the process backs up the source file by accessing and selectively transferring the first data chunk and successive data chunks of the source file as further described below. As previously discussed each source file to be backed up may be transferred data chunk by data chunk to the backup storage system. However in various implementations either the data chunk or a de duplication record e.g. a pointer and or hash value or both is transferred from the source file system to the backup storage system.

At a given data chunk is transferred only if the local deduplication database indicates that the given data chunk was not deduplicated. In other words this may be the first appearance of the data chunk in the deduplication process and therefore may need to be transferred to the backup storage system.

At a deduplication record is transferred without transferring the given data chunk if the local deduplication database indicates that the given data chunk was deduplicated. For example as previously discussed when the source file system s deduplication record may indicate that the data chunk to be transferred is not unique i.e. the same byte pattern was previously transferred then instead of transferring the data chunk again a pointer pointing to the earlier transferred copy of the same data chunk may be transferred. In a typical implementation the byte size of the pointer may be substantially smaller than that of the data chunk. For example as discussed earlier the data chunk may be 16 or 21 Kbyte in length whereas the pointer may by 64 bytes in length providing a significant savings in the amount of data being transferred to the backup storage system.

In some implementations as previously discussed the deduplication record may include the hash value for the data chunk. The backup data storage system may re use hash values from the source file system and therefore the hash values may be transmitted as a part of the deduplication record.

When the check indicates that the source file is stored without deduplication on the computer device then the source file may be backed up by transferring data chunks of the source file to the backup data storage system and performing deduplication on the data chunks of the source file.

At the process determines a block size value used to restore a backed up file in the deduplicated format. In some implementations the determination step simply involves having a priori knowledge of the block size based on e.g. the operating system or information stored during a backup or copying operation for the file. In some implementations the above described trial and error techniques are used.

At the process transfers for each data chunk of the backed up file if the data chunk was not previously transmitted during the restoration the data chunk to the source file system and updating a deduplication database at the source file system with a pointer a location where the data chunk is transferred to.

At the process updates the deduplication database at the source file system without transferring the data chunk with a deduplication entry when the data chunk was previously transmitted during the restoration. As previously discussed significant savings in the amount of data transferred during backup and restoration can be obtained when a deduplication record is transmitted instead of the data chunk itself.

In some implementations the deduplication database may be updated to indicate that the data chunk being transferred is duplicative. In some implementations the deduplication data base at the source file system may also be updated by saving a pointer value that links a duplicative data chunk to the copy of that data chunk previously transferred to the source file. In some implementations e.g. when the source file system and the backup storage system use the same hash values the deduplication record may include the hash value of the data chunk.

Those of ordinary skill in the relevant art will appreciate from the detailed description above that several techniques are now disclosed for improving efficiency of a backup operation of a source file system that is stored in a de duplicated format such as with newly available operating systems that automatically deduplicate data.

In one advantageous aspect the disclosed techniques can be used to reduce the amount of data that is transferred from the source file system to the backup storage system during a backup operation This is performed by re using information available at the source file system about uniqueness duplicativeness of data chunks making up a file to be transferred. In another advantageous aspect a backup data storage system may also further benefit from re using hash values calculated by the source file system and using the same has values in performing de duplication operation at the backup storage system. Hash values need not be computed again by the backup storage system.

Those of ordinary skill in the relevant art will also appreciate that the disclosed techniques can be used to reduce the amount of data transferred from a backup storage system to a source file system during restoration of backup data. In one advantageous aspect a deduplication database at the source file system may be used so that only unique data chunks i.e. not previously included in the deduplication database of the source file system are transferred. For data chunks that are duplicative a deduplication record may be transferred instead. The deduplication record may indicate a location of a copy of the data chunk that is not transferred existing in the deduplication database at the source file system.

Those of ordinary skill in the relevant art will furthermore appreciate that the disclosed techniques would be useful in backing up and restoring a de duplicated file system by reducing the bandwidth storage and computational resources used by these operations.

The disclosed and other embodiments modules and the functional operations described in this document can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this document and their structural equivalents or in combinations of one or more of them. The disclosed and other embodiments can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more them. The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a standalone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this document can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Computer readable media suitable for storing computer program instructions and data include all forms of nonvolatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in the sense of including but not limited to. As used herein the terms connected coupled or any variant thereof means any connection or coupling either direct or indirect between two or more elements the coupling or connection between the elements can be physical logical or a combination thereof. Additionally the words herein above below and words of similar import when used in this application refer to this application as a whole and not to any particular portions of this application. Where the context permits words in the above Detailed Description using the singular or plural number may also include the plural or singular number respectively. The word or in reference to a list of two or more items covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above Detailed Description of examples of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed above. While specific examples for the invention are described above for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. For example while processes or blocks are presented in a given order alternative implementations may perform routines having steps or employ systems having blocks in a different order and some processes or blocks may be deleted moved added subdivided combined and or modified to provide alternative or subcombinations. Each of these processes or blocks may be implemented in a variety of different ways. Also while processes or blocks are at times shown as being performed in series these processes or blocks may instead be performed or implemented in parallel or may be performed at different times. Further any specific numbers noted herein are only examples alternative implementations may employ differing values or ranges.

The teachings of the invention provided herein can be applied to other systems not necessarily the system described above. The elements and acts of the various examples described above can be combined to provide further implementations of the invention. Some alternative implementations of the invention may include not only additional elements to those implementations noted above but also may include fewer elements.

Any patents and applications and other references noted above including any that may be listed in accompanying filing papers are incorporated herein by reference. Aspects of the invention can be modified if necessary to employ the systems functions and concepts of the various references described above to provide yet further implementations of the invention.

These and other changes can be made to the invention in light of the above Detailed Description. While the above description describes certain examples of the invention and describes the best mode contemplated no matter how detailed the above appears in text the invention can be practiced in many ways. Details of the system may vary considerably in its specific implementation while still being encompassed by the invention disclosed herein. As noted above particular terminology used when describing certain features or aspects of the invention should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics features or aspects of the invention with which that terminology is associated. In general the terms used in the following claims should not be construed to limit the invention to the specific examples disclosed in the specification unless the above Detailed Description section explicitly defines such terms. Accordingly the actual scope of the invention encompasses not only the disclosed examples but also all equivalent ways of practicing or implementing the invention under the claims.

To reduce the number of claims certain aspects of the invention are presented below in certain claim forms but the applicant contemplates the various aspects of the invention in any number of claim forms. For example while only one aspect of the invention is recited as a means plus function claim under 35 U.S.C. 112 sixth paragraph other aspects may likewise be embodied as a means plus function claim or in other forms such as being embodied in a computer readable medium. Any claims intended to be treated under 35 U.S.C. 112 6 will begin with the words means for but use of the term for in any other context is not intended to invoke treatment under 35 U.S.C. 112 6. Accordingly the applicant reserves the right to pursue additional claims after filing this application to pursue such additional claim forms in either this application or in a continuing application.

