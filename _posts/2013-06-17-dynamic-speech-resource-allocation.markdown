---

title: Dynamic speech resource allocation
abstract: A call is received at an interactive voice response (IVR) system. A voice communications session is established between the IVR system and the telephonic device. A request from the IVR system to allocate a speech resource for processing voice data of the voice communications session is received by a dynamic speech allocation (DSA) engine. Configuration data associated with a current state of the voice communications session is accessed by the DSA engine. Dynamic characteristics associated with the caller are accessed by the DSA engine. A speech resource from among multiple speech resources is selected by the DSA engine based on the current state and the dynamic characteristics. The selected speech resource is allocated to the voice communications session by enabling the IVR system to use the selected speech resource to process voice data received from the caller during the current state of the voice communications session.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08699674&OS=08699674&RS=08699674
owner: Angel.com Incorporated
number: 08699674
owner_city: Vienna
owner_country: US
publication_date: 20130617
---
This application claims the benefit of U.S. Provisional Application No. 61 778 880 titled DYNAMIC SPEECH RESOURCE ALLOCATION and filed on Mar. 13 2013 and is a continuation in part of U.S. patent application Ser. No. 13 092 090 titled MULTIMODAL INTERACTIVE VOICE RESPONSE SYSTEM and filed on Apr. 21 2011 now U.S. Pat. No. 8 654 934 which claims the benefit of U.S. Provisional Application No. 61 326 636 titled MULTIMODAL APPLICATION DEVELOPMENT PLATFORM FOR VOICE SOLUTIONS and filed on Apr. 21 2010 and U.S. Provisional Application No. 61 326 616 titled COMMUNICATION OF INFORMATION DURING A CALL and filed on Apr. 21 2010 all of which are incorporated herein by reference in their entirety.

The following disclosure relates generally to speech resource allocation in an interactive voice response system.

In a general aspect a call is received at an interactive voice response IVR system the call being received from a telephonic device of a caller. A voice communications session is established between the IVR system and the telephonic device in response to the call. A request from the IVR system to allocate a speech resource for processing voice data of the voice communications session is received by a dynamic speech allocation DSA engine. Configuration data associated with a current state of the voice communications session is accessed by the DSA engine. One or more dynamic characteristics associated with the caller is accessed by the DSA engine. A speech resource from among multiple speech resources is selected by the DSA engine based on the current state of the voice communications session and the one or more dynamic characteristics. The selected speech resource is allocated to the voice communications session by enabling the IVR system to use the selected speech resource to process voice data received from the caller during the current state of the voice communications session.

The details of one or more implementations are set forth in the accompanying drawings and the description below. Other potential features and advantages will become apparent from the description the drawings and the claims.

A user may use a telephonic device to call a number that connects the user to an interactive voice response system. At a particular state of the voice interaction the interactive voice response system may provide pre recorded audio information to the user and process voice information received from the user. The complexity and cost to process the received voice information as required by the interactive voice response system may vary at different states of the voice interaction and the calling characteristics associated with the user may dynamically change during the voice interaction. It may be useful if the interactive voice response system can determine and allocate optimized resources for processing the received voice information at a particular state of the voice interaction based on the static and dynamic characteristics of the voice interaction.

A user of a particular product or service may need to contact customer service for the product or service for various reasons for example to troubleshoot a problem the user is experiencing in using the product or service. In order to contact the customer service and obtain a solution to the problem the user may call a known customer service number for the product or service using a telephonic device accessible to the user. By calling the customer service number the user may get connected to a call handling system that enables the user to interact with a voice site associated with the product or service.

A voice site is a set of scripts or more generally programming language modules corresponding to one or more linked pages that collectively interoperate to produce an automated interactive experience with a user. A standard voice site includes scripts or programming language modules corresponding to at least one voice page and limits the interaction with the user to an audio communications mode. An enhanced voice site includes scripts or programming language modules corresponding to at least one voice page and at least one multimodal action page linked to the at least one voice page that enable interaction with the user to occur via an audio communications mode and at least one additional communications mode e.g. a text communications mode an image communications mode or a video communications mode . Notably a call may be said to be directed to a voice site if it is directed to a telephone number that has been defined as corresponding to the voice site.

The voice site called by the user may be an automated interactive voice site that is configured to process using pre programmed scripts information received from the user that is input through the telephonic device being used by the user and in response provide information to the user that is conveyed to the user through the telephonic device. For standard voice sites and or standard telephonic devices the interaction between the user and the voice site may be done using an interactive voice response system IVR provided by a service provider that is hosting the voice site. A standard telephonic device in this context is understood to be a telephonic device that is not configured to handle interaction with a voice site that involves video images or rich textual information. The IVR is configured to support voice commands and voice information using text to speech processing and natural language processing by using scripts that are pre programmed for the voice site for example voice extensible markup language VoiceXML scripts. The IVR interacts with the user by prompting with audible commands enabling the user to input information by speaking into the telephonic device or by pressing buttons on the telephonic device if the telephonic device supports dual tone multi frequency DTMF signaling e.g. a touch one phone . The information input by the user is conveyed to the IVR over a voice communications session that is established between the telephonic device and the IVR when the call is connected. Upon receiving the information the IVR processes the information using the pre programmed scripts. The IVR may be configured to send audible responses back to the user via the telephonic device.

In some implementations the voice site may be an enhanced voice site that is configured to support multimedia information including audio video images and text. The telephonic device also may be an advanced telephonic device e.g. a smart phone provided with a display for conveying visual information to the user and a processor capable of performing complex tasks such as logic processing wherein the associated instructions may be stored in memory included in the telephonic device. In such circumstances the advanced telephonic device hereinafter interchangeably referred to as smart phone and the enhanced voice site can interact using one or more of voice video images or text information and commands.

A multimodal IVR MM IVR may be provided by the call handling service hosting the voice site to enable the smart phone and the voice site to communicate using one or more media e.g. voice text or images as needed for comprehensive easily understood communications. In this context multimodal refers to the ability to handle communications involving more than one mode for example audio communications and video communications. In one implementation the MM IVR may be configured to support calls to multiple different voice sites. In another implementation the MM IVR may be dedicated to one voice site and there may be a different MM IVR for each voice site.

The smart phone may be configured to run a multimodal MM application that interacts with the MM IVR that is supporting the voice site. In addition to placing a call to the voice site using a voice communications channel the smart phone may interact with the voice site via the multimodal application using a data communications channel that runs in parallel to the voice communications channel. The audio e.g. voice capture and audio playing is done in the smart phone but more complex and processing intensive tasks such as speech or image recognition and dialog management are executed using the MM IVR at the call handling service. For example the MM IVR may communicate with the user using voice over a voice communications session to get basic instructions and quick feedback the MM IVR also may communicate with the user using text over a parallel data communications session to get an e mail address associated with the user and using images over the data communications session for providing a visual sense to the user of what needs to be done.

Using a multimodal application to interact with an enhanced voice site may be useful in several situations. For example the multimodal application may be used in conjunction with the display of the smart phone to show pictures to the user during troubleshooting a product or service. The multimodal application also may be used in sending long terms and conditions related to the product or service being used by the user. In another usage the multimodal application may be used to capture data that is not easy to capture via speech e.g. the user may take a picture of the product using a camera provided with the smart phone and use the multimodal application to send the picture to the voice site. In yet another usage the multimodal application may be used to show to the user the latest bill associated with the product or service being used by the user.

As mentioned previously the voice site may be hosted by a third party service provider that facilitates the creation and hosting of voice sites on servers owned and operated by the service provider. The service provider provides a service method that enables the design development and hosting of voice applications that run a thin client on the smart phone that interacts with a fully hosted on demand voice solution platform call handling system maintained and managed by the service provider. The service method provides a way to develop a voice site that is supported by an MM IVR system the server side and push an installation of an application the client that would run on the smart phone as well as a protocol for the client and the server to interact with each other. The service method requires the installation of a thin client engine e.g. an application on the smart phone that mediates between the objects and devices in the smart phone and the MM IVR system supporting the voice site hosted on the server.

In the above scenario the role of the entity providing customer service through the voice site is that of a content provider. The customer service department of the entity company hereinafter referred to interchangeably as the content provider configures the voice site that is to be used for the particular product or service and provides the logic for the voice site that is to be executed by the MM IVR system along with the voice video image or textual information that may be exchanged with the user calling the voice site. The content provider may do so by using a graphical user interface provided by the third party service provider for configuring the voice site. The service provider handles the interpretation and compilation of the information provided by the content provider and the creation and hosting of the voice site based on the information.

The service method thus enables the deployment of voice enabled solutions on smart phones without requiring the content provider to engage in complex programming. Applications may be designed by the content provider using a web based interface and served on demand to smart phone clients. Such clients can be add ons that smart phone applications can plug into. In addition the service method enables users to interact with an application in a multimodal manner. The application is referred to as multimodal in that it enables users to interact with the voice solution platform using multiple different communications modes. For example the user may provide information to the voice solution platform by writing or speaking and may receive information from the voice solution platform by hearing or reading. Accordingly in this example four different types of interaction combinations are possible between the user and the voice solution platform 1 speak hear 2 speak read 3 write read and 4 write hear. The same client server engine UI can run all four types of interaction combinations and the same application development tool can be used to build all four types of interaction combinations.

Depending on the voice application each voice site or enhanced voice site may have different data processing requirements that require the voice site to leverage different speech resources such as for example different Automatic Speech Recognition ASR engines different Text to Speech TTS engines and in some instances a noise reduction engine. For instance the data processing requirements for a pizza ordering application may be more complex than the data processing requirements for a customer satisfaction survey application and therefore may require speech resources able to handle a more sophisticated interaction with users. In this example the pizza ordering application may for instance require a more sophisticated ASR engine that is better able to process natural language inputs to properly identify a long order of different pizzas with different toppings spoken by a user. In contrast the customer satisfaction survey application may require a much less sophisticated ASR engine because the application only asks users multiple choice questions that the users respond to by speaking single alphanumeric character answers. Since each ASR engine has an associated cost that generally increases with the sophistication of the engine a content provider having a voice site for a customer satisfaction survey may be ill served by paying the greater costs associated with using a more sophisticated ASR engine when a much less sophisticated and hence less costly engine would have sufficed. In contrast a content provider having a voice site for ordering pizza would not want to try to save costs by using a less sophisticated ASR engine because of its negative impact on the customer s experience when interacting with the voice site e.g. orders would be incorrectly captured by the engine resulting in the customers having to repeat themselves and or incorrect orders being delivered to customers .

As such from a content provider s perspective the determination of a particular speech resource for a particular voice interaction is preferably based on a balance between minimizing the transaction cost to the content provider of using the speech resource and optimizing the user s experience when interacting with the voice site by ensuring that the speech resource is up to the task of supporting a smooth interaction with the user. From a service provider s perspective the selection of particular speech resources is preferably transparent to the content provider to allow the service provider to have the flexibility of upgrading removing or replacing certain speech resources without affecting the design or operation of existing voice sites.

A dynamic speech resource allocation system like that described in more detail below may determine the data processing needs for a given voice application and may automatically select the best speech resource able to satisfy those needs e.g. the lowest cost speech resource able to handle those data processing needs without compromising the user experience . In doing so the system may be able to increase the quality of a user s experience with a voice site by selecting the specific speech resources that are best able to improve the user s experience in view of the context of a particular voice interaction with the user. Moreover the system may be able to decrease the speech resource costs associated with a voice site without decreasing the quality of the user interactions with the voice sites by avoiding wasteful use of sophisticated and hence expensive speech resources for voice interactions that can be similarly handled by using less sophisticated and hence less expensive speech resources.

Referring to a user of an intelligent mobile telephone i.e. a smart phone is able to interact with the smart phone to invoke a multimodal application on the phone to request a service from a voice site that is provided for example by a customer service department . The service may be for example a request to purchase a particular product or service offered by or made available by the customer service department through the voice site. For example the user may indicate a desire to request a service from the voice site by selecting a graphically displayed icon on a graphical user interface GUI of the intelligent mobile telephone to thereby invoke a multimodal application stored in the intelligent mobile telephone with which the user can interact to initiate a service request. Additionally or alternatively the user may indicate a desire to request a service by simply inputting via manual selection or otherwise a telephone number associated with the customer service department into the intelligent mobile telephone and initiating a call directed to the inputted telephone number. The call handling system receives the call and then interacts with the smart phone to launch the multimodal application. In some implementations the intelligent mobile telephone may include a data store that stores data indicating which inputted telephone numbers correspond to conventional phone calls e.g. via VoIP or via TDM and which inputted telephone numbers correspond to multimodal smart phone applications that will be launched by the smart phone upon entry of the corresponding number. In some implementations each of the multimodal telephone numbers has its own multimodal application associated with it. In other implementations all multimodal telephone numbers are associated with the same multimodal application such that the same multimodal application is launched upon entry of any of the multimodal telephone numbers.

The multimodal application s stored on the intelligent mobile telephone may be a thin client capable of interacting with a full hosted on demand voice solution platform. The voice solution platform may include a call handling system an application server and a data store communicatively coupled to each other as shown in . The call handling system may include an IVR system configured to receive a call from the intelligent mobile telephone when the intelligent mobile telephone is operating under the control of the thin client. In some implementations the call handling system may additionally include a call center .

In some implementations the thin client may be a conventional smart phone application that includes an add on or plug in that provides multimodal functionality to a conventional smart phone application. The thin client and or the add on or plug in may be downloaded from a host server by the intelligent mobile telephone .

Upon the user invoking the multimodal application or subsequent to the user invoking the multimodal application and then requesting submission of the service request through interactions with the multimodal application a data communications session is setup between the intelligent mobile telephone and the application server in response to the service request . The data communications session may be setup for example by the intelligent mobile telephone under the direction of the multimodal application constructing or accessing a URL for the application server and using an application programming interface API and the URL to communicate with the application server over the data network .

The intelligent mobile telephone also may setup a parallel voice communications session with the IVR or more generally with the call handling system . The voice communications session may be setup for example by the intelligent mobile telephone under the direction of the multimodal application accessing a telephone number corresponding to the IVR and placing a call via for example TDM or VoIP over the telephone network using the accessed telephone number. The accessed telephone number may be a number inputted by the user when invoking the application or alternatively may be a telephone number previously stored in connection with the multimodal application e.g. a pre stored 1 800 number associated with the particular service requested by the user . The voice communications session also may be setup with the IVR by the intelligent mobile telephone simply calling the IVR using the native telephony service of the intelligent mobile telephone and then the multimodal application being launched through subsequent interactions with the IVR . The data communications session and the voice communications session overlap in time such that the smart phone is able to communicate with the IVR and the application server in parallel.

The application server may allocate a shared memory space in a data store to store state data reflecting the interaction with the user during the two parallel communications sessions . In some implementations the IVR rather than the application server allocates the shared memory space in the data store . The application server and the IVR are able to read data from and or write data to the shared memory space . For example the application server may inform the IVR of the location of the shared memory space and may setup access rights with the data store to ensure that the application server and the IVR are each able to read data from and or write data to the shared memory space in real time during the communications sessions.

The user is able to interact with the voice solution platform by exchanging voice communications with the IVR and exchanging data communications with the application server in real time during the overlapping communications sessions . In particular the user is able to receive information from the IVR by hearing information spoken by the IVR to the user and is able to provide information to the IVR by speaking information into the phone .

The traditional processing functions of the IVR may be distributed between the IVR and the multimodal application to decrease the complexity of the multimodal aspect of the application. Specifically the audio capture and audio playing may be performed by the multimodal application on the intelligent mobile telephone . However expensive and complex tasks such as for example speech recognition and dialog management may be performed by the IVR . This separation of functions allows the multimodal aspect of the application to be relatively thin i.e. require minimal processing and or memory resources when stored and executed and not involve complex programming by the developer of the application. Instead the complex IVR related programming tasks are pushed to the IVR . In some implementations a content provider application developer can design a multimodal add on for an existing conventional i.e. non multimodal smart phone application and the voice application programming for the IVR using a single web based voice solution application development interface. The add on can then be downloaded by the intelligent mobile telephone from a data store across the data network and plugged into the conventional smart phone application to convert the conventional smart phone application into a multimodal application.

The user is also able to provide data e.g. text data video data and or audio data to the application server and receive data e.g. text data video data and or audio data from the application server over the data network during the data communications session by interacting with the intelligent mobile telephone . While the IVR and the application server interact with the user the IVR and the application server may read and write data in real time into the allocated shared memory such that for example the IVR and the application server may be concurrently aware of the state of the interaction with the user of the intelligent mobile telephone . In some implementations the IVR and or the application server may directly access the shared memory to monitor the information stored in the shared memory for the current interaction with the user such that changes in state variables and or addition of new state variables are automatically detected by the IVR or the application server . In other implementations the IVR may send a signal to the application server over the data network informing the application server when a state variable has been changed in or new data has been added to the shared memory by the IVR . Similarly the application server may send a signal to the IVR over the data network informing the IVR when a state variable has been changed in or new data has been added to the shared memory over the data network .

Use of the shared memory may allow the voice solution platform to intelligently select which communications mode is preferable for receiving or providing information to a user of the intelligent mobile telephone during the interaction with the user i.e. during the overlapping communications sessions with the user via the intelligent mobile telephone . For example an IVR is effective in delivering data serially and relatively quickly as audio. The IVR is also effective in gathering data from the user that is amenable to being structured as a multiple choice question e.g. a yes no question to which the user may provide a short response by depressing buttons corresponding to the choices on the phone or by speaking short phrases that do not require too much natural language processing or interpretation. The IVR however may not be effective in receiving data that involves longer and or more elaborate responses that are difficult to decipher such as for example full name and physical address capture and e mail address capture.

In contrast the application server is effective in delivering different pieces complex data to the user that require more time for the user to digest than that provided by serial audio presentation of the data or that are simply not amenable to translation into audio. Such data may be for example a detailed multi field form or a page having multiple distinct textual video and or image data items e.g. a voice page or a web page . The application server is effective in capturing complex data from the user such as for example free form writing or writing corresponding to a full name a physical address and or an e mail address of the user.

In the context of this discussion a page is a discrete programming routine configured to perform a discrete function. A page may be defined by a user through an interaction with for example a GUI in which the user may indicate the type of programming routine for the page and may optionally further indicate one or more other pages linked to the page. Processing may then proceed to the one or more other linked pages after completion of execution of the page or alternatively after initiation of execution of the page but before completion of execution of the page. A page may be compiled into one or more programming language modules or scripts after the page is defined by the user through interaction with the GUI. The one or more programming language modules or scripts may be used for example by an IVR and or an application server to execute the discrete programming routine to thereby perform the discrete function of the page. A voice page is a particular type of page that is configured to perform the function of delivering and or receiving audible content to a user. The user is typically a caller to an IVR and the audible content is typically speech. illustrate examples of one or more pages provided by a GUI of an application development tool.

Accordingly in some implementations the multimodal application i.e. the client application on the smart phone and the corresponding applications executed by the IVR and the application server i.e. the server applications may be designed to intelligently choose among different communications modes when working together to gather data from or provide data to the user of the intelligent mobile telephone . For example if the data to be gathered can be obtained through the answer of a yes no question then the applications may request the data from the user via prompting the user to speak a yes no answer into the smart phone that is received and interpreted by the IVR . In contrast if the data to be gathered is more complex such as an e mail address of the user the applications may request that the user input the data as for example text that is received and interpreted by the application server . As stated previously in some implementations applications can be developed that communicate data between the user and the voice solution platform using any of the four different types of interaction combinations noted previously. Some or all of the data that is gathered from the user and in some implementations some or all of the data that is communicated to the user during the communications sessions may be stored in the shared memory in real time such that both the application server and the IVR may access the data in real time during the sessions. This data along with other state variable data may be used to ensure for example that the processing of the application server and the processing of the IVR are synchronized to provide a cohesive multimodal interaction with the user of the intelligent mobile telephone .

In some implementations for some or all requests for information from the user made by the voice solution platform during the communications sessions the user may be prompted by the IVR e.g. through a voice prompt and or by the application server e.g. through a textual prompt displayed on a display of the intelligent mobile telephone to choose a mode for providing the requested information to the voice solution platform . For example the user may be prompted to choose whether to provide the requested information to the voice solution platform by speaking the information into the intelligent mobile telephone to be received and interpreted by the IVR or alternatively by providing the information as data e.g. text data to the application server via selection or input of the data through interactions with the intelligent mobile telephone . Depending on the selection made by the user the information may either be collected by the IVR or by the application server . Some or all of the information that is collected may be stored in the shared memory to allow both the IVR and the application server to access or otherwise be aware of the collected data for subsequent processing during or subsequent to the communications sessions. In one implementation example the user may be prompted by the IVR through execution of scripts corresponding to a question page to select a communication mode for providing the requested data. Depending on the user s selection the processing may subsequently branch to scripts corresponding to one or more multimodal action pages to enable the user to provide the requested data as text data video data or image data. Question voice pages and multimodal action pages are described later in reference to . A multimodal action page as mentioned in this discussion is a page configured to perform an action that enables multimodal communications with a user.

In some implementations for some or all pieces of information provided to the user by the voice solution platform the user may be prompted by the IVR e.g. through a voice prompt and or by the application server e.g. through a textual prompt displayed on a display of the intelligent mobile telephone to choose a mode for receiving the information from the voice solution platform . For example the user may be prompted to choose whether to receive the information from the voice solution platform through the IVR speaking the information to the user or alternatively through the application server communicating the information as for example text to be displayed on a display of the intelligent mobile telephone to the user. Depending on the selection made by the user the information may either be provided by the IVR or by the application server . Some or all of the information that is provided may be stored in the shared memory to allow both the IVR and the application server to access or otherwise be aware of the collected data for subsequent processing during or subsequent to the communications sessions. In one implementation example the user may be prompted by the IVR through execution of scripts corresponding to a question page to select a communication mode for receiving data. Depending on the user s selection the processing may subsequently branch to scripts corresponding to one or more multimodal action pages to provide data to the user as text data video data or image data. Question voice pages and multimodal action pages are described later in reference to .

Typically the division of processing functions between the intelligent mobile telephone and the voice solution platform results in the multimodal application directing the intelligent mobile telephone to communicate with the application server and the IVR to mediate between objects and devices on or accessible to the intelligent mobile telephone and the corresponding voice application executed by the IVR . The objects may be internal objects stored within the intelligent mobile telephone e.g. songs contact and applications or may be external objects e.g. information about shipments order status etc. accessed by the intelligent mobile telephone from external sources e.g. from the application server or elsewhere across the data network . The above described techniques may provide a way to develop applications on a server side of the offering i.e. on the voice solution platform side and then push an install of a thin client to be run on the intelligent mobile telephone that includes among other things a protocol for the intelligent mobile telephone and the voice solution platform to interact with each other.

The intelligent mobile telephone is configured to place and receive calls across the telephone network and to establish data communications sessions with servers such as the application server across the data network for transmitting and receiving data. The intelligent mobile telephone may be a cellular phone or a mobile personal digital assistant PDA with embedded cellular phone technology. The intelligent mobile telephone may be a computer that includes one or more software or hardware applications for performing communications between the intelligent mobile telephone and servers across the data network . The intelligent mobile telephone may have various input output devices with which a user may interact to provide and receive audio text video and other forms of data. For example the intelligent mobile telephone may include a screen on which may be displayed form data and with which the user may interact using a pointer mechanism to provide input to single field or multi field forms.

The telephone network may include a circuit switched voice network a packet switched data network or any other network able to carry voice data. For example circuit switched voice networks may include a Public Switched Telephone Network PSTN and packet switched data networks may include networks based on the Internet protocol IP or asynchronous transfer mode ATM and may support voice using for example Voice over IP Voice over ATM or other comparable protocols used for voice data communications.

The data network is configured to enable direct or indirect communications between the intelligent mobile telephone the application server and the call handling system or the IVR . Examples of the network include the Internet Wide Area Networks WANs Local Area Networks LANs analog or digital wired and wireless telephone networks e.g. Public Switched Telephone Network PSTN Integrated Services Digital Network ISDN and Digital Subscriber Line xDSL radio television cable satellite and or any other delivery or tunneling mechanism for carrying data.

In some implementations the data network and the telephone network are implemented by a single or otherwise integrated communications network configured to enable voice communications between the intelligent mobile telephone and the call handling system or the IVR and to enable communications between the intelligent mobile telephone the application server and the call handling system .

The application server is configured to establish a data communications session with the intelligent mobile telephone and to receive and send data to the intelligent mobile telephone across the data network . The application server also is configured to communicate with the call handling system to send data received from the intelligent mobile telephone to the IVR . The application server also may send other application related data that did not originate from the intelligent mobile telephone to the IVR or more generally to the call handling system . The application server also is configured to communicate with the data store to read and or write user interaction data e.g. state variables for a data communications session in a shared memory space as described previously. The application server may be one or more computer systems that operate separately or in concert under the direction of one or more software programs to perform the above noted functions. In some implementations the application server and the call handling system are a single integrated computer system.

The IVR may include a voice gateway coupled to a voice application system via a data network. Alternatively the voice gateway may be local to the voice application system and connected directly to the voice application system. The voice gateway is a gateway that receives user calls from or places calls to voice communications devices such as the intelligent mobile telephone and responds to the calls in accordance with a voice program. The voice program may be accessed from local memory within the voice gateway or from the application system. In some implementations the voice gateway processes voice programs that are script based voice applications. The voice program therefore may be a script written in a scripting language such as for example voice extensible markup language VoiceXML or speech application language tags SALT . The voice application system includes a voice application server and all computer systems that interface and provide data to the voice application server. The voice application system sends voice application programs or scripts to the voice gateway for processing and receives in return user responses. The user responses are analyzed by the voice application system and new programs or scripts that correspond to the user responses may then be sent to the voice gateway for processing. The voice application system may determine which programs or scripts to provide to the voice gateway based on some or all of the information received from the intelligent mobile telephone via the application server . The IVR also is configured to communicate with the data store to read and or write user interaction data e.g. state variables for a data communications session in a shared memory space as described previously.

The call center of the call handling system may include among other components an inbound call queue an outbound call request queue a call router an automatic call distributor ACD administrator and a plurality of call center agents. The call center may receive one or more calls from one or more voice communication devices such as the intelligent mobile telephone via the telephone network and may make one or more outbound calls to voice communication devices via the telephone network . The call center may determine an appropriate call center agent to route the call to or to assign an outbound call to. The determination of an appropriate agent may be based on agent performance metrics and information known about the inbound or outbound call. The determination of the appropriate agent may for example be based on some or all of the form information and or other optional information received from the intelligent mobile telephone .

Additionally the user also may select to have some or all of the information outputted to the user by the voice solution platform spoken to the user rather than displayed graphically on the interface of the intelligent mobile telephone by selecting the headphones output graphical button . The user may select to mute the sound played by the intelligent mobile telephone by selecting the mute graphical button and may select to pause any sound or speech provided by the intelligent mobile telephone by selecting the pause button . Selection of the buttons and may for example result in the smart phone communicating corresponding signals to the application server that in turn communicates with the IVR to cause the IVR to branch to multimodal action pages or to message pages as needed to provide information to the user via speech or via text or image or video respectively. Message voice pages and multimodal action pages are described later in reference to .

The communications system includes a content provider that accesses a call handling system through a data network to create update a voice site belonging to the content provider that is hosted by the call handling system . The call handling system is capable of hosting multiple voice sites that are created by multiple different content providers. In an alternative implementation the call handling system may host only a single voice site for one content provider. The data network is analogous to and is a particular example of the data network of communications system while the call handling system is similar to and is a particular example of the call handling system of communications system .

The communications system includes a smartphone that is used by a user to interact with the voice site of the content provider using an MM IVR that is included in the call handling system . The call handling system communicates with an application server component that is used for processing graphical and textual information with the smart phone . The MM IVR interacts with the applications server to support multimodal interaction between a smartphone and a voice site. The MM IVR or the application server or a combination of the two may be configured to support multimodal interactions in multiple parallel communications sessions from multiple different users who call multiple different voice sites hosted by the call handling system .

The communications between the smart phone and the call handling system is over the voice network while the communications between the smart phone and the application server is over the data network . The smart phone is analogous to and is a particular example of the intelligent mobile telephone of communications system . The MM IVR is analogous to and is a particular example of the IVR system of communications system . The voice network is analogous to and is a particular example of the telephone network of communications system . The communications system also includes a push notification service for interfacing between the smart phone and the application server .

The content provider may be a company that is interested in providing a call based customer service to users of its product or service. For example the content provider may be an Internet service provider ISP interested in providing technical support to its customers using a voice site. Alternatively the content provider may be a cable company or a satellite company that is interested in providing technical support for its modems to its customers using a voice site.

The content provider may utilize the services of a voice site hosting service that provides the call handling system to create and configure a voice site that is hosted on servers belonging to the voice site hosting service. The voice site hosting service may provide a content provider web interface as part of the call handling system to enable the content provider to easily create and configure a voice site that will be accessed by customers for technical support.

The content provider web interface is a web based GUI front end for an application development tool that can be used to build an enhanced voice site that is capable of multimodal interaction with a caller. The content provider may access the content provider web interface over the data network e.g. using a web browser that runs on a computer with Internet connectivity used by the content provider. The data network may be a publicly available network that is capable of multimedia data communications including images text video and voice e.g. the Internet. In an alternative implementation the data network may be a public network different from the Internet or a private network or a combination of public and private networks.

By accessing the application development tool using the content provider web interface the content provider may create different types of pages that will be used by the MM IVR system when processing a call to the voice site being created by the content provider . The types of pages that may be created by the content provider using the application development tool may include for example 1 a message page 2 a question page 3 a logic page 4 a transaction page and 5 a multimodal action page. In addition the types of pages that may be created by the content provider using the application development tool may include for example an address capture page a call queue page a call transfer page a data page a name capture page a reverse phone lookup page a schedule page and a voicemail page. illustrate an example of an application development tool having a content provider web interface and a voice site that is created using the application development tool with the voice site including different types of pages.

The pages created by the content provider using the content provider web interface are interpreted and or compiled by a content compiler included in the call handling system to generate scripts that are executed by the MM IVR as the MM IVR interacts with a caller calling the voice site created by the content provider . For example the content compiler may generate VoiceXML scripts for message pages question pages and logic pages that are created for the voice site by the content provider . The VoiceXML scripts may be executed by the MM IVR as the MM IVR interacts over the voice network with a caller to the voice site.

The VoiceXML scripts generated by the content compiler are stored in a data store in the call handling system . The MM IVR may access the scripts from the data store and process them when the MM IVR interacts using voice interactions with a caller to the voice site created by the content provider .

In addition to the VoiceXML scripts the content compiler may also generate other types of scripts e.g. Java scripts and other types of executable code using other programming languages based on transaction pages and multimodal action pages that may be created for the voice site by the content provider . The other types of scripts may be used by the application server to interact over the data network with the caller to the voice site. In response to or based on instructions received from the MM IVR the application server may execute the other types of scripts e.g. Java scripts and generate appropriate multimodal instructions that are communicated to the smart phone over the data network for multimodal action pages . Additionally or alternatively the application server may execute the other types of scripts e.g. Java scripts and generate a transaction that processes data which may then be stored in a variable for subsequent access by the MM IVR for transaction pages . Execution of a part of the scripts e.g. Java scripts by the application server may result in information being communicated back to the MM IVR indicating that the processing corresponding to the page i.e. the multimodal action page or the transaction page is completed. The application server also is configured to communicate with the call handling system i.e. the MM IVR and or the call center to send form data and other data received from the smart phone to the call handling system .

The scripts used by the application server are stored in a data store that is accessible by the application server. For example the data store may be a high capacity hard drive that is resident on the same device hosting the application server or the data store may be an array of high capacity storage drives that are closely coupled to the application server . In an alternative implementation the scripts used by the MM IVR and the scripts used by the application server are stored in a single data store e.g. the data store that is located within the call handling system .

The smart phone may be an intelligent telephonic device including a display or screen for providing visual information to the user of the smart phone a processor with sufficient processing power to execute instructions sent by the application server and sufficient memory to store data including text images video and audio files. For example the smart phone may be an iPhone or an Android enabled smart phone. The display or screen of the smart phone may be used to displayed text images video or form data and the user of the smart phone may interact with the display using a pointer mechanism to provide input to single field or multi field forms. The smart phone includes one or more software programs called applications also referred to as clients that are used to perform various functions. The smart phone includes a native telephony application that is used by the user of the smart phone to place a call by dialing a number of the called party. For example when the user of the smart phone wants to call the voice site created by the content provider the user may launch the native telephony application by for example clicking on an icon on the display of the smartphone that represents the native telephony application . The native telephony application when launched may provide the user with an alphanumeric keypad to enable the user to dial the number corresponding to the voice site. The call placed from the native telephony application to the voice site is communicated to the call handling system over the voice network . The voice network may include a circuit switched voice network a packet switched data network or any other network able to carry voice data. For example circuit switched voice networks may include a Public Switched Telephone Network PSTN and packet switched data networks may include networks based on the Internet protocol IP or asynchronous transfer mode ATM and may support voice using for example Voice over IP Voice over ATM or other comparable protocols used for voice data communications.

The smart phone may also include a notification application or service that is used for generating pop up notifications on the smart phone display based on instructions and or data received from servers communicating with applications on the smart phone . For example when the application server communicates instructions and or data to the smart phone as part of the multimodal interaction between the user and the voice site the instructions and or data may trigger the notification application to generate a pop up on the smart phone display asking the user permission to launch the multimodal application that is configured to handle the instructions and or data communicated by the application server . In an alternative implementation the notification application may be used to interface all instructions and data from servers communicating with applications on the smart phone . All data communications to the smart phone may be received by the notification application and then transferred to the corresponding applications to which the data communications are directed.

The smart phone also includes a multimodal application that is used by the user to interact with the voice site in a multimodal manner. As described with respect to the application is referred to as multimodal in that it enables users to interact with the voice site using multiple different communications modes. For example the user may provide information to the voice site by writing or speaking and may receive information from the voice site by hearing or reading.

The multimodal application is a thin client capable of interacting with the MM IVR . In some implementations the thin client is a conventional smart phone application that includes an add on or plug in that provides multimodal functionality to a conventional smartphone application. The thin client and or the add on or plug in may be generated by the call handling system when the content provider creates the voice site using the content provider web interface and the content compiler . The thin client and or the add on or plug in may be downloaded by the smart phone from a server hosted by the call handling system .

In one implementation each voice site may have a dedicated multimodal application that is used exclusively to allow a user to interact with the voice site. Therefore the smartphone may have more than one multimodal application installed on the smart phone one for each enhanced voice site that is accessed by the user of the smart phone . In another implementation a single multimodal application may be configured to allow a user to interact with multiple voice sites. In this case the smartphone may have one multimodal application installed on the smart phone and the content that is provided to the user using the multimodal application may be different for different voice sites accessed by the user.

The user of the smart phone may invoke the multimodal application stored in the smart phone by selecting a graphically displayed icon on the display of the smart phone . When the multimodal application is launched on the smart phone a data communications session is established between the multimodal application and the application server . The interaction between the user and the voice site occurs simultaneously using the data communications session for exchange of text images and or video between the multimodal application and the application server and using a voice communications session that is established between the native telephony application and the MM IVR for exchange of voice information. As described previously illustrate an example of a GUI for a multimodal application running on a smart phone that may be used for interaction between the smart phone and an enhanced voice site. illustrate another example of a GUI for a multimodal application running on a smart phone that may be used for interaction between the smart phone and another enhanced voice site.

The system includes a push notification service that interfaces between applications running on the smart phone and application servers that interact with the applications running on the smart phone . The push notification service may be provided by an entity that is independent of either the content provider or the voice site hosting service that provides the call handling system . The push notification service may be provided by the manufacturer of the smart phone e.g. the Orange push notification service where Orange is the name of the manufacturer of the smart phone . All communications from the application server to the multimodal application is sent to the push notification service over the data network . The push notification service then pushes the communications to the smart phone where the communications is received by the notification application and or the multimodal application . If a communication is received by the notification application and the multimodal application is not running the notification application may generate a pop up notification that is displayed to the user on the display of the smart phone . The pop up notification may ask the user for permission to launch the multimodal application . If the user agrees the user may select an affirmative button icon provided on the pop up notification. This will send a trigger to the smart phone logic to launch the multimodal application without requiring the user to select a GUI icon for the multimodal application on the display of the smart phone .

In an alternative implementation the push notification service may not be present and all communications from the application server to the multimodal application is sent directly to the smart phone over the data network.

The application server may be a server computer with high processing capabilities that is owned and operated by the voice site hosting service providing the call handling system . Alternatively the application server may represent a host of server devices having lower processing capabilities that are placed on racks that are tightly integrated with one another with various tasks being distributed between the different servers depending on the load on the servers at the time of the task distribution. The application server may be co located with the call handling system such that the MM IVR and the application server are able to share the same resources e.g. memory and or processor capacity. Alternatively the application server may be located in a location that is different from the location of the call handling system with a dedicated high speed and high bandwidth network connection coupling the application server to the call handling system .

In an alternative implementation the application server may represent a server farm that is owned and operated by an independent provider different from the content provider or the voice site hosting service providing the call handling system . For example the application server may be Amazon.com s Elastic Compute Cloud Amazon EC2 service that provides resizable compute capacity in the cloud i.e. the Internet . The voice site hosting service providing the call handling system may lease computing capacity and or storage on the application server cloud for executing and storing scripts that enable the multimodal interaction between the smart phone and the enhanced voice site created by the content provider .

The call handling system facilitates the creation and hosting of voice sites. The voice sites are both standard voice sites without multimodal features and enhanced voice sites incorporating multimodal features. The call handling system utilizes various components to enable the creation and hosting of voice sites. The various components of the call handling system may be co located in a single physical location or they may be geographically distributed with dedicated high capacity links interconnecting the various components.

The call handling system includes a registration module that handles the registration of content provider of different voice sites. The registration module enables the content provider to contact the call handling system and establish an account for billing and personalization purposes. To pre register the content provider may input name address contact information payment mechanism information preferences demographic information language etc. Other types of information requested during registration may be input and stored as well. The call handling system may assign the content provider with a registration number that may be used to access pages for the voice site using the content provider web interface . Further the content provider may personalize how services are to be billed may input payment information for use in transaction processing and may select personalization features for delivery of voice content including specification of information for use by voice personalization module . In one implementation the registration module may provide a web subscription interface to enable potential subscribers to connect over the World Wide Web in order to sign up for the voice site hosting services.

The call handling system includes a call reception module for receiving calls from users who are calling various voice sites hosted by the call handling system . For example when the user of the smart phone calls the voice site created by the content provider the call is received at the call reception module . The call reception module also delivers voice content to the smart phone . The call handling system may be configured such that a call to a voice site hosted by the call handling system is received at the call reception i.e. the call reception may act as a proxy for the calling numbers of all the voice sites hosted by the call handling system .

The call handling system includes a page execution module for executing the contents of pages corresponding to the voice site that is called. Execution of the content may include playing the content scanning the page for certain tags or markers to include other page information generate call menus and other tasks. Page execution module may coordinate with a page menu module that is provided within the call handling system . Page menu module presents receives and interprets menu options presented in a page. Page menu module may comprise a VoiceXML interpretation module that utilizes VoiceXML or other voice based XML file formats as the pages to understand the menus that are to be presented to the user to enable the user to maneuver within the MM IVR . Page menu module may also comprise a VoiceXML interpretation module a Nuance Grammar or Speech Works specification language module or a Java Speech grammar format module. Page menu module may interpret predefined menu options and determine which of the options to execute based on choices selected by the user from a choice interpretation module as described below.

The call handling system also includes a multimedia generator module for outputting voice signals to the smart phone over the voice communications session and for outputting text images and video to the smart phone over the data communications session using the application server . The multimedia generator module may play voice files may comprise a text to voice conversion module for reading text files as voice output or any other type of module for taking a data file and generating voice output to be directed by the call reception to the user of the smart phone .

A voice personalization module may be provided optionally that enables the user of the smart phone to select personalized features for the voice content of the voice site created by the content provider . Personalization features may include tone pitch language speed gender volume accent and other voice options that a user may desire to make the information more understandable or desirable. Voice personalization module modifies how multimedia generator module generates voice content to correspond to the smart phone user s desired choices. The voice personalization features may be set by the user of the smart phone upon subscribing and automatically applied when that user logs into the system. Personalization module retrieves information from subscriber database once the user is connected to the voice site and has provided his registration subscription. In doing so the user does not need to specify additional information at any point during the session. If the user is filling out a form or running a transaction his pre fetched information is placed where necessary. Personalization module also may present the user with a portal page allowing the user quick access to the content they frequently access. If the pages store user specific information then personalization module may retrieve that information. Personalization module may also allow users to modify speech output settings as described above.

Some of the multimedia e.g. text images to video to display to the user of the smart phone that is used by the voice site is generated by the application server . The page execution module executes a VoiceXML script that is retrieved from the data store using the page retrieval module and based on the execution of the VoiceXML script the page execution module sends a communication to the application server to instruct the application server to 1 execute its own script e.g. Java script to generate an appropriate multimodal instruction and communicate the multimodal instruction to the smart phone over the data network for a multimodal action page or 2 execute its own script e.g. Java script to execute a transaction that processes data which may then be stored in a variable for subsequent access by the MM IVR for a transaction page . Execution of part of the scripts e.g. Java scripts by the application server may result in communication of a signal back to the page execution module indicating that the processing corresponding to the page i.e. the multimodal action page or the transaction page is done. The page execution module may then commence the processing of the next page. In another implementation the page execution module immediately or at a predetermined time later automatically begins processing the next page without waiting to receive a communication from the application server that the execution of the multimodal action page or the transaction page is completed.

The call handling system also may include a choice interpretation module that may be used to interpret responses from the user of the smart phone such as those based on menu options. Choice interpretation module cooperates with page menu module and call reception to enable call handling system to respond to user requests based on menu options presented within a page. For example if the menu provided by the page includes five options choice interpretation module may determine which of the five options to execute based on the input received through call reception from the user. If the user presses the number on the smart phone then choice interpretation module generates a signal that indicates to page menu module to execute choice 1. Choice interpretation module may comprise a more complicated system as well. Various call menu technologies generally are known and can be used. The user may also be able to respond with voice based choices. Choice interpretation module then uses voice to text conversion natural language interpretation and or artificial intelligence to determine which of the available menu options the user desires. Other systems for interpreting and executing user menu choices may also be used for choice interpretation module .

The call handling system additionally may include a transaction processing module for processing transactions presented in a page. Transactions may include purchase of goods request for services making or changing reservations requesting information and any other type of transaction that may be performed by the smart phone or other information exchange system. The transaction processing module may be used to process transactions that occur based on voice information received by the call reception from the user of smart phone . Other types of transactions that include text images or video information are processed using the application server as described previously.

The call handling system also may include a billing module for monitoring the smart phone user s access to various pages and enabling the call handling system to allocate fees received from the user to content providers transaction processors and others. Billing module may be used to record the time the user logs into the voice site to record times when users access new pages to record when users perform transactions and other types of information that may be used for determining how to allocate fees received from the user for accessing the voice site.

Billing module may compute time spent and pages accessed on the voice site for each page. In one implementation the billing module receives a credit value for the page as specified by the content provider and calculates the charges on a minute basis throughout the call session. This information may be stored in a user statistics database and or the data store and or the data store . For each call billing module may track time of day day of week call duration call origin pages visited etc. For each page it may track hit frequency revenue generated demographics etc. It may also track the advertisements presented transactions performed and other information.

In some implementations the call handling system may optionally include a call center . The call center is analogous to and is a particular example of the call center of communications system . The call center of the call handling system may include among other components an inbound call queue an outbound call request queue a call router an automatic call distributor ACD administrator and a plurality of call center agents. The call center may receive one or more calls from one or more telephonic devices such as the smart phone that are routed to the call center by the MM IVR for example through the execution of scripts corresponding to a call transfer page. In addition the call center may make one or more outbound calls to telephonic devices via the voice network . The call center may determine an appropriate call center agent to route the call to or to assign an outbound call to. The determination of an appropriate agent may be based on agent performance metrics and information known about the inbound or outbound call. The determination of the appropriate agent may for example be based on some or all of the form information and or other optional information received from the smart phone .

When the user of smart phone calls the voice site and launches the multimodal application on the smart phone to interact with the voice site the MM IVR executes a script based on the information included in the multimodal setup page and instructs the application server to send a signal to the smart phone that provides an indication of all the files that are necessary for the multimodal application to interact with the voice site. The files that are necessary may be for example the files that are specified by the content provider on the multimodal setup page . Upon receiving the signal from the MM IVR application server the multimodal application checks in the local memory of the smart phone to see whether the necessary files as indicated by the signal from the MM IVR are present on the smart phone . If the multimodal application determines that one or more of the necessary files are not present then the multimodal application sends a message to the application server including information on the necessary files that are not locally present on the smart phone . Upon receiving the message from the multimodal application with the information on the files that are not present locally on the smart phone the application server pushes the missing files to the smart phone . The order in which the files are downloaded may be for example from top to bottom as specified on the site multimodal setup page . Therefore the top to bottom order may match the order in which the files will be used by the voice site during the multimodal interaction.

The variable that is used to store the caller id that is required to identify the smart phone from which the call is made also may be stored on the site multimodal setup page . The variable may be selected from a list of variables previously specified by the content provider by clicking on the Select a Variable drop down menu button.

The commands that are to be processed by the MM IVR system when the page is executed are shown in the body of the page under the heading Site Commands. Site Commands refer to actions that the user may perform e.g. by saying the command on the phone or pressing a button on the dial pad of the native telephony application or by pressing a button displayed by the multimodal application on the display of the smart phone to come to that particular page in the voice site. The site commands may be available on all the pages or on a subset of the pages included in the voice site.

Since page is a message page when the page is executed the MM IVR system prompts the user with a voice message that is specified using the Initial Prompts field . The content provider may define the voice message by typing in text in the text input field . When the page is executed the MM IVR system prompts the user with a voice message corresponding to the text that is entered by the content provider . For example the user of the smart phone may hear the voice site say Hi. Welcome to Cable Wireless Inc. s modem troubleshooting hotline. 

The above example is a text to speech type of prompt. A text to speech type of prompt with a text input field is presented by default when a message page is created. The content provider may delete the default text to speech type prompt and create a different type of prompt. The default text to speech type prompt may be deleted by checking the radio button next to the text input field and then selecting the Delete button. Alternatively the content provider may specify one or more other prompts in the message page . Prompts may be added by the content provider by selecting a button icon corresponding to the type of prompt to be added specified to the right of the Add Prompt . The two other types of prompts are audio and variable. When the content provider selects to add an audio prompt the content provider is able to specify a pre recorded audio file that is stored in the call handling system for example in the data store . When the page is executed the MM IVR system locates and plays the audio file specified by the audio prompt using its in built audio player such that the user of the smart phone hears the recording associated with the audio file. When the content provider selects to add a variable prompt the content provider is able to specify a pre determined variable that is specified by the content provider for the voice site. When the page is executed the MM IVR system locates the variable specified by the variable prompt and plays the data associated with the variable to the user of the smart phone using text to speech conversion. For example if the content provider selects a variable that has the number associated with it the MM IVR will play audio information to the user using the native telephony application that the user will hear as saying Five. 

In addition to the prompts the content provider may specify action commands on the message page . The actions that are possible are specified by the drop down menu list corresponding to the actions . For example the content provider may select the action Go to Designated Page and specify the page that is executed in the sequence after the current page. Once the message page is created and or updated the content provider saves the message page by selecting the Save button. The message page is subsequently stored by the call handling system for example in the data store . Alternatively the content provider may elect to discard the additions changes that have been made by selecting the Cancel button in which case the additions changes are not saved by the call handling system .

The multimodal action page is a page type that enables multimodal interaction when included in a voice site. The type of multimodal interaction is controlled by the Action dropdown menu . In one example implementation three broad categories of multimodal interaction are offered through selection of corresponding options in the dropdown menu

As described previously the multimodal action page is executed by the application server . When the MM IVR processes the multimodal action page it sends an instruction to the application server to execute the multimodal action page . The commands that are processed by the application server when the page is executed are shown in the body of the page under the heading Site Commands. Based on the action defined in the page by the content provider when the application server executes a script corresponding to page it generates an appropriate multimodal instruction that includes an action parameter and optionally a value parameter and communicates the multimodal instruction to the smart phone over the data communications session. The action specified on the multimodal action page is Show Keyboard and corresponds for example to the action parameter ShowKeyboard. Therefore the multimodal instruction communicated to the smart phone instructs the multimodal application to show the keyboard. Accordingly the multimodal application displays a keyboard to the user on the display of the smart phone along with a text input field to enter text using the displayed keyboard.

After sending the instruction to the application server the MM IVR processes the next action specified in the multimodal action page which instructs the MM IVR to go to the page numbered and with page name Ask for Email Address. Once the multimodal action page is created and or updated the content provider saves the multimodal action page by selecting the Save button. The multimodal action page is subsequently stored by the call handling system for example in the data store and or the data store . Alternatively the content provider may elect to discard the additions changes that have been made by selecting the Cancel button in which case the additions changes are not saved by the call handling system .

In addition to the prompt the content provider specifies a Listen for Page Commands action command on the message page . The Listen for Page Commands action command instructs the MM IVR to receive page commands from the user of the smart phone and process the received page command based on the definition of the page commands that are specified on the voice page . The content provider may specify one five or ten page commands by selecting one of the three buttons associated with the Add Page Commands . The page command specified by the content provider on the message page instructs the MM IVR to wait for the user to either say continue on the speaker of the smart phone or press 1 on the dial pad of the smart phone and then process the page numbered and with page name Retrieve Email Address From Phone . When the MM IVR receives a transmission from the smart phone that is processed as indicating that the user has said continue on the speaker of the smart phone and or pressed 1 on the dial pad of the smart phone the MM IVR retrieves and processes the page which is shown in .

The multimodal action page is executed by the application server . When the MM IVR processes the multimodal action page it sends an instruction to the application server to execute the multimodal action page . The action specified on the multimodal action page is GetText . Therefore the multimodal instruction generated by the application server and communicated to the smart phone over the data communications session may include for example the action parameter GetText and may instruct the multimodal application to send to the application server a text string that is entered by the user of the smart phone . The text string is entered by the user of the smart phone by typing using the keyboard in the text input field that are displayed to the user by the multimodal application on the display of the smart phone based on the instructions associated with the multimodal action page . The multimodal application captures the text string entered by the user and communicates the text string to the application server over the data communications session. The text string is saved by the application server in the variable identified by Variable To Store Text . For example the text string may be saved in the variable user email that was previously defined by the content provider . In the example shown in the text string saved in the variable user email corresponds to an email address of the user of the smart phone . The email address may be used by the call handling system to identify and locate a subscription account for associated with the user for the voice site created by content provider .

After sending the instruction to the application server the MM IVR processes the next action specified in the multimodal action page which instructs the MM IVR to process the page numbered and with page name Obtain Cable Modem Type. 

Based on the information contained in the transaction page the application server invokes a script to perform certain actions that are defined in the script. The name and location of the script are specified by the URL . The URL may specify a World Wide Web WWW address indicating that the script is accessible over the Internet. Alternatively the URL may be the address of a local file. The hypertext transfer protocol HTTP commands POST or GET are selected by the content provider to indicate whether the script specified by the URL will return a value to the application server . When the application server invokes the script specified by the URL the application server may pass one or more parameters to the script as input parameters that are needed for execution of the script. The input parameters are specified by the content provider under the Parameters heading in the page . The content provider may specify a variable or a constant parameter by selecting the Add Parameter . In the example shown in the parameter specified by the content provider is a variable with the name user email specified under Parameter Name with the value of the variable being represented by the string user email specified under Parameter Value. The variable user email corresponds to the variable that was obtained by the application server from the multimodal application by executing a script corresponding to multimodal action page .

The script specified by the URL performs certain actions using the variable user email and returns a value to the application server . The response received from the script specified by the URL is interpreted by the application server based on the instructions specified by the content provider in . The response may be interpreted as a VoiceXML script e.g. AngelXML script which is a version of a VoiceXML script . The VoiceXML script also may specify the next page e.g. Page as illustrated by that is to be executed in the execution order of the pages of the voice site. In an alternative implementation the response may be interpreted for example as text to speech.

In the example illustrated by the script specified by the URL identifies the subscriber account corresponding to the user of the smart phone for the product service that is provided by the voice site which is a wireless cable modem product. The script uses the email address provided by the user which is stored in the user email variable to identify the subscriber account. Based on identifying the subscriber account the script retrieves information related to the particular model of cable modem that is used by the user of the smart phone and returns a value to the application server indicating the particular model of the cable modem. The returned value is used by the application server to populate a variable modem type as shown with respect to .

The MM IVR executes a script corresponding to the operation rules that are specified in the logic page . The logic page specifies a logic statement that is based on the value of the variable modem type . The variable modem type is populated by the value that is returned by the script executed by the application server that is specified by the URL in the transaction page . The If statement is a condition logic block that tests the value of the variable modem type and if the value equals D Link DSL then the MM IVR executes the block and branches to the page numbered with page name Push Image of D Link DSL Modem. On the other hand if the value of the variable modem type does not equal D Link DSL then the MM IVR executes the block and branches to the page numbered with page name Push Image of D Link DCM Modem. 

The content provider may specify one or more operation rules or logic commands in the logic page by selecting one of the three buttons Condition Assignment and Transformation . The If statement described above is an example of a Condition logic operation. An Assignment logic operation is one in which a value gets assigned to a variable. A Transformation logic operation is one in which a variable gets transformed from one value to another e.g. when the value of a variable is updated based on the value of another variable.

After sending the instruction to the application server the MM IVR processes the next action specified in the multimodal action page which instructs the MM IVR to process the page numbered and with page name Instruction. 

In addition to the prompt the content provider specifies a Listen for Site Page Commands action command on the message page . The Listen for Site Page Commands action command instructs the MM IVR to receive page commands from the user of the smart phone and process the received page commands based on the definition of the page commands that are specified on the voice page . The page command specified by the content provider on the message page instructs the MM IVR to wait for the user to either say I am done or I m done on the speaker of the smart phone or press 1 on the dial pad of the smart phone and then process the page numbered and with page name Goodbye . When the MM IVR receives a transmission from the smart phone that is processed as indicating that the user has said either say I am done or I m done on the speaker of the smart phone and or pressed 1 on the dial pad of the smart phone the MM IVR retrieves and processes the page which is shown in .

In addition to the prompt the content provider specifies the action on the message page . The content provider may select the action End the Call. Therefore when the MM IVR executes a script corresponding to the page the MM IVR terminates the call that is placed by the user of the smart phone when the action is executed. When the call is terminated the MM IVR terminates the voice communications session that was established with the smart phone . In addition the MM IVR sends an instruction to the application server based on which the application server terminates the data communications session that was established with the multimodal application .

The user also may be provided with the option to save the splash image in the local storage of the smart phone by clicking on the Save Image button . If the user saves the splash image in the local storage of the smart phone by clicking on the Save Image button then for future launches of the multimodal application the splash image may be retrieved by the multimodal application from the local storage of the smart phone thereby obviating the need for the application server to push the splash image to the multimodal application . Since the native telephony application is running in the background while the multimodal application is displayed on the display of the smart phone the user may switch to the native telephony application by touching the strip near the top of the display above the splash image . This minimizes the GUI of the multimodal application and returns the GUI of the native telephony application to the foreground of the display of the smart phone .

The native telephony application is runs in the background at all times while the multimodal application is displayed on the display of the smart phone so that the user remains connected to the MM IVR over the voice communications session. From any multimodal application GUI the user may switch to the native telephony application by touching the strip e.g. near the top of the multimodal application GUI display. This minimizes the GUI e.g. of the multimodal application and returns the GUI of the native telephony application to the foreground of the display of the smart phone .

The user also may be provided with the option to save the splash image in the local storage of the smart phone by clicking on the Save Image button . If the user saves the splash image in the local storage of the smart phone by clicking on the Save Image button then for future launches of the multimodal application the splash image may be retrieved by the multimodal application from the local storage of the smart phone thereby obviating the need for the application server to push the splash image to the multimodal application .

The smart phone places a call to a voice site in response to a user request . The voice site is created by the content provider using the content provider web interface provided by the call handling system . The user of the smart phone may place the call to receive customer service from the voice site. For example the content provider may be a cable company e.g. Cable Wireless Corp. that is described with reference to and the voice site may provide technical support to subscribers product users of the cable company. The user of the smart phone may be using a wireless cable modem provided by the cable company and therefore calls the voice site to troubleshoot an issue that user is experiencing with the wireless cable modem.

When the call is connected the voice site may audibly greet the user by playing a prompt that is heard by the user through the speakers of the smart phone . During the user s interaction with the enhanced voice site the smart phone also may receive a data message from the voice site . The data message may be sent by the MM IVR and or the application server as a result of execution of scripts associated with the voice site while the user is interacting with the voice site. If the user has not registered for multimodal interaction with the call handling system the data message may be for example a text message e.g. a Short Message Service SMS message that is received using a text messaging application on the smart phone . Along with receiving the data message the user may hear audible information from the voice site that informs the user that the user is going to receive the text message that will include a link selectable to allow the user to register for multimodal interaction with the call handling system . The link may be for example a hyperlink selectable to access a network location from which the user can download and install the multimodal application associated with the voice site.

If the data message is a text message having a link selectable to register for multimodal interaction with the call handling system or in some implementations with only a particular voice site the user may select the link to download and install the multimodal MM application by for example using a graphical pointer or other selection mechanism supported by the smart phone to click or otherwise select the link provided in the text message . The user may opt not to select the link to install the MM application in which event the call with the voice site continues as an interactive voice only call . In an alternative implementation if the user opts not to install the MM application the call with the voice site is terminated by the voice site.

If the user selects the link to install the application the smart phone automatically downloads and installs the MM application . In an alternative implementation clicking on the link provided in the text message takes the user to a network location where the user has to perform further actions to download and install the MM application. The smart phone may have multiple MM applications installed where each of the multiple MM applications is used for multimodal interaction with a different voice site. In an alternative implementation the smart phone may have a single MM application installed where the single MM application is configured to handle multimodal interactions for multiple voice sites.

Once the MM application is installed on the smart phone an icon may be provided on the display of the smart phone associated with the MM application. The smart phone may launch the MM application in response to the user clicking on the icon associated with the MM application that is provided on the display of the MM application. The MM application may be for example the multimodal application . Alternatively immediately after the MM application is installed the smart phone may automatically launch the MM application to enable the user to register for multimodal interaction. Once the MM application is launched the MM application may automatically send registration information to the voice site . The registration information may be sent to the application server via the data network that forwards the registration information to the MM IVR that is executing instructions associated with the voice site. In an alternative implementation the registration information may be sent via the data network to the push notification service that stores the registration information locally. In addition or as an alternative to storing the registration information locally the push notification service may forward the registration information to the application server and or the MM IVR . In another alternative implementation the registration information may be sent automatically to the call handling system via the voice network the registration information may be received by the user registration module and or the call center module .

In yet another alternative implementation once the MM application is launched the user enters the caller id on a form that is displayed on the display of the smart phone using the MM application. The MM application communicates with the push notification service to obtain a unique token from the push notification service that identifies the smart phone . The caller id entered by the user on the form and the unique token obtained from the push notification service are sent by the MM application to the application server to register the smart phone .

The sending of the registration information to the voice site may be done only once at the time when the MM application is installed and launched for the first time. It may not be required to send the registration information for subsequent calls to the voice site and or for subsequent uses of the MM application. In an alternative implementation it may be required to send the registration information every time a call is established with the voice site.

After the registration information has been sent and processed by the MM IVR and or the application server the smart phone may receive additional data messages from the voice site . The smart phone processes the data messages using the MM application the text application and or other applications on the smart phone . For example the MM application may prompt the user of the smart phone to send additional identifying information. This may happen after the MM application has displayed a greeting page and or the MM IVR has sent audible greeting information associated with the voice site e.g. as described with reference to and then the MM application displays a keyboard and text input field on the display of the smart phone e.g. as described with reference to . In addition as described with reference to the MM IVR may audibly prompt the user to enter an email address associated with the user in the text input field that is displayed by the MM application. The email address may be used for example to locate a subscriber account for the user that is associated with the voice site. Information on the subscriber account may be stored by the call handling system and may be accessible to the MM IVR and or the application server . The information entered by the user in the text input field is communicated by the MM application to the application server which forwards the information to the MM IVRF for processing for example as described with reference to the transaction page illustrated in .

If the data message is not a text message having a link for installing the MM application and is not an MM instruction message for processing by the MM application the message may be processed in accordance with a corresponding other application to communicate its contents to the user . For example the message may be a second text message e.g. SMS message that provides other information to the user e.g. an address of interest to the user that may be processed by the text messaging application on the smart phone to enable the user to access the contents of the message.

On the other hand if the message is a MM instruction message for processing by the MM application then the smart phone may determine whether the received MM instruction message is the first MM instruction message that has been received by the smart phone for the MM application for the current call. If the smart phone determines that the received message is the not first MM instruction message that has been received for the current call then the MM application is known to be currently running and consequently the smart phone forwards the received message to the MM application. The message is then processed as an MM instruction by the MM application for example as described with reference to .

If the smart phone determines that the received message is the first MM instruction message that has been received for the MM application for the current call the smart phone checks whether the MM application is running . If the MM application is running the smart phone forwards the received message to the MM application. The message is then processed as an MM instruction by the MM application for example as described with reference to .

If the MM application is not running the smart phone may display a notification pop up on the display of the smart phone asking the user to launch the MM application e.g. as shown in the GUI in . When the user receives the pop up notification on the display of the smart phone the user has to decide whether to accept the MM message i.e. whether to launch the MM application to accept the MM message. The user may decide not to launch the MM application for example by clicking the Cancel button on the pop up notification that is displayed on the display of the smart phone as shown in the GUI of . Then the call that the user has placed to the voice site continues as an interactive voice only call . In an alternative implementation if the user opts not to launch the MM application the call with the voice site is terminated by the voice site.

Alternatively the user may decide to launch the MM application for example by clicking the View button on the pop up notification that is displayed on the display of the smart phone as shown in the GUI of . Once the MM application is launched the received message is processed as an MM instruction by the MM application for example as described with reference to .

The call handling system may receive a call from a user telephone device that initiates a voice communications session between the call handling system and the user telephone device. The call may be placed by the user of the smart phone to a number associated with the voice site created by the content provider . The call is received by the call handling system because the call handling system hosts the voice site created by the content provider . The call may be received by the call reception that is part of the MM IVR in the call handling system .

Upon receiving the call from the user telephone device the call handling system identifies the voice site that the user is trying to reach based on the called number . As described with reference to every voice site hosted by the call handling system may have one or more phone numbers uniquely associated with the voice site. Therefore the call handling system may analyze the received transmission of information from the user telephone device and determine the called number that the user telephone device is attempting to reach. Based on analyzing the called number the call handling system may be able to identify the particular voice site that the user is trying to connect to e.g. the voice site created by the content provider .

Once the voice site is identified the call handling system determines whether the voice site is an enhanced voice site . As described previously an enhanced voice site is a voice site that is configured for multimodal interaction with callers to the voice site. The call handling system may make the determination based on information that is stored at the call handling system associated with the voice site. For example when a content provider creates a voice site based on the information provided by the content provider and or the types of pages created by the content provider the call handling system may tag the created voice site as either a standard voice site or an enhanced voice site.

If the call handling system determines that the voice site is a standard voice site then the call handling system enables the interactive voice response IVR system to receive information from provide information to the user via standard voice communications . The IVR may be for example the MM IVR but handling standard calls without multimodal interaction. In an alternative implementation the IVR handling standard calls via standard voice communications may be different than the MM IVR that is configured to handle calls to enhanced voice sites including multimodal interaction. In the discussion going forward the IVR and the MM IVR will be taken to refer to the same entity and therefore the terms may be used interchangeably. Upon being enabled by the call handling system the IVR retrieves the pages associated with the called voice site for example by using the page retrieval module and executes VoiceXML scripts corresponding to the called voice site for example by using the page execution module as standard voice pages.

On the other hand if the call handling system determines that the called voice site is an enhanced voice site e.g. the voice site described by created by the content provider then the call handling system determines whether the calling telephone device is a smart phone . This determination may be made for example by data sent with the transmission of information when the call from the telephone device is received by the call handling device . The data may for example uniquely identify the phone. Using the phone identification the call handling system may look up in a database that provides information on whether the telephone is a standard telephonic device or a smart phone. The database may be part of the call handling system or it may be an external database provided by an independent entity different from the call handling system and accessed by the call handling system . In an alternative implementation the data sent with the transmission of information when the call from the telephone device is received by the call handling device may contain information sufficient to determine whether the telephone is a standard telephonic device or a smart phone.

If the call handling system determines that the telephone is a standard telephonic device then the call handling system enables the interactive voice response IVR system to receive information from provide information to the user via standard voice communications as described previously. The IVR retrieves the pages associated with the called voice site and executes for example VoiceXML scripts corresponding to the called voice site as standard voice pages. The called voice site may be an enhanced voice site but it may be configured to interact with a standard telephonic device using standard voice pages. For example the enhanced voice site may include scripts corresponding to a subset of standard voice pages e.g. message pages and question pages that are processed during the caller s interaction with the voice site instead of the scripts corresponding to the multimodal action pages in response to the call handling system determining that the telephone is a standard telephonic device rather than a smart phone. In this manner the same enhanced voice site is able to provide service to both standard telephonic devices and smart phones.

On the other hand if the call handling system determines that the telephone is a smart phone then the call handling system proceeds to check whether the smart phone is registered i.e. whether the smart phone has previously downloaded installed and launched the MM application that is associated with the called voice site. The call handling system may determine the registration status of the smart phone by performing a lookup of the information processed by the user registration module . In addition or as an alternative to performing the lookup of the information processed by the user registration module the call handling system may obtain the registration information of the smart phone from the application server and or the push notification service .

If the call handling system determines that the smart phone is registered then the call handling system configures the system for multimodal communications between the MM application and the enhanced voice site that is being called as is described below.

If the call handling system determines that the smart phone is not registered then the call handling system asks the user using the IVR via voice communications to register . For example the MM IVR may send an audible message to the smart phone over the established voice communications session that asks the user of the smart phone whether the user wants to download and install the MM application that will allow the user to engage with the voice site through multimodal interaction.

Upon receiving the message sent by the IVR asking the user to register the user of the smart phone sends back a response. The user may send a back a voice response saying Yes or No or the user may press a button on the smart phone dial pad to indicate the response for example by pressing 1 for Yes and 2 for No. Based on receiving the response from the user the IVR analyzes the received response and determines whether the user wants to register . The IVR may determine that the user does not want to register for example if the received transmission indicates that the user has either said No or pressed the 2 button on the dial pad of the smart phone. If the IVR determines that the user does not want to register then IVR is enabled to receive information from provide information to the user via standard voice communications as described previously. The IVR retrieves the pages associated with the called voice site and executes VoiceXML scripts corresponding to the called voice site as standard voice pages. The called voice site may be an enhanced voice site but it may be configured to interact with a standard telephonic device using standard voice pages.

Alternatively the IVR may determine that the user wants to register for example if the received transmission indicates that the user has either said Yes or pressed the 1 button on the dial pad of the smart phone. The IVR then sends a text message to the smart phone with a link to download and install the MM application . In addition to sending the text message the IVR may send a voice transmission to the smart phone that informs the user via audible information that the user is going to receive the text message that will contain a link to a network location from where the user can download and install the MM application associated with the voice site the user has called.

After the user downloads and installs the MM application associated with the voice site the user launches the MM application. When the MM application e.g. multimodal application is launched a data communications session may be established between the MM application running on the smart phone and the application server over the data network .

The MM application when launched for the first time may automatically communicate with the push notification service to obtain a unique token from the push notification service that identifies the smart phone . The MM application also may display a form on the display of the smart phone and prompt the user to enter the caller id associated with the smart phone on the form that is displayed using the MM application. The caller id entered by the user on the form and the unique token obtained from the push notification service are sent by the MM application to the application server to register the smart phone . The application server may store the registration information for the smart phone in the application server e.g. in the data store . In addition or as an alternative to the application server storing the registration information the application server may send the registration information to the MM IVR which forwards the information to the user registration module so that the smart phone is registered with the MM IVR as using the MM application associated with the voice site being called.

In an alternative implementation the MM application when launched for the first time may automatically send information to the application server that uniquely identifies the smart phone and or the MM application associated with the voice site that is being called. The application server may create a registration token for the smart phone and store it in the application server e.g. in the data store . In another alternative implementation the MM application may automatically send information to the push notification service that uniquely identifies the smart phone and or the MM application associated with the voice site that is being called. The push notification service may create a registration token for the smart phone and store it locally. In addition or as an alternative to storing it locally the push notification service may forward the registration token to the application server which in turn may forward the token to the MM IVR .

Once the data communications session is established between the MM application running on the smart phone and the application server the call handling system configures the system for multimodal communications between the MM application and the enhanced voice site that is being called. As described previously with reference to the call handling system allocates shared memory for interaction with the smart phone and enables the application server and the MM IVR to read from write to the shared memory . Use of the shared memory ensures that both the MM IVR and the application server have a consistent view of the multimodal session that is ongoing between the smart phone and the enhanced voice site.

Once the call handling system is configured to facilitate the multimodal interaction between the smart phone and the enhanced voice site the MM IVR instructs the application server to send MM instructions from the application server to the MM application running on the smart phone and to listen for page commands . For example the application server may push the welcome splash image to the multimodal application running on the smart phone that is described with reference to .

The application server and or the MM IVR also may receive identifying information associated with the user account from the MM application running on the smart phone. For example as described with reference to the user of the smart phone may type in an email address associated with the subscription account maintained by the user with the Cable Wireless Corp. whose customer service voice site is called by the multimodal application . In an alternative implementation such identifying information is not required and therefore the application server and or the MM IVR does receive identifying information associated with the user account from the MM application.

Subsequently the enhanced voice site may interact with the smart phone using the application server and the IVR . The MM IVR retrieves the pages associated with the voice site for example by using the page retrieval module and executes scripts based on processing voice pages and logic pages and interacts with the user of the smart phone using audio voice information through the native telephony application on the smart phone as described previously with reference to . Based on instructions received from the MM IVR application server executes multimodal action pages and transaction pages and exchanges text images and or video with the smart phone using the MM application running on the smart phone.

When the call handling system receives a signal from the smart phone the call handling system checks if the signal is to terminate the call . If the signal is meant for other data transmission for example further multimodal interaction then the call handling system determines that the call is not to be terminated and therefore continues interaction with the smart phone using the application server and the MM IVR .

However the signal from the smart phone may indicate that the call is to be terminated for example when the smart phone closes the native telephony application and or closes the MM application. If the call handling system determines that the call is to be terminated then the call handling system sends instructions to the application server to terminate the data communications session and sends instructions to the IVR to terminate the voice communications session . Based on the instructions received form the call handling system the data communications session between the MM application and the applications server is closed and or the voice communications session between the native telephony application on the smart phone and the MM IVR is closed. In an alternative implementation the data and voice communications sessions are automatically terminated when the user of the smart phone terminates the call e.g. by hanging up and therefore the call handling system does not have to send additional instructions to the application server or the MM IVR .

The user of the smart phone is able to interact with the phone to indicate a desire to request a service from a service provider . The service provider in this context is different from the provider of the voice site hosting service that provides the call handling system . The service provider may be for example a company that has created a voice site using the call handling system that is hosted by the call handling system . The user may indicate a desire to request a service from the service provider by selecting a graphically displayed icon on a graphical user interface GUI of the smart phone to thereby invoke an MM application stored in the smart phone with which the user can interact to initiate a service request. The service may be for example a request to purchase a particular product or service offered by or made available through the service provider.

In response to the indication the smart phone through execution of the MM application visually presents to the user a single field or a multi field form to fill out . A single field form is a form that includes a single data field in which the user is prompted to provide data i.e. a field in the form that the user is instructed to fill in or otherwise complete by providing input . A multi field form is a form that includes multiple such data fields A form may be for example a textual form having one or more blank spaces indicative of the data fields that are available to be filled in with data provided by the user of the smart phone . The user is able to fill out the form by providing text audio image and or video input into the smart phone and initiate the submission of a service request by the smart phone to an application server across a data network . For example after providing the form data the user may initiate submission of the service request by depressing a button on the smart phone or by selecting a graphical element displayed by the GUI of the MM application on the smart phone .

A data communications session is setup between the smart phone and the application server in response to the service request and at least some of the form information provided by the user is communicated to the application server during the data communications session . Optionally the smart phone under the direction of the MM application may provide additional caller information that is stored locally on the smart phone but that is not otherwise specifically provided by the user in connection with the specific service request to be submitted by the smart phone . Such additional information may include for example a phone number of the smart phone a profile of the user that includes the interests and or demographics of the user calendar information of the user address book information of the user information about the applications resident on the smart phone and an identification number or model number of the smart phone. A user of the smart phone may for example have previously set privacy preferences stored on the smart phone indicating that such information may be accessed by some or all of the applications on the smart phone for processing service requests or for other purposes.

The application server provides a phone number of the smart phone to a call handling system . The call handling system may include an MM IVR and or a call center . The call handling system requests that the call center and or the MM IVR initiates an outbound call to the phone number to provide service to the user of the smart phone . In other implementations the application server provides a phone number of another phone designated by or for the user as the phone over which the user desires to receive service. The other phone number may for example be provided by the user as input into one of the multiple fields of the form and communicated to the application server as part of the form information provided by the smart phone . The application server may for example provide the phone number of the smart phone or other phone number to the call center or MM IVR over the data network .

The call center or MM IVR initiates an outbound call to the phone number of the smart phone or other designated phone number across a voice network and upon the user answering the call a voice communications session is setup between the call center or MM IVR and the smart phone . In some implementations the application server provides the form information and optionally the other caller information received from the smart phone to the call center or MM IVR prior to the outbound call being made to enable identification of the right skilled agent or the correct IVR script or voice site to be used for the outbound call that best serves the user s service needs. If the user does not answer the call the call center or the MM IVR communicates this to the application server and in some implementations the application server may terminate the data communications session with the smart phone .

The application server enables the MM IVR or call center to access at least some of the form information and optionally other caller information received from the smart phone prior to upon or subsequent to the user answering the call . For example if the outbound call is made by an agent at the call center at least some of the form information and or optional other caller information may be provided to the agent as a screen pop prior to upon or subsequent to the user answering the outbound call. The form information and optional other caller information may enable the agent to better serve the user s needs by providing context information for the phone call service request. The application server may for example provide the form information and or other optional caller information to the call center or MM IVR over the data network .

If the MM IVR or the call center is very busy the outbound call request may be placed in a queue until a telephone line of the MM IVR or an appropriate agent at the call center becomes available. In some implementations the call center or MM IVR may provide the application server information indicating that the outbound call request has been placed in a queue and may additionally provide an estimate of the wait time before the outbound call will be made. The application server may communicate this information to the smart phone which under the direction of the MM application may display the information to the user during the previously established data communications session. The smart phone under the direction of the MM application may prompt the user to indicate whether he or she wishes to wait to receive the outbound call. If the user indicates that he or she does not wish to wait for the outbound call the smart phone may communicate this to the application server and the application server may request that the MM IVR or call center remove the outbound call request from the queue. In some implementations the application server also may terminate the data session with the smart phone in response to the user indicating that he or she does not wish to wait to receive service via the outbound call.

In some implementations upon a voice communications session being setup between the user of the smart phone and the MM IVR or call center the application server may terminate the data communications session with the smart phone . In other implementations the data communications session between the application server and the smart phone may persist simultaneously with the voice communications session between the smart phone and the MM IVR or call center .

In implementations in which the data communications session and the voice communications session concurrently persist the user may be presented with additional single field or multi field forms to be filled out by the user via the smart phone in real time while the user interacts with the MM IVR or the agent at the call center . The delivery of the additional forms may be triggered by the MM IVR or by the agent at the call center based on interactions with the user during the voice communications session. For example the MM IVR may process scripts for a voice site that includes a multimodal action page having a PushForm action parameter with a value parameter that indicates a name for a file that stores the form to be pushed to the smart phone . As the user interacts with the scripts corresponding to the various pages of the voice site including for example voice message pages and voice question pages the user interaction may lead to the MM IVR processing a multimodal action page that sends an MM instruction to the MM application that includes the action parameter PushForm and the value parameter Form AB corresponding to a file that stores a form having the name AB. In some implementations the MM IVR may use multiple multimodal action pages to push a form to a user and to then receive corresponding form information from the user.

Upon the delivery of an additional form being triggered by the MM IVR or by the call center agent a signal is communicated from the MM IVR or call center to the application server over for example the data network . In response to the signal the application server may communicate an MM instruction to enable the smart phone to access and download the appropriate single field or multi field form over for example the data network during the data communications session. The smart phone may then present the appropriate form to the user for entry of additional form information. After entry of the additional form information by the user the smart phone may provide all or some of the additional form information to the application server that in turn may provide to or otherwise enable access to the additional form information to the MM IVR or the call center or agent in real time during the call. In this manner the user is able to provide information to the MM IVR or the agent at the call center both via speaking to the MM IVR or to the agent and by providing form input e.g. text audio image and video input through interactions with the smart phone in real time during the call with the MM IVR or the agent.

While the above described processes and systems involve an MM IVR or a call center making an outbound call to the recipient other implementations may differ. For example in some implementations rather than the MM IVR or call center placing an outbound call the smart phone under the direction of the MM application instead initiates a call to the MM IVR or to the call center prior to concurrently with or subsequent to establishing the data communications session with the application server and submitting the form information to the application server . In these implementations the application server may provide the MM IVR or the call center with the form information during the voice communications session setup between the smart phone and the MM IVR or the call center . For example the application server may provide the form information upon receiving a signal from the MM IVR or from the call center requesting the information or additionally or alternatively upon being requested to do so by the smart phone . If the MM IVR or the call center is busy the call placed by the user may be placed in the inbound call queue and the MM IVR or the call center may provide an estimated wait time to the user of the smart phone directly or via the application server as discussed previously. As before the user of the smart phone can then choose to wait or not wait to be connected to an agent of the call center or to the MM IVR .

The above described techniques for enabling a user to push information to a call center and or to an IVR may offer various benefits. In particular if the user of the smart phone is interacting with an IVR the described techniques may allow the number of data gathering operations that are needed in the IVR to be streamlined to only include those that are best suited for voice interaction e.g. voice biometrics yes no questions . Any data that is ill suited to being gathered through voice interaction can be provided to the IVR via the user of the smart phone filling out form information that is then communicated to the IVR via the application server in real time. Additionally in this manner the IVR may be able to receive input that today is impossible to receive e.g. e mail addresses or input that requires interactions that challenge Voice User Interface VUI usability e.g. full name capture and address capture .

If the user of the smart phone is interacting with an agent at a call center the above described techniques also may offer various benefits. Specifically and as stated previously the outbound call made to the smart phone may be made by the right skilled agent e.g. the agent that speaks the language of the user of the smart phone or that is knowledgeable about the product or service type being requested by the user of the smart phone or in other implementations the call made by the smart phone to the call center can be routed to the right skilled agent. Moreover as described above the call center can provide more contextualized handling of the calls by providing the agent with some or all of the collected form information or other information received from the smart phone upon the agent receiving or making the call. The form information or other information can specify the nature of the call and or personal information such as name e mail address of the caller call recipient.

While the above described processes and systems involve an MM IVR or a call center other implementations may differ. For example in some implementations the user of the smart phone fills out a single field or a multi field form prior to initiating a call with a call recipient that is neither an IVR nor an agent at a call center but rather is simply a user of another smart phone. The application server provides the form information to the smart phone of the call recipient by establishing a data communications session with the smart phone of the call recipient. The information may be provided prior to upon or subsequent to a voice communications session being established between the two smart phones. As before the application server may or may not terminate the data communications sessions with the smart phones upon the voice communications session being established between the two smart phones. If the application server does not terminate the data communications sessions the application server may again enable the users of the smart phones to fill in and provide to each other form data in real time while the users remain conversing with each other in the voice communications session.

As mentioned previously a voice site may be hosted by a third party service provider that facilitates the creation and hosting of voice sites on servers owned and operated by the service provider. The service provider may provide a service method that enables the design development and hosting of voice applications that run a thin client on the intelligent mobile telephone that interacts with a fully hosted on demand voice solution platform call handling system maintained and managed by the service provider. A content provider may use the service to design voice applications such as for example a voice application that provides customer service for a particular product or service e.g. technical support service and or sales service to enable the customer to purchase the product or service . The content provider configures the voice site that is to be used for the particular product or service and provides the logic for the voice site that is to be executed by the IVR system. A voice interaction is an interaction flow between the user of the intelligent mobile telephone and the voice site using voice as the communication means. For an enhanced voice site the voice interaction may be supplemented by communications other than voice that occur in parallel or sequentially with the voice communications as noted previously. Notably system may be used to provide optimized dynamic speech resource allocation for both voice sites and enhanced voice sites. The term voice site as used in the following description should be understood to cover both enhanced and non enhanced voice sites.

Depending on the voice application each voice site may have different static data processing requirements. Here data may be audio video text or any other information being exchanged between the IVR system and the user. For example the data processing requirements for a pizza ordering application may be more complex than the data processing requirements for a customer satisfaction surveying application because of the greater need for more sophisticated natural language processing in the former than the latter. As another example the data processing requirements within a flow of a voice application may change at different states of the flow. For example at the topping ordering state of the pizza ordering application a robust but more expensive ASR engine may be required to process the spoken input from the user. However at the payment state of the same pizza ordering application a more cost effective ASR engine that is optimized to take credit card numbers may be sufficient to process the spoken input from the user. Moreover there may be additional dynamic data processing requirements raised during a voice interaction due to changes in the calling environment. For example the IVR system may detect that the ambient noise level around the caller has changed during the voice interaction. To satisfy the static and dynamic data processing requirements the service provider may have access to various types of speech resources that can be customized to enable the IVR system to optimally process data received from the user.

A speech resource may be developed by the service provider or may be purchased by the service provider from an external resource provider. Speech resources may include ASR engines TTS engines and a noise reduction engine. Each speech resource may have its associated functionalities properties and cost. For example an ASR engine may be optimized to process natural language or to process simple grammar e.g. numbers where the cost associated with an ASR that is optimized to process natural language may be higher due to processing complexity.

As noted previously from a content provider s perspective the determination of a particular speech resource for a particular voice interaction is preferably based on a balance between minimizing the transaction cost to the content provider and optimizing the user s experience with the voice interaction. From a service provider s perspective the selection of particular speech resources preferably occurs without that selection being visible or readily visible to the content provider to thereby enable the service provider to upgrade remove or replace certain speech resources without negatively impacting the operation of voice sites previously designed and setup for content providers. Accordingly a communications system that can integrate the service provider s available speech resources and identify from among the available speech resources those speech resources that are optimal for a voice interaction based on its static and or dynamic data processing requirements may enable a content provider and or service provider to enjoy a decrease in costs associated with their corresponding voice site without compromising the quality of the user experience with the voice site.

The communications system is an example implementation of a system that supports optimized dynamic speech resource allocation for voice interactions. The communications system includes an intelligent mobile telephone a telephone network a data network an application server a call handling system a data store and a voice site builder . The telephone the telephone network the data network the application server the call handling system and the data store are implementation examples of the telephone the telephone network the data network the application server the call handling system and the data store of respectively.

In general the intelligent mobile telephone is configured to place and receive calls across the telephone network and to establish data communications sessions with servers such as the application server across the data network for transmitting and receiving data. The intelligent mobile telephone may be a cellular phone or a mobile personal digital assistant PDA with embedded cellular phone technology. The intelligent mobile telephone may be a computer that includes one or more software or hardware applications for performing communications between the intelligent mobile telephone and servers across the data network . The intelligent mobile telephone may have various input output devices with which a user may interact to provide and receive audio text video and other forms of data. For example the intelligent mobile telephone may include a screen on which may be displayed form data and with which the user may interact using a pointer mechanism to provide input to single field or multi field forms.

The telephone network may include a circuit switched voice network a packet switched data network or any other network able to carry voice data. The data network is configured to enable direct or indirect communications between the intelligent mobile telephone the application server and the call handling system . In some implementations the data network and the telephone network may be implemented by a single or otherwise integrated communications network configured to enable voice communications between the intelligent mobile telephone and the call handling system and to enable communications between the intelligent mobile telephone the application server and the call handling system .

The application server is configured to establish a data communications session with the intelligent mobile telephone and to receive and send data to the intelligent mobile telephone across the data network . The application server also is configured to communicate with the call handling system to send data received from the intelligent mobile telephone to the IVR . The application server may also send other application related data that did not originate from the intelligent mobile telephone to the IVR or more generally to the call handling system . The application server may also be configured to communicate with the data store to read and or write user interaction data e.g. state variables for a data communications session in a shared memory space as described previously with respect to application server and data store shown in . The application server may be one or more computer systems that operate separately or in concert under the direction of one or more software programs to perform the above noted functions. In some implementations the application server and the call handling system are a single integrated computer system.

The data store is configured to store user interaction data of voice interactions. In some implementations the data store may store interaction data associated with a particular user. For example the interaction data may include the gender and other voice characteristics of the caller the choices made by the caller during each state of the voice interaction and the speech resources utilized during each state of the voice interaction. In some implementations the data store may store aggregated interaction data associated with a particular voice site or voice application. For example the aggregated interaction data may include data specifying a breakdown of genders among all callers that accessed the particular voice site. In some implementations a user may opt out such that her usage data is then not stored in the data store . In some implementations a user may opt in to have her usage data be stored in the data store .

The voice site builder is configured to provide application development tools to third party content providers for creating voice sites. The voice site builder may be implemented for example as a special purpose or a general purpose computer configured to access instructions included in one or more programming modules that are stored on a computer readable storage medium. The instructions when executed by the computer enable the computer to communicate with a content provider computing device to enable the content provider computing device to provide a user interface with which a user of the content provider computing device may interact to create a voice site using the application development tools. In one implementation the content provider computer is a desktop computer that uses a browser program e.g. a Web browser to access the voice site builder across the data network e.g. the Internet .

In some implementations the voice site builder resides in a server e.g. a Web server separate from but in communication with the call handling system . In other implementations the voice site builder is integrated into the call handling system . In yet other implementations the voice site builder is entirely contained within the content provider computing device which periodically communicates data that defines the developed voice site to the call handling system for approval and implementation.

Example application development tools provided by the voice site builder are illustrated in which were described previously and in which are described below. In some implementations a content provider may use the voice site builder to configure data processing requirements associated with a voice page and the configured data processing requirements may be stored in a configuration database .

In general the call handling system may include an interactive voice response IVR system an optimized dynamic speech allocation ODSA engine a configuration database and speech resources which include ARS engines TTS engines and a noise reduction engine . In some implementations the call handling system may additionally or alternatively include other resources that can be used to process other modes of information such as video and text. As used in this specification an engine or software engine refers to a software implemented input output system that provides an output that is different from the input. An engine can be an encoded block of functionality such as a library a platform a Software Development Kit SDK or an object.

The IVR may include a voice gateway coupled to a voice application system via a data network. Alternatively the voice gateway may be local to the voice application system and connected directly to the voice application system. The voice gateway is a gateway that receives user calls from or places calls to voice communications devices such as the intelligent mobile telephone and responds to the calls in accordance with a voice interaction. The voice interaction may be accessed from local memory within the voice gateway or from the application system. In some implementations the voice gateway processes voice interactions that are script based voice applications. The voice interaction therefore may be a script written in a scripting language such as for example voice extensible markup language VoiceXML or speech application language tags SALT . The voice application system includes a voice application server and all computer systems that interface and provide data to the voice application server. The voice application system sends voice application programs or scripts to the voice gateway for processing and receives in return user responses. The user responses are analyzed by the voice application system and new programs or scripts that correspond to the user responses may then be sent to the voice gateway for processing. The voice application system may determine which programs or scripts to provide to the voice gateway based on some or all of the information received from the intelligent mobile telephone via the application server . The IVR also is configured to communicate with the data store to read and or write user interaction data e.g. state variables for a data communications session in a shared memory space as described previously.

The optimized dynamic speech allocation ODSA engine is one or more computing devices configured to select a speech resource for the IVR system based on a set of static and or dynamic data processing requirements associated with a voice interaction and a set of engine attributes associated with speech resources. In general in response to a request from the IVR system the ODSA engine determines and provides to the IVR system one or more port identifiers for identifying speech resources. A port is a data communication channel that the IVR system may subsequently use to connect to and communicate with the identified speech resource to process voice data. In some implementations port identifiers are stored in the configuration database .

The call handling system may include multiple speech resources for processing voice data. The speech resources may include for example ASR engines . ASR engines are one or more engines that are running software and or hardware applications for performing automatic speech recognition e.g. ISPEECH GOOGLE and NVOQ When executing voice interactions the IVR system may access any one of the ASR engines through a port identified by the ODSA engine .

Additionally or alternatively the speech resources may include TTS engines . TTS engines are one or more engines that are running software and hardware applications for performing text to speech conversions e.g. ISPEECH . When executing voice interactions the IVR system may access any one of the TTS engines through a port identified by the ODSA engine .

Additionally or alternatively the speech resources may include a noise reduction engine . The noise reduction engine is configured to increase voice recognition accuracy by reducing background noise associated with the calling environment of a user. When executing voice interactions the IVR system may access the noise reduction engine through a port identified by the ODSA engine .

In particular the ODSA engine may select an optimal ASR engine by comparing the one or more sets of engine attributes to the static data processing requirements received from the configuration database and or from the IVR system and or by comparing the one or more sets of engine attributes to the dynamic data processing requirements received from the IVR system . The ODSA engine provides the IVR system with one or more port identifiers that can be used to connect to the identified ASR engine and the IVR system may subsequently communicate with the identified ASR engine or via the one or more ports using the port identifiers to process voice data.

In some implementations the engine attributes of an ASR engine may include one or more speech types. A speech type may indicate the complexity of user speech that an ASR engine may recognize and process. Examples of speech types include but are not limited to basic ASR dictation and natural language. In some implementations an ASR engine having an attribute of a basic ASR speech type may be configured to recognize a sentence within a known context. For example the IVR system has asked a user a question and the context of voice interaction with the user is constrained by the question. In some implementations an ASR engine having an attribute of a dictation speech type may be configured to render a user s speech into text automatically and without engaging in a spoken language exchange between the user and a voice application. In some implementations an ASR engine having an attribute of a natural language type may be configured to allow a user to proactively provide voice data in a voice application without the IVR system prompting the user to do so. For example a pizza ordering application may allow the user to specify desired toppings before the IVR system asks the user for such input.

In some implementations the engine attributes of an ASR engine may include one or more support languages. A support language may indicate a specific language that an ASR engine may be configured to recognize. Examples of a support language include but are not limited to English Spanish French and other foreign languages.

In some implementations the engine attributes of an ASR engine may include one or more channel types. A channel type may indicate whether an ASR engine is configured to support speech recognition only or an ASR engine is configured to support speech recognition assisted by information provided by the user using other modes e.g. text . For example the voice recognition accuracy may improve if an ASR engine can process text information provided by the user which may provide additional context for recognizing the voice data. For instance a user may be asked during a voice interaction to provide a ticket ID that is an alphanumeric string e.g. 72HB8C2 . In such instances depending on the numbers and characters allowed speech responses may have a high level of misrecognition e.g. the H may be mistaken for an 8 the 8 for H or the C for the Z . In such instances the user may be asked to enter their ticket ID by responding to an SMS that was sent to them during the call. The user may respond by typing that ID and the IVR Voice interaction may proceed on from that point.

In some implementations the engine attributes of an ASR engine may include a cost per transaction. In general a service provider may charge a content provider based on the speech resources used by the IVR system during a voice interaction with a user. For example the cost may be associated with the complexity of the required voice data. For instance a high premium may be charged for voice interactions requiring large grammars e.g. City and State or complex grammars e.g. full physical addresses or Natural language grammars e.g. the ability of the user to express themselves without any unnatural constraints in how them may express themselves for the purpose of describing a type of problem . A lesser premium may be placed on interactions that require moderately sophisticated but very well behaved grammars e.g. dates currency credit card numbers and then an even lesser premium for simple grammars e.g. phone numbers digit sequences with the least complex being a small set of keywords or phrases e.g. What is your favorite color . As another example the cost may be associated with additional functionality provided by a speech resource e.g. an ASR engine that provides an optional biometrics feature may result in a higher cost when the optional biometrics feature is enabled . As another example the cost may be associated with an arrangement between the service provider and external developers of the speech resources e.g. a service provider may pay an external developer each time an IVR system is connected to an ASR engine or the service provider may pay the external developer a flat fee each year. 

In some implementations the engine attributes of an ASR engine may include recognition accuracy of the ASR engine. An ASR engine with a higher recognition accuracy attribute provides greater accuracy in recognizing the content of spoken input than an ASR engine with a lower recognition accuracy attribute. In general an ASR engine produces a confidence level or score after processing voice data that reflects the likelihood that the content identified by the ASR engine as corresponding to the voice data in fact does correspond to the voice data. In some implementations the ASR engine may determine that there are multiple possible interpretations for the received voice data and the ASR engine may assign a separate score to each of the possible interpretations to reflect the differing respective likelihoods that each corresponding interpretation correctly identifies the content of the spoken input. In some implementations an ASR s recognition accuracy attribute or attributes is specific to speech type such that the ASR has a different recognition accuracy attribute for each of one or more different speech types. In some implementations an ASR having a higher recognition accuracy attribute may indicate that the ASR engine is better able to accurately analyze voice data in the presence of more background noise than an ASR having a lower recognition accuracy attribute.

In some implementations the engine attributes of an ASR engine may include additional security features supported by the ASR engine. For example an ASR engine may be configured to support biometrics features which allow the ASR engine to securely verify the identity of a caller by analyzing voice characteristics of the caller.

In some implementations the engine attributes of an ASR engine may include interaction types. An interaction type may indicate what type of voice interaction an ASR engine is configured to process. Examples of interaction types include but are not limited to directed dialog and mixed initiative. In some implementations an ASR engine having an attribute of directed dialog interaction type may be configured to require that the IVR system exchange voice information with the user using a step by step question and answer type of voice interaction. In some implementations an ASR engine having an attribute of mixed initiative interaction type may be configured to allow a user to initiate a conversation using natural language before the IVR system prompts a specific question to the user.

In some implementations the engine attributes of an ASR engine may include other features supported by the ASR engine. For example an ASR engine may be configured to support a feature that is specifically designed to process voice information having characteristics of a high pitch. As another example an ASR engine may be configured to support a built in feature for background noise reduction.

Each of the ASR engines and may have its own set of engine attributes. In some implementations an ASR engine may have customized engine attributes because the ASR engine is developed by a different external ASR engine developer. In some implementations the engine attributes of each of the ASR engines may be stored at the configuration database . In some other implementations the engine attributes of each of the ASR engines may be stored at the ODSA engine .

A user initiates a voice communications session with the IVR system . In some implementations the user may dial a telephone number via the telephone network that is subsequently routed to the IVR system handling the corresponding voice site. In some other implementations the user may initiate a voice application on her intelligent mobile telephone and the voice application may connect to the IVR system via the data network . In some other implementations the user may initiate a multimodal application on her intelligent mobile telephone and the multimodal application may connect to the IVR system and the application server via the data network .

The IVR system receives voice data and optionally dynamic interaction data from the user of the intelligent mobile telephone . In some implementations the voice data may be received as the user s response to a question prompted by the IVR system . In some other implementations the user may speak the voice data without being prompted by the IVR system . The dynamic interaction data includes data that represents characteristics associated with the user and her calling environment during the user s interaction with the IVR system . For example the dynamic interaction data may include the ambient noise level around the user during the call. As another example the dynamic interaction data may include the location of the intelligent mobile telephone . As another example the dynamic interaction data may include voice characteristics of the user e.g. gender pitch speed volume tone preferred spoken language age group accent and any other characteristics that may be processed using the received audio input from the user . In some implementations the IVR system may analyze the dynamic interaction data and store the analyzed dynamic interaction data in the data store . In some other implementations the IVR system may store the analyzed dynamic interaction data internally. In some other implementations the IVR system may store the received dynamic interaction data without further analysis.

The IVR system determines whether a speech resource is required to process the received voice data . If the IVR system determines that a speech resource is required to process the received voice data the IVR system may send a speech resource allocation request to the ODSA engine . In some implementations the speech resource allocation request may include the state of the voice communications session and optionally the dynamic interaction data. In some other implementations the IVR system may store the state of the voice communications session and optionally the dynamic interaction data at the data store and may not include such information in the speech resource allocation request. In some implementations the state of the voice communications session is an identifier for a voice page e.g. the voice page that was executed to collect the received voice data from the user .

The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session. In some implementations the ODSA engine may identify the state of the voice communications session by receiving such information from the IVR system . In some other implementations the ODSA engine may identify the state of the voice communications session by communicating with the data store .

After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . For example a content provider for the voice communications session may have specified static speech data processing requirements at the time of developing the voice site and the static speech data processing requirements have been previously stored at the configuration database as configuration information. The ODSA engine communicates with the configuration database to access the static speech data processing requirements i.e. configuration information based on the state of the voice communications session.

The ODSA engine then optionally accesses the dynamic interaction data associated with the voice communications session . In some implementations the ODSA engine may access the dynamic interaction data by receiving such information from the IVR system . In some other implementations the ODSA engine may access the dynamic interaction data by communicating with the data store . The ODSA engine may then determine a set of dynamic speech data processing requirements based on the dynamic interaction data.

Based on the static speech data processing requirements and optionally the dynamic speech data processing requirements the ODSA engine determines a speech resource for processing the voice data . In some implementations the ODSA engine may access engine attributes associated with a set of different speech resources and select based on the engine attributes a speech resource from among the set of different speech resources that satisfies both the static speech data processing requirements and the dynamic speech data processing requirements. In some implementations the ODSA engine may select multiple speech resources that in combination satisfy both the static speech data processing requirements and the dynamic speech data processing requirements. In some implementations the ODSA engine may select a single speech resource that satisfies the static speech data processing requirements e.g. an ASR engine that handles basic ASR and a different single speech resource that satisfies the dynamic speech data processing requirements e.g. a noise reduction engine . In some implementations the ODSA engine may select multiple different speech resources that are each able to satisfy the static speech data processing requirements and or the dynamic speech data processing requirements and may then select from among these the speech resource for the content provider based on cost e.g. the lowest cost speech resource . For example the dynamic interaction data for the user indicates that the user is a female so the ODSA engine selects an ASR engine best able to handle a female voice. In some implementations one or more static or dynamic speech data processing requirements may be weighted and the ODSA engine may determine the optimal speech resource that satisfies the weighted speech data processing requirements.

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . In some implementations the ODSA engine may identify a port that can be connected to the determined speech resource and communicates the port identifier to the IVR system . In some implementations the ODSA engine may identify more than one port for the IVR system . For example the ODSA engine may determine that the IVR system should connect to both an ASR engine and the noise reduction engine . The ODSA engine then communicates the speech resource allocation information to the IVR system . In some implementations the speech resource allocation information may include information identifying resource type and the port identifier.

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . In some implementations the IVR system may connect to and access the allocated speech resource via a port identified by the port identifier. The IVR system may communicate with the allocated speech resource to process the voice data received from the user.

Under the example process illustrated in the IVR system may continue to use the same allocated speech resource to process subsequent voice data received from the user at subsequent states of the voice interaction. However the static speech data processing requirements or the dynamic speech data processing requirements may change at subsequent states of the voice interaction. It therefore may be useful to iteratively determine and allocate speech resources at different states of the voice interaction.

If the IVR system determines that the speech resource has satisfied the user s demand the IVR system determines whether the voice communications session has ended . In some implementations the IVR system may determine whether the voice communications session has ended by identifying the state of the voice interaction. In some implementations the IVR system may determine whether the voice communications session has ended by analyzing the user s voice data. If the IVR system determines that the voice communications session has ended the IVR system may close the port connected to the allocated speech resource. If the IVR system determines that the voice communications session has not ended the IVR system receives subsequent voice data and optionally dynamic interaction data from the user . Based on the newly received voice data and optionally the dynamic interaction data the IVR system determines whether a speech resource is required to process the received voice data . In some implementations the IVR system may determine that the previously allocated speech resource is sufficient to process the newly received voice data. In that case after the IVR system processes the voice data the IVR system determines whether the voice communications session has ended .

If the IVR system determines that a new speech resource is required a speech resource allocation request is sent to the ODSA engine . Upon receiving the speech the speech resource allocation request from the IVR system the ODSA engine accesses the configuration information associated with the newly identified state optionally accesses the newly received dynamic interaction data and determines a speech resource for processing the newly received voice data . After determining the speech resource the ODSA engine allocates the speech resource to the IVR system and after receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource .

If the IVR system determines that the speech resource has not satisfied the user s demand the IVR system sends a request to the ODSA engine to determine another speech resource for processing the previously received voice data . In some implementations the ODSA engine may determine to select the most robust speech resource based on the feedback from the IVR system . In some implementations the ODSA engine may determine to select another speech resource based on the dynamic interaction data. In some implementations the ODSA engine may determine to add another speech resource e.g. the noise reduction engine in addition to the previously determined speech resource. After determining the speech resource the ODSA engine allocates the speech resource to the IVR system and after receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource .

The IVR system stores the historical interaction data at the data store . Each time a user accesses the voice application historical interaction data associated with the particular voice communications session may be stored at the data store . The data store may include aggregated historical interaction data for a particular voice application or historical interaction data for a particular user.

A user of the intelligent mobile telephone then initiates a voice communications session with the IVR system . In some implementations a caller identity e.g. a name of the caller an e mail address of the caller or an account number is determined at the beginning of the voice communications session by for example prompting the user to input using a keypad the identity or prompting the caller to speak the identity. As another example a caller identity may be identified automatically by the IVR system using metadata e.g. phone number associated with the intelligent mobile telephone . Using the caller identity corresponding historical information for the particular user may be accessed from the data store at the beginning of the session.

The IVR system receives voice data and optionally dynamic interaction data from the user . The IVR system determines whether a speech resource is required to process the received voice data . If the IVR system determines that a speech resource is required to process the received voice data the IVR system may send a speech resource allocation request to the ODSA engine . If the IVR system determines that a speech resource is not required to process the received voice data the IVR system may process the voice data and determine whether the voice communications session has ended .

If the IVR system determines that a speech resource is required to process the received voice data the IVR system may send a speech resource allocation request to the ODSA engine . The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session. In some implementations the ODSA engine may identify the state of the voice communications session by receiving such information from the IVR system . In some other implementations the ODSA engine may identify the state of the voice communications session by communicating with the data store .

After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . The ODSA engine also accesses the historical interaction data . In some implementations the ODSA engine accesses the historical interaction data from the data store . For example for a particular state of the voice communications session the ODSA engine may access the aggregated historical interaction data associated with multiple users that have accessed the voice application from the data store and identify the most common speech resource for the particular state that was determined by the ODSA engine and accessed by the IVR system for the multiple users e.g. if most callers using the voice application are females the ODSA engine may select an ASR engine optimized to process female voices . As another example for a particular state of the voice communications session the ODSA engine may access the historical interaction data associated with the user of the intelligent mobile telephone and identify the speech resource for the particular state that was determined by the ODSA engine and accessed by the IVR system for the user during the previous communications session e.g. if a caller calling from a recognized phone number was a male in the previous communications sessions the ODSA engine may select an ASR engine optimized to process male voices .

The ODSA engine then optionally accesses the dynamic interaction data associated with the voice communications session . In some implementations the ODSA engine may access the dynamic interaction data by receiving such information from the IVR system . In some other implementations the ODSA engine may access the dynamic interaction data by communicating with the data store . The ODSA engine may then optionally determine a set of dynamic speech data processing requirements based on the dynamic interaction data.

Based on the static speech data processing requirements optionally the dynamic speech data processing requirements and the historical interaction data the ODSA engine determines a speech resource for processing the voice data . In some implementations the ODSA engine may access engine attributes associated with speech resources and determines a speech resource that satisfies the static speech data processing requirements and optionally the dynamic speech data processing requirements. In some implementations the ODSA engine may determine a speech resource based on the historical interaction data. For example a caller may be known to prefer to speak in Spanish so the ODSA engine may select an ASR engine that supports Spanish. As another example the caller may be known to have a particular accent e.g. a heavy Australian accent so the ODSA engine may select an ASR engine best able to handle a particular language e.g. English spoken with that accent. This ASR assignment occurs dynamically in response to the call and is tailored to the particular information known about that user.

In some implementations the historical interaction data about the user may be combined with the static speech data processing requirements to determine the optimal speech resource to handle the call. For example if the voice interaction is completing a survey and the caller is known to speak in Spanish a simpler and lower cost ASR engine e.g. an ASR engine that supports basic ASR may be selected that supports Spanish.

In some implementations the ODSA engine may determine multiple speech resources that satisfy the static speech data processing requirements and the dynamic speech data processing requirements and may then select the speech resource with the lowest cost for the content provider. In some implementations one or more static speech data processing requirements dynamic speech data processing requirements and historical interaction data may be weighted and the ODSA engine may determine the optimal speech resource that based on the weighted static speech data processing requirements dynamic speech data processing requirements and the historical interaction data.

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . The ODSA engine then communicates the speech resource allocation information with the IVR system . After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . The IVR system then determines whether the speech resource satisfies user demand as previously described in .

The process iteratively repeats until the IVR system determines that the voice communications session has ended . The IVR system then stores the information associated with the voice communications session as historical interaction data at the data store .

In some implementations an ASR setting may include a speech type attribute . Examples of speech types supported by this particular implementation of the voice site builder include but are not limited to natural language numerical Yes No and dictation. The user is able to select from among these different types using for example a drop down menu as shown in . In some implementations a voice page having an ASR setting of a natural language type may be configured to allow a user to proactively provide voice data in a voice application without the IVR system prompting the user to do so. In some implementations a voice page having an ASR setting of a numerical type may be configured to allow a user to only provide numerical values during the particular stage of the voice interaction with the IVR system . In some implementations a voice page having an ASR setting of a Yes No type may be configured to allow a user to only provide a Yes or No answer during the particular stage of the voice interaction with the IVR system . In some implementations a voice page having an ASR setting of a dictation speech type may be configured to render a user s speech into text without engaging language exchange between the user and a voice application.

In some implementations an ASR setting may include a language attribute . In the implementation example shown in a user is able to select from among two different languages i.e. English and Spanish by interacting with a drop down menu.

In some implementations an ASR setting may include an ASR selection attribute . The user i.e. content provider may select to allow the service provider to select the ASR engine that the service provider deems is best able to satisfy the data processing requirements for the voice page by selecting the optimized option from for example a drop down menu. Alternatively the user may manually select a particular ASR engine from among a set of available ASR engines by for example instead selecting the corresponding ASR engine identifier from the drop down menu. In some implementations the ASR Settings tab may not allow the user to manually select a particular ASR engine to thereby preserve the ability of the service provider to update change and or replace the existing set of ASR engines without negatively impacting any particular voice site designed using the voice site builder .

In some implementations an ASR setting may include a minimum recognition accuracy attribute . In general an ASR engine provides a recognition accuracy associated with the processed voice data. For example the ASR engine may assign a score to the processed voice data. In some implementations the ASR engine may determine that there are multiple possible interpretations for the received voice data and the ASR engine may assign a score to each of the possible interpretation. The minimum recognition accuracy attribute may provide a threshold for filtering out possible interpretations having scores lower than the threshold. For example a particular ASR engine may process a voice input and determines that there is a possibility of 90 that the user has said the word Boston a possibility of 70 that the user has said the word Austin and a possibility of 50 that the user has said the word Houston. If the minimum recognition accuracy attribute has been set to 80 by the content provider the ASR engine may only return the word Boston to the IVR system .

In some implementations an ASR setting may include a security attribute . For example a content provider may configure the voice page to require the voice biometric feature and only ASR engines that are configured to support biometrics features would be selected for the voice page .

The IVR system then determines whether a speech resource is required to process the received voice data . Here the IVR system determines that a speech resource is required to process the received voice data and the IVR system sends a speech resource allocation request to the ODSA engine .

The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session. In some implementations the ODSA engine may identify the state of the voice communications session by receiving such information from the IVR system . In some other implementations the ODSA engine may identify the state of the voice communications session by communicating with the data store .

After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . Here by accessing the configuration database the ODSAE engine identifies that the hotel reservation application requires invoking the date grammar the time grammar the city and state grammar the credit card grammar and the yes and no grammar .

Based on the static speech data processing requirements the ODSA engine determines a speech resource for processing the voice data . The ODSA engine may access engine attributes associated with all ASR engines and determines a speech resource that satisfies the static speech data processing requirements. Here the ODSA engine determines that for such a grammar intensive application the IVR system needs to use the most robust and expensive ASR engine .

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . Here the ODSA engine identifies the ASR port corresponding to the most robust and expensive ASR in the call handling system . The ODSA engine then communicates the speech resource allocation information with the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . Here the IVR system connects to the most robust and expensive ASR engine via the port identified by ODSA engine and processes the voice data received from the user . In this example the IVR system may continue to use the most robust and expensive ASR engine until the end of the voice interaction.

The IVR system then determines whether a speech resource is required to process the received voice data . Here the IVR system determines that a speech resource is required to process the received voice data and the IVR system sends a speech resource allocation request to the ODSA engine .

The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session.

After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . Here by accessing the configuration database the ODSAE engine identifies that the survey application requires the user to give a number between 1 and 5 to describe her satisfaction level .

Based on the static speech data processing requirements the ODSA engine determines a speech resource for processing the voice data . Here the ODSA engine determines that for such a simple grammar application the IVR system may use the least expensive ASR engine .

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . Here the ODSA engine identifies the ASR port corresponding to the least expensive ASR in the call handling system . The ODSA engine then communicates the speech resource allocation information with the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . Here the IVR system connects to the least expensive ASR engine via the port identified by ODSA engine and processes the voice data received from the user . In this example the IVR system may continue to use the least expensive ASR engine until the end of the voice interaction.

The IVR system receives voice data and dynamic interaction data from the user . Here the IVR system detects that there is a high level of background noise in the user s calling environment . The IVR system then determines whether a speech resource is required to process the received voice data . Here the IVR system determines that a speech resource is required to process the received voice data and the IVR system sends a speech resource allocation request to the ODSA engine .

The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session. After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . Here by accessing the configuration database the ODSAE engine identifies that the survey application requires the user to give a number between 1 and 5 to describe her satisfaction level .

The ODSA engine then accesses the dynamic interaction data associated with the voice communications session . Here the ODSA engine determines that the calling base is a noisy environment . The ODSA engine then determines a set of dynamic speech data processing requirements based on the dynamic interaction data.

Based on the static speech data processing requirements and the dynamic speech data processing requirements the ODSA engine determines a speech resource for processing the voice data . Here the ODSA engine determines that for such a simple grammar application the IVR system may use the least expensive ASR engine. However due to the high background noise level the ODSA engine may either choose to replace the least expensive ASR engine with a robust but more expensive ASR engine or alternatively the ODSA engine may choose to add the noise reduction engine to reduce the background noise. Here the ODSA engine determines that the cost associated with accessing both the least expensive ASR engine and the noise reduction engine is lower than the cost associated with accessing the robust but expensive ASR engine. Therefore the ODSA engine selects the least expensive ASR engine and the noise reduction engine as speech resources for the IVR system .

After determining the speech resources the ODSA engine allocates the speech resources to the IVR system . Here the ODSA engine identifies i the ASR port for the ASR engine that is least expensive and ii a port for noise reduction engine . The ODSA engine then communicates the speech resource allocation information with the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . Here the IVR system connects to the least expensive ASR engine as well as the noise reduction engine via the ports identified by ODSA engine and processes the voice data received from the user . In this example the IVR system may continue to use the least expensive ASR engine and the noise reduction engine until the end of the voice interaction.

The IVR system stores the historical interaction data at the data store . Each time a user accesses the voice application historical interaction data associated with the particular voice communications session may be stored at the data store . The data store may include aggregated historical interaction data for a particular voice application and or historical interaction data for a particular user. Here the IVR system stores user characteristics such as gender of the caller at the data store .

A user of the intelligent mobile telephone then initiates a voice communications session with the IVR system . Here the user has initiated the prescription refill application using her intelligent mobile telephone .

The IVR system then determines whether a speech resource is required to process the received voice data . Here the IVR system determines that a speech resource is required to process the received voice data and the IVR system sends a speech resource allocation request to the ODSA engine .

The ODSA engine receives the speech resource allocation request from the IVR system . Upon receiving the speech resource allocation request the ODSA engine identifies the state of the voice communications session. After identifying the state of the voice communications session the ODSA engine accesses the configuration information associated with the state . Here by accessing the configuration database the ODSA engine identifies that the survey application requires moderate grammar interactions with the user .

After accessing the configuration information the ODSA engine accesses the historical interaction information associated with the state . Here by accessing the data store the ODSA engine identifies that the prescription refill application is mostly used by females .

Based on the static speech data processing requirements and the historical interaction information the ODSA engine determines a speech resource for processing the voice data . The ODSA engine may access engine attributes associated with all ASR engines and determines a speech resource that satisfies the static speech data processing requirements and the historical interaction information. Here the ODSA engine determines that given the high pitch of the voice data associated with most female callers the misrecognitions are high with the less robust ASR engine. The ASR engine that is the most robust to pitch i.e. able to most accurately interpret voice data corresponding to a voice having a high pitch is selected .

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . Here the ODSA engine identifies the ASR port corresponding to the ASR engine that is the most robust with respect to pitch in the call handling system . The ODSA engine then communicates the speech resource allocation information with the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . Here the IVR system connects to the ASR engine that is the most robust to pitch via the port identified by ODSA engine and processes the voice data received from the user . In this example the IVR system then determines whether the voice communications session has ended . If the voice communications session has ended the IVR system stores the voice interaction data with the current user at the data store . If the voice communications session has not ended the IVR system continues the voice interaction with the current user and the ODSA engine allocates the optimal ASR engine depending on the state of the voice communications session.

After determining the speech resource the ODSA engine allocates the speech resource to the IVR system . Here the ODSA engine identifies the ASR port corresponding to the ASR engine that is the most robust with respect to high pitched voices in the call handling system . The ODSA engine then communicates the speech resource allocation information to the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system accesses the allocated speech resource . Here the IVR system connects to the ASR engine that is the most robust with respect to high pitched voices via the port identified by ODSA engine and processes the voice data received from the user .

The IVR system then determines whether the speech resource satisfies user demand . Here the IVR system determines that the misrecognition rate associated with the ASR engine that is the most robust with respect to high pitched voices is too high for this particular user because for example the number of times that the ASR engine has failed to accurately interpret the user s speech in the communications session has passed a threshold e.g. the ASR engine has misinterpreted the user s identification of a prescribed drug twice . In response to determining that the misrecognition rate is too high the IVR system sends a second speech resource allocation request to the ODSA engine .

The ODSA engine determines a second speech resource for the IVR system . Here the ODSA engine determines that the caller is male and therefore the misrecognition rate associated with the ASR engine that is the most robust to pitch is high. A second ASR engine that is robust to male voice is selected.

After determining the second ASR engine the ODSA engine identifies the ASR port corresponding to the second ASR engine . The ODSA engine then communicates the speech resource allocation information with the IVR system .

After receiving the speech resource allocation information from the ODSA engine the IVR system connects to the second ASR engine via the port identified by ODSA engine and processes the voice data received from the male user . The IVR system then again determines whether the speech resource satisfies user demand . Here the recognition rate using the second ASR engine is above a threshold defined by the content provider of the prescription refill application and the IVR system moves on to determine whether the voice communications session has ended . If the voice communications session has ended the IVR system stores the voice interaction data with the current user at the data store . If the voice communications session has not ended the IVR system continues the voice interaction with the current user and the ODSA engine allocates the optimal ASR engine depending on the state of the voice communications session.

While the above described implementations focus on the dynamic allocation of speech resources the same techniques may be used to allocate other types of data processing resources that are not specifically focused on voice or speech. For example the same techniques could be used to allocate video processing resources such as for example facial recognition engines or license plate reading engines. The disclosed and other examples can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The implementations can include single or distributed processing of algorithms. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device or a combination of one or more them. The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a standalone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communications network.

The processes and logic flows described in this document can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer can include a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer can also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Computer readable media suitable for storing computer program instructions and data can include all forms of nonvolatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

While this document may describe many specifics these should not be construed as limitations on the scope of an invention that is claimed or of what may be claimed but rather as descriptions of features specific to particular embodiments. Certain features that are described in this document in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or a variation of a sub combination. Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results.

Only a few examples and implementations are disclosed. Variations modifications and enhancements to the described examples and implementations and other implementations can be made based on what is disclosed.

