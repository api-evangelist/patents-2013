---

title: System and method for automatically generating systematic reviews of a scientific field
abstract: A system and method are provided for automatically generating systematic reviews of received information in a field of science and technology, such as scientific literature, where the systematic review includes a systematic review of a research field in the scientific literature. The method includes the steps of constructing a time series networks of words, passages, documents, and citations and/or co-citations within received information into a synthesized network, decomposing the networks into clusters of fields or topics, performing part-of-speech tagging of text within the received information to provide tagged text, constructing semantic structures of concepts and/or assertions extracted from the source text, generating citation-based and content-based summaries of the clusters of fields or topics and the semantic structures, and generating structured narratives of the clusters of fields or topics and the summaries of the generated semantic structures. Narratives of the citation-based and content-based summaries are merged into a systematic review.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08935291&OS=08935291&RS=08935291
owner: Drexel University
number: 08935291
owner_city: Philadelphia
owner_country: US
publication_date: 20131001
---
This application is a continuation of U.S. patent application Ser. No. 13 117 508 filed May 27 2011 which claims benefit of Provisional Application No. 61 349 632 filed May 28 2010.

This invention was made with government support under Grant No. IIS 0612129 awarded by the National Science Foundation. The government has certain rights in the invention.

The invention relates to a system and method for automatically generating systematic reviews of a scientific field and more specifically to a system and method for transforming textual documents representing a scientific domain into an automatically constructed systematic narrative of the domain in terms of the structure and semantics of the underlying scientific literature. The invention also relates to a system and method for quantifying the potential value of newly available scientific work with reference to the systematic representation of the relevant scientific fields.

The volume of scientific publications in general has been increasing tremendously and rapidly across a wide range of scientific fields and disciplines. Such a rapid and tremendous increase means that scientists have to deal with an increasingly thick layer of transient information and that they have to distill the valuable knowledge from more noises and uncertainties associated with the overwhelming amount of input as a whole in a timely way.

The core knowledge of a scientific field is largely documented in its literature in the form of peer reviewed and non peer reviewed publications. Peer reviewed publications are considered of higher value than non peer reviewed ones because the science reported in peer reviewed publication is safeguarded by peer scientists and they are more likely to have met the rigorous and stringent criteria. This description will primarily focus on peer reviewed publications however those skilled in the art will appreciate that the method described herein is equally applicable to non peer reviewed publications and other types of text such as patent applications and technical reports.

A body of scientific literature serves two primary roles in the advancement of science archival and communicative roles. A well known conception of the structure of scientific literature in the study of science is that scientific literature consists of two principal components one is classic and the other is transient. The classic component of scientific literature contains well documented and well established knowledge of a scientific field or collective domain knowledge associated with the underlying scientific community. The classic component forms the backbone of the domain knowledge because it represents the fundamental value of the scientific domain including its principles methodologies and major claims. In contrast the transient component represents the most recent attachment to the backbone structure. It includes the latest publications of new results and new findings. The nature of such attachment remains transient until new publications have been subject to the selection of the scientific community. Such transient layers are sometime known as research fronts. The selection can lead to one of the outcomes acceptance rejection and indifference although both the structure of such backbones and these outcomes regarding the research fronts are subject to further change as new evidence becomes available or new theories become predominant. The degree of a selection is often measured in terms of the citations received i.e. the number of times subsequently published articles make references to the work. The more citations of a work the greater its perceived impact is on the scientific field and therefore the more value it adds to the development of scientific knowledge.

Systematic reviews comprehensive surveys and meta analytical studies are among the most common and effective means used by scientists scholars and people with similar needs to maintain their understanding of their fields. These methods share similar goals of identifying significant contributions and potential challenging issues and future research directions. They all rely on scientific literature as a primary source of input and try to clarify the state of the art. On the other hand they have some inherited shortcomings time consuming labor intensive biased by the view of the few. As a result such reviews are often separated by an extensive period of time. These reviews and surveys are typically performed by experts. Since experts tend to be specialized in some but not all areas of a field the coverage can be biased by their own preferences and knowledge.

A new approach to reviewing developments in a scientific field without the bias and time consuming approach of the prior art is desired. In particular a technique is desired whereby quantitative as opposed to qualitative reviews of a scientific field may be generated automatically with high scalability and medium to low cost. The present invention is designed to address these needs in the art.

The invention addresses the afore mentioned needs in the art by transforming a stream of textual documents representing a scientific domain into an automatically constructed systematic narrative of the domain in terms of the structure and semantics of its literature. The system and method described herein overcomes some of the major weaknesses of the traditional labor intensive approaches so that it can automatically generate a summary of the state of the art of a field. The invention may be applied to the study of a field repeatedly periodically and on demand. New reports and updates can be generated at minimum costs. Automatically generated summaries will be valuable in their own right as a new form of documentation. In addition the summaries may be incorporated into a traditional review method with a considerably reduced amount of overhead.

In accordance with an exemplary embodiment of the invention a method of automatically generating systematic reviews of information received from a source text in a field of literature such as scientific literature includes the steps of constructing associative networks of entities such as words sentences documents journals institutions and citations within the received information decomposing the associative networks into clusters of topics or fields performing information extraction with natural language techniques such as part of speech tagging of text within the received information constructing semantic and ontological structures of concepts and or assertions extracted from the source text generating citation based and content based summaries of the clusters of topics or fields and the semantic and ontological structures and generating structured narratives of the clusters of field or topic characterizing entities and the summaries of the generated semantic structures. The method also includes the step of merging narratives of the citation based and content based summaries into a systematic review having a predetermined arrangement.

In an exemplary embodiment the step of generating citation based and content based summaries of the clusters of fields or topics and the semantic structures includes measuring the saliency novelty significance and transformative features of individual entities in the clusters of fields or topics and semantic representations of the underlying knowledge. In the exemplary embodiment the step of generating structured narratives of the cluster of fields or topics and the summaries of the generated semantic structures includes labeling and summarizing features of the clusters of fields or topics and delinearizing the characteristics of such clusters into templates that provide summarizations of the structure and trends of the topic or field evolution at multiple levels of abstraction.

Particular embodiments of the method include constructing associative networks of scientific publications including citation co citation and other types of semantic networks within the received information by selecting node types and link types for each time slice of the received information computing similarity or proximity scores for the nodes constructing networks of the node information and merging respective networks from different time slices. The associative networks are then decomposed into clusters of research topics by clustering nodes and measuring quality of the clustering by calculating structural diagnostic scores such as modularity and mean silhouette scores. In such embodiments generating citation based and content based summaries of the clusters of fields or topics and the semantic structures includes identifying citers to and cited members of a cluster summarizing structural and temporal properties of the cluster computing metrics of saliency and novelty for an associative network formed by the cluster ranking the clusters based on the saliency and or novelty metrics and generating structured narratives from the ranked clusters. The structured narratives of the clusters of fields or topics and the summaries of the generated semantic structures may be generated by selecting a narrative template from a set of predefined templates.

The part of speech tagging is performed by annotating the received information by a type of each word in the received information and segmenting the received information into sentences paragraphs or other types of passages. On the other hand constructing semantic structures of concepts and or assertions extracted from the tagged text includes the step of constructing a structured representation of concepts and a semantic network of assertions in the received information and merging a newly constructed semantic structure with an existing semantic structure to differentiate different sources for the newly constructed and existing semantic structures. The merged structures may be ranked based on saliency and novelty generating narratives of top ranked concepts and or assertions in the received information and merging generated narratives in a predetermined order.

The scope of the invention also includes systems having programmed processors and computer readable storage media having instructions stored thereon for implementing the methods of the invention.

A detailed description of illustrative embodiments of the present invention will now be described with reference to . Although this description provides a detailed example of possible implementations of the present invention it should be noted that these details are intended to be exemplary and in no way delimit the scope of the invention.

The purpose of time slicing is to establish the sampling rate that should be applied to the events of interest. The window of observation w is the entire time interval of interest for example a century a few decades or several weeks. Time slicing divides the window of observation into consecutive time slices w. The process of time S slicing can be expressed as a mapping from w w where w t t for t

Most observation windows can be meaningfully divided using one of the three most common strategies a b or c as shown in . As illustrated in a non overlapping varying length time slicing is defined with the following overlap and width functions overlap 5 width 6 A non overlapping even length time slicing is defined with the following overlap and width functions overlap 7 width constant 8 An overlapping even length time slicing is defined with the following overlap and width functions for example with a 25 of overlap between adjacent time slices overlap 0.75 9 width constant 10 The type b of time slicing is the simplest and the most common choice. For continuity reasons one may consider overlapping time slicing strategy c. For density reasons one may consider the option a so that each time slice contains the same number of observations.

The time slicing of text can be done based on the creation time or the last updated time of the text. On the other hand the time slicing of references can be done based on the time a reference was made for example all the references made in year 2009.

For each time slicing strategy one can derive a time series of associative networks. These networks serve as a sequence of snapshots of an evolving process. Each network is defined by a set of entities nodes or vertices and a set of relations links or edges . The following notations are used for G G V E w the network defined in the itime slice w 

A given entity may not appear in all the time slices. A network may contain multiple types of entities and or multiple types of relations. For example a hybrid network may contain keywords and references as two distinct types of entities and co occurrence and referencing as two distinct types of relations.

If the only available source is text i.e. with no references possible choices of entities include words phrases and index terms either given by the original authors or assigned by human indexers as well as documents. Interrelations among these entities include direct counts of co occurrence in containing units such as sentences paragraphs or documents. Other types of interrelations may be derived from higher order matrix operations such as singular value decomposition of term by document matrices. Interrelations may be also derived from linguistic patterns for example associations between a head noun and its modifiers as the connection between star and formation from star formation. Table 1 illustrates possible types of entities and relations for text including but not limited to 1 co occurrence and 2 similarity including mutual information vector space model etc. .

If references are available in the sources of input network entities include cited references as well as all the entities derivable from text. The citation context of a cited reference is defined as the hosting sentence paragraph document or a cluster of documents based on textual similarity or citation similarity. Table 2 illustrates relations in associative networks involving cited references.

Individual networks corresponding to a given time slicing scheme are synthesized over the entire time span of interest. Different networks G G V E w are synthesized into G V E w in one of the two methods na ve or advanced. The na ve method is defined in equations 11 13 by simply taking set unions of the entities and all relations.

Candidate pruning functions include minimal spanning tree MST . Pathfinder network scaling PFnet and any other link reduction operations. It is known that a Pathfinder network is the set union of all the possible minimal spanning trees of the original network PFnet MST 17 The primary motivation for pruning the overlapping edges across adjacent networks is to clarify the most salient structural characteristics of the underlying knowledge transformation from one time slice to the next.

The synthesized network can be visualized with visual encoding to highlight temporal aspects of the underlying knowledge transformation. For example edges can be colored in corresponding to the time slice in which associative connections were made for the first time. Alternatively edges can be colored by the most recent time slice.

Once the time series of networks are synthesized into a panoramic network spanning the entire time frame the next step is to aggregate individual nodes and links and form components of higher level abstraction. By grouping similar nodes and links together one can identify emergent patterns at higher levels and produce a clarified macroscopic structure. The aggregated structure will be used as key components in the subsequent narrative generation steps. Since this step is clustering by nature it is referred to herein as the clustering step. However this step is also known as graph decomposition because as a result of the step the network is divided into a number of groups or clusters such that members of the same cluster are more similar as measured in a chosen metric than members from different clusters.

The best clustering algorithm would make no assumption about the structure or the distributions of nodes and links. It should be purely based on the strengths of linkage. The spectral clustering family of algorithms provides the best candidate clustering algorithms to meet this requirement.

Hard clustering approaches partition a network into a number of non overlapping clusters. It is more efficient to use non overlapping clusters than overlapping ones to differentiate the nature of different co citation clusters although it is conceivable to derive a soft clustering version of this particular component.

Co citation similarities between items i and j are measured in terms of cosine coefficients. If A is the set of papers that cites i and B is the set of papers that cite j then

A good partition of a network would group strongly connected nodes together and assign loosely connected ones to different clusters. This idea can be formulated as an optimization problem in terms of a cut function defined over a partition of a network. Technical details of spectral clustering algorithms are given by Luxburg in A tutorial on spectral clustering http www.kyb.mpg.de publications attachments Luxburg06 TR  5B0 5D.pdf. Ng. et al. in On spectral clustering Analysis and an algorithm Advanced in Neural Information Processing Systems Vol. 14 2 pp. 849 856 2002 and Shi et al in Normalized Cuts and Image Segmentation IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 22 8 pp. 888 905 2000 . A partition of a network G is defined by a set of sub graphs G such that

Spectral clustering algorithms identify clusters based on eigenvectors of Laplacian matrices derived from the original network. Spectral clustering has several desirable features compared to traditional algorithms such as k means and single linkage. For example spectral clustering is more flexible and robust because it does not make any assumptions on the forms of the clusters because it makes use of standard linear algebra methods to solve clustering problems and because it is often more efficient than traditional clustering algorithms.

The resultant clusters provide an appropriate context for defining the saliency novelty and significance of individual entities. Several types of importance can be derived from a given clustered structure.

The saliency of a node can be defined within the scope of its cluster its cluster plus neighboring clusters or the entire network. The one that is defined by its own cluster is the most meaningful choice because its hosting cluster will give enough contextual information while maintaining a clearly differentiable focus.

As illustrated in the saliency of a node measures the prominence of it within the scope of a cluster for example the frequency of a node n f n or a citation of a reference. The homogeneity within a cluster makes it more meaningful to compare the saliency function of nodes in the same cluster than comparing nodes in different clusters. In other words the saliency of nodes in the red green and blue clusters may not be meaningful to compare across clusters especially across disciplinary boundaries and fields. Candidates of saliency measures include frequency appearances probability likelihood information entropy in degree out degree age and many others.

The novelty of an entity or a relation in a network measures the extent to which the entity or the relation is new with respect to the history of the network evolution. The simplest notion of novelty can be defined as something that has never seen in the past. A more useful measure of novelty needs to identify not only something that is new but also potentially valuable. The potential value of an entity or a relation can be estimated with reference to their positions in the network especially in terms of clusters.

There are three relevant aspects of the novelty measurement structural temporal and semantic metrics. Structural metrics include measurements such as centrality modularity and silhouette. Temporal and hybrid metrics include citation burstness and novelty. Structurally an entity or a relation that links distinct clusters is potentially valuable. The emergence of such items may imply noteworthy novelty. Betweenness centrality can be used to identify bridges or gatekeepers between clusters. The betweenness centrality metric is defined for each node also possible for each link in a network. The metric measures the probability that the node or the link is in the middle of an exclusive path connecting other nodes or distinct areas of a network. The higher such a probability is the higher the centrality value is. High betweenness centrality values identify potentially revolutionary scientific publications as well as gatekeepers in social networks. Other types of centrality measures are also available including the power centrality introduced by Bonacich in Power and centrality A family of measures American Journal of Sociology Vol. 92 pp. 1170 1182 1987 and PageRank. The strategically significant positions of these bridges and gatekeepers should be closely watched as these are the important candidates to be featured in systematic reviews of the subject matter. For example in the unique positions of the three highlighted nodes of high betweenness centrality make them more likely to host novel ideas than other positions in the network.

The novelty of a connection made by an article in a co citation network reflects the potential novelty of the underlying idea with reference to the structure prior to the publication of the article. Modularity variation rate Modularity inter cluster brokerage and centrality variation divergence Centrality are introduced herein as novel metrics of structural variation. The first two are defined based on the cluster structure of the underlying network whereas the third is defined based on individual nodes. These three measures are referred as intrinsic measures of creativity. For comparison the number of cited references NR and the length of each article in terms of the number of pages Length are also included because they are among the most commonly used predictors of future citations of an article. These two measures are referred as extrinsic measures.

 is defined to measure the novel associations added across aggregations of nodes. First decompose G V E to a set of clusters. C in this case Cis a co citation cluster. Given a cluster configuration the modularity of the network can be computed. The modularity measures whether the network can be decomposed nicely with the given clusters. A high modularity means that the given cluster configuration can divide the network into relatively independent partitions with few cross cluster edges. In contrast a low modularity means that the given cluster configuration cannot divide the network without many cross cluster edges. If a new paper s adds an edge connecting members of the same cluster it will have no impact on the modularity. It will not make any difference to the value of . On the other hand if s adds an edge between different clusters and the two clusters are previously not connected the modularity of the new structure will be lower than that of the original structure.

The modularity of a network is a function of a set of alternative partitions of the network. Some partitions lead to a higher modularity whereas others lead to lower modularity scores. The optimal partition can be determined based on the variation of modularity scores over different partitions of the same network. Since the maximum modularity implies the maximum separation of various network components it is often used as a criterion to choose the corresponding clusters as the most representative solution.

The modularity variation rate of an article a is defined to capture the extent to which the modularity of the co citation network changes as a result of connections made by a particular article. This definition assumes that the network is decomposed into a number of clusters.

Inter cluster brokerage is also defined as the basis of a network decomposed into clusters. For each article a this metric is defined as follows 

The function scores 1 if the article a adds a link between references i and j across different clusters. The score is weighted by the overlap between the corresponding clusters . This metric takes the position of each node in the network into account. It is defined according to the change of centrality scores of all the nodes in the network. The node centrality of a network G V E C G is a distribution of the centrality scores of all the nodes where cis the centrality of node n and n is V the total number of nodes. The degree of structural change E can be defined in terms of the K L divergence this metric is denoted as .

Temporally it is more valuable to identify an entity or a relation as part of an emerging trend rather than an isolated event. Burst detection determines whether a given frequency function has statistically significant fluctuations during a short time interval within the overall time period. Burst detection is valuable for citation analysts to detect whether and when the citation count of a particular reference has surged. It can also be used to detect whether a particular connection has been significantly strengthened within a short period of time. The notion of burst detection provides a useful candidate for identifying the temporal aspect of novelty. The goal of burst detection is to identify a particularly intensified attention spell directed towards an entity or a relation with respect to others during the same period of time. illustrates the burst of a function f t over time. Burst detection algorithms such as the one described by Kleinberg in Bursty and hierarchical structure in streams Proceedings of the 8ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pp. 91 101 ACM Press 2002 may be used in an exemplary embodiment of the invention as described herein.

The third aspect of novelty is semantics. An idea that either is introduced for the first time or that contradicts previous or existing beliefs defines a semantically novel idea. The semantic novelty of an entity or a relation can be identified by algorithms that model ontological relations based on natural language processing techniques. For example when the term gastric bacteria was first mentioned it contradicted the then contemporary knowledge that bacteria cannot survive in gastric organs. The appearance of the two words gastric and bacteria can be used by algorithms to construct a knowledge representation based on published articles on a given topic. If a particular instance is not found in the existing knowledge representation then it is likely to be semantically novel. The coverage and accuracy of novelty detection can be improved by using domain independent resources such as WordNet and domain specific controlled vocabulary systems such as the Metathesaurus in UMLS so that different expressions of the same underlying concept in natural language text can be detected.

As illustrated in if the connection between a square and a circle has never been documented in scientific literature the relation is regarded as semantically novel. The degree of novelty can be measured in terms of the likelihood that such relations exist based on their distance in the knowledge representation. A semantic distance is defined as the least number of links along the shortest path connecting two entities in an ontological representation e.g. a hierarchical structure of concepts.

It is possible to define integrative metrics of saliency novelty and significance by incorporating each individual metric. For example a sigma metric a has been derived by Chen et al. in Towards an explanatory and computational theory of scientific discovery Journal of Informetrics Vol. 3 3 pp. 191 209 2009 to identify transformative research scientific novelty by combining betweenness centrality and burstness as 1 18 With the definition as Equation 18 the transformativeness becomes equivalent to betweenness centrality plus one if no burstness is detected. Holding the burstness constant the higher the betweenness centrality and the stronger the indicator of the potential of being transformative. Similarly holding the betweenness centrality constant the stronger the burstness and the stronger the indicator. By defining sigma in this manner the brokerage mechanism plays a more prominent role than the rate of recognition by peers.

In Chen et al. 2009 the inventors also proposed a generic method of combining multiple metrics using a geometric mean. For example suppose there are n metrics i 1 . . . n. The geometric mean is defined as follows 

The procedure for cluster labeling and summarization is slightly different between text only and cited references.

First assume that the input data contains text only with no cited references. In this case networks should be derived from the input text. Entities are units of text such as terms and passages extracted from text as well as documents and or metadata such as controlled vocabularies assigned to the text. Relations in such networks include co occurrence similarity or probability measures derived from syntactic statistical and behavioral patterns using methods such as vector space models latent semantic indexing probabilistic latent semantic index and more generic non negative matrix factorization NNMF and tensor factorization models.

The source text for labeling and summarizing a cluster is the same source of text with restrictions as follows. Given an identified cluster C its labeling and summarization source text Text C is made of all the documents dD that contain a sufficient supporting evidence of entities and relations in the network. The level of sufficiency can be determined either based on a predefined threshold f or a statistical significance level p i.e. v d Ci f v p v p0 v d Ci f v p v p0. Thus Text 20 

Second if references are available in the source data two alternative ways of choosing a body of source text become possible for Equation 20 Text C Text C and Text C Text C . Text C Text C consists of text of citers to members of the cluster C r s and it is more suitable to represent the impact of the cluster on subsequent research. In contrast Text C Text C forms by text of cited references r thus it represents what the cluster is about. Note these two are not necessarily always the same. Text cites 21 Text bibliography 22 

Each of such Text C can be processed as a whole by statistical methods linguistic methods or a combination of both so as to reduce its dimensionality. The objective of the dimensionality reduction is to identify the top k most significant factors or components that can adequately cover the essence of the cluster. It should be sufficient to limit the k to the first three dimensions which correspond to the three most important aspects of the underlying cluster.

Statistical dimensionality reduction can be achieved by using standard information retrieval models such as the simple bag of word models vector space models or singular value decomposition SVD of term by document matrices or non negative matrix factorization. For example SVD can approximate an otherwise large matrix with a truncated matrix with less amounts of noise.

Linguistic patterns based on part of speech POS tagging can identify phrases more naturally than bag of word models. For example a noun phrase can be identified by the pattern of adj. noun or noun to capture phrases like gastric bacteria or cancer cells.

Equation 23 illustrates how a cluster can be characterized by a subset of major dimensions Text biological weapons medical response 23 A cluster s label can be selected from either a single dimension or a composite of terms from multiple dimensions.

In an exemplary embodiment candidates of cluster labels are selected from ranked lists of noun phrases and index terms of citing articles of each cluster. Candidate terms can be ranked by different algorithms. They can also be ranked by a consensus based algorithm that synthesizes rankings from individual algorithms. For example noun phrases extracted from titles and abstracts of citing articles can be selected from ranked lists generated by term ranking algorithms such as tf idf Salton et al. A Vector Space Model for Information Retrieval Communications of the ACM Vol. 18 11 pp. 613 620 1975 log likelihood ratio LLR tests Dunning. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics Vol. 19 1 pp. 61 74 1993 and mutual information MI . Labels selected by tf idf weighting tend to represent the most salient aspect of a cluster whereas those chosen by log likelihood ratio tests and mutual information tend to reflect a unique aspect of a cluster.

Summarization of a cluster can be achieved by enumerating major dimensions by selecting sentences from each dimension or by automatically generating sentences based on corresponding knowledge representations. Specifically the most representative sentences can be selected as follows to represent one dimension identify the terms that are most characteristic along this dimension e.g. in terms of the strengths of their projections on the dimension. Then highly representative terms are used to find sentences that are associated with such terms. For example selected sentences can form a network. Each sentence is a node. The connection between two sentences indicates how similar they are e.g. as measured by Jaccard similarity or projections based on eigenvectors of the corresponding matrix. Taking the network of sentences as the input sentences of the following type are chosen the sentences that have the highest degree which are the sentences most central to this particular dimension of the cluster OR the sentences that have the highest PageRank or other centrality scores. Selected sentences then form the summary of the dimension. Alternatively summarizations can be constructed by automatic sentence generation based on knowledge representations such as Bayesian belief networks and or semantic networks of predicates extracted from text.

Transition sentences that link different dimensions are selected as follows. Take sentences for all dimensions and construct a network of sentences. Sentences of high betweenness centrality will be chosen as transition sentences.

The summarization process is iterative in that each cluster is summarized based on summarizations of its component dimensions. At a higher level all clusters as a whole are summarized in terms of clusters and interrelationships among them.

The goal of the final stage of the procedure linearization is to generate narratives of individual clusters at least the largest K clusters and their interrelationship . The linearization mechanism traverses the synthesized network of knowledge and provides summarizations of its structure and trends at multiple levels of abstraction namely prominent members of clusters clusters and the system of clusters. The linearization can be made to comply with predefined templates for example of narratives in chronological order in the size of specialties in the order of novelty or a nested combination.

1. Construct a time series of networks of terms and cited references with a time slicing of 1 year intervals.

4. For each cluster apply dimensionality reduction techniques to identify up to three most prominent dimensions factors or principle components.

5. For each cluster choose labels and select summarization sentences sentences with the highest degrees. PageRank or other centrality scores to form narratives for the cluster See .

6. For each cluster generate the narratives in the following order a description of the most prominent dimensions and key members of each major dimension the earliest the most frequently occurred the most highly cited or the fastest growing .

7. At the overall domain level generate the narratives in the following order start with the largest cluster and expand its narrative generated in step then move to the next largest cluster until either 80 of the total nodes in the synthesized network are covered or top 20 of the clusters covered whichever is reached first. Splits other than 80 20 can be used as needed.

In addition to automatically generate a template filled systematic review of a domain the procedure of the invention can support the creation of interactive online exploration of the domain with multiple level interactive and coordinated views. illustrates an illustrative interface design for exploring the source data.

The systems and methods of the invention are preferably implemented in software executed by a processor of a computer system of the type illustrated in . The hardware system will be described in connection with and then the overall procedure as implemented in software will be described with respect to .

The personal computer may further include a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media. The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media provide non volatile storage of computer readable instructions data structures program modules and other data for the personal computer .

Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it should be appreciated that other types of computer readable media which can store data that is accessible by a computer may also be used in the exemplary operating environment. Such other types of media include a magnetic cassette a flash memory card a digital video versatile disk a Bernoulli cartridge a random access memory RAM a read only memory ROM and the like.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the personal computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite disk scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor a personal computer typically includes other peripheral output devices not shown such as speakers and printers. The exemplary system of also includes a host adapter a Small Computer System Interface SCSI bus and an external storage device connected to the SCSI bus .

The personal computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the personal computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the personal computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the personal computer typically includes a modem or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media include both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media include but are not limited to RAM. ROM EEPROM flash memory or other memory technology CDROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Combinations of any of the above should also be included within the scope of computer readable media that may be used to store source code for implementing the flow charts described in detail below.

As illustrated in the input data may contain two major types text and citations of the scientific literature of a research field. Citations are also referred to herein as cited references and may not always be available from a given data source. The type of data is thus selected at step and the flow branches to Step or Step depending upon the availability of citation data. Step may utilize the results of Steps and or of Steps through to summarize the clusters. Narratives on the citation shaped structure are generated at Step and or narratives on semantic contents are generated at Step . The final output of the procedure is an automatically generated structured systematic review of the research field as generated at Step . The process of will be described in more detail below where each numbered step in is shown in an individual flow chart in .

Individual networks from all the time slices scaled or non scaled are merged at step .. Networks are merged with an optional local network scaling applied to the overlapping sub networks. It should be noted that network scaling can be applied to the merged network . . as well as individual networks . . A technique for time slicing and merging adjacent networks is described for example by Chen in Searching for intellectual turning points Progressive Knowledge Domain Visualization Proc. Natl. Acad. Sci. USA Vol. 101 suppl. pp. 5303 5310 2004 . The contents of these citations are hereby incorporated by reference in their entireties. Sample pseudo code of merging networks includes 

Accordingly a network with a higher modularity is structurally better defined. A cluster configuration with a higher mean silhouette score is of high homogeneity in terms of the relations between the members of a cluster and other connecting clusters. These metrics can be used to guide the refinement of the clustering quality until the results are satisfactory. Alternatively predefined parameters can be used based on empirical heuristics to avoid any human intervention at runtime. A description of using a non overlapping clustering algorithm spectral clustering and the use of modularity and silhouette metrics is described in the context of labeling co citation clusters by Chen et al. in the Structure and Dynamics of Co Citation Clusters A Multiple Perspective Co Citation Analysis Journal of the American Society for Information Science and Technology 2010 submitted .

Each co citation cluster corresponds to two sets of items cited members and citers to these members. The cited members of a cluster are identified at step . and the citers to a cluster are identified at step .. They are treated differently by sub processes starting with steps . and . respectively. Usually cited items contain a lesser amount of information than citing items which is the case for the Web of Science Scopus and Google Scholar the three most widely used sources of literature data. Data enrichment at step . is thus optional for retrieving additional information for cited items so that they have the same level of detail. Both cited items and citing items contain text data notably in terms of abstracts titles and to some extent the full text. The summarization process branches off to two possible routes summarization based on structural and temporal properties at step . and summarization based on text analysis including natural language based summarization See Steps through of . The summarization based on text analysis may treat the cluster as semantic networks of concepts and assertions as illustrated at step ..

To summarize structural and temporal properties of a cluster the cluster is treated as an associative network and metrics of saliency and novelty are computed at step .. Saliency metrics may include the total number of citations received by cited items the total number of collaborating papers published by authors and the frequency of term occurrence. As noted above saliency metrics aim to identify prominent items to the associated scientific field while novelty metrics aim to measure the extent to which an item is new with respect to the existing time frame of analysis. Useful measures include the degree of sudden increases of access or citation so called burst and the recentness of an item when it is published for the first time . Items in each cluster are ranked by these numerical metrics at step .. The summarization of the cluster at step . consists of narratives that run through the ranked list of items according to the descending order of saliency and novelty. Users may configure the system so as to start with saliency features or novelty features.

A cluster may be referred to either by its serial number or by labels chosen for the cluster. Cluster labels can be chosen based on the most frequent or most common terms found in its members or based on available indexing models such as vector space models or variant versions such as latent semantic indexing probabilistic latent semantic indexing or non negative matrix factorization. Statistical term distribution models may be also used to choose a cluster label. Log likelihood ratio tests and mutual information are possible term ranking mechanisms. Once candidate terms are ranked top ranked terms are chosen as the titles of clusters.

The following patterns illustrate the pattern matching technique that can be used for Step illustrated in . These patterns are defined hierarchically. Complex patterns are built on simple patterns. The syntax follows the Java language.

Semantic networks generated at . can be stored as a network or a hierarchical structure. In order to be stored as a hierarchy head nouns are treated as parent nodes and their attributive nodes are treated as children nodes. For example algorithm is the parent of new in the above example. Similarly we is the parent node of propose which is in turn the parent node of algorithm. 

A new semantic structure can be merged with an existing semantic structure at .. For comparative studies it is often useful to differentiate two different sources. Two semantic components from two different sources may be related in two possible ways 1. The two components overlap 2. The two components do not overlap. Merging two structures can be done by merging common ancestor nodes up to where they differ. For example merging we propose a new algorithm with we propose a faster algorithm would align we propose and algorithm but branch off to two different nodes new and faster as the children nodes of algorithm. Sample pseudo code for a pattern matching routine is set forth below 

Merged structures contain assertions further annotated by concept trees for example we propose algorithm a new b faster. The saliency of such structures can be derived from the saliency of corresponding assertion and concept components. The novelty measure can be similarity derived. Narratives of the top ranked concepts . assertions . and items . are generated and all narratives for both types of patterns are merged in a user predefined order at . for example narratives of concepts first then narratives of assertions and finally both. The following is an illustrative example 

The final step of generating systematic reviews Step of is illustrated in . The goal is to merge the narratives of two types of data citation based and content based summaries. The order of the appearance between citation based and content based summarized can be predefined by users for example citation based summaries to be followed by content based ones. Corresponding references will be inserted into narratives accordingly.

As illustrated in the process of generating systematic reviews includes retrieving the citation based narratives at step . and retrieving the content based narratives at step .. The retrieved narratives are matched with corresponding references at step . and arranged at step . and automatically generated systematic reviews are exported at step .. The resultant automatic systematic review consists of summaries of the main intellectual structure defined by citation behavior of the corresponding scientific community and summaries of contents in terms of salient and novel concepts and assertions made by citers as well as cited articles. The systematic review identifies key components of a scientific field. It will serve either as a jump start for additional manual refinements or as a machine generated and periodically renewed systematic review.

It should be understood that this invention is not limited to the particular embodiments disclosed but it is intended to cover modifications within the spirit and scope of the present invention as defined by the appended claims. All such modifications of the invention are intended to be covered by the appended claims.

