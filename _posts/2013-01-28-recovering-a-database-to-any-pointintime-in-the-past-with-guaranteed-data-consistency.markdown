---

title: Recovering a database to any point-in-time in the past with guaranteed data consistency
abstract: A data management method wherein a real-time history of a database system is stored as a logical representation and the logical representation is then used for any point-in-time recovery of the database system. More specifically, a method for capturing transaction data, binary data changes, metadata, and events, and for tracking a real-time history of a database system according to the events. The method enables tracking and storing of consistent checkpoint images of the database system, and also enables tracking of transaction activities between checkpoints. The database system may be recovered to any consistent checkpoint or to any point between two checkpoints.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08712970&OS=08712970&RS=08712970
owner: Dell Software Inc.
number: 08712970
owner_city: Aliso Viejo
owner_country: US
publication_date: 20130128
---
This patent application is a continuation of U.S. patent application Ser. No. 12 099 837 now U.S. Pat. No. 8 364 648 filed Apr. 9 2008. U.S. patent application Ser. No. 12 099 837 is based on and claims priority to Ser. No. 60 910 718 filed Apr. 9 2007. This application incorporates by reference the entire disclosure of U.S. patent application Ser. No. 12 099 837.

Ser. No. 10 841 398 filed May 7 2004 titled Method and system for automated no downtime real time continuous data protection 

Ser. No. 10 842 286 filed May 10 2004 titled Method and system for real time event journaling to provide enterprise data services 

Ser. No. 10 863 117 filed Jun. 8 2004 titled Method and system for no downtime real time continuous data protection 

Ser. No. 10 862 971 filed Jun. 8 2004 titled Method and system for no downtime resynchronization for real time continuous data protection 

Ser. No. 11 185 313 filed Jul. 20 2005 titled Method and system for virtual on demand recovery for real time continuous data protection 

Ser. No. 11 123 994 filed May 6 2005 titled Method and system for moving real time data events across a plurality of devices to in a network for simultaneous data protection replication and access services 

Ser. No. 10 943 541 filed Sep. 17 2004 titled Method and system for data protection and Ser. No. 11 638 253 filed Apr. 26 2007 titled Method and system for managing real time data history of a file system. 

Unlike a regular application that saves its contents in a file a database is a structured logical data store that usually stores its data set in multiple files or storage volumes. A database may be a relational database an object oriented database an email server such as Microsoft Exchange or a content management database. In a typical database server there may be one or multiple databases in some cases some databases are for storing configuration information and others for user data.

In a relational database server there are system tables and user defined tables. System tables contain configuration data and user defined schemas whereas user defined tables typically contain user and business data. For example a customer database would contain customer data while the structure of the database e.g. name phone number etc. is stored in the system tables in the form of schemas. In some database servers all tables are stored in one database while other database servers store system tables and user tables in multiple databases.

Although each database has its own files or storage volumes the databases served by one database server as a group may be interrelated. For example if a user table schema is lost from the system tables the user data would not be accessible from the user defined tables. Therefore the success of a data protection i.e. backup and recovery solution in recovering a database or a database server lies in its ability to reconstruct one or more related data sets to a consistent state when all the related files and devices are in synchrony at that recovery time point. When the data state of a database or a related set of databases of a server is not in synchrony the data sets would be incorrect or corrupted and may become inaccessible by the database server and thus inaccessible by the associated applications and users .

A database may store its data in a file system or directly into raw storage volumes. These data include the binary data e.g. tables for relational databases and a transaction log write ahead log . A database may store its transaction log in the same device or file system with its binary data or it may store its log in different storage devices or different file systems. The files of all databases that belong to the same database server may reside in the same or different file system or device. As mentioned a database data set can be stored either in files or in storage volumes for simplicity the following sections refer to database store as files.

Conventional data protection solutions for backing up and restoring a database server include scheduled tape based archiving and volume based snapshots. Although in most cases these solutions provide consistent recovery they cannot eliminate or minimize data loss when failure occurs. They also do not address application downtime during data recovery. Over the last several years disk block base real time journaling solution has emerged which attempts to minimize data lost. A block based real time journaling solution is commonly known as Continuous Data Protection CDP . Although addressing data loss CDP cannot guarantee recovery consistency and integrity.

Currently tape archive database protection solutions usually are scheduled to run once or twice a day while a database server is either shutdown or in quiescent mode hot backup mode during which the databases of the server is in consistent state.

Usually a database vendor provides a specific application programming interface API for the archive solution vendors. These API are designed for the following purposes 1 to enter hot backup mode unless cold backup is carried out i.e. server shutdown 2 to retrieve full copy of binary data and log files 3 to retrieve changes to binary data of a database after the last archive for incremental backup 4 to retrieve log changes of a specific database after the last archive 5 to restore a database from the backup media and 6 to apply incremental backup to a restoring database.

With the above API tape backup vendors provide tape archive solutions. A database administrator may use a tape archive solution to perform a full archive once a week and then perform daily incremental backup. The database administrator may also use a script to archive log files in hourly bases or once several hours .

When recovery is necessary the tape archive solutions provide a user interface for a database administrator DBA to restore the databases of a server from a full backup tape set. After that the DBA may have to apply incremental backup tape set manually. The final step is to roll forward the archived log to bring the database server to a point in time closest to the failure point.

There are many well known problems with using tape archive solutions for backing up and recovering a database server. First databases must be copied in full and then in change incremental from the host server to the tape media upon schedule. During copying this large amount of data the database server is either shutdown or in a much degraded mode for a long time period. Second data is at risk in between backups. Third recovery is manual in many cases incremental recovery is necessary. The log roll forward is also manual. The entire restoring process may cost hours if not days of downtime depending on the data set size and the scale of incremental recovery and log roll forward. In addition data retrieval from tape media is slow unreliable and error prone. In some cases recovery fails because of tape mishandling or media failure.

Volume snapshot solutions are designed to address the shrinking tape backup window copying of data to tape with a limited backup window and to eliminate manual incremental recovery because incremental backup is unnecessary.

There are many volume snapshot techniques such as split mirror copy on write and so on. These techniques offer different resource usage optimization and snapshot efficiency. The objective of all snapshot techniques is the same which is to create a point in time storage device image. Unlike tape archive solutions a snapshot usually can be taken with much shorter time some volume snapshot techniques can complete a snapshot within seconds. To generate consistent snapshots most snapshot services involve a quiesce of a database server so that the server first flushes out its updates to the storage from system memory to make a persistent copy of its databases consistent and then freezing of I O activities during which a volume snapshot can be taken. When a snapshot is taken without quiesce of a database server i.e. a hot snapshot the disk images may not be consistent and may not be usable for recovery. In particular the image may include fracture blocks which cannot be used for recovery.

Because database files may be stored in multiple storage volumes a consistent database snapshot requires that all volumes be captured at the same moment i.e. consistency group otherwise the snapshot would not be useful for recovery. Some snapshot solutions are not capable of capturing consistency group.

During recovery if a snapshot image is consistent and non corrupted the snapshot image can be copied to a recovering server and the database server can be started from that recovered data. After that if there are archived logs the log files can be used to roll forward the binary files manually. If a hot snapshot is taken the database administrator must first copy the databases into a recovering server repair the databases and perform verification test. If the repair is successful the database server can roll forward the binary files using archive log files. In case the image is not repairable another point in time snapshot must be selected and the entire copy repair and verification process must be repeated.

Because snapshot is still schedule based in between snapshot intervals there are still risks of losing production data. Although a snapshot can be taken very quickly there is still requirement to quiesce a database server to get consistent snapshot image therefore there is still server performance impact. When hot snapshot is taken server performance impact is eliminated however that results in potential inconsistent snapshot images and increases recovery downtime as data repair and verification may be needed. With a volume snapshot approach the entire recovery process is still manual a database administrator must know which snapshot volume has what data and reconstruct the database storage volumes manually. This gets harder when database binary data and transaction logs are stored in distributed volumes. The entire recovery process may takes hours or days and it involves identifying the snapshot volume image set copy back the snapshot volumes into the right storage devices repairing and verifying the integrity of the database bring up database server and manually roll forward the necessary archived log.

A traditional real time protection approach known as continuous data protection CDP is used to capture all the storage block changes of the primary storage devices that store the databases of a database server. The primary goal of this approach is to eliminate data loss causes by scheduled backup.

This approach involves first making a full image of the storage volumes that belong to a database server. After that it continuously records all the block changes persistent storage updates as it occurs during runtime. Periodically another full image may be taken. The storage for recording the block journal is known as time addressable storage. Because the block updates are recorded continuously as they occur one can reconstruct a storage volume from the time addressable storage to any point in time by applying block changes to an initial full volume image. The reconstructed volume however is similar to a volume image taken from hot snapshot see above as the database server is most likely not in quiescent state therefore the database is most likely not in consistent state and the data may be corrupted if fractured blocks are captured at that point in time.

Some CDP allows a database administrator to save a marker on the time addressable storage in which case a database administrator can quiese a database server and put a tag on the CDP storage to indicate that at that specific moment in time the volumes are in consistent state and the data is non corrupted. The point in time tagging of the storage images is no different than a consistent snapshot. If only these tagged images are used for recovery the benefit of performing real time protection is not realized.

When recovery is needed for a specific point in time a full image volume set from the time addressable storage that is closest to the recovery point can be copied to the appropriate primary storage volumes of the database server. After that the necessary recorded block journal can be applied to the recovering volumes to bring its state to a point in time.

Because the continuous journal of the primary storage results in continuous hot snapshot images being stored one cannot guarantee that a recovered database server from the time addressable storage is non corrupted. Therefore recovery could be a process of trial and error first a database server data image is reconstructed from the time addressable storage second a database integrity verification process would determine if the database can be repaired. If the recovered database volumes are found to be corrupted another point in time must be picked and the process starts again. The entire recovery process is no better then recovering a database from snapshots in fact in many cases it could be worst. When logs and binary data are stored in multiple distributed volumes the volume reconstruction process must be manually managed to ensure that all volumes are recovered correctly. When consistency tag is applied on the time addressable storage then the recovery result is no different then taking periodical consistent snapshot. In addition time addressable storage requires huge amount of storage space to continuously track the block changes.

The conventional approaches described above are not able to reduce data loss to near zero indeed even when CDP attempts to record block journal continuously data loss may still occurs when a consistent database server cannot be reconstructed. IN attempting to reduce data loss CDP however greatly increases backup storage cost and still cannot guarantee recovery consistency and integrity. All the conventional solutions require intensive manual handling of tape media volume images and archived logs. In addition the recovery process is manual and error prone.

In addition both snapshot and CDP manage data in the block level storage device level without any meta information these solutions do not know when a new volume is added to a database. As a result managing these solutions requires manual work. Further because these solutions do not have knowledge of what is inside the blocks and because they are not capable of providing a backup catalog user interface granular recovery e.g. database files table space transaction etc. is not possible.

This disclosure describes a data management method wherein a real time history of a database system is stored as a logical representation and that logical representation is then used for any point in time recovery of the data set of the database system. More specifically this disclosure describes a technique for capturing data metadata and events and for track real time history of a database system according to events. The technique enables tracking and storing of consistent checkpoint images a consistent database version of a database and a database server which may be a set of databases and also enables tracking of transaction activities in between checkpoints. A data management system DMS object hierarchy may be used to implement a data structure for storing and tracking the real time event based history. Once such a history is generated and tracked a database or a database server with multiple databases can be recovered to any point in time in the past with guaranteed consistency. The databases can be recovered to any consistent checkpoint or any point between two checkpoints in which case the state of the databases can be rolled forward from a prior checkpoint to the desired recovery point using either transaction requests or write ahead log entries.

The foregoing has outlined some of the more pertinent features of the invention. These features should be construed to be merely illustrative. Many other beneficial results can be attained by applying the disclosed invention in a different manner or by modifying the invention as will be described.

The subject matter herein may be implemented in a data management system DMS such as the system described in U.S. Ser. No. 10 841 398 filed May 7 2004 U.S. Ser. No. 11 123 994 filed May 6 2005 or U.S. Ser. No. 11 185 313 filed Jul. 20 2005 the disclosures of which are incorporated herein by reference.

The following provides additional background information concerning database system functionality and operations.

A database stores its information in both its log and binary files. When update requests are received the updates are first entered into the log files in the form of a redo journal this is known as write ahead log and the actual binary data modifications occur in the system memory which may be flushed into the binary files in the persistent storage in a later time for better performance.

The flushing of the binary updates from system memory into binary files would cause the binary file s to be consistent with their associated log file s at that instant in time when flushing is completed and before a next activity arrives and is entered into the log files. This consistent moment is known as a database checkpoint during which the database state is similar to or almost similar to when the database is cleanly shutdown. The checkpoint state of a database is a strong consistent state this means if the persistent data at that moment is captured the captured data can be used for recovering the database with guaranteed success. When the updates of a database are flushed into the binary files a marker is entered into the database log. In some databases there may be a separate checkpoint files for recording additional checkpoint information. For better performance some database may not necessarily flush all the binary updates from memory to binary files during checkpoints instead the control information and some updates that are necessary to bring the database to a recoverable and consistent state are written out. In this case the set of related files are also considered in consistent state.

When checkpoint occurs the updates that are flushed from the system memory to the persistent storage may consist of some pending transactions incomplete user transactions . When there are pending transactions during checkpoint a journal of undo entries may also be entered into the log prior to the checkpoint marker for rolling back those transactions in case the database state has to be restored to that checkpoint in the future.

Periodically a database server generates checkpoints based on some parameters such as maximum allowed memory usage and checkpoint interval. The memory updates of a database are either flushed at checkpoint interval or when memory utilization threshold is met. This means that a database with very high write rate could result in more frequent checkpoint then its configured checkpoint interval. Besides a database s internal checkpoints there are many different ways to trigger a database to flush out its cached data and force a checkpoint. One of which is to issue a CHECKPOINT SQL statement another way is to shutdown a database yet another way is to put a database server in quiescent mode by locking database tables putting a database server in hot backup mode or by a specific API provided by a database vender.

When checkpoint occurs or when a database administrator performs a log archive operation a database may reclaim the old log space log roll over or shrink truncate the log files. The database administrator may also expand the log file during runtime.

Traditional tape or disk based backup or snapshot solutions usually once a day e.g. tape or virtual tape library backup or once every few hours e.g. disk volume snapshot copy the persistent data of a database to a backup media. During the copy process it is required that the database state be consistent therefore the copy process is carried out either when a database is shutdown or when a database is in hot backup or quiescent mode during which the database is checkpoint ed and frozen to prevent new updates to enter its files so that its state is clean . In some databases additional changes during backup are not allowed while in some databases all the changes during backup are only entered into the log files. After a backup is completed IT administrators often use a database archive interface to archive the log files generated after the last binary data backup for recovery purposes. Using these traditional methods for backing up data either result in significant downtime or performance impact on the database.

As noted above traditional Continuous Data Protection CDP schemes today capture data in the storage block level as a result they are unable to detect checkpoints and cannot identify real time consistency points. Traditional CDP also does not have capability to capture metadata of a database.

It is known to provide real time database protection using a real time host based driver and an optional storage block level driver to allow for event detection metadata gathering and flexibility of data capturing in either file or block level. By doing so data can be captured in real time and indexed with the metadata and events. In this way a consistency point along the data timeline can be identified and meta information can be associated to and add meaning to the data to allow for granular recovery. A technique of this type is implemented in a data management system DMS that is available from Asempra Technologies Inc. of Sunnyvale Calif. As described in co pending application Ser. No. 10 841 398 the DMS system associates a host driver with one or more of the application s running in the application servers to transparently and efficiently capture the real time continuous history of all or substantially all transactions and changes to data associated with such application s across the enterprise network. This facilitates real time so called application aware protection with substantially no data loss to provide continuous data protection and other data services including without limitation data distribution data replication data copy data access and the like. In operation a given host driver intercepts data events between an application and its primary data storage and it may also receive data and application events directly from the application and database. By intercepting data through the application fine grain but opaque data is captured to facilitate the data service s . The DMS servers provide a distributed object storage that can be built above raw storage devices a traditional file system a special purpose file system a clustered file system a database or the like. As described in co pending application Ser. No. 11 123 994 each DMS node executes an object runtime environment. This object runtime environment includes an object manager that manages the lifecycle of all the DMS objects during runtime. The object manager creates DMS objects and the object manager saves them in the shared storage. The objects continually undergo modification as the system protects data in the enterprise s primary storage. In an illustrative embodiment the system automatically creates a trail of objects called versions typically the versions do not actually exist on primary storage outside of the data management system. The DMS manages the creation storage display recovery to primary storage deletion automatic via policy or manual and the like of these versions. The host drivers protect data into the continuous object data store. Using this architecture data in primary storage can be recovered to any point in time.

As mentioned in earlier sections due to the write ahead log during runtime the state of a database s log is usually ahead of its binary data in the persistent storage. This means that during runtime the binary data and log files of a database are usually in an inconsistent state in the persistent storage. The only times when the state of a database s log and binary files are in synchronous are 1 when a database is shutdown 2 when a database is in quiescent mode triggered externally in the event of hot backup tables maintains etc. or 3 a moment right after an internal checkpoint is completed and before a new activity arrived. When the binary and log files of a database are in synchrony the database is in strong consistency state this is perfect time to capture the database data. Out of the three situations only database checkpoint is generated by the database itself and the frequency of checkpoint can be relatively high. To save a copy of a database persistent data for recovery in a later time and with guaranteed success one could capture a database in a strong consistent state as identified above. A database could also be recoverable if the captured data is in a weak consistency but non corrupted state when its log is intact and ahead of its binary file and the state of its files and database headers are synchronous.

Most conventional data backup solutions capture the database state when the database is shutdown or in quiescent mode for prolonged period of time to make a copy of the database. These solutions are not capable of capturing a runtime consistent checkpoint because a database checkpoint state may exist for only a very short moment potentially a fraction of a second.

With conventional backup solutions the steps to restore a database to a point in time after the last consistent backup are handled manually by a database administrator. When point in time recovery is necessary and when archived log files are available a database administrator typically first recovers a complete database to a point in time closest to the desired recovery point by recovering all the binary and log files from a full backup and then manually applies incremental backups to those files. Once a full database is recovered a database administrator uses the sequence of archived log files which are saved after the last backup to manually roll forward the binary data state. These manual steps can be error prone and time consuming and can take hours or days. The duration of the restoration depends on the number of incremental backups and archived logs. During recovery in some cases the necessary log files may not be available because the files may be corrupted or missing before archive could occur. In such case the data state of the desired recovery point in time cannot be reconstructed and there would be data lost upon recovery.

As noted above traditional CDP capture data in storage volume level and records change in storage block. As mentioned these CDP schemes cannot identify consistency point of the data it captured. Worst yet for large databases a database administrator typically stores the binary data and log data in separate volumes. These separate volumes may be attached to the database host server through the same or different paths. If traditional CDP capture the blocks through different paths they may capture out of order data. For example they may capture binary updates of a partial transaction before any part of the transaction is logged such that undo cannot be carried out during recovery. Therefore traditional CDP not only cannot detect a consistency point they may not be able to recover a database with consistency when they capture out of order data blocks. Even when consistency is maintained in some cases recovery using traditional CDP requires a database consistency verification process which along with recovery of the files may take hours to days.

The subject matter described herein captures data and monitors events in real time therefore it is capable of assembling captured data to form strong consistency when a checkpoint event is detected. It is also capable of reconstructing a weak consistency data set at any point in time by combining a strong consistent copy the database and necessary log entries that include transactions that occur after the checkpoint. The current invention is data aware. In particular it recognizes log files versus binary data files as a result it is also capable of tracking real time redo log entries. These capabilities allow the subject matter herein to enable consistent guaranteed recovery to any point in time.

In particular and as will be described in more detail below when any point in time recovery is desired the technique described herein re constructs a database by combining a consistent database data set and subsequent log entries that contain continuous redo journal occurs after the consistent data set to form a consistent point in time database state. Once reconstructed a database set it allows a database to automatically roll forward its binary data state to the desired recovery point in time. Because the technique described herein tracks database checkpoints and those checkpoints occur frequently the real time redo log that has to be captured between two checkpoints are relatively small. The technique also induces checkpoints as necessary. During recovery when the described technique combines a checkpoint with redo log captured in real time the amount of time for the database to roll forward is almost negligible. When combined with virtual on demand recovery such as described in Ser. No. 11 185 313 filed Jul. 20 2005 the subject disclosure is capable of recovering a database server within seconds regardless of the database size.

As mentioned above a database server may serve one or more databases. In some database servers system tables for storing database control and configuration information may be stored as separate databases while in other servers system tables may be stored together with user databases. As a result when a user database failed one may not be able to recover the data by simply recovering the data and log files of one particular database. In the situation when a database server serves multiple databases in parallel the databases may be interrelated and therefore these databases must be recovered with consistency. In the case when system tables are stored in a separate database the databases of the server must be recovered as a set when all the files are in synchronous otherwise user data could become inaccessible. For example if a user table schema is modified or new user data file is added these changes must be first entered into the system tables before the modification of user data takes effect. In the event when a later set of user tables are recovered with an older set of system tables the user tables would contain data that requires newer configuration information and as a result those user tables might become inaccessible or appear to be corrupted.

Because conventional data protection solutions shutdown or quiese a database server during backup these solutions guarantee the consistency of database server upon recovery. The disadvantages of these solutions are associated with data loss and recovery inefficiency as described in the above section.

Because a database server may have multiple volumes its binary and log files of different databases may be stored in different volumes if traditional CDP capture the databases through different IO paths they cannot guarantee recovery consistency. The shortcomings of these solutions are described in above section.

The current invention identifies consistency point s of an entire database server rather then each individual database within a server. It captures all the databases during checkpoint and it captures log changes through the same data path to preserve the actual write order so that consistency across multiple databases during recovery can be guaranteed.

A database server divides its binary and log files into headers and pages. A database server updates a record header or a page in its entirety i.e. never partial . While capturing database changes in real time for recovery purpose it is important to capture the changed records in their entirety yet at the same time the change order of these records mush be preserved. If change order is not preserved or fractured records are captured a database may not be reconstructed i.e. when put together the data is corrupted . In addition during runtime new binary and log files may be added and these new files may be added to a new volumes. When protecting a database in real time changes to new volumes must also be captured in order to ensure recoverability of the database.

The conventional tape and disk based backup solutions do not encounter this challenge regarding recovery integrity as they do not capture data in real time.

Traditional CDP schemes capture data in block level and often in storage network as a result the captured block may not necessary line up with the records. Also these solutions do not capture meta data and have no knowledge of when new storage is added to the database during runtime. These solutions cannot guarantee recovery integrity.

As will be described the technique described herein captures meta data and captures change records in atomic fashion. It also preserves the change ordering while storing and indexing the change history. When new volume is added to a database the new volume is instantly being protected. As a result recovery integrity is guaranteed.

Based on the DMS continuous object store this disclosure takes a real time database aware data management approach to backup distribute replicate and recover a database or a database server with zero or near zero data lost with negligible server impact guaranteed integrity and consistency upon recovery significantly reduced recovery downtime and significantly eliminate possible human error during recovery. The combination of the current invention and a prior invention on virtual on demand recovery Ser. No. 11 185 313 significantly reduces recovery downtime to the range of seconds rather then hours or days independent of the data set size. Also the combination of the current invention and a prior invention Ser. No. 10 943 541 on two stage delta reduction greatly reduces storage requirements for tracking real time database history.

As mentioned a database may store its data in a file system or directly into raw devices. The following discussion of the current invention uses a file system as underlying data store for databases simply as an example and is not intended to be a limitation. For example when a database is added or expended if a file system is used as the underlying store the file system CREATE event would be detected. If a storage device is used as the underlying store a storage device addition event would be detected. The following discussion uses file system events merely as examples.

The current invention protects databases in real time by streaming real time event journal from a host server where a database server resides to a DMS cluster where realtime database history is tracked and maintained. The current invention can also protect a database by capturing and streaming real time data changes from a network storage device to a DMS cluster.

A real time event journal is also sent from a DMS cluster to another DMS cluster for data distribution and from DMS cluster to another standby host server for data replication service. When recovery is necessary a recovery point of any point in time can be selected in the database history and the state of the data at that desired recovery point is reconstructed at a recovering host server.

The DMS Host driver for providing real time database protection recovery and replication services is platform and database aware. As illustrated in a simple host driver may consist of only one data agent and one I O filter . Alternatively a host driver in may have one control agent multiple data agents and an I O filter . A data agent may protect one or more data sources it may have three modules application module database module I O module and an event processor . The application module is for tracking application meta information. The database module is for tracking database meta information. The I O module is for configuring what I O to monitor and the event processor processes raw events and generates a real time even journal stream.

A host driver in particular the database module is able to determine type of database server the number of databases in a database server to locate the log and binary data files or devices to protect or replicate to look out for new files or volumes that are added to a database server during runtime to watch for changes happen to the log and binary data and to watch for database checkpoint events and to watch for log structure changes. It also forces a database checkpoint as needed for creating a point in time consistent database as triggered by users or user configuration.

A DMS host driver is a finite state machine FSM that with significantly no downtime automatically switches state to upload protected databases protect the data by streaming real time events and information perform resynchronization upon any transfer failure or network congestion recover data as instructed and so on. This technology is described in U.S. Pat. No. 7 092 396. When a host driver data service is initiated the host driver first creates a consistent snapshot of the databases to be protected and uploads to the DMS as baseline. Optionally the host driver may simply upload an inconsistent image as baseline and then follow up with subsequence consistent versions. After upload is completed it watches for I O and database events and streams the data metadata and events to the DMS accordingly. A set of DMS active objects are created by the host driver to receive the real time event journal of the databases and track the real time history of the databases.

In real time the DMS host driver captures log entries in full through I O filter so as to provide any point in time recovery. Periodically upon detection of a database checkpoint a consistent set of binary and log files from the server are synchronized with their associated DMS active objects in DMS cluster to generate new database version. By detecting a database checkpoint rather than frequently forcing database consistency by putting a database server in quiescent mode the DMS host driver significantly minimizes performance impact to a database server. With the combination of the checkpoint data and a real time log a trail of real time history is maintained by the DMS active objects such that the protected databases of a server can be recovered to any point in time in the past with guaranteed strong consistency. The DMS host driver also performs virtual on demand recovery a separate invention that reduced recovery time to seconds regardless of the size of the data sets.

One embodiment of a DMS host driver has a control agent and one or more data agents with each data agent responsible for a protected data source as seen in . Within a data agent one embodiment includes an application module a database module an I O module I O filter and an event processor as seen in . The application module database module and I O module are responsible for configuring or registering to receive application database and I O events. These modules also extract necessary metadata. The I O filter captures data changes. Together the change data metadata and events are processed by the event processor to remove unnecessary redundancy and prepare for the DMS data source to store and index this real time history.

An alternative embodiment allows the components of a data agent to be spread out partially in the protected host server partially in the DMS and possibly partly in a storage switch. shows one possible embodiment where the application database and I O modules reside in the host driver to configure to receive the proper events as well as extracting metadata. The I O filter may reside in the host as illustrated in or it could reside in the storage switch . Alternatively the I O filter could be embedded in yet another appliance attached to the storage switch . The I O filter may capture file level I O file level events storage volume level I O in blocks or storage volume events. In this diagram the storage switch is configured to stream raw information into a queue in the DMS. The event processor in this case can reside in the DMS to process the raw events. Alternatively the I O raw events may be streamed to the event processor by the I O filter from wherever the filter reside.

Database real time event journal includes transaction data binary data changes the metadata information and the events that may or may not be associated with the changes.

Some examples of database events that are associated with database changes include ADDING files or new storage devices CREATE database CREATE log MOVE RENAME relocation of the data set REMOVING files or devices DELETE database file or device OPEN log record WRITE TRANSACTION entry binary data WRITE file or device CLOSE SET metadata database CHECKPOINT BEGIN CHECKPOINT END CHECKPOINT SNAPSHOT log ROLLOVER log TRUNCATE log EXPAND and log ALTER. Log ROLLOVER TRUNCATE and EXPAND are fine grain events that alter the structure of the log files one can simply use log ALTER event to represent any of the collection of log events. CHECKPOINT can be instantaneous or can be a sequence of events BEGIN CHECKPOINT DELTA binary file WRITE binary file SET property and END CHECKPOINT. Also CHECKPOINT events may be generated by a database server trigger by users or other software or hardware applications or utilities. These are some examples of database events in some cases there may be more events in other cases multiple events may be combined into one.

In addition to the above mentioned events DMS also tracks events that may not necessary associate to data changes examples of these events include database server START database server STOP software upgrade virus alert specific user tags and so on. These events can be used as information for administrator to identify a recovery point when recovery is necessary.

Metadata may include location of files which file is for what database which file is binary and which is log the database page size header size header information checkpoint information access control database schema and so on. It is desirable to capture change data according to database page size. If fractured pages are captured a database cannot be reconstructed when assembled using fractured pages the recovered database may be corrupted. The current invention preferably uses the page size meta information for both log and binary data capturing to prevent capturing fractured pages.

The DMS host driver detects and captures the above mentioned events along with changed data. It also retrieves and captures database metadata and then forms and streams a real time event journal to the DMS Active objects. A DMS host driver either resides entirely in a host server or partially in a host server partially in a remote device or the DMS as seen .

The DMS object system typically handles four types of events creation modification termination and destruction events. Creation events cause new DMS active objects to be created. Modification events cause new object versions to be generated. When a new version of an object is generated its previous version is terminated. Termination events terminate the last version of an object and end the history of the object.

Destruction events permanently delete an active object and its entire history in the DMS system. In some cases the creation modification and termination may be triggered by a singleton event in other cases a sequence of sub events is required to cause the DMS object history to change.

For example a new object may be created with a sequence of events such as CREATE WRITE s SET s CLOSE. The sequence of events that creates an object often involve the modification events WRITE SET etc. While modifying an object cause a new object version to be generated. A new object version can be generated by MAKE VERSION while an object is opened and in the middle of an update or OPEN SET WRITE TRANSACTION DELTA LOG ALTER CLOSE. Deletion of an object simply ends the last version and terminates the history so that there will be no new history to add to the object. Terminating an object history could simply be stamping the TerminationDate and Time property of the object and unlink the object from its parent s for the future i.e. unlink from the parent s version pages . Destroying an object from DMS means to completely remove the object from the DMS storage.

An instance of a database data source class i.e. clsDBDataSource as labeled in is used for storing metadata as related to a protected database server. Because a database server may serve multiple databases a database data source owns the one or more database instances clsDatabase . A database instance has a time dimension that is not shown in this object hierarchy diagram. In the time dimension a database instance has multiple versions each version represents a point in time when a database is consistent or the entire database server is in a consistent state. A database version is generated typically when a database generates a checkpoint. A database instance has a number of file objects some of them are binary data files others are log or control data files. The data and control files clsFile are linked directly to the database instance while the log files clsFile in one embodiment can be linked to the database instance via a journal group object instance clsJournalGroup . Optionally the log file instances can be connected directly to the database instance . The advantage of having a journal group is that a journal group instance allows different type of transaction records to be grouped and associated with a database version. Similar to a database object all these objects binary files control files log files and log groups each has a time dimension and each has a trail of versions. All these related binary log and control files may be forced to generate new versions simultaneously when a database version is generated so as to form a consistent image of the entire data set.

A database instance may have one or more journal group instances if multiple types of journal are to be tracked. A journal group instance is for tracking database journal i.e. trail of changes to a database . Database activities can be captured from different sources. One is to capture successful requests from the service interface e.g. an email transaction a SQL statement etc. another source is to capture the binary entries that record in the write ahead journal log files yet another source is to capture activities through a database stored procedures triggers etc.

ClsRecordFile is an embodiment that may be used in a journal group to track application level transactions in the form of SQL statements that may be captured from service interface or a special purpose stored procedure. ClsRecordFile instance and a clsFile instance are embodiments that maybe be used in a journal group one for tracking the meta information about binary log activity another one for tracking the actual data chunks written to the log file.

A journal group is not a requirement for tracking multiple database journal types it is simply one way to isolate multiple types of database journals. The above mentioned object hierarchy for tracking database history is simply an embodiment of the current invention these are not the requirements for storing and tracking database history there are many different ways of tracking and storing journal and binary changes with current invention. For example clsRecordFile and clsFile can be combined to form one single DMS active object i.e. one data structure . Journal group is an abstraction it can be eliminated especially if only one journal type is to be captured. Alternatively journal information can be stored as part of a clsDatabase instance. In another embodiment file system hierarchy with directories sub directories and files can be introduced in addition to database objects for tracking database history.

This disclosure describes a technique for capturing data metadata and events and track real time history according to events. In particular tracking and storing consistent checkpoint images a consistent database version of a database and a database server which may be a set of databases and also tracking the transaction activities in between checkpoints. A data management system DMS object hierarchy may be used to implement a structure for storing and tracking real time event based history of databases. Once such a history is generated and tracked a database or a database server with multiple databases can be recovered to any point in time in the past with guaranteed consistency. The databases can be recovered to any consistent checkpoint or any point between two checkpoints in which case the state of the databases can be rolled forward from a prior checkpoint to the desired recovery point using either transaction requests or write ahead log entries.

A DMS object system is an object database instantiated based on the class hierarchy as shown in . The DMS object system is designed for tracking event based real time information history. In the DMS preferably each object has a set of properties some of the properties are versioned and others are not. In one embodiment as shown in the non versioned properties can be stored in an anchor page a logical structure and versioned properties can be stored on metadata pages and . Additionally more pages can be created for specific data such as ACL and binary data for object schema such as file objects. Binary data includes baseline binary and deltas for tracking binary data changes. The idea is to create a logical structure as an embodiment for the invention. Following are a list of object schemas created for managing real time database and database server history.

A database data source object instance serves as a container for the history of a protected database server. It is also a data service entity for managing inbound data protection stream or inbound distribution stream and outbound for distribution and replication services event stream for the databases. This instance owns one or more databases. It may provide time sequence as index to coordinate the journal activities across all its database instances to ensure recovery consistent across multiple databases.

The properties of this object class include the configuration of the protected database server. Following is some property examples of this object class 

The above table is a subset of properties used in the DMS one may add more or remove some of the above properties. For example there may be more database server configuration information policy for managing the protected data may be added and one may not need RuntimeStates. In one embodiment the properties of this object are not versioned which means that the history of the above properties is not tracked. Alternatively one can version some of the properties such as DB server name DB model DB version DB checkpoint timeout ProtectedDateTime ArchivedDateTime and Children so that these configuration changes are recorded in time. When properties are versioned it would also make sense to track the version begin and end timestamp.

ClsDatabase schema is defined for tracking the history of a database of a database server. There may be one or more instances of clsDatabase in a clsDBDataSource history of a database server . A database object has a set of binary files control files and write ahead log files. A database object may also track real time application requests in SQL statement email etc. or any specific redo activities. This object tracks database checkpoints. When a checkpoint occurs a version of the object is created to represent a consistency point. Within the version all its files and journals are versioned as well to form a consistent and clean point in time image. Note that versioning is one way of indexing in the DMS it allows for fast traversal on a time line.

Because a data source may have multiple databases a database object also coordinates with other databases through its data source object to generate a consistency group index for cross consistency.

This disclosure is capable of creating different types of cross consistency indexing models i.e. consistency for the entire data source three examples are shown in and .

Other consistency models can be created by mixing and matching these three models. For example an older database history may use a cross consistency model of while the most recent history uses the any point in time consistency model. There can also be a model wherein a first subset of the databases uses the model of and a second subset uses the model of . Because the model in is a superset of that in the resulting consistency point is the same as that of .

These properties are example of database object schema there can be more or some properties in the table may be eliminated. For example one may include more properties such as data management policies file name metadata from the host server and more. Because it is not the purpose of this application to discuss index and search the index able attribute are intentionally not mentioned.

In this embodiment a database object has one or more journal group object s for managing one or multiple types of journals between two checkpoints. Each journal group manages only one type of journal. For example binary journal group contains write ahead log files which track binary data changes associated with transactions. Yet another example is application level transaction in term of SQL databases it could be a journal group with a record file object that tracks all the SQL UPDATE statements that are successfully executed by the protected database server.

A database can be versioned each version contains a set of version able properties. When a database is versioned all its children are versioned. This allows the cross consistency model as depicted in to be achieved. The journal groups of a database can be versioned without versioning a database. In this case the binary files of the database are not versioned but the journal groups and all its associated log and record files are versioned. This allows the cross consistency model of to be realized. By including the sequence number as a property in the database and a record entry of the journal the any point in time cross consistency model of can be accomplished.

Event tag is an array of symbols or text information with a timestamp to index all events host system events database events not those already indexed network events DMS events user entered events etc. For example quarter closing virus detected system patched new software installed data downloaded etc. . . .

The other journal group tracks SQL requests between two checkpoints. Another way to reconstruct a point in time data state is to use a closest checkpoint all the database files at the checkpoint are required and apply the necessary SQL requests recorded in this journal group to arrive at the desired state. Only one journal group is necessary for recovery.

A different embodiment is possible for any point in time recovery and real time data services as long as transaction log are captured continuously or frequently and the data set is checkpoint ed either planned or unplanned. For any point in time recovery a different embodiment is possible as long as data at a checkpoint can be indexed and reconstructed and necessary transaction records at the write ahead log level application request level or archived level can be applied to the reconstructed checkpoint.

In this embodiment the transaction activities are tracked by journal groups which are children of the database objects. shows only the database objects without its next level down in the hierarchy. The entire hierarchy of a database object is shown in and is similar to and the database versions and in is similar to the database versions in . The binary files journal groups and log files that are not shown in would be similar to those in .

In this disclosure as noted above cross database consistency can be managed in many different ways and show three different consistency indexing models. shows the object version view based on the consistency indexing model of . In this model all databases are versioned at once i.e. the versions are aligned see where is aligned with is aligned with and is aligned with . The object version view for consistency indexing models of are different than that shown in . In these latter two models the versions of the individual database objects are not necessary aligned as seen in . However the activities that include database versioning journal group versioning and transactions are sequenced so that consistency and integrity across databases for the entire data source can be guaranteed.

In this embodiment clsJournalGroup is a schema for tracking database activities in sequential order and to version a log file as needed. Database activities can be captured and journal in many different forms. For example one can capture transaction requests as SQL statements while the requests enter a database server one can capture transaction operations via a store procedure installed in a database server or one can capture database update from write ahead transaction log files. For the purpose of any point in time recovery only one form of journal is enough although a version of log file at every checkpoint is always necessary for a database recovery. After that a journal of any form can be used to roll the database forward. An instance of a journal group is a container for storing one and only one form of database activities. This disclosure allows one or more form of database journals to be captured stored and indexed via multiple journal group objects.

One alternate embodiment is to simply use a directory for separating the different form of journals. Yet another embodiment is to simply save all forms of journal directly within a database object container and allow the database object to manage the differences.

ClsFile is a schema which can be used for storing and tracking the database binary files control files and log files. As mentioned in earlier section although refer as files in this section these files may be contiguous raw device blocks.

The above table is one example of what a file object may contain. One may include more properties such as a full path name policies etc.

The non versioned properties include timestamp when the object is created its creator access journal for forensic purposes and event tags for tracking user events across time line.

The versioned properties include name modification information status ACL and content. Whenever the name of the document changed the content of the document changed the ACL changed document metadata or attribute changed or when the document is moved a new logical version is created. Whenever the document is deleted from the protected data source the file object at the DMS is terminated with DateTimeTerminated timestamped and the last version ended.

In the DMS file object on each version preferably there is a property called CONTENT and this property is of the type random access binary blob. The binary value of this property type may be stored inside or outside of the metadata page. In this case the binary data of version 1 is in the Binary Page which has its own GUID. The changes deltas that are made to the file for version 2 may be stored as a sequence of forward deltas in the Delta Page . The changes deltas of version 3 may also be appended to the same delta page or another new delta page. A file object may have one or multiple binary pages. The binary pages contain the baseline data. A file object also may have one or multiple delta pages for all its changes. The sparse index refers to the data in both the baseline and the deltas to make up the content for the version. Both the Binary and Delta pages may be stored in one physical storage unit be broken up and stored in multiple physical storage units. This is simply one embodiment of the DMS in structuring the binary data. Alternatively each version may have its own binary pages so that no delta has to be kept. Yet another alternative is to store reverse deltas. It is not the purpose of this document to discuss the physical structuring of the binary data.

The file object structure and its metadata allows one to track a file history on what information has changed at what time by whom through what event and what meaningful events to this object occur during the lifecycle of this object. This file object also optimized storage usage by using sparse index.

ClsRecordFile is an object schema for recording a sequence of records. Each record can contain anything ranging from an event a point in time reference to another object meta information to raw data. The content of a record can have its own schema definition . A journal group object may use a record file object to record a contiguous list of transactions or a list of reference to the binary transaction in a write ahead log file. A record may contain a sequence number or a timestamp that can be useful during data recovery to identify a desired recovery point. Once a recovery point is selected the DMS uses the closest database checkpoint for recovery and then roll forward the remaining transactions according to a records file to arrive at the desired state.

In each of the records there is a record header. A record header may include sequence number timestamp size of the record type of the record and the like.

A database server may serve one database e.g. Oracle or multiple databases e.g. MS SQL . When a server serves multiple databases it is important to create and index data history with consistency tracking. As noted above preferably one or more consistency models can be created in the DMS. In particular in the DMS objects and object versions can be captured and indexed to form a continuous history as illustrated in and each of which represent a consistency model.

The three diagrams show the flexibility of the DMS object system in storing and indexing database history. One preferred technique for storing a database server history is 1 generate an index for a database upon a snapshot or checkpoint 2 generate an index for all the associated databases upon a snapshot or a checkpoint on one of the databases and 3 generate an index for a transaction or group of transaction. In the DMS note that an index can be represented by an object version a marker or transaction grouping. The purpose of generating an index for a database upon a snapshot or checkpoint is to preserve a consistent state of a database to be used for recovery. Generating indices for a group of associated databases e.g. when a checkpoint or snapshot occurs serves to preserve a group consistency state for recovery or other purposes. Indexing transactions allows for fine grain recovery in terms of time and application activity. Index can be generated for each and every transaction or for a chunk of transactions.

As noted above shows a database data source that contains three databases. This is merely representative. Whenever a checkpoint or a snapshot occurs on one of the databases new versions for all the databases are generated. In this case the technique described herein may or may not generate an index for the database transactions that occur between two database versions. If the transactions are not indexed then the recovery point would be at database versions. Note that a real time event journal with realtime transactions of a database is forwarded to the DMS preferably however it is up to the DMS to generate indices.

As noted previously shows yet another embodiment illustrating indexing of a database history. In this case whenever a database is versioned i.e. when a checkpoint or snapshot occurs the journal of the other associated databases are versioned. The model shows that for DB2 and DB3 only journal groups are versioned see L2 V3 L2 V4 L2 V5 L3 V3 and L3 V5 . For DB1 whenever a journal group is versioned preferably its database is also versioned see e.g. DB1 V2 DB1 V3 and DB1 V5 . During recovery time the other databases must take a closest database version and roll forward their journal up to the journal version to recover to a particular checkpoint or snapshot. For example to recover DB2 to DB2 V2 can be used as a baseline and L2 V4 journal group would be used to roll forward the state of DB2 starting from DB2 V2. In between database and journal versioning real time transactions may or may not be indexed both can be achieved with the current invention. If transactions are indexed individually any point in time recovery can be achieved. If transactions are indexed as a group then recovery points are only possible at the transaction group journal version and database version boundary.

Of course show only three possible structural embodiments of the described subject matter. As mentioned transaction level tracking can be applied to the structure as shown in .

In addition to storing and tracking database server history in real time with guaranteed consistency cross multiple databases and guaranteed integrity upon recovery the same indexing can be applied to tracking multiple related database server history. Events and data changes of multiple related databases from multiple servers can be tracked and streamed to the DMS in the original order as they occur. The technique described herein can apply the same technique to index and store the database history and guarantee consistency across multiple database servers for the purpose of data recovery.

When the real time event journal stream arrives at a DMS node the event that is associated with the changed data and metadata is examined at step . Depending on the event type the associated data metadata along with the event are dispatched to the appropriate process as seen in and described below.

The process in is for creating database objects. Database objects are created during initial upload and during regular protection time when a new database is added to the protected server or when a new database file binary log or control file or a storage device is added. A database administrator can also add new transaction tracking with DMS in which case new journal group and record file object may be added.

Step determines what type of database object to create. For initial upload a new data source object the root container must be created by the host driver as a resulting data source creation is at the very beginning of the real time event journal stream. In the DMS a data source object saves the meta information of a database server. For database initial upload or when new database is added to a protected database server a database CREATE event is forwarded and handled by the DMS to create the database object. A first version of a database is automatically generated and remain open once it the database is created and anchor and the first version is linked to its data source parent of the protected server as indicated by the metadata. Steps and create data objects for storage history of databases. First version of the file is also created. A DMS file object can capture content in a database file or raw storage device. A database file may be a database binary file or a control file. A file object is created during upload or when new file or storage device is added to a database. A database can have multiple binary or control files. Once created the first version of the file object is linked to the latest version of its database parent. Steps and create a journal group object. At initial upload a journal group object is created as a container for the binary log file s . During runtime user can create more journal group container to track database activities in many different levels for example in SQL transaction level. Same as the other object a first version of the object is created and link to the latest version of its database parent. Steps and create record file object or log file object log file object is simply a file object . Record file is for tracking granular transaction records or binary transaction record boundary in the binary log file. A first version is created and the object is tight to the latest version of its journal group. Once created the DMS object remains open for content to be uploaded and modified as seen in step .

This process handles all modification events such as RENAME MOVE CHECKPOINT begin checkpoint and end checkpoint TRANSACTION WRITE LOG LOG ALTER LOG ROLLOVER WRITE BINARY SET metadata BINARY DELTA and so on. Step verifies that the target object of the event existed. Step handles OPEN event by opening the target object . Step verifies that the object to be modified is opened. After that dispatches the event to the appropriate event handler. As shown in earlier sections when a database snapshot is created or when a database server performs an internal checkpoint memory flush a full consistent database is captured and versioned. During which all the binary and control files all the log groups and the log and log record files of a database are versioned. When a consistent database version is generated indexed it represents a point in time when the database is strong consistent state example see of DB3 V1 V2 at and of diagram . The earlier sections show that the DMS can track database history in three different consistency models when a database server has multiple databases.

Also as indicated in earlier section between two database versions real time log can be tracks e.g. L3 V2 of diagram of diagram in such a way that when a point in time recovery is necessary a previous database version prior to the recovery point along with the additional log entries happen after the database version but up to the recovery point can be combined to reconstruct database. The recovery is done by rolling forward the additional transaction entries using a database a fully versioned with a strong consistency state as baseline. Therefore database binary and control files changes are accumulated and versioned when a database version is created. For example see . For the recovery of DB2 to a point in time before the baseline DB2 V1 can be used to roll forward part of the transactions in . In step when BEGIN CHECKPOINT is received by the DMS node immediately the DMS closed versioned all its journal groups and their associated log and record files. At which point if the consistency model is all the other databases that are served by the same database server are also versioned see of . If the consistency model used is then the journal groups and all their associated log and record files of the other databases of the same database server are versioned see of . Once a version of the journal group log and record files is closed versioned a new version is opened for capturing new updates. Transaction records are captured by step .

All the updates and metadata changes to the binary and control files are captured stored and indexed by step . This step handles the update events such as SET WRITE and DELTA DMS host driver sends this event in case it performs delta reduction to the original WRITE event . In this step data may be delta reduced or compressed and byte level indices are generated to prepare the data in a recovery ready format. If there are queuing caching and that binary data updates are delayed and sent after the actual SNAPSHOT and database internal CHECKPOINT event DMS accounts for this by sending an END CHECKPOINT event after all the binary and metadata updates for a database version are forwarded to the DMS. When END CHECKPOINT is received step handles it by immediately versioned closed the active version and indexed the database the binary and control file objects. A new version of all these objects is created and ready to capture new changes after the checkpoint.

All the transaction records TRANSACTION event changes to the structure of a log file LOG ALTER or when a log file is rolled over ROLLOVER as well as all the events that associated with log files step handles it by capturing the associated changes to the log or record files. For consistency model each transaction or a group of transactions the granularity is flexible is time stamped along with a transaction sequence number. Transaction sequence number is issued by data source object. In this flow diagram does not have to be done this way a SEQ event is generated and separate step then queries the data source object to obtain a sequence number and timestamp for the log or record files.

When the consistency model of or applies and when a database among a group of databases that belong to a database server is versioned in the DMS the appropriate database objects of the other related databases are also versioned. For consistency model of the entire database object set all the binary journal group log and record files of the related databases are versioned. In the case of only the journal groups and the associated log and record files are versioned. The MAKE VERSION event is self generated in step and handled in step . Database files can be moved and renamed during run time and those events are handled by . In which case the associated object metadata is changed. When a database is detached from it server or when a database server is shutdown the associated database files are closed. The CLOSE event is handled by step in which the last version of each of the database objects is closed i.e. versioned . New database files and storage devices can be added in runtime. The associated DMS objects are created according to the process shown in and modified according to the process shown in .

There are many different kinds of termination event. These events are handled by the process shown in . Step dispatches the event to the right process accordingly. The DESTROY event can only apply generated by users when a DMS database object is no longer active not protecting a database server and not involves in any replication. If the data source is not idle step will report an error. This event instructs the DMS to remove the target database object from the DMS object storage for good all its history is erased as handled by step . The parent child link between the database and its data source is disconnected. Users can also generate a DESTROY event to a DMS data source object if it is no longer active. The data source DESTROY event is also generated by users and handled in step . This step uses to destroy any remaining database objects and then permanently remove the data source object with its entire history from the DMS.

During runtime in a database server a database can be deleted from a database server. When DMS host driver detects the database deletion event it sends a TERMINATION event to the DMS. In step when database TERMINATION event is received the last version of the database and all its binary and control files all its journal groups and their log and record files are all closed. The last version of these objects is time stamped. From this point on there will be no more history for the database as it will no longer exists. This is very different then DESTROY event as DESTROY event removes the entire history from the DMS. TERMINATION event only stop the history from continuing.

An administrator can add different level of transaction tracking which translate to the addition of DMS journal group. An administrator can also remove the tracking of some transaction in which case the associated journal group is removed. This user action translates to a journal group TERMINATION event and it is handled by . When a journal group is terminated the last version of the journal group and all its log and record file children is time stamped and closed. There will be no more continuous history for these objects from this point on.

Although not shown in if a database is restructured and its file is deleted the last version of the file will be terminated in the same way as the journal group. It is not shown in the flow diagram because the individual file of a database in most databases is never deleted unless the entire database is deleted.

This section describes 1 traversing for recovery at database checkpoints and then 2 traversing database at any point in time and 3 traversing for recovery at any point in time with guaranteed consistency and integrity uncorrupted and guaranteed usable files .

Once a database history is captured and indexed in the DMS continuous object store a point in time data state can be traversed. The traversal process differs depending on the consistency model applied on the indexing and versioning of the database history. The capability of traversing the data state at any point in time in the past allows the DMS to recover a corrupted database or missing database information.

For a database server with multiple protected databases the traversal preferably is handled one at a time either sequentially or in parallel as shown in until all the databases are traversed . The traversal process is different depending on how the database history is indexed . For the consistency model of the traversal process is shown in for the consistency model of the traversal process is shown in and for the consistency model of the traversal process is shown in .

As previously mentioned the DMS is used to index data and metadata history at any time granularity so as to allow recovery to any point in time in the past. The capability of this technique is illustrated in the consistency model of . The consistency models of are used to illustrate the flexibility and extensive indexing capability of the disclosed technique. As previously noted as well these two consistency models only allow checkpoint selected time point indexing these models typically do not index transactions continuously instead only database checkpoints are indexed . As a result the consistency models of only allow recovery to any former database checkpoints not exactly any point in time. The recovery point limitation of the consistency models and is by indexing choice and is not a limitation however.

As noted above illustrates a process for traversing a database history of a given database DB that is indexed with the consistency model of . In this case the index granularity is at database version level. When traversal is completed the particular database version that is closest right before to the given point in time PIT is returned in the DBVersion parameter . In operation the process shown in examines all the database versions until the last version and or until the timestamp of the next database version is beyond the given PIT and . If a version of a database created right before the given PIT is located its version number is set on DBVersion and the traversing ends. Otherwise the next database version is examined .

The process in traverses the database history of a given database DB to locate the closest database version DBVersion and its closest journal group version JGVersion to a given point in time PIT . The database version is set in DB Version parameter upon completion of the process and the journal group version is set in JGVersion parameter. For recovery purposes one can use the files in the database version as baseline and the journal group transaction log or record files in the journal group version to roll forward the database state. For example in to recover DB2 to DB2 V2 can be used as a baseline and L2 V4 journal group would be used to roll forward the state of DB2 starting from DB2 V2.

The process uses the routine of to locate a database version that is the closest to the given PIT . Once the database version is located the subsequence versions of a journal group of the database is examined . Only those journal group versions that are created after the desired database version and before the next database version need to be examined. The journal group versions are checked until there is no more version and or until the timestamp of a journal group version passes the given PIT and . If a journal group version that is closest to the given PIT is located JGVersion is set to that journal group version number and . It is possible that no journal group is found in which case the desired traversal point or recovery point if the traversal is for recovery purposes is at the database version and there is nothing to roll forward.

A significant advantage of the described technique is the capability to provide data metadata and any point in time event indexing. The flexibility of the tracking and indexing versioning and timestamping of the described technique is demonstrated in wherein a database state DB can be traversed at any given point in time PIT and at the exact PIT not the closest roundup . In this case a closest database version as baseline is located and returned in DBVersion a closest journal group for rolling forward in case it is used for recovery is located and returned in JGVersion and finally a list of necessary transactions following the journal group version up to the exact PIT is gathered and returned in listOfTransaction parameter . Those transactions then are used for further rolling forward the database state to the exact PIT if recovery is desired.

In the process shown in in step the process of preferably is used to locate the closest database and journal group version. After that the transactions following the last journal group version are examined until all transactions are examined or until the timestamp of a next transaction is beyond the desired PIT and . If a transaction is recorded before the given PIT the transaction is added to the list and . This process locates a database baseline DBVersion the next transaction log checkpoint JGVersion and the necessary list of transactions occur after the checkpoint up to the desired PIT ListOfTransaction . This process demonstrates the full capability of the current invention in particular the capability to structure real time data history for track data changes metadata and events and to index all these events associated with the data in real time continuously as well as to enable the traversal and recovery of a database to any point in time in the past with guaranteed consistency.

As mentioned in a previous section during runtime preferably database transactions are entered into the transaction log file s as or before the transactions are processed. The updates to the binary and control data files may be delayed and flushes out randomly. When a database performs an internal checkpoint it flushes all its memory at which moment all the database files are guaranteed with strong consistent. Database checkpoint can also be triggered externally through a CHECKPOINT SQL request or through a storage snapshot request. shows three database checkpoints at 1 00 PM 2 00 PM and 3 00 PM . DMS generates database version when a database checkpoint is detected DBV1 DBV2 and DBV3 . At each database version all the files belong to the database are versioned as a way for indexing at that consistent event .

As mentioned during runtime binary changes to the database binary files are likely to be cached in memory and flush out randomly. So at any moment in time in the persistent storage the data state of the binary control and the log files are not in consistent because part of the changes to the database binary files are not yet written to the storage. Traditional replication or Continuous Data Protection CDP solutions are designed to record all the updates to the persistent storage continuously in real time rather then using the database event for indexing. As a result when recovery is necessary these solutions are only capable to recover to the recovery point as indicated in . At that point the data state these solutions are capable of reconstructing is a crash consistent state which the state of the log file s out of synchronous with the state of the binary and control files. This crash consistent state may be repaired by a database server or a database tool to bring the state of all the files to a consistent state if recovery is desired. Repairing a database is a time consuming process it is also possible that a repair may fail therefore recovery to a crash consistent state does not guarantee usable files.

In contrast the DMS indexes versions a database checkpoint by generating database versions DBV1 DBV2 and DBV3 so as the database files . It also sequences timestamps and indexes the transaction activity in the transaction log. When recovery is desired a strong consistent database baseline version is first recovered and then the necessary log files and transaction activity are used to roll the state of the database forward. In the above example is one strong consistent data point when a database version checkpoint can be recovered. Another example is when the recovery point is desired. In the example DBV2 with strong consistency is used as baseline and the list of transaction is used to roll the database state forward. Because the state of the binary updates is unknown DMS discards those updates for that recovery point. DMS always starts recovery at a strong consistent baseline and rolls forward with a valid transaction thus it can reconstruct a database to any point in time with guaranteed data consistency and integrity guaranteed usable files .

The flow diagram in illustrates the steps to recover a database or database server using the captured database history in DMS to a former point in time with guaranteed consistency and integrity.

The process begins with making a list of database to recover from the given database or database server and . For each of the databases to be recovered and traverse the data state using process or depending on the consistency model used for indexing the database history. In step for each database once the database version journal group version and list of transactions are obtained create the necessary files in the recovering server retrieve the content of the files at those located versions and recover to the recovering files. If journal group and or the list of additional transactions exist then those log files and transactions are used to roll forward the state of the recovering database. If consistency model applies then the DMS recovery process recovers a database or a database server to any given point in time in the past with guaranteed data consistency and integrity. The process iterates until all the necessary databases are recovered .

Because the DMS indexes events in particular consistency events along with the associated changed data and metadata it is capable of reconstructing a database state to any point in time in the past with guaranteed consistency and integrity. There is no need for database repair once the data is recovered the recovered files are guaranteed usable by a database server. With such assurance the current invention can be combined with a prior disclosure virtual on demand recovery as described in Ser. No. 11 185 313 filed Jul. 20 2005 to provide instantaneous database and database server recovery. The combined subject matter allows a database server regardless of data set size to be recovered to any point in time and begun serving both reads and writes its application within seconds.

After the data state is adjusted in the DMS in step recovery at the destination host server begins in step . In this step the missing recovering database files or volumes are created empty. If the files or volumes existed delta recovery can apply so there is no need to delete them this is optional. After which the host driver creates a recovery bitmap and dirty bitmap for all the recovering files and volumes. Each cell in the bitmaps represents a segment of a file or a volume. The cells are all set in an OFF state initially. The OFF state in recovery bitmap means that the segment of the file or the volume has not been recovered yet while OFF state in the dirty bitmap means that the segment has not been modified. After this step is completed the database server can be started and database application and users served and all updates to the database can be captured and indexed backed up while recovery is going on simultaneously.

In step after the database server is started the DMS host driver preferably performs duo stream processing. In the background the DMS host driver recovers segments of the recovering files or volumes sequentially by retrieving the most recent data note that the data state in the DMS is adjusted such that the most recent state is the recovered state from the DMS. As segments are recovered the corresponding cells in the recovery bitmap are turned ON.

Simultaneously in the foreground in step a real time event journal process as illustrated in for simultaneous database backup and recovery is executing until all the cells in the recovery bitmaps are ON. At which point the database or the server is fully recovered. Once fully recovered at step the DMS host driver returns to regular backup mode.

As noted above the technique described herein may be combined with virtual on demand recovery and DMS host driver automated no down time finite state machine data upload and protection. The DMS provides a significantly no downtime data protection services with near instantaneous and guaranteed usable data recovery to a database application.

While the present invention has been described in the context of a method or process the present invention also relates to apparatus for performing the operations herein. In an illustrated embodiment the apparatus is implemented as a processor and associated program code that implements a finite state machine with a plurality of states and to effect transitions between the states. As described above this apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but is not limited to any type of disk including optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

While the above written description also describes a particular order of operations performed by certain embodiments of the invention it should be understood that such order is exemplary as alternative embodiments may perform the operations in a different order combine certain operations overlap certain operations or the like. References in the specification to a given embodiment indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic.

