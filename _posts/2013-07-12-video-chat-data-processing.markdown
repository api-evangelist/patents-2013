---

title: Video chat data processing
abstract: A graphics processing unit and a system are described herein. The graphics processing unit includes a decoder, a post processor, and a renderer. The decoder is to decode a video data stream from an incoming data stream. The post processor is to perform post-processing of the decoded video data stream. The renderer is to render the post processed video data stream and discard a null video data stream from a video chat application during a video chat session.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09232177&OS=09232177&RS=09232177
owner: Intel Corporation
number: 09232177
owner_city: Santa Clara
owner_country: US
publication_date: 20130712
---
Video chat applications enable a user of a computing system to communicate with at least one user of another computing system by transmitting video chat data from one computing system to the another computing system across a network such as the Internet. The video chat data may be encoded using a codec at the one computing system then packaged according to network protocols and sent across the network. The encoded video chat data may be received at the another computing system from the network extracted from the package and decoded using the codec. As the video chat data is encoded and decoded the particular codec used by the video chat application may not be revealed to other components and modules of the one computing system or the another computing system.

The same numbers are used throughout the disclosure and the figures to reference like components and features. Numbers in the 100 series refer to features originally found in numbers in the 200 series refer to features originally found in and so on.

Video chat data includes the images text audio and video associated with a video chat session. Each video chat application encodes or decodes the graphics portion of the video chat data using a codec. A codec is a software or hardware component of a computing device that can encode or decode a stream of data. In some cases the data is encoded and decoded for data compression purposes. The graphics portion of the video chat data includes raw video data. A video chat application typically implements a codec using software algorithms to compress the data stream. The software algorithms used by the video chat application to implement a codec are executed using the central processing unit CPU . However hardware encode and decode functionality is available on most computing systems through graphics hardware. Graphics hardware includes but is not limited to a graphics processing unit GPU fixed function hardware video encode logic video decode logic and graphics engines.

Video chat applications typically perform the encode or decode functions without using the graphics hardware as standard interfaces with the graphics hardware may not be available. In some cases the graphics hardware is capable of faster more efficient hardware based encoding and decoding when compared to the software encoding and decoding functions of video chat applications. Additionally by using the CPU to execute encode and decode functionality of a video chat application the power consumption during video chat may be relatively high. Moreover the performance of the video chat application may result in the rendered video being slow or choppy depending on the data throughput of the CPU.

Embodiments described herein enable video chat data processing. In some embodiments the graphics camera and network drivers may be embedded with intelligence or logic that transfers encode decode and post processing functionality from the video chat application to the graphics hardware. In this manner the performance of the video chat is enhanced where enhanced performance may refer to the improved quality of the video text images and sound presented to the user as well as improved system power consumption. Furthermore in some embodiments the graphics hardware may process video chat data when standard interfaces with the graphics hardware are not available. For ease of description a destination computing system and a source computing system are used to describe functions during a video chat session. However a single system can perform the functions of the destination computing system and the source computing system simultaneously. Moreover any number of computing systems can participate in a video chat session.

In the following description and claims the terms coupled and connected along with their derivatives may be used. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical or electrical contact with each other. Coupled may mean that two or more elements are in direct physical or electrical contact. However coupled may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other.

Some embodiments may be implemented in one or a combination of hardware firmware and software. Some embodiments may also be implemented as instructions stored on a machine readable medium which may be read and executed by a computing platform to perform the operations described herein. A machine readable medium may include any mechanism for storing or transmitting information in a form readable by a machine e.g. a computer. For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices or electrical optical acoustical or other form of propagated signals e.g. carrier waves infrared signals digital signals or the interfaces that transmit and or receive signals among others.

An embodiment is an implementation or example. Reference in the specification to an embodiment one embodiment some embodiments various embodiments or other embodiments means that a particular feature structure or characteristic described in connection with the embodiments is included in at least some embodiments but not necessarily all embodiments of the present techniques. The various appearances of an embodiment one embodiment or some embodiments are not necessarily all referring to the same embodiments. Elements or aspects from an embodiment can be combined with elements or aspects of another embodiment.

Not all components features structures characteristics etc. described and illustrated herein need be included in a particular embodiment or embodiments. If the specification states a component feature structure or characteristic may might can or could be included for example that particular component feature structure or characteristic is not required to be included. If the specification or claim refers to a or an element that does not mean there is only one of the element. If the specification or claims refer to an additional element that does not preclude there being more than one of the additional element.

It is to be noted that although some embodiments have been described in reference to particular implementations other implementations are possible according to some embodiments. Additionally the arrangement and or order of circuit elements or other features illustrated in the drawings and or described herein need not be arranged in the particular way illustrated and described. Many other arrangements are possible according to some embodiments.

In each system shown in a figure the elements in some cases may each have a same reference number or a different reference number to suggest that the elements represented could be different and or similar. However an element may be flexible enough to have different implementations and work with some or all of the systems shown or described herein. The various elements shown in the figures may be the same or different. Which one is referred to as a first element and which is called a second element is arbitrary.

The computing device may also include a graphics processing unit GPU . As shown the CPU may be coupled through the bus to the GPU . The memory device may store instructions that are executable by the GPU . The GPU may be configured to perform any number of graphics operations within the computing device . For example the GPU may be configured to render or manipulate graphics data such as graphics images graphics frames videos or the like to be displayed to a user of the computing device . The graphics data may be rendered during a video chat session.

The memory device can include random access memory RAM read only memory ROM flash memory or any other suitable memory systems. For example the memory device may include dynamic random access memory DRAM . The memory device includes one or more drivers . The drivers may include device drivers such as a graphics driver a network driver or a camera driver. In some examples hardware components such as a graphics encoder may be operated by an encoding module of the graphics driver. Similarly in some examples a graphics decoder may be operated by a decoding module of the graphics driver. The computing device also includes an image capture mechanism . In some embodiments the image capture mechanism is a camera webcam stereoscopic camera scanner infrared sensor or the like. The image capture mechanism may be used to capture graphics data such as a video data stream or an image during a video chat session.

The graphics driver the network driver the camera driver or any combinations thereof can detect that the video chat application has initialized or started a video chat session using hints. In some cases a hint is any action that can indicate the start of a video chat session. The graphics network and camera drivers may each receive different hints based on the manner in which the video chat session was initialized by the video chat application. For example the graphics driver may receive a call from the video chat application to create surfaces for rendering the video that is displayed during a video chat session. In such an example the call received serves as a hint to the graphics driver of an impending video chat session. In another example the camera driver may receive a notification or request for access to the camera functionality from the video chat application. In such an example the notification or request serves as a hint to the camera driver of an impending video chat session. Furthermore as an example the network driver may detect data packets that are being sent or received by the video chat application. In such an example the detection of data packets to or from the video chat application may serve as a hint to the network driver of an impending video chat session.

A user mode module of each device driver may also be used to detect hints that indicate the start of a video chat session. The user mode module of a device driver enables the device driver to execute in the user mode space of a computing system rather than in the privileged space of the kernel mode. By executing in the user mode the device drivers call an application programming interface API to access system hardware. In some embodiments a user mode module of the device driver may determine the identity of the application that is requesting service from the device driver. When the application requesting service is a video chat application the device driver may use the request by the video chat application as a hint that a video chat session has been initialized.

When a hint that a video chat session has been initialized is detected the encoding decoding and post processing functionality can be transferred from the video chat application to the GPU hardware. Typically the GPU hardware is specialized for media functions such as encoding decoding and post processing. In some examples the video codec format used by the video chat application may be implemented by the encoder hardware and the decoder hardware of the GPU subsystem. The specialized GPU hardware can provide faster more efficient encoding decoding and post processing functionality when compared to the encoding decoding and post processing functionality of the video chat application. Typically the video chat application implements such functionality using software as discussed above. Accordingly the performance of the video chat application may be improved by using the GPU hardware. Furthermore the computing device can save power by using the GPU hardware for the encoding decoding and post processing functionality of the video chat application.

The CPU may also be connected through the bus to an input output I O device interface configured to connect the computing device to one or more I O devices . The I O devices may include for example a keyboard and a pointing device wherein the pointing device may include a touchpad or a touchscreen among others. The I O devices may be built in components of the computing device or may be devices that are externally connected to the computing device .

The CPU may be linked through the bus to a display interface configured to connect the computing device to one or more display devices . The display devices may include a display screen that is a built in component of the computing device . The display devices may also include a computer monitor television or projector among others that is externally connected to the computing device .

The computing device also includes a storage device . The storage device is a physical memory such as a hard drive an optical drive a thumbdrive an array of drives or any combinations thereof. The storage device may also include remote storage drives. The storage device also includes applications . The applications may include a video chat application. The computing device may also include a network interface controller NIC configured to connect the computing device through the bus to a network . The network may be a wide area network WAN local area network LAN or the Internet among others. The data transmitted across a network is described as streaming data wherein the streaming data includes data that is in packets according to a network protocol. The packet data includes but is not limited to image frames and corresponding audio data.

The block diagram of is not intended to indicate that the computing device is to include all of the components shown in . Further the computing device may include any number of additional components not shown in depending on the details of the specific implementation. Moreover the computing device may be implemented as a system on chip SOC . In an SOC implementation various components of the computing device are combined onto a single chip substrate.

In some embodiments the video chat application may send a notification to the graphics driver to create a surface that is to render video processed by the video chat application. In some cases a surface is an area of memory where graphics data is written. In examples when using APIs such as those provided by DirectX the surface created at the request of the video chat application is a render target surface which may be located in an area of memory that is not managed by the GPU hardware. As a result the GPU will track the surface created at the request of the video chat application by setting a flag for each surface. In examples the flag may be stored by the graphics driver software. Additionally in examples a table may be used to indicate the allocated surfaces along with a Boolean value to indicate if the surface is tracked. During a render operation from the application if the application asks a specific surface to be rendered and the graphics driver has a flag set against this surface the graphics driver performs a video post processing on the surface that contains the decoded data and will not render the surface generated by the application. This process may be known as trapping the surface.

The graphics driver may also change the create surface notification sent by the video chat application from a render target surface to a video process render target surface. In this manner the surfaces created by the video chat application are converted from a render target surface to a video process render target surface. Video process render target surfaces are managed by the GPU hardware. Further in some embodiments the video process render target surface may be located on the graphics card. The graphics driver may also create additional surfaces for decode render targets. The decode render targets may be used to send decoded graphics data to the post processing engine. The graphics driver can also inform the network driver and the camera driver that a video chat session has been initiated by the video chat application.

Even when the video chat application does not have any active video calls or conferences the network driver may monitor the ports used for sending or receiving video chat data packets for any video chat application activity. If the network driver detects a packet from the video chat application it marks the traffic from the video chat session as a means of tracking the video chat session. In some cases the network driver may mark the traffic by using marker bits or any other marking mechanism. The network driver can detect a packet from the video chat application through examining the packet header or data inspection. The network driver may then inform the graphics driver and the camera driver that a video chat session has been initialized.

The manner in which the device drivers are notified of a new video chat session occurs according to how the video chat session is initialized by the video chat application as well as the video chat features used by the video chat application during the video chat session. In a video chat session computing systems may be designated as source computing systems and destination computing systems. In some cases the source computing system is a computing system that is sending video chat data while a destination computing system is a computing system that receives video chat data. Each computing system may be both a source computing system and a destination computing system simultaneously during the video chat session. However for ease of description each computing system is described as a source computing system or a destination computing system.

Consider the scenario where an image capture mechanism such as a webcam is absent from a source computing system. The source computing system may send video chat data to a destination computing system where the video chat data includes audio and text. In this case neither the graphics driver nor the camera driver will participate in the workflow at the source computing system as an image capture mechanism is not present within the source computing system and the graphics hardware has no graphics data to process. Accordingly the network driver of the source computing system may be the first driver to detect a new video chat session through the use of various hints. The network driver may notify the other drivers of the new video chat session. When no video stream is transmitted to the destination computing system due to the lack of a webcam the graphics driver of the destination computing system does not enable decoding or post processing functionality of the graphics hardware as there is no graphics data to process. Accordingly the manner in which the drivers are notified of an impending video chat session depends on the features of the video chat session.

At block the video data stream is sent to the graphics subsystem while a null video stream is sent to the video chat application. In some embodiments the network driver is used to route the video data stream from the video chat application to the graphics subsystem. The null video stream sent to the video chat application is a place holder for the actual video data that is processed by the graphics hardware. In some embodiments a packet containing the audio data stream from the incoming data stream is sent to the video chat application along with the null video stream. The video chat application can recognize the audio data stream as an audio session and process the audio data stream so that the audio data stream can be rendered.

In some embodiments the network driver may rip the video data onto a shared area or memory. This area of memory may be shared by the graphics hardware and the network driver. The network driver rips the video data to the shared memory and then informs the graphics driver that there is video data in the shared memory that is waiting to be consumed by the graphics subsystem.

At block the video data stream is processed using the graphics subsystem. In some embodiments the graphics hardware receives the video data stream and then decodes the stream. The graphics hardware may also perform post processing such as color conversion scaling and de interlacing of the video data. Furthermore the graphics subsystem can perform any additional image enhancement operations on the decoded video data stream including but not limited to skin toning and hue saturation and brightness controlling. While the graphics subsystem performs post processing of the decoded video data stream that was received from the network the video chat application performs decoding and post processing functions on the null video stream simultaneously. However as the null stream is a placeholder the packets sent to the video application do not contain any data. As a result the no data processing is done by the video chat application. In this manner the video chat application functions in the same manner as when the video data is sent to the video chat application.

At block the processed video data is rendered. When the video chat application calls the graphics driver for rendering the graphics driver traps the surfaces so that the placeholder data from the video chat application is not rendered onto the surface. The graphics driver renders the processed video data stream from the graphics subsystem onto the surface. In some cases trapping the surface refers to the process by which the graphics driver prevents the video chat application from accessing the surfaces. The graphics driver may discard or ignore any data received from the video chat application for rendering. In some embodiments the surfaces are trapped according to the flag that was set by the graphics driver when the video chat application sent a request to create the surfaces. The video chat application executes a render function to these surfaces even when the video chat application receives a null video stream for processing as the video chat application is unaware that it is not handling the decode and post processing of the video data stream. The video may be rendered to a display from the surface.

The decode module A of the graphics driver causes the graphics decode and post processing hardware to perform decoding and post processing functions on the video data stream as described above. A render module B of the graphics driver then causes the GPU Render Hardware to render the decoded and post processed data. The render module B of the graphics driver is aware that the data sent by the video chat application at block is dummy data. Any video data from the video chat application is ignored. In some embodiments the render module B of the graphics driver writes the decoded and post processed video data stream from the graphics decode and post processing hardware to a surface to be rendered.

A decode session may be initiated at reference number . In the decode session the incoming frames from the video data stream are continually decoded using the graphics hardware as indicated at reference number . At reference number post processing is performed on the video data frames. Accordingly the graphics driver may cause the graphics hardware to post processing the decoded video data and render the data as discussed above. The video chat application sends video data to be rendered at reference number . However the video data from the video chat application is not rendered as the packets processed by the video chat application were null data packets and the resulting video surface contains no information. The graphics driver causes the decoded and post processed frames received from the graphics hardware to be rendered.

At block the video data is captured. In some embodiments an image capture mechanism such as a camera is used to capture the video data. Moreover audio data may be captured using a microphone. At block the camera driver causes the image capture mechanism to send the captured video data to the graphics subsystem for encoding. Particularly the captured video data may be sent to an encoder of the graphics subsystem. The camera driver also causes the image capture mechanism to send null video data to the video chat application. The audio captured by the microphone is also sent to the video chat application so that the resulting packet from the video chat application includes the correct audio and null video. At block the captured video data is processed using the graphics subsystem. In some embodiments the encode module of the graphics driver uses the graphics hardware such as an encoder to encode the captured video data.

At block the encoded data from the graphics subsystem is prepared for transmission across a network. In some embodiments the encoded data is sent to the network driver. The network hardware can intercept the packet sent from the video chat application for transmission across the network and repackage the packet by inserting the encoded video data from the graphics subsystem. Then the repackaged packet is then sent across the network according to the network protocol. In some embodiments as the network hardware repackages the packet by inserting encoded data from the graphics subsystem the network header information remains intact. For example the network subsystem may use the packet header to keep track of the number of bytes that are sent in the packet. When the encoded video data from the graphics subsystem is inserted into the packet that is sent from the video chat application the packet header may be modified to reflect the changes in packet size thus maintaining accurate header information. Such packaging is performed in accordance with the underlying networking protocol. This will ensure the packet that is transmitted will not be rejected when it is received.

In some embodiments the render module of the graphics driver causes the graphics subsystem to render the captured video data alongside the received video data within the video chat application of a source computing system. For example a video chat application may render the received video chat data in a larger portion of the video chat application while rendering the source video data in a smaller portion of the video chat application so that a user can see their own image. In such a scenario the graphics subsystem re uses the raw video stream forwarded by the image capture mechanism when it is called for presenting this source data. In some embodiments color space conversion and scaling may be performed by the graphics hardware before the captured source data is rendered on the same computing system.

The encode module A of the graphics driver communicates with the network driver so that the packet received from the video chat application can be repackaged. The encoded video data is sent to the network hardware from the encoding hardware of the graphics subsystem. The network driver causes the packet from the video chat application to be combined with the encoded video data from the encoding hardware of the graphics subsystem. In some embodiments a multiplexer is used to combine the encoded video data from the encoding hardware of the graphics subsystem with the data packet from the video chat application that includes audio and null video. The multiplexer may be implemented in hardware or software. The network hardware is used to transmit the repackaged data packet across the network.

The camera driver also causes the captured video data from the camera hardware to be sent to the GPU render hardware of the GPU subsystem by communicating with the render module B of the graphics driver. The render module B may cause the render hardware of the graphics subsystem to render video data captured by the camera hardware thereby rendering the captured video data at the same computing system. In some embodiments the video chat application renders the source video data alongside the video and audio data received from a remote computing system.

In various embodiments the system comprises a platform coupled to a display . The platform may receive content from a content device such as content services device s or content delivery device s or other similar content sources. A navigation controller including one or more navigation features may be used to interact with for example the platform and or the display . Each of these components is described in more detail below.

The platform may include any combination of a chipset a central processing unit CPU a memory device a storage device a graphics subsystem applications and a radio . The chipset may provide intercommunication among the CPU the memory device the storage device the graphics subsystem the applications and the radio . For example the chipset may include a storage adapter not shown capable of providing intercommunication with the storage device . The applications may be the applications the applications or the applications as described above. The components of the system may be implemented as a system on chip SOC . In an SOC implementation all components of the platform are combined onto a single chip substrate.

The CPU may be implemented as Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU . In some embodiments the CPU includes multi core processor s multi core mobile processor s or the like. The memory device may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM . The storage device may be implemented as a non volatile storage device such as but not limited to a magnetic disk drive optical disk drive tape drive solid state drive an internal storage device an attached storage device flash memory battery backed up SDRAM synchronous DRAM and or a network accessible storage device. In some embodiments the storage device includes technology to increase the storage performance enhanced protection for valuable digital media when multiple hard drives are included for example.

The graphics subsystem may perform processing of images such as still or video for display. The graphics subsystem may include a graphics processing unit GPU such as the GPU or a visual processing unit VPU for example. An analog or digital interface may be used to communicatively couple the graphics subsystem and the display . For example the interface may be any of a High Definition Multimedia Interface DisplayPort wireless HDMI and or wireless HD compliant techniques. The graphics subsystem may be integrated into the CPU or the chipset . Alternatively the graphics subsystem may be a stand alone card communicatively coupled to the chipset .

The graphics and or video processing techniques described herein may be implemented in various hardware architectures. For example graphics and or video functionality may be integrated within the chipset . Alternatively a discrete graphics and or video processor may be used. As still another embodiment the graphics and or video functions may be implemented by a general purpose processor including a multi core processor. In a further embodiment the functions may be implemented in a consumer electronics device.

The radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Exemplary wireless networks include wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks satellite networks or the like. In communicating across such networks the radio may operate in accordance with one or more applicable standards in any version.

The display may include any television type monitor or display. For example the display may include a computer display screen touch screen display video monitor television or the like. The display may be digital and or analog. In some embodiments the display is a holographic display. Also the display may be a transparent surface that may receive a visual projection. Such projections may convey various forms of information images objects or the like. For example such projections may be a visual overlay for a mobile augmented reality MAR application. Under the control of one or more applications the platform may display a user interface on the display .

The content services device s may be hosted by any national international or independent service and thus may be accessible to the platform via the Internet for example. The content services device s may be coupled to the platform and or to the display . The platform and or the content services device s may be coupled to a network to communicate e.g. send and or receive media information to and from the network . The content delivery device s also may be coupled to the platform and or to the display .

The content services device s may include a cable television box personal computer network telephone or Internet enabled device capable of delivering digital information. In addition the content services device s may include any other similar devices capable of unidirectionally or bidirectionally communicating content between content providers and the platform or the display via the network or directly. It will be appreciated that the content may be communicated unidirectionally and or bidirectionally to and from any one of the components in the system and a content provider via the network . Examples of content may include any media information including for example video music medical and gaming information and so forth.

The content services device s may receive content such as cable television programming including media information digital information or other content. Examples of content providers may include any cable or satellite television or radio or Internet content providers among others.

In some embodiments the platform receives control signals from the navigation controller which includes one or more navigation features. The navigation features of the navigation controller may be used to interact with the user interface for example. The navigation controller may be a pointing device or a touchscreen device that may be a computer hardware component specifically human interface device that allows a user to input spatial e.g. continuous and multi dimensional data into a computer. Many systems such as graphical user interfaces GUI and televisions and monitors allow the user to control and provide data to the computer or television using physical gestures. Physical gestures include but are not limited to facial expressions facial movements movement of various limbs body movements body language or any combinations thereof. Such physical gestures can be recognized and translated into commands or instructions.

Movements of the navigation features of the navigation controller may be echoed on the display by movements of a pointer cursor focus ring or other visual indicators displayed on the display . For example under the control of the applications the navigation features located on the navigation controller may be mapped to virtual navigation features displayed on the user interface . In some embodiments the navigation controller may not be a separate component but rather may be integrated into the platform and or the display .

The system may include drivers not shown that include technology to enable users to instantly turn on and off the platform with the touch of a button after initial boot up when enabled for example. Program logic may allow the platform to stream content to media adaptors or other content services device s or content delivery device s when the platform is turned off. In addition the chipset may include hardware and or software support for 6.1 surround sound audio and or high definition 7.1 surround sound audio for example. The drivers may include a graphics driver for integrated graphics platforms. In some embodiments the graphics driver includes a peripheral component interconnect express PCIe graphics card.

In various embodiments any one or more of the components shown in the system may be integrated. For example the platform and the content services device s may be integrated the platform and the content delivery device s may be integrated or the platform the content services device s and the content delivery device s may be integrated. In some embodiments the platform and the display are an integrated unit. The display and the content service device s may be integrated or the display and the content delivery device s may be integrated for example.

The system may be implemented as a wireless system or a wired system. When implemented as a wireless system the system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum. When implemented as a wired system the system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller or the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics or the like.

The platform may establish one or more logical or physical channels to communicate information. The information may include media information and control information. Media information may refer to any data representing content meant for a user. Examples of content may include for example data from a voice conversation videoconference streaming video electronic mail email message voice mail message alphanumeric symbols graphics image video text and the like. Data from a voice conversation may be for example speech information silence periods background noise comfort noise tones and the like. Control information may refer to any data representing commands instructions or control words meant for an automated system. For example control information may be used to route media information through a system or instruct a node to process the media information in a predetermined manner. The embodiments however are not limited to the elements or the context shown or described in .

As described above examples of a mobile computing device may include a personal computer PC laptop computer ultra laptop computer server computer tablet touch pad portable computer handheld computer palmtop computer personal digital assistant PDA cellular telephone combination cellular telephone PDA television smart device e.g. smart phone smart tablet or smart television mobile internet device MID messaging device data communication device and the like.

An example of a mobile computing device may also include a computer that is arranged to be worn by a person such as a wrist computer finger computer ring computer eyeglass computer belt clip computer arm band computer shoe computer clothing computer or any other suitable type of wearable computer. For example the mobile computing device may be implemented as a smart phone capable of executing computer applications as well as voice communications and or data communications. Although some embodiments may be described with a mobile computing device implemented as a smart phone by way of example it may be appreciated that other embodiments may be implemented using other wired or wireless mobile computing devices as well.

As shown in the device may include a housing a display an input output I O device and an antenna . The device may also include navigation features . The display may include any suitable display unit for displaying information appropriate for a mobile computing device. The I O device may include any suitable I O device for entering information into a mobile computing device. For example the I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches rocker switches microphones speakers a voice recognition device and software or the like. In other examples the device may include a navigation controller that can be used for entering information into the mobile computing device. Information may also be entered into the device by way of microphone. Such information may be digitized by a voice recognition device.

The various software components discussed herein may be stored on one or more tangible non transitory computer readable media as indicated in . For example an encode module may be configured to cause the graphics subsystem to encode image data. A decode module may be configured to cause the graphics subsystem to decode incoming data packets received from a network. A post processing module may be configured to cause the graphics subsystem to perform post processing of the decoded video data. Further a render module may be used to cause the graphics subsystem to render video data.

The block diagram of is not intended to indicate that the tangible non transitory computer readable media is to include all of the components shown in . Further the tangible non transitory computer readable media may include any number of additional components not shown in depending on the details of the specific implementation.

A graphics processing unit is described herein. The graphics processing unit includes a decoder. The decoder is to decode a video data stream from an incoming data stream. The graphics processing unit also includes a post processor. The post processor is to perform post processing of the decoded video data stream. Additionally the graphics processing unit includes a renderer. The renderer is to render the post processed video data stream and discard a null video data stream from a video chat application during a video chat session.

A device driver that may detect the video chat session so that the video data stream from the incoming data is sent to the decoder and the null video stream is sent to the video chat application. The incoming data stream may include the video data stream and an audio data stream and the video chat application may receive the audio data stream and the null video data stream. The decoder may decode the video data stream according to a codec of the video chat application. Additionally post processing the decoded data stream may include any image enhancements to the video data stream. Further hints may be used to detect a new video chat session.

A system is described herein. The system includes an encoder and the encoder is to encode image data. The system also includes a multiplexer and the multiplexer is to repackage the encoded image data with a data packet from a video chat application during a video chat session. Additionally the system includes networking logic and the networking logic is to transmit the repackaged data packet across a network.

The encoder may encode the video data stream according to a codec of the video chat application. An image capture device may capture image data and send the image data to the encoder. The image capture device may also send null image data to the video chat application. The data packet from the video chat application may include null image data and audio data from the video chat session. A renderer may render the image data using the video chat application during the video chat session. Hints may be used to detect a new video chat session.

A system is described herein. The system includes a display a radio and a memory that is to store instructions and that is communicatively coupled to the display. The system also includes a processor communicatively coupled to the radio and the memory wherein when the processor is to execute the instructions the processor is to detect a video chat session by an application. The processor also encodes image data that is to be transmitted across a network wherein a graphics subsystem encodes the image data from an image capture device and the application receives null image data from an image capture device. Additionally the processor decodes incoming data packets received from the network wherein networking logic rips the encoded video data from the incoming data packets and sends the encoded video data to the graphics subsystem to be decoded and the networking logic sends null video data to the application. The processor may be a graphics processing unit. Additionally the system may be a system on chip. Further the encode and decode functions may be performed by the processor instead of the application.

A tangible non transitory computer readable medium comprising code to direct a processor is described herein. The code may direct the processor to encode image data that is to be transmitted across a network wherein the processor encodes the image data instead of a video chat application. The code may also direct the processor to decode incoming data packets received from the network wherein encoded image data is ripped from the incoming data packets and sent to the processor to be decoded.

The image data may be received from an image capture device. Additionally the video chat application may encode null video data when the processor encodes the image data. The video chat application may receive null data packets when the processor receives encoded image data.

It is to be understood that specifics in the aforementioned examples may be used anywhere in one or more embodiments. For instance all optional features of the computing device described above may also be implemented with respect to either of the methods or the computer readable medium described herein. Furthermore although flow diagrams and or state diagrams may have been used herein to describe embodiments the present techniques are not limited to those diagrams or to corresponding descriptions herein. For example flow need not move through each illustrated box or state or in exactly the same order as illustrated and described herein.

The present techniques are not restricted to the particular details listed herein. Indeed those skilled in the art having the benefit of this disclosure will appreciate that many other variations from the foregoing description and drawings may be made within the scope of the present techniques. Accordingly it is the following claims including any amendments thereto that define the scope of the present techniques.

