---

title: Kernel execution for hybrid systems
abstract: A method for executing kernels in a hybrid system includes running a program on a host computer and identifying in an instruction stream of the program a first instruction including a function of a target classification. The method includes generating a first kernel including the function and transmitting the first kernel to a client system to execute the first kernel based on identifying the first instruction as being of the target classification. The method also includes determining whether to store results of executing the first kernel in a read-only buffer of the client system based on determining whether a subsequent instruction of the target classification relies upon results of the first instruction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08966510&OS=08966510&RS=08966510
owner: International Business Machines Corporation
number: 08966510
owner_city: Armonk
owner_country: US
publication_date: 20130204
---
The present disclosure relates generally to distributed function execution and more specifically to distributed function execution for hybrid systems using OpenCL.

Open Computing Language OpenCL is a framework for writing programs that execute across heterogeneous platforms consisting of CPUs Graphics Processing Units GPUs and other processors. OpenCL includes a language for writing kernels which are functions that execute on OpenCL devices and application programming interfaces APIs that are used to define and then control the platforms. OpenCL provides parallel computing using task based and data based parallelism.

Since OpenCL was designed to be used with a non distributed system OpenCL is not designed to optimize data transmission between the various processors and buffers used by the devices in the system. In addition some function calls such as function calls to scientific function libraries requiring parallel processing of algebraic functions may not be supported by a computing system resulting in an error when scientific functions are encountered in an application.

According to one embodiment of the present disclosure a computer implemented method for executing kernels in a hybrid system includes running a program on a host computer and identifying in an instruction stream of the program a first instruction including a function of a target classification. The method includes generating a kernel including the function and transmitting the kernel to a client system to execute the kernel. The method also includes determining whether to push a read only buffer to the client system to store results of executing the kernel based on determining whether a subsequent instruction of the target classification relies upon results of the first instruction.

Accordingly to another embodiment of the present disclosure a computer program product for executing a kernel in a hybrid system includes a tangible storage medium readable by a processing circuit and storing instructions for execution by the processing circuit for performing a method. The method includes running a program on a host computer identifying in an instruction stream of the program a first instruction including a function of a target classification and generating a kernel including the function. The method further includes transmitting the kernel to a client system to execute the kernel and determining whether to push a read only buffer to the client system based on determining whether a subsequent instruction of the target classification relies upon results of the first instruction.

Accordingly to yet another embodiment of the present disclosure a client computer system for executing a function kernel includes memory having stored therein a computer program and a processor. The processor is configured to receive from a host computer a buffer having stored therein a kernel corresponding to an instruction of programming code to execute the kernel to store results of executing the kernel in the buffer and to determine whether to transmit the results of executing the kernel to the host computer based on determining whether the buffer is a read only buffer.

Additional features and advantages are realized through the techniques of the present disclosure. Other embodiments and aspects of the invention are described in detail herein and are considered a part of the claimed invention. For a better understanding of the invention with the advantages and the features refer to the description and to the drawings.

Computing systems running OpenCL may run inefficiently or encounter errors when attempting to call non OpenCL functions floating point functions and complex functions such as scientific functions from scientific function libraries. Embodiments of the present disclosure relate to executing kernels of complex functions such as scientific functions in a distributed system.

The computing system may be referred to as a hybrid system since some operations are executed in a non distributed manner by a host and other operations are executed in a distributed manner by a plurality of processing modules to of a client system . Additionally each of the processing modules to may have different processor types than the host . In one embodiment the host has a SYSTEM z operating system e.g. zOS or zLinux while the client system has any other type of operating system e.g. AIX or Linux . In one embodiment host is configured to transmit Open CL programming instructions to the client system for execution on the client system . The client system may be configured to execute both OpenCL kernels as well as non OpenCL programming code such as C programming code.

The host includes a data management and dispatch unit memory a buffer one or more device I O modules to and one or more processing cores to . The data management and dispatch unit may include processing circuitry including fetching units and a pre processor as well as memory including data caches and buffers. The memory may include volatile and non volatile memory read only memory ROM hard disks hard drives optical disks random access memory RAM flash memory and any other type of memory device for storing data. The buffer may include any type of data buffer such as a RAM data buffer.

The device I O modules to may include data ports and corresponding data processing circuitry such as data converters transmission method converters e.g. electrical to optical and any other circuitry to enable the host to transmit data to and receive data from one or more external devices. The processing cores to may include processors for simultaneously executing instructions.

In one embodiment the host including the data management and dispatch unit and processing cores to are configured to run a first type of programming code or a first runtime environment and the client system is configured to run a second type of programming code or a second runtime environment. For example in one embodiment the host is configured to run non OpenCL programming code on the processing cores to of the host computer . In such an embodiment when an OpenCL instruction is detected by the data management and dispatch unit the data management and dispatch unit may generate a kernel store the kernel in the buffer and transmit the kernel to the client system for executing the OpenCL programming code.

The client system includes an agent buffer and one or more processing modules to . The agent may be a software code executed by a processor to receive instructions from the host and control the client system to execute data from the host on the one or more processing modules to . The buffer may store data received from the host and waiting to be transmitted to the host . In one embodiment the buffer is a group of locations in memory designated by an application or operating system as being allotted to a particular purpose. For example the host may generate a buffer to store a kernel. The buffer may include descriptor data such as contents description size and other information describing the buffer. The host may transfer the buffer or the kernel and descriptor information to the client system which generates the corresponding buffer or allocates memory of the size indicated by the descriptor and having the contents indicated by the descriptor.

In one embodiment the processing modules to are separate computing cores such as separate computers or separate servers. In one embodiment the client system is a distributed system. For example the agent and buffer may be located in a central server and the processing modules to may each be separate computers or servers connected to the central server via a communications network. In an embodiment in which the host is a SYSTEM z processor computer by IBM the separate processing modules to may be BLADE servers.

In operation the data management and dispatch unit of the host fetches executes and manages one or more streams of instructions of one or more applications. The data management and dispatch unit recognizes instructions or functions in the one or more streams of instructions to be sent to the client system for execution. The instructions or functions that are identified to be sent to the client system may correspond to one or more predetermined target classifications such as OpenCL functions and instructions that include an enqueue native kernel instruction. The data management and dispatch unit creates a kernel corresponding to the portions of the stream of instruction to be sent to the client system and stores the kernel input parameters for the function and descriptor data in the buffer . In one embodiment the buffer includes a set up buffers. The host transmits the buffer including the kernel input parameters and descriptor data to the client system . The agent of the client system communicates with the data management and dispatch unit of the host to receive instructions for receiving the buffer generating a corresponding buffer and executing the kernel. The buffer may include a set of buffers including at least one output results buffer designated to store output results of an executed kernel.

As discussed above the data management and dispatch unit may recognize instructions to be sent to the client by detecting an OpenCL instruction or instructions that are not OpenCL but are desired to be executed on the client system as indicated by an enqueue native kernel function in the instructions. Examples of functions that may be executed by enqueueing a native kernel in the client system may include floating point operations scientific functions or calls to a scientific library such as a Basic Linear Algebra Subroutines BLAS library or Linear Algebra Package LAPACK library that include routines for solving systems of simultaneous linear equations or other complex functions.

In one embodiment the agent of the client system executes the scientific functions in a distributed manner such as by dividing up multiple linear equations to be executed simultaneously by different processing modules to aggregates the results and stores the results in the buffer . In one embodiment the contents of the buffer are pushed to a corresponding buffer of the host and the results are then accessed by an execution unit or processor of the host to execute an application.

In one embodiment the data management and dispatch unit determines whether one instruction uses results from another instruction and if both instructions are to be executed on the client system the data management and dispatch unit marks the kernel and the result buffer of the first executed instruction to be kept on the client system until the second instruction is executed. Then the results of the second instruction may be sent to the host without sending the results of the first instruction to the host . Accordingly latency may be reduced and processing bandwidth of the host is preserved.

In particular when the data management and dispatch unit determines that one instruction that is to be sent to the client system depends on results from another the data management and dispatch unit may store a kernel corresponding to the first instruction in a buffer may mark an additional result buffer corresponding to the aforementioned kernel with a read only flag and may also provide exception data such as an exception or violation flag indicating that although the buffer is a read only buffer the buffer may be written to with the results of the first kernel. The host transmits the buffer to the client system and the agent generates an output buffer corresponding to the buffer .

The agent reads the descriptor data of the buffer and may receive instructions from the data management and dispatch unit to execute the first kernel. The agent may divide the kernel into segments and execute different segments on different processing modules to . When the agent recognizes the kernel as corresponding to an enqueue native kernel function the agent may control the processing modules to to execute the kernel in a native programming code instead of the default programming code. For example in one embodiment the client system is configured to execute instructions in an OpenCL runtime execution environment but the kernel associated with the enqueue native kernel instruction may be in another code such as C programming code FORTRAN or any other native code. Accordingly the agent determines the native code and controls the processing modules to to execute the kernel in the native code.

Upon executing the kernel the agent may then determine whether the buffer is read only and if so the agent may determine whether an exception flag is set. If the exception flag is set then the agent accumulates the results of the executed kernel and writes the results to the buffer despite the buffer being designated as read only. The agent may form another buffer corresponding to the second kernel may control the processing modules to to execute the second kernel and may combine the results of the first and second kernels in the second buffer. Alternatively the results of the first kernel may be used as input parameters of the second kernel. The agent may determine whether the second buffer is designated as read only and if not the agent may push the second buffer to the host which forms a corresponding buffer to store the combined results of the first and second kernels.

In other words in the OpenCL programming model embodiment the read only indicator may be set on the output buffer of the kernel. When an OpenCL kernel executes and issues writes to a read only buffer agent would normally flag this as erroneous during compilation or during runtime execution. However according to an embodiment of the invention a programmer first places a pragma directive called read only override in the instruction which allows an output buffer marked as read only to be written to as an output buffer of the kernel even though it violates buffer IO rules write on read only buffer . On the client system the agent receives the pragma setting along with the function execution command and sets a bit in a buffer IO runtime violation flag corresponding to the output buffer of the kernel to remember that the buffer is read only but is being used as read write and provides the function to the local OpenCL Native runtime execution system to execute the kernel with its buffer indicator set to Read Write. The client system executes the kernel and writes its output to the corresponding output buffer as the function call is now compliant with IO buffer rules. If the agent is required to immediately push back the buffer to the host it first checks the buffer IO runtime violation flag. If this set the buffer is not written back right away but is kept in memory for a second kernel to use the output buffer in a different invocation.

In one embodiment the agent of the client system is an OpenCL accelerator runtime environment that an acts as a proxy for the host and calls OpenCL API on behalf of the host . The OpenCL accelerator runtime environment responds to host commands and sends event notifications back to the host.

In one embodiment the data management and dispatch unit determines which data will be read back from the buffer of the client system to the host after kernel execution. The data management and dispatch unit may instruct the agent of the client system to push these data from the buffer to the host after kernel execution. By selectively pushing the data from the client system to the host and storing the data in the host buffer the data management and dispatch unit increases execution speed and minimizes latency by providing the host with access to the data in the host buffer without waiting for the host to request the data from the client system .

As discussed above in certain instances the data written by a kernel on the client system may not need to be read by the host . For example these data may only be needed for execution of another kernel on the client system . If the data management and dispatch unit determines that the data in the buffer of the client system are not need by the host the data in the buffer is not sent back to the host after kernel execution.

Accordingly embodiments of the present disclosure encompass a host computer is configured to transmit a predetermined class of instructions such as OpenCL instructions and instructions including an enqueue native kernel function to a client system for execution. The client system executes the function and pushes the results back to the host computer. The client system may also hold results from a kernel and combine the results with those of a subsequent kernel or use the results as inputs for a subsequent kernel prior to pushing the results to the host computer .

If the instruction is not an OpenCL enqueue task or enqueue ND Range kernel instruction then the host computer determines in block whether the instruction includes an enqueue native kernel function. If so then the instruction or the function called by the instruction is sent to the client system for execution in block . Examples of functions which may include the enqueue native kernel function include floating point functions and other scientific functions particularly complex functions requiring parallel processing of equations.

If the instruction does not include the enqueue native kernel function then the instruction is executed by the host computer in block and the next instruction is fetched and analyzed.

In block when the kernel sent to the client system has been executed an agent in the client system that controls interaction of the host computer with the client system determines whether the output buffer corresponding to the kernel is designated as read only. If not then the results from the executed kernel are pushed to the host computer in block .

If the output buffer is designated as read only then the agent of the client computer determines whether an exception flag is set in the descriptor of the buffer. If it is determined that the exception flag is not set then an error is generated in block since data cannot be written to the buffer. However in embodiments of the invention the host system or a programmer generating the program executed by the host computer includes in the instruction an exception indicator to permit the results from the executed kernel to be written to the read only buffer in block .

In block the results from the output buffer are read and either used as input parameters for a next kernel executed by the client system or are combined with the results of the next kernel. The results of the subsequent kernel may be stored in a buffer and pushed to the host computer in block .

If it is determined in block that the instruction includes the enqueue native kernel function then the agent of the client system determines the native programming code of the kernel. For example in one embodiment the client system is configured to receive OpenCL instructions from a host computer but the kernel is written in C or FORTRAN programming code. Accordingly in block the agent directs the client system to execute the kernel in the native programming code and the client system executes the kernel in the native runtime environment. In block the results of the executed kernel are written to the buffer.

Accordingly the disclosed methods for distributed function execution across a hybrid system allow for the hybrid system to execute a first class of instructions on a host computer and a second class of instructions on a client system. The methods also allow for the hybrid system to recognize particular functions in addition to the second class of instructions to be sent to the client system for execution. The client system according to embodiments of the invention communicates with the host computer to receive the second class of instructions and the additional functions and to execute the additional functions in their native programming code.

As will be appreciated by one skilled in the art aspects of the present disclosure may be embodied as a system method or computer program product. Accordingly aspects of the present disclosure may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present disclosure may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present disclosure may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present disclosure have been described above with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present disclosure. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one more other features integers steps operations element components and or groups thereof.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present disclosure has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated

While the preferred embodiment to the invention had been described it will be understood that those skilled in the art both now and in the future may make various improvements and enhancements which fall within the scope of the claims which follow. These claims should be construed to maintain the proper protection for the invention first described.

