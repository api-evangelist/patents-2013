---

title: Deferred execution in a multi-thread safe system level modeling simulation
abstract: Methods, systems, and machine readable medium for multi-thread safe system level modeling simulation (SLMS) of a target system on a host system. An example of a SLMS is a SYSTEMC simulation. During the SLMS, SLMS processes are executed in parallel via a plurality of threads. SLMS processes represent functional behaviors of components within the target system, such as functional behaviors of processor cores. Deferred execution may be used to defer execution of operations of SLMS processes that access a shared resource. Multi-thread safe direct memory interface (DMI) access may be used by a SLMS process to access a region of the memory in a multi-thread safe manner. Access to regions of the memory may also be guarded if they are at risk of being in a transient state when being accessed by more than one SLMS process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09075666&OS=09075666&RS=09075666
owner: Synopsys, Inc.
number: 09075666
owner_city: Mountain View
owner_country: US
publication_date: 20130820
---
This disclosure relates to the field of system level modeling simulation for example SYSTEMC simulation.

SYSTEMC is a system level modeling language used for simulating the behavior of a target system such as a system on chip SoC . SYSTEMC is approved by the Institute of Electrical and Electronics Engineers IEEE Standards Association as IEEE 1666. SYSTEMC allows a system to be described at different levels of abstraction. More specifically SYSTEMC is a language built in standard C by extending the C language with the use of class libraries. SYSTEMC addresses the need for a system design and verification language that spans hardware and software. The language is particularly suited to modeling a system s partitioning to evaluating and verifying the assignment of blocks to either hardware or software implementations and to architect and measure the interactions between and among functional blocks.

In particular IEEE Standard Std. 1666 2011 Clause 4.2.1.2 third paragraph provides that when the same target system is simulated multiple times using the same stimulus and the same version of the simulator the SYSTEMC process ordering between different runs should not vary. That is the execution order of SYSTEMC processes should be reproducible between various runs of the simulation of the target system in order that intermediate and end results are consistent and reproducible from run to run.

Typically implementation of SYSTEMC simulations is performed in a single threaded manner. However the speed of the simulation has suffered when simulating target systems that themselves comprise multiple processor cores. For example smart phones from year to year are increasingly faster and hold more computation power and are designed with multiple processor cores for performing various tasks. As a result the speed of a SYSTEMC simulation on a single processor core further and further lags behind the speed of the actual hardware device that is being simulated.

In order to speed up the implementation of SYSTEMC simulators the simulation itself may be performed in a multi threaded manner on a multi core processing host system that comprises two or more processor cores within a single computing component. For example multiple processor cores may be placed in a single processor die. Each of the processor cores is configured to act individually for purposes of program instructions. In that manner by distributing instructions of a program for execution by the multiple processor cores the speed for executing the program can be greatly increased when compared to executing the program on a single processor core. In particular one way to speed up a SYSTEMC simulation is by executing multiple runnable SYSTEMC processes concurrently by means of multiple operating system OS threads.

However SYSTEMC by itself is not multi thread safe and under IEEE Std. 1666 2011 a reproducible process execution order must be complied with. That is the reproducibility of the SYSTEMC simulation SYSTEMC kernel code as well as user code should be multi thread safe MT safe . As such data races e.g. simultaneous accesses to shared resources and other conditions that can affect the reproducibility of a SYSTEMC simulation from one run to the next must be avoided.

A conventional solution for multi thread safeness is to guard accesses to shared resources with synchronization elements such as OS mutexes. However this is costly from a simulation performance perspective. Moreover this approach by itself does not address SYSTEMC process execution order reproducibility in order to be compliant with the IEEE Std. 1666 2011 standard. It is thus desirable to have a SYSTEMC simulation that is reproducible and MT safe.

Embodiments of the present disclosure include methods systems and machine readable medium for multi thread safe system level modeling simulation SLMS that produces reproducible results. In one embodiment a SLMS describes a class of simulations that perform simulation using models of components of a target system. A SYSTEMC simulation is one specific example of a SLMS that can benefit from the multi thread safe principles of the disclosed embodiments. In other embodiments other event driven simulators in the field of SLMS that utilize multi threading may also benefit from the multi thread safe principles disclosed herein.

One embodiment of the present disclosure uses deferred execution to make a SLMS reproducible and multi thread safe. According to this embodiment disclosed is a computer implemented method for multi threaded SLMS of a target system on a host system. The host system may include a plurality of processor cores that are controlled by a plurality of threads e.g. operating system threads . The method comprises beginning parallel execution of a plurality of SLMS processes via the plurality of threads. The SLMS processes represent functional behaviors of components within the target system. During the parallel execution of the SLMS processes operations within the SLMS processes that access at least one shared resource within the host system are detected. Also during the parallel execution one or more of the operations within the SLMS processes that access the at least one shared resource within the host system are deferred until after the parallel execution is completed. The deferred operations may then be executed sequentially.

Another embodiment of the present disclosure enables direct memory interface DMI access to be used during a multi threaded SLMS in a multi thread safe manner. According to this embodiment disclosed is a computer implemented method for multi threaded SLMS of a target system on a host system. The method comprises beginning parallel execution of a plurality of SLMS processes via a plurality of threads. The SLMS processes represent functional behaviors of components within the target system that access a memory of the target system through an interconnect of the target system. During the parallel execution a request for DMI access to a region of the memory is detected. The request for DMI access is initiated by a requesting SLMS process of the SLMS processes. Responsive to the request for DMI access the requesting SLMS process is executed in an exclusive execution mode EEM that prevents the requesting SLMS process from executing in parallel with other SLMS processes of the SLMS processes. The DMI access is then granted to the requesting SLMS process responsive to executing the requesting SLMS process in the exclusive execution mode.

A further embodiment of the present disclosure uses guarded memory access to memory regions to make a SLMS multi thread safe. According to this embodiment disclosed is a computer implemented method for multi threaded SLMS of a target system on a host system the target system having components that access a memory of the target system. The method comprises setting a region of the memory into guarded mode based on operations in a plurality of SLMS processes. The SLMS processes represent functional behaviors of the components of the target system. During parallel execution of the SLMS processes via a plurality of threads an access to the region of the memory by a SLMS process of the SLMS processes is detected. Responsive to detecting the access to the region of the memory and the region of the memory being in guarded mode acquiring a guard lock for the region of the memory that allows the SLMS process to access the memory region while preventing other SLMS processes of the SLMS processes from accessing the region of the memory.

The Figures FIGS. and the following description relate to preferred embodiments by way of illustration only. It should be noted that from the following discussion alternative embodiments of the structures and methods disclosed herein will be readily recognized as viable alternatives that may be employed without departing from the principles of what is claimed.

Reference will now be made in detail to several embodiments examples of which are illustrated in the accompanying figures. It is noted that wherever practicable similar or like reference numbers may be used in the figures and may indicate similar or like functionality. The figures depict embodiments of the disclosed system or method for purposes of illustration only. One skilled in the art will readily recognize from the following description that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles described herein.

The machine may be a server computer a client computer a personal computer PC a tablet PC a set top box STB a personal digital assistant PDA a cellular telephone a smartphone a web appliance a network router switch or bridge or any machine capable of executing instructions sequential or otherwise that specify actions to be taken by that machine. Further while only a single machine is illustrated the term machine shall also be taken to include any collection of machines that individually or jointly execute instructions to perform any one or more of the methodologies discussed herein.

The example computer system includes one or more processors e.g. a central processing unit CPU a graphics processing unit GPU a digital signal processor DSP one or more application specific integrated circuits ASICs one or more radio frequency integrated circuits RFICs or any combination of these a main memory and a static memory which are configured to communicate with each other via a bus . The computer system may further include graphics display unit e.g. a plasma display panel PDP a liquid crystal display LCD a projector or a cathode ray tube CRT . The computer system may also include alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse a trackball a joystick a motion sensor or other pointing instrument a storage unit a signal generation device e.g. a speaker and a network interface device which also are configured to communicate via the bus .

The storage unit includes a non transitory machine readable medium on which is stored instructions e.g. software embodying any one or more of the methodologies or functions described herein. The instructions e.g. software may also reside completely or at least partially within the main memory or within the processor e.g. within a processor s cache memory during execution thereof by the computer system the main memory and the processor also constituting machine readable media. The computer system includes multiple processor cores that can be distributed across one or more of the processors . The instructions e.g. software may be transmitted or received over a network via the network interface device .

While machine readable medium is shown in an example embodiment to be a single medium the term machine readable medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database or associated caches and servers able to store instructions e.g. instructions . The term machine readable medium shall also be taken to include any medium that is capable of storing instructions e.g. instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies disclosed herein. The term machine readable medium includes but not be limited to data repositories in the form of solid state memories optical media and magnetic media.

The host system can be divided into a hardware layer H W below line and a software layer S W above line . The hardware layer H W includes several processor cores . The processor cores may be cores of a central processing unit CPU graphics processing unit GPU or other type of processor. Additionally the processor cores may belong to a single processor or may be distributed among several different processors.

The software layer S W includes an operating system OS and a SLMS simulator . In one embodiment the OS and SLMS simulator can be stored as instructions in a machine readable medium of the host system . The OS is a collection of software that manages the hardware of the host system and acts as an intermediary between the SLMS simulator and hardware layer H W of the host system . Examples of an OS include ANDROID LINUX WINDOWS and IOS. OS controls the execution of processor cores through multiple OS threads . The OS threads can be assigned to different processor cores and executed in parallel by the processor cores . In other embodiments the OS may not be present and the SLMS simulator may be responsible for controlling execution of the processor cores through parallel threads.

The SLMS simulator allows verifying the behavior of a target system by performing a multi threaded simulation of a target system model . The target system model is a simulation representation of a physical target system that is to be verified during simulation such as a SoC or other hardware design. The target system includes components such as processor cores an interconnect and a memory. The processor cores are coupled to the interconnect and access the memory through the interconnect. The target system model includes models for the various components of a target system such as processor core models an interconnect model and a memory model . The target system model can also include software not shown that is to be executed on the components of the target system. In other embodiments the target system model may have a different configuration of component models than that shown in .

The SLMS kernel represents the central control logic for a SLMS that schedules and controls execution of the simulation across the OS threads as will be explained herein. In specific the SLMS kernel can generate SLMS processes schedule execution of the SLMS processes and includes functions that are called by the target system model through an application programming interface API during a SLMS.

The SLMS kernel generates SLMS processes from the models of the hardware components of the target system model and software inside the target system model . A SLMS process is a collection of operations that represent the functional behavior of a component of the target system as described by the target system model . For example one SLMS process may represent the behavior of processor core 1 and another SLMS process may represent the behavior of processor core M and these SLMS processes can be generated from the respective core models . The SLMS kernel also controls the execution of the SLMS processes across the OS threads during various execution phases as will be described herein.

In an embodiment that uses SYSTEMC the SLMS process may be a 1 method process or a 2 thread process. A method process behaves like a function and is called upon the occurrence of one or more events. When called the method process starts executing and returns to the calling mechanism when finished. Method processes support the explicit state machine paradigm. On the other hand a thread process behaves like an OS thread and is resumed upon the occurrence of one or more events. When resumed the thread process continues executing and suspends when finished. Thread processes support the implicit state machine paradigm.

Further in an embodiment that uses SYSTEMC the SLMS kernel can include a SYSTEMC class library including a public shell consisting of predefined classes functions macros and so forth that are used directly by the target system model during a SYSTEMC simulation. The SLMS kernel also includes a private kernel that implements the core functionality of the class library.

The SLMS kernel includes a process scheduler module a deferred execution module and a shared resource . Shared resource represents functionality provided by the SLMS kernel that affects the internal state of the SLMS kernel. The shared resource may be accessed by the SLMS processes through the API of the SLMS kernel . Examples of a shared resource in SYSTEMC are the wait function next trigger function notify function cancel function and sc stop function of the SYSTEMC kernel. Although only one shared resource is shown in in other embodiments there may be more than one shared resource .

Process scheduler module schedules the SLMS processes across multiple OS threads so that the SLMS processes can be executed in parallel which can increase the speed of the SLMS. The process scheduler module may schedule multiple SLMS processes to each OS thread . As the SLMS processes are executed in parallel via the OS threads some operations within the SLMS processes may attempt to access the shared resource . Accesses to the shared resource have the potential for causing data races that prevent the simulation results from being reproducible from one simulation run to the next. To prevent data races the deferred execution module detects operations that attempt to access the shared resource during the parallel phase of execution and defers these operations until they can be executed sequentially during a deferred sequential phase of execution.

The shared resource is shown as being in the SLMS kernel but in other embodiments the shared resource may be located elsewhere in the host system . In one embodiment the shared resource may be a shared functionality within the target system model . For example the shared resource in the target system model can be a state variable within the memory model or a global state variable of the target system model . If the shared resource is in the target system model the target system model can be configured to call a function of the deferred execution module when a shared resource of the target system model is being accessed which provides the deferred execution module with an indication of an access to the shared resource. In another embodiment the shared resource may be a shared functionality in the OS . For example the shared resource in the OS can be a standard output function of the OS that prints information to standard output. If the shared resource is in the OS the corresponding OS function call can be wrapped such that the target system model calls a function of the deferred execution module when a shared resource of the OS is being accessed which provides the deferred execution module with an indication of an access to the shared resource.

As shown in there are three different SLMS processes that can be scheduled across the OS threads SLMS process A SLMS process B and SLMS process C . SLMS process A includes an operation of E.notify SC ZERO TIME which is a delta notification of event E in SYSTEMC terminology. Delta notifications allow triggering of events in subsequent delta cycles. SLMS process B includes an operation of E.cancel which cancels any pending notifications of event E. SLMS process C includes the operation wait E which means that SLMS process C waits until event E is triggered before resuming execution.

If SLMS process A is scheduled before SLMS process B SLMS process C will not resume execution in the next delta cycle. That is SLMS process A schedules a notification of event E for the next delta cycle. However SLMS process B within the same delta cycle subsequently cancels any pending notification of event E. In that case in the next delta cycle event E will not be triggered and so SLMS process C will not resume execution.

On the other hand if SLMS process B is scheduled before SLMS process A SLMS process C will resume execution in the next delta cycle. That is SLMS process B is executed before SLMS process A and acts to cancel any pending notification of event E. Thereafter SLMS process A is executed within the same delta cycle and schedules a notification of event E for the next delta cycle. In this scenario the ordering of SLMS process A and SLMS process B is such that event E will be triggered.

When SLMS process A and SLMS process B are scheduled to different OS threads and execute in parallel with each other there is a potential for a race condition between SLMS process A and SLMS process B . During one run of the simulation SLMS process A may execute before SLMS process B and therefore SLMS process C will not run. During another run of the simulation SLMS process B may execute before SLMS process A and therefore SLMS process C will run. This behavior is not desirable and causes the output of a multi threaded SLMS to be unpredictable i.e. non reproducible from one run to the next.

During the parallel execution phase the SLMS processes begin executing in parallel according to their scheduled order across the OS threads . As the SLMS processes are executing in parallel the execution eventually reaches operations that access a shared resource . Operations that access a shared resource are shown with diagonal shading and include operations OP4 OP8 and OP13. Instead of executing these operations OP4 OP8 and OP13 during the parallel execution phase the execution of these operations is deferred until a later deferred sequential execution phase . The operations OP4 OP8 OP13 can be deferred by placing these operations into a deferred execution queue that is assigned to OS Thread 1.

In one embodiment there may be different types of shared resources and only operations accessing shared resources of some types can be deferred. Deferrable operations are those that still allow for standards compliant execution if they are not executed immediately but are executed before the next phase of simulation begins e.g. for SYSTEMC prior to the SYSTEMC update phase . Examples of deferrable operations that access a shared resource include operations corresponding to the SYSTEMC functions of wait next trigger notify cancel and sc stop . Operations accessing these functions can be deferred as these functions do not return a result which is used in subsequent operations of a SLMS process. These functions only affect a later phase of the simulation or a later delta cycle in the simulation.

Non deferrable operations are those that must be executed immediately to allow for standards compliant execution. Non deferrable operations generally include operations that obtain a result used for calculations or decision making during a later operation of the current SLMS process. For instance if OP8 obtains a result that OP9 depends on to make a decision OP8 cannot be deferred because OP9 cannot execute unless it has the result from OP8. Examples of non deferrable operations are operations asking for the current simulation time from the SLMS kernel and operations that create and obtain a handle for a new SLMS process.

In an embodiment where the shared resource is located in the target system model an example of a deferrable operation includes updating the attribute of the target system model that will not be read in the current delta cycle. An example of a non deferrable operation is updating attributes of the target system model that will be read again in the current delta cycle. In an embodiment where the shared resource is located in the OS an example of a deferrable operation is writing data to a logfile of the OS .

In one embodiment the deferred execution module is pre configured with knowledge of which shared resources can be accessed in a deferred manner and which shared resources should not be accessed in a deferred manner. If an operation accesses a shared resource that can be accessed in a deferred manner the deferred execution module defers the operation. If an operation accesses a shared resource that cannot be accessed in a deferred manner the deferred execution module does not defer the operation. Thus some operations i.e. a set of the operations accessing some shared resources are deferred and other operations accessing other shared resources are not deferred.

Other operations within a SLMS process that do not access a shared resource are allowed to continue executing. For example even though operation OP13 of SLMS process P2 is deferred operation OP14 is executed anyways. Additionally the remaining SLMS processes are executed until all of the scheduled SLMS processes P1 P8 have been executed. At this point the parallel execution phase is complete and the deferred sequential execution phase begins.

During the deferred sequential execution phase the operations that were deferred OP4 OP8 OP13 are now executed sequentially. The sequential execution of operations that access a shared resource prevents race conditions and ensures reproducibility of simulation results across different simulation runs. As shown in in one embodiment the deferred operations are executed by order of the OS threads they were originally scheduled to e.g. OP4 OP8 OP13 . Executing by OS thread order is appropriate when the SLMS processes can be reproducibly scheduled across the OS threads e.g. SLMS process P2 always scheduled to OS thread 2 and schedule SLMS process P6 always scheduled to OS thread 1 .

In another embodiment the deferred operations are executed in order of the SLMS processes associated with the deferred operations e.g. OP13 OP4 OP8 . Executing by SLMS process order is appropriate when the scheduling of the SLMS processes across the OS threads is not deterministic. For instance an example of non deterministic scheduling occurs when SLMS process P2 is scheduled to OS thread 2 and SLMS process P6 is scheduled to OS thread 1 in one run but in another run SLMS process P2 is scheduled to OS thread 1 and SLMS process P6 is scheduled to OS thread 2.

Once the deferred sequential execution phase is completed and there are SMLS processes to be executed the SLMS enters another scheduling phase and the process starts again.

In step after parallel execution is complete the deferred execution module orders the deferred operations for sequential execution. As previously explained the deferred operations can be ordered in OS thread order or SLMS process order. In step the deferred execution module begins sequential execution of the deferred operations and the deferred operations then execute in the order determined in step .

The processor core models or more specifically the SLMS processes representing the functional behaviors of the processor cores can access data in the memory models through the interconnect model . For example a SLMS process corresponding to processor core 1 model can request data by calling a function of the interconnect model . The interconnect model then calls a function of the memory model to retrieve the data. The data is then returned to the SLMS process corresponding to processor core 1 model .

Alternatively the SLMS process corresponding to processor core 1 model can access the memory model through DMI access. DMI access allows the SLMS process to bypass the interconnect model during simulation and to directly access a region of the memory model . One implementation of DMI is defined by the IEEE Std. 1666 2011. Simulating a DMI access is much faster than simulating a memory access that uses the interconnect model because the interconnect logic does not need to be simulated during a DMI access. However current implementations of DMI in a multi threaded simulation are problematic because of potential data races between different SLMS processes for example when issuing or invalidating a DMI handle.

The DMI module handles DMI access requests from SLMS processes and grants DMI access to the SLMS processes. In one embodiment a SLMS process requests DMI access by requesting a DMI handle. A DMI handle represents the right to directly access a region of memory and includes information describing the memory access. In one embodiment the DMI handle may include a DMI pointer e.g. a pointer to the region of memory and a DMI descriptor e.g. the start address and end address of the region of memory timing information for reading and writing the region of memory and the type of access granted read write . The DMI module creates the DMI handle and returns the DMI handle to the SLMS process requesting the DMI handle. In one embodiment creating a DMI handle can include filling an empty DMI handle provided by a SLMS process. In other embodiments creating a DMI handle can include generating a brand new DMI handle.

The EEM module places a SLMS process into EEM when a request for DMI access is detected. The EEM prevents a SLMS process from being executed in parallel with other SLMS processes. In one embodiment placing a SLMS process into EEM suspends execution of the SLMS process until all other SLMS processes scheduled for parallel execution are completed after which the SLMS process is executed exclusively i.e. by itself . In other embodiments all other SLMS processes are suspended immediately or only SLMS processes that are already executing are allowed to complete executing upon which the SLMS process in EEM can be executed exclusively. In one embodiment the EEM module may also place a SLMS process into EEM under other conditions such as conditions that will be described with respect to guarded memory access.

During the parallel execution phase the SLMS processes begin executing in parallel according to their scheduled order across the OS threads . As the SLMS processes are executing in parallel the EEM module places SLMS process P2 into EEM which suspends execution of SLMS process P2. The other SLMS processes P1 P3 P7 still execute until they are completed at which point the parallel execution phase is complete. As previously explained in some embodiments placing P2 into EEM immediately suspends all other SLMS processes or only SLMS processes that are already executing e.g. P5 are allowed to complete executing. In one embodiment SLMS process P2 is placed into EEM when it requests DMI access to the memory model .

The sequential execution phase follows the parallel execution phase . SLMS process P2 which is in EEM is now executed exclusively such that no other SLMS processes are executed in parallel with SLMS processes P2. There may be other SLMS processes that are executed before or after SLMS process P2 during the sequential execution phase but no SLMS processes are executed in parallel with SLMS process P2. Exclusive execution of SLMS process P2 thus ensures that SLMS process P2 is the only SLMS process that can access the memory model when it is executing.

In step during the parallel execution phase the DMI module detects a request for DMI access initiated by a requesting SLMS process. For example the requesting SLMS process can be a SLMS process that represents the behavior of processor core 1 and corresponds to core 1 model . In step the EEM module places the requesting SLMS process into EEM and begins exclusively executing the requesting SLMS process in the sequential execution phase .

In step if another SLMS process currently has DMI access to the same memory region for which access was requested in step the existing DMI access is invalidated. Invalidation prevents data races between two or more SLMS processes attempting to access the same memory region via DMI. The existing DMI access is also invalidated while the requesting SLMS process is executing in EEM so that another SLMS process that has the existing DMI access is not interrupted while accessing the memory. In one embodiment invalidating DMI access can include invalidating one or more existing DMI handle that have been granted to one or more other SLMS processes.

In step once the requesting SLMS process is executed in EEM and existing DMI access to the same memory region has been invalidated the DMI module grants DMI access to the requesting SLMS process. Granting DMI access in one embodiment includes creating a DMI handle and then returning the DMI handle to the requesting SLMS process. The DMI handle is created while the requesting SLMS process is executing in EEM because race conditions in granting and invalidating DMI access must be avoided to be multi thread safe. Executing a SLMS process in EEM ensures that only one DMI access request is processed at a time to prevent race conditions between multiple DMI requests. In step the requesting SLMS process then accesses the memory model using DMI. The SLMS process may access the memory model using DMI during the parallel phase of execution or during the sequential phase of execution .

Initially there may be many SLMS processes executing in parallel during the parallel execution phase. SLMS process P then requests a DMI handle from the interconnect model and the request is forwarded to the DMI module within the memory model . In one embodiment the request for a DMI handle represents a DMI access request.

The DMI module requests that SLMS process P be placed into EEM upon detecting the DMI handle request. EEM module places SLMS Process P into EEM upon receiving the request thereby switching SLMS Process P from non EEM into EEM. When SLMS process P is placed into EEM it is initially suspended until all other scheduled SLMS processes complete executing. After the other scheduled SLMS processes complete executing SLMS process P begins executing exclusively in EEM. Once SLMS process P is executing in EEM EEM module confirms that process P is executing in EEM.

The DMI module creates a DMI handle upon receiving confirmation that SLMS process P is executing in EEM. Once the DMI handle is created the DMI module requests that SLMS process P be placed into non EEM. EEM module places SLMS process P into non EEM upon receiving the request. EEM module also confirms that SLMS process P1 is executing in non EEM. DMI module then returns the DMI handle to the interconnect model which forwards the DMI handle back to the SLMS process P. SLMS process P uses the DMI handle for performing DMI accesses to the memory model not shown .

The guard module restricts access to regions e.g. address ranges of the memory model that are subject to transient states and are shared between multiple SLMS processes so that only one SLMS process at a time can access the region. A memory region is in a transient state if the data in the memory region has been accessed for modification but the modified data has not yet been written back into the memory region. Specifically the guard module sets a memory region into guarded mode when the SLMS processes are planning on executing operations on the memory region that lead to transient memory states. The guarded mode indicates that the memory region should be locked when it is accessed. When these guarded memory regions are accessed a guard lock is acquired from the guard module by the SLMS process that intends to access the guarded memory region. The guard lock ensures that only one SLMS process at a time can access the locked memory region.

Locking a memory region prevents transient states from causing variations in the SLMS simulation results from one run to the next. Transient states are now explained by reference to . is a timeline illustrating a possible and correct ordering of two READ MODIFY WRITE operations of separate SLMS processes. A READ MODIFY WRITE operation reads a value from memory model modifies the value and then writes the value back to the memory model . READ MODIFY WRITE operations may sometimes be referred to as atomic operations.

The timeline in shows two READ MODIFY WRITE operations performed sequentially by SLMS process P1 and SLMS process P2. SLMS process P1 represents the functional behavior of processor core 1 and SLMS process P2 represents the functional behavior of processor core 2. Initially the memory value is 10 at . SLMS process P1 performs a READ at a MODIFY at and a WRITE at storing a value of 11. SLMS process P2 thereafter performs a READ at a MODIFY at and a WRITE at storing a value of 12. Because the operations performed by SLMS process P1 and SLMS process P2 were sequentially performed the ending value at point is 12.

On the other hand is a timeline illustrating another possible and incorrect ordering of two READ MODIFY WRITE operations of separate SLMS processes. Initially the memory value is 10 at . SLMS process P1 performs a READ at a MODIFY at and a WRITE at storing a value of 11. In parallel with SLMS process P1 SLMS process P2 performs a READ at a MODIFY at and a WRITE at storing a value of 11. Because the operations performed by SLMS process P1 and SLMS process P2 were performed in parallel the ending value at point is 11.

As shown by the timelines in and the memory region storing the value is in a transient state between the time SLMS process P1 reads the value and the time the modified value is written back to the memory region. The ending value stored in the memory region thus depends on the timing of the two READ MODIFY WRITE operations performed by SLMS process P1 and SLMS process P2. Acquiring a guard lock for this memory region prevents any intervening accesses to the memory region while in a transient state and creates consistency in the SLMS results across different simulation runs.

If there are operations leading to transient states in step the guard module places one or more memory regions that are shared and will be accessed by those operations into guarded mode. The guarded mode indicates that the memory region is shared and is subject to transient states and should only be accessed by one SLMS process at a time. Steps and can occur prior to the SLMS processes being executed in parallel. In other embodiments steps and can occur while the SLMS processes are being executed in parallel.

In step as the SLMS processes are executing in parallel during a parallel phase of execution a SLMS process attempts to access a memory region and the guard module detects this memory access. In SYSTEMC terms the detected memory access may be an interface method call IMC that is initiated by a SLMS process that requests memory access through the interconnect model . This IMC can be detected by portions of the guard module that are distributed within the interconnect model or the memory model . Alternatively if the SLMS process accesses the memory model through DMI the guard module may detect the DMI access before any data is transferred via DMI. The DMI access can be detected by portions of the guard module that are distributed within the processor core models .

In step the guard module determines if the accessed memory region is in guarded mode. If the memory region is in guarded mode in step the guard module acquires a guard lock for the memory region. The guard lock allows only a single SLMS process to access the memory region while the guard lock is held. On the other hand if the memory region is not in guarded mode in step the guard module does not acquire a guard lock for the memory region because the memory region is not at risk of being in a transient state or is not being shared.

In step the SLMS process accesses the memory region. If a guard lock was previously acquired in step the memory access occurs while the lock is held. If a lock was not acquired as in step the memory access occurs without any lock being held.

In step the guard lock is released if a guard lock was previously acquired for the memory region in step . In one embodiment guard locks are not kept across SLMS process invocations. A SLMS process invocation is a single execution of a SLMS process i.e. between resuming and suspending the SLMS process . This is to avoid deadlock in the simulation. As an example a deadlock may occur when two SLMS processes are each holding a guard lock and are waiting for the guard lock held by the other SLMS process to be released.

The SLMS processes may iterate and repeat at step to detect another access to a memory region. In step the guard module clears the guarded mode once the memory region no longer needs to be guarded. For example the guarded mode may be cleared if the execution of SLMS processes is switched from a parallel phase of execution into a sequential phase of execution where transient states are no longer relevant. The guarded mode also may be cleared when the software being simulated in the target system causes the operations in the SLMS processes to change such that they no longer access the memory region in a way that causes transient state or when the memory region is no longer shared.

In one embodiment the EEM is used during the transition from non guarded mode into guarded mode and back. For instance when transitioning to guarded mode the EEM module temporarily places a SLMS process that includes transient operations into EEM. Once the SLMS process is confirmed to be executing in EEM the guard module places a memory region into guarded mode. Placing the memory region into guarded mode while executing a SLMS process in EEM prevents data races for example if one SLMS process wants to place a memory region into guarded mode and another SLMS process wants to clear the guarded mode for the memory region.

In one embodiment the deferred execution module the DMI module the EEM module and the guard module may all reside within the same host system. A single SLMS can thus use deferred execution multi thread safe DMI access and or guarded memory access to simulate in a multi thread safe manner.

Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter herein.

Certain embodiments are described herein as including logic or a number of components modules or mechanisms. Modules may constitute either software modules e.g. code embodied on a machine readable medium or hardware modules. A hardware module is a tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more hardware modules of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a hardware module that operates to perform certain operations as described herein.

In various embodiments a hardware module may be implemented mechanically or electronically. For example a hardware module may comprise dedicated circuitry or logic that is permanently configured e.g. as a special purpose processor such as a field programmable gate array FPGA or an application specific integrated circuit ASIC to perform certain operations. A hardware module may also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

The various operations of example methods described herein may be performed at least partially by a plurality of processors cores e.g. processor that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processor cores may constitute processor implemented modules that operate to perform one or more operations or functions. The modules referred to herein may in some example embodiments comprise processor implemented modules.

The plurality of processor cores may also operate to support performance of the relevant operations in a cloud computing environment or as a software as a service SaaS . For example at least some of the operations may be performed by a group of computers as examples of machines including processors these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. application program interfaces APIs . 

The performance of certain of the operations may be distributed among the plurality of processor cores not only residing within a single machine but deployed across a number of machines. In some example embodiments the plurality of processor cores or processor implemented modules may be located in a single geographic location e.g. within a home environment an office environment or a server farm . In other example embodiments the plurality of processor cores or processor implemented modules may be distributed across a number of geographic locations.

Some portions of this specification are presented in terms of algorithms or symbolic representations of operations on data stored as bits or binary digital signals within a machine memory e.g. a computer memory . These algorithms or symbolic representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. As used herein an algorithm is a self consistent sequence of operations or similar processing leading to a desired result. In this context algorithms and operations involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions herein using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or a combination thereof registers or other machine components that receive store transmit or display information.

As used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. For example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the disclosure. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for a system and a process for a multi thread safe system level modeling simulation that enables the simulation results to be reproducible across simulation runs through the disclosed principles herein. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications changes and variations which will be apparent to those skilled in the art may be made in the arrangement operation and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims.

