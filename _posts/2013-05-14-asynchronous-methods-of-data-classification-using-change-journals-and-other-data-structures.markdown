---

title: Asynchronous methods of data classification using change journals and other data structures
abstract: Aspects of the present invention are generally concerned with systems and methods for generating a database of metadata that describes system data and storage operations. The database of metadata may be referred to herein as a “metabase.” For example, to generate a metabase, a data agent may traverse a file system to obtain certain characteristics of data managed by the file system while substantially simultaneously detecting and recording change notifications. These actions may be performed even if the actions of the data agent are interrupted one or more times during the traversal of the file system. The data agent may process the characteristics and change notifications to generate and update a metabase. Once formed, the metabase may be consulted to determine changes in system data rather than determining the changes by scanning the data files themselves.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09047296&OS=09047296&RS=09047296
owner: CommVault Systems, Inc.
number: 09047296
owner_city: Tinton Falls
owner_country: US
publication_date: 20130514
---
This application is a continuation of U.S. patent application Ser. No. 12 978 050 filed Dec. 23 2010 entitled ASYNCHRONOUS METHODS OF DATA CLASSIFICATION USING CHANGE JOURNALS AND OTHER DATA STRUCTURES now U.S. Pat. No. 8 442 983 which claims the benefit of U.S. Patent Application No. 61 291 813 filed Dec. 31 2009 entitled ASYNCHRONOUS METHODS OF DATA CLASSIFICATION USING CHANGE JOURNALS AND OTHER DATA STRUCTURES each of which is hereby incorporated herein by reference in its entirety.

Current storage management systems employ a number of different methods to perform storage operations on electronic data. For example data can be stored in primary storage as a primary copy or in secondary storage as various types of secondary copies including as a backup copy a snapshot copy a hierarchical storage management copy HSM as an archive copy and as other types of copies.

Storage systems may scan the file system of a client or other computing device for various reasons such as to determine which data objects on the client should be associated with a particular storage operation. For example this determining may involve collecting metadata by scanning or traversing the file system of the client prior to performing storage operations. The scanning process is typically time consuming and uses significant client resources that might be more desirably spent performing other tasks associated with production applications. Thus it is desirable to limit the frequency of file system scans. To reduce the number of file system scans a system may update the metadata obtained from a scan using other information generated and cached by a change journal process during and after a scan. However if a volume on a client s file system is large and or a file system experiences a high rate of changes to files the information cached by a change journal process alone may be insufficient to update the metadata to reflect all system changes that occurred during a scan. The scanning process may also need to be restarted anew if the scan is paused for any reason before its completion.

The need exists for a system that overcomes the above problems as well as one that provides additional benefits. Overall the examples herein of some prior or related systems and their associated limitations are intended to be illustrative and not exclusive. Other limitations of existing or prior systems will become apparent to those of skill in the art upon reading the following Detailed Description.

The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the claimed invention.

Aspects of the present invention are generally concerned with systems and methods for generating a database of metadata that describes system data and storage operations. The database of metadata may be referred to herein as a metabase. For example to generate a metabase a data agent may traverse a file system to obtain certain characteristics of data managed by the file system while substantially simultaneously detecting and recording change notifications. These actions may be performed even if the actions of the data agent are interrupted one or more times during the traversal of the file system. The data agent may process the characteristics and change notifications to generate and update a metabase. Once formed the metabase may be consulted to determine changes in system data rather than determining the changes by scanning the data files themselves.

With this arrangement if it is desired to obtain information regarding data a system administrator or system process may simply consult the metabase for such information rather than iteratively accessing and analyzing each data object in the system. Thus this significantly reduces the amount of time required to obtain data object information by substantially eliminating the need to obtain information from the source data and furthermore minimizes the involvement of network resources in this process substantially reducing the processing burden on the host system.

Various examples of the invention will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand however that the invention may be practiced without many of these details. Likewise one skilled in the relevant art will also understand that the invention may include many other obvious features not described in detail herein. Additionally some well known structures or functions may not be shown or described in detail below so as to avoid unnecessarily obscuring the relevant description.

The terminology used below is to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific examples of the invention. Indeed certain terms may even be emphasized below however any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section.

While aspects of the invention such as certain functions are described as being performed exclusively on a single device the invention can also be practiced in distributed environments where functions or modules are shared among disparate processing devices which are linked through a communications network such as a Local Area Network LAN Wide Area Network WAN and or the Internet. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

Aspects of the invention may be stored or distributed on tangible computer readable media including magnetically or optically readable computer discs hard wired or preprogrammed chips e.g. EEPROM semiconductor chips nanotechnology memory biological memory or other data storage media. Alternatively computer implemented instructions data structures screen displays and other data under aspects of the invention may be distributed over the Internet or over other networks including wireless networks on a propagated signal on a propagation medium e.g. an electromagnetic wave s a sound wave etc. over a period of time or they may be provided on any analog or digital network packet switched circuit switched or other scheme .

Aspects of the invention will now be described in detail with respect to . illustrate various components of a data storage system that may employ aspects of the invention. is a flow diagram illustrating a process for building a metabase. is a flow diagram illustrating a process for scanning a client file system and populating interim change tables in a substantially simultaneous fashion.

The system may generally include combinations of hardware and software components associated with performing storage operations on electronic data. Storage operations include copying backing up creating storing retrieving and or migrating primary storage data e.g. data stores and or and secondary storage data which may include for example snapshot copies backup copies hierarchical storage management HSM copies archive copies and other types of copies of electronic data stored on storage devices . The system may provide one or more integrated management consoles for users or system processes to interface with in order to perform certain storage operations on electronic data as further described herein. Such integrated management consoles may be displayed at a central control facility or several similar consoles distributed throughout multiple network locations to provide global or geographically specific network data storage information.

In one example storage operations may be performed according to various storage preferences for example as expressed by a user preference a storage policy a schedule policy and or a retention policy. A storage policy is generally a data structure or other information source that includes a set of preferences and other storage criteria associated with performing a storage operation. The preferences and storage criteria may include but are not limited to a storage location relationships between system components network pathways to utilize in a storage operation data characteristics compression or encryption requirements preferred system components to utilize in a storage operation a single instancing or variable instancing policy to apply to the data and or other criteria relating to a storage operation. For example a storage policy may indicate that certain data is to be stored in the storage device retained for a specified period of time before being aged to another tier of secondary storage copied to the storage device using a specified number of data streams etc.

A schedule policy may specify a frequency with which to perform storage operations and a window of time within which to perform them. For example a schedule policy may specify that a storage operation is to be performed every Saturday morning from 2 00 a.m. to 4 00 a.m. A retention policy may specify how long data is to be retained at specific tiers of storage or what criteria must be met before data may be pruned or moved from one tier of storage to another tier of storage. In some cases the storage policy includes information generally specified by the schedule policy and or the retention policy. Put another way the storage policy includes the schedule policy and or the retention policy. Storage policies schedule policies and or retention policies may be stored in a database of the storage manager to archive media as metadata for use in restore operations or other storage operations or to other locations or components of the system .

The system may comprise a storage operation cell that is one of multiple storage operation cells arranged in a hierarchy or other organization. Storage operation cells may be related to backup cells and provide some or all of the functionality of backup cells as described in the assignee s U.S. patent application Ser. No. 09 354 058 now U.S. Pat. No. 7 395 282 which is incorporated herein by reference in its entirety. However storage operation cells may also perform additional types of storage operations and other types of storage management functions that are not generally offered by backup cells.

Storage operation cells may contain not only physical devices but also may represent logical concepts organizations and hierarchies. For example a first storage operation cell may be configured to perform a first type of storage operations such as HSM operations which may include backup or other types of data migration and may include a variety of physical components including a storage manager or management agent a secondary storage computing device a client and other components as described herein. A second storage operation cell may contain the same or similar physical components however it may be configured to perform a second type of storage operations such as storage resource management SRM operations and may include monitoring a primary data copy or performing other known SRM operations.

Thus as can be seen from the above although the first and second storage operation cells are logically distinct entities configured to perform different management functions i.e. HSM and SRM respectively each storage operation cell may contain the same or similar physical devices. Alternatively different storage operation cells may contain some of the same physical devices and not others. For example a storage operation cell configured to perform SRM tasks may contain a secondary storage computing device client or other network device connected to a primary storage volume while a storage operation cell configured to perform HSM tasks may instead include a secondary storage computing device client or other network device connected to a secondary storage volume and not contain the elements or components associated with and including the primary storage volume. The term connected as used herein does not necessarily require a physical connection rather it could refer to two devices that are operably coupled to each other communicably coupled to each other in communication with each other or more generally refer to the capability of two devices to communicate with each other. These two storage operation cells however may each include a different storage manager that coordinates storage operations via the same secondary storage computing devices and storage devices . This overlapping configuration allows storage resources to be accessed by more than one storage manager such that multiple paths exist to each storage device facilitating failover load balancing and promoting robust data access via alternative routes.

Alternatively or additionally the same storage manager may control two or more storage operation cells whether or not each storage operation cell has its own dedicated storage manager . Moreover in certain embodiments the extent or type of overlap may be user defined through a control console or may be automatically configured to optimize data storage and or retrieval.

The clients typically include application software for performing various operations. Clients typically also include an operating system on which the application software runs. Clients may include local storage such as a media module or media drive with fixed or removable media. A file system can be provided to facilitate and control file access by the operating system and application software. File systems can facilitate access to local and remote storage devices for file or data access and storage.

File systems can also facilitate the generation of certain kinds of metadata pertaining to data objects stored on local and remote storage devices. For example a file system may expose an Application Programming Interface API that permits processes or modules within the system to determine one or more of the following for a data object accessible by the file system a data owner e.g. the client or user that generates the data object a last modified time e.g. the time of the most recent modification the data object size e.g. number of bytes of data information about the data object s content e.g. content tags to from information for email objects e.g. an email sender email recipient or individual or group on an email distribution list creation time e.g. the time at which the data object was created file type e.g. format or application type last accessed time e.g. the time the data object was most recently accessed or viewed application type e.g. the application which generated the data object location or path e.g. a current past or future location of the data object and network pathways to from the data object business unit e.g. a group or department that generates manages or is otherwise associated with the data object and aging information e.g. a schedule for migrating a data object to secondary or long term storage etc.

A client may also comprise a monitor agent that is configured to monitor and record certain data interactions within a client typically on a continuous basis during the operation of the client . In one example a monitor agent may include a filter driver program and may be deployed on an input output port or data stack and operate in conjunction with a client file system to record data interactions. For example a monitor agent may be deployed to monitor interactions between client and data objects stored in data store . A monitor agent may maintain a change journal database that comprises a change record for each data interaction detected by the monitor agent. Each change record may include relevant properties of the data object involved in an interaction such as a file reference number FRN and or parent file reference number PFRN . Each change record may also include one or more change codes that provide information regarding the type of data interaction detected. Each change record may further include a unique change record identifier such as an update sequence number USN that the monitor agent increments for each new change record created and stored in the change journal database.

In some examples the size of the change journal database may be fixed so that the monitor agent may cache or store only a certain number of change records within the change journal database. This fixed size is referred to herein as the change journal cache size. The change journal cache size may be configurable by a user or other processes or modules running within the system. In examples where the change journal database has a fixed change journal cache size the change journal database may operate on a first in first out FIFO basis. Thus at any given time the change journal database may reflect only a fixed number of the most recent data interactions detected by the monitor agent.

The monitor agent may further provide a change notification service that permits other processes or modules within the system to subscribe to the change notification service in order to receive change notifications. A change notification reflects all or some of the content of a change record and is provided by the change notification service at approximately the same time that the change record is created by the monitor agent or shortly thereafter. For example a change notification may include a USN one or more change codes and an FRN. In some implementations upon the request of a subscriber the change notification service may be configured to provide additional metadata information in each change notification that may not be included in the change record. For example a change notification service may provide to a subscriber in a change notification a USN one or more change codes an FRN data object size and last modified time.

In some implementations a monitor agent may be provided by an operating system on the client or elsewhere. Either the monitor agent itself or the operating system may expose an API to permit other system components to query a change journal database and or subscribe to a change notification service. One example of a monitor agent is Microsoft s Change Journal. In one example Microsoft s Change Journal also provides a change notification service. In some examples the clients include storage mechanisms for allowing computer programs or other instructions or data to be loaded into memory for execution. Such storage mechanisms might include for example a fixed or removable storage unit and an interface. Examples of such storage units and interfaces can include a program cartridge and cartridge interface a removable memory for example a flash memory or other removable memory module and memory slot a PCMCIA slot and card and other fixed or removable storage units and interfaces that allow software and data to be transferred from the storage unit to memory.

Data agent may be a software module or part of a software module that is generally responsible for performing storage operations on the data of the client stored in data store or other memory location. Each client may have at least one data agent and the system can support multiple clients . Data agent may be distributed between client and storage manager and any other intermediate components or it may be deployed from a remote location or its functions approximated by a remote process that performs some or all of the functions of data agent . In some implementations a data agent may be responsible for generating a metabase and or metabase information stored within a secondary storage computing device index .

As used herein the term module might describe a given unit of functionality that can be performed in accordance with one or more embodiments of the present invention. As used herein a module might be implemented utilizing any form of hardware software firmware or a combination thereof. For example one or more processors controllers ASICs PLAs logical components software routines or other mechanisms might be implemented to make up a module. In implementation the various modules described herein might be implemented as discrete modules or the functions and features described can be shared in part or in total among one or more modules. In other words as would be apparent to one of ordinary skill in the art after reading this description the various features and functionality described herein may be implemented in any given application and can be implemented in one or more separate or shared modules in various combinations and permutations. Even though various features or elements of functionality may be individually described or claimed as separate modules one of ordinary skill in the art will understand that these features and functionality can be shared among one or more common software and hardware elements and such description shall not require or imply that separate hardware or software components are used to implement such features or functionality.

The overall system may employ multiple data agents each of which may perform storage operations on data associated with a different application. For example different individual data agents may be designed to handle Microsoft Exchange data Lotus Notes data Microsoft Windows file system data Microsoft Active Directory Objects data Microsoft SQL Server data Microsoft Sharepoint Server data and other types of data known in the art. Other embodiments may employ one or more generic data agents that can handle and process multiple data types rather than using the specialized data agents described above.

If a client has two or more types of data one data agent may be required for each data type to perform storage operations on the data of the client . For example to back up migrate and restore all the data on a Microsoft Exchange server the client may use one Microsoft Exchange Mailbox data agent to back up the Exchange mailboxes one Microsoft Exchange Database data agent to back up the Exchange databases one Microsoft Exchange Public Folder data agent to back up the Exchange Public Folders and one Microsoft Windows File System data agent to back up the file system of the client . These data agents would be treated as four separate data agents by the system even though they reside on the same client .

Alternatively the overall system may use one or more generic data agents each of which may be capable of handling two or more data types. For example one generic data agent may be used to back up migrate and restore Microsoft Exchange Mailbox data and Microsoft Exchange Database data while another generic data agent may handle Microsoft Exchange Public Folder data and Microsoft Windows File System data etc.

Data agents may be responsible for arranging or packing data to be copied or migrated into a certain format such as an archive file. Nonetheless it will be understood that this represents only one example and any suitable packing or containerization technique or transfer methodology may be used if desired. Such an archive file may include metadata a list of files or data objects copied the file and data objects themselves. Moreover any data moved by the data agents may be tracked within the system by updating indexes associated with appropriate storage managers or secondary storage computing devices . As used herein a file or a data object refers to any collection or grouping of bytes of data that can be viewed as one or more logical units.

Generally speaking storage manager may be a software module or other application that coordinates and controls storage operations performed by the system . Storage manager may communicate with some or all elements of the system including clients data agents secondary storage computing devices and storage devices to initiate and manage storage operations e.g. backups migrations data recovery operations etc. .

Storage manager may include a jobs agent that monitors the status of some or all storage operations previously performed currently being performed or scheduled to be performed by the system . One or more storage operations are alternatively referred to herein as a job or jobs. Jobs agent may be communicatively coupled to an interface agent e.g. a software module or application . Interface agent may include information processing and display software such as a graphical user interface GUI an application programming interface API or other interactive interface through which users and system processes can retrieve information about the status of storage operations. For example in an arrangement of multiple storage operations cell through interface agent users may optionally issue instructions to various storage operation cells regarding performance of the storage operations as described and contemplated herein. For example a user may modify a schedule concerning the number of pending snapshot copies or other types of copies scheduled as needed to suit particular needs or requirements. As another example a user may employ the GUI to view the status of pending storage operations in some or all of the storage operation cells in a given network or to monitor the status of certain components in a particular storage operation cell e.g. the amount of storage capacity left in a particular storage device .

Storage manager may also include a management agent that is typically implemented as a software module or application program. In general management agent provides an interface that allows various management agents in other storage operation cells to communicate with one another. For example assume a certain network configuration includes multiple storage operation cells hierarchically arranged or otherwise logically related in a WAN or LAN configuration. With this arrangement each storage operation cell may be connected to the other through each respective interface agent . This allows each storage operation cell to send and receive certain pertinent information from other storage operation cells including status information routing information information regarding capacity and utilization etc. These communications paths may also be used to convey information and instructions regarding storage operations.

For example a management agent in a first storage operation cell may communicate with a management agent in a second storage operation cell regarding the status of storage operations in the second storage operation cell. Another illustrative example includes the case where a management agent in a first storage operation cell communicates with a management agent in a second storage operation cell to control storage manager and other components of the second storage operation cell via management agent contained in storage manager .

Another illustrative example is the case where management agent in a first storage operation cell communicates directly with and controls the components in a second storage operation cell and bypasses the storage manager in the second storage operation cell. If desired storage operation cells can also be organized hierarchically such that hierarchically superior cells control or pass information to hierarchically subordinate cells or vice versa.

Storage manager may also maintain an index a database or other data structure . The data stored in database may be used to indicate logical associations between components of the system user preferences management tasks media containerization and data storage information or other useful data. For example the storage manager may use data from database to track logical associations between secondary storage computing device and storage devices or movement of data as containerized from primary to secondary storage .

Generally speaking the secondary storage computing device which may also be referred to as a media agent may be implemented as a software module that conveys data as directed by storage manager between a client and one or more storage devices such as a tape library a magnetic media storage device an optical media storage device or any other suitable storage device. In one embodiment secondary storage computing device may be communicatively coupled to and control a storage device . A secondary storage computing device may be considered to be associated with a particular storage device if that secondary storage computing device is capable of routing and storing data to that particular storage device .

In operation a secondary storage computing device associated with a particular storage device may instruct the storage device to use a robotic arm or other retrieval means to load or eject a certain storage media and to subsequently archive migrate or restore data to or from that media. Secondary storage computing device may communicate with a storage device via a suitable communications path such as a SCSI or Fibre Channel communications link. In some embodiments the storage device may be communicatively coupled to the storage manager via a SAN.

Each secondary storage computing device may maintain an index a database or other data structure that may store index data generated during storage operations for secondary storage SS as described herein including creating a metabase MB . For example performing storage operations on Microsoft Exchange data may generate index data. Such index data provides a secondary storage computing device or other external device with a fast and efficient mechanism for locating data stored or backed up since a device may simply consult the metabase for information rather than iteratively accessing and analyzing each data object stored or backed up. Thus a secondary storage computing device index or a database of a storage manager may store data associating a client with a particular secondary storage computing device or storage device for example as specified in a storage policy while a database or other data structure in secondary storage computing device may indicate where specifically the data of the client is stored in storage device what specific files were stored and other information associated with storage of the data of the client . In some embodiments such index data may be stored along with the data backed up in a storage device with an additional copy of the index data written to index cache in a secondary storage device. Thus the data is readily available for use in storage operations and other activities without having to be first retrieved from the storage device .

Generally speaking information stored in cache is typically recent information that reflects certain particulars about operations that have recently occurred. After a certain period of time this information is sent to secondary storage and tracked. This information may need to be retrieved and uploaded back into a cache or other memory in a secondary computing device before data can be retrieved from storage device . In some embodiments the cached information may include information regarding format or containerization of archives or other files stored on storage device .

One or more of the secondary storage computing devices may also maintain one or more single instance databases . Single instancing alternatively called data deduplication generally refers to storing in secondary storage only a single instance of each data object or data block in a set of data e.g. primary data . More details as to single instancing may be found in one or more of the following commonly assigned U.S. patent applications 1 U.S. patent application Ser. No. 11 269 512 entitled SYSTEM AND METHOD TO SUPPORT SINGLE INSTANCE STORAGE OPERATIONS 2 U.S. patent application Ser. No. 12 145 347 entitled APPLICATION AWARE AND REMOTE SINGLE INSTANCE DATA MANAGEMENT or 3 U.S. patent application Ser. No. 12 145 342 entitled APPLICATION AWARE AND REMOTE SINGLE INSTANCE DATA MANAGEMENT 4 U.S. patent application Ser. No. 11 963 623 entitled SYSTEM AND METHOD FOR STORING REDUNDANT INFORMATION 5 U.S. patent application Ser. No. 11 950 376 entitled SYSTEMS AND METHODS FOR CREATING COPIES OF DATA SUCH AS ARCHIVE COPIES 6 U.S. patent application Ser. No. 12 565 576 entitled SYSTEMS AND METHODS FOR MANAGING SINGLE INSTANCING DATA or 7 U.S. patent application Ser. No. 12 647 906 entitled BLOCK LEVEL SINGLE INSTANCING each of which is incorporated by reference herein in its entirety.

In some examples the secondary storage computing devices maintain one or more variable instance databases. Variable instancing generally refers to storing in secondary storage one or more instances but fewer than the total number of instances of each data block or data object in a set of data e.g. primary data . More details as to variable instancing may be found in the commonly assigned U.S. patent application Ser. No. 12 649 454 entitled STORING A VARIABLE NUMBER OF INSTANCES OF DATA OBJECTS.

In some embodiments certain components may reside and execute on the same computer. For example in some embodiments a client such as a data agent or a storage manager coordinates and directs local archiving migration and retrieval application functions as further described in the previously referenced U.S. patent application Ser. No. 09 610 738. This client can function independently or together with other similar clients .

As shown in each secondary storage computing device has its own associated metabase . Each client may also have its own associated metabase that may provide a fast and efficient mechanism for locating data since other system components may simply consult the metabase for information rather than iteratively accessing and analyzing each data object associated with the client e.g. data objects stored in data store . However in some embodiments each tier of storage such as primary storage secondary storage tertiary storage etc. may have multiple metabases or a centralized metabase as described herein. For example rather than a separate metabase or index associated with each client in the metabases on this storage tier may be centralized. Similarly second and other tiers of storage may have either centralized or distributed metabases. Moreover mixed architecture systems may be used if desired that may include a first tier centralized metabase system coupled to a second tier storage system having distributed metabases and vice versa etc.

Moreover in operation a storage manager or other management module may keep track of certain information that allows the storage manager to select designate or otherwise identify metabases to be searched in response to certain queries as further described herein. Movement of data between primary and secondary storage may also involve movement of associated metadata and other tracking information as further described herein.

In some examples primary data may be organized into one or more sub clients. A sub client is a portion of the data of one or more clients and can contain either all of the data of the clients or a designated subset thereof. As depicted in the data store includes two sub clients. For example an administrator or other user with the appropriate permissions the term administrator is used herein for brevity may find it preferable to separate email data from financial data using two different sub clients having different storage preferences retention criteria etc.

Referring to a block diagram illustrating an example of components of a server used in data storage operations is shown. A server such as storage manager may communicate with clients to determine data to be copied to storage media. As described above the storage manager may contain a jobs agent a management agent a database a stream agent an interface agent and or other agents . Jobs agent may manage and control the scheduling of jobs such as copying data files from clients to storage devices . Management agent may control the overall functionality and processes of the data storage system or may communicate with global managers. Database or another data structure may store storage policies schedule policies retention policies or other information such as historical storage statistics storage trend statistics and so on. Interface agent may interact with a user interface enabling the system to present information to administrators and receive feedback or other input from the administrators or with other components of the system such as via APIs . The other agents may perform additional functions.

Referring to a block diagram illustrating components of a data stream that may be utilized by a data storage system is shown. The stream may originate from a client continue as indicated by reference character to a media agent and then as indicated by reference character to a secondary storage device . For example in storage operations the system may store receive and or prepare data to be stored copied or backed up at a server or client . The system may then transfer the data to be stored to media agent which may then refer to storage policies schedule policies and retention policies and other policies to choose a secondary storage device . The media agent may include a snapshot agent and an index agent although these agents may also be separate components . The secondary storage device receives the data from the media agent and stores the data as a secondary copy. Secondary storage devices may be magnetic tapes optical disks USB and other similar media disk and tape drives and so on. Of course the data storage system may employ other configurations of stream components not shown in .

In some implementations the generated metabase may be represented by a table wherein each row corresponds to a file or data object accessible by a client s file system. The metabase may have at most one row for each file or data object accessible by the file system. The columns or fields for each row in the metabase table may include fields such as FRN PFRN the most recent USN relating to the file that is reflected in the metabase table creation time last modified time last accessed time data object size low and or high data object size short file name location or full path a user or owner identifier metatags and or other attributes of the data object.

The process begins at step where data agent generates and populates an initial change table. Each row in an initial change table corresponds to a particular change record notified or created by the monitor agent. The initial change table may comprise columns or data fields such as USN FRN PFRN and change codes. The initial change table may also comprise additional fields such as those described previously with respect to a metabase table. Additionally data agent may associate an initial change table with a start USN and an end USN the lowest and highest USNs that appear in the table . To populate an initial change table a data agent may request an initial set of change records present in the change journal database at the time of the request or shortly thereafter. Data agent may utilize an API to request and receive this set of change records from the monitor agent. Furthermore at step data agent may request and receive via a file system API additional metadata from the file system regarding one or more data objects that are the subject of a received change record. Using the received information from one or both of these sources data agent may populate an initial change table.

At step data agent substantially simultaneously 1 populates a metabase by scanning or traversing a client file system and 2 populates interim change tables. Each row in an interim change table corresponds to a particular change record created by a monitor agent. An interim change table may have columns or fields similar to those of an initial change table described previously. In some implementations an interim change table may instead have fewer additional or different data fields. A data agent may associate an interim change table with a start USN and an end USN the lowest and highest USNs that appear in the table .

Populating a metabase by scanning or traversing a large volume on a client s file system or another portion of a client s file system may take a significant amount of time. Additionally applicable system conditions and user provided settings may mandate that a data agent go from being online to being offline which may mean that the data agent pauses or stops its traversal or other processing functions. Pauses may further add to the total time required for a file system traversal. For example a data agent may go offline if a client is powered off if there is heavy processing or network load on the client or during certain scheduled times defined by a user e.g. daytime hours . To reduce the strain on a client s file system it is desirable that when a data agent is restarted i.e. when the data agent is online performing a file system traversal goes temporarily offline and then comes back online it may simply resume its traversal of the file system from approximately the same point in the file system without having to re scan significant portions of the file system. Thus the system may flag a location in the table when the scan stopped so that the scan can resume from that point as based on e.g. one of the identifiers noted above such as USN .

If data interactions occur on a client during a file system scan some of the metadata acquired during the scan may be inaccurate by the end of the scan. For example if a data agent traverses a specific file early in a scan e.g. acquires and stores metadata reflecting its last modified time and the file is modified by a user during a later part of the scan the stored metadata for that file will be inaccurate. Change records generated by a monitor agent and stored in a change journal database provide some indication of metadata changes that may have occurred during a scan. However if a change journal database has a finite change journal cache size then for long scan times and or high change rates some relevant change records created during a scan may be pushed from the change journal database in favor of change records reflecting more recent data interactions. Thus the change journal database alone may be insufficient to accurately update metadata acquired during a scan. To improve the accuracy of the metabase at step during a file system scan a data agent uses interim tables that reflect many of the change records created during the execution of a file system scan.

As shown at step the process begins when a data agent comes online such as when system conditions or other conditions permit the data agent to actively perform its metabase generation functions. At step data agent determines the USN associated with the last change record in the change journal database by querying the monitor agent. The process then bifurcates into two parallel subprocesses a scanning subprocess comprising steps and and a change logging subprocess comprising steps and .

The change logging subprocess begins at step where data agent may create a new interim change table. Data agent may not create a new interim change table at step under certain conditions. For example it may continue using a prior interim change table if the data agent has just come online from a short pause and or the last change record in the change journal database was already reflected in a prior interim change table.

At step data agent may register with a change notification service to receive change notifications. At step data agent listens or otherwise waits for a new change notification. When data agent receives a new change notification at step the notification may reflect change record information such as a USN an FRN and a change code and or other change record or metabase information.

At step using the received information e.g. an FRN data agent may utilize a file system API to query for additional metadata related to the data object that was the subject of the received change notification. For example data agent may utilize a received FRN to query a file system for the data object size of the file having that FRN. In some implementations step may additionally or alternatively be performed in conjunction with an update step described subsequently. In such implementations data agent may only perform a query for each unique FRN appearing in interim change tables instead of performing a query for each row in interim change tables.

The change logging subprocess then proceeds to step where data agent updates the new interim change table with received change notification information and related metadata. Alternatively in some implementations data agent may immediately parse and or process these and update a metabase to reflect the received change notification information and or attributes. For example data agent may immediately determine if there is an existing entry in a metabase having the same FRN and if so it may update the metadata associated with that FRN in the metabase. Additionally at step data agent may update the start USN and or end USN associated with the new interim change table to reflect the most recently received USN.

The change logging subprocess then proceeds to decision block where data agent determines whether the traversal is complete i.e. all files accessible by a file system or located in a particular volume or portion of a file system have been scanned. If the traversal is complete at decision block the process returns or may return to block . Otherwise the change logging subprocess proceeds to decision block where data agent determines whether it is still online. If data agent is still online the change logging subprocess repeats starting from step . If data agent is no longer online the subprocess pauses and resumes at step only when the data agent comes back online.

The scanning subprocess begins at step where data agent traverses the next file or object in a client file system and requests metadata related to the next file. Data agent may utilize a file system API and or other information to determine which is the next file or object in the file system structure. Alternatively data agent may utilize stored information about the file system to determine which file to traverse next. If no file has yet been traversed the data agent may utilize a file system API to instead determine a logical starting point within a file system and or may start from a pre determined or pre configured starting point.

During step data agent utilizes a file system API to request and receive metadata that is related to the next file. Data agent may request metadata that corresponds to the fields utilized by a metabase table. For example data agent may request the last modified time and data object size of the next file. At step data agent records received metadata in a metabase.

The scanning subprocess then proceeds to decision block where data agent determines whether the traversal of a file system or a volume or portion therein is complete. If the traversal is complete at decision block the process proceeds to step where the scanning subprocess waits for the change logging subprocess to make any necessary updates to interim change tables and then the process returns. Otherwise the scanning subprocess proceeds to decision block where data agent determines whether it is still online. If data agent is online the scanning subprocess repeats starting from step . If data agent is no longer online at decision block the scanning subprocess pauses and resumes at step only when it comes back online.

Referring again to the process continues to step where data agent identifies gaps in interim change tables and fills the identified gaps. As described previously during the process of a change logging subprocess may be restarted repeatedly at step after a pause in the data agent s processing. While the change logging subprocess is paused waiting for the data agent to come back online a monitor agent may detect additional data interactions and create new change records each with an additionally incremented USN. Since data agent is offline during the creation of these new change records data agent may not receive related change notifications reflecting them. When data agent eventually does come back online and creates a new table at step there may be a gap between the last USN associated with the last interim change table and the starting USN associated with the new interim change table. That is there will be a gap in the USNs recorded in the various interim tables. Data agent may utilize these missing USNs or other related information to request that a monitor agent and or file system supply change record information and or metadata that is missing from the interim tables. Data agent may add or store the missing change record information and or metadata in an interim table and or directly parse and analyze these in order to update a metabase directly.

In some implementations the gap identification and filling step may occur after the conclusion of step that is after all interim tables have been built. Alternatively or additionally after every restart of data agent at step data agent may attempt to identify and fill any gap created by the last pause.

The process proceeds to step where data agent updates a metabase with information from initial and interim change tables. If step was not performed during the process of during step data agent may query a file system for metadata related to the various files that are the subject of the change table entries. In such implementations data agent may perform a query only for each unique FRN appearing in the initial and interim change tables instead of performing a query for each row in the change tables and thereby identify missing data and to fill in the table.

At step data agent may parse and analyze each of the entries in the initial and interim change tables to determine whether an entry indicates that some related metadata stored in a metabase is inaccurate. To make this determination data agent may analyze change codes stored in the change table entries. Alternatively or additionally data agent may compare metadata stored in the metabase against metadata stored in the change tables. If data agent determines that a table entry indicates an inaccuracy in the metabase data agent may update the metabase with accurate metadata stored in the change tables or may request accurate metadata from a file system and store this in the metabase.

In some implementations data agent may parse change table entries in reverse chronological order that is it may process more recent change record notifications first e.g. change record notifications having higher USNs . As data agent parses each change table entry and updates a metabase data agent may update a field in the metabase indicating the most recent USN processed for a given file i.e. for a given FRN . In some implementations data agent may not attempt to parse and analyze an entry in a change table having a particular FRN and a first USN if a metabase entry for that same FRN shows data agent has processed a more recent USN for the same file.

After the conclusion of step at steps and data agent may periodically perform updates of the generated metabase by 1 listening for additional change notifications and or retrieving new change records from a change journal database and 2 updating a metabase to reflect these new change records and or notifications. In some implementations at step data agent may listen for additional change notifications and or retrieve new change records from a change journal database in substantially the same fashion as described with respect to the change logging subprocess of and gap filling step . In some implementations at step data agent may update a metabase in substantially the same fashion described with respect to step .

From the foregoing it will be appreciated that specific examples of data storage systems have been described herein for purposes of illustration but that various modifications may be made without deviating from the spirit and scope of the system. For example although files may have been described herein other types of content such as user settings application data emails and other data objects for example blocks of data can be imaged by snapshots. Accordingly the system is not limited except as by the appended claims.

Terms and phrases used in this document and variations thereof unless otherwise expressly stated should be construed as open ended as opposed to limiting. As examples of the foregoing the term including should be read as meaning including without limitation or the like the term example is used to provide exemplary instances of the item in discussion not an exhaustive or limiting list thereof the terms a or an should be read as meaning at least one one or more or the like and adjectives such as conventional traditional normal standard known and terms of similar meaning should not be construed as limiting the item described to a given time period or to an item available as of a given time but instead should be read to encompass conventional traditional normal or standard technologies that may be available or known now or at any time in the future. Likewise where this document refers to technologies that would be apparent or known to one of ordinary skill in the art such technologies encompass those apparent or known to the skilled artisan now or at any time in the future.

The presence of broadening words and phrases such as one or more at least but not limited to or other like phrases in some instances shall not be read to mean that the narrower case is intended or required in instances where such broadening phrases may be absent. The use of the term module does not imply that the components or functionality described or claimed as part of the module are all configured in a common package. Indeed any or all of the various components of a module whether control logic or other components can be combined in a single package or separately maintained and can further be distributed in multiple groupings or packages or across multiple locations.

If a synchronization process or synchronization processes are described herein it is not intended to require that multiple synchronizations occur simultaneously or that multiple computing systems being synchronized each receive the same data. Although in some examples the data can be broadcast to all participating computing systems simultaneously or close to simultaneously in other examples the data can be sent to different computing systems or groups of computing systems at different times. Likewise in some examples the same data or the same subset of the data can be sent to all computing systems. However in other examples subsets of the data can be tailored for a given computing system or group of computing systems.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in the sense of including but not limited to. The word coupled as generally used herein refers to two or more elements that may be either directly connected or connected by way of one or more intermediate elements. Additionally the words herein above below and words of similar import when used in this application shall refer to this application as a whole and not to any particular portions of this application. Where the context permits words in the above Detailed Description using the singular or plural number may also include the plural or singular number respectively. The word or in reference to a list of two or more items that word covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above detailed description of embodiments of the system is not intended to be exhaustive or to limit the system to the precise form disclosed above. While specific embodiments of and examples for the system are described above for illustrative purposes various equivalent modifications are possible within the scope of the system as those skilled in the relevant art will recognize. For example while processes or blocks are presented in a given order alternative embodiments may perform routines having steps or employ systems having blocks in a different order and some processes or blocks may be deleted moved added subdivided combined and or modified. Each of these processes or blocks may be implemented in a variety of different ways. Also while processes or blocks are at times shown as being performed in series these processes or blocks may instead be performed in parallel or may be performed at different times.

The teachings of the system provided herein can be applied to other systems not necessarily the system described above. The elements and acts of the various embodiments described above can be combined to provide further embodiments.

Any patents and applications and other references noted above including any that may be listed in accompanying filing papers are incorporated herein by reference. Aspects of the invention can be modified if necessary to employ the systems functions and concepts of the various references described above to provide yet further implementations of the invention.

These and other changes can be made to the system in light of the above Detailed Description. While the above description details certain embodiments of the system and describes the best mode contemplated no matter how detailed the above appears in text the system can be practiced in many ways. Details of the system may vary considerably in implementation details while still being encompassed by the system disclosed herein. As noted above particular terminology used when describing certain features or aspects of the system should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics features or aspects of the system with which that terminology is associated. In general the terms used in the following claims should not be construed to limit the system to the specific embodiments disclosed in the specification unless the above Detailed Description section explicitly defines such terms. Accordingly the actual scope of the system encompasses not only the disclosed embodiments but also all equivalent ways of practicing or implementing the system under the claims.

While certain aspects of the invention are presented below in certain claim forms the inventors contemplate the various aspects of the invention in any number of claim forms. For example while only one aspect of the invention is recited as embodied in a computer readable medium other aspects may likewise be embodied in a computer readable medium. As another example while only one aspect of the invention is recited as a means plus function claim under 35 U.S.C. 112 sixth paragraph other aspects may likewise be embodied as a means plus function claim or in other forms such as being embodied in a computer readable medium. Any claims intended to be treated under 35 U.S.C. 112 6 will begin with the words means for. Accordingly the inventors reserve the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the invention.

