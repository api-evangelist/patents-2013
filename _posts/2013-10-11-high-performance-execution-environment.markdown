---

title: High performance execution environment
abstract: The subject matter of this specification can be implemented in, among other things, a computer-implemented method for accessing a native application programming interface (API) of a computing device including receiving on the computing device one or more control objects from a first application written in a device-independent programming language. The control objects define a context for accessing the native API and the control objects include at least one control script. The method further includes compiling the control script on the computing device into a second application that is native to the operating system of the computing device. The method further includes executing the second application on the computing device. The executed second application accesses the native API of the computing device to generate an output through a hardware interface of the computing device based on the context.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09069567&OS=09069567&RS=09069567
owner: Google Inc.
number: 09069567
owner_city: Mountain View
owner_country: US
publication_date: 20131011
---
Mobile computing devices such as smartphones are becoming more and more popular. As mobile devices become more and more popular users of the devices demand more and more functionality from them. In some cases users expect mobile devices to replace functionality once performed by desktop or laptop computing devices. This additional functionality can test the bounds of the hardware resources available on the mobile computing device such as processor or display screen performance e.g. resolution refresh rate or responsiveness . Generally such hardware is not as powerful as that in desktop or laptop computers because of size weight and battery life issues.

Software for mobile devices frequently uses one of two approaches when rendering drawing objects on a display screen. These approaches generally access an application programming interface such as OpenGL for rendering drawing objects. The drawing application programming interface API for such systems is generally written in a native programming language such as the C programming language. This can improve drawing performance on the mobile device over non native programming languages and or applications. In some cases software code written to access the native drawing API is also written in the native programming language. The native software code sends drawing commands to the native drawing API to update drawing objects on the display screen of the mobile device. This native software code is generally specific to a particular type of mobile device and separate native software code needs to be written and or compiled from the software code for other mobile devices.

In other cases software code can be written in a non native programming language such as a high level device independent programming language e.g. the Java programming language . The device independent software code then accesses a wrapper for the native drawing API such as the Java Native Interface JNI . The wrapper can be written in the high level device independent programming language. The wrapper generally includes an API that provides access to the features of the native drawing API. The device independent software code then sends individual drawing commands to the wrapper API which are then passed to the native drawing API.

In general this document describes a high performance execution environment that accesses native APIs and or hardware. In some cases the execution environment is implemented in a mobile computing device or other computing device that has limited processing resources. An application written in a high level device independent programming language passes control objects to the execution environment. The control objects include one or more control scripts. The execution environment compiles the control scripts into a native application and executes the native application. The native application then accesses the native APIs for example to render drawing objects on a display screen. In some implementations the native application can communicate with the high level application while the native application is being executed. In some implementations the high performance execution environment is provided by the RENDERSCRIPT API of the ANDROID operating system OS available from the OPEN HANDSET ALLIANCE.

In a first aspect a computer implemented method for accessing a native application programming interface API of a computing device includes receiving on the computing device one or more control objects from a first application written in a device independent programming language. The control objects define a context for accessing the native API and the control objects include at least one control script. The method further includes compiling the control script on the computing device into a second application that is native to the operating system of the computing device. The method further includes executing the second application on the computing device. The executed second application accesses the native API of the computing device to generate an output through a hardware interface of the computing device based on the context.

Implementations can include any all or none of the following features. The second application can be compiled as one or more threads that are separate from the first application. The second application can be compiled as a process that is separate from the first application. The first application can be executed on a first processor of the computing device and the second application can be executed on a second processor of the computing device that is separate from the first processor. The first processor can include a central processing unit and the second processor can include a graphics processing unit. The first application does not directly access the native API. The native API can include a native rendering API the hardware interface can include a display screen and the second application accesses the native rendering API to render drawing objects on the display screen. The method can include receiving one or more updates to the context from the first application and wherein in response to receiving the updates to the context the executed second application accesses the native API of the computing device to generate an output through the hardware interface of the computing device based on the updated context.

In a second aspect a computer program product encoded on a computer readable medium operable to cause one or more processors to perform operations for accessing a native application programming interface API of a computing device includes receiving on the computing device one or more control objects from a first application written in a device independent programming language. The control objects define a context for accessing the native API and the control objects include at least one control script. The operations further include compiling the control script on the computing device into a second application that is native to the operating system of the computing device. The operations further include executing the second application on the computing device. The executed second application accesses the native API of the computing device to generate an output through a hardware interface of the computing device based on the context.

Implementations can include any all or none of the following features. The second application can be compiled as one or more threads that are separate from the first application. The second application can be compiled as a process that is separate from the first application. The first application can be executed on a first processor of the computing device and the second application can be executed on a second processor of the computing device that is separate from the first processor. The first processor can include a central processing unit and the second processor can include a graphics processing unit. The first application does not directly access the native API. The native API can include a native rendering API the hardware interface can include a display screen and the second application accesses the native rendering API to render drawing objects on the display screen. The operations can include receiving one or more updates to the context from the first application and wherein in response to receiving the updates to the context the executed second application accesses the native API of the computing device to generate an output through the hardware interface of the computing device based on the updated context.

In a third aspect a computing device includes a hardware interface that outputs information to a user of the computing device. The device further includes a memory storing instructions including a native application programming interface API configurable to make an output through the hardware interface of the computing device a compiler configured to compile control scripts into applications that are native to an operating system of the computing device and a first application written in a device independent programming language that when executed provides one or more control objects to the compiler. The control objects define a context for accessing the native API and the control objects include at least one control script. The device further includes one or more processors that execute the first application and as a result execute a second application compiled from the control script by the compiler. The executed second application accesses the native API to generate the output through the hardware interface of the computing device. The output is based on the context.

Implementations can include any all or none of the following features. The hardware interface can include a display device the native API can include a native rendering API and the output can include one or more drawing objects rendered on the display device.

In a fourth aspect a computing device includes a hardware interface that outputs information to a user of the computing device. The device further includes a central processing unit. The device further includes a graphics processing unit. The device further includes means for executing code provided from the central processing unit to the graphics processing unit by passing one or more control objects including at least one control script from the central processing unit to the graphics processing unit.

The systems and techniques described here may provide one or more of the following advantages in certain implementations. First using such systems programmers can generate software code and applications and have the same code execute on multiple different types of devices. Second the code can provide high performance rendering of drawing objects in a mobile device. Third a system can provide high performance applications by offloading the heavy lifting of interfacing with a native graphics API while retaining full application control. Fourth a system can prevent stuttering or lagging display response to user interaction in a mobile computing device. Fifth a system can maintain vertical synchronization level performance which may allow a display frame buffer to be filled before the display frame buffer is transmitted to the display. Sixth a system can provide for refreshing a display screen of a mobile computing device by the compiled script without a call back to the control application. In this manner such a system may provide for improved graphical performance while allowing common code to be used across multiple device types which may lead to better user experiences and more complete adoption of a platform by software developers.

The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description and drawings and from the claims.

This document describes systems and techniques for accessing a native application programming interface API of a computing device. In some implementations the computing device is a device with limited processing resources such as a mobile computing device. In one example discussed here an application that has been written using a high level device independent programming language such as Java passes control objects to an execution environment. The control objects include state information e.g. a context that define an initial state of the information provided to the native API e.g. an initial state of a drawing or rendering for output on a display screen . The control objects also include one or more scripts. The execution environment on the mobile computing device initiates a compiler that compiles the scripts into a native application. The native application then accesses the native API in lieu of the high level application accessing the native API. The native application uses the actions from the scripts and the initial state of the information to control the output of the information to the hardware interface such as an output of drawing objects on a display screen. In some implementations the execution environment initiates compilation of the scripts at run time when the high level application passes the control objects to the execution environment for execution.

The computing device executes or runs the application . The application is written in a high level device independent programming language such as Java. In some implementations the computing device or another device pre compiles the application at some time prior to a request to run the application . Alternatively the computing device may compile the application at run time or may use some combination of pre compilation and compilation at run time.

The application accesses an API of the control environment either at run time compile time or both. In some implementations the API of the control environment is written in the high level device independent programming language of the application . Alternatively the API of the control environment can be written in another programming language that is otherwise callable by the application . The API of the control environment passes the control objects from the application to the execution environment .

The control objects include at least one script. In some implementations the script is written in the native programming language used by the native API . The script may alternatively be written in another programming language such as an intermediate programming language that can be translated into the native programming language during compilation. The execution environment then provides the script to a compiler within the computing device . The compiler compiles the script into a compiled script . The compiled script is a native application and has direct access to the native API . In some implementations compiling the script at the computing device provides portability of the software code in the script.

The compiled script uses the state information in the control objects along with the processing specified in the script to access the native API and consequently a hardware interface of the computing device. In some implementations the control environment passes the state information in the control objects to the native API when the control environment passes the control objects to the execution environment . In some implementations the control environment passes the state information in the control objects to the native API when the control objects are used by the compiled script .

The compiled script can continue to update the output to the hardware interface through the native API as the compiled script receives updates to the state information. For example a user may make an input to the computing device to initiate the application . The application may have a graphical user interface GUI that allows the user to interact with the application . The application may then initiate the GUI by passing the control objects to the execution environment . The compiler of the execution environment may then compile the script from the control objects into the compiled script . The execution environment runs the compiled script . The compiled script directly accesses the native API to draw the GUI and can receive updates to the state of the GUI in the control objects for example from the application or another application. The compiled script then makes corresponding calls to the native API to update the display of the GUI on the display screen.

In some implementations the computing device is a mobile computing device such as a smartphone or other computing device with limited resources. For example the computing device may have limited space available or energy available for a central processing unit CPU or a graphics processing unit GPU . The limitations on size and energy consumption for the CPU and or GPU may accordingly reduce the processing capability of the CPU and or GPU. The separation of direct access to the native API from the application can in some implementations reduce the amount of processing needed for accessing certain hardware interfaces such as a display device light emitting diodes LEDs a speaker a hardware keyboard or buttons or a vibration device. In the case of a display device the state of the objects to be drawn or rendered on the display device can be represented by one or more of the control objects while the instructions for rendering the drawing objects are included in the script. In certain examples the control environment may execute on a CPU while the execution environment may execute on a GPU so that passing of control objects and other messages occurs between the two processors. Also such allocation of responsibilities may permit general code to be resident on the general CPU and the GPU to compile the scripts or other information in a manner that is appropriate to the hardware of the computing device .

In general a parent application calls a construction state machine in the control API to create an instance of a particular control object such as any one of the control objects . The parent application and or the control API makes a series of one or more function or procedure calls to build up the control object. For example the parent application can start by calling a Begin procedure that resets the internal object creation buffer to a default state. In another example the control API can use temporary builder objects to contain the internal creation state. In some implementations the temporary builder objects allow the parent application to construct multiple objects concurrently. The parent application then makes one or more calls that modify the default state to a state desired by the parent application. Once the control object is in the desired state the parent application and or the control API calls a Create procedure that constructs the control object from this desired state and provides the control object to the parent application. Multiple such control objects may be created in this manner.

The control objects are reference counted internally by the control API. In particular when the control API creates an initial control object a handle to the initial control object is created with an associated reference count of one. Each time the control API binds the initial control object to another control object the control API increments the reference count associated with the initial control object.

The control API decrements the reference count of the initial control object when the control API unbinds the other control object from the initial control object. This allows the control API to create a control object bind it to another object and then release the user reference e.g. the reference from the calling or parent application . The control API destroys the initial control object once it unbinds the initial control object from the last of the other control objects that reference the initial control object. This may occur for example during a destruction procedure for the other control objects. In some implementations the parent application can use the control API to call the destruction procedure for a particular control object.

The example of the control objects shown in includes a number of control objects that divide up the operations associated with accessing the native rendering API such as a device control object . The device control object represents a combination of hardware and software that implements the control API. In some implementations the control objects can include multiple device control objects. For example where a computer device includes more than one display screen there can be a device control object for each display screen. In another example where a computer device includes more than one native API for a display screen there can be a device control object for each of the native APIs. In some implementations the device control object allows calling applications such as the application to query the basic parameters of the device control object such as the versions of the control API that are supported. In some implementations the parent application uses the control API to create the device control object first and the device control object is used in turn to create other control objects such as a context control object .

The context control object contains the basic state that represents the currently active rendering pipeline. The context control object has bind points for various programs or other control objects that form the graphics pipeline. The context control object represents a version of the control API that is exposed by a particular computing device such as a smartphone. In some implementations a calling application such as the application may have more than one context control object.

In some implementations a computing device can support multiple revisions of the control API. The control API call that creates the context control object in such a situation takes a version to indicate which revisions a calling application such as the application requires. In some implementations this allows for incompatible changes to be made to a future revision of the control API without breaking existing applications that call functions from the control API.

Once the context control object is created it is bound to a particular native API and hardware combination as specified by the device control object . In some implementations the application can release the context control object from the device control object and re bind it to another device control object. In some implementations destroying the context control object also destroys any unshared control objects that were created by the context control object . For example the context control object may be used to create other sub control objects that describe the drawings or images to be rendered on the displays screen such as a component control object .

The component control object is a basic object that represents the smallest element of data in the drawing system. For example a pixel in the red green blue RGB color model would have three component control objects. Each of those component control objects would contain three pieces of state information. The first is what the particular component control object represents such as a red green or blue color value or other drawing information such as an alpha value. In addition drawing information for three dimensional model data can include positional information e.g. x y and z coordinates normal information e.g. nx ny and nz coordinates and texture coordinates e.g. s and t . The component control object describes the properties of what is to be rendered on the display device. The information in the component control object can be used to create meshes of triangles lines or points. The second piece of state information is the number of bits used to store the component control object . The third piece of state information is the storage format such as decimal floating point number normalized signed integer or unsigned integer. Other pieces of drawing information may also be stored with respect to particular component control objects as appropriate.

The control objects also include an element control object that groups one or more component control objects. An element control object is an object that represents the contents of one location in a data structure. Typically this one location is one pixel one vertex one texel or one user defined drawing object. For example an RGB pixel would have three components that describe the layout of the data. For example an element control object can include three component control objects for the RGB color system e.g. R8 G8 B8 . In another example an element control object can include spatial information such as normal coordinates e.g. nx ny and nz coordinates or other coordinates e.g. x y and z coordinates .

The control API provides operations for managing element control objects. For example the control API can include a procedure for clearing the internal state machine for building element control objects. The control API can include a procedure for adding an element control object to an internal buffer by creating the element control object from a type that is selected from a predefined list of element control object types such as a pixel vertex or texel. The control API can include a procedure for adding a component or element control object to the internal buffer that is defined by the calling application. The control API can include a procedure for returning a reference to one of the predefined element control object types. The control API can include a procedure for destroying or releasing a reference to an element control object.

The element control object can be grouped with one or more other element control objects by a type control object . The type control object defines a collection of element control objects that are assigned a dimensional structure. The shape of the structure can be defined by the calling application. For example the type control object may define a square with component and element control objects for RGB color values e.g. R8 G8 B8 a height value and a width value.

The type control object can have one or more of several pre defined dimensions or parameters to which the calling application may assign values. Typically only a subset of the dimensions are used. For example the type control object can include an X dimension. The X dimension is the lowest order structural dimension. The type control object can also include a Y dimension which if present implies the particular type control object can be viewed as a two dimensional surface. For example an image can be a two dimensional surface. If the type control object includes a Y dimension then the type control object can also include a Z dimension which if it is present indicates that the particular type control object can be represented as a three dimensional volume. If a Z dimension is not specified the type control object can include a faces dimension. If the faces dimension is set to true then the structure represented by the type control object is a cubemap. The type control object can include a mips dimension with a value of true or false. If the mips dimension is true then the type control object includes one or more mipmaps for the x y z faces structure. The type control object can also include an array dimension. The array dimension acts similar to arrays in the ANSI C programming language. The array dimension allows the calling application and or one or more control scripts to select between multiple identical substructures.

Storage for the type control object is provided by an allocation control object . The allocation control object stores a particular type control object and the elements of the type control object in a particular memory allocation. For example the allocation control object can store textures vertex buffers index data and or usage hints such as OpenGL vertex buffer object VBO hints.

The control API can provide a procedure for creating an allocation control object from a particular type control object and for creating an allocation control object from a particular number of an element control objects such as by creating a one dimensional array of the element control object. The control API can provide a procedure for loading an image file constructing a type control object from the image file and then creating an allocation control object from the constructed type control object. The control API can also provide a procedure for promoting an allocation control object to texture memory and for destroying or releasing an allocation control object that is specified by a calling application and or script.

The allocation control object can be simplified by an adapter control object . The adapter control object presents an allocation control object in a form that is accessible as a simpler structure. The adapter control object takes inputs including a reference to an allocation control object. The adapter control object holds zero or more of the dimensions of the allocation control object as constants and presents the remaining dimensions as parameters to accessor functions. The type of the adapter control object e.g. one dimensional two dimensional etc. determines how many dimensions will be held constant. Adapter control objects allow the writing of APIs or functions that understand a specific set of dimensions. For example in regard to an image filter the image filter can be fed two dimensional filter levels of a mipmap faces of a cubemap or slices of a voxel by changing the constant dimensions on the adapter control object .

The adapter control object is in essence a conversion container that adapts an allocation control object such as the allocation control object to present it as a lower dimension object. For example a mipmap adapter can present an allocation control object that has two dimensional images and mipmap levels as simply a two dimensional object. In some implementations an adapter control object can be used interchangeably with an allocation control object. The adapter control object receives its data from an allocation control object to which the adapter control object is bound. In some implementations no copy of data from the bound allocation control object to the adapter control object is made.

The control API can include functions for creating and destroying adapter control objects and a function for setting a dimension to a constant that is not in the basic dimensionality of the adapter control object . This selects a part of a larger type control object for access. For example a two dimensional adapter control object may set mipmap level to four to select the two dimensional image for mipmap level four.

The allocation control object in its original or simplified form is used by a sampler control object to represent the drawing information as a texture sample. The sampler control object contains the state that is used to turn a texture source and coordinate into a sample. The sampler control object takes as input an allocation control object and a definition of how the allocation control object is to be accessed as a texture and defines the wrap modes filter modes and other texture properties that are not part of the allocation control object itself. The control API includes functions for binding the sampler control object to a particular allocation control object and for setting the modes of the sampler control object .

The drawing system state defined by the previously described control objects can be manipulated by operations defined in a script control object . The script control object includes a portion of embeddable code that is received in source form from an application such as the application and then compiled or interpreted for example by the execution environment and the compiler . In general the script control object contains a list of commands that are executed when the compiled script is run by the execution environment. In some implementations the compiler compiles the script control object into a process that is separate from the other compiled scripts. Alternatively the compiled script may be in the same process as the other compiled scripts but in its own thread. In some implementations the compiled script includes more than one thread. In some implementations the compiled script is executed on a processor other than the processor of the calling application and or other compiled scripts.

In some implementations the script control object runs in a well defined environment such as is defined by one or more of the following features. The script control object may have access to only a short list of functions such as a subset of functions from the control API. For example the subset may exclude the control API functions that construct the control objects . Other features of the well defined environment may include any of a small fixed size memory stack for the compiled scripts preventing directly shared data between compiled scripts preventing memory allocation and preventing the calling of other compiled scripts. However in some implementations the well defined environment can provide functions for changing the state of the context control object and or running a compiled script concurrently with one or more other compiled scripts.

In some implementations the control API provides a function the parent application can call to identify a script control object as a root script control object. A root script control object is special in that it is designed to be attached to a surface. For example a root script for the context control object is given the responsibility of redrawing the display each time the root script is called. As such the initial state of the context control object will be well defined and the leftover state upon exiting the root script will be assumed to be lost and not carried over to the next invocation of the root script.

The script control object can access local and shared data stores. Each script control object has an implied allocation of temporary variables and may also have one or more constants buffers. These buffers are allocation control objects that are attached to the script control objects. By default the attachments are read only but can be made writable so that a script control object can produce a persistent run to run state.

Data can be passed to the script control object in multiple ways. For example one or more allocation control objects can be bound to the script control object . In some implementations the type of the allocation control objects is defined at the time the script control object is created. In addition or alternatively a binding may be changed by the parent e.g. the calling application or control object and a bound allocation control object may be read only write only or read and write.

In another example data can be passed to the script control object through one or more input parameters. In some implementations these parameters passed into the function in the script control object allow different data to be passed to different instances of the script control object . For example ten scripts can be used to draw ten different icons. In such a case each script can receive a different icon id and position that specify what icon is displayed and where the icon is displayed.

In some implementations the script control object inherits a default state that is the state of the context control object when the compiled script is first executed or instanced. State changes made by a compiled script during execution of the compiled script can be lost at the end of the execution and in some implementations this minimizes side effects produced by the compiled scripts and allows the concurrent execution of many scripts at once.

The control objects can include objects that mirror specific drawing operations provided by the native rendering API. For example the control objects include a vertex control object and a fragment control object that are similar to vertex and fragment objects in the OpenGL rendering API. In addition a fragment store control object can encapsulate the state and in some implementations programmable operations that occur when the fragment control object is written to a buffer. A raster control object contains the state that is used to rasterize primitives from the vertex control object and provides the rasterized primitives to the fragment control object . For example the rasterized primitives can include points lines and triangles.

In this manner the control objects provide a set of objects for storing the state of the drawings or images to be rendered on the display screen. The control objects also provide a representation of operations that can be performed from the native rendering API for manipulating the drawings. Further the control object include the script control object that when compiled and executed provides direct access to those operations from the native rendering API to update the display screen with the rendered drawings and images.

The process begins with receiving one or more control objects from a first application that is written in a device independent programming language and is executed on a particular computing device. The control objects define a context for accessing a native API and include at least one control script. For example the application can pass the control objects to the execution environment to request a drawing rendering operation for a GUI of the application . The device independent programming language allows the first application to be used with multiple devices that have different types of hardware.

The process then compiles the control script into a second application that is native to an operating system of the computing device. For example the computing device in includes the compiler that compiles the control script from the control objects into the compiled script . In some implementations the computing device can be a smartphone or other mobile device that runs a mobile device operating system such as the ANDROID operating system. In this example the compiler at the computing device compiles the control script into a format that can be executed natively by the ANDROID operating system.

The process then executes the second application. The executed second application accesses the native API of the computing device to generate an output through a hardware interface of the computing device. The output generated by the second application is based on the context. For example the execution environment executes the compiled script which includes operations that are capable of interfacing with the native API to send an output through a hardware interface such as a display screen or audio output.

Optionally the process can receive one or more updates to the context from the first application. In response to receiving the one or more updates the executed second application accesses the native API of the computing device to make another output through the hardware interface of the computing device based on the updated context. For example the application can send an update to the control objects . Accordingly the compiled script either while continuing to execute or while being executed again by the execution environment can access the native API again to send an updated or additional output through the hardware interface.

Thus by this process a computing device may coordinate control information generated by an application running on the device and running using a device independent language with graphics generated on the device in coordination with the native rendering API.

The process begins with a parent application calling functions from a control environment to create and provide one or more control objects to an execution environment . The execution environment passes a script from among the control objects to a compiler on the computing device. The script is written in a programming language that is capable of accessing a native API such as a native rendering API. The compiler parses the instructions in the script and compiles the script into a native compiled script that is capable of being executed by a processor of the computing device on which the process is performed. The execution environment then executes the native compiled script on the processor.

The native compiled script calls one or more functions from a native API of the computing device and the functions in turn access a hardware interface of the computing device such as a display screen LED speaker or vibration device to make an output through the hardware interface . The native compiled script can continue to run and make outputs through the hardware interface without further input from the parent application . The native compiled script bases further outputs on the state or context in the control objects. Processing carried out by the native compiled script can alter the state context and thus can subsequently result in an update to the output through the hardware interface .

In some implementations the native compiled script accesses the native API one or more times to request updates to the output or additional outputs through the hardware interface . The native API correspondingly accesses the hardware interface to make the updated additional outputs. For example the native compiled script may be in a processing loop that repeatedly draws a spinning logo on the display screen. The native compiled script repeatedly accesses the native API to update the orientation of the spinning logo and in response the native API repeatedly accesses the hardware interface to update the orientation of the logo.

In some implementations the parent application sends an update to the context in the control objects to the execution environment . Accordingly the execution environment makes the updated context available to the native compiled script . The native compiled script processes the update to the context in the control objects and accesses the native API to request an update to the output or an additional output through the hardware interface . The native API accesses the hardware interface to make the updated additional output. For example the parent application can send an update to the context to stop or start the spinning of the logo. In some implementations the parent application can retrieve a current state of the control objects and base its updates to the control objects on changes made to the state of the control objects by the native compiled script .

The computing device includes a processor a memory a storage device a high speed interface connecting to the memory and multiple high speed expansion ports and a low speed interface connecting to a low speed expansion port and the storage device . Each of the processor the memory the storage device the high speed interface the high speed expansion ports and the low speed interface are interconnected using various busses and may be mounted on a common motherboard or in other manners as appropriate. The processor can process instructions for execution within the computing device including instructions stored in the memory or on the storage device to display graphical information for a GUI on an external input output device such as a display coupled to the high speed interface . In other implementations multiple processors and or multiple buses may be used as appropriate along with multiple memories and types of memory. Also multiple computing devices may be connected with each device providing portions of the necessary operations e.g. as a server bank a group of blade servers or a multi processor system .

The memory stores information within the computing device . In some implementations the memory is a volatile memory unit or units. In some implementations the memory is a non volatile memory unit or units. The memory may also be another form of computer readable medium such as a magnetic or optical disk.

The storage device is capable of providing mass storage for the computing device . In some implementations the storage device may be or contain a computer readable medium such as a floppy disk device a hard disk device an optical disk device or a tape device a flash memory or other similar solid state memory device or an array of devices including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that when executed perform one or more methods such as those described above. The computer program product can also be tangibly embodied in a computer or machine readable medium such as the memory the storage device or memory on the processor .

The high speed interface manages bandwidth intensive operations for the computing device while the low speed interface manages lower bandwidth intensive operations. Such allocation of functions is exemplary only. In some implementations the high speed interface is coupled to the memory the display e.g. through a graphics processor or accelerator and to the high speed expansion ports which may accept various expansion cards not shown . In the implementation the low speed interface is coupled to the storage device and the low speed expansion port . The low speed expansion port which may include various communication ports e.g. USB Bluetooth Ethernet wireless Ethernet may be coupled to one or more input output devices such as a keyboard a pointing device a scanner or a networking device such as a switch or router e.g. through a network adapter.

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a standard server or multiple times in a group of such servers. In addition it may be implemented in a personal computer such as a laptop computer . It may also be implemented as part of a rack server system . Alternatively components from the computing device may be combined with other components in a mobile device not shown such as a mobile computing device . Each of such devices may contain one or more of the computing device and the mobile computing device and an entire system may be made up of multiple computing devices communicating with each other.

The mobile computing device includes a processor a memory an input output device such as a display a communication interface and a transceiver among other components. The mobile computing device may also be provided with a storage device such as a micro drive or other device to provide additional storage. Each of the processor the memory the display the communication interface and the transceiver are interconnected using various buses and several of the components may be mounted on a common motherboard or in other manners as appropriate.

The processor can execute instructions within the mobile computing device including instructions stored in the memory . The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide for example for coordination of the other components of the mobile computing device such as control of user interfaces applications run by the mobile computing device and wireless communication by the mobile computing device .

The processor may communicate with a user through a control interface and a display interface coupled to the display . The display may be for example a TFT Thin Film Transistor Liquid Crystal Display display or an OLED Organic Light Emitting Diode display or other appropriate display technology. The display interface may comprise appropriate circuitry for driving the display to present graphical and other information to a user. The control interface may receive commands from a user and convert them for submission to the processor . In addition an external interface may provide communication with the processor so as to enable near area communication of the mobile computing device with other devices. The external interface may provide for example for wired communication in some implementations or for wireless communication in other implementations and multiple interfaces may also be used.

The memory stores information within the mobile computing device . The memory can be implemented as one or more of a computer readable medium or media a volatile memory unit or units or a non volatile memory unit or units. An expansion memory may also be provided and connected to the mobile computing device through an expansion interface which may include for example a SIMM Single In Line Memory Module card interface. The expansion memory may provide extra storage space for the mobile computing device or may also store applications or other information for the mobile computing device . Specifically the expansion memory may include instructions to carry out or supplement the processes described above and may include secure information also. Thus for example the expansion memory may be provide as a security module for the mobile computing device and may be programmed with instructions that permit secure use of the mobile computing device . In addition secure applications may be provided via the SIMM cards along with additional information such as placing identifying information on the SIMM card in a non hackable manner.

The memory may include for example flash memory and or NVRAM memory non volatile random access memory as discussed below. In some implementations a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that when executed perform one or more methods such as those described above. The computer program product can be a computer or machine readable medium such as the memory the expansion memory or memory on the processor . In some implementations the computer program product can be received in a propagated signal for example over the transceiver or the external interface .

The mobile computing device may communicate wirelessly through the communication interface which may include digital signal processing circuitry where necessary. The communication interface may provide for communications under various modes or protocols such as GSM voice calls Global System for Mobile communications SMS Short Message Service EMS Enhanced Messaging Service or MMS messaging Multimedia Messaging Service CDMA code division multiple access TDMA time division multiple access PDC Personal Digital Cellular WCDMA Wideband Code Division Multiple Access CDMA2000 or GPRS General Packet Radio Service among others. Such communication may occur for example through the transceiver using a radio frequency. In addition short range communication may occur such as using a Bluetooth WiFi or other such transceiver not shown . In addition a GPS Global Positioning System receiver module may provide additional navigation and location related wireless data to the mobile computing device which may be used as appropriate by applications running on the mobile computing device .

The mobile computing device may also communicate audibly using an audio codec which may receive spoken information from a user and convert it to usable digital information. The audio codec may likewise generate audible sound for a user such as through a speaker e.g. in a handset of the mobile computing device . Such sound may include sound from voice telephone calls may include recorded sound e.g. voice messages music files etc. and may also include sound generated by applications operating on the mobile computing device .

The mobile computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a cellular telephone . It may also be implemented as part of a smart phone personal digital assistant or other similar mobile device.

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

To provide for interaction with a user the systems and techniques described here can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

The systems and techniques described here can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here or any combination of such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network . Examples of communication networks include a local area network LAN a wide area network WAN and the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

Although a few implementations have been described in detail above other modifications are possible. In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

