---

title: Stability improvements for timing-driven place and route
abstract: Techniques for reducing post-routing delay variance are described herein. In an example embodiment, an initial netlist includes multiple instances that represent digital components of an electronic design. An base signature is assigned to each instance in the initial netlist, where the base signature is based on two or more design or connectivity attributes of the instance. The base signatures are then used to generate an initial instance ordering of the instances in the initial netlist. A subsequent netlist, different from the initial netlist but representing the same electronic design, is received. Base signatures are assigned to the instances on the subsequent netlist and a subsequent instance ordering is generated. The subsequent instance ordering preserves the same order as the initial instance ordering for those instances that are included in both the initial netlist and the subsequent netlist. In this manner, any later netlist-based processing (e.g., such as packing, placement, and routing) is shielded from the negative re-design effects caused by the subsequent changes to the initial netlist and, consequently, the post-routing timing delay variance of the electronic design is reduced.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09003346&OS=09003346&RS=09003346
owner: Cypress Semiconductor Corporation
number: 09003346
owner_city: San Jose
owner_country: US
publication_date: 20130313
---
This application claims the benefit and priority of U.S. Provisional Application No. 61 648 497 filed on May 17 2012 the entire contents of which is hereby incorporated by reference as if fully set forth herein this application also claims the benefit and priority of U.S. Provisional Application No. 61 653 309 filed on May 30 2012 the entire contents of which is hereby incorporated by reference as if fully set forth herein and this application also claims the benefit and priority of U.S. Provisional Application No. 61 680 378 filed on Aug. 7 2012 the entire contents of which is hereby incorporated by reference as if fully set forth herein.

Field programmable Gate Arrays FPGAs and Programmable Logic Devices PLDs have been used in data communication and telecommunication systems. Conventional PLDs and FPGAs consist of an array of programmable elements with the elements programmed to implement a fixed function or equation. Some currently available Complex PLD CPLD products may comprise arrays of logic cells.

One of the drawbacks of conventional FPGA PLD and CPLD devices is the limited processing resources. For example the area of such devices is typically dominated by the routing resources which may consume up to 80 90 of the total area. Due to the ever increasing design complexity various Electronic Design Automation EDA programs tools use iterative processes to ensure that the processing resources of a target device are efficiently utilized when a design is placed and routed on the device.

Because of the increased design complexity and the iterative nature of the design process the predictability of a design tool becomes a key issue in the placement and routing of an electronic design on a target device. In this regard high variance in post routing delays poses a serious threat to meeting timing constraints in Engineering Change Order ECO scenarios. For example after a design is mapped to a target device and timing constraints are met a minor ECO type change may make the design fail timing constraints due to high variance in post routing delays. By way of illustration a minor ECO type change in the pin placement a perturbation in the initial instance order or a delta change in the choice of a starting solution during annealing may drastically change the quality of routing QoR and may lead to costly and time consuming design iterations.

The following description sets forth numerous specific details such as examples of specific systems components methods and so forth in order to provide a good understanding of various embodiments of the techniques for reducing post routing delay variance described herein. It will be apparent to one skilled in the art however that at least some embodiments may be practiced without these specific details. In other instances well known components or methods are not described in detail or are presented in a simple block diagram format in order to avoid unnecessarily obscuring the techniques described herein. Thus the specific details set forth hereinafter are merely exemplary. Particular implementations may vary from these exemplary details and still be contemplated to be within the spirit and scope of the present invention.

Further in various embodiments the techniques for reducing post routing delay variance described herein may comprise one or more methods that are executed by one or more computing devices or computer systems. Although the operations of such method s are shown and described hereinafter in a particular order the operations of each method may be altered so that certain operations may be performed in a different order or so that certain operation may be performed at least in part concurrently and or in parallel with other operations. In other embodiments instructions or sub operations of distinct operations may be executed in an intermittent and or alternating manner. Thus the various method embodiments of the described techniques as well as the order of operations therein are to be regarded in an illustrative rather than a restrictive sense.

The techniques for reducing post routing delay variance described herein include techniques for canonical instance ordering techniques for congestion aware timing driven placement and techniques for timing critical net based routing.

In an example embodiment a method for reducing post routing delay variance is performed by a computer system. The computer system receives an initial netlist where the netlist includes multiple instances that represent digital components of an electronic design. The computer system assigns an initial base signature to each instance on the initial netlist where the base signature is based on two or more design or connectivity attributes of the instance. The computer system then uses the initial base signatures to generate an initial instance ordering of the instances on the initial netlist. The computer system then receives a subsequent netlist that represents the electronic design where the subsequent netlist is different from the initial netlist. The computer system assigns base signatures to the instances on the subsequent netlist and generates a subsequent instance ordering where the subsequent instance ordering preserves the same order as the initial instance ordering for those instances that are included in both the initial netlist and the subsequent netlist. In this manner when any subsequent ECO changes are made to the initial netlist of the electronic design any subsequent instance ordering preserves the order of the instances thereby shielding the later netlist based processing e.g. such as packing placement and routing from the negative re design effects of the changes. As a result the post routing timing delay variance caused by the changes is reduced.

In an example embodiment a method for generating instance signatures is performed by a computer system. The computer system receives a netlist that includes a list of multiple instances that represent digital components of an electronic design. For each instance on the list the computer system generates a base signature and a fan in signature and then combines the base signature and the fan in signature to generate a combined signature for that instance. The computer system sorts the instances based on their combined signatures into a canonical ordering and stores the canonical ordering of the instances in or in association with the netlist.

In an example embodiment a method for congestion aware timing driven placement of an electronic design is performed by a computer system. The computer system determines a first state of the design by assigning a first instance representing a first component to a first location on an asymmetrical architecture that represents the organization of a set of physical resources e.g. such as a digital block array of a programmable target device. The asymmetrical architecture comprises multiple control logic blocks multiple horizontal H channels each having a given capacity and multiple vertical V channels each having a given capacity where the H channels capacity is different from the V channels capacity. After determining the first state of the design the computer system computes a first placement cost which includes a first congestion cost for the first state of the design. The computer system then determines a second state of the design by assigning a second instance representing a second component to a second location on the asymmetrical architecture. The computer system computes a second placement cost which includes a second congestion cost for the second state of the design. The computer system then computes a delta change as a difference between the first placement cost and the second placement cost and decides whether to accept or to reject the second state of the design based on the delta change. Since the congestion costs are accounted for in the placement costs any congestion that may be caused by the asymmetry of the architecture of the programmable target device is automatically accounted for during the placement of the components which in turn reduces the timing delay variance that is computed after a later routing operation.

In an example embodiment a method for timing critical net based routing is performed by a computer system. After performing placement to assign instances of digital components to locations on the architecture of a programmable target device the computer system performs routing by allocating routing resources to connect the nets that include the instances of the digital components. As part of performing routing the computer system determines the timing critical priorities for multiple nets that are represented by the placed instances and then iteratively routes the multiple nets based on their timing critical priorities where at each iteration a net having a higher timing critical priority is routed before another net that has a lower timing critical priority. In this manner it is ensured that timing critical nets are routed first thereby reducing the timing delay variance in the final routing.

In an example embodiment a method for reducing post routing delay variance may comprise a combination of operations that include two or more of the canonical instance ordering congestion ware annealing based placement and timing critical net based routing operations that are described herein.

In other embodiments the techniques for reducing post routing delay variance described herein may be embodied as a set of instructions that are stored on non transitory computer readable storage media. Such instructions when executed by one or more processors cause the one or more processors to perform the methods described herein. In yet other embodiments the techniques described herein may be embodied as an apparatus comprising one or more processors and non transitory media that stores a set of instructions. The set of instructions when executed by the one or more processors causes the apparatus to perform the methods described herein.

Referring to an exemplary programmable system is configured and or programmed by computer system . Programmable system includes microcontroller and configurable hardware components such as programmable array of digital blocks and possibly programmable array of analog blocks . Microcontroller can be programmed and re programmed and the programmable digital and analog arrays and can be configured and reconfigured to implement various applications and to perform a variety of functions.

An exemplary computer system may be configured and or programmed to execute processing logic that is configured and operable to perform the described techniques for reducing post routing delay variance. As used herein logic refers to a set of instructions which when executed by one or more processors are configured and operable to perform one or more functionalities. In various embodiments and implementations any such logic may be implemented as one or more software components that are executable by one or more processors e.g. such as central processing units or CPUs as one or more hardware components e.g. such as Application Specific Integrated Circuits or ASICs or as any combination of one or more software and hardware components. For example any particular logic may be implemented without limitation as a standalone and or client server software application as one or more software modules as one or more libraries of functions as one or more dynamically linked libraries as one or more active X controls and or as one or more browser plug ins. Further in various embodiments the functionalities of any particular logic may be implemented in the same integrated module or may be combined in two or more modules that may provide some additional functionality. When executed on a computer system or in a distributed computing environment a particular logic may be embodied as one or more computer processes threads or any other run time entities that are allocated computing resources e.g. such as memory CPU time persistent storage and network bandwidth to perform the logic s functionalities.

As illustrated in computer system is configured to execute integrated development environment IDE logic allowing for unified hardware and software development and for configuration of programmable system with hardware configuration files and software programming. Computer system can include one or more processors to execute IDE logic for example by executing instructions stored in memory or in other computer readable volatile and or non volatile storage media.

After hardware configuration files and software programming are generated computer system can program and or configure programmable system with the developed hardware configuration and software programming for example through communication device . In some embodiments device can be a wired device such as a Universal Serial Bus USB device network interface card e.g. such as Ethernet card and the like or it can be a wireless communication device that can establish a wireless link between computer system and programmable system .

Computer system may also include system interface s that allow the computer system to communicate with external devices such as user input device display device and programmable system . For example computer system may include a system interface to communicate with programmable system over communication device . In some embodiments system interface s can receive inputs for example through input device and present information for example via display device .

Computer system and or IDE logic can generate hardware configuration and or software applications for programmable system in response to user input for example from input device . IDE logic can include various development tools and or programs that allow system designers to describe hardware circuitry for programmable system and to implement and provide software or firmware code for microcontroller . In some embodiments IDE logic can receive hardware description code that describes this hardware circuitry in an abstracted or generic manner and can convert the generic code into device specific configuration files that are particular to the architecture and or resources of programmable system . The hardware description code provided by the system designers may include schematic circuit diagrams and or hardware code written according to a hardware description language such as Verilog or VHDL.

Computer system and or IDE logic can also generate application programming interfaces APIs based at least in part on the hardware description code. These APIs when provided to programmable system can program microcontroller to communicate with programmable digital and analog arrays and that are configured according to the device specific configuration files.

Computer system and or IDE logic can send the device specific configuration files and the application programming interfaces to programmable system . Programmable system can utilize the configuration files to configure particular hardware components in the programmable digital and or analog arrays and to implement the hardware circuitry described by the hardware description code. Programmable system can utilize the application programming interfaces to program the microcontroller to communicate with the programmable digital and or analog arrays and that are configured according to the device specific configuration files.

After programmable system has been programmed with the hardware configuration and software or firmware programming developed with IDE logic computer system can execute debug hardware to perform debugging operations on programmable system . In some embodiments debug hardware can be located externally from computer system and can communicate with the computer system via a system interface .

In various embodiments a computer system such as computer system may execute instructions to configure and re configure various target devices. Examples of such devices include but are not limited to FPGAs PLDs and CPLDs. In some embodiments the computer system may execute instructions to configure and re configure various programmable systems on chip or other electronic systems that include one or more processors microcontrollers or other processing devices that have configurable hardware components such as for example programmable digital and or analog arrays.

One example of such programmable system on chip is a device from the Programmable System on Chip PSoC family of products offered by Cypress Semiconductor Corporation of San Jose Calif. A computer system such as computer system can execute processing logic that allows designers to develop applications for and program both the configurable hardware components and the microcontroller of the PSoC device.

Device may also include CHub Core Hub which may include bridge e.g. such as a single level or multi level Advanced High Performance Bus Bridge and optionally a DMA Direct Memory Access controller that is coupled to microcontroller via bus . CHub may provide the primary data and control interface between microcontroller and its peripherals and memory and programmable core . DMA controller may be programmed to transfer data between system elements without burdening CPU core . In various embodiments each of these subcomponents of microcontroller and CHub may be different with each choice or type of CPU core . CHub may also be coupled to shared SRAM and SPC System Performance Controller . Private SRAM is independent of the shared SRAM which is accessed by microcontroller through bridge . CPU core accesses the private SRAM without going through bridge thus allowing local register and RAM accesses to occur simultaneously with DMA access to shared SRAM . Although labeled here as SRAM these memory modules may be any suitable type of a wide variety of volatile or non volatile memory or data storage modules in various other embodiments.

In various embodiments and implementations programmable core may include various combinations of subcomponents not shown including but not limited to global routing channels digital processing channels digital peripherals analog processing channels analog peripherals DMA controller s SRAM and other appropriate types of data storage 10 ports and other suitable types of subcomponents. In the example embodiment illustrated in programmable core includes GPIO General Purpose IO and EMIF Extended Memory Interface block to provide a mechanism to extend the external off chip access of microcontroller programmable digital array programmable analog array and special functions array each configured to implement one or more of the subcomponent functions. In various embodiments special functions array may include dedicated non programmable functional blocks and or one or more interfaces to dedicated functional blocks such as a USB a crystal oscillator drive a JTAG Joint Test Action Group interface and the like.

Programmable digital array may include an array of digital logic blocks and associated routing. In one embodiment the digital block architecture is comprised of UDBs Universal Digital Blocks . For example each UDB may include an ALU Arithmetic Logic Unit together with CPLD functionality or other types of digital programmable logic functions.

In various embodiments one or more UDBs of programmable digital array may be configured to perform various digital functions including but not limited to one or more of the following functions a basic IC slave an IC master a SPI Serial Peripheral Interface master or slave a multi wire e.g. 3 wire SPI master or slave e.g. MISO MOSI multiplexed on a single pin timers and counters e.g. a pair of 8 bit timers or counters a 16 bit timer or counter a 8 bit capture timer or the like pulse width modulators or PWMs e.g. a pair of 8 bit PWMs a 16 bit PWM a 8 bit deadband PWM or the like a level sensitive interrupt generator a quadrature encoder an Universal Asynchronous Receiver Transmitter or UART e.g. half duplex delay lines and any other suitable type of digital function or combination of digital functions which can be implemented in one or more UDBs.

In other embodiments additional functions may be implemented using a group of two or more UDBs. Merely for purposes of illustration and not limitation the following functions may be implemented using multiple UDBs an IC slave that supports hardware address detection and the ability to handle a complete transaction without CPU core intervention and to help prevent the force clock stretching on any bit in the data stream an IC multi master which may include a slave option in a single block an arbitrary length cyclical redundancy check or CRC e.g. up to 32 bits secure digital input output or SDIO serial general purpose input output or SGPIO a digital correlator e.g. having up to 32 bits with 4 over sampling and supporting a configurable threshold a LIN Local Interconnect Network bus interface a delta sigma modulator e.g. for class D audio DAC having a differential output pair an integrated interchip sound or IS stereo a liquid crystal display or LCD drive control e.g. UDBs may be used to implement timing control of the LCD drive blocks and provide display RAM addressing full duplex UART e.g. 7 8 or 9 bit with 1 or 2 stop bits and parity and RTS CTS support a capture timer e.g. 16 bit or the like a deadband PWM e.g. 16 bit or the like a system management bus or SMbus including formatting of SMbus packets with CRC in software a brushless motor drive e.g. to support 6 12 step commutation auto BAUD rate detector and generator e.g. automatically determine BAUD rate for standard rates from 1200 to 115200 BAUD and after detection to generate required clock to generate BAUD rate and any other suitable type of digital function or combination of digital functions which can be implemented in multiple UDBs.

Programmable analog array may include analog resources including but not limited to comparators mixers PGAs Programmable Gain Amplifiers TIAs Trans Impedance Amplifiers ADCs analog to digital converters DACs digital to analog converters voltage references current sources sample and hold circuits and any other suitable type of analog resources. Programmable analog array may support various analog functions including but not limited to analog routing LCD drive IO support capacitive sensing voltage measurement motor control current to voltage conversion voltage to frequency conversion differential amplification light measurement inductive position monitoring filtering voice coil driving magnetic card reading acoustic doppler measurement echo ranging modem transmission and receive encoding or any other suitable type of analog function.

Computer system may also include one or more input devices and one or more display devices that are coupled to processor s over bus . Input device s may include an alphanumeric input device e.g. such as a touch sensitive or typewriter style keyboard a pointing device that provides spatial input data e.g. such as a computer mouse or equivalent device and or any other suitable human interface device that can communicate user commands and other user generated information to processor s . Display device s may include a liquid crystal display LCD device cathode ray tube CRT monitor field emission device FED or flat panel CRT device light emitting diode LED display device plasma display device electro luminescent display device or any other display device suitable for creating graphic images and alphanumeric characters recognizable to the user.

Computer system may also include one or more communication devices and one or more data storage devices that are coupled to processor s over bus . Communication device s are configured to transmit and receive data to and from other computer systems and or computing devices. For example communication device s may include a USB controller and bus for communicating with USB peripheral devices a network interface card NIC for communicating over wired communication networks and or wireless network card that can implement a variety of wireless data transmission protocols for example IEEE 802.11 and or Bluetooth. Data storage device s are configured for persistently storing data and information that is used by computer system and or by its users. Data storage devices may include persistent storage media of one or more types including but not limited to electromagnetic disks e.g. hard disks optical storage disks e.g. CD ROMs magneto optical storage disks solid state drives USB flash drives and the like.

In the embodiment illustrated in IDE logic includes design editor to receive information describing hardware circuitry. The information describing hardware circuitry can be received from various sources and in various formats for example through user interface . Design editor can include various development tools that present a user or system designer with options for inputting circuit designs or descriptions to IDE logic . For example design editor can receive code written according to a hardware description language such as Verilog or VHDL. Design editor can also provide a graphics based circuit design application such as a Schematic Editor a Symbol Editor a GPIF General Programmable Interface editor etc. which allow designers and other users to create schematic diagrams of the hardware circuitry to be implemented by a programmable target device e.g. such as programmable system in . In some embodiments design editor can access database to determine dependencies build rules and debug rules for the received descriptions of the hardware circuitry.

Design editor can also receive user generated program code from user interface or from other system interface. The program code can utilize at least one application programming interface generated by the IDE logic to communicate with the hardware components in a programmable target device e.g. such as programmable system in . This program code can also include at least one application programming interface to allow a processor or a microcontroller in the programmable target device when programmed with the code to communicate with hardware components in the target device.

IDE logic includes processing logic which may be configured to perform various functionalities. For example processing logic may be configured to generate configuration files from the received descriptions of the hardware circuitry. In some embodiments when the received descriptions of the hardware circuitry are in an abstracted or generic format processing logic can access a device specific hardware mapping unit to map the received descriptions of the hardware circuitry to the programmable digital and or analog components of a programmable target device. In other words the processing logic can determine where and how the programmable target device implements the generic circuitry provided by the user or system designer. This level of abstraction allows users without specific knowledge of the programmable target device to program and configure the target device to perform various applications through the use of generic circuit descriptions and diagrams. Processing logic can also be configured to generate the configuration files from the device specific version of the hardware circuitry descriptions.

Processing logic may also generate one or more application programming interfaces from the received descriptions of the hardware circuitry. For example an application programming interface when provided to a programmable target device can program one or more processors or microcontrollers to allow them to communicate with hardware components of the target device.

In example embodiments processing logic may also be configured to perform the techniques for reducing post routing delay variance that are described herein. For instance in some embodiments processing logic is configured to perform the techniques for canonical instance ordering that are described hereinafter. In addition to or instead of in some embodiments processing logic may be configured to perform the techniques for congestion aware timing driven placement that are described hereinafter. In some embodiments processing logic may further be configured to perform the techniques for timing critical net based routing that are also described hereinafter.

As illustrated in IDE logic can include a compiler to compile the configuration files and or the application programming interfaces and link them into executables that can be loaded onto a programmable target device e.g. such as programmable system in . Once the configuration files and the application programming interfaces have been compiled and linked compiler can provide them to programmable system configuration unit to send them to the programmable target device for example via a programmable system interface . The programmable target device can configure its programmable digital and or analog arrays according to the configuration files and program its microcontroller according to the application programming interfaces in order to implement the hardware circuitry described by the user.

Compiler can also provide the configuration files and the application programming interfaces to debugger e.g. such as debug hardware in . Debugger can perform debugging operations on the programmable target device that is configured with the configuration files and the application programming interfaces. For example debugger can perform step over step into and step out operations which allows users the ability to perform incremental evaluations that step through programming code.

Certain embodiments of the techniques for reducing post routing delay variance described herein may be implemented as a computer program product that may include instructions stored on non transitory computer readable media e.g. such as volatile storage and or non volatile storage. For example a computer program product may include executable instructions that implement IDE logic and or processing logic as described above with respect to . These instructions may be used to program one or more computing devices or computer systems that include one or more general purpose or special purpose processors e.g. CPUs or equivalents thereof e.g. such as processing cores processing engines microcontrollers and the like . When executed by the processor s or the equivalents thereof the instructions cause the computing devices or computer systems to perform the operations that comprise the techniques for reducing post routing delay variance described herein. A non transitory computer readable medium may also include one or more mechanisms for storing or transmitting information in a form e.g. software processing application etc. that is readable by a machine e.g. such as a computing device or a computer system . Such non transitory computer readable storage medium may include but is not limited to electromagnetic storage medium e.g. floppy disks hard disks and the like optical storage medium e.g. CD ROMs and the like magneto optical storage medium read only memory e.g. ROM and the like random access memory e.g. RAM and the like erasable programmable memory e.g. EPROM EEPROM and the like flash memory or another now known or later developed type of medium that is suitable for storing information and or executable instructions.

Additionally some embodiments of the techniques described herein may be practiced in distributed computing environments where the computer readable medium is stored on and or executed by more than one computing device or computer system. One example of such distributed computing environment is a client server environment where some of the various functionalities of the techniques described herein may be performed by a client computer system and or some of the functionalities may be performed by a server computer system. Another example of such distributed computing environment is a cloud computing environment. In a cloud computing environment computing resources are provided and delivered as a service over a network such as a local area network e.g. LAN or a wide area network e.g. the Internet . Examples of cloud based computing resources may include but are not limited to physical infrastructure resources e.g. physical computing devices or computer systems and virtual machines executing thereon that are allocated on demand to perform particular tasks and functionalities platform infrastructure resources e.g. an operating system or OS programming language execution environments database servers web servers and the like that are installed imaged onto the allocated physical infrastructure resources and application software resources e.g. application servers single tenant and multi tenant software platforms and the like that are instantiated and executed in the environment provided by the platform infrastructure resources. In various distributed computing environments the information transferred between the various computing devices and or computer systems may either be pulled or pushed across the transmission medium connecting the computing devices and or computer systems.

Referring to a processing logic receives hardware description code such as hardware description language code state diagrams hardware schematics and flowcharts which describe the hardware circuitry of an electronic design. The hardware circuitry can include one or more circuits to perform various application or functions and analog and or digital signal routing associated with the circuits. Hardware description language code can be written in Verilog VHDL or other similar hardware description language. Hardware schematics can be schematic diagrams of the hardware circuitry created with a graphics based circuit design application such as a Schematic Editor a Symbol Editor a GPIF General Programmable Interface editor etc.

In block the processing logic performs netlisting of hardware description language code state diagrams hardware schematics and or flowcharts to generate a single representation e.g. such as a netlist of the hardware circuitry to be implemented by a programmable target device e.g. such as programmable system of . For example as part of netlisting the processing logic can combine and integrate the circuitry descriptions which may have various formats into a single netlist that represents the entire hardware circuitry.

In block the processing logic uses the information stored in the netlist to perform a canonical instance ordering process according to the techniques described herein. Specifically the processing logic uses the list of instances from the initial netlist to generate a mapping to another canonical ordering that is largely invariant to and independent from the instance names and their position on the original netlist order. In this manner the processing logic ensures that when any subsequent ECO changes are made to the netlist the subsequent canonical ordering will preserve the order of those instances that are included in both the previous netlist and the subsequent netlist. As a result later processing e.g. such as packing placement and routing that uses the netlist with the canonical ordering will be substantially invariant to minor changes in the initial netlist thereby leading to a reduced post routing timing delay variance. In some embodiments the operations in block may be performed after the high level and or low level synthesis operations described below in blocks and respectively but before any packing or placement has been performed.

In block the processing logic performs high level synthesis on the netlist that represents hardware description code . As part of the high level synthesis the processing logic breaks down e.g. reduces the netlisted hardware description code into lower level primitives logic equations and or flip flops and stores the reduced description code in or in association with the corresponding netlist. In block the processing logic maps the reduced hardware description code in the netlist to the programmable target device through low level synthesis. As part of the low level synthesis flow the processing logic 1 determines which hardware resources or components within the programmable target device e.g. such as programmable digital arrays and or programmable analog arrays can implement the circuitry components and primitives described by the reduced hardware description code in the netlist and 2 stores in or in association with the netlist a mapping that associates instances representing the components and primitives with the corresponding hardware resources of the programmable target device.

After block in some embodiments the processing logic may perform packing which is a flow that groups one or more instances from the netlist into one or more structures that can then be placed into the architecture of the programmable target device. For example the processing logic may pack into a single PLD a group instances that represent one or more equations and may then place and route that PLD onto one or more resource elements of the architecture of the programmable target device.

In block the processing logic performs placement and routing for the instances included in the netlist that represents the hardware circuitry of the electronic design. In some embodiments the processing logic performs annealing based placement for a programmable target device with asymmetrical architecture. For example according to the techniques described herein the processing logic uses congestion ware placement costs in determining the locations in a digital array of the programmable target device where the various instances of the netlist are to be placed. Since according to the techniques described herein the congestion costs are accounted for in the placement costs the annealing mechanism used by placement operation automatically accounts for any congestion that may be caused by the asymmetry of the architecture of the target device in turn this reduces the timing delay variance that is computed after the routing operation. In addition to performing placement for the instances of the digital components in some embodiments the processing logic may also perform placement for the instances of the analog components included in the hardware circuitry.

After placement in block the processing logic performs routing of the placed instances. During routing the processing logic determines routes and the corresponding switches that are needed to connect the placed instances. According to the techniques described herein in some embodiments the processing logic determines a timing critical priority for each net represented on the netlist and then iteratively routes the nets based on their timing critical priorities where at each iteration nets with higher priorities are routed before nets with lower priorities. In this manner the processing logic ensures that timing critical nets are routed first thereby reducing the timing delay variance in the final routing.

In block the processing logic generates hardware configuration files and application programming interfaces . For example the processing logic generates hardware configuration files based on the netlist of the reduced hardware description code and based on the placement and routing performed in block . It is noted that in embodiments in which the programming target device has asymmetric digital array architecture a dataset representing this architecture may also be included in the hardware configuration files . The processing logic generates application programming interfaces based on software programming code received from at least one system interface and possibly based on the netlist of the reduced hardware description code and on the placement and routing performed in block . Software programming code may include at least one application programming interface to allow a processor or a microcontroller in the programmable target device when programmed with the software programming code to communicate with hardware components in the target device.

In block a compiler compiles and links application programming interfaces and also compiles and or otherwise prepares hardware configuration files for loading to the programmable target device. In block the compiler or other logic sends the compiled and linked hardware configuration files and application programming interfaces to the programmable target device. In this manner the programmable target device e.g. such as programmable system in is configured to implement the hardware circuitry of the electronic design e.g. that is described in hardware description language code state diagrams hardware schematics and or flowcharts responsive to the hardware configuration files and the application programming interfaces. In block a debugger may execute a debugging application to debug the programmable target device when any issues are found or when a design or re design needs to be tested.

In some embodiments the processing logic can receive an indication to initiate automatic configuration and programming of the programmable target device after receiving the input information and . The processing logic and the compiler can automatically perform operations associated with the blocks and possibly with block in response to receiving the indication. In some embodiments the indication can be received from a user via at least one of system interfaces.

As used herein netlist refers to one or more data structures that store data describing the components connectivity and other properties of the circuitry of an electronic design. In various embodiments and implementations a netlist may be implemented as various types of data structures stored on volatile and or non volatile storage media. Examples of such data structures include but are not limited to files tables lists e.g. structured lists length name value pairs lists and the like data records e.g. records stored in relational hierarchical or object oriented databases data objects instantiated from object oriented classes arrays and or any other suitable structured data arrangements that can store persistent or in memory data.

In some embodiments a netlist comprises a list of instances and possibly other connectivity and design information such as nets input pins output pins clocks etc. and their definitions and attributes. As used herein instance refers to a data object that represents a digital component in a netlist. Digital component refers to a physical component that can be used in a digital circuitry to perform a certain function. Examples of digital components include but are not limited to logic gates e.g. AND gates universal gates such as NAND and NOR gates OR gates NOT gates XOR gates XNOR gates and the like flip flops e.g. SR flip flops D flip flops T flip flops JK flip flops and the like and various other primitives e.g. memory primitives data and address bus primitives port primitives library elements such as adders multipliers logic equations and the like that may be provided by a programmable target device. In various embodiments and implementations an instance may be implemented as a set of data as one or more records in a database as one or more entries on a list as a name value pair as an object oriented class instance as a set of ordered values and as any other suitable data object that can store or represent data in operation a data object may be stored on volatile and or non volatile media.

Engineering change orders ECOs for digital array designs e.g. such as FPGA based designs or digital block arrays in programmable systems on chip often require design changes late in the design process in order to correct functional timing and or technological problems. Such ECO type changes may involve adding and or removing instances from the circuitry netlist or may involve changing the values of one or more attributes of one or more instances on the netlist. Typically an ECO type change causes a change to a small portion of the circuitry netlist. To take advantage of the enormous resources and time already spent on placement and routing flow it is desirable to maintain post routing delay characteristics that are the same as or substantially similar to to the corresponding characteristics of the pre ECO state of the design in order to avoid further expensive design iterations. In some embodiments e.g. such as embedded systems it is very costly and time consuming to perform design iterations especially in ECO situations. It is noted that the canonical instance ordering techniques described herein are especially applicable in ECO situations but may not be as useful in design optimization scenarios that intentionally use variance as an advantage when exploring the entire solution space in the search for the best solution. 

For example an ECO type change may cause a modification of a small subset of the circuit netlist which may result in a minor variation in the instance list order seen by a packer during the packing stage. Most packing heuristics including fast greedy heuristics as well as relatively slower non greedy heuristics process the instances on the netlist in a certain order and have varying degrees of dependence on the initial instance order. Even a slight variation in this order may result in a substantially different packing and the subsequent placement and routing results may also change. In the worst case the post routing delay may fail timing constraints and require an expensive design iteration.

One conventional approach in addressing the challenges posed by ECO type changes uses custom heuristics during the high level logic synthesis in order to make the output from the synthesis stage more ECO tolerant. Another conventional approach involves packing look up tables LUTs into clusters where the LUT packing may be performed as a sub task within the mapping stage or as a separate task before placement is performed on the packed clusters. It is noted however that highly optimized packers e.g. packing engines and placers e.g. placement engines are inherently more susceptible to high variance from minor changes to the input netlist. For example EDA tools using highly optimized placement algorithms typically produce close to minimum wire length placements with great timing characteristics. However due to the huge solution space on which the placers usually work most stochastic placement algorithms have dependency on the initial starting state. Thus any disturbance in the initial starting state can still produce vastly different placement. As a result minor changes to the input netlist provided to a placer can result in a placement for which post routing timing constraints may be violated resulting in expensive design iterations.

The predictability of an EDA tool used in the design process is not unique just to ECO situations but the success of using the tool to address an ECO type change is highly dependent on predictability of the tool. A typical EDA tool may use several algorithms to perform design optimizations. Most design problems are NP Hard and there are no exact methods. Instead heuristic approaches are employed which return suboptimal solutions within a reasonable length of time. These heuristics lead to noise that creates variability in solution quality. This tool noise may be used advantageously by a designer to choose the best solution after running the tool several times where at each run the designer can make a slight change to a source of noise e.g. to one or more initial seeds . But the disadvantages resulting from such tool noise considerably outweigh its benefits. For example tool noise makes the solution space less smooth which reduces the solution quality and increases the convergence time of gradient descent algorithms. Tool noise also tends to magnify the variation in the solution quality in the event of ECO changes. Further tool noise negatively impacts the accuracy of upfront estimators e.g. such as a pre routed estimation of interconnect delays to rank and cost the criticality of nets during the placement stage. 

The techniques for canonical instance ordering described herein address the disadvantages caused by EDA tool noise and improve the predictability of the EDA tool especially in ECO situations where minor changes to a placed and or routed design may cause an unacceptable post routing delay when compared to the delay and or timing of the initially placed routed design. The techniques described herein either guarantee a unique instance order e.g. if an ECO type change caused a change in the initial instance order or minimize the perturbation to the instance order as seen by a subsequent operation e.g. at a packing stage or placement stage from any significant ECO induced change to the initial instance order. This helps in isolating the post packing placement and routing flow from netlist changes and drastically reduces the variance in post routing delay. For example experimental results generated by the techniques described herein demonstrate zero variance against random shuffling of instances on the netlist before the packing stage where the shuffling is used to simulate an ECO scenario . Experimental results for other non functional or slight functional modifications to the input netlist show greatly reduced post routing delay variance.

According to the techniques described herein a canonical ordering process should be performed on the instances of a netlist as early as possible in the design flow so that any ECO induced changes would not perturb the design flow. A canonical ordering process can have one or more of the following characteristics 

As used herein instance ordering refers to a dataset that is associated with instances on a netlist where the dataset elements represent an order of the instances on the netlist. For example an instance ordering may comprise a sequence of data elements e.g. such as data values where each data element corresponds to an instance on the netlist and where the sequence of the data elements indicates the order of their associated instances on the netlist. In various embodiments an instance ordering may be implemented in various ways including but not limited to as a list of data values stored in a file associated with a netlist as a list of data values stored as an entry in the netlist as a set of data values stored in a column of a spreadsheet or table that is stored in or in association with the netlist as data fields stored in an object instantiated from an object oriented class and or as any other storage structure that is suitable of representing ordered instances.

In order to achieve a stable instance ordering under ECO type situations given a list of instances in a netlist in some embodiments a processing logic which embodies a canonical ordering process computes a mapping to a canonical instance ordering. The canonical instance ordering indicates an order that is invariant with respect to any changes to the input order of the list of instances. In other words a mapping function applied by the processing logic produces the exact same order no matter what the input order is. If an instance is added or removed from the netlist as a result of an ECO type change then the canonical instance ordering generated by the processing logic should maintain the same relative order for the unchanged portion of the instances in the netlist. For such mapping function to exist the function cannot be dependent on the instance name and the position of an instance in the initial input list of instances.

In an example embodiment a mapping function uniquely identifies each instance based on one or more of its design attributes and or connectivity attributes. If two instances in the netlist are in fact structurally equivalent then their relative order in the canonical instance ordering doesn t matter from packing and placement point of view. Thus two instances may be uniquely identified e.g. with the same signature if and only if they are structurally equivalent e.g. if the two instances have the exact same instance type fan in cone structure and or fan out cone structure. As used herein signature refers to a data value that is associated with an instance and identifies the instance based on structural connectivity and or design attributes of the instance. In some embodiments a signature of an instance does not depend on a position of an instance on a netlist or on a non structural label e.g. such as a name assigned to the instance.

In block a processing logic receives an initial netlist. The initial netlist comprises multiple instances that represent digital components of an electronic design. For example in some embodiments the processing logic may be included in an EDA tool that is configured to read the netlist from a file while in other embodiments the processing logic may be configured to receive and or retrieve the netlist from a database or over a network. In some embodiments the processing logic may receive the netlist from another EDA component or logic which has performed various netlisting operations to assemble the netlist e.g. such as netlisting of hardware description language code state diagrams hardware schematics and or flowcharts that describe the circuitry of the electronic design .

In block the processing logic assigns a base signature to each instance on the initial netlist and stores the base signature in association with the corresponding instance. The base signature for a given instance is based on two or more design attributes or connectivity attributes of that instance. For example the processing logic may determine one or more design attributes of the instance e.g. such as structural attributes functional attributes etc. and one or more connectivity attributes of the instance e.g. such as the names of its terminal nodes the names of the terminal nodes of its fan in and fan out etc . Then the processing logic may generate the base signature for the instance based on two or more of the determined design and or connectivity attributes. In various embodiments and implementations the base signature generation for an instance may involve various operations including but not limited to selecting several of the design and or connectivity attributes of the instance concatenating the selected design and or connectivity attributes computing a digital representation e.g. a hash based on the design and or connectivity attributes and or any other operation that can generate a suitable data value that can identify the instance based on some or all of its design and or connectivity attributes.

In block the processing logic generates an initial instance ordering for the instances on the initial netlist. For example the processing logic may execute a canonical ordering process based on the base signatures assigned to the instances in the netlist to generate a canonical instance ordering. In some embodiments generation of the canonical instance ordering may involve applying a mapping function to the base signatures. In some embodiments generation of the canonical instance ordering may involve combining the base signatures with other structural or design information associated with the instances on the initial netlist and then applying the mapping function to the combined information. After generation the processing logic stores the canonical instance ordering in or in association with the initial netlist.

In block the processing logic receives a subsequent netlist. The subsequent netlist is different from the initial netlist but represents the same electronic design. In one example embodiment the subsequent netlist reflects an ECO type change to the electronic design. For example the ECO type change may involve adding one or more digital components to the design and or changing one or more design and or connectivity attributes of component s previously included the design. Thus the subsequent netlist may include one or more new instances representing the additional one or more digital components and or changes to one or more design and or connectivity attributes of instances already on the initial netlist.

In block the processing logic assigns base signatures to instances on the subsequent netlist by using the same operations as the operations performed in block for the initial netlist.

In block the processing logic generates a subsequent instance ordering for the subsequent netlist by using the same operations as the operations performed in block for the initial netlist. The subsequent instance ordering preserves the same order as the initial instance ordering for those instances that are included e.g. without any changes in both the initial and the subsequent netlists. For example the processing logic may execute the same canonical ordering process based on the base signatures assigned to the instances in the subsequent netlist to generate the subsequent canonical instance ordering.

After the operations in block are completed the processing logic may continue with other operations in the design flow. For example in some embodiments the processing logic may use the subsequent instance ordering in performing packing and or placement of the design onto a particular architecture. In the packing stage the processing logic groups one or more instances from the subsequent netlist based on their subsequent canonical instance ordering and then passes the generated structures to the placement stage. In the placement stage the processing logic executes an annealing based placement process to assign the instances to locations in the architecture of a programmable target device. In one embodiment such placement process may be a congestion aware placement flow that places the instances of the netlist onto an asymmetrical architecture that has horizontal and vertical channels with different capacities. One example of such congestion ware placement flow is described below in Section IV. In another embodiment the placement process may place the instances of the netlist onto a non asymmetrical architecture e.g. an architecture having symmetrical horizontal and vertical channels and optionally one or more additional dedicated channels .

In block a processing logic receives an initial netlist. The initial netlist includes a list of instances that represent digital components of an electronic design. For example in some embodiments the processing logic may be configured to read the netlist from a file while in other embodiments the processing logic may be configured to receive and or retrieve the netlist from a database or over a network. In some embodiments the processing logic may be configured to receive the netlist from another component or logic e.g. a module in an IDE that has performed various netlisting operations to assemble the netlist e.g. such as netlisting of hardware description language code state diagrams hardware schematics and or flowcharts that describe the circuitry of the electronic design .

In block the processing logic generates a base signature for each instance on the list of instances and stores the generated base signatures in association with their corresponding instances. The base signature for a given instance is based on two or more design attributes or connectivity attributes of that instance. The design attributes of the instance may vary depending on the type of component represented by the instance and may include without limitation type of the instance e.g. type of gate type of flip flop etc. number of input terminals width e.g. in bits of each input terminal number of output terminals width e.g. in bits of each output terminal string value representing an equation if the instance represents a macro cell and the like. The connectivity attributes of the instance may vary depending on the type of component represented by the instance and may include without limitation terminal names of the instance and terminal names of the fan in and fan out of the instance.

In block the processing logic sorts the list of instances based on their base signatures. In some embodiments the sort operation may be performed by using one or more pre determined heuristics e.g. such as heuristic s that are specific to the architecture of the programmable target device on which the design is to be implemented . In some embodiments the sort operation may be performed by using a tie breaking heuristic that defines how to order two or more instances that have the same signature.

In block the processing logic generates combined signature for each instance on the list of instances and stores the generated combined signatures in association with their corresponding instances. The combined signature of an instance is generated based on the base signature and on the fan in signature of the instance. As used herein fan in or fan in cone refers to the set of instances that can reach directly or indirectly through another instance the input node s of an instance. The fan in signature of a given instance is based on the base signatures of the instances in the fan in of that instance. For example in some embodiments the fan in signature of an instance may be a value e.g. a hash value an XOR value etc. computed over the base signatures of the instances included in the fan in for that instance. In some embodiments the combined signature of an instance may be computed by traversing the fan in of the instance in a forward breadth first traversal and at each node computing the combined signature by performing an operation e.g. hash XOR over the signature obtained at the previous traversal node and the base signature of the instance at the current node in the traversal.

In block the processing logic generates a transformed combined signature for each instance on the list of instances and stores the generated transformed combined signatures in association with their corresponding instances. The transformed combined signature of an instance is generated based on the combined signature and on the fan out signature of the instance. As used herein fan out or fan out cone refers to the set of instances that can be reached directly or indirectly through another instance from the output node s of an instance. The fan out signature of a given instance is based on the base signatures of the instances in the fan out of that instance. For example in some embodiments the fan out signature of an instance may be a value e.g. a hash value an XOR value etc. computed over the base signatures of the instances included in the fan out for that instance. In some embodiments the transformed combined signature of an instance may be computed by traversing the fan out of the instance in a backward breadth first traversal and at each node computing the transformed combined signature by performing an operation e.g. hash XOR over the signature obtained at the previous traversal node and the base signature of the instance at the current node in the traversal.

In block the processing logic generates a canonical instance ordering by sorting the list of instances based on their transformed combined signatures. In some embodiments the sort operation may be performed by using one or more pre determined heuristics that may include without limitations some or all of the heuristic s used in block and heuristic s that are different from the heuristic s used in block . In some embodiments the sort operation may be performed by using a tie breaking heuristic that defines how to order two or more instances that have the same transformed combined signature where such tie breaking heuristic may be the same as or different from the tie breaking heuristic used in block .

In an example embodiment the first operation in the canonical ordering process is to generate a base signature. In this embodiment the base signature for an instance is a linear combination e.g. the output from bit wise XOR operation of the following 

After the base signature for each instance on a netlist is generated in one embodiment a processing logic sorts the instances based on their base signatures before a breadth first search BFS traversal is performed. The sort guarantees that the BFS traversal will not be dependent on an arbitrary order of instances.

In one embodiment during the base signature sort the processing logic uses a heuristic to perform tie breaking for instances that have the same base signature. According this tie breaking heuristic the processing logic determines whether the name of an instance contains a bit index value. A bit index value is typically included in a name to define a width in bits associated with the represented component for example if the instance represents a component of a bus that is 10 bits wide then the instance name may be iobus10 . This heuristic is helpful in implementations where bit index values for an instance are not stored in the instance data structure as an integer property but can be extracted from the instance name for breaking ties between instances which are structurally identical.

After the base signature sort in one embodiment a processing logic uses the sorted instances to identify inputs and outputs. Any instance which does not have an input that is being driven is identified as a primary input and is added to an input list. Any instance that does not have a fan out is identified as a primary output and is added to an output list.

In this embodiment the processing logic initiates a forward BFS traversal from the input list to generate fan in signatures. To generate fan out signatures the processing logic initiates a backward BFS traversal from the output list. At every instance visited during the traversal the processing logic performs the following operations to encode the signature of the entire fan in or fan out for that instance while minimizing aliasing probability.

At the end of the signature generation flow in one embodiment the processing logic sorts the instances again based on their combined e.g. base fan in and fan out signatures. If ties exist then the processing logic may apply one or more of the following tie breaking operations as part of a heuristic during or after the sort.

In one embodiment a tie breaking heuristic performed after the list of instances is sorted based on the base signatures may include operations I and II above. In one embodiment a tie breaking heuristic performed after the list of instances is sorted based on the combined e.g. base fan in and fan out signatures may include operations I II and III .

Conventionally the instances from an input netlist are sorted by name. Thus a change to an instance name may alter the order of the instance list but should not have any effect on post placement delay characteristics.

To simulate the effect of instance name changes an example embodiment was used to perform experiments in which the instances on the netlists of several circuits were shuffled randomly. The random number generator seed was specified through a command line interface in order to achieve repeatable results. A script was developed to run a placer repeatedly for each netlist specifying a different random number seed for each run which resulted in a different instance order. The script automatically recorded the minimum slack for each clock domain. To measure the effectiveness of the techniques for canonical instance ordering described herein the script was run with the canonical instance ordering disabled and then with the technique enabled. The placer used in the experiments was a hybrid of Quadratic Placement followed by refinement and low temperature annealing. The timing results of these experiments are shown in Table 1 below.

In Table 1 the Variance columns show the maximum percentage difference between the minimum and maximum frequency values across 10 runs. As can be seen without canonical instance ordering the maximum frequency varied over a range of up to 20 . With canonical instance ordering enabled the maximum frequency was unaffected by the shuffling of the instances. For the test cases that had multiple clock domains each clock domain is listed in a separate row of the table.

The name based tie breaking criteria always provide a total order for the instances since the names are always unique. However actual name changes would affect the final order of the instances. The last column of Table 1 shows the results without name based tie breaking. A few of the test circuits used in the experiment exhibit order variation but many of them still have zero variance. As can be seen a slightly larger variance is observed for a couple of cases as part of the random name change based experiments. This is due to router induced effects where the unsorted version may just chance upon a good greedy ordering which suits the router better. But for majority of cases the results in Table 1 show that the sorted version has 0 variance.

Various alternative embodiments are contemplated to be within the spirit and scope of the techniques for canonical instance ordering described herein.

For example various embodiments may use different operations to combine base signatures with fan in and or fan out signatures. Such operations may include without limitation XOR based operations hash based operations various combinations of bit wise operations and any other operations that can generate unique output values based on multiple input values.

In another example some embodiments may compute a topological order for the input list of instances and may then use the topological order ID of each instance when generating its signature.

In another example various embodiments may use different combinations of design attributes and connectivity attributes in computing the base signatures for the instances on a given netlist. In some embodiments such combinations may be determined based on the specific characteristics and properties of the programmable target device of the specific properties of the electronic design being implemented and or on any other properties that are specific to the particular application of the target device and or the design that is to be implemented thereon.

In another example various embodiments may use just the fan in signatures or just the fan out signatures when computing the combined signatures based on which a canonical instance ordering for a netlist is generated.

In another example various embodiments may use different tie breaking heuristics that may be specific to the particular application of the programmable target device and or of the electronic design that is to be implemented thereon.

Digital block arrays e.g. such FPGAs are continually hard pressed to accommodate the requirements of large complex electronic designs. Typically the area of a digital block array is dominated by the routing resources which may consume up to 80 90 of the total area. Thus a good placement ensures that the routing resources of a target digital block array are efficiently utilized and once a design is mapped to a digital block array and timing constraints are met minor ECO type changes should not cause timing failures.

The routability and timing predictability of a design mapped to a digital block array depends on the underlying architecture on the placement solution as well as on the complexity of the interconnections of the circuit s included in the design. However routability and area efficiency are two competing constraints. Thus to improve both the routability and the timing predictability the routing and placement flows have to account for both congestion and timing constraints. Conventional congestion methods e.g. such as linear congestion algorithms however do not scale well for asymmetric architectures where the routing resources are distributed differently and un equally along the vertical and horizontal directions.

To address these issues the techniques for congestion aware placement described herein provide methods that account for any asymmetry in the targeted architecture by computing congestion aware placement costs that are used by the placement flow that assigns component instances to control logic blocks in a digital block array. The techniques described herein show significant improvement in predictability of the post routing timing via reduced variance in ECO type scenarios.

As used herein control logic block refers to a digital block that can be programmed to perform one or more functions. In some embodiments a control logic block comprises programmable resources that include without limitation one or more PLDs one or more data paths and one or more registers. In some embodiments the programmable resources of a control logic block may have independently selectable clocks and registers and may be allocated and programmed independently to perform one or more possibly unrelated functions. The functions that can be mapped onto a control logic block include without limitation timers decoders sequencers pulse width modulators UARTs and various other digital functions that can be performed by one or more digital blocks.

As used herein architecture refers to a dataset representing an organization of components included in a device e.g. such as a chip where the components include at least an array of control logic blocks coupled over communication channels. An example of an architecture is the organization of an FPGA PLD CPLD or any other chip that provides digital blocks and connectivity there between. As used herein asymmetrical architecture refers to an architecture in which one set of channels have a different capacity than another set of channels. Channel refers to a connection that a signal can take to propagate from one location in the architecture to another a channel may have multiple sub channels e.g. traces or routes so that multiple signals can be propagated through the channel simultaneously and or in parallel.

One example of an asymmetrical architecture is an architecture in which the horizontal H channels have a different number of sub channels than the vertical V channels functionally this difference in capacity indicates that the H channels can simultaneously and or in parallel carry a different number of signals than the V channels. In some embodiments the H and V channels may be included as part of a routing fabric that is programmable. It is noted that the designations of horizontal H and vertical V are used throughout herein for illustration purposes only and do not necessarily indicate a positional orientation of a channel.

In another example an asymmetrical architecture may include H channels and V channels that are of the same type but have different capacities. By way of illustration in this architecture both the H channels and the V channels may be data channels configured to carry data where each of the H channels has one capacity e.g. a number of sub channels and each of the V channels have a different capacity e.g. a different number of sub channels . Similarly both the H channels and the V channels may be address channels configured to carry address data where the H channels have one capacity and the V channels have a different capacity. It is noted that in some embodiments an architecture may not necessarily be asymmetrical just because the architecture may provide one or more dedicated channels each having a different and unique type. For example an architecture would not be asymmetrical if it provides one dedicated channel having one capacity and a set of ordinary H and V channels that each have the same capacity. To put it differently in these embodiments the asymmetry would need to be found between sets of channels that have the same type and or perform the same function.

In another example an asymmetrical architecture may be expressed in terms of the ratio between the capacity of the H channels and the capacity of the V channels. For example such asymmetrical architecture may have an H to V capacity ratio of 3 1. More generally an asymmetrical architecture may have an H to V capacity ratio that is in the range between 2 1 and 5 1.

In some embodiments a device having an asymmetric architecture may be programmable. Examples of such devices include but are not limited to PLDs CPLDs programmable systems on chip and any other device that includes a digital block array and switches bridges that can be programmatically controlled by a processor microcontroller. One example of such programmable system on chip is a device from the Programmable System on Chip PSoC family of products offered by Cypress Semiconductor Corporation of San Jose Calif.

In various embodiments the asymmetry of an architecture may be based on one or more of the following factors 

In some embodiments the techniques for congestion aware placement described herein provide for a placement flow that uses a simulated annealing based placement algorithm with an improved cost function that is adapted to model any asymmetry of the underlying architecture. In some embodiments the techniques described herein provide for estimating the routability of a placement solution which is useful in characterizing the correlation between the timing of the post placement solution and the timing of post routing solution thereby improving predictability. In one embodiment the techniques described herein may be implemented to place and route a design onto a device from the PSoC family of products offered by Cypress Semiconductor Corporation of San Jose Calif. In this embodiment the devices includes a digital array of UDB blocks such as for example the digital array described heretofore with respect to .

In the asymmetrical architecture illustrated in the H channels have 3 times the capacity of the V channels . For example the H channels have 96 sub channels while the V channels have 32 sub channels. Thus each of the H channels can carry 96 signals simultaneously and or in parallel while each of the V channels can carry 32 signals simultaneously and or in parallel. As illustrated in in this asymmetrical architecture there are no horizontal channels in the middle section of bank .

In the asymmetrical architecture of each CLB pair is tightly coupled and can communicate with the other CLB in the pair directly via a V channel. Each CLB in a pair is also coupled to a horizontal channel and thus can communicate with any other CLB through one or more HV switches that are programmed appropriately. In this asymmetrical architecture it is considerably harder for CLBs that are not part of the same pair to communicate with each other.

The techniques described herein provide a congestion aware timing driven placement flow that constructs a congestion cost function and integrates it with a simulated annealing flow. The cost function effectively accounts for the asymmetry of the underlying architecture without any significant impact on the delay penalty.

As used herein annealing or annealing flow refers to a process performed as part of placement that searches a solution space to find a desirable placement. The solution space may include a large number of states where each state is data indicating a unique combination of CLB locations onto which the components of an electronic design are mapped. The solution space may be very large since there may be a large number of states for placement based on the number and types of CLB locations and the number and types of instances representing digital components of an electronic design.

In some embodiments the annealing flow starts with a random solution and then uses a schedule to move components instances thereby traversing different states in the search for a better placement. A move is a transition from one state having a certain mapping of component instances to CLB locations to another state having a different mapping. The annealing flow may perform moves according to a schedule which is data that defines the starting state of the moves and the allowable states to which the moves can transition. For example a schedule may specify the input for a move e.g. the original CLB location of one or more component instances and one or more target states that the move can transition to e.g. one or more different CLB locations to which the one or more components can be mapped . In some embodiments an annealing flow may perform its moves iteratively and use a temperature indicator to indicate the level of movement that is available at each iteration.

In block a processing logic determines a first state of an electronic design by assigning a first instance representing a first component to a first location on an asymmetrical architecture. The asymmetrical architecture comprises a digital array of multiple control logic blocks multiple H channels each having a first capacity and multiple V channels each having a second capacity that is different from the first capacity.

For example the processing logic may receive retrieve and or access the first state where the first state may be a set of data elements that collectively define a mapping of the component instances to CLB locations in the digital array. In various embodiments and implementations a state may be implemented as a set of data elements stored in various types of data structures on volatile and or non volatile storage media. Examples of such data structures include but are not limited to files tables lists data records e.g. records stored in relational hierarchical or object oriented databases data objects instantiated from object oriented classes arrays and or any other suitable structured data arrangements that can store persistent or in memory data.

In block the processing logic computes a first placement cost for the first state of the design. The first placement cost indicates how the resources of the digital block array are allocated and utilized in the first state. In addition according to the techniques described herein the placement cost includes a congestion cost that indicates the contention for the allocated resources in the first state.

In block the processing logic determines a second state of the electronic design by assigning a second instance representing a second component to a second location on an asymmetrical architecture. For example the processing logic may use a schedule to select a move to and generate the target second state in which one or more instances representing one or more components are placed in locations that are different from their locations in the first state. The second state may be a set of data elements that collectively define a different mapping of the component instances to CLB locations in the digital array and the processing logic may store such data elements in suitable data structures on volatile and or non volatile storage media.

In block the processing logic computes a second placement cost for the second state of the design. The second placement cost indicates how the resources of the digital block array are allocated and utilized in the second state. In addition according to the techniques described herein the placement cost includes a congestion cost that indicates the contention for the allocated resources in the second state.

In block the processing logic computes a delta change as the difference between the first placement cost for the first state of the design and the second placement cost for the second state of the design .

In block the processing logic uses the delta change to determine whether to accept or to reject the second state of the design. Since the delta change is based on the placement costs of the two states before the move and after the move that include congestion costs the delta change accounts for any congestion that may be caused by the asymmetry of the architecture onto which the electronic design is being placed. In some embodiments the processing logic may use the delta change to compute a probability that indicates the chances that the move to the second state would result in an acceptable solution. If the computed probability indicates a better chance of reaching an acceptable solution the processing logic accepts the second state of the design with certain probability and continue the flow by using the schedule to determine the next move s . Otherwise the processing logic rejects the second state of the design and returns to the first state and then iteratively explores one or more other states. In some embodiments the probability that defines whether a state is accepted or rejected may be computed by using a function that uses as input the delta change for the state and one or more parameters that may be specified in or determined from a schedule that defines the temperature indicator associated with the allowable moves at that stage of the annealing flow.

In some embodiments the method of may be repeated to search the entire placement solution space while in other embodiments the method may be used on a subset of the solution space and or in conjunction with other types of annealing flows. After placement flow is completed and a final state of the design is accepted in some embodiments a processing logic may perform a routing flow. A routing flow is a process that assigns connectivity resources e.g. channels switches etc. that connect the component instances of the design.

The techniques for congestion aware placement described herein enhance the placement cost function used in the simulated annealing to factor in congestion in a way that accounts for the asymmetry of the architecture and can reduce the variance of the final post placement and post routing solutions.

In one embodiment the placement cost function used in the annealing flow has two components timing cost TC and bounding box cost BC and the objective is to minimize a linear combination of these costs. The simplified placement cost PC after every move during annealing can be expressed as PC TC BC In this embodiment the congestion cost CC is factored in the above placement cost function. The delay part in the timing cost TC should not be impacted directly rather any impact on the delay should be 2order effect from the overall cost function and the choice of move. Thus the congestion cost CC is factored in the bounding box cost BC part of the placement cost function by accounting for overlap of resource usage.

The bounding box of a multi terminal net is the rectangular box that contains all its terminals. As used herein net refers to the path of connections that a signal traverses from one location on the digital block array to another location. By way of illustration a net may represent the connections that comprise a circuit . The horizontal and vertical channels that fall within the bounding box are the resources used by that specific bounding box. When bounding boxes of multiple nets overlap they compete for the same channel resources. This causes congestion.

According to the techniques described herein the channels in a congested region of the digital block array are assigned overlap penalties so that during move selection as part of annealing the congested channels are less likely to be used. Further unlike some conventional approaches the overlap penalties cannot be assigned to the CLBs because of the non uniformity of the resources in the asymmetrical architecture thus the overlap penalties should be dealt with at the channel level.

In some embodiments the techniques for congestion aware placement described herein are implemented for an asymmetrical architecture. Since in an asymmetrical architecture the horizontal and vertical channel capacities are different the congestion cost for the horizontal and vertical channels are computed separately and then combined. This differs from symmetric architectures where the horizontal and vertical channel capacities are the same and they contribute equally to the cost function.

To illustrate how the architecture asymmetry may be accounted for in the placement cost suppose that in one embodiment Ndenotes the number of horizontal channels and Hdenotes the horizontal overlap penalty e.g. the number of nets whose bounding boxes include the i j th horizontal channel segment . Then the horizontal congestion cost can be computed as follows CC Similarly suppose that Ndenotes the number of vertical channels and Vdenotes the vertical overlap penalty e.g. the number of nets whose bounding boxes include the i j th vertical channel segment . Then the vertical congestion cost can be computed as follows CC In the above equations the resources are the horizontal and vertical channels and their numbering e.g. illustrates the numbering of 0 to 3 for the horizontal channels and the numbering of 0 to 3 for the vertical channels . The exponent k in the above equations is a function of the annealing window size.

The computed congestion cost can then be factored in the total placement cost as follows PC TC CC BC where CC denotes the congestion coefficient corresponding to the placement before or after the annealing move. For every move during placement the change in placement cost can be computed based on the placement cost before the move and the placement cost after the move. For example suppose that PCdenotes the placement cost for the design state before a move and that PCdenotes the placement cost for the design state after the move. Then PC TC CC BC PC TC CC BC where

After the placements costs are computed as described above the delta change between the placement cost before a move and the placement cost after the move can be computed as follows DELTA CHANGE PC PC In this manner the DELTA CHANGE implicitly takes into account the congestion differences for the two different design states i.e. the states of placement before and after a move during annealing.

As illustrated by the above examples the placement corresponding to is more uniform and hence it has a lower congestion cost.

In order to keep the post placement variance to a minimum and not let the congestion factor dominate in the beginning of annealing in some embodiments a threshold may be introduced on the value of the congestion cost. For example the congestion cost may be factored in when its value is higher than the threshold. In another example while combining the horizontal congestion cost e.g. CC and the vertical congestion cost e.g. CC the vertical congestion cost may be given higher weight when the vertical channel capacity is less than e.g. such as of the horizontal channel capacity. An example heuristic is defined in Table 2 below.

In some embodiments the congestion cost that is factored in the placement cost may be a global congestion cost. In these embodiments a coarse grained approach may be used when computing the congestion cost.

According to an example of the coarse grained approach in one embodiment the congestion cost may be computed across all the nets identified at given state of the design. In this embodiment the overlap penalties for the channel resources are computed for all the nets and then a single horizontal congestion cost CC over all nets and a single vertical congestion cost CC over all nets are computed. These two congestion costs are then applied while computing placement cost for a move.

One consequence of this approach is that a local congestion in one area of the digital block array may affect moves in other non congested areas of the array. In turn this may unnecessarily de rate the timing characteristics of the chip. However this consequence can be improved significantly by restricting the congestion cost computation to the perturbation bounding box only. The perturbation bounding box is the bounding box that includes all the nets that are associated with a given move. When the congestion cost computation is thusly restricted only the congested resources within the bounding box will impact the cost of the move.

In some embodiments the congestion cost that is factored in the placement cost may be a per net congestion cost. In these embodiments a fine grained approach may be used when computing the congestion cost.

According to an example of the fine grained approach in one embodiment the congestion cost is computed per net. Only the channel resources that belong to the bounding box of the current net are considered when computing the congestion cost. While this approach is computationally more expensive it tends to provide a better timing behavior because local congestion does not affect the non congested areas of the digital block array. To compute the congestion cost per net only the nets that are involved in a given move are considered.

In one embodiment multi terminal nets are broken into a set of two terminal nets and a congestion cost value is computed for the source sink pairs. One consequence of this may be that the channel resources that are closer to the source may be unnecessarily penalized. To avoid this consequence a heuristic may be used to handle multi terminal nets. For example the sink terminals may be ordered based on their proximity to the source terminal and then for each pair the previous sink may be used as the source.

To evaluate the efficacy of the techniques for congestion aware placement described herein an example embodiment was used to perform experiments for an asymmetric FPGA architecture in which post routing delay variances were computed for a set of industrial circuits. The experiment results showed maximum benefit for the global congestion cost case while limiting the congestion cost computation to the bounding box of the move. For these experiments multi terminal nets were simply split into multiple source sink pairs.

It is noted that for an asymmetric architecture a placement which is optimized for timing delay is likely to have large sensitivity to perturbation and the delay values may change drastically even if there is a minor non functional design change e.g. such as a ECO type change . However according to the techniques described herein the placement is made more uniform while minimizing the impact to net delays.

Table 3 below shows the experimental results obtained for an asymmetric FPGA architecture such as the architecture illustrated in . The maximum theoretical frequency for a circuit was computed based on the slacks computed by a static timing analyzer after placement and routing. The minimum maximum and mean values of the frequency were computed over ten runs where for each run a different random number starting seed was used for simulated annealing. Minor changes in the design were emulated by changing the initial seed for the annealing process.

Specifically Table 3 lists the average frequency and variance for the different clocks in the designs of the industrial circuits used for the experiments. The average frequency was the average across 10 runs. For each run the spread between the maximum and minimum frequencies were computed as a percentage of the minimum frequencies. The variance reported was the maximum of those percentage spreads. For the test cases that have multiple clock domains each clock domain is listed in separate row.

As can be seen from Table 3 the variance was reduced when the placement cost function used congestion coefficients during the annealing process. Another key observation is that the average frequency is not degraded. This is achieved by not impacting the delay factor in the placement cost directly. Also accounting for asymmetry by splitting the congestion cost helps in reducing the impact to the post routing delays. In a few cases marked in bold italics the variance marginally increased with the congestion cost. This can be attributed to the fact that the initial seed change caused too much of a difference and the starting point at the beginning of the annealing process was in a completely different solution space. In these cases the hill climbing during annealing was not very effective contributing to increased variance at the end despite improved uniformity brought in by the factoring in of congestion.

In some embodiments only some of the segments that fall within the bounding box of a net may be used during actual routing. Thus one possible enhancement to such embodiments would be to 

In one embodiment the techniques for congestion aware placement described herein may be implemented as a method performed by one or more computer systems for simulated annealing based placement of an electronic design. In this embodiment the method comprises the steps of determining a first state of the design by assigning a first instance representing a first component to a first location on an asymmetrical architecture wherein the asymmetrical architecture comprises multiple control logic blocks multiple horizontal H channels each having a first capacity and multiple vertical V channels each having a second capacity and wherein the first capacity is different from the second capacity computing a first placement cost which includes a first congestion cost for the first state of the design determining a second state of the design by assigning a second instance representing a second component to a second location on the asymmetrical architecture computing a second placement cost which includes a second congestion cost for the second state of the design computing a delta change as a difference between the first placement cost and the second placement cost and determining whether to accept or to reject the second state of the design based on the delta change.

In one aspect of this embodiment the method further comprises using a cost function to compute the first congestion cost and the second congestion cost wherein using the cost function comprises assigning overlap penalties to one or more H channels and V channels.

In one aspect of this embodiment the method further comprises using a cost function to compute the first congestion cost wherein using the cost function comprises determining at least one net that includes one or more control logic blocks to which the first instance is assigned and one or more H channels or V channels that connect the one or more logic blocks and assigning overlap penalties to those of the one or more H channels or V channels which are included in one or more nets that are different from said at least one net. In this aspect the step of using the cost function further comprises computing a first portion of the first congestion cost for any H channels separately from computing a second portion of the first congestion cost for any V channels and combining the first portion and the second portion to determine the first congestion cost.

In one aspect of this embodiment the method further comprises using a cost function to compute the second congestion cost wherein using the cost function comprises determining at least one net that includes one or more control logic blocks to which the second instance is assigned and one or more H channels or V channels that connect the one or more logic blocks and assigning overlap penalties to those of the one or more H channels or V channels which are included in one or more nets that are different from said at least one net. In this aspect the step of using the cost function further comprises computing a first portion of the second congestion cost for any H channels separately from computing a second portion of the second congestion cost for any V channels and combining the first portion and the second portion to determine the second congestion cost.

In one aspect of this embodiment the step of computing the first placement cost comprises minimizing a first combination of a first timing cost a first bounding box cost and the first congestion cost that are associated with the first state of the design and the step of computing the second congestion cost comprises minimizing a second combination of a second timing cost a second bounding box cost and the second congestion cost that are associated with the second state of the design.

In one aspect of this embodiment the first congestion cost and the second congestion cost are equal to a pre determined value for completely uniform placement and the first congestion cost and the second congestion cost are different from the pre determined value for non uniform placement.

In one aspect of this embodiment the method further comprises using a heuristic based on a threshold to compute at least one of the first congestion cost and the second congestion cost.

In one aspect of this embodiment the method further comprises one or more of computing the first congestion cost across all nets included in the first state of the design computing the second congestion cost across all nets included in the second state of the design computing the first congestion cost based on a first bounding box for a first single net that includes first one or more control logic blocks to which the first instance is assigned and computing the second congestion cost based on a second bounding box for a second single net that includes second one or more control logic blocks to which the second instance is assigned.

In another embodiment the techniques for congestion aware placement described herein may be implemented as a set of instructions that are stored on non transitory computer readable storage media. Such instructions when executed by one or more processors cause the one or more processors to perform the method and its various aspects for simulated annealing based placement that is described above. In yet other embodiments the techniques described herein may be embodied as an apparatus comprising one or more processors and non transitory media that stores a set of instructions. The set of instructions when executed by the one or more processors causes the apparatus to perform the method and its various aspects that is described above.

Various alternative embodiments are contemplated to be within the spirit and scope of the techniques for congestion aware placement described herein.

For example various embodiments may use different approaches to factor in the congestion costs computed for an asymmetrical architecture. Examples of such approaches include but are not limited to the following computation equations PC TC BC CC PC CC TC BC PC TC CC BC where PC denotes a placement cost for a given state of an electronic design TC denotes timing cost BC denotes bounding box cost and CC denotes the congestion cost for that state of the design.

In another example various embodiments may use different computations to split the congestion coefficients of the design states before and after an annealing move.

In another example various embodiments may use different thresholds and or different threshold based heuristics when combining and or weighing the horizontal congestion costs and the vertical congestion costs.

In another example various embodiments may use the CLBs of a digital block array as resources in addition to using the channel resources when assigning overlap penalties.

The techniques for reducing post routing delay variance described herein include techniques for timing critical net based routing.

In an example embodiment the techniques for timing critical net based routing are performed by a processing logic executed by a computer system. After performing placement to assign instances of digital components to locations on the architecture of a programmable target device the processing logic performs routing by allocating routing resources to connect the nets that include the instances of the digital components. For example during routing the processing logic determines the channels and or sub channels thereof and the corresponding switches that are needed to connect the placed nets.

As part of performing routing according to the techniques described herein the processing logic determines a timing critical priority for each net represented on the netlist of the design being routed and then iteratively routes the nets based on their timing critical priorities. At each iteration a net having a higher timing critical priority is routed before another net that has a lower timing critical priority. In this manner the processing logic ensures that timing critical nets are routed first thereby reducing the timing delay variance in the final routing.

To determine the timing critical priorities various embodiments may use various timing properties of the electronic design being routed. For example in one embodiment a processing logic may use the timing criticality of one or more components of the design and or the number of fan outs for one or more component instances to determine the timing critical priority of the nets represented in the design. In some embodiments the timing critical priorities of the nets may be data elements e.g. data values data objects etc. that are stored in association with their corresponding nets. Such data elements may be implemented in any suitable data structures that are stored on volatile and or non volatile storage media. Examples of such data structures include but are not limited to files tables lists data records e.g. records stored in relational hierarchical or object oriented databases data objects instantiated from object oriented classes arrays and or any other suitable structured data arrangements that can store persistent or in memory data.

In one embodiment the processing logic performs routing by executing a path finding process that attempts to route one net at a time. The path finding process organizes the nets from a netlist into a graph and then searches for suitable routing solutions by traversing the graph. Once the path finding process has routed N number of nets where N 2 it computes how many edges on the graph are overused. If two nets use the same edge then the path finding process increases a cost associated with the edge and then performs another iteration to route the N nets again by taking into account the assigned edge costs. Thus the difference between the two iterations is the cost of the underlying graph changes based on edge overuse. For example if in the first iteration two nets are overusing the same edge before the second iteration the cost of that edge is increased. Then during the second iteration one net will use the edge and another net will not use the edge. In conventional path finding algorithms determining which net will use an overused edge is based on heuristics that are typically related to the amount of overuse.

According to the techniques described herein the path finding process uses information indicating which nets are timing critical in addition to or instead of using conventional heuristics based on edge overuse. In some embodiments such information is the timing critical priority of each net and in these embodiments the path finding process is configured to determine which nets have a higher priority and to route these nets first. This improves the search for a desired routing solution in two ways first more importance is given to timing critical nets and second the post routing delay variance is decreased because the interrelated timing criticality of the nets is effectively imposing the order in which the nets are routed. Thus the techniques for timing critical routing described herein reduce post routing delay variance because they are more deterministic than conventional path finding approaches that rely only on edge overuse.

In one embodiment the techniques for timing critical net based routing described herein may be implemented as a method performed by one or more computer systems. In this embodiment the method comprises the steps of determining timing critical priorities for multiple nets that are represented on a netlist wherein the netlist describes components and connectivity of an electronic design and wherein placement of instances representing the components on the netlist has been completed and iteratively routing the multiple nets based on the timing critical priorities wherein at each iteration a first net that has a higher timing critical priority is routed before a second net that has a lower timing critical priority.

In another embodiment the techniques for timing critical net based routing described herein may be implemented as a set of instructions that are stored on non transitory computer readable storage media. Such instructions when executed by one or more processors cause the one or more processors to perform the method that is described above. In yet other embodiments the techniques described herein may be embodied as an apparatus comprising one or more processors and non transitory media that stores a set of instructions. The set of instructions when executed by the one or more processors causes the apparatus to perform the method that is described above.

Various alternative embodiments are contemplated to be within the spirit and scope of the techniques for timing critical net based routing described herein. For example various embodiments may employ different approaches in using the timing critical priorities determined for the nets of a placed design. Such approaches include but are not limited to using different heuristics for ordering the nets based on their timing critical priorities during path finder iterations using different timing critical priority ordering heuristics for different iterations and using timing critical priority ordering for some iteration s but not for others.

In various embodiments the techniques for reducing post routing delay variance may comprise a combination of operations that include two or more of the canonical instance ordering congestion ware annealing based placement and timing critical net based routing operations that are described herein.

For example in one embodiment the techniques for reducing post routing delay variance described herein may be implemented as a method performed by one or more computer systems. In this embodiment the method comprises one or more of generating a canonical instance ordering for a netlist wherein the netlist comprises multiple instances that represent digital components of an electronic design performing annealing based placement to assign multiple instances of digital components to locations on an asymmetrical architecture wherein the asymmetrical architecture comprises multiple control logic blocks multiple horizontal H channels each having a first capacity and multiple vertical V channels each having a second capacity wherein the first capacity is different from the second capacity and wherein performing the annealing based placement comprises computing one or more placement costs that include one or more respective congestion costs and placing the multiple instances based on the one or more placement costs and performing routing of placed instances of digital components wherein performing the routing comprises determining timing critical priorities for multiple nets that are represented by the placed instances and iteratively routing the multiple nets based on the timing critical priorities of the multiple nets wherein at each iteration a net having a higher timing critical priority is routed before another net that has a lower timing critical priority.

In another example in one embodiment the techniques for reducing post routing delay variance described herein may be implemented as a method performed by one or more computer systems. In this embodiment the method comprises the steps of generating a canonical instance ordering for a netlist wherein the netlist comprises multiple instances that represent digital components of an electronic design for an asymmetrical architecture wherein the asymmetrical architecture comprises multiple control logic blocks multiple horizontal H channels each having a first capacity and multiple vertical V channels each having a second capacity and wherein the first capacity is different from the second capacity and performing annealing based placement of the multiple instances based on the canonical instance ordering wherein performing the annealing based placement comprises computing one or more placement costs that include one or more respective congestion costs and placing the multiple instances onto the asymmetrical architecture based on the one or more placement costs. In one aspect the method further comprises performing routing after performing the annealing based placement. In various implementations of this aspect performing the routing may comprise determining timing critical priorities for multiple nets that are represented on the netlist and iteratively routing the multiple nets based on the timing critical priorities wherein at each iteration a first net that has a higher timing critical priority is routed before a second net that has a lower timing critical priority.

In other embodiments the techniques reducing post routing delay variance described herein may be implemented as a set of instructions that are stored on non transitory computer readable storage media. Such instructions when executed by one or more processors cause the one or more processors to perform the methods and their aspects that are described above. In yet other embodiments the techniques described herein may be embodied as an apparatus comprising one or more processors and non transitory media that stores a set of instructions. The set of instructions when executed by the one or more processors causes the apparatus to perform the methods and their aspects that are described above.

Various embodiments of the techniques for reducing post routing delay variance described herein described herein may include various operations. These operations may be performed by hardware components software firmware or a combination thereof. As used herein the term coupled to may mean coupled directly or indirectly through one or more intervening components. Any of the signals provided over various buses and switches described herein may be time multiplexed with other signals and provided over one or more common buses. Additionally the interconnection between circuit components or blocks may be shown as buses or as single signal lines. Each of the buses may alternatively be one or more single signal lines and each of the single signal lines may alternatively be buses.

In the foregoing specification the invention has been described with reference to specific exemplary embodiments thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are accordingly to be regarded in an illustrative sense rather than a restrictive sense.

