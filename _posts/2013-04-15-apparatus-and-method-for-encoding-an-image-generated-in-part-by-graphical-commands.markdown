---

title: Apparatus and method for encoding an image generated in part by graphical commands
abstract: A method and apparatus for encoding an image is disclosed. In one embodiment, the method comprises identifying initial pixels within a spatially defined sub-section, the initial pixels at least a defined number of pixels each comprising a first color; identifying background pixels, the background pixels comprising the first color and in a first defined spatial proximity to the initial pixels; identifying text pixels, the text pixels contrasting the first color and in a second defined spatial proximity to the background pixels; identifying picture pixels as all pixels other than the background pixels and the text pixels; generating a background encoding comprising (i) spatial locations of the background pixels and (ii) a lossless encoding of the first color; generating a text encoding identifying a spatial location and a lossless color encoding of each of the text pixels; and generating a picture encoding comprising a lossy encoding of the picture pixels.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08855414&OS=08855414&RS=08855414
owner: Teradici Corporation
number: 08855414
owner_city: Burnaby, B.C.
owner_country: CA
publication_date: 20130415
---
This application is a continuation of co pending U.S. patent application Ser. No. 12 825 092 filed Jun. 28 2010 which is a continuation in part of i U.S. patent application Ser. No. 11 173 303 filed Jun. 30 2005 which claims benefit of U.S. provisional patent application Ser. No. 60 584 869 filed Jun. 30 2004 and is also a continuation in part of ii U.S. patent application Ser. No. 11 333 955 filed Jan. 17 2006 which claims benefit of U.S. provisional patent application Ser. No. 60 703 767 filed Jul. 28 2005. Each of the aforementioned related patent applications is herein incorporated by reference in its entirety.

The present invention relates broadly to encoding computer display images for communications across a network. Specifically the present invention relates to applying decomposition methods compressing and transmitting images rendered by a processing system. More specifically the present invention relates to display images in a frame buffer that are accessed compressed and transmitted in priority sequence with the aid of multi layer image decomposition performed by the processing system in conjunction with drawing command hints issued by a processor.

Masked wavelets have been used to improve the compression of natural images with superimposed text or lines images as might be characteristic of a computer display image that requires compression in order for it to be transmitted to a remote system. Generally some form of pixel level image filter is applied to the image in order for select areas of the image which are better suited to alternative encoding methods are designated as don t care regions and these areas are excluded from the wavelet compression process.

However pixel level pre processing of an image to determine its characteristics prior to encoding is a processing intensive task especially when performed by computing resources also tasked with maintaining a high quality user experience by servicing latency sensitive functions such as image rendering and application software processing.

Therefore there is a need in the art for a system and method for improving the performance of image decomposition in such a manner as to overcome degradation in the user experience.

Embodiments of the present invention generally relate to a method and apparatus for encoding images. In one embodiment the method comprises identifying initial pixels within a spatially defined sub section the initial pixels at least a defined number of pixels each comprising a first color identifying background pixels the background pixels comprising the first color and in a first defined spatial proximity to the initial pixels identifying text pixels the text pixels contrasting the first color and in a second defined spatial proximity to the background pixels identifying picture pixels as all pixels other than the background pixels and the text pixels generating a background encoding comprising i spatial locations of the background pixels and ii a lossless encoding of the first color generating a text encoding identifying a spatial location and a lossless color encoding of each of the text pixels and generating a picture encoding comprising a lossy encoding of the picture pixels.

The present invention discloses a system and method for preparation of a computer display image for efficient encoding so that the encoded computer display may be transmitted across the network and accurately reproduced at the remote computer. Embodiments of the present invention decompose a computer display image into different layer types and associated masks based on the unique nature of the image. These include text object background and picture layer types. A set of image masks is used to uniquely identify different layer types within an image where each layer type includes none some or all of the pixels of the original image. Each layer of the image is processed prior to transmission i.e. compressed using a lossy or lossless encoding method appropriate for the characteristics of that layer.

In order to determine if a pixel from the original image is represented on a layer each layer is assigned a single bit pixel mask of the same dimensions of the original image. If a pixel from the original image is represented on a layer the corresponding bit in the pixel mask for that layer is set. Once the image is decomposed the original image and the mask is forwarded to the processing method defined for that layer and the mask is used by the processing method to identify which pixels of the image should be processed.

Embodiments of the present invention decompose image into layers of different image types and corresponding masks as in preparation for image compression. Each mask is generally implemented as an array i.e. each mask is a map of one bit pixels of image where a bit value of 1 positively identifies a pixel as an element of that mask. In one case image is decomposed into four mutually exclusive layers so therefore a mask set that defines image comprises a two dimensional array of the same dimension as image with each array element defined as a two bit value. In such a case each two bit value describes four different states and each state identifying the presence of a pixel on one of the four layers of the image. In alternative embodiments for example in cases where the masks are not mutually exclusive or cases where fewer or more than four masks are defined other structures including single bit or three bit elements are used.

In some embodiments one or more masks comprise information related to drawing commands associated with the rendering of image in a frame buffer. In one such embodiment additional mask layers are defined for lossy and lossless image types as classified through the interpretation of the drawing commands. Lossy image types include rendered Joint Photographic Experts Group JPEG files computer wallpapers and the like while lossless image types include rendered text and icons. Such classified image areas are thereby enabled to bypass pixel level filtering processes described herein and be forwarded directly to downstream lossless or lossy encoding methods. In another such embodiment a mask layer is defined for video image type in which case the classified area of image is processed using a video encoding method which may perform lossy encoding of rendered pixels transcoding of the source video stream or forwarding of the source video stream to the remote computer in different embodiments.

Text image types are generally encoded using lossless or high quality lossless methods to ensure accurate reproduction. Referring to text image type is identified by text mask . Text image type is defined by any small high contrast area that is surrounded by a background image with characteristics that enable the background image to be described using one or more graphical primitives. Background image type in as identified by background mask represents such a background image type. In an embodiment the basic graphical primitive is a line. Multiple lines of the same color represent solid color areas . Multiple lines of different colors represent gradient areas of the background. When image is regenerated regions of text image type overwrite the regions of background image type thus enabling the background image to be defined as continuous graphical objects through the text regions.

To maximize the area of regions comprising background image type without constraint by regions of text the decomposition process first identifies regions of text image identified by text mask which are then marked as don t care regions for the subsequent background decomposition analysis. Using this approach areas of background image may be specified as simple graphics descriptors that define long lines of the same length and the same color. Such descriptors are efficiently compressed and enable lossless background image reproduction.

Process proceeds to step Background Identification and Mask Generation . Step identifies and marks background image areas suitable for identification before other image types are identified. Process proceeds to step Text Identification and Mask Generation in which high contrast filters including saturated pixel filters and other pixel pattern filters are used to identify and mark high contrast areas including text graphics or icons. Following step the text mask contains both text images and type 2 object types. Process proceeds to step Background Expansion and Mask Update in which the background mask is updated to include areas that have been marked in the text mask as additional background areas in the background mask. Process proceeds to step Text Expansion and Mask Update in which the updated background mask is used as a reference to clear the text mask of pixels that are assigned as both text and background pixels. In some embodiments optional step attempts to expand the text mask through iterations of steps and until a desired level of quality is achieved for the text mask and the background mask. Process proceeds to step Enclosed Object Additions in which small areas that are not identified in the text or background masks are reviewed based on the image type of neighboring pixels. Small areas adjacent to text background or type 1 objects are generally reclassified as text image type. Process proceeds to step Separate Object Layer from Text Layer in which the text mask is divided into two layers i.e. an object layer associated with type 2 object image and text image layer associated with text image type . The object layer consists of areas on the original text mask that are not fully surrounded by background. Pixels in the object layer are removed from the text mask and placed in the object mask. The text layer consists of areas on the original text mask that are fully surrounded by background. Pixels in the text layer remain on the text mask. Process proceeds to step Generate Picture Mask in which pixels that are not already identified as text objects or background are identified as picture pixels in the picture mask. Process proceeds to step Optimize Filter Mask in which the mask set is filtered to reassign small isolated image regions that may hinder optimum compression and can be reclassified without degrading the image quality. Process ends at step .

Such a filter seeks a line of adjacent pixels that is 16 pixels in length with all pixels matching in color. A variation of this filter allows small variations in color. In cases where these variations are not factored into the graphics primitive for the background the compression process reduces the image quality. Other variations include rectangular area filters diagonal lines dotted or dashed lines or color lines of even gradient to identify background pixels or a graphic descriptor that determine a default background color for an area or an entire display.

To meet an underlying need for accurate text reproduction a conservative analysis for text identification is generally prudent. While accidental classification of non text areas as text areas does not impact image quality text areas should always be correctly identified to ensure lossless compression. Graphical images that happen to incorporate lines of a constant color e.g. line of 16 pixels are generally decomposed onto the background layer rather than the text layer if they are identified by the background filter. This may decrease the overall compression ratio but both the background and high contrast features are reproduced accurately.

Based on the variety of shapes and forms expected for text embodiments of the present invention use a series of contrast filters in conjunction with an accumulated pixel density integration filter to positively identify text pixels. Each contrast filter is applied to the image and marks are assigned to individual pixels identified as text prospects. Once the image has been processed by the series of contrast filters the marks for each pixel are accumulated and the image is filtered by the pixel density integration filter to select only areas that have a high density of text markings.

Process starts at step Identification and Marking of Saturated Text Pixels in which a first filter method identifies and marks saturated text pixels. Due to their vivid nature saturated pixels in computer display images have a high probability of being text. In a 24 bit color space embodiment a saturated color in Red Green Blue RGB space is defined as any color where R G and B are each 0 or 255 where each RGB color is represented by an 8 bit value. For a grayscale embodiment these values correspond to the values used for the colors black and white. The mere presence of saturated color pixels does not guarantee that the pixels are text so the saturated color pixel needs to be adjacent to a pixel of contrasting color. The filter seeks saturated color pixels with the additional constraint that each be adjacent to a pixel of reasonably high contrast. Background pixels are usually saturated so an additional constraint is that the saturated pixel should not be a background pixel as determined by previous filters.

Process proceeds to step Application of 3 4 and 5 Element Pixel Patterns in which pixel regions of various sizes that match either exactly or within some predefined difference pre determined pixel patterns. These pixel patterns are based on the expected color gradient and contour of text. In addition these pixel patterns may include the expected location of background pixels where a background pixel is a pixel that has been detected by the aforementioned background filter . In an embodiment multiple pixel pattern filters that compare groups of 1 3 1 4 or 1 5 regions of pixels are applied to the image to determine which pixels are assigned text pixel markings.

Process proceeds to step Integration and Filtering of Marked Text in which prospective text pixels receive multiple markings from the multiple pixel pattern filters. Once all of the text filters have been applied the marks are accumulated and integrated over a small area. The output of the integration filter is a value that is used to measure if the area has a sufficient density of text marks. If the area passes the threshold then all text marks in that area of the text mask identify text pixels. If the area does not pass the threshold then all text markings are considered to be noise and the text marks in that area are removed.

Process proceeds to step Text Mask Generation in which the remaining text pixel markings are converted into a text mask after the text pixel markings determined to indicate noise have been removed. Indicia for pixels that are identified as both text and background are also removed from a text mask as step Remove Background Pixels from Text Mask .

Following step the text mask contains both text and high contrast objects. These high contrast objects are removed from the text mask by a later filter. Text indication is not a perfect process and not every text pixel is positively identified by the aforementioned pixel patterns. As a next step Text Surround Mask Generation a blocking operation is performed to mark the pixels surrounding text pixels to ensure the mask is expanded to include all text pixels. The expanded area is also useful for background identification.

Pixel B may be to the right left above or below the saturated color pixel A. The saturated pixel filter may be applied in multiple directions for example in some embodiments diagonal filter is also used.

Anti aliased text does not comprise boundaries as sharp as standard aliased text. As such saturated pixels in anti aliased text are normally adjacent to gray pixels and the color difference between them may not meet the minimum difference requirement. A variation better suited to anti aliased text measures the contrast between the saturated pixel A and the pixel B where B is two pixels away from A rather than directly adjacent as shown for pixel pair . In such an embodiment the middle pixel between pixel A and pixel B is either not considered in the filter equation or the filter coefficient for that pixel has a reduced weighting. For example a weighted average value may be calculated across the two non saturated pixels where the weighting for the center pixel is lower than the weighting for the outer pixel. This averaged contrast level is then used to determine if a contrast threshold is exceeded.

In another embodiment color pixels that are saturated in one or two of the R G or B levels are also considered for text identification. However the probability of false detection increases as the number of saturated colors is reduced from three to two or one. The probability of errors further increases as the filter width increases. In these cases additional filtering is required to remove the unwanted detections. For example one approach decreases the contrast threshold between the saturated color pixel and the adjacent pixel that positively identifies the color pixel as text.

An embodiment of the 3 pixel filter comprises two control values for determining if pixel or group of pixels matches this pattern and should be marked as text. The first control value is the minimum difference between the center pixel and the nearest outside pixel. The second control value is the maximum difference between the two outer pixels. While the minimum difference of the center pixel need not be large if the end pixels are identical in cases where the maximum allowable difference between the end pixels is increased the center pixel minimum difference should also be increased to prevent excessive false text markings. An optional parameter for the filter is to use the background information to determine if a pixel is text. Pixels A B and C are marked as text according to the criteria in expressions 4 and 5 below minimum difference between center pixel and nearest outside pixel and optionally A and or B are background pixels 5 

If there are background pixels at both ends of the filter and the center pixel is not a background pixel then there is a high probability that the center pixel is a text pixel. If only one end of the filter is an identified background pixel but there is minimal difference between the two ends then there is a reasonable probability that the text is on a gradient background. In cases where a pixel identified as a background pixel is under filter examination the other two parameters may be reduced without increased false text detection.

4 Pixel filter also depends on the background in a digital image being precisely constant without any noise i.e. pixels A D minimum difference or C D minimum difference for readability purposes.

An application of a 1 4 pixel pattern that accounts for pixels in the same text character being exactly equal comprises pixels A B C and D marked as text using the middle pixels according to the expression minimum difference 9 and minimum difference 10 The 1 4 pixel pattern filter may be applied to detect large font over a wide area of flat text. In addition some pixel patterns associated with small fonts can only be properly expressed by a 1 4 pixel pattern. A variation on the 4 pixel filter uses background pixel information to improve the search in a similar mode to the 1 3 pattern filter. Pixel pattern filters of 1 5 format are also useful for detecting wider text. While the simple n m pixel pattern recognition works well for small values of n and m as the pixel pattern increases in size it loses its suitability to capturing generic text characteristics and becomes better suited to character recognition applications.

Next accumulated text markings provided by the text filters are filtered to evaluate the text mark density and remove erroneous text detections. If the number of text marks over a small area exceeds a defined threshold the text pixels in that area remain marked as text pixels. In different embodiments the weighting of text marks and the text density threshold may be varied in different areas of the image. Nevertheless depending on how the text markings are accumulated and the defined threshold value some false text indications may result especially in areas where text is drawn over textured image .

Small areas of image types may be filtered at step of process once the masks are created. This filter reclassifies small areas of one image type based on the type of adjacent pixels in order to improve the compression ratio of the image. One filter method changes small areas of background pixels that are surrounded by text pixels to text pixels. The reason this is more efficient is that background image types compress well if they define a large area but the text compression algorithms may be better at handling small groups of pixels. Another filter method changes small groups of background pixels that are surrounded by picture pixels to picture pixels because these areas are likely a flat area of the picture. Yet another filter method converts small groups of picture pixels surrounded by background or text pixels to text pixels using methods similar to the detection method of process stet .

The described decomposition method primarily discusses a grayscale image for simplicity purposes. However various embodiments apply decomposition methods to an RGB computer display image by individually testing each color component using the steps of process described. The text filters used in such color applications may select the number of colors required in order to satisfy the positive text identification criteria. In other embodiments color space translation is used to improve or simplify the decomposition method. In such case the image compression process that follows decomposition should generally use either an RGB format or an alternative lossless translation to ensure accurate reproduction of the image.

Referring to host system is connected to remote system by network . Host system is comprised of CPU connected to system memory and drawing processor by chipset . While a single CPU is illustrated it is to be understood that alternative embodiments where multiple CPUs are utilized in a cooperative arrangement can also be realized. In an embodiment drawing processor is a discrete silicon component such as a GPU connected to CPU by a data bus via chipset . In other embodiments drawing processor comprises a silicon function integrated into chipset or CPU . In yet other embodiments such as a virtualized architecture uses in Virtualized Desktop Infrastructure VDI system comprises multiple drawing processors each implemented at least in part as machine readable instructions that are executed by CPU i.e. drawing processor may be a virtualized GPU . Drawing processor is coupled to drawing memory which incorporates one or more frame buffers. In discrete embodiments of drawing processor drawing memory is generally high speed memory double data rate e.g. DDR3 or extreme data rate XDR memory dedicated for access by drawing processor and encoding system . In a virtualized embodiment drawing memory comprises one or more regions of system memory . Drawing memory generally stores information associated with an image representation including image vector or pixel data attributes drawing commands file information or other details pertinent to an image.

In some embodiments host system also includes other peripherals such as host USB controller and or host audio controller connected to CPU by chipset . In an embodiment host USB controller is bridged at the buffer management layer with remote USB system to provide a synchronized data path that enables the communications of different traffic types including control and status packets in addition to packet transport of different USB data types such as isochronous and bulk data types. Host audio controller is bridged at the buffer management layer with remote audio system to provide synchronized communications of packetized audio data and audio control information between host and remote systems. In some embodiments host USB controller and host audio controller are implemented at least in part as software functions executed by CPU and or embedded in other host subsystems including chipset or encoding system .

In an embodiment encoding system is connected to drawing memory so that it can read and encode sections of the display image in drawing memory . In such an embodiment encoding system may have directly addressable access to a drawing memory that is used by drawing processor . In an alternative embodiment drawing memory may be part of system memory connected to CPU or chipset and in which case encoding system also has access to the drawing memory. In some embodiments at least part of encoding system is implemented as machine readable instructions suitable for execution by CPU or a second processor in communication with drawing memory .

In the embodiment of encoding system is connected to traffic manager for transfer of encoded display data from the encoding system to the traffic manager. Traffic manager aggregates display data with other CPU or peripheral traffic and forwards it to network controller which manages the transport of network packets from host system to remote system . Network controller also receives media streams such as audio USB and control messages from remote system which are forwarded to traffic manager which in turn passes them to destination host USB controller or audio controller .

In some embodiments network controller and encoding system are connected to chipset by a system bus such that encoded display data and network management data may be communicated between network controller and encoding system over the system bus. In such implementations traffic manager may not be necessary to the encoding and transmission system.

Drawing operations may be performed using published methods such as existing industry compatible application programming interfaces APIs available to existing application software. CPU issues drawing commands to drawing processor which renders display images in drawing memory . Encoding system then accesses image sections from drawing memory and compresses them using encoding methods described below.

In an embodiment encoded image sections are forwarded from encoding system to traffic manager where they are prioritized and multiplexed with audio USB and other control signals from CPU or peripherals that are also destined for the remote system. Traffic manager prioritizes the outgoing traffic based on the real time demands of the image audio and USB media streams and the attributes of the present image to ensure perceptually insignificant delays at remote system . As one example display update information receives higher priority than bulk USB transfers. As a second example outbound display updates are multiplexed with outbound audio data updates in situations where a portion of the display has been identified as a video sequence. This ensures that a video sequence remains synchronized with its audio channels. As a third example each traffic type is allocated a fixed maximum bandwidth. For example image data may be granted 80 of the network bandwidth while audio and USB data may each be allocated 10 of the available bandwidth. In the case where audio data meets its allocated bandwidth a higher compression ratio may be activated. In the case of bulk USB data meeting its threshold the USB data may be delayed until competing higher priority transfers have completed. In the case where image data exceeds its bandwidth a different image encoding method that requires less bandwidth may be selected and used. Other methods of traffic management such as the real time allocation to different traffic types according to traffic type and priority may also be used.

Traffic manager may also feed network availability information back to encoding system so that suitable encoding methods may be selected based on network conditions. Such network availability information may be determined by monitoring the bandwidth requirements of inbound and outbound USB and audio streams monitoring error rates and receiving performance information provided by remote system and optionally real time network management equipment. In an exemplary embodiment multiplexed media and control streams are encapsulated using an appropriate network protocol for example UDP IP are then forwarded to network controller for transmission over an Ethernet network . Network controller then manages the physical and link layer communication of the data streams to remote network controller in the remote system .

Remote network controller manages the physical and link layer communication of the data streams to and from host network controller . Remote network controller forwards inbound traffic to remote traffic manager which reconverts the aggregated streams from host system into separate audio USB and image streams. USB data and audio streams are directed to remote USB and remote audio systems respectively while display image data is directed to remote display decoder . Remote traffic manager also directs host bound traffic from the remote USB and audio systems to remote network controller for encapsulation and transfer to host system .

The display data received from host system is decoded by remote display decoder and stored in remote frame buffer . Alternatively the image may be stored directly in frame buffer in compressed form and decoded by remote display decoder in real time as controlled by display controller . Display controller accesses the image from frame buffer and generates a timed display video signal e.g. Digital Visual Interface DVI signal which is used to drive remote display .

Network errors and bandwidth availability are managed at various protocol levels by different modules. At the physical and network protocol layers the transport is managed between network controller and remote network controller . Remote traffic manager monitors network congestion and availability based on the timing of received packets sequence numbers and lost packets and periodically signals traffic manager regarding network and data transfer status. Traffic manager forwards this status information to encoding system which adapts the encoding scheme in real time based in part on bandwidth availability. Encoding system may also predict future bandwidth requirements based on interpreted drawing commands as described.

At a higher protocol layer remote display decoder detects if image sections are corrupt late or dropped. In these cases remote display decoder signals encoding system that the section should be retransmitted. Encoding system either retransmits the requested section or an updated version depending on the availability of refreshed information in the drawing memory .

Drawing memory incorporates one or more designated areas that are used by drawing processor to render and store display image frames ref. frame buffers . The presence of a bus arbiter between the drawing memory and drawing processor encoding system enables processor to draw to drawing memory in a transparent manner i.e. as if an encoding system were not also connected to drawing memory . Such an arbitrated coupling enables the rendering performance of the drawing system to not be impacted by the presence of the encoding system .

In an embodiment encoding system comprises three modules. First encoding sequencer has read access to drawing memory and responds to requests for updated display sections by reading the requested sections from the drawing memory . Second display encoder is connected to the output of encoding sequencer and compresses sections of the display image using any of several means described below. Third command monitor has access to the drawing commands issued by CPU . The command monitor may either be a software function executing on the CPU and or a dedicated function or functions embedded within encoding sequencer and or display encoder . In select embodiments the display encoder is a dedicated hardware module but the functionality of encoder may be implemented either as hardware or software or a combination within drawing processor or CPU in other embodiments. Encoding sequencer uses synchronized timing means to access pixels blocks lines frames or other sections of image from a frame buffer in the drawing memory . This access is initiated by any of several mechanisms including an incoming request from remote display decoder or locally generated timing. In select embodiments regions of a frame buffer are read on request by remote display decoder only after drawing processor has signaled that the rendering of a current frame is complete for example using frame buffer timing signal . To prevent the tearing of a display image during encoding it is generally recommended to delay the encoding of a frame until the completion of some raster operations such as move operations.

In some embodiments the drawing command stream rate at which a software application executed by CPU calls drawing processor is controlled e.g. using CPU blocking commands so that drawing memory is updated at a rate that matches the image throughput rate. The optimum frame update rate is determined by identifying image throughput bottlenecks. In one embodiment the bottleneck is identified by comparing the throughput of the drawing encoding transmitting and decoding functions and the rate at which drawing command are issued is controlled to match the slowest throughput. In another embodiment the encoding method is selected so that the transmission rate matches the slowest of the drawing command throughput rate the encoding rate and the decoding rate. In an embodiment frame buffer timing signal is used to establish the frame update rate used by the encoder. In embodiments where network bandwidth is unconstrained a frame buffer is read by encoding system prior to the drawing processor flagging the completion of the rendering operation. In such cases encoding system may encode and transmit the image prior to drawing completion. In this embodiment encoding system keeps track of sections updated by drawing changes that occur after the selection of a particular frame buffer and transmits these changed sections after the drawing processor signals the availability of the rendered image. The advantage of this method in systems with a high availability of network bandwidth is that even though some data may be transmitted twice pre encoding and pre transmission of image sections reduces the overall latency between the rendering operations and remote display operations.

Encoding sequencer reads the requested image segment and forwards it to display encoder for compression. Encoding sequencer may also emulate a local display controller by providing timing signals e.g. VSYNC signal for drawing processor . Command monitor filters drawing commands issued by CPU to drawing processor for useful information that may facilitate or optimize image decomposition and or display encoding functions. Useful information includes an understanding of image type co ordinates image quality display priority i.e. latency and other attributes of the display. Display encoder uses knowledge gained from the drawing commands that have been forwarded by command monitor and additional knowledge of which areas of the frame buffer have been updated to compresses image sections or changed areas of the image sections.

Command monitor may also monitor source commands executed by CPU for display setup parameters configuration instructions and timing requirements including display refresh rates issued to display controller and forwards configuration information to remote display controller . Timing requirements are forwarded to encoding sequencer which uses the information to provide emulated timing for the drawing processor e.g. VSYNC signal . In select cases where a software application is blocked waiting for the completion of drawing operations e.g. a waitforvsync function call CPU is abstracted from the fact that the VSYNC signal is generated by the encoding system rather than the drawing processor. Encoding system determines the timing of drawing processor but in the case of a blocking command the token is returned by the drawing system to CPU ref. signal on command completion. In an embodiment command monitor initiates a low power state based on the absence of drawing commands. In an exemplary power saving application the access circuitry of drawing memory associated with a particular frame buffer is temporarily disabled if the frame buffer is not updated over a determined period.

The image drawn to a frame buffer in the same way as a system without the presence of an encoding system. When a drawing API function is called a graphic instruction is issued to graphics device driver that interprets the instruction for the particular hardware implementation of the drawing processor. Some embodiments comprise an additional command monitoring software processing layer between drawing command API and graphics driver . The drawing command monitor issues the command to the drawing processor via the graphics driver and forwards selective duplicate commands to encoding sequencer and display encoder .

Command monitor extracts and forwards essential elements of the drawing commands including sequencer related commands which comprise useful hints based on what part of the image is being drawn and encoder related commands which describe properties of the image used to influence the selection of encoding method. Command monitor may also monitor operating system for system commands and display setup and configuration instructions destined for the display controller. Configuration instructions are forwarded to the remote display controller while synchronization instructions that synchronize image updates with the display refresh rate are sent to the encoding sequencer to enable the appropriate frame buffer to be encoded transmitted decoded and displayed at the remote display .

Frame buffer read and sequence module may also generate synchronization signals for drawing processor such as the vertical retrace and blanking signals by using the ability of read timing control module to synchronize with the timing of the remote display.

In some embodiments process proceeds to step in which encoding sequencer access to the frame buffer is delayed until a frame buffer ready signal is received. In such embodiments the frame buffer is made available for reading only following its released by drawing processor . Alternatively in the case of a host system with a single frame buffer step may be bypassed and encoding sequencer may access the frame buffer asynchronously to rendering functions.

As a next step Copy frame buffer change map the frame buffer change map is copied. As a next step Reset frame buffer change map the frame buffer change map is reset. As a next step Read display sections the sections pixels lines blocks or frames identified in the buffer change map copy are then accessed and assembled with the other information described. As a next step Write to encoder the display sections and other information is forwarded to the display encoder.

System power management module is enabled to reduce the power consumed by elements of encoding system for example by shutting down elements of the multi method encoder based on frame buffer change activity and the selected encoding method. In one embodiment motion estimation circuit is disabled when there is no motion. Examples of useful drawing commands associated with the reduction of power consumption are shown in TABLE 9.

Image decomposition module is enabled to classify the image type as a precursor to the encoding operation. In an embodiment the image is classified into different image types such as background text picture or object layers based on a combination of spatial features detected using multilayer image decomposition method temporal features such as periodic image change rate useful in detection of video image type and drawing commands interpreted by command interpreter . A selective list of drawing commands that identify image types are listed in Table 2. The various masked layers as classified by module are subjected to different encoding methods that may include application of lossless encoders for text background and object image types application of lossy encoders to picture and video image types and context selection and application of different entropy encoders.

In an embodiment various multilayer masks generated by the image decomposition process i.e. process are encoded using a lossless encoding technique supported by encoder and multiplexed with encoded image payloads prior to transmission to remote system . In an embodiment four masks M1 M2 M3 and M4 associated with text background picture and object image types are multiplexed with data comprising encoded 16 16 pixel blocks in a packet stream with a frame header as shown.

Each sequence of mask M1 M4 information fields describes a compressed block area of 16 16 pixels. The compressed image and masks are transmitted to the remote system as a data stream. In alternative embodiments the blocks may comprise other dimensions including larger blocks lines or entire frames.

Generally remote display decoder is enabled to interpret the received data stream and extract the mask information from the mask information fields and decodes the image based on this information to reconstruct the original image frame. Remote display decoder maintains decoder algorithms complementary to the various elements of encoder such as is necessary to decompress the image data using the methods identified by the mask information. Depending on the compression method used the compressed display stream may be decompressed on a per block basis across multiple blocks e.g. LZW JPEG or across frame updates e.g. MPEG . In some embodiments background and picture layers are decompressed and reconstructed before the text and object layers. In the case of the background mask the mask provides the co ordinates for the start and end co ordinates of graphic descriptors or the predictive background decoder. Alternatively the descriptors themselves may define the background co ordinates. In some embodiments the remote display decoder uses the received picture mask to identify the co ordinates and boundaries of the picture areas once they have been decompressed. The object mask identifies the exact location of object pixels in the original image although the mask does not specify the object texture. Objects are decompressed and the pixels are populated over the background of the reconstructed image using the co ordinate positions provided by the mask.

In the case of anti aliased text the text mask defines the boundaries of the text. Texture detail is derived through a lossless decoding method used for the text layer text. In the case of simple fine text the text mask provides an accurate specification of the form and texture of the text. For example in the case of simple single color text accurate text reconstruction is accomplished by populating the locations of the image specified by the text mask with the pixels matching the color specified by the text layer.

Drawing command interpreter interprets drawing commands identified to enhance the image decomposition process. In one embodiment a drawing command identifies a section of the display as a video sequence which allows the decomposition function to classify the defined region as a picture or natural image region independent of the contrast features of the region. If the video sequence displays text it may be desirable to classify the text overlay as either picture or text dependent on other attributes of the video sequence. This enhanced classification is used to optimize the trade off between image quality and network bandwidth limitations.

In another embodiment a video sequence is identified by drawing commands. Drawing command information relating to the video such as blocking information motion vectors and quantization levels are captured and used to select the blocking information motion vectors and quantization levels of the encoding method. If the parameters are well matched the image may be encoded at a quality level and bandwidth comparable to the original video sequence.

In another embodiment drawing commands enhance the decomposition process by identifying font copy commands that indicate the presence of text fill commands are identified to indicate the presence of background and texture related commands are identified to indicate textured regions.

In another embodiment drawing command hints identify the status of changes to image areas so that an encoding method may be selected based at least in part on change status information. In such an embodiment information extracted from a drawing command is passed to section change detection module regarding areas of the inbound image sections from encoding sequencer that have changed and therefore require encoding and transmission. Block change pixel change and motion vector commands all provide status information used to identify status changes.

In another embodiment drawing command hints improve the efficiency of encoding by providing target quality predictions If incorrect predictions are made based on the hints the image is encoded and transmitted using a higher bandwidth than predicted but without sacrificing quality.

In another embodiment the encoding sequence is prioritized to improve the encoding quality based on drawing command hints. As listed in Tables 3 and 8 below OpenGL drawing commands provide quality and performance hints which provides insight into the quality and performance intended by the application and the encoding method may be set accordingly.

In an embodiment encoder method selector selects an appropriate encoding method based on various established criteria. Compression is based on the type of image. Drawing commands may be interpreted to understand attributes of the different sections of the display based on interpreted drawing commands where sections may have regular or arbitrary pixel boundary shapes. The commands may be used to identify areas as background text photographs video etc. Each region may then be encoded using an optimum encoding method.

Compression is also based on network availability as indicated by traffic manager . Traffic manager determines network bandwidth based on availability information from remote traffic manager and feeds this back to encoding system . Drawing command interpreter then determines the most effective encoding process based on the combination of the current encoding process quality requirements how much of the image is changing as indicated by drawing commands and the available network bandwidth as indicated by traffic manager information. For example in an embodiment in which a set portion of available bandwidth is allocated to peripheral data traffic and the remaining available bandwidth is granted to image data traffic the image encoding method is changed when the image data is predicted or measured to exceed its allocated bandwidth.

Based on the desired quality level and the network availability for example as indicated by traffic manager suitable encoding methods are selected. For each image type e.g. picture video text etc. a lookup table may be used either to determine the bandwidth required in bits sec to achieve a given quality or the quality in bits pixel achievable for a unit of image area using a given bandwidth. In cases where bandwidth is limited due to low network availability or frequent screen changes over a large area a higher compression mode may be selected or progressive build sequence may be used. In the case of progressive encoding a relatively low network bandwidth is used to transfer a baseline image or image section of perceptually acceptable quality over a short period of time. Assuming the image or section does not change more detail is added to the original baseline over time using small amounts of network bandwidth until the image reaches a perceptually lossless quality level. Progressive encoding methods are typically applied at different times and different rates to different sections of an image dependent on quality requirements and the nature of section changes. As a result at any given time the different sections of an image will be at different progressive encoding states.

In the case of an actively changing image knowledge of the area of the image that must be updated and an indication of the type of image provides significant information on how much data will be generated when the changing image is encoded. This information may be used in context with information from the traffic manager to modify the encoder method selection. As one example a low bandwidth encoding method such as lossy encoding may be applied to the changing image in the case of low network availability. As a second example a higher bandwidth encoding method may be applied to the changing image in the case of high network availability.

In an architecture that shares processing resources between drawing and compression functions for example a CPU architecture with a single graphic processing unit or drawing processor used for both compression and drawing functions the processing resource is actively balanced between updating the image e.g. rendering activities and updating the remote display e.g. compression activities . The processing load is balanced in such a way as to equalize all processing based and transmission based bottlenecks at a minimum level across the data path.

One example is the case where the frame buffer update rate is higher than the frame transfer rate. In this case the frame buffer update rate may be decreased to balance the compression transfer rate. If the same resources are used lowering the frame buffer update rate may have the desirable effect of increasing the frame transfer rate. A second example is the case where the frame buffer update rate is lower than the frame transfer rate. In this case the transfer rate may be lowered to balance the frame buffer update rate. Similarly if the same resources are used lowering the transfer rate may increase the frame update rate with an overall effect of improving the new frame rate.

In such an embodiment drawing processor is connected to chipset by a high capacity bus such as a PCI Express bus an AGP bus or alternative interconnect suited to graphic data transfer. In alternative embodiments drawing processor may be integrated with chipset or CPU . Drawing processor uses image bus to write rendered images into drawing memory . As encoding sequencer also accesses drawing memory access between the competing resources is arbitrated by drawing memory arbiter .

The arbitration sub system generally grants encoding system memory access according to strict encoding timing requirements while simultaneously accommodating the variable requirements of drawing processor . In an embodiment arbitration between the two resources is achieved by granting drawing processor a fixed priority and granting encoding system a low priority. Encoding system monitors the actual encoding rate in comparison with the desired encoding rate as determined by the frame update rate. If the encoding system exceeds a time lag threshold it signals drawing memory arbiter to change its priority. In another embodiment drawing memory arbiter increases memory burst sizes when encoding system is granted higher priority. Once encoding system exceeds a lead time threshold it is once again granted a low priority and burst size is reduced. As a result encoding system maintains a desirable memory access priority without impeding drawing processor .

Drawing processor comprises control bus with timing signals such as synchronization and control signal and frame buffer ready signal previously described connected to encoding sequencer . It also carries drawing commands and display controller instructions captured by command monitoring method destined for command monitor . As previously described these commands typically originate from CPU . Drawing processor receives the commands across data bus and forwards them to command monitor . In an alternative embodiment drawing commands are stored in drawing memory and are directly accessible by command monitor .

Any of several methods may be deployed to lower the memory bandwidth requirements between encoding system and drawing memory . One method deploys frame buffer change map to ensure fewer memory read operations. Frame buffer change map indicates which memory areas have been updated so that memory areas that have not changed need not be re read. Another method deploys command monitor to interpret drawing commands which provides an indication of the type of image in a given area and how it is changing. Frame buffer read and sequence module may then limit memory access based on status information. As one example a rapid changing video sequence may be read at a reduced frame rate. Another method for reducing memory bandwidth takes advantage of drawing processor cache memory . While the embodiment of generally reads image sections from drawing memory this may not be ideal once image sections have been updated. For example in applications such as video sequences that occupy a large display area the rendering function demands a high proportion of the available bandwidth of image bus . In such applications it may be desirable to reduce the competing bandwidth requirements of encoding system . One method achieves bandwidth reduction by providing encoding system with access to drawing processor cache memory . In such an embodiment image sections are encoded directly from drawing processor cache memory rather than external drawing memory which reduces maximum bandwidth requirements of memory interface .

Command monitor uses control bus to write the description of identified image regions previously described to the register file of frame buffer read sequencer . On read request command from read timing control frame buffer read sequencer accesses frame buffer change table from bus to determine which sections of the image have changed. Frame buffer read sequencer reads the relevant sections of drawing memory on using image bus and resets frame buffer change map using reset signal . In an embodiment where multiple displays are supported only the bitmap relating to the current display need be reset. Image data is read directly into display encoder across image bus .

Read timing control implements a state sequencer to generate timing control signal for drawing processor and read timing signal . Timing requirements are derived from remote decoder timing requests written across control bus to the register file of read timing control ref. in as well as frame buffer ready signal in the case of an embodiment with multiple frame buffers.

In various embodiments supported by process the image is processed by fill detection filter which identifies regions of identical color as background regions i.e. fill regions . In one such embodiment fill detection filter identifies contiguous pixels of constant color exceeding a threshold e.g. a threshold number of pixels which are designated as background pixels in a binary mask associated with the image. Background pixels are suited to lossless encoding by constant color lossless encoder . Fill detection filter also detects additional text pixels which include additional pixels within a threshold distance of the identified contiguous pixels of constant color separated by a selection of text candidate pixels. Additional text pixels also include text candidate pixels surrounded by background pixels and non background pixels. Select pixels not identified as background but within a threshold distance of one of these additional text pixels are also added to the additional text pixels . In an embodiment pixels identified as neither text nor background are designated as picture type pixels in a binary mask. Picture type pixels are suited to lossy encoding by lossy discrete transform encoder also referred to as lossy encoder .

Discrete color lossless encoder comprises an encoder circuit such as a masked color cache encoder or a masked dictionary encoder enabled to encode text pixel areas of the image designated by the text mask. Constant color lossless encoder comprises an encoder circuit such as a lossless run length encoder or a predictive encoder enabled to encode background or fill pixel areas of the image designated by the background mask. In some embodiments constant color lossless encoder identifies select pixels previously identified as text pixels as don t care pixels which are encoded as background pixels for encoding efficiency purposes. Lossy encoder comprises an encoder such as a DCT or wavelet encoder enabled to encode picture type pixel areas of the image designated by the picture mask i.e. lossy encoder may comprise a masked discrete wavelet transform encoder or a masked discrete cosine transform encoder in different embodiments . Mask encoder is enabled to encode positional information of the identified text pixels background pixels and picture type pixels . In an embodiment mask encoder is an entropy encoder such as a predictive encoder or a context adaptive binary arithmetic encoder CABAC enabled to encode each of the binary mask layers.

The encoded lossy and lossless data sets in addition to encoded masks from mask encoder are multiplexed on encoded image bus and forwarded to traffic manager .

While the set of coupled elements illustrates the logical data path for text background and picture pixel types a physical embodiment of image decomposition circuit coupled to multi method encoder generally comprises a shared memory region not shown in that stores a set of masks or a multi layer mask and associated image pixels. The various processing modules or circuits i.e. masked encoders evaluate relevant mask layers to determine which sections of the image should be accessed and processed. For example discrete color lossless encoder evaluates i.e. scans the text mask to identify regions of the image suitable for text encoding prior to retrieving text image sections for lossless encoding constant color lossless encoder evaluates the background mask prior to retrieving background image sections for lossless encoding and lossy encoder evaluates a picture mask prior to retrieving candidate picture image sections for lossy encoding.

In some embodiments multi method encoder also uses drawing command hints and or decomposition hints generated from copy fill and BitBlt commands received from CPU by command monitor to improve encoding. As one example select pixels identified by the fill command are designated as background pixels. As another example select pixels defined by a BitBlt command define the boundaries for a consistent pixel type e.g. the boundary of a background pixel type ending part way into a 16 16 pixel block. By concatenating adjacent pixel boundaries as defined by contiguous BitBlt operations larger areas of an identified pixel type may be established. As one example a larger section of picture type may be identified by contiguous BitBlt operations. As another example a section of background pixels combined with a section of text pixels may be identified by a series of contiguous BitBlt operations. A periodically timed BitBlt operation over a region may be an indication of video image type. In some embodiments pixel type is determined by weighting decomposition hints for a region against the results of the pixel filters for the region e.g. weighted against the number of positive contrast filter hits for a region of candidate text pixels to determine if the region should be designated as text or picture type . The boundary specified for commands such as copy commands can be used to prevent small areas of low gradient images e.g. pale blue sky from being detected as background which is best encoded using a lossy transform encoder rather than a constant color lossless encoder to maximize compression efficiency and prevent the generation of image artifacts.

In some embodiments other information related to a source image including alpha blending information mouse movement screensaver activity or image composition information obtained from a desktop manager e.g. Microsoft Windows Desktop Window Manager WDM provides decomposition or encoding hints. As one example a pattern of alpha blending for a group of pixels is generally indicative that an image region is of an object type and should be encoded at text pixels. As another example a moving mouse or copy command provides hints for motion estimation circuitry. As another example an active screen saver generally indicates that an image may be encoded at reduced quality to preserve network bandwidth. A desktop manager provides application level information to the encoder. For example a Computer Aided Design CAD application window generally demands high quality encoding whereas a video window generally tolerates reduced quality encoding without reduced user experience.

In an embodiment encoding method selector sets encoding parameters for the filters and encoders shown by writing to control registers of the circuits across control bus .

Method proceeds to step Analyze image in which image decomposition circuit analyzes the image based on the decomposition hints to identify pixel types such as picture pixels background pixels and text pixels suited for processing by different masked encoders. In various embodiments step is conducted in conjunction with process such that pixels not identified by drawing commands or decomposition hints are identified as picture pixels background pixels or text pixels by application of a set of pixel filters in decomposition circuit e.g. text detection filter and fill detection filter . In an embodiment the decomposition hints are weighted with results of the set of pixel filters to generate a final determination of whether pixels should be assigned to picture pixel background pixel or text pixel layers.

Method proceeds to step Encode image in which the image is encoded based on identified pixel type. In an embodiment multi method encoder circuit comprises encoders and for encoding of text pixels background pixels and picture pixels respectively. The image mask which identifies positional information of the text pixels background pixels and picture pixels is encoded by mask encoder . Method ends at step End .

The tables below illustrate examples of drawing commands from various APIs that may be used by the display encoder to optimize image compression and transfer.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

