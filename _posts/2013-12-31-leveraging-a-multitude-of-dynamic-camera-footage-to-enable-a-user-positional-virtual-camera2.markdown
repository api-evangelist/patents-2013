---

title: Leveraging a multitude of dynamic camera footage to enable a user positional virtual camera
abstract: A virtual camera within a volumetric model of a real world environment during an event occurring within the real world environment can be identified. The virtual camera can be associated with at least one of a location and an orientation within the real world environment. A virtual stream for the virtual camera can be constructed. The field of view of the stream can include video obtained from two cameras present within the real world environment and video not captured by a camera within the real world environment. The video field point of view can correspond to at least one of the location and orientation of the virtual camera. The virtual stream of the virtual camera can be presented within an interface of computing device responsive to the constructing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09576394&OS=09576394&RS=09576394
owner: 360 LAB LLC.
number: 09576394
owner_city: Miami
owner_country: US
publication_date: 20131231
---
This application claims priority to provisional application No. 61 853 711 entitled System and Method for Stitching Videos Received from Multiple Unsynchronized Cameras filed Apr. 10 2013 as well as provisional application No. 61 854 397 entitled 360 Degrees Cameras filed Apr. 23 2013. Both provisional applications are hereby included in their entirety.

The present invention relates to the field of video processing and more particularly to leveraging a multitude of dynamic camera footage to enable a user positional virtual camera.

Auto racing also known as automobile racing car racing or motor car racing is an extremely popular sport with loyal and involved fans. Auto racing includes stock car racing production car racing sports car racing formula racing and the like where vehicles race each other on a fixed moto racing track.

Spectators which include live and broadcast spectators of auto racing often desire to be immersed in the experience. The more immersive and interactive the experience the more enthusiasm is generated for the sport. In a number of instances spectators are willing to pay for premium access to race details. While a number of premium access mechanisms exist these do not satisfy fans desires for an immersive and interactive experience.

For example NASCAR mobile applications exist for APPLE and ANDROID devices which offer news video social and race information. An in app subscription to this mobile application allows users to receive enhanced live content which includes driver audio a 3D race virtualization track positions and live driver telemetry GPS positioning information . In car audio is also provided for some races.

NASCAR also offers a product called RACE BUDDY which includes an ability to see live camera feeds a pit road camera a chat and a leaderboard. Generally speaking the live cameras are time delayed sometimes over a minute from each other. The cameras are the set of cameras that broadcasters select from for race coverage. Effectively the above apps and other known enhancements are aggregating Web portals that group information for user viewing. None of the known mechanisms grant end users an ability to control race specifics such as viewing details seen from race driver perspectives. Thus existing products are effectively a set of pushed facts covered over an Internet Protocol IP network about a race as opposed to an interactive and immersive experience that gives end users a level of control on how a race is to be experienced.

One aspect of the present invention can include a system an apparatus a computer program product and a method for leveraging a multitude of dynamic camera footage to enable a user positional virtual camera. A virtual camera within a volumetric model of a real world environment during an event occurring within the real world environment can be identified. The virtual camera can be associated with at least one of a location and an orientation within the real world environment. A virtual stream for the virtual camera can be constructed. The field of view of the stream can include video obtained from two cameras present within the real world environment and video not captured by a camera within the real world environment. The video field point of view can correspond to at least one of the location and orientation of the virtual camera. The virtual stream of the virtual camera can be presented within an interface of computing device responsive to the constructing.

Another aspect of the present invention can include an apparatus a computer program product a method and a system for leveraging a multitude of dynamic camera footage to enable a user positional virtual camera. A virtual camera engine can be configured to present a virtual video stream associated with a virtual camera. The virtual camera can be mapped to a location and or an orientation of a volumetric model of a real world environment. The video stream can be synchronized to a timeline of an event occurring within the real world environment. A data store can be able to persist the model the video stream and or the virtual camera metadata. The metadata can be a field of view a focal length and or an aperture.

The present disclosure is a solution for leveraging a multitude of dynamic camera footage to enable a user positional virtual camera. In the solution one or more cameras within a physical environment can capture video feeds of a real world event. The video feeds can be aggregated and analyzed to produce a volumetric model. The model can enable a virtual camera to be specified and a real time virtual video stream for the virtual camera to be viewed. In one instance the stream can be presented during the event upon a companion computing device. In the instance the virtual camera can be dynamically adjusted and the corresponding video stream can be generated and presented.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions.

These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

In scenario one or more video feeds obtained from an event can be leveraged to enable a custom view from any location within environment . The location can permit a virtual camera to be placed at a user specified location. Feeds can be captured by one or more cameras and can be conveyed to a broadcast system . When a virtual camera is specified system can convey a virtual video stream to a companion device . When no virtual camera is specified the system can convey one or more feeds . Application executing on device can present feed or stream within one or more interfaces e.g. interface .

Feeds can be captured during event for the duration of event . Event can occur within a real world environment such as physical environment . For example event can be an automotive racing event taking place at a racing track arena . In one instance feeds can be obtained from a broadcast camera and or omni directional camera affixed to vehicle . In the instance camera can be a fixed and or movable camera. For example broadcast camera can be a stationary camera which can capture video of vehicle traveling around track . In one embodiment additional cameras can be leveraged to produce a virtual video stream . In the embodiment user operated cameras e.g. spectator cameras can be utilized to obtain feed which can enable a virtual video stream .

In scenario interface can permit viewing feeds and or stream via interface element selection . Interface can include a graphics pane which can present one or more feeds . For example when a Camera A e.g. broadcast camera is selected via interface element e.g. interface button a video feed from Camera A e.g. broadcast camera can be presented within pane . In one instance interface can include an interface element which can permit the specification of a virtual camera . In the instance upon selection interface can be presented.

In interface a map of track can be presented within graphics pane . Map can permit a virtual camera to be positioned and or oriented based on a user input. In one instance map can be a pictoral map representing track . In another instance map can be a global positioning system GPS based map allowing a virtual camera to be placed via a mouse cursor within a geographical region of track . In one embodiment map can be a three dimensional map two dimensional map and the like.

In interface stream of virtual camera can be generated from existing video feed of one or more cameras . That is virtual video stream can be dynamically generated in real time from subsequent real time feeds. In one instance stream can be concurrently presented within interface during event . In another instance stream can be simultaneously presented with one or more feeds . It should be appreciated that camera can facilitate views which can be impossible to capture using cameras . For example a virtual camera can be placed in the middle of a racing track permitting cars to appear to travel through the camera.

Virtual camera can include one or more characteristics which can shape the stream characteristics. Characteristics can include but is not limited to field of view focal length aperture and the like. Stream characteristics can include but is not limited to frame rate video quality aspect ratio video compression stereoscopic channels and the like.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that camera can be 360 degree cameras able to capture a greater than three hundred and sixty degree view of track and or arena .

It should be appreciated that video feed can include continuous oblique video aerial video and the like. In one instance the video can be continuously aligned to a three dimensional point cloud. In the instance the point cloud can be utilized to compute two dimensional perspective video and or three dimensional perspective video associated with a virtual camera position and or orientation. In one embodiment a modeling through registration approach e.g. photogrammetric modeling and model based stereo computation can be utilized to fuse photometric data with video. In the embodiment the approach can enable a real time virtual video feed from a virtual camera can be constructed from the model.

It should be appreciated that feed can include video frames of real world video and can lack computer graphics. That is feed can lack graphically rendered frames. In one embodiment feed can include interpolated frames generated from feeds . In one instance a video baseline of a physical environment can be utilized to interpolate frames when feeds lack sufficient data.

It should be appreciated that feeds from cameras can be subject to video processing to eliminate and or reduce motion blur e.g. jitter noise low light and the like.

In step a video playback session can be established. The playback session can be manually and or automatically established. In step one or more cameras within a real world environment can be identified. The cameras can be identified via traditional and or proprietary mechanisms. In step one or more video feeds from the cameras can be aggregated. Video aggregation can be performed in real time or near real time. In step a volumetric model can be established from the aggregated feeds. The volumetric model can include additional video feeds including but not limited to real time photography previously recorded video baselines and the like. In step a virtual camera can be specified. The virtual camera can be specified based on user preferences historic settings and the like. In step a view origin point associated with the virtual camera can be identified within the model. The origin point can be identified utilizing traditional camera pose estimation user input and the like. In step the virtual camera characteristics can be established. Characteristics can be manually and or automatically established. In step a virtual stream for the virtual camera can be constructed utilizing established characteristics. In step the virtual stream can be presented within an interface. In one embodiment the virtual stream can be associated with an authorization mechanism permitting the virtual stream to be conveyed to authorized devices. In step if the session is terminated the method can continue to step else return to step . In step the method can end.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that method can be performed in real time or near real time. Further method can be performed in serial and or in parallel. Steps can be performed for each virtual specified during the session.

Media server can be a hardware software entity for executing virtual camera engine . Server functionality can include but is not limited to camera registration device registration communication management file sharing encryption and the like. Server include but is not limited to virtual camera engine virtual camera volumetric model data store and the like. In one embodiment server can be a component of a television broadcasting system.

Virtual camera engine can be a hardware software element for leveraging video feed into a virtual stream associated with a virtual camera . Engine functionality can include but is not limited to volumetric model creation synchronization e.g. to event stream synchronization and the like. In one embodiment engine can be a distributed computing engine networked computing engine and the like. In another embodiment engine can be a functionality of a companion application able to present additional content of an event.

Feed analyzer can be a hardware software entity for processing feed from one or more cameras . Analyzer functionality can include but is not limited to feature registration camera pose estimation photometric extraction photogrammetry and the like. In one instance analyzer can determine feed format feed characteristics and the like.

Virtual camera manager can be a hardware software element for handling virtual camera . Manager functionality can include but is not limited to camera positioning view determination and the like. In one embodiment manager can be a functionality of a client side application permitting the configuration of a virtual camera . In the embodiment virtual camera configuration can include but is not limited to location orientation field of view focal length aperture and the like. It should be appreciated that virtual camera configuration can be automatically determined utilizing historic settings and or user preferences.

Stream generator can be a hardware software entity for constructing a real time virtual stream . Generator functionality can include but is not limited to frame generation frame synchronization audio synchronization and the like. In one embodiment a virtual camera mapping can be utilized to associate a stream with a virtual camera and a computing device. It should be appreciated that mapping can be automatically generated by generator .

Settings can be one or more rules for establishing the behavior of system server and or engine . Settings can include but is not limited to feed analyzer options virtual camera manager settings stream generator options and the like. In one instance settings can be manually and or automatically established. In the embodiment settings can be heuristically established based on historic settings. Settings can be persisted within data store computing device and the like.

Virtual camera can be a digital representation of a real world camera lacking video feed. Camera can include a view which can conform to traditional view parameters such as field of view perspective and the like. Camera can be associated with a stream which can be presented within view . In one instance view parameters can be utilized to tailor stream . For example the aspect ratio of view can be used to create a stream with a corresponding aspect ratio. It should be appreciated that camera can be associated traditional camera functionality including but not limited to pan zoom change focus fade and the like.

Volumetric model can be a digital representation of a physical environment e.g. environment . In one instance model can be generated from video feed . In one embodiment model can be a point cloud data set which can correspond to one or more time indicies associated with an event. In one configuration of the embodiment model can be a sparse point cloud which can be populated over the duration of an event. In one instance a camera can be associated with a point of the point cloud within the model . In the instance point cloud channel data can persist camera parameters e.g. view parameters stream parameters and the like.

Data store can be a hardware software component able to persist camera settings mapping model and the like. Data store can be a Storage Area Network SAN Network Attached Storage NAS and the like. Data store can conform to a relational database management system RDBMS object oriented database management system OODBMS and the like. Data store can be communicatively linked to server in one or more traditional and or proprietary mechanisms. In one instance data store can be a component of Structured Query Language SQL complaint database.

Virtual camera mapping can be one or more data sets for organizing virtual camera and stream associations. Mapping can include but is not limited to a virtual camera identifier a stream identifier a device identifier a timestamp authentication data and the like. For example in entry a virtual camera V Camera A can be associated with a virtual stream Stream A which can be conveyed to a device Device A. It should be appreciated that mapping can be manually and or automatically maintained.

Camera can be a video camera able to record video feed of an event. Camera can include but is not limited to an omni directional video camera professional video cameras camcorders webcams mobile phone cameras and the like. Camera can capture and convey feed to engine and or device . In one instance camera can include a camera array in which each camera records a portion of a video frame.

Computing device can be a software hardware element for collecting presenting video feed and or view . Device can include but is not limited to input components e.g. keyboard camera output components e.g. display interface and the like. In one instance interface can be a Web based interface e.g. rich internet application media player . Device hardware can include but is not limited to a processor a non volatile memory a volatile memory a bus and the like. Computing device can include but is not limited to a desktop computer a laptop computer a mobile phone a mobile computing device a portable media player a Personal Digital Assistant PDA and the like.

Network can be an electrical and or computer network connecting one or more system components. Network can include but is not limited to twisted pair cabling optical fiber coaxial cable and the like. Network can include any combination of wired and or wireless components. Network topologies can include but is not limited to bus star mesh and the like. Network types can include but is not limited to Local Area Network LAN Wide Area Network WAN Virtual Private Network VPN and the like.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be appreciated that one or more components within system can be optional components permitting that the disclosure functionality be retained. It should be understood that engine components can be optional components providing that engine functionality is maintained. It should be appreciated that one or more components of engine can be combined and or separated based on functionality usage and the like. System can conform to a Service Oriented Architecture SOA Representational State Transfer REST architecture and the like.

In embodiment a volumetric model having a time synchronized point channel data can be utilized to enable the functionality described herein. The volumetric model can include one or more points . In the embodiment the model can be synchronized to an event timeline . In one configuration of the embodiment each point within the volumetric model can include channel data for multiple time indicies of timeline . The synchronization data can be manually and or automatically obtained. In one instance data can be extracted from timing data associated with a video feed e.g. broadcast feed .

It should be appreciated that event can include one or more timelines . It should be understood that embodiment is one contemplated configuration for enabling the functionality described herein. Other configurations are contemplated.

The flowchart and block diagrams in the illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

