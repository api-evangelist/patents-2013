---

title: Fractional reserve high availability using cloud command interception
abstract: An approach is provided to provide a high availability (HA) cloud environment. In the approach, an active cloud environment is established in one cloud computing environment using a primary set of resources and a passive cloud environment is established in another cloud computing environment, with the passive cloud environment using fewer resources than are used by the active cloud environment. A workload is serviced by the active cloud environment. While servicing the workload, cloud commands are processed that alter the primary set of resources and the commands are stored in a queue. When a failure of the active cloud environment occurs, the workload is serviced by the passive cloud environment in the second cloud computing environment and the cloud commands stored in the queue are used to alter the resources used by the passive cloud environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495238&OS=09495238&RS=09495238
owner: International Business Machines Corporation
number: 09495238
owner_city: Armonk
owner_country: US
publication_date: 20131213
---
Cloud computing relates to concepts that utilize large numbers of computers connected through a computer network such as the Internet. Cloud based computing refers to network based services. These services appear to be provided by server hardware. However the services are instead served by virtual hardware virtual machines or VMs that are simulated by software running on one or more real computer systems. Because virtual servers do not physically exist they can therefore be moved around and scaled up or out on the fly without affecting the end user. Scaling up or down refers to the addition or reduction of resources CPU memory etc. to the VM performing the work. Scaling out or in refers to adding or subtracting the number of VMs assigned to perform a particular workload.

In a traditional environment when a site fails applications running on that site will also fail. Traditional application High Availability HA setups require exact replica of the primary environments. In other words an Active cloud environment would handle the workload while an exact replica a Passive cloud environment stands by waiting to take over if the Active cloud environment fails. When not being used the Passive cloud environment consumes considerable resources the same amount of resources as the Active cloud environment thus reducing the resources available to other applications actively running in the Passive cloud environment.

An approach is provided to provide a high availability HA cloud environment. In the approach an active cloud environment is established in one cloud computing environment using a primary set of resources and a passive cloud environment is established in another cloud computing environment with the passive cloud environment using fewer resources than are used by the active cloud environment. A workload is serviced by the active cloud environment. While servicing the workload cloud commands are processed that alter the primary set of resources and the commands are stored in a queue. When a failure of the active cloud environment occurs the workload is serviced by the passive cloud environment in the second cloud computing environment and the cloud commands stored in the queue are used to alter the resources used by the passive cloud environment.

The foregoing is a summary and thus contains by necessity simplifications generalizations and omissions of detail consequently those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting. Other aspects inventive features and advantages of the present invention as defined solely by the claims will become apparent in the non limiting detailed description set forth below.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer server or cluster of servers. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The following detailed description will generally follow the summary of the invention as set forth above further explaining and expanding the definitions of the various aspects and embodiments of the invention as necessary. To this end this detailed description first sets forth a computing environment in that is suitable to implement the software and or hardware techniques associated with the invention. A networked environment is illustrated in as an extension of the basic computing environment to emphasize that modern computing techniques can be performed across multiple discrete devices.

Northbridge and Southbridge connect to each other using bus . In one embodiment the bus is a Direct Media Interface DMI bus that transfers data at high speeds in each direction between Northbridge and Southbridge . In another embodiment a Peripheral Component Interconnect PCI bus connects the Northbridge and the Southbridge. Southbridge also known as the I O Controller Hub ICH is a chip that generally implements capabilities that operate at slower speeds than the capabilities provided by the Northbridge. Southbridge typically provides various busses used to connect various components. These busses include for example PCI and PCI Express busses an ISA bus a System Management Bus SMBus or SMB and or a Low Pin Count LPC bus. The LPC bus often connects low bandwidth devices such as boot ROM and legacy I O devices using a super I O chip . The legacy I O devices can include for example serial and parallel ports keyboard mouse and or a floppy disk controller. The LPC bus also connects Southbridge to Trusted Platform Module TPM . Other components often included in Southbridge include a Direct Memory Access DMA controller a Programmable Interrupt Controller PIC and a storage device controller which connects Southbridge to nonvolatile storage device such as a hard disk drive using bus .

ExpressCard is a slot that connects hot pluggable devices to the information handling system. ExpressCard supports both PCI Express and USB connectivity as it connects to Southbridge using both the Universal Serial Bus USB the PCI Express bus. Southbridge includes USB Controller that provides USB connectivity to devices that connect to the USB. These devices include webcam camera infrared IR receiver keyboard and trackpad and Bluetooth device which provides for wireless personal area networks PANs . USB Controller also provides USB connectivity to other miscellaneous USB connected devices such as a mouse removable nonvolatile storage device modems network cards ISDN connectors fax printers USB hubs and many other types of USB connected devices. While removable nonvolatile storage device is shown as a USB connected device removable nonvolatile storage device could be connected using a different interface such as a Firewire interface etcetera.

Wireless Local Area Network LAN device connects to Southbridge via the PCI or PCI Express bus . LAN device typically implements one of the IEEE 0.802.11 standards of over the air modulation techniques that all use the same protocol to wireless communicate between information handling system and another computer system or device. Optical storage device connects to Southbridge using Serial ATA SATA bus . Serial ATA adapters and devices communicate over a high speed serial link. The Serial ATA bus also connects Southbridge to other forms of storage devices such as hard disk drives. Audio circuitry such as a sound card connects to Southbridge via bus . Audio circuitry also provides functionality such as audio line in and optical digital audio in port optical digital output and headphone jack internal speakers and internal microphone . Ethernet controller connects to Southbridge using a bus such as the PCI or PCI Express bus. Ethernet controller connects information handling system to a computer network such as a Local Area Network LAN the Internet and other public and private computer networks.

While shows one information handling system an information handling system may take many forms. For example an information handling system may take the form of a desktop server portable laptop notebook or other form factor computer or data processing system. In addition an information handling system may take other form factors such as a personal digital assistant PDA a gaming device ATM machine a portable telephone device a communication device or other devices that include a processor and memory.

The Trusted Platform Module TPM shown in and described herein to provide security functions is but one example of a hardware security module HSM . Therefore the TPM described and claimed herein includes any type of HSM including but not limited to hardware security devices that conform to the Trusted Computing Groups TCG standard and entitled Trusted Platform Module TPM Specification Version 1.2. The TPM is a hardware security subsystem that may be incorporated into any number of information handling systems such as those outlined in .

The cloud computing environment includes each of cloud groups and and provides computing resources to the deployed workloads. The set of computing resources include resources such as CPU and memory assigned to the various compute nodes nodes and are shown running in Cloud Group nodes and are shown running in Cloud Group and nodes and are shown running in Cloud Group . Resources also include IP addresses. IP addresses for Cloud Group are shown as IP Group with ten IP addresses IP addresses for Cloud Group are shown as IP Group with fifty IP addresses and IP addresses for Cloud Group are shown as IP Groups and each with fifty IP addresses per group. Each Cloud Group has a Cloud Group Profile CG Profile being the profile for Cloud Group CG Profile being the profile for Cloud Group and CG Profile being the profile for Cloud Group . The computing resources made available by the cloud computing environment are allocated amongst the cloud groups based on the sets of computing resources assigned to the workloads running in each of the cloud groups. The cloud computing environment also provides Network Backplane that provides network connectivity to the various Cloud Groups. Links are provided so that Cloud Groups with more links assigned have greater network bandwidth. In the example shown the Human Resources Cloud Group has one network link . However Finance Cloud Group has two full network links assigned links an as well as a partial link which is shared with Social Connections Cloud Group . Social Connections Cloud Group shares link with the Finance Cloud Group and also has been assigned three more network links and .

In the following example shown in the Finance application running in Cloud Group required increase security and priority in the following month since its the month where employee s receive bonuses. The application therefore requires it be more highly available and have higher security. These updated requirements come in the form of a modified Cloud Group Profile . Processing of the updated Cloud Group Profile determines that the current configuration shown in does not support these requirements and therefore needs to be reconfigured.

As shown in a free compute node compute node is pulled into the Cloud Group from Cloud Group to increase the application s availability. The updated security requirements restrict access on the firewall and increases the security encryption. As shown in the network connections are reconfigured to be physically isolated further improve security. Specifically notice how network link is no longer shared with the Social Connections Cloud Group. In addition due to the increased network demands now found for the Finance Cloud Group one of the network links link formerly assigned to the Social Connections Group is now assigned to the Finance Group. After the reassignment of resources the Cloud Group Profile is correctly configured and the Finance application s requirements are met. Note that in the Social Connections applications were running with High security and High priority the Internal HR applications were running with Low security and Low Priority and the Internal Finance applications were running with Medium security and Medium priority. After the reconfiguration due to the changes to the Finance Profile the Social Connections applications are still running with Medium security and Medium priority but the Internal HR applications are running with High security and High Priority and the Internal Finance applications are also running with High security and High priority

At step the process adds or deletes the application profile that corresponds to the application that is entering or leaving to from cloud group application profiles that are stored in data store . Cloud group application profiles stored in data store include the application by cloud group currently running in the cloud computing environment. At predefined process the process reconfigures the cloud group after the cloud group profile has been adjusted by step see and corresponding text for processing details . At step processing waits for the next reconfiguration trigger to occur at which point processing loops back to step to handle the next reconfiguration trigger.

Returning to decision if the reconfiguration trigger was not due to an application entering or leaving the cloud group then decision branches to the no branch for further processing. At step the process selects the first application currently running in the cloud group. At step the process checks for changed requirements that pertain to the selected application by checking the selected application s profile. The changed requirements may effect areas such as the configuration of a firewall setting defined load balancers policies an update to an application server cluster and application configuration an exchange and update of security tokens network configurations that need updating configuration items that need to be added updated in Configuration Management Database CMDB and the setting of system and application monitoring thresholds. A decision is made by the process as to whether changed requirements pertaining to the selected application were identified in step decision . If changed requirements were identified that pertain to the selected application then decision branches to the yes branch whereupon predefined process executes to reconfigure the cloud group see and corresponding text for processing details . On the other hand if no changed requirements were identified that pertain to the selected application then processing branches to the no branch. A decision is made by the process as to whether there are additional applications in the cloud group to check decision . If there are additional applications to check then decision branches to the yes branch which loops back to select and process the next application in the cloud group as described above. This looping continues until either an application with changes requirements is identified with decision branching to the yes branch or until there are no more applications to select in the cloud group with decision branching to the no branch . If there are no more applications to select in the cloud group then decision branches to the no branch whereupon at step processing waits for the next reconfiguration trigger to occur at which point processing loops back to step to handle the next reconfiguration trigger.

At step the process selects the first highest priority tenant from the list of prioritized tenants stored in memory area . The workloads corresponding to the selected tenant are retrieved from the current cloud environment which is stored in memory area . At step the process selects the first workload that is deployed for the selected tenant. At step the process determines or calculates a priority for the selected workload. The workload priority is based on the priority of the tenant as set in the tenant SLA as well as the application profile that is retrieved from data store . A given tenant can assign different priorities to different applications based on the needs of the application and the importance of the application to the tenant. provided an example of different priorities being assigned to different applications running in a given enterprise. The workload priorities are then stored in memory area . At step the process identifies the workload s current demand and also calculates the workload s weighted priority based on the tenant priority the workload priority and the current or expected demand for the workload. The weighted priorities for the workloads are stored in memory area . A decision is made by the process as to whether there are more workloads for the selected tenant that need to be processed decision . If there are more workloads for the selected tenant to process then decision branches to the yes branch which loops back to step to select and process the next workload as described above. This looping continues until there are no more workloads for the tenant to process at which point decision branches to the no branch.

A decision is made by the process as to whether there are more tenants to process decision . If there are more tenants to process then decision branches to the yes branch which loops back to select the next tenant in terms of priority and process the workloads for the newly selected tenant as described above. This looping continues until all of the workloads for all of the tenants have been processed at which point decision branches to the no branch for further processing.

At step the process sorts the workloads based on the weighted priorities found in memory area . The workloads ordered by their respective weighted priorities are stored in memory area . At predefined process the process sets workload resources for each of the workloads included in memory area see and corresponding text for processing details . Predefined process stores the allocated workload resources in memory area . At predefined process the process optimizes the cloud groups based upon the allocated workload resources stored in memory area see and corresponding text for processing details . The process then returns to the calling routine see at .

At step the process computes the resources required by the selected workload based on the workload s demand and the workload s priority. The resources needed to run the workload given the workload s demand and priority are stored in memory area .

At step the process retrieve the resources allocated to the workload such as the number of VMs the IP addresses needed the network bandwidth etc. and compares the workload s current resource allocation to the workload s computed resources required for workload. A decision is made by the process as to whether a change is needed to the workload s resource allocation based on the comparison decision . If a change is needed to the workload s resource allocation then decision branches to the yes branch whereupon at step the process sets a preferred resource allocation for the workload which is stored in memory area . The preferred designation means that if resources are amply available these are the resources that the workload should have allocated. However due to resource constraints in the cloud group the workload may have to settle for an allocation that is less than the preferred workload resource allocation. Returning to decision if the workload has already been allocated the resources needed then decision branches to the no branch bypassing step .

A decision is made by the process as to whether there are more workloads ordered by weighted priority that need to be processed decision . If there are more workloads to process then decision branches to the yes branch which loops back to step to select the next next highest weighted priority workload and set the newly selected workload s resources as described above. This looping continues until all of the workloads have been processed at which point decision branches to the no branch and processing returns to the calling routine see at .

At step the process gathers the preferred workload resources for each workload in selected cloud group and compute the preferred cloud group resources total resources needed by the cloud group to satisfy the preferred workload resources of workload s running in the selected cloud group. The preferred workload resources are retrieved from memory area . The computed preferred cloud group resources needed to satisfy the workload resources of the workloads running in the selected cloud group are stored in memory area .

At step the process selects the first resource type available in the cloud computing environment. At step the selected resource is compared with the current allocation of the resource already allocated to the selected cloud group. The current allocation of resources for the cloud group is retrieved from memory area . A decision is made by the process as to whether more of the selected resource is needed by the selected cloud group to satisfy the workload resources of the workloads running in the selected cloud group decision . If more of the selected resource is needed by the selected cloud group then decision branches to the yes branch whereupon at predefined process the process adds resources to the selected cloud group see and corresponding text for processing details . On the other hand if more of the selected resource is not needed by the selected cloud group then decision branches to the no branch whereupon a decision is made by the process as to whether an excess of the selected resource is currently allocated to the cloud group decision . If an excess of the selected resource is currently allocated to the cloud group then decision branches to the yes branch whereupon at step the process marks the excess of the allocated resources as being available from the selected cloud group. This marking is made to the list of cloud group resources stored in memory area . On the other hand if an excess of the selected resource is not currently allocated to the selected cloud group then decision branches to the no branch bypassing step .

A decision is made by the process as to whether there are more resource types to analyze decision . If there are more resource types to analyze then decision branches to the yes branch which loops back to step to select and analyze the next resource type as described above. This looping continues until all of the resource types have been processed for the selected cloud group at which point decision branches to the no branch. A decision is made by the process as to whether there are more cloud groups to select and process decision . If there are more cloud groups to select and process then decision branches to the yes branch which loops back to step to select and process the next cloud group as described above. This looping continues until all of the cloud groups have been processed at which point decision branches to the no branch and processing returns to the calling routine see at .

A decision is made by the process as to whether one or more cloud groups were identified that have an excess of the desired resource decision . If one or more cloud groups are identified with an excess of the desired resource then decision branches to the yes branch whereupon at step the process selects the first cloud group with an identified excess of the desired needed resource. A decision is made by the process based on both the selected cloud group s profile and the other cloud group s profile retrieved from memory area as to whether this cloud group is allowed to receive the resource from the selected cloud group decision . For example in a scenario was presented where one cloud group the Finance group had a high security setting due to sensitivity in the work being performed in the Finance group. This sensitivity may have prevented some resources such as a network link from being shared or reallocated from the Finance group to one of the other cloud groups. If the resource can be moved from the selected cloud group to this cloud group then decision branches to the yes branch whereupon at step the resource allocation is moved from the selected cloud group to this cloud group and reflected in the list of cloud resources stored in memory area and in the cloud resources stored in memory area . On the other hand if the resource cannot be moved from the selected cloud group to this cloud group then decision branches to the no branch bypassing step . A decision is made by the process as to whether there are more cloud groups with resources to check decision . If there are more cloud groups to check then decision branches to the yes branch which loops back to step to select and analyze the resources that might be available from the next cloud group. This looping continues until there are no more cloud groups to check or until the resource need has been satisfied at which point decision branches to the no branch.

A decision is made by the process as to whether the cloud group still needs more of the resource after checking for excess resources available from other cloud groups decision . If no more resources are needed then decision branches to the no branch whereupon processing returns to the calling routine see at . On the other hand if more resources are still needed for this cloud group then decision branches to the yes branch for further processing.

At step the process checks with the data center for available resources that are not currently allocated to this cloud computing environment and which are permitted to be allocated to this cloud computing environment based on cloud profiles SLAs etc. The data center resources are retrieved from memory area . A decision is made by the process as to whether data center resources were found that satisfy the resource need of this cloud group decision . If data center resources were found that satisfy the resource need of this cloud group then decision branches to the yes branch whereupon at step the process allocates the identified data center resources to this cloud group. The allocation to this cloud group is reflected in an update to the list of cloud resources stored in memory area . Returning to decision if the data center resources were not found to satisfy this cloud group s resource need then decision branches to the no branch bypassing step . Processing then returns to the calling routine see at .

Box depicts an altered VM VM that has been scaled up by dedicating additional resources such as CPU and memory to the original VM . Box depicts a replicated VM that has been scaled out by adding additional virtual machines to the workload VMs and .

The scaled up environment is tested and the test results are stored in memory area . Likewise the scaled out environment is tested and the test results are stored in memory area . Process is shown comparing the scale up test results and the scale out test results. Process results in one or more workload scaling profiles that are stored in data store . The workload scaling profiles would indicate the preferential scaling technique up out etc. for the workload as well as the configuration settings e.g. allocated resources if scale up number of virtual machines if scale out . In addition a scale diagonal is possible by combining some aspects of the scale up with some aspects of the scale out e.g. increasing the allocated resources as well as dedicating additional virtual machines to the workload etc. .

A decision is made by the process as to whether a workload scaling profile already exists for this workload decision . If a workload scaling profile already exists for this workload then decision branches to the yes branch whereupon at predefined process the process implements the existing scaling profile see and corresponding text for processing details by reading the existing workload scaling profile from data store .

On the other hand if a workload scaling profile does not yet exist for this workload then decision branches to the no branch whereupon at predefined process the process creates a new scaling profile for the workload see and corresponding text for processing details . The new scaling profile is stored in data store .

At step the process adds resources to Workload A s VM. This is reflected in step with Workload A receiving the additional resources.

At step the process adds additional VMs that are used to process Workload B. This is reflected in step with Workload B receiving the additional VMs.

At step the process duplicates the incoming traffic to both Workload A and Workload B. This is reflected in Workload A s step processing the traffic requests using the additional resources allocated to the VM running Workload A. This is also reflected in Workload B s step processing the same traffic using the additional VMs that were added to process Workload B.

At step both Workload A and Workload B direct outbound data responses back to the requestor. However step blocks the outbound data from one of the workloads e.g. Workload B so that the requestor receives only one set of expected outbound data.

At predefined process the process monitors the performance of both Workload A and Workload B see and corresponding text for processing details . Predefined process stores the results of the scale up Workload A in memory area and the results of the scale out Workload B in memory area . A decision is made by the process as to whether enough performance data has been gathered to decide on a scaling strategy for this workload decision . Decision may be driven by time or an amount of traffic that is processed by the workloads. If enough performance data has not yet been gathered to decide on a scaling strategy for this workload then decision branches to the no branch which loops back to predefined process to continue monitoring the performance of Workload A and Workload B and providing further test results that are stored in memory areas and respectively. This looping continues until enough performance data has been gathered to decide on a scaling strategy for this workload at which point decision branches to the yes branch whereupon at step the process creates a workload scaling profile for this workload based on gathered performance data e.g. preference of scale up scale out or scale diagonally and the amount of resources allocated etc. . Processing then returns to the calling routine see at .

At step the process implements the preferred scaling method per the workload scaling profile as well as adding the resources CPU memory etc. when scaling up VMs when scaling out both when scaling diagonally . This implementation is reflected in the workload where at step the additional resources VMs are added to the workload. At step the workload continues to process traffic requests received at the workload with the processing now being performed with the added resources VMs . At predefined process the process monitors the performance of the workload see and corresponding text for processing details . The results of the monitoring are stored in scaling results memory area either scale up results scale out or scale diagonal results .

A decision is made by the process as to whether enough time has been spent monitoring the performance of the workload decision . If enough time has not been spent monitoring the workload then decision branches to the no branch which loops back to predefined process to continue monitoring the workload and continue adding scaling results to memory area . This looping continues until enough time has been spent monitoring the workload at which point decision branches to the yes branch for further processing.

A decision is made by the process as to whether a performance increase reflected in the scaling results stored in memory area are acceptable based on the anticipated performance increase decision . If the performance increase is unacceptable then decision branches to the no branch whereupon a decision is made by the process as to whether to re profile the workload or use a secondary scaling method on the workload decision . If the decision is to re profile the workload then decision branches to the re profile branch whereupon at predefined process the scaling profile is re created for the workload see and corresponding text for processing details and processing returns to the calling routine at .

On the other hand if the decision is to use a secondary scaling method then decision branches to the use secondary branch whereupon at step the process select another scaling method from the workload scaling profiles and reads the anticipated performance increase when using the secondary scaling method. Processing then loops back to step to implement the secondary scaling method. This looping continues with other scaling methods being selected and used until either the performance increase of one of the scaling methods is acceptable with decision branching to the yes branch and processing returning to the calling routine at or when a decision is made to re profile the workload with decision branching to the re profile branch .

At step the process calculates averages peaks and accelerations for each index and stores the calculations in memory area . At step the process track characteristics for bottlenecks and threshold policies by using bottleneck and threshold data from data store in relation to monitor data previously stored in memory area .

A decision is made by the process as to whether any thresholds or bottlenecks are violated decision . If any thresholds or bottlenecks are violated then decision branches to the yes branch whereupon at step the process sends the processed data to analytics engine for processing. On the other hand if thresholds or bottlenecks are not violated then decision branches to the no branch bypassing step .

A decision is made by the process as to whether to continue monitoring the performance of the workload decision . If monitoring should continue then decision branches to the yes branch whereupon at step the process tracks and validates the decision entries in the workload scaling profile that corresponds to the workload. At step the process annotates the decision entries for future optimization of the workload. Processing then loops back to step to collect monitoring data and process the data as described above. This looping continues until the decision is made to discontinue monitoring the performance of the workload at which point decision branches to the no branch and processing returns to the calling routine at .

Analytics engine processing is shown commencing at whereupon at step the analytics engine receives the threshold or bottleneck violation and monitoring data from the monitor. At step the analytics engine creates a new provisioning request based on violation. A decision is made by the analytics engine as to whether a decision entry already exists for the violation decision . If the decision entry already exists then decision branches to the yes branch whereupon at step the analytics engine updates the profile entry based on the threshold or bottleneck violation and the monitoring data. On the other hand if the decision entry does not yet exist then decision branches to the no branch whereupon at step the analytics engine creates a ranking for each characteristic for the given bottleneck threshold violation and creates a profile entry in the workload scaling profile for the workload.

As shown Active Cloud Environment is provided with resources virtual machines VMs computing resources etc. needed to handle the current level of traffic or load experienced by the workload. Conversely Passive Cloud Environment is provided with fewer resources than the Active Cloud Environment. Active Cloud Environment is at a cloud provider such as a preferred cloud provider whereas Passive Cloud Environment is at another cloud provider such as a secondary cloud provider.

In the scenario shown in Active Cloud Environment fails which causes the Passive Cloud Environment to assume the active role and commence handling the workload previously handled by the Active Cloud Environment. As explained in further detail in the commands used to provide resources to Active Cloud Environment were intercepted and stored in a queue. The queue of commands is then used to scale the Passive Cloud Environment appropriately so that it can adequately handle the workload that was previously handled by the Active Cloud Environment.

At step the process initializes the primary active cloud environment and starts servicing the workload. At step the process retrieve components and data regarding the cloud infrastructure for the secondary passive cloud environment which has fewer resources than the active cloud environment. At step the process initialize the secondary passive cloud environment which assumes a backup passive standby role in comparison to the active cloud environment and as previously mentioned uses fewer resources than are used by the active cloud environment.

After both the active cloud and the passive cloud environments have been initialized at predefined process the process performs cloud command interception see and corresponding text for processing details . The cloud command interception stores intercepted commands in command queue .

A decision is made by the process as to whether the active cloud environment is still operating decision . If the active cloud environment is still operating then decision branches to the yes branch which loops back to continue intercepting cloud commands as detailed in . This looping continues until such point as the active cloud environment is no longer operating at which point decision branches to the no branch.

When the active cloud environment is no longer in operation at predefined process the process switches the passive cloud environment to be the active cloud environment utilizing the intercepted cloud commands that were stored in queue see and corresponding text for processing details . As shown this causes Passive Cloud Environment to scale appropriately and become new Active Cloud Environment .

At step the process creates cloud entities on Active Cloud Environment in accordance with the received command or API e.g. allocating additional VMs computing resources etc. to the Active Cloud Environment etc. . At step the process queues the command or API in command queue . At step the process check the replication policies for passive backup cloud environment by retrieving the policies from data store . For example rather than leaving the passive cloud environment at a minimal configuration the policy might be to grow scale the passive cloud environment at a slower pace than the active cloud environment. So when five VMs are allocated to the active cloud environment the policy might be to allocate an additional VM to the passive cloud environment.

A decision is made by the process as to whether the policy is to create any additional cloud entities in the passive cloud environment decision . If the policy is to create cloud entities in the passive cloud environment then decision branches to the yes branch to create such entities.

At step the process create all or portion of cloud entities on Passive Cloud as per the command or API. Note that the command API may need to be translated to Passive Cloud Environment if the commands APIs are different than those used in the Active Cloud Environment. This results in an adjustment scale change to Passive Cloud Environment . At step the process performs entity pairing to link objects in the Active and the Passive Clouds. At step the process store the entity pairing data in data repository . At step the process adjusts the commands APIs stored in command queue by reducing eliminating the last command or API based on the cloud entities that have already been created in the Passive Cloud Environment step based on the replication policies. Returning to decision if the policy is not to create cloud entities in the passive cloud environment based on this command API then decision branches to the no branch bypassing steps through .

At step the process waits for the next command or API to be received that is directed to the Active Cloud Environment at which point process loops back to step to process the received command or API as described above.

At step the process automatically routes all traffic to the Passive Cloud Environment with the Passive Cloud Environment becoming New Active Cloud Environment . Next the command queue is processed to scale the new Active Cloud Environment in accordance with the scaling performed for the previous Active Cloud Environment.

At step the process selects the first queued command or API from command queue . At step the process creates cloud entities on new Active Cloud Environment in accordance with the selected command or API. Note that the command API may need to be translated to Passive Cloud Environment if the commands APIs are different than those used in the Active Cloud Environment. A decision is made by the process as to whether there are more queued commands or APIs to process decision . If there are more queued commands or APIs to process then decision branches to the yes branch which loops back to step to select and process the next queued command API as described above. This looping continues until all of the commands APIs from command queue have been processed at which point decision branches to the no branch for further processing.

A decision is made by the process as to whether there is a policy to switch back to the original Active Cloud Environment when it is back online decision . If there is a policy to switch back to the original Active Cloud Environment when it is back online then decision branches to the yes branch whereupon at step the process waits for the original Active Cloud Environment to be back online and operational. When the original Active Cloud Environment is back online and operational then at step the process automatically routes all traffic back to the Initial Active Cloud Environment and at step the new Active Cloud Environment is reset back to the Passive Cloud Environment and the Passive Cloud Environment is scaled back to the scale of the Passive Cloud Environment when the switchover occurred with such state information being retrieved from data store .

Returning to decision if there is no policy to switch back to the original Active Cloud Environment when it is back online then decision branches to the no branch whereupon at step command queue is cleared so that it can be used to store commands APIs used to create entities in the new Active Cloud Environment. At step predefined process the process performs the Fractional Reserve High Availability Using Cloud Command Interception routine with this cloud being the new Active Cloud Environment and other cloud the initial Active Cloud Environment now assuming the role as the Passive Cloud Environment see and corresponding text for processing details .

At step the process selects the first set of VM adjustments to use in Mirrored Environment with the VM adjustments being retrieved from data store . A decision is made by the process as to whether there are more adjustments being tested by additional VMs running in the mirrored environment decision . As shown multiple VMs can be instantiated with each of the VMs running using one or more VM adjustments so that each of the mirrored environment VMs VMs and are running with a different configuration of characteristics. If there are more adjustments to test then decision branches to the yes branch which loops back to select the next set of VM adjustments to use in the mirrored environment and sets up another VM based on the set of adjustments. This looping continues until there are no more adjustments to test at which point decision branches to the no branch for further processing.

At step the process receives a request from requestor . At step the request is processed by each VM production VM and each of the mirrored environment VMs and timing is measured as to how long each of the VMs took to process the request. Note however that the process inhibits the return of results by all VMs except for the production VM. The timing results are stored in data store . A decision is made by the process as to whether to continue testing decision . If further testing is desired then decision branches to the yes branch which loops back to receive and process the next request and record the time taken by each of the VMs to process the request. This looping continues until no further testing is desired at which point decision branches to the no branch for further processing.

A decision is made by the process as to whether one of the test VMs VMs or running in mirrored environment performed faster than the production VM decision . In one embodiment the test VM needs to be faster than the production VM by a given threshold factor e.g. twenty percent faster etc. . If one of the test VMs performed the requests faster than the production VM then decision branches to the yes branch for further processing.

At step the process swaps the fastest test environment VM with the production environment VM so that the test VM is now operating as the production VM and returns results to the requestors. At step the process saves adjustments that were made to the fastest test environment VM to the production settings that are stored in data store . On the other hand if none of the test VMs performed faster than the production VM then decision branches to the no branch whereupon at step the process keeps the production environment VM as is with no swapping with any of the test VMs.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

While particular embodiments of the present invention have been shown and described it will be obvious to those skilled in the art that based upon the teachings herein that changes and modifications may be made without departing from this invention and its broader aspects. Therefore the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of this invention. Furthermore it is to be understood that the invention is solely defined by the appended claims. It will be understood by those with skill in the art that if a specific number of an introduced claim element is intended such intent will be explicitly recited in the claim and in the absence of such recitation no such limitation is present. For non limiting example as an aid to understanding the following appended claims contain usage of the introductory phrases at least one and one or more to introduce claim elements. However the use of such phrases should not be construed to imply that the introduction of a claim element by the indefinite articles a or an limits any particular claim containing such introduced claim element to inventions containing only one such element even when the same claim includes the introductory phrases one or more or at least one and indefinite articles such as a or an the same holds true for the use in the claims of definite articles.

