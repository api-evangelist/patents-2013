---

title: Video coding using reference motion vectors
abstract: Techniques are described to use a reference motion vector to reduce the amount of bits needed to encode motion vectors for inter prediction. One method includes identifying a candidate motion vector used to inter predict each of a plurality of previously coded blocks to define a plurality of candidate motion vectors, identifying a set of reconstructed pixel values corresponding to a set of previously coded pixels for the current block, and generating, using each candidate motion vector, a corresponding set of predicted values for the set of previously coded pixel values within each reference frame of a plurality of reference frames. A respective error value based on a difference between the set of reconstructed pixel values and each set of predicted values is used to select a reference motion vector from the candidate motion vectors that is used to encode the motion vector for the current block.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09485515&OS=09485515&RS=09485515
owner: GOOGLE INC.
number: 09485515
owner_city: Mountain View
owner_country: US
publication_date: 20130823
---
Digital video streams may represent video using a sequence of frames or still images. Digital video can be used for various applications including for example video conferencing high definition video entertainment video advertisements or sharing of user generated videos. A digital video stream can contain a large amount of data and consume a significant amount of computing or communication resources of a computing device for processing transmission or storage of the video data. Various approaches have been proposed to reduce the amount of data in video streams including compression and other encoding techniques.

This disclosure relates generally to encoding and decoding video data and more particularly relates to video coding using reference motion vectors. The teachings herein can reduce the number of bits required to encode motion vectors for inter prediction. One method for encoding a video stream described herein includes identifying for each previously coded block of a plurality of previously coded blocks of a current frame of the video stream a candidate motion vector used to inter predict the previously coded block to define a plurality of candidate motion vectors identifying for a current block to be encoded a set of reconstructed pixel values corresponding to a set of previously coded pixels the current block and the set of previously coded pixels in the current frame generating using each candidate motion vector of the plurality of candidate motion vectors a corresponding set of predicted values for the set of previously coded pixel values within each reference frame of a plurality of reference frames wherein at least one of the plurality of reference frames is temporally non adjacent to the current frame determining a respective error value based on a difference between the set of reconstructed pixel values and each set of predicted values selecting based on the error values a reference motion vector from the plurality of candidate motion vectors and encoding a motion vector for the current block using the reference motion vector.

Another method described herein is a method for decoding an encoded video bitstream including determining from bits included in the encoded video bitstream whether a motion vector for a current block to be decoded was encoded using a reference motion vector the current block being one of a plurality of blocks of a current frame of the encoded video bitstream identifying for each previously decoded block of a plurality of previously decoded blocks of the current frame a candidate motion vector used to inter predict the previously decoded block to define a plurality of candidate motion vectors identifying for the current block a set of reconstructed pixel values corresponding to a set of previously decoded pixels the set of previously decoded pixels in the current frame generating using each candidate motion vector of the plurality of candidate motion vectors a corresponding set of predicted values for the set of previously decoded pixel values within each reference frame of a plurality of reference frames wherein at least one of the plurality of reference frames is separated from the current frame within a temporal sequence of the video stream by at least one frame determining a respective error value based on a difference between the set of reconstructed pixel values and each set of predicted values selecting based on the error values a reference motion vector from the plurality of candidate motion vectors and decoding a motion vector for the current block using the reference motion vector.

An example of an apparatus for encoding a video stream described herein includes a memory and a processor. The processor is configured to execute instructions stored in the memory to identify for each previously coded block of a plurality of previously coded blocks of a current frame of the video stream a candidate motion vector used to inter predict the previously coded block to define a plurality of candidate motion vectors identify for a current block to be encoded a set of reconstructed pixel values corresponding to a set of previously coded pixels the current block and the set of previously coded pixels in the current frame generate using each candidate motion vector of the plurality of candidate motion vectors a corresponding set of predicted values for the set of previously coded pixel values within each reference frame of a plurality of reference frames wherein at least one of the plurality of reference frames is separated from the current frame within a temporal sequence of the video stream by at least one frame determine a respective error value based on a difference between the set of reconstructed pixel values and each set of predicted values select based on the error values a reference motion vector from the plurality of candidate motion vectors and encode a motion vector for the current block using the reference motion vector.

Variations in these and other aspects of the disclosure will be described in additional detail hereafter.

Compression schemes related to coding video streams may include breaking each image into blocks and generating a digital video output bitstream using one or more techniques to limit the information included in the output. A received bitstream can be decoded to re create the blocks and the source images from the limited information. Encoding a video stream or a portion thereof such as a frame or a block can include using temporal and spatial similarities in the video stream to improve coding efficiency. For example a current block of a video stream may be encoded based on a previously encoded block in the video stream by predicting motion and color information for the current block based on the previously encoded block and identifying a difference residual between the predicted values and the current block. In this way only the residual and parameters used to generate it need be added to the bitstream instead of including the entirety of the current block. This technique may be referred to as inter prediction.

One of the parameters in inter prediction is a motion vector that represents the spatial displacement of the previously coded block relative to the current block. The motion vector can be identified using a method of motion estimation such as a motion search. In motion search a portion of a reference frame can be translated to a succession of locations to form a prediction block that can be subtracted from a portion of a current frame to form a series of residuals. The X and Y translations corresponding to the location having the smallest residual can be selected as the motion vector. Bits representing the motion vector can be included in the encoded bitstream to permit a decoder to reproduce the prediction block and decode the portion of the encoded video bitstream associated with the motion vector.

For video compression schemes the number of bits used to encode the motion vectors can be significant especially for video streams encoded at lower data rates or higher compression ratios. To improve the encoding efficiency a motion vector can be differentially encoded using a reference motion vector i.e. only the difference between the motion vector and the reference motion vector is encoded. In some instances the reference motion vector can be selected from previously used motion vectors in the video stream for example the last non zero motion vector from neighboring blocks. Selecting a previously used motion vector to encode a current motion vector can further reduce the number of bits included in the encoded video bitstream and thereby reduce transmission and storage bandwidth requirements.

In implementations of this disclosure a reference motion vector can be selected from candidate motion vectors based on a match score. For example the match score can be based on the results of using candidate motion vectors e.g. those used by previously decoded blocks to predict a trial set of pixel values for those pixels close to the current block. Since the trial set has already been encoded and reconstructed the predicted values can be compared against the corresponding reconstructed values to determine the match score. This permits the same procedure to take place at a decoder where the reconstructed values would be available to calculate match scores before reconstructing the current block.

Due to the proximity of the current block to the pixels used in generating the trial set it is likely in many cases that the current block has similar motion characteristics to those pixels. Thus a candidate motion vector that generates the best predictor of the trial set may closely resemble the actual motion vector for the current block. For this reason the motion vector of the candidate motion vectors that has the best match score may be selected as the reference motion vector for the actual motion vector of the current block. Fewer bits can be used to code the actual motion vector by coding the small difference in motion vectors thus improving the overall coding efficiency. Other ways in which the selected motion vector may be used are discussed hereinafter.

The candidate motion vectors may be limited to spatial temporal neighboring motion vectors. That is the pool of candidate motion vectors may be selected from regions neighboring regions the current block. In some video coding schemes particularly those where video frames are encoded out of order it is desirable to include in the pool of candidate motion vectors motion information from video frames in the distant past or future. Encoding video frames can out of order may occur for example in the coding of so called alternate reference frames that are not temporally neighboring to the frames coded immediately before or after them. An alternate reference frame may be a synthesized frame that does not occur in the input video stream or is a duplicate frame to one in the input video stream that is used for prediction and is generally not displayed following decoding. Such a frame can resemble a video frame in the non adjacent future. Another example in which out of order encoding may occur is through the use of a so called golden reference frame which is a reconstructed video frame that may or may not be neighboring to a current video frame and is stored in memory for use as a reference frame until replaced e.g. by a new golden reference frame.

Herein alternate reference frames and golden reference frames also called alternate frames and golden frames in addition to adjacent video frames are used to infer motion vectors for a block of a frame of video data using pixels from the non adjacent or adjacent video frames to predict reconstructed pixels spatially near the block to be predicted. Other details are described herein after first describing an environment in which the invention may be implemented.

A network connects transmitting station and a receiving station for encoding and decoding of the video stream. Specifically the video stream can be encoded in transmitting station and the encoded video stream can be decoded in receiving station . Network can be for example the Internet. Network can also be a local area network LAN wide area network WAN virtual private network VPN a cellular telephone network or any other means of transferring the video stream from transmitting station to in this example receiving station .

Receiving station can in one example be a computer having an internal configuration of hardware including a processor such as a CPU and a memory . CPU is a controller for controlling the operations of receiving station . CPU can be connected to memory by for example a memory bus. Memory can be ROM RAM or any other suitable memory device. Memory can store data and program instructions that are used by CPU . Other suitable implementations of receiving station are possible. For example the processing of receiving station can be distributed among multiple devices.

A display configured to display a video stream can be connected to receiving station . Display can be implemented in various ways including by a liquid crystal display LCD a cathode ray tube CRT or a light emitting diode display LED such as an OLED display. Display is coupled to CPU and can be configured to display a rendering of the video stream decoded in receiving station .

Other implementations of the encoder and decoder system are also possible. For example one implementation can omit network and or display . In another implementation a video stream can be encoded and then stored for transmission at a later time by receiving station or any other device having memory. In one implementation receiving station receives e.g. via network a computer bus or some communication pathway the encoded video stream and stores the video stream for later decoding. In another implementation additional components can be added to the encoder and decoder system . For example a display or a video camera can be attached to transmitting station to capture the video stream to be encoded.

At the next level single frame can be divided into a set of blocks which can contain data corresponding to in some of the examples described below a 8 8 pixel group in frame . Block can also be of any other suitable size such as a block of 16 8 pixels a block of 8 8 pixels a block of 16 16 pixels a block of 4 4 pixels or of any other size. Unless otherwise noted the term block can include a macroblock a subblock i.e. a subdivision of a macroblock a segment a slice a residual block or any other portion of a frame. A frame a block a pixel or a combination thereof can include display information such as luminance information chrominance information or any other information that can be used to store modify communicate or display the video stream or a portion thereof.

When video stream is presented for encoding each frame within video stream can be processed in units of blocks. Referring to at intra inter prediction stage each block can be encoded using either intra prediction i.e. within a single frame or inter prediction i.e. from frame to frame . In either case a prediction block can be formed. The prediction block is then subtracted from the block to produce a residual block also referred to herein as residual .

Intra prediction also referred to herein as intra prediction or intra frame prediction and inter prediction also referred to herein as inter prediction or inter frame prediction are techniques used in modern image video compression schemes. In the case of intra prediction a prediction block can be formed from samples in the current frame that have been previously encoded and reconstructed. In the case of inter prediction a prediction block can be formed from samples in one or more previously constructed reference frames such as the last frame i.e. the adjacent frame immediately before the current frame the golden frame or the constructed or alternate frame described above.

The prediction block is then subtracted from the current block. The difference or residual is then encoded and transmitted to decoders. Image or video codecs may support many different intra and inter prediction modes each block may use one of the prediction modes to obtain a prediction block that is most similar to the block to minimize the information to be encoded in the residual so as to re create the block. The prediction mode for each block of transform coefficients can also be encoded and transmitted so a decoder can use the same prediction mode s to form prediction blocks in the decoding and reconstruction process.

The prediction mode may be selected from one of multiple intra prediction modes. Alternatively the prediction mode may be selected from one of multiple inter prediction modes using one or more reference frames including for example last frame golden frame alternative reference frame or any other reference frame in an encoding scheme. The inter prediction modes can include for example a mode sometimes called ZERO MV mode in which a block from the same location within a reference frame as the current block is used as the prediction block a mode sometimes called a NEW MV mode in which a motion vector is transmitted to indicate the location of a block within a reference frame to be used as the prediction block relative to the current block or a mode sometimes called a NEAR MV or NEAREST MV mode in which no motion vector is transmitted and the current block uses the last or second to last non zero motion vector used by neighboring previously coded blocks to generate the prediction block. Inter prediction modes may be used with any of the available reference frames.

Next still referring to transform stage transforms the residual into a block of transform coefficients in for example the frequency domain. Examples of block based transforms include the Karhunen Lo ve Transform KLT the Discrete Cosine Transform DCT Walsh Hadamard Transform WHT the Singular Value Decomposition Transform SVD and the Asymmetric Discrete Sine Transform ADST . In one example the DCT transforms the block into the frequency domain. In the case of DCT the transform coefficient values are based on spatial frequency with the lowest frequency e.g. DC coefficient at the top left of the matrix and the highest frequency coefficient at the bottom right of the matrix.

Quantization stage converts the block of transform coefficients into discrete quantum values which are referred to as quantized transform coefficients using a quantizer value or quantization level. The quantized transform coefficients are then entropy encoded by entropy encoding stage . The entropy encoded coefficients together with other information used to decode the block which can include for example the type of prediction used motion vectors and quantization value are then output to compressed bitstream . Compressed bitstream can be formatted using various techniques such as variable length encoding VLC and arithmetic coding. Compressed bitstream can also be referred to as an encoded video stream and the terms will be used interchangeably herein.

The reconstruction path in shown by the dotted connection lines can be used to provide both encoder and a decoder described below with the same reference frames to decode compressed bitstream . The reconstruction path performs functions that are similar to functions that take place during the decoding process that are discussed in more detail below including dequantizing the quantized transform coefficients at dequantization stage to generate dequantized transform coefficients and inverse transforming the dequantized transform coefficients at inverse transform stage to produce a derivative residual block i.e. derivative residual . At reconstruction stage the prediction block that was predicted at intra inter prediction stage can be added to the derivative residual to create a reconstructed block. In some implementations loop filtering stage can be applied to the reconstructed block to reduce distortion such as blocking artifacts.

Other variations of encoder can be used. For example a non transform based encoder can quantize the residual block directly without transform stage . In another implementation an encoder can have quantization stage and dequantization stage combined into a single stage.

Decoder similar to the reconstruction path of encoder discussed above includes in one example the following stages to perform various functions to produce an output video stream from compressed bitstream an entropy decoding stage a dequantization stage an inverse transform stage an intra inter prediction stage a reconstruction stage a loop filtering stage and a deblocking filtering stage . Other structural variations of decoder can be used to decode compressed bitstream .

When compressed bitstream is presented for decoding the data elements within compressed bitstream can be decoded by the entropy decoding stage using for example arithmetic coding to produce a set of quantized transform coefficients. Dequantization stage dequantizes the quantized transform coefficients and inverse transform stage inverse transforms the dequantized transform coefficients to produce a derivative residual that can be identical to that created by reconstruction stage in encoder . Using header information decoded from compressed bitstream decoder can use intra inter prediction stage to create the same prediction block as was created in encoder e.g. at intra inter prediction stage . In the case of inter prediction the reference frame from which the prediction block is generated may be transmitted in the bitstream or constructed by the decoder using information contained within the bitstream.

At reconstruction stage the prediction block can be added to the derivative residual to create a reconstructed block that can be identical to the block created by reconstruction stage in encoder . In some implementations loop filtering stage can be applied to the reconstructed block to reduce blocking artifacts. Deblocking filtering stage can be applied to the reconstructed block to reduce blocking distortion and the result is output as output video stream . Output video stream can also be referred to as a decoded video stream and the terms will be used interchangeably herein.

Other variations of decoder can be used to decode compressed bitstream . For example decoder can produce output video stream without deblocking filtering stage .

Process can be implemented using specialized hardware or firmware. Some computing devices can have multiple memories multiple processors or both. The steps of process can be distributed using different processors memories or both. Use of the terms processor or memory in the singular encompasses computing devices that have one processor or one memory as well as devices that have multiple processors or multiple memories that can each be used in the performance of some or all of the recited steps. For simplicity of explanation process is depicted and described as a series of steps. However steps in accordance with this disclosure can occur in various orders and or concurrently. Additionally steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore not all illustrated steps may be required to implement a method in accordance with the disclosed subject matter.

Process assumes that a stream of video data having multiple frames each having multiple blocks is being encoded using a video encoder such as video encoder executing on a computing device such as transmitting station . The video data or stream can be received by the computing device in any number of ways such as by receiving the video data over a network over a cable or by reading the video data from a primary memory or other storage device including a disk drive or removable media such as a CompactFlash CF card Secure Digital SD card or any other device capable of communicating video data. In some implementations video data can be received from a video camera connected to the computing device operating the encoder. At least some of the blocks within frames are encoded using inter prediction as described in more detail below.

At step process identifies candidate motion vectors from previously coded blocks in the video stream. The previously coded blocks in the video stream can include any block encoded using inter prediction before the current block such as a block from a previously coded frame or a block from the same frame as the current block that has been encoded before the current block. For example in some encoding decoding codec schemes such as ones that code in raster scan order the previously coded blocks can include a block above to the left or to the above left of the current block in the same frame. The previously coded blocks can also include for example a block from the immediately previous frame i.e. last frame a block from the golden frame described at intra inter prediction stage a block from any other reference frame or any combination thereof. Desirably however the candidate motion vectors are obtained from previously coded blocks that correspond in some way to the current block based on the theory that such blocks due to the proximity of their pixels to the current block are likely to have similar motion characteristics to the current block.

In the example of frame Fis a golden frame available for inter prediction of blocks in current frame F. Therefore one or more of the adjacent blocks to the current block in frame Fmay refer to frame Fsuch that its motion vector is included among the candidate motion vectors. Further one or more motion vectors used for the prediction of the blocks in golden frame Fmay also be added to the candidate motion vectors. For example a dominant motion vector of the frame could be selected. In some cases motion vectors of inter predicted blocks in golden frame Fwithin a specified spatial neighborhood of for example the same pixel position as the current block may be used as candidate motion vectors. Flags may be associated with frame F such as bits in its header to indicate that a motion vector used in coding frame F e.g. against frame F is available to some blocks in frame Fas a candidate motion vector.

Referring again to process includes selecting or identifying a set of reconstructed pixel values corresponding to a set of previously coded pixels at step . In some implementations the set of previously coded pixel values can include one or more rows of pixel values above the current block or one or more columns of pixel values to the left of the current block or both. The following examples are described using data in the two rows immediately above and the two columns immediately to the left of the current block. When the scan order is other than raster scan order other adjacent pixels may be used. In other implementations data from rows or columns not immediately adjacent to the current block including data from blocks that are not adjacent to the current block can be included in the set of previously coded pixel values. Due to the proximity of the set of previously coded pixel values to the current block it is likely that the current block has similar motion characteristics as the set of previously coded pixel values. The set of reconstructed pixel values corresponding to the set of previously coded pixel values is available for example from the reconstruction path in at encoder .

Each of the pixels in rows A B and columns C D has a reconstructed pixel value resulting from encoding and decoding blocks A B respectively. Using these values an error value also called a match score can be determined for the candidate motion vectors at step . To determine such an error value a candidate motion vector may be used to generate predicted pixel values for the pixels of rows A B and columns C D for a comparison against the reconstructed pixel values. The motion vector is applied to the selected pixels which produces predicted pixel values from a reference frame and then the predicted pixel values are compared against the selected reconstructed pixel values to produce the error value for each motion vector. Step can be implemented for example at intra inter prediction stage of encoder in and one implementation is explained using .

More generally determining error values for motion vectors acquired from reference frames either temporally adjacent or temporally non adjacent to the current frame includes using the motion vectors to translate pixels from a reference frame to positions coincident with the set of reconstructed pixels spatially near the current block from the current frame to be predicted. A comparison may be performed by subtracting the translated pixel values from the reconstructed pixel values. The residual or difference for each set of pixel values may be combined to produce a match score or error value that represents the magnitude of the residual summed the absolute values summed the squared differences summed or the differences averaged the absolute values of the differences averaged or any other technique for arriving at a relative magnitude of the residuals.

The error value can be determined using metrics such as sum of absolute differences SAD sum of squared error SSE mean squared error MSE or any other error metric. For example when SAD is used the set of predicted values can be compared against the set of reconstructed pixel values to determine a SAD value for each motion vector. In some implementations different weights can be associated with different pixels in the set of previously coded pixel values. For example more weight can be given to the row or column of pixels immediately adjacent to the current block or less weight can be given to the row or column of pixels further away from the current block. Error values may be similarly determined for each candidate motion vector and each possible reference frame as described below.

The reference frame used for the identification of the prediction values in step may be a temporally adjacent frame such as last frame F or a temporally non adjacent frame such as golden frame For alternate frame A . Desirably each available reference frame is used as part of a rate distortion loop within an encoder that determines the best coding mode for the current block by comparing the rate e.g. the bit cost of each coding mode with the resulting image distortion e.g. the change in image due to the coding for each tested mode. However since the candidate motion vectors may be generated using frames separated by different temporal distances than the current frame and the particular reference frame under consideration. Accordingly step also includes scaling candidate motion vectors where needed which is described by reference again to .

Scaling up or down a motion vector so that it may be applied as a candidate motion vector means adjusting its magnitude. The magnitude of the candidate can be scaled depending upon the results of comparing the temporal distance and direction between the reference frame and the frame including the current block and the temporal distance and direction used to form the candidate motion vector. The temporal distance between frames can be determined by their respective positions in the video stream. For example when a candidate motion vector is a motion vector that was used to encode a block of frame Fagainst frame F the magnitude of the motion vector can be used directly for encoding frame Fagainst reference frame Fsince frames Fand Fare like frames Fand F a frame apart temporally that is they are adjacent frames in the frame sequence . In contrast a candidate motion vector from Fand previous coded blocks of Fwhen a block of Fwas encoded using the golden frame i.e. Fin this needs to be scaled to take into account the difference of temporal distance before being used to generate the prediction pixels in step . For example a motion vector used in previously coding a block of current frame Fagainst Fwill be scaled up using a factor proportional to k 2 to become a candidate motion vector for generation of the prediction pixels when the current block such as block of is in evaluation to be coded against reference frame F. Scaling up or down a motion vector so that it may be applied as a candidate motion vector means adjusting its magnitude. The magnitude of the candidate can be scaled depending upon the results of comparing the temporal distance and direction between the reference frame and the frame including the current block and the temporal distance and direction used to form the candidate motion vector.

An alternate reference frame such as frame Amay be treated similarly to other references frames such as the last or golden reference frame. However since an alternate reference frame may be constructed using portions of multiple frames from multiple temporal positions in the video stream techniques may be used to determine a temporal position in the video stream that most closely matches the image data included in the alternate frame.

This can be explained further using an example from assuming the use of a candidate motion vector used to predict a block in Ffrom frame Ato generate prediction pixels for analysis of the current block using reference frame F. Because the distance in frames between Fand A where Aactually resembles frame F is k m 1 the motion vector magnitude may be divided by k m 1 before using the candidate motion vector to generate the prediction pixels. This is because the distance between frames Fand Fis less than the distance k m 1 therefore the motion vector has to scaled down to approximate the motion between frames Fand F. In cases where the motion vectors are taken from frames temporally close together and used to form inter prediction pixels from frames with greater temporal separation the motion vectors can be multiplied by a scaling factor proportional to the ratio of the two temporal distances.

At step a reference motion vector can be selected from the candidate motion vectors identified at step . The selection can be based on for example selecting the motion vector from the candidate motion vectors associated with the best match score which can be for example the motion vector with the lowest error value among all the candidate motion vectors generated in step . Other selection criteria can also be used. For example if it is determined that candidate motion vector has the lowest error value among the candidate motion vectors candidate motion vector can be selected as the reference motion vector which can be used for further processing. Namely the motion vector of the current block can be encoded using the reference motion vector in step before processing begins again for the next block of the current frame. In addition the current block can be encoded according to the process described with respect to .

There are several ways to use the reference motion vector in encoding the motion vector of the current block. For example and as described above process may be part of a rate distortion loop used to select the inter prediction mode for the current block to be encoded. As part of the rate distortion loop the actual motion vector for inter prediction of the current block may be determined through a motion search according to any number of techniques. One use of the reference motion vector may include using the reference motion vector as a starting parameter for the motion search algorithm based on the reasoning that the actual motion vector is likely to be close to those used in selecting the reference motion vector. A motion search may alternatively be performed before or in parallel with process .

Whether or not the reference motion vector is incorporated into the motion search step may include using the reference motion vector to differentially encode the actual motion vector. For example a difference value can be calculated by subtracting the reference motion vector from the motion vector used to encode the current block. The difference value can be encoded and included in the video stream. Since the reference motion vector was formed using previously encoded and decoded data the same data can be available at a decoder to identify the same reference motion vector as was used in forming the motion vector at the encoder thus no motion vector is required to be encoded and transmitted for the current block. The decoded difference value can be added to the reference motion vector identified by the decoder as described below to form a motion vector to decode the current block. Note that the reference motion vector is associated with one of the available reference frames used to generate the set of predicted values and hence the error value. Therefore in the event the reference motion vector is associated with a reference frame that is different from the reference frame associated with the actual motion vector the reference motion vector may be scaled as described previously so as to generate the difference between the reference motion vector and the actual motion vector. In some implementations a separate indication of the reference frame used would also be encoded into the bitstream.

In another implementation the reference motion vector may be used to choose a probability distribution to encode the magnitude of the motion vector used to encode the current block. In this implementation bits can be included in the video stream to identify the encoded magnitude of the motion vector and which predetermined probability distribution to use to form the motion vector based on the encoded magnitude. One or more bits indicating which reference frame to use in decoding the current block may also be included in the bitstream in some variations. Like its use in differential encoding the reference motion vector may also be scaled to the extent it is desirable.

In an implementation the reference motion vector may also be used directly in the encoding of the current block. This can occur for example when a comparison of the rate distortion value involved in coding the current block using the motion vector determined by the motion search is higher than that involved in coding the current block using the reference motion vector. In this comparison the reference frame used would desirably be the one used in selecting the reference motion vector so no scaling is needed. In some cases the decision as to whether or not use the reference motion vector may be tied to the difference between the reference motion vector and the motion vector resulting from the search. When the difference is small or zero the difference in prediction results for the reference frame resulting from the search using the reference motion vector versus the actual motion vector is also small or zero . When the reference motion vector is used directly to encode the current block no motion vector would need to be separately encoded at step . Instead one or more bits would be inserted into the bitstream in association with the current block to indicate use of the reference motion vector for encoding.

In each of the above ways the use of a reference motion vector may reduce the number of bits needed to represent the motion vector needed to decode an inter coded block. In some cases the motion vector used for encoding the current frame would not be separately. Bits may be inserted into frame slice and or block headers indicating whether reference motion vectors are used and how they are used for encoding the current block. When applicable the motion vector found by the motion search or the motion vector differential and or the reference frame used in encoding the current block are also transmitted.

Regardless of the motion vector used for encoding a prediction block can be determined based on a reference frame by applying a candidate motion vector to the previously coded pixel values of the reference frame. The prediction block can be subtracted from the current block to form a residual that can be further encoded according to the processing described with respect to and included in an encoded video bitstream.

For simplicity of explanation process is depicted and described as a series of steps. However steps in accordance with this disclosure can occur in various orders and or concurrently. Additionally steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore not all illustrated steps may be required to implement a method in accordance with the disclosed subject matter.

Desirably process substantially conforms to process . There are some differences however that are pointed out in the following description of process . Where steps are substantially similar to those in process reference will be made to the description above.

At step the decoder determines whether the motion vector for the current block was encoded using a reference motion vector. This information can be communicated by reading and decoding bits from an encoded video bitstream that indicate the use of a reference motion vector according to one of the techniques disclosed above. The encoded bitstream or encoded video data may have been received by decoder of a computing device in any number of ways such as by receiving the video data over a network over a cable or by reading the video data from a primary memory or other storage device including a disk drive or removable media such as a DVD CompactFlash CF card Secure Digital SD card or any other device capable of communicating a video stream. Step involves decoding at least a portion of the encoded video bitstream to extract the information regarding the motion vector for the current block. This information can be included in a header associated with a current block or a frame header for example. The information in the one or more headers indicate to the decoder that the current block is to be decoded using inter prediction and that the motion vector used for that inter prediction relies on the reference motion vector as described previously. For example information in the bitstream could indicate that the actual motion vector used in encoding the current block was differentially encoded using the reference motion vector. Alternatively information could indicate that the reference motion vector was used directly for encoding the current block.

When a reference motion vector was used in the encoder to encode the motion vector for the current block process advances to step to identify candidate motion vectors from previously decoded blocks. The identified candidate motion vectors should be the same as those identified by the encoder in step which may be accomplished by flags as described previously and or by a priori rules regarding the selection of candidate motion vectors that are available to both the encoder and decoder based on the position of the current block.

At step a set of reconstructed pixel values corresponding to a set of previously decoded pixels is selected or identified at step . The set of pixels corresponds to the set of pixels used in step of . Thus the set of reconstructed pixel values in step is the same as the set of reconstructed pixel values in step .

At step an error value can be determined each candidate motion vector based on the set of reconstructed pixel values and a set of predicted values for the set of previously decoded pixel values associated with the candidate motion vector as described above with respect to step of . Using the error values for each candidate motion vector and each reference frame the reference motion vector is selected in the same manner as in step of such as by selecting the candidate motion vector and associated reference frame with the lowest error value.

Once the reference motion vector is selected the motion vector used to encode the current block can be decoded using the selected reference motion vector at step . The decoded motion vector may then be used to decode the current block according to the process of .

In one example of the implementation of step if the reference motion vector is used to differentially encode the actual motion vector for the current block the decoder can decode the motion vector by for example decoding an encoded difference value that can then be added to the reference motion vector selected at step to generate the actual motion vector. Then the actual motion vector may be used to decode the current block using inter prediction. In other implementations the reference motion vector can be used to identify a predetermined probability distribution which can be used to decode a magnitude value of the motion vector used to encode the current block before decoding the current block using the motion vector. Similar to the discussion in step of this may involve scaling the reference motion vector. In other implementations the reference motion vector may be used directly as the motion vector to decode the current block after decoding one or more bits indicating that the reference motion vector should be so used.

Once the motion vector and current block are decoded at step the next block may be processed. In the next block is inter coded process may be repeated. A frame can be reconstructed from the blocks derived from reconstructed values by intra or inter prediction or both. The output can be an output video stream such as the output video stream shown in .

According to the teachings herein a reference motion vector may be selected so as to reduce the number of bits required to encode a motion vector determined by for example motion search techniques. The teachings herein take advantage of temporal motion continuity to reduce the number of bits required to transmit motion vector information by referring to motion vectors from adjacent and non adjacent video frames. The decoder has all the information the encoder has to select the reference motion vector allowing the selection of the reference motion vector without explicit transfer of further information.

The aspects of encoding and decoding described above illustrate some exemplary encoding and decoding techniques. However it is to be understood that encoding and decoding as those terms are used in the claims could mean compression decompression transformation or any other processing or change of data.

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Moreover use of the term an implementation or one implementation throughout is not intended to mean the same embodiment or implementation unless described as such.

Implementations of transmitting station and or receiving station and the algorithms methods instructions etc. stored thereon and or executed thereby including by encoder and decoder can be realized in hardware software or any combination thereof. The hardware can include for example computers intellectual property IP cores application specific integrated circuits ASICs programmable logic arrays optical processors programmable logic controllers microcode microcontrollers servers microprocessors digital signal processors or any other suitable circuit. In the claims the term processor should be understood as encompassing any of the foregoing hardware either singly or in combination. The terms signal and data are used interchangeably. Further portions of transmitting station and receiving station do not necessarily have to be implemented in the same manner.

Further in one aspect for example transmitting station or receiving station can be implemented using a general purpose computer or general purpose processor with a computer program that when executed carries out any of the respective methods algorithms and or instructions described herein. In addition or alternatively for example a special purpose computer processor can be utilized which can contain other hardware for carrying out any of the methods algorithms or instructions described herein.

Transmitting station and receiving station can for example be implemented on computers in a video conferencing system. Alternatively transmitting station can be implemented on a server and receiving station can be implemented on a device separate from the server such as a hand held communications device. In this instance transmitting station can encode content using an encoder into an encoded video signal and transmit the encoded video signal to the communications device. In turn the communications device can then decode the encoded video signal using a decoder . Alternatively the communications device can decode content stored locally on the communications device for example content that was not transmitted by transmitting station . Other suitable transmitting station and receiving station implementation schemes are available. For example receiving station can be a generally stationary personal computer rather than a portable communications device and or a device including an encoder may also include a decoder .

Further all or a portion of implementations of the present invention can take the form of a computer program product accessible from for example a tangible computer usable or computer readable medium. A computer usable or computer readable medium can be any device that can for example tangibly contain store communicate or transport the program for use by or in connection with any processor. The medium can be for example an electronic magnetic optical electromagnetic or a semiconductor device. Other suitable mediums are also available.

The above described embodiments implementations and aspects have been described in order to allow easy understanding of the present invention and do not limit the present invention. On the contrary the invention is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structure as is permitted under the law.

