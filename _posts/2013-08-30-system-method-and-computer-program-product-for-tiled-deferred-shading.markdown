---

title: System, method, and computer program product for tiled deferred shading
abstract: A system, method, and computer program product are provided for tiled deferred shading. In operation, a plurality of photons associated with at least one scene are identified. Further, a plurality of screen-space tiles associated with the at least one scene are identified. Additionally, each of the plurality of screen-space tiles capable of being affected by a projection of an effect sphere for each of the plurality of photons are identified. Furthermore, at least a subset of photons associated with each of the screen-space tiles from which to compute shading are selected. Moreover, shading for the at least one scene is computed utilizing the selected at least a subset of photons.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09305324&OS=09305324&RS=09305324
owner: NVIDIA Corporation
number: 09305324
owner_city: Santa Clara
owner_country: US
publication_date: 20130830
---
This application claims the benefit of U.S. Provisional Application No. 61 745 264 filed Dec. 21 2012 the entire contents of which are incorporated herein by reference.

The present invention relates to graphics processing and more particularly to shading in the context of graphics processing.

In graphics processing efficiently rendering light that has scattered off multiple surfaces in the context of a real time application such as a video game is highly desirable. Photon mapping is known as a consistent estimator for indirect illumination in offline rendering. Photon mapping not only excels at sampling caustic paths that converge slowly for many other rendering methods but also estimates lower frequency glossy and diffuse interreflection well and is surprisingly simple to implement.

Many variations on photon mapping intended for eventual real time rendering of complex scenes have been proposed and even demonstrated on limited scenes at interactive rates. Combined with this algorithmic progress GPUs are now powerful enough that photon mapping may be implemented in real time rendering systems. One current challenge however is maintaining quality while scaling efficiently on a modern GPU.

Photon mapping includes two steps tracing photons along rays from light sources and estimating radiance due to those photons scattering off visible surfaces i.e. shading . Efficient parallel ray tracing hardware and software systems are capable of tracing hundreds of millions of rays per second and the process may be amortized over multiple frames. Thus existing systems meet the performance needed for photon tracing. Net performance of these systems typically hinge on efficient photon shading.

A system method and computer program product are provided for tiled deferred shading. In operation a plurality of photons associated with at least one scene are identified. Further a plurality of screen space tiles associated with the at least one scene are identified. Additionally each of the plurality of screen space tiles capable of being affected by a projection of an effect sphere for each of the plurality of photons are identified. Furthermore at least a subset of photons associated with each of the screen space tiles from which to compute shading are selected. Moreover shading for the at least one scene is computed utilizing the selected at least a subset of photons.

Further in operation a plurality of screen space tiles associated with the at least one scene are identified. In one embodiment the plurality of screen space tiles associated with the at least one scene may include a plurality of pixels associated with the scene. For example the screen space tile may include an n n array of pixels where n is an integer greater than one.

As shown in operation each of the plurality of screen space tiles capable of being affected by a projection of an effect sphere are identified for each of the plurality of photons. In the context of the present description an effect sphere of a photon refers to the sphere of influence capable of influencing pixels and or tiles associated therewith. In one embodiment a copy of each photon may be inserted in or associated with etc. each screen space tile that would contain a projection of an effect sphere of that photon. In another embodiment a copy of each photon may be placed in buckets corresponding to the plurality of screen space tiles the photon is capable of affecting. In another embodiment a pointer to each photon may be inserted in or associated with etc. each screen space tile that is capable of containing a projection of an effect sphere of that photon. In yet another embodiment either a copy of or a pointer to each photon may be inserted in each screen space tile that is capable of containing a projection of an effect sphere of the photon.

Further in one embodiment one or more chunks of photons associated with the screen space tiles may be identified for processing. For example in the case that there are more photons in a tile than fit in memory multiple passes over a tile may be implemented processing chunks of the photons in the tile in each pass. Additionally in one embodiment photons associated with the plurality of screen space tiles that do not intersect a predefined depth range associated the plurality of screen space tiles may be culled. For example in one embodiment during the process of categorizing the photons into tiles a tiled algorithm may function to cull photons that do not intersect the depth range of the scene within a tile.

As shown further in operation at least a subset of photons associated with each of the screen space tiles may be selected from which to compute shading. In one embodiment selecting the subset of photons associated with each of the screen space tiles from which to compute shading may include iterating over all pixels in each of the plurality of screen space tiles. In another embodiment selecting the subset of photons associated with each of the screen space tiles from which to compute shading may include iterating over all pixels in each of the plurality of screen space tiles and selecting a subset of the photons in each of the screen space tiles from which to compute shading.

Furthermore in one embodiment selecting at least a subset of photons associated with each of the screen space tiles from which to compute shading may include selecting all photons associated with each of the screen space tiles i.e. not just a subset etc. . Additionally in one embodiment a stochastic process may be utilized to select the subset of photons associated with each of the screen space tiles from which to compute shading. For example in one embodiment a subset of photons may be stochastically selected independently at each pixel. In yet another embodiment an interleaving process may be utilized to select the subset of photons associated with each of the screen space tiles from which to compute shading.

As shown in operation shading is computed for the at least one scene utilizing the selected subset of photons. In one embodiment computing the shading may include reconstructing smooth shading at each pixel associated with the at least one scene. Further in one embodiment computing the shading may include reconstructing smooth shading at each pixel associated with the at least one scene from neighbor pixel values.

Additionally in one embodiment computing the shading may include utilizing a lateral filter. Of course in various embodiments any number of filters that respect edges may be utilized to compute the shading. Still yet in one embodiment the method may include rendering the at least one scene.

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing framework may or may not be implemented per the desires of the user. It should be strongly noted that the following information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of the following features may be optionally incorporated with or without the exclusion of other features described.

In one embodiment the PPU includes an input output I O unit configured to transmit and receive communications i.e. commands data etc. from a central processing unit CPU not shown over the system bus . The I O unit may implement a Peripheral Component Interconnect Express PCIe interface for communications over a PCIe bus. In alternative embodiments the I O unit may implement other types of well known bus interfaces.

The PPU also includes a host interface unit that decodes the commands and transmits the commands to the task management unit or other units of the PPU e.g. memory interface as the commands may specify. In one embodiment the PPU comprises U memory interfaces U where each memory interface U is connected to a corresponding memory device U . The host interface unit is configured to route communications between and among the various logical units of the PPU .

In one embodiment a program encoded as a command stream is written to a buffer by the CPU. The buffer is a region in memory e.g. memory or system memory that is accessible i.e. read write by both the CPU and the PPU . The CPU writes the command stream to the buffer and then transmits a pointer to the start of the command stream to the PPU . The host interface unit provides the task management unit TMU with pointers to one or more streams. The TMU selects one or more streams and is configured to organize the selected streams as a pool of pending grids. In one embodiment a thread block comprises 32 related threads and a grid is an array of one or more thread blocks that execute the same stream and the different thread blocks may exchange data through global memory. The pool of pending grids may include new grids that have not yet been selected for execution and grids that have been partially executed and have been suspended.

A work distribution unit that is coupled between the TMU and the SMs manages a pool of active grids selecting and dispatching active grids for execution by the SMs . Pending grids are transferred to the active grid pool by the TMU when a pending grid is eligible to execute i.e. has no unresolved data dependencies. An active grid is transferred to the pending pool when execution of the active grid is blocked by a dependency. When execution of a grid is completed the grid is removed from the active grid pool by the work distribution unit . In addition to receiving grids from the host interface unit and the work distribution unit the TMU also receives grids that are dynamically generated by the SMs during execution of a grid. These dynamically generated grids join the other pending grids in the pending grid pool.

In one embodiment the CPU executes a driver kernel that implements an application programming interface API that enables one or more applications executing on the CPU to schedule operations for execution on the PPU . An application may include instructions i.e. API calls that cause the driver kernel to generate one or more grids for execution. In one embodiment the PPU implements a SIMT Single Instruction Multiple Thread architecture where each thread block i.e. warp in a grid is concurrently executed on a different data set by different threads in the thread block. The driver kernel defines thread blocks that are comprised of k related threads such that threads in the same thread block may exchange data through shared memory.

In one embodiment the PPU may include 15 distinct SMs . Each SM is multi threaded and configured to execute a plurality of threads e.g. 32 threads from a particular thread block concurrently. Each of the SMs is connected to a level two L2 cache via a crossbar or other type of interconnect network . The L2 cache is connected to one or more memory interfaces . Memory interfaces implement 16 32 64 128 bit data buses or the like for high speed data transfer. In one embodiment the PPU may be connected to up to 6 memory devices such as graphics double data rate version 5 synchronous dynamic random access memory GDDR5 SDRAM .

In one embodiment the PPU implements a multi level memory hierarchy. The memory is located off chip in SDRAM coupled to the PPU . Data from the memory may be fetched and stored in the L2 cache which is located on chip and is shared between the various SMs . In one embodiment each of the SMs also implements an L1 cache. The L1 cache is private memory that is dedicated to a particular SM . Each of the L1 caches is coupled to the shared L2 cache . Data from the L2 cache may be fetched and stored in each of the L1 caches for processing in the functional units of the SMs .

In one embodiment the PPU comprises a graphics processing unit GPU . The PPU is configured to receive commands that specify shader programs for processing graphics data. Graphics data may be defined as a set of primitives such as points lines triangles quads triangle strips and the like. Typically a primitive includes data that specifies a number of vertices for the primitive e.g. in a model space coordinate system as well as attributes associated with each vertex of the primitive. The PPU can be configured to process the graphics primitives to generate a frame buffer i.e. pixel data for each of the pixels of the display . The driver kernel implements a graphics processing pipeline such as the graphics processing pipeline defined by the OpenGL API.

An application writes model data for a scene i.e. a collection of vertices and attributes to memory. The model data defines each of the objects that may be visible on a display. The application then makes an API call to the driver kernel that requests the model data to be rendered and displayed. The driver kernel reads the model data and writes commands to the buffer to perform one or more operations to process the model data. The commands may encode different shader programs including one or more of a vertex shader hull shader geometry shader pixel shader etc. For example the TMU may configure one or more SMs to execute a vertex shader program that processes a number of vertices defined by the model data. In one embodiment the TMU may configure different SMs to execute different shader programs concurrently. For example a first subset of SMs may be configured to execute a vertex shader program while a second subset of SMs may be configured to execute a pixel shader program. The first subset of SMs processes vertex data to produce processed vertex data and writes the processed vertex data to the L2 cache and or the memory . After the processed vertex data is rasterized i.e. transformed from three dimensional data into two dimensional data in screen space to produce fragment data the second subset of SMs executes a pixel shader to produce processed fragment data which is then blended with other processed fragment data and written to the frame buffer in memory . The vertex shader program and pixel shader program may execute concurrently processing different data from the same scene in a pipelined fashion until all of the model data for the scene has been rendered to the frame buffer. Then the contents of the frame buffer are transmitted to a display controller for display on a display device.

The PPU may be included in a desktop computer a laptop computer a tablet computer a smart phone e.g. a wireless hand held device personal digital assistant PDA a digital camera a hand held electronic device and the like. In one embodiment the PPU is embodied on a single semiconductor substrate. In another embodiment the PPU is included in a system on a chip SoC along with one or more other logic units such as a reduced instruction set computer RISC CPU a memory management unit MMU a digital to analog converter DAC and the like.

In one embodiment the PPU may be included on a graphics card that includes one or more memory devices such as GDDR5 SDRAM. The graphics card may be configured to interface with a PCIe slot on a motherboard of a desktop computer that includes e.g. a northbridge chipset and a southbridge chipset. In yet another embodiment the PPU may be an integrated graphics processing unit iGPU included in the chipset i.e. Northbridge of the motherboard.

As described above the work distribution unit dispatches active grids for execution on one or more SMs of the PPU . The scheduler unit receives the grids from the work distribution unit and manages instruction scheduling for one or more thread blocks of each active grid. The scheduler unit schedules threads for execution in groups of parallel threads where each group is called a warp. In one embodiment each warp includes 32 threads. The scheduler unit may manage a plurality of different thread blocks allocating the thread blocks to warps for execution and then scheduling instructions from the plurality of different warps on the various functional units i.e. cores DPUs SFUs and LSUs during each clock cycle.

In one embodiment each scheduler unit includes one or more instruction dispatch units . Each dispatch unit is configured to transmit instructions to one or more of the functional units. In the embodiment shown in the scheduler unit includes two dispatch units that enable two different instructions from the same warp to be dispatched during each clock cycle. In alternative embodiments each scheduler unit may include a single dispatch unit or additional dispatch units .

Each SM includes a register file that provides a set of registers for the functional units of the SM . In one embodiment the register file is divided between each of the functional units such that each functional unit is allocated a dedicated portion of the register file . In another embodiment the register file is divided between the different warps being executed by the SM . The register file provides temporary storage for operands connected to the data paths of the functional units.

Each SM comprises L processing cores . In one embodiment the SM includes a large number e.g. etc. of distinct processing cores . Each core is a fully pipelined single precision processing unit that includes a floating point arithmetic logic unit and an integer arithmetic logic unit. In one embodiment the floating point arithmetic logic units implement the IEEE 754 2008 standard for floating point arithmetic. Each SM also comprises M DPUs that implement double precision floating point arithmetic N SFUs that perform special functions e.g. copy rectangle pixel blending operations and the like and P LSUs that implement load and store operations between the shared memory and the register file via the J texture unit L1 caches and the interconnect network . The J texture unit L1 caches are coupled between the interconnect network and the shared memory and are also coupled to the crossbar . In one embodiment the SM includes 64 DPUs 32 SFUs and 32 LSUs . In another embodiment the L1 cache is not included within the texture unit and is instead included with the shared memory with a separate direct connection to the crossbar .

Each SM includes an interconnect network that connects each of the functional units to the register file and to the shared memory through the interconnect network . In one embodiment the interconnect network is a crossbar that can be configured to connect any of the functional units to any of the registers in the register file to any of the J texture unit L1 caches or the memory locations in shared memory .

In one embodiment the SM is implemented within a GPU. In such an embodiment the SM comprises J texture unit L1 caches . The texture unit L1 caches are configured to access texture maps i.e. a 2D array of texels from the memory and sample the texture maps to produce sampled texture values for use in shader programs. The texture unit L1 caches implement texture operations such as anti aliasing operations using mip maps i.e. texture maps of varying levels of detail . In one embodiment the SM includes 16 texture unit L1 caches . In one embodiment the texture unit L1 caches may be configured to receive load and store requests from the LSUs and to coalesce the texture accesses and the load and store requests to generate coalesced memory operations that are output to a memory system that includes the shared memory . The memory system may also include the L2 cache memory and a system memory not shown .

The PPU described above may be configured to perform highly parallel computations much faster than conventional CPUs. Parallel computing has advantages in graphics processing data compression biometrics stream processing algorithms and the like.

In one embodiment the aforementioned systems may be utilized to implement photon mapping. Photon mapping includes emitting photons tracing photons and computing the scattered radiance by estimating the density of photons i.e. shading etc. . Photon emission and trace steps are similar to path tracing. They produce a series of scattering points along transport paths. Tracing stores an incident photon in a photon map at each scattering point. The choice of data structure for the map depends on the shading algorithm employed later.

Many variations on photon mapping intended for real time rendering of complex scenes have been proposed. Combined with this algorithmic progress GPUs are now powerful enough that photon may be utilized in real time rendering systems.

Efficient parallel ray tracing hardware and software systems such as OptiX can trace hundreds of millions of rays per second and the process can be amortized over multiple frames. Thus existing systems meet the performance needed for photon tracing. Net performance hinges on efficient photon shading. Accordingly architecture aware optimization of photon shading for parallel vector architectures may be implemented to increase the scalability of photon gathering e.g. for achieving film quality lighting in interactive applications etc. and generally advance deferred shading on GPUs utilizing a tiled deferred photon gathering implementation.

As shown in operation a copy of or a pointer to each photon is placed in each screen space tile that would contain the projection of its effect sphere. Furthermore as shown in operation iterations are performed over the pixels in each tile and for each a subset of the photons in the tile is chosen from which to compute shading. Moreover as shown in operation smooth shading is reconstructed at each pixel from the values at its neighbors.

As shown in operation a copy of or a pointer to each photon is placed in each screen space tile that would contain the projection of its effect sphere and photons that do not intersect the depth range of the scene within a tile are culled. Further as shown in operation iterations are performed over the pixels in each tile in chunks and a subset of the photons in the tile is chosen from which to compute shading. Additionally smooth shading is reconstructed at each pixel from the values at its neighbors as shown in operation .

In this way in one embodiment a tiled algorithm may be utilized to insert copies of each photon in buckets corresponding to the screen space tiles it might affect. This allows for a second pass to shade all pixels within a tile from a common subset of photons that fit within shared memory for a compute shader.

In the case where there are more photons in a tile than fit in memory of the implementing system multiple passes may be made over a tile processing sizable chunks of the photons in the tile in each pass. In one embodiment during the process of categorizing the photons into tiles a tiled algorithm may function to cull photons that do not intersect the depth range of the scene within a tile. In scenes with high depth variance that may launch many shading threads that immediately terminate reducing vector lane occupancy without providing useful computation.

Table 1 shows exemplary code illustrative of a tile insertion pass in accordance with one embodiment.

In one embodiment tiles may be further partitioned into chunks each containing a bounded photon count. Each photon consumes little memory thus in one embodiment photons may be duplicated and embedded directly in the chunks instead of utilizing pointers. This also uses the cache efficiently and enables coalesced parallel memory fetches.

In one embodiment a subset of photons may be stochastically selected independently at each pixel. This allows simultaneously sampling over space and photons preserving resolution. Additionally for stochastic sampling during shading as an option statistically independent random numbers at each pixel may be utilized. Cooperative sampling methods may be utilized to dramatically increase convergence by coordinating samples at adjacent pixels. In one embodiment a more sophisticated reconstruction filter may be utilized to reduce the number of samples required to achieve acceptable convergence.

As shown in Table 2 step x refers to a geometrically distributed random number generator representing samples of the number of trials until the first success a Bernoulli random variable with success probability 1 x. In one embodiment the process may include incrementing by this value when iterating through the photon array to randomly sample 1 x photons on average.

The image shows a warehouse in which small gaps create a complex indirect paths for late afternoon sunlight from windows on the far right. In order to generate the image a tiled algorithm was utilized to compute scattered indirect illumination from traced photons for this scene. The inset image with only direct illumination shows the importance of rendering indirect light for this scene as such image is indistinguishable.

In various embodiments a deferred tile algorithm may be implemented as software e.g. a CUDA implementation etc. or as hardware. In one embodiment the tiled algorithm may use an output of a photon trace e.g. computed in OptiX etc. and gather relevant photons onto each pixel in real time. As noted each photon has among other properties a position and a radius of effect in 3D.

In one embodiment the tiled algorithm may be configured to operate in three stages. At a first stage a copy of or a pointer to each photon may be placed in each screen space tile that would contain the projection of its effect sphere. As a second stage the algorithm may function to iterate over the pixels in each tile and for each the algorithm may operate to choose a subset of the photons in the tile from which to compute shading. For the third stage smooth shading may be reconstructed at each pixel from the values at its neighbors.

In various embodiments the tiled deferred shading algorithm may be configured to ensure coherent execution within a vector SIMD architecture implement culling based on depth and perform chunking for handling more photons than fit within shared memory and allowing efficient scheduling when different tiles have different numbers of photons.

Additionally in various embodiments at least portions of the tiled deferred shading algorithm may be directly implemented in a GPU e.g. depth culling etc. . As another option the tiled deferred shading algorithm may be employed for real time rendering in games digital content creation DCC and CAD applications. Furthermore in one embodiment the tiled deferred shading algorithm may function to dramatically increase the scalability of photon gathering e.g. for achieving film quality lighting in interactive applications etc. .

The system also includes input devices a graphics processor and a display i.e. a conventional CRT cathode ray tube LCD liquid crystal display LED light emitting diode plasma display or the like. User input may be received from the input devices e.g. keyboard mouse touchpad microphone and the like. In one embodiment the graphics processor may include a plurality of shader modules a rasterization module etc. Each of the foregoing modules may even be situated on a single semiconductor platform to form a graphics processing unit GPU .

In the present description a single semiconductor platform may refer to a sole unitary semiconductor based integrated circuit or chip. It should be noted that the term single semiconductor platform may also refer to multi chip modules with increased connectivity which simulate on chip operation and make substantial improvements over utilizing a conventional central processing unit CPU and bus implementation. Of course the various modules may also be situated separately or in various combinations of semiconductor platforms per the desires of the user.

The system may also include a secondary storage . The secondary storage includes for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive a compact disk drive digital versatile disk DVD drive recording device universal serial bus USB flash memory. The removable storage drive reads from and or writes to a removable storage unit in a well known manner.

Computer programs or computer control logic algorithms may be stored in the main memory and or the secondary storage . Such computer programs when executed enable the system to perform various functions. For example a compiler program that is configured to examiner a shader program and enable or disable attribute buffer combining may be stored in the main memory . The compiler program may be executed by the central processor or the graphics processor . The main memory the storage and or any other storage are possible examples of computer readable media.

In one embodiment the architecture and or functionality of the various previous figures may be implemented in the context of the central processor the graphics processor an integrated circuit not shown that is capable of at least a portion of the capabilities of both the central processor and the graphics processor a chipset i.e. a group of integrated circuits designed to work and sold as a unit for performing related functions etc. and or any other integrated circuit for that matter.

Still yet the architecture and or functionality of the various previous figures may be implemented in the context of a general computer system a circuit board system a game console system dedicated for entertainment purposes an application specific system and or any other desired system. For example the system may take the form of a desktop computer laptop computer server workstation game consoles embedded system and or any other type of logic. Still yet the system may take the form of various other devices including but not limited to a personal digital assistant PDA device a mobile phone device a television etc.

Further while not shown the system may be coupled to a network e.g. a telecommunications network local area network LAN wireless network wide area network WAN such as the Internet peer to peer network cable network or the like for communication purposes.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

