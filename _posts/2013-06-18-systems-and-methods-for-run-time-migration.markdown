---

title: Systems and methods for run time migration
abstract: A method, system, and non-transitory computer readable medium for safely and efficiently migrating applications from one application server to another is provided. A termination request is received. When an API call has been sent by a first application since a last recurring checkpoint, the sent API call is processed one of several ways. Sometimes the API call is immediately terminated. Alternatively, the first application server waits a waiting period for an answer to the API call, and during the waiting period any new API calls are captured and not sent. Upon completion of the waiting period, if no answer has been returned, the API call is terminated. Then a new checkpoint of the application is taken in order to obtain a new checkpoint data set. The application is then migrated to another application server using the new checkpoint data set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09531805&OS=09531805&RS=09531805
owner: Google Inc.
number: 09531805
owner_city: Mountain View
owner_country: US
publication_date: 20130618
---
The present application claims priority to U.S. Provisional Patent Application Ser. No. 61 661 685 filed Jun. 19 2012 the entire disclosure of which is hereby incorporated by reference.

The disclosed embodiments relate generally to methods and systems sometimes called application servers for hosting and executing large numbers of heterogeneous applications including copying and moving applications from one server to another.

In general increases in an application s popularity could present a variety of scalability problems that negatively impact a user s experience. For example users could experience slower response times slower page loading and increased time outs on page requests. These scalability problems are typically alleviated by allocating additional capacity to the application such as more storage more memory more CPUs and more machines in general.

Allocating or installing more computing capacity may be a reasonable solution when increases in an application s popularity are experienced over a prolonged period of time or when usage of the application is predictable. Similarly when an application experiences a decrease in usage removing computing capacity previously allocated to the application may be a reasonable solution especially when this is experienced over a prolonged period of time or when the decrease is predictable. However the popularity of an application is often unpredictable due to a variety of factors e.g. time of day current events advertising trends etc. and fluctuates to a large extent which creates load spikes and dips in the application execution or hosting system.

Predefined allocations of computing resources are inefficient solutions for handling temporary load spikes and dips. Increasing or installing more computing resources to handle a load spike is inefficient since the additional pre allocated resources go unused when the spike disappears e.g. when the spike in demand subsides or the application s popularity dips . Similarly decreasing computing resources allocated to an application when its popularity declines is also inefficient since future usage spikes will require the re allocation of previously removed resources back to the application.

To complicate matters further application systems may host a large number of heterogeneous applications each with its own set of fluctuating resource requirements. Pre allocation of resources for the reasons discussed above is often an inefficient solution for ensuring consistent positive user experiences among heterogeneous applications hosted on an application system.

Furthermore long running applications may need to be moved from one server to another due to fluctuating demand machine fatigue and or other factors. Moving an application from one server to another can cause errors if the application is moved at an inopportune time. For example it may not be advantageous to move an application when an answer has not yet been returned for an outstanding API call. Determining a good time to move an application from a first server to a second server in order to resume the application in the same state in which it was checkpointed is thus desirable.

The present disclosure overcomes the limitations and disadvantages described above by providing methods systems and non transitory computer readable storage mediums for managing and moving applications on an application execution system having a plurality of application servers.

The following presents a summary of the invention in order to provide a basic understanding of some of the aspects of the invention. This summary is not an extensive overview of the invention. It is not intended to identify key critical elements of the invention or to delineate the scope of the invention. Its sole purpose is to present some of the concepts of the invention in a simplified form as a prelude to the more detailed description that is presented later.

Some embodiments provide a method of managing and moving applications on an application execution system having a plurality of application servers. The method is performed on a first application server in the plurality of application servers having one or more processors memory storing an API interface module and an application. The application is checkpointed on a recurring basis over time e.g. periodically . The migration process begins when a termination request is received. The first application server determines whether an API call has been sent by the application since the last checkpoint. When no API call has been sent since the last checkpoint the API interface module uses the data set associated with the last checkpoint to migrate the application to another application server in the application execution system. When an API call has been sent by the application since the last checkpoint of the application the sent API call is processed in one of several ways. In some embodiments the API call is immediately terminated. In other embodiments the first application server waits a waiting period for an answer to the API call and during the waiting period any new API calls are captured and not sent. Upon completion of the waiting period either an answer has been received or not. If no answer has been returned the API call is terminated. Then a new checkpoint of the application is taken in order to obtain a new checkpoint data set. Depending on the situation this new checkpoint data will include one or more of the following identity information for a terminated API call any answers to API calls received since the last checkpoint and any captured and unsent new API calls. The new checkpoint data set is then used to migrate the application to another application server in the application execution system.

Some other embodiments provide an application execution system having a plurality of application servers. A first application server in the plurality of application servers has one or more processors and memory storing an API interface module and an application. The application on the first application server is checkpointed on a recurring basis over time e.g. periodically . The API interface module on the first application server includes instructions for performing the following. A termination request is received. The first application server determines whether an API call has been sent by the application since the last checkpoint. When no API call has been sent since the last checkpoint the API interface module uses the data set associated with the last checkpoint to migrate the application to another application server in the application execution system. When an API call has been sent by the application since the last checkpoint of the application the sent API call is processed one of several ways. In some embodiments the API call is immediately terminated. In other embodiments the first application server waits a waiting period for an answer to the API call and during the waiting period it captures and does not send any new API calls. Upon completion of the waiting period either the answer has been returned or not. If no answer has been returned the API call is terminated. Then a new checkpoint of the application is taken in order to obtain a new checkpoint data set. Depending on the embodiment this new checkpoint data will include one or more of the following identity information for a terminated API call any answers to API calls received since the last checkpoint and any captured and unsent new API calls. The new checkpoint data set is then used to migrate the application to another application server in the application execution system.

Yet other embodiments provide a non transitory computer readable storage medium storing an API interface module and an application to be executed by one or more processors of an application server in a system having a plurality of application servers. The application on the first application server is checkpointed on a recurring basis e.g. periodically . The API interface module on the first application server includes instructions for performing the following. A termination request is received. The first application server determines whether an API call has been sent by the application since the last checkpoint. When no API call has been sent since the last checkpoint the API interface module uses the data set associated with the last checkpoint to migrate the application to another application server in the application execution system. When an API call has been sent by the application since the last checkpoint of the application the sent API call is processed one of several ways. In some embodiments the API call is immediately terminated. In other embodiments the first application server waits a waiting period for an answer to the API call and during the waiting period it captures and does not send any new API calls. Upon completion of the waiting period either the answer has been returned or not If no answer has been returned the API call is terminated. Then a new checkpoint of the application is taken in order to obtain a new checkpoint data set. Depending on the embodiment this new checkpoint data will include one or more of the following identity information for a terminated API call any answers to API calls received since the last checkpoint and any captured and unsent new API calls. The new checkpoint data set is then used to migrate the application to another application server in the application execution system.

These methods systems and non transitory computer readable storage mediums provide new more efficient ways for an application in an application execution system to be moved from one server to another such that when moved to the new server the application can immediately be restored to a state that application was in when it was terminated on the originating application server. Since moving an application from one server to another can cause errors if the application is moved at an inopportune time it is desirable to determine a good time to terminate move and then resume the application. The description below provides detailed descriptions of various embodiments and mechanisms for determining when and how an application will be advantageously moved from one application server to another.

Reference will now be made in detail to embodiments examples of which are illustrated in the accompanying drawings. In the following detailed description numerous specific details are set forth in order to provide a thorough understanding of the present embodiments. However it will be apparent to one of ordinary skill in the art that the present various embodiments may be practiced without these specific details. In other instances well known methods procedures components and networks have not been described in detail so as not to unnecessarily obscure aspects of the embodiments.

It will also be understood that although the terms first second etc. may be used herein to describe various elements these elements should not be limited by these terms. These terms are only used to distinguish one element from another. For example a first element could be termed a second element and similarly a second element could be termed a first element without changing the meaning of the description so long as all occurrences of the first element are renamed consistently and all occurrences of the second element are renamed consistently. The first element and the second element are both elements but they are not the same element.

The terminology used in the description of the embodiments herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the claims. As used in the description of the embodiments and the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items. It will be further understood that the terms comprises and or comprising as well as the terms includes and or including when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

As used herein the term if may be construed to mean when or upon or in response to depending on the context. Similarly the phrase if it is determined or if a stated condition or event is detected may be construed to mean upon determining or in response to determining or upon detecting the stated condition or event or in response to detecting the stated condition or event depending on the context.

Applications especially long running applications that may run for more than a day may need to be moved from one server to another due to fluctuating demand machine fatigue and or other factors. In order to avoid server failure one option is to move applications from one server to another. Another option is to predict when a server is likely to fail and then move the long running applications before the server fails. For example run times may vary from one server to another. In some instances applications are monitored. When an instance of an application is performing slower than average for that application or slower than desired the application may be a candidate to be moved to another application server. Moving an application from one server to another can cause errors if the application is moved at an inopportune time. For example it may not be advantageous to move an application when an answer has not yet been returned for an outstanding API call. Thus in some embodiments it is desirable to determine if an API call has been sent by an application since a last checkpoint of the application. Furthermore it may not be advantageous to move an application that has an outstanding state changing API call whereas moving an application that has an outstanding non state changing API call but not outstanding state changing API calls may be less problematic. Thus in some embodiments the type of outstanding API call is determined as a part of the process of moving the application from one server to another. Determining a good time to pause serialize move an application from a first server to another server is thus desirable.

In some embodiments the application execution system includes one or more front end servers . The front end server receives application execution requests from clients and returns results to the requesting clients.

The application execution system also includes a plurality of application servers e.g. through . Each of the application servers includes volatile storage for executing one or more applications non volatile storage for storing one or more applications and computational resources for executing applications in response to requests received by the application execution system . In some embodiments a long running application will be moved from a first application server to another application server . This may occur for example because the first application server is taken down for maintenance or is expected to malfunction.

In some embodiments the application execution system also includes an application master that distributes applications from a main library having a plurality of applications among the application servers . In some embodiments the application master communicates with data store which includes information about which application servers accept service requests for a particular application.

In some embodiments the application execution system includes data store that is accessible to each of the application servers for storing applications including applications that are checkpointed in order to be moved from one application server to another. It will be appreciated that data store and date store may in fact be the same physical data store. However they are illustrated as different physical data stores in to emphasize the different roles that they play and to illustrate that the application master does not require access to the checkpointed applications being moved in some embodiments of the present disclosure.

In the embodiment shown in the main library is stored in the application master . In some embodiments each application of the plurality of applications in the main library is a web application that is responsive to HTTP requests. However the present invention can also be used in non web based environments in which case the applications need not be web based applications.

Optionally the distributed system includes additional resources which may be located either internally or externally to the system for use when executing applications in the application execution system . For example an application executed by the application execution system may access information in one or more of the additional resources in order to process a request received from a respective client .

In some embodiments the application is checkpointed on a recurring e.g. periodic basis . Each checkpoint derives a checkpoint data set. In some embodiments the checkpointing is performed in time based periods e.g. every 30 seconds every 1 minute every two minutes every 5 minutes every 15 minutes every 30 minutes every hour etc. In other embodiments the checkpointing is performed in response to a triggering event e.g. it is performed when directed to by an application master . In other embodiments the checkpointing is performed when a certain number of API calls have been sent e.g. after every API call after every 5 API calls after every 10 API calls after every 25 API calls etc. . In other embodiments the checkpointing is performed when a certain number of API answers have been received e.g. after every API answer after every 5 API answers after every 10 API answers after every 25 API answers etc. In other embodiments the checkpointing is performed after a certain number of client requests have been processed e.g. after at least 10 processed client requests after at least 50 processed client requests after at least 100 processed client requests after at least 200 processed client requests etc. It is further noted that in some embodiments recurring checkpoints are not necessary to perform the process described below. For example the process described below is utilized in some implementations after only a single checkpoint e.g. a checkpoint taken in response to a triggering event.

A termination request is received for the first application . In some embodiments the termination request is received from the application master. In other embodiments it is received from the front end server. In still other embodiments it is received from another application server . Alternatively it is received from the first application server itself. For example a self monitoring application server may generate a termination request. In some embodiments a termination requests is generated or received when indication of failure of the first application or the first application server is obtained or detected. For example when the application or application server is responding slower than average or slower than expected a termination request may be generated or received. In other embodiments the termination request may be unrelated to any indication of failure. For example in some embodiments a termination request is generated or received when the application or application server is being taken down for maintenance or when the application is being moved according to an application migration protocol. It is noted that in some embodiments the termination request is received because of an immediate need to terminate the first application e.g. in response to a power failure warning. However in other embodiments the termination request is not necessarily the result of a terminal event. For example a termination request could be received due to a load balancing process as described herein.

After the termination request for the first application is received the following is performed. The application server determines whether an API call has been sent by the first application since a last checkpoint of the first application . In practice the application server determines whether one or more API calls have been sent. However for the sake of discussion and for clarity reference is often made below to a single API call.

As used herein an API call is any request to a service outside of the application itself. In some embodiments an API call is handled by the application server hosting the application. That is the application server hosting the application or another application running on the application server processes the API call and provides a result responsive to the API call back to the requesting application. In some embodiments an API call is handled by a device that is addressable by the application server hosting the application such as a data store or other network component. That is the API call is sent by the application server hosting the application to the device typically over a network. The device processes the API call and provides a result responsive to the API call back to the application server hosting the application and thereby ultimately back to the application.

One of skill in the art will appreciate that an application is any set of instructions that are processed either directly or in compiled form at least in part by a processing unit.

When an API call has not been sent since the last checkpoint no the checkpoint data set associated with the last checkpoint is used for the migration . In some embodiments the last checkpoint data set is sent to another application server e.g. in the plurality of application servers. In other embodiments the last checkpoint data set is sent to shared data store e.g. where it can then be accessed by and moved to another application server e.g. . In other embodiments the last checkpoint data set is sent to the application master e.g. where it can then be accessed by and moved to another application server e.g. .

When an API call has been sent since the last checkpoint by the first application yes the API call is processed as follows. The application server determines whether the API call is still outstanding since the last checkpoint e.g. the application server determines whether an answer to the API call has been received .

When an answer to the API call has been received e.g. when the API call is not outstanding yes then a new checkpoint data set including the answer to the API call is recorded . In other words a new checkpoint of the first application is taken in order to obtain a new checkpoint data set . In this instance the new checkpoint data set includes an answer to the sent API call. The new checkpoint data set is then used for the migration . In some embodiments the new checkpoint data set is sent to another application server e.g. in the plurality of application servers. In other embodiments the new checkpoint data set is sent to a shared data store e.g. where it can then be accessed by and moved to another application server e.g. . In other embodiments the new checkpoint data set is sent to the application master e.g. where it can then be accessed by and moved to another application server e.g. . It is noted that the above described embodiments of where the new checkpoint data is sent are true for each new checkpoint data set described below as well.

When an answer to the API call answer has not been received e.g. when the API call is outstanding no the application server determines whether to wait a waiting period for the API call answer . It is noted that more than one API call may have been sent and received an answer since the last checkpoint but for the purposes of the processes described here which follows the determination of no at least one API call answer is still outstanding.

In some embodiments the application server determines whether to wait a waiting period for the API call answer based on the type of outstanding API call. For example in some embodiments if the outstanding API call is a state changing API call e.g. it is a write not a read operation then the application server determines to wait for the answer or to wait at least a waiting period for the answer. In some embodiments if the outstanding API call is non state changing then the application server determines not to wait a waiting period for the answer. It is noted that in some other embodiments the application server may not wait a waiting period when the application server of the application is eminently expected to fail.

In some embodiments if the outstanding API call is a state changing API call e.g. it is a write not a read operation then the application server determines to wait at least a first waiting period for the answer. And if the outstanding API call is non state changing the application server determines to wait a second period for the answer where the first waiting period is longer than the second waiting period.

When the application server determines not to wait a waiting period for the API call answer no then the at least one outstanding API call is terminated . Then a new checkpoint data set including the identity information for the terminated API call is recorded . In other words a new checkpoint of the first application is taken in order to obtain a new checkpoint data set . In this embodiment the new checkpoint data set includes at least the identity information for the terminated API call but it may also include answers to any sent API calls that have been returned since the last checkpoint was recorded. This new checkpoint data set is then used for the migration . As described above for migration the new checkpoint data set may be sent to the shared data store e.g. sent to the application master e.g. or sent directly to another application server e.g. in the plurality of application servers depending on the embodiment employed.

When application server determines to wait a waiting period for the API call answer yes then the process A continues as shown in . The application server waits a waiting period for an answer to the outstanding API call . It is noted that in some embodiments the waiting period is 0.5 to 2 seconds 2 to 5 seconds 5 to 10 seconds 10 to 30 seconds 30 seconds to 1 minute 1 to 2 minutes 3 to 5 minutes 5 to 15 minutes 15 to 30 minutes or 30 minutes to one hour. In other embodiments the waiting period is determined based how frequently the application has historically made API calls. In some embodiments the waiting period is determined based on how recently the application was checkpointed. In some embodiments the waiting period is determined based the health of the application. For example it the application is expected to die within the next hour then the waiting period is significantly less than an hour such as for example 10 minutes to half an hour 5 to 10 minutes 1 to 5 minutes or 1 minute or less.

During the waiting period the application server captures and does not send out any new API calls it receives . Upon completion of the waiting period the application server determines whether the API call has been received .

If the API call answer has been received during the waiting period yes then a new checkpoint data set including the API call answer is recorded . In other words a new checkpoint of the first application is taken in order to obtain a new checkpoint data set . In this embodiment the new checkpoint data set includes at least the API call answer. It will also include any API calls that were captured and not sent during the waiting period and will additionally include answers to any sent API calls that were returned since the last checkpoint was recorded. This new checkpoint data set is used for the migration . As described above the new checkpoint data set may be sent to the shared data store e.g. sent to the application master e.g. or sent directly to another application server e.g. in the plurality of application servers depending on the embodiment employed.

If the API call answer has been not been received during the waiting period no then the outstanding API call is terminated or recorded as in progress . Then a new checkpoint data set including the identity information for the API call is recorded . In other words a new checkpoint of the first application is taken in order to obtain a new checkpoint data set . In this embodiment the new checkpoint data set includes at least the identity information for the API call. This new checkpoint data set is used for the migration . As described above the new checkpoint data set may be sent to the shared data store e.g. sent to the application master e.g. or sent directly to another application server e.g. in the plurality of application servers depending on the embodiment employed. As such the new checkpoint data set can be termed a migration checkpoint dataset. 

It will be appreciated that a reply to the API call may be received after the migration checkpoint dataset has been migrated to a new migration destination. Some embodiments advantageously make use of this by migrating the reply to the API call to the same destination as the migration checkpoint dataset. In such embodiments this alleviates the need to rerun the API call at the migration destination. This is particularly useful in instances where the reply is to an API call that took a long time to run but nevertheless was high priority. Thus in some embodiments the original server holds onto any response it receives to the API call from the termination application for a predetermined waiting period and forwards the reply to the same migration destination as the migration checkpoint dataset. In such embodiments the response is reconstituted with the migration checkpoint dataset at the migration destination.

In some embodiments the new server migration destination informs the original application server to forward the response to the API call the terminated application made on the original application server. Of course the migration destination has the option of cancelling the outstanding API call in the migration checkpoint dataset set and rerunning the API call at the migration destination.

One benefit of migrating responses to API calls that are received after the migration checkpoint dataset has been formed in the manner described above is that when the original application server stabilizes or is not powered off as was expected to happen in some embodiments the replies to the API calls are not lost and thus there is little or minimal loss in application performance.

The migration checkpoint dataset will include any API calls that were captured and not sent during the waiting period as well as answers to any sent API calls that were returned since the last checkpoint was recorded e.g. the checkpoint immediately prior to the migration checkpoint dataset .

The local library data includes information e.g. application identifiers identifying the applications installed on the application server. Optionally local library data includes additional information such as distribution date information or version information for the listed applications. The information in the local library data for a respective application server is received from that application server and may be stored at the application server either as a distinct data structure or together with the local application library itself or in combination with other information retained by the application server.

In some embodiments a single application will be moved from a first application server to another application server . For example the application may be running slower than its demand on the first application server and moving it to another application server will allow the application to run more quickly. In such embodiments the data structure is useful in identifying the respective application e.g. Application ID and moving it at an in accordance with the procedures described above. In other embodiments the entire application server maybe taken off line. In such instances many if not all of the applications installed on the application server will be moved. In these embodiments the data structure is useful in identifying each of the applications to to be moved.

The data structure stores a respective record for each application to which the front end may need to route application execution requests. This record may be called an application distribution map. In some embodiments the record for a respective application includes the following information an identifier of the application and distribution data for the application. The distribution data includes a list of identifiers or other information identifying the application servers that currently have a copy of the application in their local libraries and will accept service requests for the application corresponding application type. Optionally the front end application server may include in the resource data for a particular application server the number of application execution requests that have been sent to the application server over a defined period of time e.g. the past hour and or the number of outstanding or queued requests that are pending at the application server. The resource data stored by the front end for a respective application server may comprise averages or running averages of resource usage by the applications being executed by the respective application server.

In some embodiments the front end server receives at least a portion of the application distribution map from the data structure or in some embodiments from the application master or a cached copy thereof. As noted above the application distribution map optionally includes resource usage information that can be used to route requests received from client s . For example upon receiving a request from a client to execute a specified application the front end server accesses the corresponding record of application distribution map for the specified application or the cached copy thereof to determine the application servers that will accept service requests for that application. In some embodiments the front end server routes such requests using a round robin methodology e.g. in round robin order within the list of application servers in the record for the application or a random assignment methodology e.g. randomly or pseudo randomly among the application servers listed in record . An example of such a random assignment methodology is a Monte Carlo technique.

In some other embodiments the front end server routes requests based on current and historical load information that the front end server has observed directly. Two load metrics that the front end server can observe directly are the number of application execution requests that the front end server has recently sent to each application server and the number of currently outstanding application execution requests at each application server e.g. the number of recent application execution requests sent to each application server which have yet to return results or a completion signal . It is noted that the number of pending application execution requests also called currently outstanding application execution requests is a latency metric and thus measures performance from the perspective of the system s users. Using this information which may be observed and stored by the front end server the front end server may route application requests. For example the front end server may route a request to the application server that A will accept service requests for the requested application and B has the least number of outstanding requests. In another example the front end server may route a request to the application server that A will accept service requests for the requested application and B has the least number of outstanding requests for the requested application.

Each of the above identified elements may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

Each of the above identified elements may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs e.g. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

In some embodiments the application master interface module includes procedures for adding and removing applications from the non volatile storage of the application server.

In some embodiments the front end interface module includes procedures for handling application requests Handle Request Module forwarded from the front end server .

In some embodiments live process cache monitor and control includes procedures Load and Remove Application Instance Module for loading and removing application instances into the live process cache in accordance with application usage and available volatile memory procedures Execute Application Instance Module for executing application instances when processing application requests. The Execute Application Instance Module may also include procedures Resource Limit Enforcement for limiting resource consumption of a particular application. For example an application that consumes more resources than a limit or threshold may be terminated Terminate App Instance . The resource limit may be a predefined amount or the threshold may vary depending on factors such as the number of requests for the application. For example applications that receive higher numbers of requests may have a higher threshold before the application instance is terminated. Alternatively the threshold may also depend on the amount of processing resources e.g. one or more of CPU time wall clock time e.g. total elapsed real time memory communication bandwidth and number of system function calls made consumed by the application. The threshold s may be applied per execution of an application or to a running average of resources used over multiple executions of the application. An application instance that consumes resources above a corresponding threshold may be terminated.

In some embodiments the API interface module for managing procedures for migrating an application from the application server system to a separate application server includes a variety of modules to perform various aspects of the migration. The API interface module includes an API Call Status Module which is used to determine whether an API call has been sent by a first application since a last checkpoint of the first application in response to receiving a termination request for the first application . The API interface module also includes a Waiting Period Determination Module which determines whether to wait a waiting period for an answer to an outstanding API call and also determines how long the waiting period if any will be. The API interface module further includes an API Call Capture Module which captures and does not send any new API calls received during a waiting period and provides the captured and unsent API calls for a new checkpoint data set. The API interface module also includes an API Call Termination Module for terminating the outstanding API calls in accordance with the procedures methods described with respect to . The API interface module includes a New Checkpoint Determination Module which determines when to take a new checkpoint and what data should be obtained in the new checkpoint data set to be stored in checkpoint data sets . The API interface module additionally includes an Application Migration Module which migrates the application from the application server system to a separate application server using either a new data set obtained by the New Checkpoint Determination Module or the checkpoint data set associated with the last checkpoint depending on the process determined and performed by the above described modules. Furthermore the Application Migration Module determines whether the data set used in the migration will be sent to a shared data store e.g. the application master e.g. or to another application server e.g. depending on the embodiment employed.

Each of the above identified elements in may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

Although show an application master a front end server and an application server respectively these figures are intended more as functional descriptions of the various features which may be present in a set of servers than as a structural schematic of the embodiments described herein. In practice and as recognized by those of ordinary skill in the art items shown separately could be combined and some items could be separated. For example some items shown separately in or could be implemented on single servers and single items could be implemented by one or more servers. The actual number of servers used to implement each such subsystem and how features are allocated among them will vary from one implementation to another and may depend in part on the amount of data traffic that the system must handle during peak usage periods as well as during average usage periods.

The foregoing description for purpose of explanation has been described with reference to specific embodiments. However the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications to thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated.

