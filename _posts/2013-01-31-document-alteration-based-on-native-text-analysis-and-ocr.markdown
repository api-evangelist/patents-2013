---

title: Document alteration based on native text analysis and OCR
abstract: Example embodiments relate to document alteration based on native text analysis and optical character recognition (OCR). In example embodiments, a system analyzes native text obtained from a native document to identify a text entity in the native document. At this stage, the system may use a native application interface to convert the native document to a document image and perform OCR on the document image to identify a text location of the text entity. The system may then generate an alteration box (e.g., redaction box, highlight box) at the text location in the document image to alter a presentation of the text entity.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09256798&OS=09256798&RS=09256798
owner: Aurasma Limited
number: 09256798
owner_city: Cambridge
owner_country: GB
publication_date: 20130131
---
Often it is desirable to modify a document in some way before reproducing it for distribution to others. For example a user may wish to alter e.g. redact highlight etc. portions of text or images in a document before distributing it in order to maintain confidentiality. Typically the user manually reviews the document and designates portions of the document for alteration prior to production.

As discussed above users often wish to alter e.g. redact highlight portions of documents before producing the documents to other parties. For example a user may wish to redact all occurrences of social security numbers from documents in order to protect the privacy of their respective holders. However altering documents manually is a time consuming process that is susceptible to errors and oversights. To address this issue the user may use an automated alteration process that is capable of recognizing portions of the documents for alteration.

Various document production applications exist that are capable of automatically redacting portions of a document. For example a document production application may perform optical character recognition OCR on a scanned document to identify phone numbers for redaction. In this example the document production application may identify candidates for redaction that are reviewed by a user. Alternatively the document production application may automatically redact the identified phone numbers. In either case the quality of the OCR may affect the recall of the identified portions for redaction. In this example recall may be represented as the proportion of actual phone numbers that were identified by the document production application. For instance if the scanned document includes five phone numbers and four of the phone numbers were identified the recall of the analysis performed by the document production application would be 80 .

In another scenario document production applications may analyze and convert native documents to document images that include alterations. For example a document production application may analyze a formatted native document to identify social security numbers and then convert the formatted native document to a document image while simultaneously redacting the social security numbers. In this example the document production application applies a third party application that simulates the formatting of the native document to generate the document image. As a result the formatting in the document image may not accurately depict the native document as viewed in a corresponding native application.

Example embodiments disclosed herein provide document alteration based on native text analysis and OCR that is based on native text in a native document and OCR results of a document image rendered from the native document using a corresponding native application. For example in some embodiments a computing device analyzes native text from the native document to identify text entities e.g. social security numbers phone numbers account numbers etc. of the native document that should be altered. At this stage the native document may be converted to a document image using a native application interface where the document image depicts the native document as it would be rendered by a native application associated with the native document. OCR may then be performed on the document image to recognize the characters and or words in the document image and to determine the corresponding bounding rectangles for those characters and or words. Based on the results of the OCR locations of the text entities to be altered may be determined and altered in the document image.

In this manner example embodiments disclosed herein improve the recall of automated alteration by analyzing native text of a native document and a native image conversion of the native document. Specifically by performing a combined analysis of the native text and the document image text entities in the document to be altered may be more consistently detected and represented. The use of the native image conversion creates more aesthetically pleasing images and allows for a more accurate visual representation of the document to be produced. Further because the results of OCR performed on the document image can be enhanced with further analysis at a word level advanced matching algorithms e.g. stemming may be used to determine the text locations of the text entities in the document image.

Referring now to the drawings is a block diagram of an example computing device for document alteration based on native text analysis and OCR. Computing device may be for example a notebook computer a desktop computer an all in one system a tablet computing device a mobile phone an electronic book reader a printing device or any other electronic device suitable for processing native documents for production. In the embodiment of computing device includes a processor and a machine readable storage medium .

Processor may be one or more central processing units CPUs microprocessors and or other hardware devices suitable for retrieval and execution of instructions stored in machine readable storage medium . Processor may fetch decode and execute instructions to enable document alteration based on native text analysis and OCR. As an alternative or in addition to retrieving and executing instructions processor may include one or more electronic circuits comprising a number of electronic components for performing the functionality of one or more of instructions .

Machine readable storage medium may be any electronic magnetic optical or other physical storage device that stores executable instructions. Thus machine readable storage medium may be for example Random Access Memory RAM an Electrically Erasable Programmable Read Only Memory EEPROM a storage drive an optical disc and the like. As described in detail below machine readable storage medium may be encoded with executable instructions for document alteration based on native text analysis and OCR.

Native text analyzing instructions may obtain native text from a native document. For example native text may be extracted from a word processing document a spreadsheet a presentation etc. After receiving the native text the text analyzing instructions may then analyze the native text to identify text entities i.e. portions of the native text to be altered e.g. redacted highlighted in the native document. Each of the text entities may be identified as matching a text pattern such as but not limited to a social security number a bank account number a phone number a selected word or name etc. The identified text entities may be stored and associated with the native document so that they may be accessed as discussed below by the alteration box generating instructions .

The native document may be any stored file that includes text. For example the native document may be a word processing document a spreadsheet a presentation a file based database a text file etc. In this example each of the native documents may be associated with a document type that may be represented by the extension of the file e.g. a doc file extension indicates that the native document is a word processing file a dbf file extension indicates that the native document is a database file an xml file extension indicates that the native document is an extensible markup language file etc. . A file extension may be used to determine a native application that is suitable for accessing and or modifying a corresponding native document. For instance a text editor can be identified as the appropriate native application for accessing a text file based on the txt file extension. In another example a metadata field of the native document may be used to determine its document type. Specifically a metadata field may be obtained from analysis of the header of the native document to identify the native application that should be used to access the native document.

In some cases the text entities may be identified in the native text using recognition techniques such as named entity recognition. Named entity recognition may be applied to native text to identify and categorize text entities into predefined text categories e.g. identification numbers locations organizations individuals dates etc. . Once a text entity is identified and categorized it may be determined whether the text entity should be altered. Particular text categories may be redacted regardless of their content e.g. an identification number such as a social security number or driver s license number phone numbers etc. . In other cases a text entity in a particular text category may be redacted if it satisfies search criteria. For example a text entity categorized as an individual may be redacted if it matches a name included in a list of predetermined names that should be redacted. Alternatively the text entities in the particular text category may be designated for redaction using pattern matching e.g. regular expressions wildcards literal character strings etc. . Particularly text categories may be similarly designated for highlighting as discussed above.

Native document converting instructions may convert a native document to a document image. Specifically native document converting instructions may provide the native document to a native application interface and receive the document image as output. The native application interface is capable of rendering the native document in its native form as a document image i.e. the document image presents the native document as it would be presented if viewed in the corresponding native application . Native document converting instructions may also determine which native application interface to use based on the document type of the native document. In this case native document converting instructions may have access to numerous native application interfaces for a variety of document types.

Optical character recognition instructions may perform OCR on the document image generated by the native document converting instructions . Specifically OCR recognizes the characters in the document image as text and generates a bounding rectangle for each of the characters. A bounding rectangle is described by bounding coordinates on vertical and horizontal axes that form a geometric rectangle surrounding a corresponding character or word in the document image. In some cases the bounding rectangle also includes a buffer area that extends the area surrounding the character. In this case the buffer area may be determined using a preconfigured surrounding threshold that defines the additional area i.e. additional height and width that should be included in the bounding rectangle. Further the preconfigured surrounding threshold may be a random value within a range of potential values so that the buffer area is a different height and width for each bounding rectangle. The buffer area may ensure that redaction boxes generated using the bounding rectangle better obfuscate the redacted character or word.

Optical character recognition instructions may also perform further analysis to identify words based on the recognized characters. Specifically optical character recognition instructions may use the location of space characters to identify words in the document image. In this case the average width of the space characters may be analyzed to locate superfluous spaces in the recognized characters. For example a space character with a width that is significantly less than the average width may be determined to be superfluous and be ignored when identifying words in the document image. Similar to as discussed above with respect to characters bounding rectangles may also be generated for each of the words where the bounding rectangles can include a buffer area to better obfuscate the words.

Alteration box generating instructions may generate alteration boxes for text entities identified by the native text analyzing instructions . Initially alteration box generating instructions may use the characters and or words recognized by the optical character recognition instructions to determine the text locations of the text entities in the document image. For example alteration box generating instructions may search the characters and or words for matches to the text entities. In this example advanced matching techniques such as stemming may be used to identify closely matching words in the OCR results to the text entities. Each matching set of characters and or words may be designated as a text location of a corresponding text entity. After the text locations are determined alteration boxes e.g. redaction boxes highlight boxes may be generated using the bounding rectangles of the matching characters and or words. In response to generating the redaction boxes alteration box generating instructions may create an updated document image that includes the redactions or highlights. In some cases the updated document image may include both redactions and highlights. In this case particular text categories may be designated for redaction while others are designated for highlighting.

Native application interface may be an application programming interface API that provides access to native functions of a native application. For example native application interface may be loaded as a dynamic linked library DLL shared library or statically linked library that is accessible to other modules e.g. native module of computing device . Native functions provided by the native application interface may include a print function that receives a native document as input and prints the native document to a selected format e.g. hard copy portable document format image etc. with its native formatting. In the case of the image format the native print function creates more aesthetically pleasing images and allows for more accurate visual representations in the document images to be generated from the native documents.

As illustrated in and described in detail below computing device may also include a number of modules . Each of the modules may include a series of instructions encoded on a machine readable storage medium and executable by a processor of computing device . In addition or as an alternative each module may include one or more hardware devices comprising electronic circuitry for implementing the functionality described below.

Native module may access and analyze native documents for the purpose of identifying text entities to be altered e.g. redacted highlighted in the native documents. Native text may refer to the content of the native document without formatting information. Native text analysis module may obtain and analyze native text from a native document. For example native text analysis module may extract the native text directly from the native document if the native document is a markup language file e.g. extensible markup language file hypertext markup language file etc. . In another example if the native document is a binary file the native text analysis module may use the native application interface to obtain the native text from the native document. Alternatively the native text analysis module may be configured to access particularly binary file formats directly in order to obtain the native text from the native document.

After obtaining the native text native text analysis module may analyze the native text to identify text entities for alteration. As discussed above with respect to the text entities may be identified by using recognition techniques such as named entity recognition or by using pattern matching that is facilitated by regular expressions wildcards etc. The identified text entities may be stored for later use by or provided directly to the alteration module for further processing.

Native conversion module may convert native documents to document images for further processing by the optical character recognition module . Specifically native conversion module may use native application interface as discussed above to convert native documents to document images. After converting a native document to a document image native conversion module may associate the document image with the text entities identified for the native document by the native text analysis module .

Optical character recognition module may perform OCR on the document images generated by native conversion module . For example optical character recognition module may perform OCR as discussed above with respect to optical character recognition instructions of . The results e.g. characters words bounding rectangles etc. of the OCR may be stored for later use by or provided directly to the alteration module for further processing. In some cases the optical character recognition module may not have the capability to recognize words in the document image. In this case the geometry analysis module may use the characters and bounding rectangles in the OCR results to identify words and to generate corresponding bounding rectangles.

Alteration module may generate alteration boxes e.g. redaction boxes highlight boxes for native documents based on text entities identified by the native module and OCR results provided by the optical character recognition module . Geometry analysis module may search the OCR results of a document image to determine text locations of text entities identified in the native document as discussed above with respect to alteration box generating instructions of . Specifically geometry analysis module may search for characters and or words in the OCR results that match the text entities from the native document and then determine the text locations based on the corresponding bounding rectangles of any matching characters and or words. For example geometry analysis module may search the OCR results of a document image for a social security number identified in a corresponding native document. If characters matching the social security number are found geometry analysis module may determine the text location of the social security number as the combination of the bounding rectangles of the matching characters. Alternatively the optical character recognition module may be configured to perform searches for characters and or words in the OCR results.

Alteration box module may generate alteration boxes e.g. redaction boxes highlight boxes based on the text locations determined by the geometry analysis module . In response to generating the alteration boxes alteration box module may create an updated document image that includes the alteration boxes. Alternatively the alteration box module may store the alteration boxes for later use.

Method may start in block and continue to block where computing device may analyze native text from a native document to identify a text entity. Specifically named entity recognition may be performed to categorize the text entity where the text entity is then optionally analyzed to determine if it should be altered. For example a text entity categorized as being an identification number may be redacted regardless of its actual content i.e. no further analysis is required . In another example a text entity categorized as being a location may be highlighted if it matches an address included in a list of predetermined confidential addresses.

Next in block computing device may use a native application interface to convert the native document to a document image. For example computing device may use a native application interface to convert the native document to a document image. The native application interface may convert the native document such that the document image is formatted the same as the native document when viewed in a corresponding native application.

In block computing device may perform OCR on the document image to identify the text location of the text entity. Initially computing device may recognize the characters in the document image and generate a bounding rectangle for each of the characters. Further computing device may recognize words in the document image based on the recognized characters. In this case the words may be recognized by grouping characters occurring between space characters into words. In other cases languages that do not use the English alphabet e.g. Chinese may include implicit splits between words other than space characters that could be used to recognize the words. For instance a Chinese language document may be analyzed using a lexicon to perform context specific word segmentation that identifies the implicit splits. After the OCR is performed the characters and or words may be searched to identify a portion of the document image that matches the text entity identified in block . At this stage the bounding rectangles of the characters and or words in the matching portion of the document image may be combined to generate the text location of the text entity.

In block an alteration box e.g. redaction box highlight box is generated based on the text location determined in block . The text location may be described as a bounding rectangle which is used to generate an alteration box to alter e.g. conceal highlight the text entity in the document image. In the case of redaction the text location may already include a buffer to cover additional area surrounding the text entity where the additional area further obfuscates the underlying text entity. Alternatively a buffer may be added to the text location when generating the redaction box. In response to generating the alteration box the document image may be modified to include the alteration box to conceal the text entity. Method may subsequently proceed to block where method may stop.

Method may start in block and proceed to block where computing device may analyze native text to identify text entities in a native document. The native text may be obtained from the native document using a native application interface. Once the native text is obtained named entity recognition may be performed on the native text as discussed above to identify the text entities.

Next in block computing device may use the native application interface to convert the native document to a document image. Specifically the computing device may call a print or similar function in the native application interface to generate the document image where the document image is formatted as if the native document is being viewed in a corresponding native application.

In block computing device recognizes characters in the document image. For example computing device may perform OCR on the document image to recognize the characters and to generate a bounding rectangle for each of the characters. In block anomalies are detected in the character widths of the characters recognized in block . For example the widths of the space characters may be analyzed to identify extraneous spaces with widths that differ greatly from the average width of a space character. In this example the extraneous spaces may be removed from the OCR results obtained in block .

In block computing device may recognize words in the document images. Specifically computing device may group characters occurring between space characters into words. Computing device may also identify words and word boundaries using a lexicon to perform context specific word segmentation. Further in block bounding rectangles may be generated for the words by combining the bounding rectangles of the grouped characters.

At this stage the text entities identified in block may be sequentially analyzed. In block it may be determined if there are any recognized words in the document image that match the next text entity in the list of text entities. Specifically pattern matching analysis may be performed to search for any recognized words that match the next text entity where advanced pattern matching techniques such as stemming may be applied to also match variations of the next text entity. For example a stemming match technique may match variations of a root portion of the text entity to a matching word recognized in block e.g. read is a root portion of the word reading where read may be matched to read reading reads etc. . If there is no match for the next text entity method may proceed to block where method may stop.

If there is a match for the next text entity method may proceed to block where bounding rectangle s are identified as the text location of the next text entity in the document image. For example the bounding rectangle s of the characters and or words matched in block may be identified as the text location of the next text entity. In block an alteration box e.g. redaction box highlight box may be generated at the text location in the document image. Specifically the bounding rectangle s identified in block may be combined to generate the alteration box. In the case of redaction a buffer area may be added to the redaction box to further obfuscate the underlying text entity by concealing the actual width and or height of the text entity.

In block it may be determined if there are more text entities to process from the list of text entities identified in block . If there are no more text entities to process method proceeds to block where method may stop. If there are more text entities to process method proceeds to block where method may proceed as discussed above with respect to blocks .

Method may start in block and proceed to block where computing device may perform named entity recognition on native text to categorize text entities in a native document. The native text may be obtained from the native document using a native application interface. Once the native text is obtained named entity recognition may be performed on the native text to categorize detected text entities into predefined text categories e.g. identification numbers locations organizations individuals dates etc. . In block once the text entities are identified and categorized it may be determined whether each of the text entities should be altered e.g. redacted highlighted based on its predefined text category. In some cases particular text categories may be redacted regardless of their content e.g. an identification numbers such as a social security number or driver s license number phone numbers etc. may be redacted regardless of content . In other cases a text entity in a particular text category may be redacted if it satisfies a pattern match. Particularly text categories may be similarly designated for highlighting as discussed above.

Next in block computing device may use the native application interface to convert the native document to a document image. Specifically the computing device may call a print or similar function in the native application interface to generate the document image where the document image is formatted as if the native document is being viewed in a corresponding native application.

In block computing device recognizes characters and words in the document image. For example computing device may perform OCR on the document image to recognize the characters and to generate a bounding rectangle for each of the characters. Further computing device may also recognize words in the document images by grouping recognized characters occurring between space characters into words. In other cases languages that do not use the English alphabet e.g. Chinese may include implicit splits between words other than space characters that could be used to recognize the words. In block bounding rectangles may be generated for the words by combining the bounding rectangles of the grouped characters.

At this stage the text entities identified in block may be sequentially analyzed. In block it may be determined if there are any recognized words in the document image that match the next text entity in the list of text entities. Specifically pattern matching analysis may be performed to search for any recognized words that match the next text entity where advanced pattern matching techniques such as stemming may be applied to also match variations of the text entity. If there is no match for the next text entity method may proceed to block where method may stop.

If there is a match for the next text entity method may proceed to block where a count i.e. quantity is incremented for the predefined text category of the next text entity. For example if the next text entity is an identification number the count of matched identification numbers may be incremented. In block bounding rectangle s are identified as the text location of the next text entity in the document image. For example the bounding rectangle s of the characters and or words matched in block may be identified as the text location of the next text entity. In block an alteration box e.g. redaction box highlight box may be generated at the text location in the document image. Specifically the bounding rectangle s identified in block may be combined to generate the alteration box. In the case of redaction a buffer area may be added to the redaction box to further obfuscate the underlying text entity by concealing the actual width and or height of the text entity.

In block it may be determined if there are more text entities to process from the list of text entities identified in block . If there are more text entities to process method proceeds to block where method may proceed as discussed above with respect to block . If there are no more text entities to process method proceeds to block where the count of text entities with matches in the OCR results for each of the predetermined text categories is displayed. For example computing device may display a notification that ten identification numbers of the twelve identifications numbers and that eight addresses of the nine addresses identified in block were matched and altered. The count of matches may be related to the recall achieved by the iterative document alteration of method where recall is the proportion of actual text entities that are altered in the document. Method may then proceed to where method may stop.

The foregoing disclosure describes a number of example embodiments for document alteration based on native text analysis and OCR by a computing device. In this manner the embodiments disclosed herein enable document alteration based on native text analysis and OCR by analyzing native text of a native document and OCR results of a document image converted from the native document.

