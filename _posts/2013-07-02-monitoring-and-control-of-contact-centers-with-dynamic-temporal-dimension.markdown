---

title: Monitoring and control of contact centers with dynamic temporal dimension
abstract: A system with a dynamic temporal dimension for monitoring and control of contact centers, comprising: a scalable simulation service configured with a virtual environment that replicates and is maintained in synchrony with a production contact center environment; an analysis manager; a persistent query service; and a visualizer. The persistent query service receives data from contact center systems and updates virtual tables based on the updates; the analysis manager, sends real-time updates to the visualizer, and the visualizer updates a visualization provided to a user by displaying the real-time updates as a set of past states; and the scalable simulation service performs a time-warped simulation to compute at least a future state of one of the virtual environments and sends a second plurality of updates to the visualizer, and the visualizer updates the visualization provided to the user by displaying the second plurality of real-time updates as a projected future state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08788254&OS=08788254&RS=08788254
owner: Aria Solutions, Inc.
number: 08788254
owner_city: Calgary
owner_country: CA
publication_date: 20130702
---
This application is a continuation of U.S. patent application Ser. No. 13 839 725 titled MONITORING AND CONTROL OF CONTACT CENTERS WITH DYNAMIC TEMPORAL DIMENSION which is a continuation in part of U.S. patent application Ser. No. 13 792 058 titled HIGH PERFORMANCE REAL TIME RELATIONAL DATABASE SYSTEM AND METHODS FOR USING SAME filed on Mar. 9 2013 which claims priority to U.S. patent application Ser. No. 61 682 756 filed on Aug. 13 2012 the entire specifications of each of which is hereby incorporated by reference in its entirety. This application is related to co pending and co owned U.S. patent application Ser. No. 12 804 750 titled SYSTEM AND METHOD FOR TIME VIRTUALIZATION IN COMPUTER SYSTEMS which was filed on Jul. 27 2010 the entire specification of which is hereby incorporated by reference in its entirety.

The invention relates to the field of operations management systems and particularly to the field of advanced real time monitoring and control systems using a dynamic temporal dimension.

Business reporting or enterprise reporting is a fundamental part of identifying the capabilities and performance metrics within an organization to convert into knowledge to improve efficiency and overall performance of people systems and processes within the organization. To support better business decision making businesses rely on large amounts of information for example transactional log files system configuration information human resource information customer transaction data path analytics etc. produced by management systems that provides managers with information about sales inventories and other data that would help in managing and improving the enterprise.

With the dramatic expansion of information technology and a desire for increased competitiveness in corporations there has been an enormous increase in the capture of large datasets representing every facet of business processing customer transactions and other data to understand and improve how the business functions often referred to as Big Data . As such computing power to produce unified reports for example those that join different views of the enterprise in one place has increased exponentially. This reporting process involves querying data sources with different logical models to produce a human readable report. For example in a customer service communication center environment a manager may query a human resources database an employee performance database a set of transactional logs and real time metrics to identify where resources may require improvement and further training.

The problem with systems known in the art is that the cause of inefficiencies that appear in many complex interaction management systems issues are never fully understood or the true cause understood or remedied due to the nature of how large datasets are presented which is typically as linear text files that are often many gigabytes in size. Using such a mechanism becomes prohibitive for human analysis and understanding. Furthermore the ability to move to focus to a point in time of when the issue happened is not coherent when using a text file interface.

To remedy this situation various techniques have been tried in the art for example a tabular presentation of data or a collection of common objects and color coding text elements however this only provides a very limited improvement in data analysis of large complex data sets.

What is needed is a highly responsive system and methods to provide a graphical representation that enable users to better understand the data and use it to achieve tactical and strategic objectives. Furthermore a system that provides the ability to generate simulation data based on a knowledge of the behavior of the environment and give the ability for users to perform experimentation by changing system parameters in a controlled environment would increase the efficiency of businesses with large complex data sets.

Accordingly the inventor has conceived and reduced to practice in a preferred embodiment of the invention a system for monitoring and control of contact centers with dynamic temporal dimension and various methods of using the same.

According to a preferred embodiment of the invention a system with a dynamic temporal dimension for monitoring and control of contact centers is disclosed comprising a scalable simulation service stored and operating on a plurality of network attached computers and configured with a virtual environment that replicates and is maintained in synchrony with a production contact center environment an analysis manager stored and operating on a network attached computer a persistent query service stored and operating on a plurality of network attached computers and coupled to a network attached data store and a visualizer stored and operating on a network connected computer. According to the embodiment the persistent query service receives data from a plurality of contact center systems and updates a plurality of virtual tables based at least on the received data updates the analysis manager based at least on changes in one or more persistent queries sends a first plurality of real time updates to the visualizer and the visualizer thereupon updates a first visualization provided to a user of the state of a production contact center by displaying the first plurality of real time updates as a set of past states of the production contact center environment and the scalable simulation service based at least on changes in one or more persistent queries performs a time warped simulation to compute at least a future state of one of the virtual environments and sends a second plurality of real time updates to the visualizer and the visualizer thereupon updates the first visualization provided to the user by displaying the second plurality of real time updates as a projected future state of the production contact center environment. The visualizer updates the first visualization based at least on the time warped simulation such that all data visualization corresponding to a time before a first cutover time is based on actual data

According to another preferred embodiment of the invention a method for monitoring and control of contact centers with a dynamic temporal dimension is disclosed comprising the steps of a receiving at a persistent query service stored and operating on a plurality of network attached computers and coupled to a network attached data store data from a plurality of contact center systems b updating a plurality of virtual tables based at least on the received data updates c sending using an analysis manager stored and operating on a network attached computer based at least on changes in one or more persistent queries a first plurality of real time updates to a visualizer stored and operating on a network connected computer d updating by the visualizer a first visualization provided to a user of the state of a production contact center by displaying the first plurality of real time updates as a set of past states of the production contact center environment e performing using a scalable simulation service stored and operating on a plurality of network attached computers and configured with a virtual environment that replicates and is maintained in synchrony with a production contact center environment a time warped simulation to compute at least a future state of one of the virtual environments based at least on changes in one or more persistent queries f sending the second plurality of real time updates to the visualizer and g updating by the visualizer the first visualization provided to the user by displaying the second plurality of real time updates as a projected future state of the production contact center environment.

The inventor has conceived and reduced to practice a high performance real time relational database system and various methods for using the same. Systems deployed in accordance with one or more embodiments of the invention will generally be easily extensible to handle new interaction types and other activities such as work items or eLearning modules that may require routing and will be suitable for use in a wide range of deployment architectures including particularly cloud based routing architectures that manage routing of interactions for a large number of agents across a large number of enterprises.

One or more different inventions may be described in the present application. Further for one or more of the inventions described herein numerous alternative embodiments may be described it should be understood that these are presented for illustrative purposes only. The described embodiments are not intended to be limiting in any sense. One or more of the inventions may be widely applicable to numerous embodiments as is readily apparent from the disclosure. In general embodiments are described in sufficient detail to enable those skilled in the art to practice one or more of the inventions and it is to be understood that other embodiments may be utilized and that structural logical software electrical and other changes may be made without departing from the scope of the particular inventions. Accordingly those skilled in the art will recognize that one or more of the inventions may be practiced with various modifications and alterations. Particular features of one or more of the inventions may be described with reference to one or more particular embodiments or figures that form a part of the present disclosure and in which are shown by way of illustration specific embodiments of one or more of the inventions. It should be understood however that such features are not limited to usage in the one or more particular embodiments or figures with reference to which they are described. The present disclosure is neither a literal description of all embodiments of one or more of the inventions nor a listing of features of one or more of the inventions that must be present in all embodiments.

Headings of sections provided in this patent application and the title of this patent application are for convenience only and are not to be taken as limiting the disclosure in any way.

Devices that are in communication with each other need not be in continuous communication with each other unless expressly specified otherwise. In addition devices that are in communication with each other may communicate directly or indirectly through one or more intermediaries logical or physical.

A description of an embodiment with several components in communication with each other does not imply that all such components are required. To the contrary a variety of optional components may be described to illustrate a wide variety of possible embodiments of one or more of the inventions and in order to more fully illustrate one or more aspects of the inventions. Similarly although process steps method steps algorithms or the like may be described in a sequential order such processes methods and algorithms may generally be configured to work in alternate orders unless specifically stated to the contrary. In other words any sequence or order of steps that may be described in this patent application does not in and of itself indicate a requirement that the steps be performed in that order. The steps of described processes may be performed in any order practical. Further some steps may be performed simultaneously despite being described or implied as occurring non simultaneously e.g. because one step is described after the other step . Moreover the illustration of a process by its depiction in a drawing does not imply that the illustrated process is exclusive of other variations and modifications thereto does not imply that the illustrated process or any of its steps are necessary to one or more of the invention s and does not imply that the illustrated process is preferred. Also steps are generally described once per embodiment but this does not mean they must occur once or that they may only occur once each time a process method or algorithm is carried out or executed. Some steps may be omitted in some embodiments or some occurrences or some steps may be executed more than once in a given embodiment or occurrence.

When a single device or article is described it will be readily apparent that more than one device or article may be used in place of a single device or article. Similarly where more than one device or article is described it will be readily apparent that a single device or article may be used in place of the more than one device or article.

The functionality or the features of a device may be alternatively embodied by one or more other devices that are not explicitly described as having such functionality or features. Thus other embodiments of one or more of the inventions need not include the device itself.

Techniques and mechanisms described or referenced herein will sometimes be described in singular form for clarity. However it should be noted that particular embodiments include multiple iterations of a technique or multiple instantiations of a mechanism unless noted otherwise. Process descriptions or blocks in figures should be understood as representing modules segments or portions of code which include one or more executable instructions for implementing specific logical functions or steps in the process. Alternate implementations are included within the scope of embodiments of the present invention in which for example functions may be executed out of order from that shown or discussed including substantially concurrently or in reverse order depending on the functionality involved as would be understood by those having ordinary skill in the art.

As used herein Extract Transform and Load ETL means a process to migrate data from one database to another to form data marts data warehouses and to convert databases from one format or type to another. The ETL function is made up of three steps. Extract is the process of reading data from a database. Transform is the process of converting the extracted data from its previous form into the form it needs to be in so that it can be placed into another database. Transformation occurs by using rules or lookup tables or by combining the data with other data. Load is the process of writing the data into the target database.

As used herein a persistent query service is a database system supporting persistent queries and comprising a client software application operating on a computer comprising at least a listener comprising client code to be executed when the listener is invoked a persistent query service stored and operating on a network attached computer adapted to receive connections and requests from the client software application and a plurality of network attached data sources. On receiving a request to create a persistent query from the client software application the persistent query service creates a query virtual table corresponding to the persistent query parses the persistent query to create a tree structure representing a logical arrangement of a plurality of operators that yield results required by the persistent query creates a plurality of intermediate virtual tables corresponding to the plurality of operators wherein the step of creating an intermediate virtual table further comprises establishing listeners associated with the intermediate virtual table to receive data change notifications establishes listeners for the query virtual table to receive data change notifications from a plurality of intermediate virtual tables creates a plurality of data source virtual tables each corresponding to a specific data source required to fulfill the persistent query causes the plurality of data source virtual tables to retrieve initial data from the plurality of data sources and propagates data via the plurality of intermediate virtual tables and their associated listeners to the persistent query virtual table. On detection of a data change in a data source the associated data source virtual table invokes a plurality of corresponding methods of listeners of a plurality of virtual intermediate tables and propagates the data change via the plurality of intermediate virtual tables and their associated listeners to the persistent query virtual table and the client software application executes the client code of at least one affected listener.

Generally the techniques disclosed herein may be implemented on hardware or a combination of software and hardware. For example they may be implemented in an operating system kernel in a separate user process in a library package bound into network applications on a specially constructed machine on an application specific integrated circuit ASIC or on a network interface card.

Software hardware hybrid implementations of at least some of the embodiments disclosed herein may be implemented on a programmable network resident machine which should be understood to include intermittently connected network aware machines selectively activated or reconfigured by a computer program stored in memory. Such network devices may have multiple network interfaces that may be configured or designed to utilize different types of network communication protocols. A general architecture for some of these machines may be disclosed herein in order to illustrate one or more exemplary means by which a given unit of functionality may be implemented. According to specific embodiments at least some of the features or functionalities of the various embodiments disclosed herein may be implemented on one or more general purpose computers associated with one or more networks such as for example an end user computer system a client computer a network server or other server system a mobile computing device e.g. tablet computing device mobile phone smartphone laptop and the like a consumer electronic device a music player or any other suitable electronic device router switch or the like or any combination thereof. In at least some embodiments at least some of the features or functionalities of the various embodiments disclosed herein may be implemented in one or more virtualized computing environments e.g. network computing clouds virtual machines hosted on one or more physical computing machines or the like .

Referring now to there is shown a block diagram depicting an exemplary computing device suitable for implementing at least a portion of the features or functionalities disclosed herein. Computing device may be for example any one of the computing machines listed in the previous paragraph or indeed any other electronic device capable of executing software or hardware based instructions according to one or more programs stored in memory. Computing device may be adapted to communicate with a plurality of other computing devices such as clients or servers over communications networks such as a wide area network a metropolitan area network a local area network a wireless network the Internet or any other network using known protocols for such communication whether wireless or wired.

In one embodiment computing device includes one or more central processing units CPU one or more interfaces and one or more busses such as a peripheral component interconnect PCI bus . When acting under the control of appropriate software or firmware CPU may be responsible for implementing specific functions associated with the functions of a specifically configured computing device or machine. For example in at least one embodiment a computing device may be configured or designed to function as a server system utilizing CPU local memory and or remote memory and interface s . In at least one embodiment CPU may be caused to perform one or more of the different types of functions and or operations under the control of software modules or components which for example may include an operating system and any appropriate applications software drivers and the like.

CPU may include one or more processors such as for example a processor from one of the Intel ARM Qualcomm and AMD families of microprocessors. In some embodiments processors may include specially designed hardware such as application specific integrated circuits ASICs electrically erasable programmable read only memories EEPROMs field programmable gate arrays FPGAs and so forth for controlling operations of computing device . In a specific embodiment a local memory such as non volatile random access memory RAM and or read only memory ROM including for example one or more levels of cached memory may also form part of CPU . However there are many different ways in which memory may be coupled to system . Memory may be used for a variety of purposes such as for example caching and or storing data programming instructions and the like.

As used herein the term processor is not limited merely to those integrated circuits referred to in the art as a processor a mobile processor or a microprocessor but broadly refers to a microcontroller a microcomputer a programmable logic controller an application specific integrated circuit and any other programmable circuit.

In one embodiment interfaces are provided as network interface cards NICs . Generally NICs control the sending and receiving of data packets over a computer network other types of interfaces may for example support other peripherals used with computing device . Among the interfaces that may be provided are Ethernet interfaces frame relay interfaces cable interfaces DSL interfaces token ring interfaces graphics interfaces and the like. In addition various types of interfaces may be provided such as for example universal serial bus USB Serial Ethernet Firewire PCI parallel radio frequency RF Bluetooth near field communications e.g. using near field magnetics 802.11 WiFi frame relay TCP IP ISDN fast Ethernet interfaces Gigabit Ethernet interfaces asynchronous transfer mode ATM interfaces high speed serial interface HSSI interfaces Point of Sale POS interfaces fiber data distributed interfaces FDDIs and the like. Generally such interfaces may include ports appropriate for communication with appropriate media. In some cases they may also include an independent processor and in some in stances volatile and or non volatile memory e.g. RAM .

Although the system shown in illustrates one specific architecture for a computing device for implementing one or more of the inventions described herein it is by no means the only device architecture on which at least a portion of the features and techniques described herein may be implemented. For example architectures having one or any number of processors may be used and such processors may be present in a single device or distributed among any number of devices. In one embodiment a single processor handles communications as well as routing computations while in other embodiments a separate dedicated communications processor may be provided. In various embodiments different types of features or functionalities may be implemented in a system according to the invention that includes a client device such as a tablet device or smartphone running client software and server systems such as a server system described in more detail below .

Regardless of network device configuration the system of the present invention may employ one or more memories or memory modules such as for example remote memory block and local memory configured to store data program instructions for the general purpose network operations or other information relating to the functionality of the embodiments described herein or any combinations of the above . Program instructions may control execution of or comprise an operating system and or one or more applications for example. Memory or memories may also be configured to store data structures configuration data encryption data historical system operations information or any other specific or generic non program information described herein.

Because such information and program instructions may be employed to implement one or more systems or methods described herein at least some network device embodiments may include nontransitory machine readable storage media which for example may be configured or designed to store program instructions state information and the like for performing various operations described herein. Examples of such nontransitory machine readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROM disks magneto optical media such as optical disks and hardware devices that are specially configured to store and perform program instructions such as read only memory devices ROM flash memory solid state drives memristor memory random access memory RAM and the like. Examples of program instructions include both object code such as may be produced by a compiler machine code such as may be produced by an assembler or a linker byte code such as may be generated by for example a Java compiler and may be executed using a Java virtual machine or equivalent or files containing higher level code that may be executed by the computer using an interpreter for example scripts written in Python Perl Ruby Groovy or any other scripting language .

In some embodiments systems according to the present invention may be implemented on a standalone computing system. Referring now to there is shown a block diagram depicting a typical exemplary architecture of one or more embodiments or components thereof on a standalone computing system. Computing device includes processors that may run software that carry out one or more functions or applications of embodiments of the invention such as for example a client application . Processors may carry out computing instructions under control of an operating system such as for example a version of Microsoft s Windows operating system Apple s Mac OS X or iOS operating systems some variety of the Linux operating system Google s Android operating system or the like. In many cases one or more shared services may be operable in system and may be useful for providing common services to client applications . Services may for example be Windows services user space common services in a Linux environment or any other type of common service architecture used with operating system . Input devices may be of any type suitable for receiving user input including for example a keyboard touchscreen microphone for example for voice input mouse touchpad trackball or any combination thereof. Output devices may be of any type suitable for providing output to one or more users whether remote or local to system and may include for example one or more screens for visual output speakers printers or any combination thereof. Memory may be random access memory having any structure and architecture known in the art for use by processors for example to run software. Storage devices may be any magnetic optical mechanical memristor or electrical storage device for storage of data in digital form. Examples of storage devices include flash memory magnetic hard drive CD ROM and or the like.

In some embodiments systems of the present invention may be implemented on a distributed computing network such as one having any number of clients and or servers. Referring now to there is shown a block diagram depicting an exemplary architecture for implementing at least a portion of a system according to an embodiment of the invention on a distributed computing network. According to the embodiment any number of clients may be provided. Each client may run software for implementing client side portions of the present invention clients may comprise a system such as that illustrated in . In addition any number of servers may be provided for handling requests received from one or more clients . Clients and servers may communicate with one another via one or more electronic networks which may be in various embodiments any of the Internet a wide area network a mobile telephony network a wireless network such as WiFi Wimax and so forth or a local area network or indeed any network topology known in the art the invention does not prefer any one network topology over any other . Networks may be implemented using any known network protocols including for example wired and or wireless protocols.

In addition in some embodiments servers may call external services when needed to obtain additional information or to refer to additional data concerning a particular call. Communications with external services may take place for example via one or more networks . In various embodiments external services may comprise web enabled services or functionality related to or installed on the hardware device itself. For example in an embodiment where client applications are implemented on a smartphone or other electronic device client applications may obtain information stored in a server system in the cloud or on an external service deployed on one or more of a particular enterprise s or user s premises.

In some embodiments of the invention clients or servers or both may make use of one or more specialized services or appliances that may be deployed locally or remotely across one or more networks . For example one or more databases may be used or referred to by one or more embodiments of the invention. It should be understood by one having ordinary skill in the art that databases may be arranged in a wide variety of architectures and using a wide variety of data access and manipulation means. For example in various embodiments one or more databases may comprise a relational database system using a structured query language SQL while others may comprise an alternative data storage technology such as those referred to in the art as NoSQL for example Hadoop Cassandra Google BigTable and so forth . In some embodiments variant database architectures such as column oriented databases in memory databases clustered databases distributed databases or even flat file data repositories may be used according to the invention. It will be appreciated by one having ordinary skill in the art that any combination of known or future database technologies may be used as appropriate unless a specific database technology or a specific arrangement of components is specified for a particular embodiment herein. Moreover it should be appreciated that the term database as used herein may refer to a physical database machine a cluster of machines acting as a single database system or a logical database within an overall database management system. Unless a specific meaning is specified for a given use of the term database it should be construed to mean any of these senses of the word all of which are understood as a plain meaning of the term database by those having ordinary skill in the art.

Similarly most embodiments of the invention may make use of one or more security systems and configuration systems . Security and configuration management are common information technology IT and web functions and some amount of each are generally associated with any IT or web systems. It should be understood by one having ordinary skill in the art that any configuration or security subsystems known in the art now or in the future may be used in conjunction with embodiments of the invention without limitation unless a specific security or configuration system or approach is specifically required by the description of any specific embodiment.

In various embodiments functionality for implementing systems or methods of the present invention may be distributed among any number of client and or server components. For example various software modules may be implemented for performing various functions in connection with the present invention and such modules can be variously implemented to run on server and or client components.

Further in some cases applications such as application X and application Y run on a computer that operates under control of an operating system but do not directly invoke operating system functions for time dependent functions but rather rely on some other low level library for access to these functions. For example some time dependent functions are contained in a standard C library referred to in the art as libc. Functions such as date sleep and the like can be called by programs written in C or programs written in languages that use libc such as interpreted languages like Perl . In these cases applications in the art make calls to libc that are then passed as needed to the underlying operating system as needed in a way that is not visible or useful to the requesting application . There are many arrangements such as that illustrated in the right side of including those that involve use of the Java language in these cases the identity of library will depend on the language and computer architecture chosen. Additionally in some cases applications use a mixed mode for handling time dependent calls that is function calls sometimes going directly to the operating system and sometimes going through an intermediate library it will be appreciated by one having ordinary skill the art of computer architectures and computer programming that there are many ways in which applications can access time dependent functions in order to carry out their instructions all of which depend on a real time system clock that is a clock which is synchronized with actual clock time for the location in which the computer is operating although many computer systems ignore time zones and operate instead using universal computer time we need not consider time zone effects at all for the purposes of this application as the issue herein pertains to time virtualization or more specifically an intentional change in a time scale used within affected applications such that time passes for the application more or less quickly than it does in real time i.e. for a real observer without the application s being aware of the change and importantly without requiring the application to be changed in any way while such time warping will normally be done to speed up time time virtualization systems and methods according to the present invention can as easily cause virtual time to pass more slowly than real time within an application.

A key aspect of the present invention is the interception of time dependent function or method calls to an operating system or library . In a preferred embodiment of the invention illustrated in computers operate analogously to those in except time dependent function or method calls to operating systems or library are intercepted by a time warp daemon . That is time dependent function or method calls that would normally have been sent to an operating system or a library such as libc are instead redirected to a time warp daemon . There are many ways in which such a redirection can be accomplished. According to an embodiment of the invention time dependent function or method calls are redirected using a principle referred to in the art as dynamic linking. Linking is a function that links functions or methods stored in separate files or libraries to a particular executable application. In many cases applications are linked with desired libraries and functions using static linking at compile time. But in other cases linking is performed dynamically at run time. An advantage to dynamic linking is that it generally allows common libraries and functions to be maintained once even if they are used by many applications. For example in Windows based computers many functions or methods are deployed as dynamic loaded libraries or DLLs allowing updates to be made to them without requiring recompilation of programs that depend on them. Another method of dynamic linking common on UNIX and Linux based machines is through use of a built in dynamic loader which is configured via environment variables such as LD PRELOAD. It will be appreciated by those having ordinary skill in the art of modern computer programming that there are many methods including others not based on dynamic linking for intercepting a function call directed to one library and instead handling it with a different library.

In a preferred embodiment of the invention a dynamic linker is configured using a LD PRELOAD environment variable to redirect all calls to libc to a time warp daemon so that all time dependent functions accessed by programs will run through time warp daemon instead of a standard libc library which normally is very closely tied to the system clock . In the embodiment time dependent function interception is carried out in user space and affects only applications running within an affected user space. In some embodiments other libraries or a plurality of libraries containing time dependent functions or methods are handled via analogous redirections for instance calls to glibc may be intercepted instead of or in addition to calls to libc and so on. In yet other embodiments time warp daemon may be implemented as a kernel level library and intercept system level time dependent calls. Such an approach is advantageous in that it would work with applications that make direct calls to kernel level time dependent functions instead of or in addition to calls to user space libraries such as libc or glibc but require kernel level patching and is therefore not always necessary or desirable for a particular purpose. For example in order to support time warped simulation involving unmodified third party applications such as applications A B X or Y in it is often adequate to intercept user space time dependent functions via library rather than intercepting calls going to system space functions resident in operating system since applications generally execute in user space and would thus be aware only of time as exposed via library .

In some embodiments an entire machine may be run on virtualized time using a system or method according to the invention. For instance if computer runs operating system and all time dependent functions from applications are intercepted by time warp daemon then in effect time warp daemon will provide a virtualized time to all functions running on computer . This may be advantageous as time virtualization will effectively maximize utilization of computing resources on computer . A limitation of such system wide time virtualization is that if the system interacts in real time with other systems and clock time is an important aspect of interactions between the system and other non time warped or differently time warped systems then time warping would be disadvantageous as the systems could lead to unexpected and inaccurate results. However simulation is only one example of a process type where virtualizing time would be advantageous. Other examples would be systems which normally experience light loading but on occasion experience heavy peaks in load and which interact with other systems asynchronously and without actual clock time s being an important parameter in such systems time virtualization would allow the machine to run at full utilization always with virtual time speeding up and slowing down as described in detail below based on changes in processing load .

In various embodiments time warp daemon intercepts calls to time dependent functions or methods from an application software and then provides an expected response back to the specific application . Time warp daemon emulates all time based functions of an operating system kernel or low level library and independently determines a response time to include in its response rather than using an actual operating system system time or clock time.

For example assume application Y under normal circumstances sends a call to operating system signaling that application Y wants to sleep or time out for 300 milliseconds. Time warp daemon however intercepts the call and sends a timer event back to application just as soon as it is the next event in a queue maintained internally by time warp daemon . Typically this event would be sent only a few milliseconds after a sleep for 300 milliseconds i.e. sleep 300 request was sent thus warping or virtualizing time.

In an embodiment time warp daemon maintains an internal queue of upcoming events and a virtualized time at which each is expected to occur. Each event is added to the internal queue pre sorted so that the internal queue is ordered based on upcoming event times. For example when inserting a new event time warp daemon uses one of a variety of well established sorting algorithms to insert the new event into a queue of upcoming events in a position such that all events of lower index that is ordinal position in the queue than the new event have earlier virtual times at which they will occur and such that all events of higher index than the new event have later virtual times at which they will occur. There are numerous algorithms for such incremental sorting that are well known in the art any of which can be used for the purposes of maintaining an ordered upcoming event queue without departing from the scope of the invention.

According to an embodiment of the invention when an event occurs either because it was scheduled to occur by being the next entry in the upcoming events queue or when an event occurs asynchronously which mechanism is discussed further below the event is dispatched to the appropriate application by a time warp daemon and the event is tagged or identified with a virtual time essentially corresponding to the virtual time stored in the upcoming events queue or included within an asynchronous event when it arrived . Because the only times sent to applications are virtual times associated with those events applications are unaware that they are operating on virtual time rather than clock time. Unaware here means that the application has no means of determining any actual clock time since all time dependent functions and methods are intercepted by a time warp daemon and are handled using virtual time. Thus importantly applications are able to run faster or slower than real time or clock time without having to make any adjustments in their internal operations. Because of this feature of time virtualization off the shelf applications that depend on time such as applications that use rates as internal variables can be run at fast speed using virtual time without any necessity to recode the applications or to reinterpret results afterward this refers to an approach where one might run an off the shelf time dependent application faster than real time then reinterpret the results by compensating for the inaccuracy of time after the fact which can only be done when such inaccuracies are well defined and isolable from other effects which is rarely the case .

In another embodiment of the invention rather than maintaining a queue of upcoming events time warp daemon maintains a list of threads storing for each sleeping thread a time at which the sleeping thread is scheduled to be woken additionally threads might be awoken by socket activity as described herein . When all threads monitored by time warp daemon are sleeping time warp daemon advances virtual time to the earliest of the scheduled wake up times associated with threads and wakes up the thread associated with that earliest scheduled time to wake up. In some embodiments a plurality of applications operate using virtual time under supervision of a time warp daemon and in these embodiments all time virtualized applications can share a common virtual time and interoperate without any of the applications being aware that the common time being used is not in fact a system time or clock time.

In another embodiment of the invention time virtualization is carried out directly by a computer s operating system such that all time on the system is virtualized. In some embodiments a binary tree is used for storing upcoming events or for storing thread information rather than an ordered list. It should be understood that there are many ways to store this time information that are well known in the art some of which are more optimized for speed of execution such as binary trees and some of which are more optimal for easy coding and maintenance such as ordered lists and any of these may be used according to the invention.

Another benefit of running applications in virtualized time is that doing so provides another approach to optimally using information technology resources. Some applications are required to deal with computing loads that are highly variable for example contact center call routing engines experience computing intensities that are very highly dependent on arriving call volumes and these call volumes in turn tend to vary from very low late at night to very high in mid day periods for typical contact centers. In previous times such systems typically servers would be operated at much less than full capacity in order to allow such a system to surge when demand picked up without exceeding available resources. For several years two main approaches have been used to address this problem. One is to distribute resources over multiple physical machines for instance by using cluster architectures in which for example requests to a single internet protocol IP address are distributed across a cluster of servers which collectively act as a distributed computer. This approach has challenges with state and data management because state or data changes in one of the clustered servers may need to be propagated to others an approach to mitigating this problem has been to rely on formally stateless application designs. A second approach to delivering optimal computing resource utilization for applications or systems in which demand varies widely is to use physical virtualization which is distinct from time virtualization which is the object of the present invention . Physical virtualization allows many virtual machines to be operated on a single large scale general purpose computer with each using only the resources it needs. In such systems it is possible to place a high priority application with a widely varying demand profile on a virtual machine that is coresident operates on the same physical machine as a virtual machine that executes some less demanding application or one of lower priority so that when the first application experiences a sudden increase in demand it is able to pull resources away from the lower priority process in order to expand the virtual machine s resources for the first application. This approach is quite flexible and when combined with the first approach that is when using the second approach on a clustered server which acts as a large distributed computer hosting multiple virtual machines can handle demand swings of large magnitude while maintaining a high level of resource utilization.

In contrast to the methods of resource management known in the art and just described time virtualization according to embodiments of the invention allow a far simpler approach to be used when appropriate applications are involved. Appropriate applications are those such as large scale simulation but not limited to simulation where resource demand varies greatly over real time time based computation is needed but the application does not need a close tie between system time and real time. That is time virtualization is an excellent approach to resource optimization when resource demands vary greatly over real time or clock time but when there is no need to interact dynamically in real time with devices or other applications that are directly tied to an actual physical or clock time. For example an application that analyzes data that has already been collected and that experiences extreme variations in resource requirements based on the content of the data for instance when encountering a large table of data and where requests to a separate application are made that depend in some way on table size a sudden increase in CPU power may be needed whereas for most smaller tables far less power is needed . In normal systems if the main application or application to which requests are sent computes rates or performs other time based computations for example if some computations or resource allocations depend on a computation rate computed in real time then the situation is analogous to that experienced in large scale simulations. Such applications can readily be performed in a resource optimal way in time virtualized systems since the rate at which virtual time proceeds will naturally vary as demand varies such that when demand is extremely high virtual time may pass slower than clock time while when demand is very light virtual time may pass many times faster than real time. Since no clock time is wasted in time virtualized machines the machine will not need to wait for a timeout or another asynchronous event it will automatically advance virtual time to the next event thus maximally utilizing computing resources with the exception of overhead caused by time virtualization which generally is quite low compute power will automatically be fully utilized in such systems.

Each application has time dependent calls to operating systems that are intercepted by a time warp daemon . As in the previous example a time warp daemon within each server maintains an internal queue of upcoming events and a virtualized time at which each upcoming event is to occur. Each such queue is sorted so that the next event to occur in virtual time will always be on top of the queue or stack ensuring that all time based events occur in the right order with a correct virtual time . After processing any incoming event time warp daemon fires a next expected event off its associated upcoming event queue or stack and passes it to an appropriate application immediately advancing the virtual time clock and collects any new event now processing it into the queue in the appropriate time sorted fashion. By maintaining a queue or stack of upcoming time based events and jumping form one event to the next all idle time that occurs as applications wait for real time to catch up is eliminated.

Where applications are not limited by central processing unit CPU power there is a lot of idle time wasted for instance a CPU on machine might be idle after updating all requested statistics on receiving an event from contact center simulator until receiving a next event from contact center simulator . An embodiment of the invention utilizing time warp daemon processes effectively eliminates such wasted time. The specific application is unaware that time is compressed or warped so they behave normally. Time warp daemons process allows simulated activities to run much faster by illuminating idle time. The invention allows simulations of large systems to be accomplished by creating this time virtualized or time compressed environment. For example in a typical call routing scenario routing operations can take place at as much as 200 times as fast as normal physical clock time. In other words 200 seconds of real time are simulated in just one second and this is achieved using off the shelf contact center application software which never realize that time is being virtualized or compressed.

It should be noted that the arrangement shown in adds some complexity to time virtualization since virtual times maintained by time warp daemons must be kept synchronized. This arrangement is merely exemplary and other arrangements are possible but before discussing them it is helpful to describe how such synchronization can be achieved according to the invention there are several methods that occur to the inventor and in fact many synchronization schemes are known in the art . In one approach a plurality of time warp daemons exchange after each event is processed a virtual time expressed typically in universal computer time that is as a number of seconds after Jan. 1 1970 or another reference data known to each of operating systems representing the virtual time for each time warp daemon at which the next upcoming event in that daemon s upcoming event queue is to occur. Since each time warp daemon receives the same set of three next event times one from itself and one from each of the other two each of the time warp daemons can perform a simple algorithm such as pick the lowest time and in case of a tie take the event from the tied events in a prearranged order based on its source machine to determine when the next virtual time stop is to occur and the daemon which owns this next event would immediately process that event. Such an approach is simple but does add messaging overhead. Alternative approaches such as maintaining a single upcoming event queue with a basic data locking mechanism to prevent conflicts can be used. Alternatively one master time warp daemon for instance in a preferred embodiment one on the machine that runs contact center simulator can be designated and it can maintain a single upcoming event queue and by extension a single virtualized time dimension that is used by applications thus ensuring a synchronized virtual time that is shared by all the applications.

Time warp daemons each keep a list or queue of all threads and tracks if each thread is asleep and if so when each is scheduled to be awakened. Time warp daemons act immediately after receiving a command from a process. If all registered threads in a queue are sleeping the time warp daemon essentially time travels to the earliest wake up time in step of all its managed threads and sends a message to that thread s socket telling it that it is time to wake up. When the stub receives the wake up message in step the call to poll is unblocked and the stub will make the application think that it has timed out in step .

In the scenario where all threads are busy that is not sleeping but actually doing something such as computing a statistic a time warp daemon does nothing. Activity on a socket in step may wake up a thread independent of a time warp daemon. In this case a time warp daemon client stub then tells its specific time warp daemon that it is awake and the time warp daemon removes the applicable thread ID from its queue of sleeping threads. This is a synchronous call so that the time warp daemon client stub can determine its current virtual time and guarantee that no further time travel occurs after the response is received. Thus if an application wakes up due to network activity before control is returned back to the application a time warp daemon will have stopped time virtualization temporarily and cannot start again until all threads in the system are asleep. Thus a time warp daemon is able to handle asynchronous events while virtualizing time.

In some embodiments applications don t work directly with events per se rather their threads are simply woken up or put to sleep. The events are sent to the time warp stubs who are asleep waiting for an event from time warp daemon as well as some application defined file descriptors in case of some time based functions such as poll and select . As an optimization to avoid extra context switching when clock gettime or related functions are called the stubs not the application are told what time it is upon wakeup but this is not necessary as they could just ask time warp daemon for the time each time clock gettime is called.

In another embodiment a proprietary or open source query language may be used for managing data linking aggregation projections filters macros compositional syntax establishing data types and functions and creating persistent queries in a persistent query system .

In some embodiments of the invention frequently reused virtual tables may be maintained even when all current persistent queries that use them have been deleted by the applications that created them in order to further improve system performance. In such embodiments when a new persistent query is created by an application any virtual tables required that have been maintained can be immediately used without running any queries against underlying data sources since the still maintained virtual tables will be populated by data that reflects that latest changes to any underlying data sources thus enabling rapid creation and execution of new persistent queries.

In a particular embodiment system includes simulation system which is preferably a scalable simulation service accessible via a network which may perform simulations of a plurality of interactions and events in an interaction processing environment. For example simulation engine may collect interaction information for example the number of interactions in a given period the average length of time an interaction is in the system etc. communication object behavior for example in a communication environment skills associated to agents commanding a communication object the number of agents based on a predefined schedule etc. and interaction movement information for example interaction routing behavior from an interaction routing system such as an intelligent routing system an ACD queue a hunt group and the like known in the art . In another embodiment forecasted or computed information on interaction behavior may be used as well. Once simulation engine collects necessary information environment replication creates a schema to define how simulated interaction traffic may behave when simulated interactions are run through the system by simulation engine . A simulation may take many forms for example a simulation may be intended to mimic the behavior of an interaction system for the purpose of predicting future issues. In a particular embodiment a simulation may be used to experiment on what if scenarios in for example an attempt to make interaction systems more efficient or to determine the root cause of an issue. For example in a communication center environment a problem may have been reported by a customer that a particular system was unresponsive. In this example a support analyst user may access visualizer with data loaded from LiveSQL system . User scrolls back that is configure visualizer to focus on the time interval when the problem occurred to visually inspect the state of communication objects and the behavior of interactions in an attempt to remedy the issue.

In a particular embodiment simulation engine collects a small amount of high level data for example average handle times service level average speed of answer and the like as opposed to detailed event by event data to generate a coarse environment replication. In this embodiment a much faster but potentially a less accurate simulation would result.

Referring again to as analysis manager collects analyses and actions performed by user and circumstances surrounding the actions. Once analysis manager detects repeated behavior or specific patterns emerge analysis manager stores the action by user in configuration DB via configuration system . In this example analysis manager may automatically perform corrections to the interaction system for example a contact center a CRM system such as Siebel Salesforce.com or the like via interaction system interface to automatically perform system adjustments in real time based on a threshold when problems are detected or at some later time based on historical modifications by user and pattern analysis by analysis manager .

In a particular embodiment step monitors simulated interactions delivered from simulation system in an effort to predict alerts before they happen in the real system or used a method to predict when issues will happen.

In a particular embodiment step simultaneously monitors real interactions and simulated interactions to monitor experimentation efforts through what if scenarios.

In a particular embodiment step is directly linked to visualizer so that the progression of alert parameters can be viewed in real time and user can react immediately for example before an alert happens. In this example user would be able to commit changes from the simulated environment if it were for example showing or favorable behavior and commit changes to the system for example immediately.

The foreground boxes of track represent interactions that take place on object for one or more interactions at a time interval represented by time index . For example interactions may include but are not limited to ringing at an approximate time index 8 45 as denoted by the corresponding position in time index which represents a notification of an incoming request for communication on a communication device in a communication center environment. In some embodiments there may be parallel foreground boxes representing simultaneous communications for example at an approximate time index of 9 15 agent receives a ringing event and communication is established shortly thereafter. At an approximate time index 9 32 the interaction is put on hold that is the communication is put into a state of temporary interruption without severing the communication connection . While the communication is on hold agent initiates a second call for example for the purpose of consulting with another agent. To do this agent initiates dialing event that is to signal a communication server to initiate an outbound communication . It should be noted that the length of the foreground box relates to the duration of the event as noted by corresponding time index . At approximately 10 10 in time index a communication is established with the second agent. Once the interaction is complete as symbolized by the end of the foreground box at time index 10 28 agent returns to the initial interaction. The transition is noted by the change in pattern between held and established it will be appreciated by one having ordinary skill in the art that an established state is where a synchronous conversation is active for example when two humans begin a conversation the interaction is established at 10 28 in time index .

In another embodiment user may wish to perform experimentation to explore what if scenarios. For example user may wish to analyze a problem reported with track 1 for example in a communication center environment a problem was reported where an agent represented by track 1 was unable to receive calls during a specified period of time . In this example user may scroll to a time index that corresponds to when the issue was reported to have happened. User may select various events for example configuration change events to appear for the time interval 1 that corresponds to time index to view a visualization of interactions that took place within time interval 1 . In this example user may have seen that the time index for a particular a configuration change coincided with the time index of when the issue was reported to happen. User may decide to change the configuration element that may have caused the problem and run a what if scenario using simulation system and review the behavior to verify if the issue happens again. In some embodiments GUI may show parallel tracks and where tracks and are tracks with actual interaction and event behavior and tracks and are what if tracks of interaction and event behavior that is the tracks with the simulated behavior generated by simulation system with the experimental change activated. This delivers an improvement over systems known in the art in that user may understand the behavior of system with a much more advanced perspective.

In some embodiments simulation system may run multiple simultaneous simulations to present a visual representation of multiple combinations and permutations of different configurations to user for experimentation of system . In this embodiment user is able to view a plurality of simulated alternatives simultaneously or through the use of different views using GUI .

When user runs experiments using simulation system she may play that is commence the presentation of interaction in client area and or pause that is to cease the progression of the display of interactions in client area . For example user runs a simulation by making a request to simulation system by selecting play . When user reaches a point where she may wish for interactions to stop displaying for example to rerun a simulation with different parameters she may select pause .

User may select an interaction within tracks and by moving a cursor over certain areas. Once selected user may see more detail on the interaction or event in detail section . For example in a communication center environment details can include but are not limited to identification number of string of the interaction the name of a person involved with said interaction access numbers or addresses used to initiate terminate or modify said interaction information whether location of or identification of hardware units software processes and the like of associated systems that pertain to said interaction customized data describing aspects or participants or other entities with respect to said interaction.

In a particular embodiment user may use query text box to filter interaction information within main client area by using one or more special purpose programming language designed for managing data held in interaction DB . For example an SQL data query such as SELECT name address FROM CustomerData WHERE AgentID 1234 and exemplary operators outlined in Table 1. In some embodiments data queries may be performed using a proprietary programming language.

In another embodiment an iterative step may not result in the resolution of a problem so the process ends in step after analysis step . For example it is determined that the issue was with an unrelated system.

In another embodiment a resolution may be found in step immediately after step without the need of configuration and the process ends in step .

The skilled person will be aware of a range of possible modifications of the various embodiments described above. Accordingly the present invention is defined by the claims and their equivalents.

