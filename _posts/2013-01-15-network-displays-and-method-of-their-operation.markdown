---

title: Network displays and method of their operation
abstract: Distribution problems are solved using an off-the-shelf network, e.g. using an IP based or similar data protocol, such as an IP network based distributed system architecture to bring the display controller functionality closer to the source and to replace proprietary busses used for transporting video, audio, RGB, graphical information and/or metadata with building blocks based on standard IP and compression technologies. A characteristic of such a network is to use unicast, multicast and/or broadcast technologies (based on network addresses) and to route data from one address to another. The network provides redundancy in case any of the digital generation units.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09264678&OS=09264678&RS=09264678
owner: BARCO N.V.
number: 09264678
owner_city: Kortrijk
owner_country: BE
publication_date: 20130115
---
This application is a divisional of allowed U.S. patent application Ser. No. 11 487 357 filed Jul. 17 2006 and incorporated by reference herein.

The present inventions relate to multi head display controllers and multi head displays as well as methods of operating these displays e.g. as used during pre sports events and in sports events phases of operation for metadata process and broadcast monitoring purposes. The term multi head refers to using more than one display unit e.g. monitor side by side to create a very large logical desktop. A multiple of display units e.g. monitors may display a multiple of different video and or RGB images and related and or embedded metadata such as video characteristics or embedded audio for example as e.g. in broadcast studios utilities control rooms or air traffic control. The present invention also relates to all applications for multi screen large area displays or applications where parts of the same information have to be shown synchronously on multiple display units. Typical applications are broadcast telecommunications utilities transportation security defense process control simulation and others.

The need for increased functionality of display controllers preferably at lower prices drives product evolution in ever shorter cycles. Over the years it has been shown that an increase in display controller functionality requires an even faster increase in internal bus bandwidth. Initial hardware designs used point to point connectivity. The advent of IT hardware caused proprietary bus structures to appear. Standardization of the IT market generated a fast evolution of cheap standard bus designs. High end requirements were fulfilled with proprietary busses often driving future standards forward.

First generations of multi head display controllers focused on the display of graphics data. Standard bus based system could handle this well. The emerging demand for showing video and or RGB images and related and or embedded metadata was handled by either limiting the data rate caused by video data transfer on a standard bus leading to lower quality or by using additional proprietary busses. The need for higher numbers of higher quality video RGB images and more powerful video and metadata processing grew stronger and caused the design of highly complex bus solutions most of the time still based upon existing standards .

A similar evolution was noted in IT networking. Low speed networking evolved very rapidly over the years towards very high speed networking 10 Gbit sec data rate being readily available 1 Gbit sec already becoming standard for high end workstations and laptops 100 Mbit sec almost being outdated. Switch and router bus capacities were driven by the ever faster network speed and QoS requirements nowadays guaranteeing sufficient processing and transfer capacity to avoid packet loss. At the same time there has been an evolution in compression technology MPEG MPEG2 MPEG4 JPEG JPGEG2000 . . . to yield higher compression rate for the same visible quality of images.

Today more and more customers demand solutions where the distribution is done of multiple sources in different locations with sources being of multiple signal types to different places where display units such as projectors plasma displays monitors are available. Today this can be solved with presently available display controllers such as e.g. Hydra or Argus available from the applicant for the present patent . The classical system architecture however has the disadvantage that one display controller e.g. a Hydra multi viewer display controller drives one display unit which may consist of multiple screens . One can easily come to a stage where one such display controller is not big enough to drive a display unit or where multiple display controllers in different locations are required to display the same sources. In this case an external distribution device such as a router or matrix switch e.g. CVBS SDI RGB routers is required to enable the switching and multiplexing of input signals to several destinations as illustrated in . This architecture has the disadvantage that every display controller needs to be connected to the external distribution device e.g. router by as many cables as there are images to be displayed on a single display unit screen . Cabling therefore is a major issue. It is furthermore a disadvantage of such implementation that the external video audio distribution in the central external distribution device required to bring the input source signals to the relevant display controllers is a high cost amplifiers matrix switchers cabling . . . . Another disadvantage as already indicated is the fact that the distribution internally in the display controller requires ever more complex bus solutions.

In the particular case of a control room e.g. a broadcast studio utilities control room or an air traffic control tower operations room such control room is equipped with a multitude of displays in the latter case allowing one or more air traffic controllers to monitor the air and ground traffic landings and all vehicle movements on the runway and the apron. Most of today s systems used in a traffic control environment are based on the principle of one monitor for one application in a static configuration. Every display has its proper mouse and keyboard and is thus dedicated to one particular application or system. Consequently the human machine interface is composed of several displays of different sizes and shapes with each its own user interface. This situation is sub optimum from an ergonomic perspective. Existing solutions using KVM switches fall short in providing the required functionality when operators demand simultaneous viewing and interoperability with applications running on multiple application servers.

It is an object of the present invention to provide good apparatus or methods for displaying images on a display system comprising a plurality of display units.

a shared resource network linking the display generator units the shared resource network being adapted to receive a plurality of input source signals encoding images to be displayed 

a plurality of display units the display units being for display of at least some of the images encoded in the input source signals 

wherein each display generator unit is adapted for storing a configuration document the configuration document including a definition of a task of all display generator units.

This provides the advantage of the use of a shared resource network. The shared resource network can be a local or wide area network. No proprietary busses are needed and hence dependencies on physical limitations common to high speed busses are relaxed. The cost can be lower less cabling being necessary. Management of IT networking equipment is common knowledge for IT departments therefore the system is easier to manage. A configuration document controls video streams as to how these are displayed. One configuration document for all DGUs provides local graphics configuration for the DGU s and makes the DGUs independent from any central processor. This allows the DGU s to render different parts of the image in parallel at full speed.

An additional feature of the present invention is that each display generator unit has a filter to filter out or extract tasks assigned to that display generator unit. This has the advantage that swapping between devices is possible in case of fault on one processing device. The new device is able to filter out other information.

The configuration document may be or may contain a tagged mark up language description of the image to be displayed. Languages formats styles such as SGML XML SVG can be used for example. These languages allow specification of objects and attributes that allow swapping between devices in case of fault on one processing device. Any new device can filter out other information from such documents.

The system may comprise a control unit for controlling distribution of the configuration document to the display generator units.

Optionally the processing means of the display generator units may comprise a gaming video processor for rendering the images to be displayed. This provides fast rendering of images. On the fly rendering is also enabled.

As a further feature the display generator unit may comprise local synchronisation means for synchronising operations within a display generator unit. In addition global synchronisation means may be provided for synchronising operation of a plurality of display generator units. Then different display units all display the same output frame at a same moment in time so that for an image over a plurality of display units no errors are noticed.

Preferably there is a single configuration document for all images to be displayed on the plurality of display units. This provides the advantage of redundancy. As all display units are controlled by the same configuration file any display unit can take over for any of the others combination of the others or all others if so desired.

Encoders may be provided for encoding image data to be displayed so as to generate the input source signals. These encoders may comprise coder logic for compressing data related to images to be displayed. For example the codec logic can be a JPEG2000 logic.

A further feature of the present invention is that each display generator unit is adapted for subscribing e.g. either by listening to the unicast network e.g. IP address used to transmit the compressed data or by listening to the multicast group used to distribute the information to multiple sources of image data to be displayed.

The display generator units may comprise decoder logic for decompressing data related to images to be displayed. The decoder logic can be a JPEG2000 logic for example.

The display generator units may furthermore comprise means for reading multimedia information and for filling it into the data stream of the image to be displayed.

To provide additional flexibility there can be at least one redundant display generator unit i.e. at least one more than the number of display generator units required to provide the image data for the display units. Each display unit can have a first and a second input the first input being for connection to a display generator unit and the second input being for linking to the at least one redundant display generator unit each display unit furthermore having a switch for switching between the first and second inputs.

Optionally a display generator unit can be integrated into a display unit. In another aspect the present invention provides a display system for displaying streaming image data comprising 

a plurality of display units display generator units for generation of display data for the plurality of display units a shared resource network linking the display generator units the shared resource network being adapted to receive a plurality of input source signals encoding images to be displayed wherein there is at least one redundant display generator unit in excess of the number of display generator units required to provide the image data for the display units 

wherein each display unit has a first and a second input the first input being for connection to a display generator unit and the second input being for linking to the at least one redundant display generator unit each display unit furthermore having a switch for switching between the first and second input. The shared resource network can be a local area network or a wide area network. The network may be wired wireless optical etc. as required. If one display generator unit fails its function can be seamlessly taken over by the redundant one. This provides fault tolerance against failure even without using a central logic processor.

A loop through connection can be provided for connecting the second inputs of the display units to the at least one redundant display generator unit. Each display generator unit may be adapted for storing a configuration document the configuration document including a definition of tasks for all display generator units. The configuration document may comprise a full description of the image content of each of the display units. The full description may be defined in the document by means of a network address for the display unit to be used.

The configuration document may be or may contains a tagged mark up language description of the image to be displayed. Examples are SGML XML SVG documents. Using the configuration document swapping between devices is possible in case of a fault on one processing device. The new device can filter out other information not relevant to its new task using the information in the configuration document.

Accordingly each display generator unit can have a filter to filter out from the configuration document tasks assigned to that display generator unit. This provides the advantage that each DGU is thereby capable of defining its active role within the display wall. Swapping between devices is possible in case of fault on one processing device as the new device can filter out the relevant information for the new display role and also ignore other information.

Preferably a single configuration document is used to define all images to be displayed on the plurality of display units. This is a convenient way of providing redundancy as every display unit can take over the role of any of the others some of the others or even for all others if so desired.

Preferably a control unit is provided for controlling distribution of the configuration document to the display generator units.

Another feature of the present invention is that each display generator unit is adapted for subscribing to sources of image data to be displayed.

Another feature of the present invention is that the processing means of the display generator units comprises a gaming video processor for rendering the images to be displayed. This provides fast rendering of images and on the fly rendering is possible.

Another feature of the present invention is that the display generator unit comprises local synchronisation means for synchronising operations within a display generator unit. A global synchronisation means may be provided for synchronising operation of a plurality of display generator units. This provides the advantage that different display units e.g. a set thereof can all display the same output frame at a same moment in time so that for an image over a plurality of display units no errors are noticeable.

Encoders may be provided for encoding image data to be displayed so as to generate the input source signals. The encoders comprise coder logic for compressing data related to images to be displayed. The codec logic can be JPEG2000 logic.

Accordingly the display generator units comprise decoder logic for decompressing data related to images to be displayed. The decoder logic ican be JPEG2000 logic.

Another feature of the present invention is that the display generator units can furthermore comprise means of reading multimedia information for filling it into the data stream of the image to be displayed.

In yet another aspect of the present invention a display system for displaying streaming image data is provided comprising display generator units each comprising a processing means and a memory a shared resource network linking the display generator units the shared resource network being adapted to receive a plurality of input source signals encoding images to be displayed a plurality of display units the display units being for display of at least some of the images encoded in the input source signals wherein each display generator unit has a means for rendering an image each means for rendering being adapted for rendering autonomously a dynamically reconfigurable portion of an image to be viewed. The shared resource network can be a local area network or a wide area network. The network may be wired wireless optical etc. as required.

The display generator units may furthermore comprise means for communicating with other display generator units for synchronisation of rendering. This allows that different display units can all display the same output frame at a same moment in time so that for an image over a plurality of display units no errors are noticeable.

The display generator unit may furthermore comprises local synchronisation means for synchronising operations within a display generator unit. Multiple logical channels may be provided for transferring input source signals encoding images to be displayed to the display generator units.

Preferably a priority is assigned to the logical channels to distribute power of the DGUs across multiple information sources.

As an additional feature the processing means of the display generator units can comprise a gaming video processor for rendering the images to be displayed. This provides fast rendering of images e.g. on the fly rendering.

Each display generator unit can be adapted for storing a configuration document the configuration document including a definition of tasks for all display generator units. The configuration document preferably comprises a full description of the image content for each of the display units. For example the configuration document is or contains a tagged mark up language description of the image to be displayed. The document can be a SGML XML SVG document for example. This allows swapping between devices in case of fault on one processing device. The new device takes over the role of the faulty device by interrogating the configuration document and has to filter out other information. Accordingly each display generator unit has a filter to filter out from the configuration document tasks assigned to that display generator unit. Thereby each DGU capable of defining its active role within the display wall. Preferably there is a single configuration document for all images to be displayed on the plurality of display units. This is a convenient way to provide redundancy as a display or some of the display units or all display units can take over the job of a display unit some of the display units or all other display units if so desired. Preferably a control unit is provided for controlling distribution of the configuration document to the display generator units.

Preferably each display generator unit is adapted for subscribing to sources of image data to be displayed.

Encoders can be provided for encoding image data to be displayed so as to generate the input source signals. The encoders may comprise coder logic for compressing data related to images to be displayed. The coder logic can be a JPEG2000 logic. Consequently the display generator units can comprise decoder logic for decompressing data related to images to be displayed. The decoder logic can be JPEG2000 logic.

The display generator units can furthermore comprise means of reading multimedia information for filling it into the data stream of the image to be displayed.

display generator units each comprising a processing means and a memory a shared resource network linking the display generator units the shared resource network being adapted to receive a plurality of input source signals encoding images to be displayed the images being encoded by a scalable video codec a plurality of display units the display units being for display of at least some of the images encoded in the input source signals wherein each display generator unit is adapted to selectively subscribe to one or more input sources and to scale the images locally. The shared resource network may be a local area network or a wide area network for example. The network may be wired wireless optical etc. as required. The scalable video codec can be based on JPEG2000.

Each display generator unit may be adapted for storing a configuration document the configuration document including a definition of a task of all display generator units. The configuration document may comprise a full description of the image content of each of the display units. The configuration document may be or may contain a tagged mark up language description of the image to be displayed such as a SGML XML SVG document for instance. This allows swapping between devices is possible in case of fault on one processing device. The new device takes its graphics configuration from the configuration document and has to filter out other information. Accordingly each display generator unit has a filter to filter out from the configuration document tasks assigned to that display generator unit. Thereby each DGU is made capable of defining its active role within the display wall. Preferably there is a single configuration document for all images to be displayed on the plurality of display units. This is a convenient way to provide redundancy all display units can take over for all others if so desired. A control unit may be provided for controlling distribution of the configuration document to the display generator units. The processing means of the display generator units may be a gaming video processor for rendering the images to be displayed. This allows fast rendering of images and on the fly rendering is possible.

The display generator unit may comprise local synchronisation means for synchronising operations within a display generator unit. Global synchronisation means may be provided for synchronising operation of a plurality of display generator units. This provides the advantage that different display units all display the same output frame at a same moment in time so that for an image spread over a plurality of display units no errors are noticeable.

Encoders may be provided for encoding image data to be displayed so as to generate the input source signals. The encoders may comprise a video codec for compressing data related to images to be displayed. The display generator units may comprise decoder logic for decompressing data related to images to be displayed. The decoder logic can be based on JPEG2000.

The display generator units may furthermore comprise means of reading multimedia information for filling it into the data stream of the image to be displayed. Particular and preferred aspects of the invention are set out in the accompanying independent and dependent claims. Features from the dependent claims may be combined with features of the independent claims and with features of other dependent claims as appropriate and not merely as explicitly set out in the claims.

The above and other characteristics features and advantages of the present invention will become apparent from the following detailed description taken in conjunction with the accompanying drawings which illustrate by way of example the principles of the invention. This description is given for the sake of example only without limiting the scope of the invention. The reference figures quoted below refer to the attached drawings.

The present invention will be described with respect to particular embodiments and with reference to certain drawings but the invention is not limited thereto but only by the claims. The drawings described are only schematic and are non limiting. All references to specific blocks or parts eg. P25 ADV202 etc. . . . are only for illustrative purposes and do not limit the invention to the use of these specific components. In the drawings the size of some of the elements may be exaggerated and not drawn on scale for illustrative purposes. The dimensions and the relative dimensions do not correspond to actual reductions to practice of the invention.

Furthermore the terms first second third and the like in the description and in the claims are used for distinguishing between similar elements and not necessarily for describing a sequential or chronological order. It is to be understood that the terms so used are interchangeable under appropriate circumstances and that the embodiments of the invention described herein are capable of operation in other sequences than described or illustrated herein.

It is to be noticed that the term comprising used in the claims should not be interpreted as being restricted to the means listed thereafter it does not exclude other elements or steps. It is thus to be interpreted as specifying the presence of the stated features integers steps or components as referred to but does not preclude the presence or addition of one or more other features integers steps or components or groups thereof. Thus the scope of the expression a device comprising means A and B should not be limited to devices consisting only of components A and B. It means that with respect to the present invention the only relevant components of the device are A and B.

Similarly it is to be noticed that the term coupled also used in the claims should not be interpreted as being restricted to direct connections only. Thus the scope of the expression a device A coupled to a device B should not be limited to devices or systems wherein an output of device A is directly connected to an input of device B. It means that there exists a path between an output of A and an input of B which may be a path including other devices or means.

The invention will now be described by a detailed description of several embodiments of the invention. The text is arranged so that in a first part the general arrangement of a system in accordance with the present invention followed by second part giving a more specific description of embodiments of the present invention each of which may be used with any other of the embodiments and may be included in the system as described in any combination. It is clear that other embodiments of the invention can be configured according to the knowledge of persons skilled in the art without departing from the true spirit or technical teaching of the invention the invention being limited only by the terms of the appended claims.

The present invention provides a design of a digital networked studio and the needed software services to allow the use of the system for monitoring the creation and distribution processes of real time created content.

A new approach in accordance with the present invention is to solve the distribution problems using an off the shelf network e.g. using an IP based or similar data protocol such as an IP network based distributed system architecture to bring the display controller functionality closer to the source and to replace proprietary busses used for transporting video audio RGB graphical information and or metadata with building blocks based on standard IP and compression technologies. A characteristic of such a network is to use unicast multicast and or broadcast technologies based on network addresses and to route data from one address to another. This approach requires new network components to provide the necessary services.

Some of the benefits of the replacement of a bus based system by a distributed network based system architecture are 

A distributed system architecture combined with an optional ubiquitous network allows bringing of the system inputs closer to the source. This eliminates the need for analog video audio RGB or metadata distribution and guarantees higher quality digital signals all the way. Still it makes sense to keep the classic distinction between the distribution of the signal and the digital networked studio as 

In an aspect of the present invention an optimal use of a standard network is made to provide sufficient bandwidth based on network based system architectures. A schematic system of embodiments of the present invention is shown in and .

According to the present invention the classical system architecture as described with respect to has been replaced by a network based architecture which solves the cabling issue as only the cabling towards the network switch has to be provided to allow the different data streams to travel from encoder to decoder display. Two embodiments of the present invention will be described hereinafter.

A first embodiment of the present invention is shown schematically in . The first embodiment provides a plurality of encoders e.g. a High Definition Standard Definition Serial Digital Information Source Capturing Unit HD SD SDI SCU type of encoder and a Hydra Display Generator Unit Hydra DGU card for usage with a current display controller e.g. Hydra hardware platform The drawing engine functional block represents an optionally redundant system generating and distributing a graphics configuration file such as a tagged mark up language description of the image to be displayed. The signal processing block represents an optionally redundant plurality of systems able to convert different types of information streams e.g. JP2K to MPEG2 or vice versa or any other combination or able to extract derive metadata from an information stream and placing this new information back on the network. Drawing engine and signal processing may be handled by a plurality of servers connected to the network. The encoders e.g. SCUs can be placed in a managed rack and be hot swappable. This embodiment uses a switching device such as a network switch for the distribution of the encoded data streams e.g. a GbE switch GigabitEthernet switch . In case the switching device is a GbE switch it is connected to the display controllers e.g. Hydra multi viewers by means of GbE cabling. This way everything is brought down to a modular solution with the help of common network techniques. Any suitable carrier can be used for the network e.g. wires glass fibres wireless connections etc.

A second embodiment of the present invention is shown in . In the hardware platform of the second embodiment the display controllers e.g. Hydra units containing Hydra DGUs are replaced by standalone display generator units DGU . Drawing engine and signal processing functionality as explained above can be logically separated from the decoder functionality. For example the DGU card and the single board computer are replaced in the Hydra based solution by a completely new DGU unit . In this embodiment use can be made of a dedicated GPU graphics processor unit sometimes called a gaming video processor for example inside the DGU to render the images. The transition to a services based architecture allows the relocation of major pieces of processing from the display controllers to highly powered networked servers e.g. serving as drawing engine or signal processing servers. This makes it possible to reduce the new unit to the functionality of an autonomous graphics channel.

Hence the present invention provides at least one of an encoder e.g. SCU a DGU unit with a Hydra DGU and a standalone DGU being particular embodiments a drawing engine and one or more signal processing servers as well as related software in a non redundant or redundant configuration.

In this diagram the encoder comprises a plurality of multi input SCU sub units where each sub unit has equalising means capable of equalizing EQ and decoding means capable of decoding DEC a number of incoming SDI signals. A compressor Codec Logic ADV202 SDRAM e.g. for performing JPEG2000 compression is provided for compressing the equalized and decoded input signals and for multiplexing the encoded signals prior to unicasting or multicasting them on the network by network processing means e.g. on a redundant 1 GB s Ethernet network. A processor block Boot flash SDRAM Processor with a redundant fast Ethernet connection separation of streaming and control channels is in control of the multi input encoder .

Since this board can only accept a limited number of streams no bandwidth limiting actions must be taken on SCU side.

Real time encoding at full frame rate is required e.g. during in sports events phases of operation for broadcast monitoring purposes. Usage of JPEG2000 compression technology or similar codec for compression a scalable codec is selected to meet the given requirements in terms of compression latency etc. . . . . In particular the JPEG2000 compression scheme provides particularly useful features. For example JPEG2000 can provide visually lossless compression while still reaching a reasonable compression ratio. JPEG2000 provides through the progression mechanism already a usable form of downscaling. This may avoid the need for the implementation of a downscaler on the display controller inputs. A large number of sources being displayed need not be shown in full resolution. For these images lossy compression is allowed and JPEG2000 supports such scalability and quality shaping. Influencing compression characteristics allows optimizing the required bandwidth and latency. JPEG2000 supports tiling sending out the compressed image in tiles brings down the latency as decoding can start as soon as the first tile is being received instead of having to wait for a complete frame. Splitting the encoded image transmission into multiple streams containing different progressions allows minimizing the network load endpoints not requiring the high resolution information can subscribe to only the streams with the low resolution data.

This particular embodiment uses a plurality of decoding devices e.g. ADV202 s for the encoding of multiple channels or to support a lower number of channels at higher resolution. Separation of different JPEG2000 progressions into multiple streams is provided by the network processing block. Tiling can be used to reduce the end to end latency. Effective use can be made of the different JPEG2000 frequency levels e.g. wavelet scaling to reduce the required bandwidth towards the DGU s . A DGU will only receive data up to the scale factor it needs.

The DGU in accordance with the first embodiment of the present invention as described above is shown in . The block schematic shown describes the different functional parts provided in the DGU mezzanine.

The DGU unit receives a number of encoded signals unicasted or multicasted on the network through the redundant 1 Gb s network interface in a number of input buffers RJ45 Magnetics PHY . The buffered signals are processed in a processor Network processing SDRAM Flash . The received signals are then decoded in a decoder Codec logic SDRAM ADV202 and transferred across the baseboard mezzanine interface of the multi viewer driver e.g. Hydra to the baseboard of the multi viewer driver e.g. Hydra. This baseboard takes care of inserting the decoded image on the internal bus of the multi viewer driver e.g. Hydra. A controller block SDRAM flash processor with an own redundant fast Ethernet network interface to separate streaming and control channels RJ45 Mac Phy is used to control the display generator unit . The Hydra Single Board Computer SBC is used to render metadata and embedded information.

A particular embodiment of a standalone DGU unit of the second embodiment is shown schematically in . The standalone DGU has a design which is different from the DGU mezzanine as described above.

Because of the fact that the DGU has to take over the rendering capability of the multi viewer driver e.g. Hydra single board computer the DGU can be equipped with a drawing unit existing of a GPU graphical processor unit graphical accelerator DDR SRAM panellink transmitter . Multiple decoding units can be hooked up to a single DGU enhancing or increasing the number of signals that can be decoded and shown. The encoded signals are received across an Ethernet input block Network processing PHY and decoded by a decoder block which might contain different types of decoding devices or decoders e.g. ADV202 for JPEG2000 an MPEG2 4 decoding DSP . . . . The decoded signals are subsequently rendered by the GPU of the drawing unit .

Since this board can accept a high number of coded input streams bandwidth limiting actions may be required on the side of the encoder e.g. on SCU side to minimize the network load on the DGU or the network interface on the DGU side may be designed to have a higher bandwidth than the SCU. For example the load may be divided over one or more pairs of Gigabit network interfaces in accordance with an aspect of the present invention.

The following functional blocks can be used in this DGU the drawing unit the decoding units and the CPU unit . These building blocks are connected together via a switching means e.g. via a PClexpress switch. The decoding units execute the same function as in the first embodiment. The single board computer SBC of the Hydra in the first embodiment is replaced by the drawing unit and CPU unit in the second embodiment. This separation allows to provide better performance on both the CPU and drawing functionality. The CPU unit is in control of the setup and operation of the DGU unit and can receive commands across a separated control network out of band control or across the video network in band control . The decoding unit receives the encoded information across the gigabit interface decodes the information and forwards it to the drawing unit . The drawing unit renders the information requested in the graphics configuration file e.g. tagged mark up language configuration document .

The Video Processing unit e.g. FPGA is responsible for the reception of the encoded information from the network as well as the decoding and forwarding of the information to the graphic accelerator of the drawing unit . To ensure enough video processing capability for 2 times UXGA graphic resolution and to support overlapping video windows the Video Processing unit e.g. FPGA together with its appropriate compression e.g. JPEG2000 decoders is available multiple times.

The streams coming from the encoders e.g. SCUs preferably have to following properties in this embodiment 

The DGU generates the output for one two or more display units e.g. monitors or projectors. It is aware of the X Y position of the display units within a physical display wall for which it generates the output and performs the necessary clipping to render the graphics information received.

The DGU should introduce as little delay e.g. frame delays as possible into the video streams between the video being present on the network and the videos getting visible on the display unit e.g. monitor or projector. illustrates frame delay introduced by DGU internal processing. shows that the estimated frame delay for an embodiment is approximately 3 frames progressive scan . But this mainly depends on the size of the tiles. Smaller tiles introduce less delay.

In accordance with the present invention streams are broken down at the streaming server side so multiple streams each having different kinds of information are obtained. Even the compressed video stream can be transmitted in different parts each containing a subset of the information. Clients may have to subscribe to multiple streams to receive the information required for decoding. The reason for this added complexity is scalability. If all information would be combined the needed bandwidth would be very high. This would make it impossible for a standard PC to receive multiple streams. In case of the present invention only the parts of the information needed are received.

Coupling this with the size of the video windows in discrete steps makes it possible to state that we can show unlimited sources as we can now provide decoding capacity to fill as many pixels as the displays provide. If large windows are used more info will be taken for that source from the network. If multiple smaller windows are used smaller pieced are taken for each source from the network.

As said each source can provide multiple separated streams providing embedded or metadata information. Clients need to ask the server sourcing the stream to provide them with the wanted information otherwise the information is pruned to reserve bandwidth.

Information can be streamed on the network using point to point connections or using multicast connections. Multicast connections are limited resources. This means the assignment of multicast addresses has to be managed in a dynamic way to make sure that no traffic bottlenecks exist as x unicasts require x times the bandwidth of a single multicast stream within the network.

Decoding a source and switching to another source has to happen substantially instantaneously. This means that both the previous source and the new source to be displayed have to be decoded at the same time requiring the information from both sources to be transferred during the transition period. To prevent exceeding available bandwidth the subscription to multiple parts of a video stream has to be handled dynamically.

The data and command flow of a system according to the present invention are illustrated by means of .

A control unit also called Media Operating System sends a graphics configuration file e.g. a tagged mark up language configuration document e.g. an XML document or an SVG document to the DGUs . This configuration document includes a definition of a task of each of the DGUs and is stored in the DGUs .

Encoded streams or SCU streams i.e. image data streams encoded in the encoders e.g. JPEG2000 encoded source data to several multicast IP addresses on the shared resource network not illustrated in . The IP addresses or multicast groups are regarded as the unique identification of a certain source which is processed within a DGU . The Media Operating System via the configuration document tells the DGU to which IP addresses it has to subscribe and how the dedicated source has to be processed in terms of scaling color space conversion and positioning.

The network interface of the DGU for receiving the e.g. JPEG2000 encoded SCU streams is preferably implemented in hardware to guarantee maximum throughput with minimum processor intervention. The streams to be received are defined by a dedicated MAC addresses. The hardware receives this MAC address from a conversion block PPC which does the conversion from IP addresses to MAC addresses.

Packet reordering up to certain level is supported by using Data Address Offset DAO within the packet header which may be a proprietary header introduced to ease DGU design. This header will be added by the encoder SCU to each network packet. The DAO in this header specifies the byte address offset for data sent within this packet relative to the start of the tile.

Identification of incoming streams is done completely by IP addressing. Each tile of an input source is identified by its multicast IP address. The control unit Media Operating System has all information available which tiles a DGU has to receive in order to visualize the desired part of a source. Identification of incoming frames is done by means of an input frame counter embedded in the packet header this is used to determine which packets belong to which input frame.

Positioning of insertion rectangles on the screen is part of the operating system e.g. Xwindows running on the DGU . X.11 windows without borders may for example be used which insertions are mapped to. So standard X.11 methods can be available to achieve positioning. The relation between an input stream and an X.11 window is defined via Streams HAL. This hardware access layer HAL is an API application programming interface providing access to the Hydra hardware.

The DGU is capable of performing both up and down scaling by using the texture engine of the graphic accelerator e.g. a P25 . The control unit Media Operating System tells the DGU by means of the configuration document which scaling operation has to be done on the dedicated input stream. Therefore it defines source size and destination size for each stream of tiles which has to be processed within the DGU . The destination size is in fact the size of the X.11 window which defines the streams area on the screen of the display unit . So standard X.11 methods can be used to feed this information to the DGU . The relation between and input stream and an X.11 window is defined via Streams HAL.

The output color format on the DGU is typically RGB. The DGU is capable of converting any input stream from a first color format e.g. YUV 4 2 2 to a color format to be displayed e.g. RGB. This is done within the texture engine of the graphic accelerator e.g. a P25 . The control unit Media Operating System tells the DGU via the configuration document which color format the incoming stream has. Based on this DGU performs color space conversion to the color format to be displayed if necessary.

For overlapping images alpha blending can be defined for each source in 256 color levels. When set to 0 the foreground is completely transparent. When it is set to 1 it becomes opaque and totally obscures the background. Any intermediate value creates a mixture of the two images as illustrated in .

For non rectangular display areas one can have non rectangular cropping or non rectangular mapping. In non rectangular cropping a source image can be cropped in a way that any non rectangular part of it is visible on the screen. Via Streams HAL any client may specify a pixel oriented on off bitmap output coordinates for each source which specifies the visible part on the image. Amongst others this allows to visualize control and monitoring elements within a source e.g. audio metering in an effective way. In non rectangular mapping a source image is mapped to a non rectangular area both 2 dimensional e.g. rhombus and 3 dimensional e.g. sphere . This is possible by using 3D capabilities of the graphic accelerator e.g. a P25 .

Using 2D or 3D graphics accelerator capabilities it is possible to underlay or overlay graphics and decoded compressed information with respect to one another see . This allows e.g. for efficient ways to mark up decoded compressed information.

As long as no further action is taken the DGU will run in free running mode which means the output timing is generated internally and not locked to another device neither encoder SCU nor DGU . This means that different DGUs driving display units forming one display wall are not synchronized so they will not necessarily display the same frame at the same moment in time. As a consequence a user may see 2 different parts of one picture if a stream has to be shown on more than one screen as illustrated in .

This effect can be avoided by running DGUs in frame lock mode which means their output timing is locked to the output timing of another DGU . The result is that at any moment in time for the frame locked DGUs a user always sees the two corresponding parts of one picture as illustrated in .

In HW based frame lock there is an input connector available on the DGU which accepts an external VSync or blackburst signal. If enabled via Streams HAL the DGU locks its vertical retrace signal to this input. Furthermore the DGU can deliver its Vsync via a connector to the external world. So via cabling one DGU which is programmed to free running mode the Vsync can be provided to all other DGUs which are programmed to use the external Vsync input as reference.

In network based frame lock frame lock is possible without having a dedicated cable connection between DGUs based on synchronization packets sent by one of the DGUs which are then reconstructed within another DGU to a vertical retrace signal. This network based frame lock mode can be established using time synchronisation standards such as for example IEEE 1588 or using proprietary solutions such as described below 

A DGU can subscribe to a dedicated multicast address which is considered to be the connection to receive synchronization packets. These packets are used to reconstruct internally a Vsync signal which can be used as vertical retrace. Synchronization of DGU operations within the DGU is done based on the vertical retrace signal Vysnc which allows operations to occur always frame synchronized. Furthermore the synchronization packet contains a start value for the output frame counter which is loaded if DGU is told to do so by means of the configuration document .

The synchronization packet is sent by the synchronization master within the system. This can be either an encoder SCU genlock as illustrated in or a DGU framelock . The control unit Media Operating System determines which device is synchronisation master and tells this to the system by means of the configuration document . So both encoder SCU and DGU are able to send the synchronization packet to a dedicated multicast address. When sending synchronisation packets jitter has to be minimized because the send frequency of this packet reflects the vertical refresh rate of the source.

The synchronization packet may be a standard UDP packet which e.g. contains 64 bit data. A possible data format thereof is illustrated in .

All source tiles of one frame are logically tied together by a common Input Frame Counter which is available within the proprietary packet header. Several frames of different sources can be synchronized to one output frame by defining a layout switch to be done at one output frame. The control unit Media Operating System may define all tiles to be switched at the same moment by passing a linked list of source tile descriptors as illustrated in to DGU headed by a descriptor defining the output frame at which the layout switch should occur.

The DGU provides a 32 bit output frame counter which is incremented on each vertical retrace. It can be set and read by the control unit Media Operating System via Streams HAL . Also the frame counter may be set automatically to the value defined within a synchronization packet.

The output frame counter is used for both frame lock and genlock to make sure that all DGUs display the same output frame at the same moment in time. Also it can be used to perform time based layout switch.

When describing a layout switch operation via Streams HAL it is possible to define at which output frame the new arrangement of streams should appear. Knowing both actual output frame and vertical refresh frequency the control unit Media Operating System can send stream related commands to the DGUs in advance by means of a configuration document and their result will appear at a defined moment in time.

A software layering on the Hydra DGU or standalone DGU according to embodiments of the present invention is illustrated in more detail in . A multi protocol server different socket connections per protocol e.g. based on X.11 is running on DGU to allow to applications like the control unit Media Operating System access to streams processing and rendering capabilities. Besides standard X.11 protocol including standard X extensions this server offers a configuration document interface e.g. an SVG interface as well as an API to control stream related functionality Streams HAL .

The hardware abstraction layer HAL for streams commands is in fact the API provided by DGU to allow external clients like the control unit Media Operating System to control subscription and processing of streams delivered by encoders SCU via the network . Streams related commands which have to be processed by the graphic accelerator P25 are translated to either 2D or 3D e.g. Direct3D OpenGL calls.

Each stream inserted to DGU is displayed within a window e.g. an X.11 window without borders which offers a display area for the incoming live stream source . There is a one to one relation between a window and a source. The window is filled completely with the dedicated source. This allows usage of standard e.g. X.11 methods to control positioning and scaling of streams which is equal to modify position and size of the window.

As described above streams related functions have to be synchronized to the output frame number. Using e.g. the standard X.11 API this would not be possible. This means X.11 calls to configure the X.11 window which is used to display a source cannot be done directly by the control unit Media Operating System . In fact the X.11 call to configure the window will be done by Streams HAL as soon as the control unit Media Operating System asks Streams HAL to provide a new configuration position scaling stacking order of a source to be displayed on the screen.

From the logical point of view Streams HAL has to provide additional functionality which is described below. This list should not be regarded as a description how the API is implemented but merely provides a view on possible additional functionality of the API to be provided.

Implementation of an SVG scalable vector graphics interface based on X.11 allows document based rendering according to embodiments of the present invention as an alternative way for external applications to initiate rendering operations on a DGU .

X.11 may be provided as a 2D and 3D rendering interface for external applications like the control unit Media Operating System . Standard X protocol is supported.

The processing of live streams may be done using the texture engine of the graphic accelerator eg. P25 . OpenGL is preferably used internally as an interface to control texture engine e.g. Direct3D could be used on a MS Windows based platform . It is integrated within the X.11 server using GLX extension. Streams related commands sent by application via Streams HAL or X.11 API are translated to OpenGL calls which are processed by the graphic accelerator e.g. P25 .

The video FPGA MAC controls the MAC interface within the Video FPGA . After sending MAC addresses to the video FPGA main parts of both network protocol and streams processing is done by hardware.

The video FPGA DMA controls the DMA part of the Video FPGA . It forwards the streams related graphic accelerator commands which will be synchronized to the decoded stream and sent to the dedicated streams queues after stream data are transferred to the graphic accelerator eg. P25 .

The loadable Xserver module for the graphical accelerator e.g. P25 3D serves the purpose of processing OpenGL commands called via the GLX extension. It uses a direct rendering module DRM to access the HW of the graphic accelerator . Direct Rendering Module DRM is a Linux kernel module driver which performs HW access to the graphic accelerator eg. P25 . Standard 2D rendering operations are handled by means of another loadable Xserver module eg. P25 2D .

The proxy architecture as shown in allows X11 applications to be used multi screen without having a single point of failure fault tolerance . Each proxy server accepts the same calls as the local multi protocol server and passes them to the dedicated DGUs .

A proxy server architecture used to access DGU in accordance with embodiments of the present invention may be a multi protocol Proxy Server which supports 

Any application may access DGU resources via the proxy server architecture in order to display their output on the display unit . If a standard application is started the dedicated proxy proxy proxy in has to ask the control unit Media Operating System for an area on the screen to display its output. Once assigned this is an exclusive display area for this application. It can be changed at runtime but there is no possibility to run a client window manager who allows to move these exclusive display areas interactively using the mouse pointer. As soon as exclusive display areas are used all changes of position and size have to be controlled by an application wall management software based on the control unit Media Operating System .

Applications e.g. applications by the owner of the present invention accessing DGUs via the control unit Media Operating System have no need for exclusive display areas . As long as no other applications are used it would be possible to run the display wall in interactive mode where the operator may change window position via mouse pointer. This restriction reduces interactive work with the display wall .

In another embodiment the proxy server architecture may be a multi screen proxy in which each proxy server allows an application to perform X.11 calls dedicated to a certain number of DGUs which form a contiguous rendering area. The inherent multi screen approach is fully transparent to the application. The application sees just one big surface. Proxy servers acting as multi screen X.11 servers can be started several times on several machines within the network. This allows to have one proxy per application or even one application e.g. Multimedia Operating System using several proxies. So if one machine would crash this application would not be visible any longer on the display wall but all other application would keep on running. In that respect this concept is very flexible and fault tolerant.

The control unit Media Operating System may use several proxies to achieve fault tolerance. Only one of them is active at a given moment in time and controls the display. Others proxies are operating in hot stand by to take over in case of emergency machine crash . The active proxy controls the complete multi screen display comprising several DGUs .

The networked display controller architecture as described above is preferably scalable towards low end and high end systems. The network approach communication methods choice of protocols actual devices usable etc. . . . is to a large extent dependant on the performance of the network in terms of connection and disconnection latency subscription join and leave latency etc. . . . . Optimization of these parameters is very important towards overall usability specifications of the system. For instance it is preferred to be able to stop a stream very quickly as this means it would be possible to switch rapidly between different streams on a single connection.

The Ethernet network interconnecting encoders SCUs and DGUs has several limitations. Two important ones are 

As a result the driver needs to take these into account when managing the resources of this network. As a first step it needs to know the actual current topology of the network which might vary over time due to network failures . Since the Ethernet network should be considered as a black box it needs to interrogate this network by means of a standardized mechanism e.g. SNMP management information to gather this information. By combining this information with knowledge from the end systems e.g. the MAC addresses of the connected encoders SCUs and DGUs the driver can build a full view on the network connectivity e.g. which equipment is connected to which Ethernet port . If information is not available directly i.e. number of supported multicast groups on a switch it can be made available through an additional database of supported equipment. The algorithms for topology detection will then need to link device type information with this database.

Knowing the exact topology of the network the driver needs to tune encoding parameters in the encoder SCU to influence network bandwidth requirements. These parameters will be bounded by a minimal required value and will have a desired value both values will need to be part of the request . A priority indication for each of the connections that might depend on the actual application or on the privileges of the operator that wants to use the connection will complement this. This priority will determine which connections get precedence when negotiating for bandwidth.

The request parameters and network constraint together form a complex QoS matching problem. This becomes even more complex when transition scenarios need to be taken into account. In that case also the transition of one set of connection to another needs to be provisioned when looking at the capacity requirements of the network. This might for instance mean a temporal reduction of video quality to free capacity during the transition.

Network problems or impossible connection requests need to be detected and propagated upwards to the wall management layer as this layer needs to make decisions on the set of connections to be established if new bottlenecks are showing up.

Different approaches can be taken towards finding a solution to process and deliver the input signals to their destination such as take the first solution found fastest try balance network load try to balance processor load trying to minimize network load by running as much services as possible on the same processor node. Whatever approach or combination of approaches is chosen the visual effects of modifying a set of connections should be kept minimal and happen within an acceptable timeframe in order not to disturb the modus operandi of the display wall.

In these embodiments are illustrated the 3 types of streams that will be present in the system the video streams going from encoders SCU to DGU s the audio and data streams sent from encoder s SCU s and used by the iStudio control software to create an internal model of the data and finally the graphical stream representing the information to be shown on the DGUs . The viewers are showing a representation of a model. The drawing engine draws this representation with help of the DGUs and mixes it with the video streams on the DGU s . The connection manager is responsible for setting up and maintaining the needed connectivity in the system. Care has to be taken to minimize the delays introduced by each service in the distributed architecture e.g. by minimizing real network transfers by avoiding data copies . . . in order to obtain acceptable and predictable overall system latency.

The software is preferably distributed and controllable through a web interface. A UI is provided to demonstrate the product but the normal usage will be by integration into existing broadcast environments using web services. The images generated on each head display unit of the networked studio are genlocked. For example all heads can be synchronized on vertical retrace pulses and or a possible external genlock reference signal .

Information arriving across the network will at first be buffered to account for network delays and possible jitter. The network being a shared medium it would be impossible to let a decoder work immediately on the information received without buffering. Using buffering we can guarantee that the decoder will not stall due to lack of information. In practice we expect to always submit a fully received frame. To achieve low latency the size of the buffer has to be kept low.

An information stream representing a single source eg. SDI stream or a combined derived measurement may contain different types of information that may be routed to different endpoints e.g. audio and video information.

Larger and very loaded networks may require bigger buffers to compensate network delays and jitter. Buffering together with deterministic behavior of the network make it necessary to also provide explicit synchronization of the received frames to make sure that the images shown on different display units are parts of the same frame.

This requires fast and accurate synchronization between the input and output units on the network a tolerance of 10 20 usec would be the maximum allowed. One way of achieving this might be the implementation of the IEEE1588 Precision Time Protocol. The inclusion of this genlock is considered to be part of the framework on top of which the iStudioNG application is built.

The above described method embodiments of the present invention may be implemented in a system e.g. a computer processing system as described above. The system includes a plurality of programmable processors coupled to a memory subsystem that includes at least one form of memory e.g. RAM ROM and so forth. It is to be noted that the processor or processors may be a general purpose or a special purpose processor such as a gaming processor and may be for inclusion in a device e.g. a chip that has other components that perform other functions. Thus one or more aspects of the present invention can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The processing system may include a storage subsystem that has at least one disk drive and or CD ROM drive and or DVD drive. In some implementations a display system a keyboard and a pointing device may be included as part of a user interface subsystem to provide for a user to manually input information. Ports for inputting and outputting data also may be included. More elements such as network connections interfaces to various devices and so forth may be included as described above. The memory of the memory subsystem may at some time hold part or all of a set of instructions that when executed on the computer processing system implement the steps of the method embodiments described herein. A system that includes the instructions to implement aspects of the methods for obtaining information for or for optimising of the lithographic processing of a substrate is not prior art.

The present invention also includes a computer program product which provides the functionality of any of the methods according to the present invention when executed on a computing device e.g. as described above. Such computer program product can be tangibly embodied in a machine readable storage medium carrying machine readable code for execution by a programmable processor. The present invention thus relates to a machine readable storage medium carrying a computer program product that when executed on computing means provides instructions for executing any of the methods as described above. The term machine readable storage medium refers to any medium that participates in providing instructions to a processor for execution. Such a medium may take many forms including but not limited to non volatile media and transmission media. Non volatile media includes for example optical or magnetic disks such as a storage device which is part of mass storage. Common forms of computer readable media include a CD ROM a DVD a flexible disk or floppy disk a tape a memory chip or cartridge or any other medium from which a computer can read. Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to a processor for execution. The computer program product can also be transmitted via a carrier wave in a network such as a LAN a WAN or the Internet. Transmission media can take the form of acoustic or light waves such as those generated during radio wave and infrared data communications. Transmission media include coaxial cables copper wire and fibre optics including the wires that comprise a bus within a computer.

Further inventions which may be used independently or with the inventions described above are described hereinafter.

I Tagged or Mark Up Language e.g. XML Based Content Description for Use in Controlling the Display of Images Using the Above System

The use of a tagged mark up language configuration document such as an XML or SVG document to provide the definitions for how elements of the above system should deal with each information e.g. video stream has many advantages. For example if each element of the above system has received a tagged language document giving the details of how a video stream is to be displayed then in case of a fault on one processing device the process can be swapped to another and the information required to process the video stream will be available from the same tagged mark up language configuration document which has been multicasted or broadcasted around the network . Such a configuration document is attached in annex and controls video streams to display an image as shown in .

Display wall processors typically provide the capability to organize the content of the display wall . Many but not all display wall processors have the capability to store a certain arrangement of content typically referred to as layout so that it can later be recalled by simple request. A display processor normally relies on the presence of a central processor to interpret the layout definition and to translate this in the right commands towards the underlying equipment to arrange the content as requested.

The display generator units define a viewport on the XML description or configuration document to filter out their assigned tasks. Rendering of the graphical content happens in parallel locally on each of the display generator unitss reading multimedia information allows the display generator unit to fill in the appropriate multimedia content.

According to an embodiment of this invention one mark up language description e.g. XML configuration document of the whole output is provided i.e. one mark up language configuration document for a large number of display units e.g. in a matrix or an array of display units forming a display wall . This configuration document includes data relating to location of all images over the complete display wall spreading of the images over the plurality of display units etc.

At start up the single mark up language configuration description of the whole output as generated by the drawing engine is distributed to all display generator units for calibration. Each display generator unit knowing the X Y location of a corresponding display unit in the display wall clips out the area it needs by means of the viewport functionality of the SVG viewer used to render the tagged mark up language configuration file and based on the information in the relevant part of the mark up language description subscribes to relevant streams identified by an SCU unicast IP address or a multicast group IP address in the network where it takes the information it needs. Subscription to only a part of the image streams reduces the load on the network . Such subscription to only a part of the image streams is possible e.g. when using JPEG2000 as a compression scheme and making the different streams available on different addresses or multicast groups.

It is an advantage of this invention that each display generator unit once calibrated can act independently. Each display generator unit independently performs the tasks it has to perform to enable the visualisation of image information although the content of the image information spans over a plurality of display units .

Embodiments of the present invention relate to multiple streaming servers serving multiple end users each end user being able of simultaneous handling of multiple streams of the different servers.

Current display walls and their display wall controllers are very vulnerable. Failure of a component can lead to loss of information for the user. This is due to the fact that a display wall processor has typically only one internal transmission infrastructure bus e.g. that there is typically only one central processor providing the logic to the complete system and that outputs have a direct physical connection to a display device. This situation leads to complete duplication of the display wall processor in those circumstances where redundancy is required.

An aspect of this invention lies in an architecture that makes it possible to build a display wall consisting of N display units with N 1 display generator units only with fault tolerance against failure of one of the display generator units even with absent central logic processor.

When a display generator unit of the display wall processor fails the extra display generator unit can take over the task of any other due to the fact that that display generator unit holds the whole description of the display wall as described above with regard to the configuration document e.g. mark up language description and the fact that it can subscribe to the appropriate sources to be displayed while at the same time the display unit can switch to the second input. The second input of all display units is connected to the redundant display generator unit . The display generator unit contains sufficient information and is capable of organizing itself in such a way that it can take over the role of any of the other display generator units . This is illustrated in .

III. Scalable Synchronized Distributed Rendering with Embedded Rendering Priorization Automatic Load Adaptation and Redundancy Mechanisms.

Matrixes of display units are used to render information when the resolution of a single display is too limited to show the needed content. Images can be sent over the network with a high resolution e.g. 3000 4000 pixels. If the image is larger than a display unit the image stream can be split so as to display the image over a plurality of display units in the matrix and each display unit can subscribe only to the part it needs.

In case of such matrices of display units rendering of information on the display matrix wall must be synchronized to avoid image tearing and misaligned images across display boundaries. Current architectures use some form of central instance be it hardware or a software process to distribute the rendering information and to synchronize the rendering by one or multiple rendering devices. This central instance is a single point of failure and most likely a performance bottleneck when wall size and the amount of information shown gets larger. For performance reasons most central instances will cache information in the rendering devices making an n 1 redundancy scheme on these devices impossible and making hot plugging impossible. When the central instance is becoming a bottleneck the processes delivering the information is normally slowed down to cure the situation.

A problem to be solved is how to display a number of visual sources video computer graphics offered in various formats on a number of control room visualization systems whereby the visualization systems can be multiple and physically separated whereby each visualization system on itself has a high degree of modularity in that it exists out of a number of display units whereby a source might need to be displayed various times in various sizes resolutions or with various quality levels e.g. limited by bandwidth between source and visualization system whereby real time behaviour has to be achieved real time defined as an end to end latency below 80 milliseconds.

The distributed display wall processor consists of N input units M output units and one or more logic control units. All these components use a consumer of the shelve COTS non proprietary IP network to send and receive all control data and all multimedia content.

The aspect of this invention lies in the combination of using a scalable video codec e.g. based on JPEG2000 on input side appropriate network stream organization before transmission combined with composing the output based on selecting the right streams and the right elements out of the streams decode and use a programmable 3D graphical processor to map video textures to the wanted output. The encoding at input side is done to reduce needed bandwidth to introduce a coarse scaling level 1 1 1 2 1 4 1 16 . . . and to be able to arrange the data in multiple multicast streams in such a way that bandwidth usage is optimal esp. avoiding clogging of the output units and exploiting the multicast capabilities of the network. The graphical processor at the receiving end does scaling to the exact display size as many times as needed and assures correct display order z order . The novelty lies also in using standard network equipment for the transmission between inputs and outputs resulting in a control room display processor with the capability of a fault tolerant transmission between inputs and outputs.

Current display wall processors are physically constrained between inputs and outputs signal distribution is always done externally all processors have limits on how many times a source can be displayed typically once or in how many sizes a source can be displayed. All current processors depend on an internal data transmission mechanism resulting in an architecture where the display wall processor is a single point of failure. This is no longer the case in the proposed solution.

The difficulties lie in the amount of data to be processed addressing the real time aspect bandwidth optimization without giving in on quality or latency network management frame accurate synchronization of all visual content the logic control of a distributed system.

Here again this embodiment of the invention is performed by using a configuration document e.g. mark up language description of the whole distributed system. This mark up language configuration document is read into the multiple display units which interpret it and act upon it. Each of the display units may display a different format and or a different quality of image.

For the above embodiments the mark up language configuration document may be composed by the drawing engine on a central processing device e.g. a standard PC and may be distributed from there.

Embodiments of the present invention include distributed commands based on a mark up language document. Such a document is attached in annex and can be used to display the various video streams as shown in .

It is to be understood that although preferred embodiments specific constructions and configurations as well as materials have been discussed herein for devices according to the present invention various changes or modifications in form and detail may be made without departing from the scope and spirit of this invention.

