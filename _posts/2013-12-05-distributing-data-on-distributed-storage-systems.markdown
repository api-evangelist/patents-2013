---

title: Distributing data on distributed storage systems
abstract: A method of distributing data in a distributed storage system includes receiving a file into non-transitory memory and dividing the received file into chunks using a computer processor in communication with the non-transitory memory. The method also includes distributing chunks to storage devices of the distributed storage system based on a maintenance hierarchy of the distributed storage system. The maintenance hierarchy includes maintenance units each having active and inactive states. Moreover, each storage device is associated with a maintenance unit. The chunks are distributed across multiple maintenance units to maintain accessibility of the file when a maintenance unit is in an inactive state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09367562&OS=09367562&RS=09367562
owner: Google Inc.
number: 09367562
owner_city: Mountain View
owner_country: US
publication_date: 20131205
---
A distributed system generally includes many loosely coupled computers each of which typically includes a computing resource e.g. one or more processors and or storage resources e.g. memory flash memory and or disks . A distributed storage system overlays a storage abstraction e.g. key value store or file system on the storage resources of a distributed system. In the distributed storage system a server process running on one computer can export that computer s storage resources to client processes running on other computers. Remote procedure calls RPC may transfer data from server processes to client processes. Alternatively Remote Direct Memory Access RDMA primitives may be used to transfer data from server hardware to client processes.

One aspect of the disclosure provides a method of distributing data in a distributed storage system. The method includes receiving a file into non transitory memory and dividing the received file into chunks using a computer processor in communication with the non transitory memory. The method also includes distributing chunks to storage devices of the distributed storage system based on a maintenance hierarchy of the distributed storage system. The maintenance hierarchy includes maintenance units each having active and inactive states. Moreover each storage device is associated with a maintenance unit. The chunks are distributed across multiple maintenance units to maintain accessibility of the file when a maintenance unit is in an inactive state.

Implementations of the disclosure may include one or more of the following features. In some implementations the method further includes restricting the number of chunks distributed to storage devices of any one maintenance unit.

In some implementations the method further includes determining a distribution of the chunks among the storage devices by determining a first random selection of storage devices that matches a number of chunks of the file and determining if the selection of storage devices is capable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state. In some examples when the first random selection of storage devices is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the method further includes determining a second random selection of storage devices that match the number of chunks of the file or modifying the first random selection of storage devices by adding or removing one or more randomly selected storage devices. The method may further include determining the first random selection of storage devices using a simple sampling a probability sampling a stratified sampling or a cluster sampling.

In some implementations the method further includes determining a distribution of the chunks among the storage devices by selecting a consecutive number of storage devices equal to a number of chunks of the file from an ordered circular list of the storage devices of the distributed storage. When the selected storage devices are collectively incapable of maintaining the accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the method further includes selecting another consecutive number of storage devices from the ordered circular list equal to the number of chunks of the file. Additionally or alternatively the method further includes determining the ordered circular list of storage devices of the distributed storage system. Adjacent storage devices on the ordered circular list are associated with different maintenance units. In some examples a threshold number of consecutive storage devices on the ordered circular list are each associated with different maintenance units or are each in different geographical locations.

In some implementations the method further includes determining the maintenance hierarchy of maintenance units e.g. using the computer processor where the maintenance hierarchy has maintenance levels and each maintenance level includes one or more maintenance units. The method also includes mapping each maintenance unit to at least one storage device. In some examples each maintenance unit includes storage devices powered by a single power distribution unit or a single power bus duct. Additionally or alternatively maintenance units may include storage devices associated with a cooling unit or some other piece of equipment that needs maintenance either sporadically or routinely .

The method may further include dividing the received file into stripes. Each file includes a replication code or an error correcting code. When the file includes a replication code the method includes replicating at least one stripe as replication chunks. When the file includes an error correcting code the method includes dividing at least one stripe into data chunks and code chunks. The method may also include distributing replication chunks among the storage devices differently than distributing the data chunks and the code chunks among the storage devices.

Another aspect of the disclosure provides a system for distributing data in a distributed storage system. The system includes non transitory memory a computer processor and storage devices. The non transitory memory receives one or more files from users. The computer processor communicates with the non transitory memory and divides the received files into chunks. The storage devices communicate with the computer processor and the non transitory memory. The computer processor stores the chunks on the storage devices based on a maintenance hierarchy of the distributed storage system. The maintenance hierarchy includes maintenance units having active and inactive states. Each storage device is associated with a maintenance unit. The computer processor distributes the chunks across multiple maintenance units to maintain accessibility of the file when a maintenance unit is in an inactive state.

In some examples the computer processor restricts a number of chunks distributed to storage devices of any one maintenance unit. The computer processor may determine a distribution of the chunks among the storage devices by determining a first random selection of storage devices matching a number of chunks of the file and by determining if the selection of storage devices is capable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state. Additionally or alternatively the computer processor may determine a second random selection of storage devices matching the number of chunks of the file when the first random selection of storage devices is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state.

In some implementations the computer processor modifies the first random selection of storage devices by adding and removing one or more randomly selected storage devices when the first random selection of storage devices is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state. Additionally or alternatively the computer processor may determine the first random selection of storage devices using a simple sampling a probability sampling a stratified sampling or a cluster sampling.

In some examples the computer processor determines a distribution of the chunks among the storage devices by selecting a consecutive number of storage devices equal to a number of chunks of the file from an ordered circular list of the storage devices of the distributed storage system. Additionally or alternatively the computer processor may select another consecutive number of storage devices from the ordered circular list equal to the number of chunks of the file when the selected storage devices are collectively incapable of maintaining the accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state.

In some implementations the computer processor determines the ordered circular list of storage devices of the distributed storage system where adjacent storage devices on the ordered circular list are associated with different maintenance units. Additionally or alternatively a threshold number of consecutive storage devices on the ordered circular list may each be associated with different maintenance units. Additionally or alternatively a threshold number of consecutive storage devices on the ordered circular list may each be in different geographical locations.

In some examples the computer processor determines a maintenance hierarchy of maintenance units and maps each maintenance unit to at least one storage device. The maintenance hierarchy has maintenance levels with each maintenance level including one or more maintenance units. Additionally or alternatively each maintenance unit may include storage devices powered by a single power distribution unit or a single power bus duct.

In some implementations the computer processor divides the received file into stripes with each file including a replication code and or an error correcting code. When the file includes a replication code the computer processor replicates at least one stripe as replication chunks. When the file includes an error correcting code the computer processor divides at least one stripe into data chunks and code chunks. Additionally or alternatively the computer processor may replicate chunks among the storage devices differently than distributing the data chunks and the code chunks among the storage devices.

The details of one or more implementations of the disclosure are set forth in the accompanying drawings and the description below. Other aspects features and advantages will be apparent from the description and drawings and from the claims.

Storage systems include multiple layers of redundancy where data is replicated and stored in multiple data centers. Data centers house computer systems and their associated components such as telecommunications and storage systems . Data centers usually include backup power supplies redundant communications connections environmental controls to maintain a constant temperature and security devices. Data centers may be large industrial scale operations that use a great amount of electricity e.g. as much as a small town . Data may be located in different geographical locations e.g. different cities different country and different continents . In some examples the data centers or a portion thereof requires maintenance e.g. due to a power outage or disconnecting a portion of the storage system for replacing parts or a system failure or a combination thereof . The data stored in these data centers may be unavailable to users during the maintenance period resulting in the impairment or halt of a user s operations. Therefore it is desirable to provide a distributed storage system where a user is capable of retrieving stored data despite the storage system or portions thereof undergoing maintenance.

Referring to in some implementations a distributed storage system includes loosely coupled memory hosts e.g. computers or servers each having a computing resource e.g. one or more processors or central processing units CPUs in communication with storage resources e.g. memory flash memory dynamic random access memory DRAM phase change memory PCM and or disks that may be used for caching data. A storage abstraction e.g. key value store or file system overlain on the storage resources allows scalable use of the storage resources by one or more clients . The clients may communicate with the memory hosts through a network e.g. via RPC .

In some implementations the distributed storage system is single sided eliminating the need for any server jobs for responding to remote procedure calls RPC from clients to store or retrieve data on their corresponding memory hosts and may rely on specialized hardware to process remote requests instead. Single sided refers to the method by which most of the request processing on the memory hosts may be done in hardware rather than by software executed on CPUs of the memory hosts . Rather than having a processor of a memory host e.g. a server execute a server process that exports access of the corresponding storage resource e.g. non transitory memory to client processes executing on the clients the clients may directly access the storage resource through a network interface controller NIC of the memory host . In other words a client process executing on a client may directly interface with one or more storage resources without requiring execution of a routine of any server processes executing on the computing resources . This single sided distributed storage architecture offers relatively high throughput and low latency since clients can access the storage resources without interfacing with the computing resources of the memory hosts . This has the effect of decoupling the requirements for storage and CPU cycles that typical two sided distributed storage systems carry. The single sided distributed storage system can utilize remote storage resources regardless of whether there are spare CPU cycles on that memory host furthermore since single sided operations do not contend for server CPU resources a single sided system can serve cache requests with very predictable low latency even when memory hosts are running at high CPU utilization. Thus the single sided distributed storage system allows higher utilization of both cluster storage and CPU resources than traditional two sided systems while delivering predictable low latency.

In some implementations the distributed storage system includes a storage logic portion a data control portion and a data storage portion . The storage logic portion may include a transaction application programming interface API e.g. a single sided transactional system client library that is responsible for accessing the underlying data for example via RPC or single sided operations. The data control portion may manage allocation and access to storage resources with tasks such as allocating storage resources registering storage resources with the corresponding network interface controller setting up connections between the client s and the memory hosts handling errors in case of machine failures etc. The data storage portion may include the loosely coupled memory hosts 

The distributed storage system may store data in dynamic random access memory DRAM and serve the data from the remote hosts via remote direct memory access RDMA capable network interface controllers . A network interface controller also known as a network interface card network adapter or LAN adapter may be a computer hardware component that connects a computing resource to the network . Both the memory hosts and the client may each have a network interface controller for network communications. A host process executing on the computing processor of the memory host registers a set of remote direct memory accessible regions of the memory with the network interface controller . The host process may register the remote direct memory accessible regions of the memory with a permission of read only or read write. The network interface controller of the memory host creates a client key for each registered memory region 

The single sided operations performed by the network interface controllers may be limited to simple reads writes and compare and swap operations none of which may be sophisticated enough to act as a drop in replacement for the software logic implemented by a traditional cache server job to carry out cache requests and manage cache policies. The transaction API translates commands such as look up or insert data commands into sequences of primitive network interface controller operations. The transaction API interfaces with the data control and data storage portions of the distributed storage system .

The distributed storage system may include a co located software process to register memory for remote access with the network interface controllers and set up connections with client processes . Once the connections are set up client processes can access the registered memory via engines in the hardware of the network interface controllers without any involvement from software on the local CPUs of the corresponding memory hosts .

Referring to in some implementations the distributed storage system includes multiple cells each cell including memory hosts and a curator in communication with the memory hosts . The curator e.g. process may execute on a computing processor e.g. server having a non transitory memory connected to the network and manage the data storage e.g. manage a file system stored on the memory hosts control data placements and or initiate data recovery. Moreover the curator may track an existence and storage location of data on the memory hosts . Redundant curators are possible. In some implementations the curator s track the striping of data across multiple memory hosts and the existence and or location of multiple copies of a given stripe for redundancy and or performance. In computer data storage data striping is the technique of segmenting logically sequential data such as a file in a way that accesses of sequential segments are made to different physical storage devices e.g. cells and or memory hosts . Striping is useful when a processing device requests access to data more quickly than a storage device can provide access. By performing segment accesses on multiple devices multiple segments can be accessed concurrently. This provides more data access throughput which avoids causing the processor to idly wait for data accesses.

In some implementations the transaction API interfaces between a client e.g. with the client process and the curator . In some examples the client communicates with the curator through one or more remote procedure calls RPC . In response to a client request the transaction API may find the storage location of certain data on memory host s and obtain a key that allows access to the data . The transaction API communicates directly with the appropriate memory hosts via the network interface controllers to read or write the data e.g. using remote direct memory access . In the case that a memory host is non operational or the data was moved to a different memory host the client request fails prompting the client to re query the curator .

Referring to in some implementations the curator stores and manages file system metadata . The metadata may include a file map that maps files to file descriptors . The curator may examine and modify the representation of its persistent metadata . The curator may use three different access patterns for the metadata read only file transactions and stripe transactions.

Referring to data may be one or more files where each file has a specified replication level and or error correcting code . The curator may divide each file into a collection of stripes with each stripe being replicated or encoded independently from the remaining stripes . For a replicated file each stripe is a single logical chunk that the curator replicates as stripe replicas and stores on multiple storage resources . In that scenario a stripe replica is also referred to as a chunk . For an encoded file each stripe consists of multiple data chunks and code chunks that the curator places on multiple storage resources where the collection of data chunks and code chunks forms a single code word. In general the curator may place each stripe on storage resources independently of how the other stripes in the file are placed on storage resources . The error correcting code adds redundant data or parity data to a file so that the file can later be recovered by a receiver even when a number of errors up to the capability of the code being used were introduced. Error correcting code is used to maintain data integrity in storage devices to reconstruct data for performance latency or to more quickly drain machines.

Referring back to in some implementations file descriptors stored by the curator contain metadata such as the file map which maps the stripes to stripe replicas or to data chunks and code chunks as appropriate stored on the memory hosts . To open a file a client sends a request to the curator which returns a file descriptor . The client uses the file descriptor to translate file chunk offsets to remote memory locations . The file descriptor may include a client key e.g. a 32 bit key that is unique to a chunk on a memory host and is used to RDMA read that chunk . After the client loads the file descriptor the client may access the data of a file via RDMA or another data retrieval method.

The curator may maintain status information for all memory hosts that are part of the cell . The status information may include capacity free space load on the memory host latency of the memory host from a client s point of view and a current state. The curator may obtain this information by querying the memory hosts in the cell directly and or by querying a client to gather latency statistics from a client s point of view. In some examples the curator uses the memory host status information to make rebalancing draining recovery decisions and allocation decisions.

The curator s may allocate chunks in order to handle client requests for more storage space in a file and for rebalancing and recovery. In some examples the processor replicates chunks among the storage devices differently than distributing the data chunks and the code chunks among the storage devices . The curator may maintain a load map of memory host load and liveliness. In some implementations the curator allocates a chunk by generating a list of candidate memory hosts and sends an allocate chunk request to each of the candidate memory hosts . If the memory host is overloaded or has no available space the memory host can deny the request. In this case the curator selects a different memory host . Each curator may continuously scan its designated portion of the file namespace examining all the metadata every minute or so. The curator may use the file scan to check the integrity of the metadata determine work that needs to be performed and or to generate statistics. The file scan may operate concurrently with other operations of the curator . The scan itself may not modify the metadata but schedules work to be done by other components of the system and computes statistics.

Referring to the curator may determine a maintenance hierarchy of the distributed storage system to identify the levels e.g. levels at which maintenance may occur without affecting a user s access to stored data. Maintenance may include power maintenance cooling system maintenance networking maintenance updating or replacing parts or other maintenance or power outage affecting the distributed storage system .

The maintenance hierarchy identifies levels e.g. levels of maintenance units where each maintenance unit may be in an active state or an inactive state. Each storage device of the distributed storage system is associated with one or more maintenance unit . Moreover the processor maps the association of the storage devices with the maintenance units and their components . shows a strict hierarchy where each component depends on one other component . While does shows a non strict hierarchy where one component has more than one input feed. In some examples the processor stores the maintenance hierarchy on the non transitory memory of the processor . For example storage resource is mapped to a rack which is mapped to a bus duct which in turn is mapped to a power module distribution center which in turn is mapped to a power plant . The processor determines based on the mappings of the components what storage devices are inactive when a component is undergoing maintenance. Once the system maps the maintenance units to the storage resources the system determines a highest level e.g. levels at which maintenance can be performed while maintaining data availability.

A maintenance unit includes a component undergoing maintenance and any components depending from that component . Therefore when one component is undergoing maintenance that component is inactive and any component in the maintenance unit of the component is also inactive. As shown in level components may be the power plants providing power to levels to components level components may include power module distribution centers level components may include bus ducts level components may include racks and level components may include the storage resource . Other component distribution may also be available. When the power plant is undergoing maintenance a level maintenance unit including any power module distribution centers bus ducts racks and storage devices depending on the power plant are inactive and therefore a user cannot access data located within the level maintenance unit. When a power module distribution center is undergoing maintenance a level maintenance unit that includes the power module distribution center and any components in levels to depending from the power module distribution center are in an inactive state. When a bus duct is undergoing maintenance a level maintenance unit that includes the bus duct and any components in levels and that depend from the bus duct are in an inactive state. When a rack is underdoing maintenance a level maintenance unit that includes the rack and storage devices depending from the rack are in an inactive state. Finally when a storage device is undergoing maintenance a level maintenance unit includes the storage device and that storage device is inactive.

In some examples as shown in a non strict hierarchy component may have dual feeds i.e. the component depends on two or more other components . For example a bus duct may have a feed from two power modules and or a rack may have a dual feed from two bus ducts . As shown a first maintenance unit may include two racks and where the second rack includes two feeds from two bus ducts . Therefore the second rack is part of two maintenance units and . Therefore the higher levels of the maintenance hierarchy are maintained without causing the loss of the lower levels of the maintenance hierarchy . This causes a redundancy in the system which allows the for data accessibility. In particular the power module distribution center may be maintained without losing any of the bus ducts depending from it. In some examples the racks include a dual powered rack that allows the maintenance of the bus duct without losing power to the dual powered racks depending from it. In some examples maintenance units that may be maintained without causing outages are ignored when distributing chunks to allow for maintenance however the ignored maintenance units may be included when distributing the chunks since an unplanned outage may still cause the loss of chunks .

In some examples the maintenance hierarchy is a cooling hierarchy or may be a combination of a power hierarchy and a cooling hierarchy . The cooling hierarchy maps a cooling device to the racks that it is cooling. As shown a cooling device may cool one or more racks . The processor stores the association of the storage devices with the cooling maintenance units . In some implementations the processor considers all possible combinations of maintenance that might occur within the storage system to determine a hierarchy or a combination of hierarchies 

Therefore when a component in the storage system is being maintained that component and any components that are mapped to or depending from that component are in an inactive state. A component in an inactive state is inaccessible by a user while a component in an active state is accessible by a user allowing a user to access data stored on that component or on a storage device mapped to that component . As previously mentioned during the inactive state a user is incapable of accessing the storage devices associated with the maintenance units undergoing maintenance and therefore the user is incapable of accessing the files i.e. chunks which including stripe replicas and data chunks and code chunks .

In some implementations the processor restricts a number of chunks distributed to storage devices of any one maintenance unit e.g. based on the mapping of the components . Therefore if a level maintenance unit is inactive the processor maintains accessibility to the file or stripe although some chunks may be inaccessible. In some examples for each file or stripe the processor determines a maximum number of chunks that may be placed within any storage device within a single maintenance unit so that if a maintenance unit associated with the storage device storing chunks for a file is undergoing maintenance the processor may still retrieve the file . The maximum number of chunks ensures that the processor is capable of reconstructing the file although some chunks may be unavailable. In some examples the maximum number of chunks is set to a lower threshold to accommodate for any system failures while still being capable of reconstructing the file from the chunks . When the processor places chunks on the storage devices the processor ensures that within a stripe no more than the maximum number of chunks are inactive when a single maintenance unit undergoes maintenance.

Referring to in some implementations the processor determines a distribution of the chunks among the storage devices . In some examples the processor makes a first random selection of storage devices from an available pool of storage devices to store the chunks of a file . The processor selects a number of storage devices e.g. selected storage device S equal to the number of chunks in a stripe . Next the processor determines if the selection of selected storage devices S is capable of maintaining accessibility of the file i.e. the chunks of the file are available when one or more or a threshold number of maintenance units are in an inactive state. The random selection has the goal of allowing reconstruction of the stripe if maintenance occurs on one of the maintenance components .

Referring to in some examples when the processor determines that the first random selection of selected storage devices S is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the processor determines a second random selection of selected storage devices S that matches the number of chunks of the file . Then the processor determines if the second random selection of selected storage devices S is capable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state. If the processor determines that the second random selection is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the processor continues to make random selections of selected storage devices S until the processor identifies a random selection of selected storage devices S that is capable of maintaining accessibility of the file .

Referring to in some implementations when the processor determines that the first random selection of selected storage devices S is incapable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the processor modifies the first random selection of selected storage devices S by adding one or more randomly selected storage device S and removing a corresponding number of different storage devices S. The processor then determines if the updated first random selection is capable of maintaining accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state. If the processor determines that updated first random selection is incapable of maintaining accessibility of the stripe when one or more or a threshold number of maintenance units are in an inactive state the processor updates the selection of selected storage devices S by adding and removing one or more randomly selected storage device S. The processor continues to update the random selection of storage devices until the processor determines that the selected storage devices S are capable of maintaining accessibility of the stripe during maintenance of the distributed storage system . Once the processor makes that determination the processor moves to the next stripe or file to determine a distribution of the next stripe .

In some implementations the processor determines the random selection of selected storage devices S by using a probability sampling a simple sampling a stratified sampling a cluster sampling or a combination therefrom. In probability sampling every unit in a population has a chance greater than zero of being selected in the sample and this probability can be accurately determined. Probability sampling provides an unbiased estimate of population totals by weighing sampled units according to their probability selection. In a simple random sampling SRS of a given number of samples all subsets of a sampling frame are given an equal probability. In addition any given pair of elements has the same chance of selection as any other such pair and similarly for triples quadruplets etc. . SRS minimizes bias and simplifies analysis of the results. The variance between the results within the sample is a good indicator of variance in the population making it easier to estimate the accuracy of the results. In stratified sampling the population includes a number of distinct categories where the frame is organized by these categories into separate strata . Each stratum is sampled as an independent sub population out of which individual elements are randomly selected. Stratified sampling has several advantages over other sampling methods. Stratified sampling focuses on important subpopulations and ignores irrelevant ones it allows the use of different sampling techniques for different subpopulations improves the accuracy and efficiency of estimation and permits greater balancing of statistical power of tests of differences between strata by sampling equal numbers from strata that vary greatly in size. Cluster sampling allows the selection of respondents in clusters grouped by geography or by time periods. Cluster sampling does not require a sampling frame that lists all elements in the target population rather clusters can be chosen from a cluster level frame with an element level frame created only for the selected clusters.

Referring to in some implementations the processor determines a number of chunks in a stripe . The processor then selects a selected list having a consecutive number of storage devices equal to a number of chunks of the file from an ordered circular list of storage devices of the distributed storage system the ordered circular list beginning at a first storage device . The list may be stored on the non transitory memory of the processor . The processor then determines if the selected storage devices from the selected list are collectively incapable of maintaining accessibility of the file i.e. stripe when one or more or a threshold number of maintenance units are in an inactive state. If the processor determines that the selected storage devices are collectively incapable of maintaining the accessibility of the file or stripe when one or more or a threshold number of maintenance units are in an inactive state the processor selects another selected list having consecutive number of storage devices from the ordered circular list equal to the number of chunks of the stripe or file . In some examples the processor moves to a second storage device 1 after the first storage device in the ordered circular list when the processor determines that storage devices of the selected list are collectively incapable of maintaining the accessibility of the file or stripe . In other examples the processor moves a predetermined number of positions down the ordered circular list . In some implementations the processor determines the ordered circular list of storage devices of the storage system where adjacent storage devices or a threshold number of consecutive storage devices on the ordered circular list are associated with different maintenance units . Additionally or alternatively the processor determines the ordered circular list of storage devices of the storage system where adjacent storage devices or a threshold number of consecutive storage devices on the ordered circular list is each in different geographical locations. In some examples the storage devices on the ordered circular list are arranged so that different maintenance units cause the dispersion of data sequentially along the ordered list . For example as shown in the list may not contain sequentially storage devices dependent from the same bust duct . Instead two sequential storage devices on the list are from different maintenance units to make sure that data accessibility is maintained.

Referring to in some implementations a method of distributing data in a distributed storage system includes receiving a file into non transitory memory and dividing the received file into chunks using a computer processor in communication with the non transitory memory . The method also includes distributing chunks to storage devices of the distributed storage system based on a maintenance hierarchy of the distributed storage system . The maintenance hierarchy includes maintenance units each having active and inactive states. Moreover each storage device is associated with a maintenance unit . The chunks are distributed across multiple maintenance units to maintain accessibility of the file or stripe when a maintenance unit is in an inactive state. In some examples the method includes restricting the number of chunks distributed to storage devices of any one maintenance unit .

In some implementations the method further includes determining a distribution of the chunks among the storage devices by determining a first random selection of selected storage devices S that matches a number of chunks of the file and determining if the selection of selected storage devices S is capable of maintaining accessibility of the file or stripe when one or more or a threshold number of maintenance units are in an inactive state. In some examples when the first random selection of selected storage devices S is incapable of maintaining accessibility of the file or stripe when one or more or a threshold number of maintenance units are in an inactive state the method further includes determining a second random selection of selected storage devices S that match the number of chunks of the file or stripe or modifying the first random selection of storage devices S by adding and removing one or more randomly selected storage devices . The method may further include determining a random selection of storage devices using a simple sampling a probability sampling a stratified sampling or a cluster sampling previously explained . In some examples the method determines a third fourth fifth . . . etc. random selection of selected storage devices S until the selected random selection of storage devices is capable of maintaining accessibility of the file or stripe when one or more or a threshold number of maintenance units are in an inactive state.

In some implementations the method further includes determining a distribution of the chunks among the storage devices by selecting a list having a consecutive number of storage devices equal to a number of chunks of the file from an ordered circular list of the storage devices of the distributed storage system . When the selected storage devices are collectively incapable of maintaining the accessibility of the file when one or more or a threshold number of maintenance units are in an inactive state the method further includes selecting another list having a consecutive number of storage devices from the ordered circular list equal to the number of chunks of the file or stripe . Additionally or alternatively the method further includes determining the ordered circular list of storage devices of the distributed storage system where adjacent storage devices on the ordered circular list are associated with different maintenance units . In some examples a threshold number of consecutive storage devices on the ordered circular list are each associated with different maintenance units or are each in different geographical locations.

In some implementations the method further includes determining the maintenance hierarchy of maintenance units e.g. using the computer processor where the maintenance hierarchy has maintenance levels e.g. levels and each maintenance level includes one or more maintenance units . The method also includes mapping each maintenance unit to at least one storage device . Each maintenance unit includes storage devices powered by a single power distribution unit or a single power bus duct .

The method may further include dividing the received file into stripes . Each file includes a replication code or an error correcting code . When the file includes a replication code the method includes replicating at least one stripe as replication chunks . When the file includes an error correcting code the method includes dividing at least one stripe into data chunks and code chunks . The method may also include distributing replication chunks among the storage devices differently than distributing the data chunks and the code chunks among the storage devices .

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Moreover subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter affecting a machine readable propagated signal or a combination of one or more of them. The terms data processing apparatus computing device and computing processor encompass all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as an application program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user one or more aspects of the disclosure can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor or touch screen for displaying information to the user and optionally a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

One or more aspects of the disclosure can be implemented in a computing system that includes a backend component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a frontend component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such backend middleware or frontend components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some implementations a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

While this specification contains many specifics these should not be construed as limitations on the scope of the disclosure or of what may be claimed but rather as descriptions of features specific to particular implementations of the disclosure. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multi tasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results.

