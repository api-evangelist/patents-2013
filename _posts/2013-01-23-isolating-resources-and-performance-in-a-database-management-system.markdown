---

title: Isolating resources and performance in a database management system
abstract: Techniques for tenant performance isolation in a multiple-tenant database management system are described. These techniques may include providing a reservation of server resources. The server resources reservation may include a reservation of a central processing unit (CPU), a reservation of Input/Output throughput, and/or a reservation of buffer pool memory or working memory. The techniques may also include a metering mechanism that determines whether the resource reservation is satisfied. The metering mechanism may be independent of an actual resource allocation mechanism associated with the server resource reservation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477710&OS=09477710&RS=09477710
owner: Microsoft Technology Licensing, LLC
number: 09477710
owner_city: Redmond
owner_country: US
publication_date: 20130123
---
Cloud computing delivers resources as a service to customers over a network such as the Internet. For example a database service DaaS e.g. Microsoft Windows Azure SQL Database may offer database functionalities via a cloud computing environment to allow customers to make relational queries against stored data.

To reduce costs a database service provider may share resources of a database server among multiple customers e.g. enterprises or different applications within an enterprise . While reducing costs this resource sharing may adversely affect the performance of the database and or a customer s overall experience. For example customers of a DaaS platform may execute arbitrary Structured Query Language SQL queries. These queries may be complex and require substantial and varied resources of the database server. As a result the performance of the database server with respect to a customer may vary significantly due to workloads concurrently issued by other co located customers.

In sum resource sharing with respect to a database service may cause performance unpredictability which may result in a negative customer experience for those users that attempt to access data via the database service.

Described herein are techniques for isolating user s performance from other co located users in a multiple tenant Database Management System DBMS . The techniques may provide a reservation of resources of a server to a user in a database server process. The reservation may include at least an amount of the resources of the server. The server may also meter the reservation promise to establish accountability for the user.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

This disclosure is directed in part to tenant performance isolation in a multiple tenant DBMS. Embodiments of the present disclosure provide to a tenant a reservation of one or more resources of a database service and meter the promised reservation.

In accordance with the embodiments a database server operates a database server process that hosts databases of multiple tenants within a DBMS. In the database server process the database service may promise a reservation of one or more server resources to a tenant of the multiple tenants. The one or more server resources may include a central processing unit CPU memory and an Input Output I O throughput network bandwidth data instruction cache and other resources of the database server.

After the reservation is promised the database service may meter the reservation to verify whether the reservation for the tenant is met. In some embodiments the database service may meter the reservation based on a metering algorithm specific to an individual resource of the one or more server resources. In some embodiments the metering reservation may be independent from an implementation of the reservation. In response to determining that the tenant fails to receive the server resources the database service may establish accountability of the DBMS service provider to the tenant.

Existing techniques for resource management in a traditional enterprise DBMS may not be adequate for assurances of tenant performance at a resource level e.g. a CPU memory and an I O throughput of a database server . For example some techniques include assigning relative priorities enabling proportional sharing or enforcing maximum limits on resource usages. However particularly in standard cloud computing a major drawback of relative priorities and proportional sharing is that the assurance of how much resources a tenant will receive is not absolute. In fact the assurance depends on which other tenants are active and priorities shares associated with the other tenants.

Similarly enforcing maximum limits also suffers from this drawback when the service provider overbooks i.e. promises more resources in aggregate to tenants than the available system capacity to increase utilization and cost effectiveness. However embodiments of the present disclosure provide the assurance of how much resources the tenant will receive wherein the assurance is not dependent on other tenant s workloads of the DBMS.

In the illustrated embodiment the techniques are described in the context of tenant . . . N via tenant devices . . . N operating applications . . . N . The applications . . . N access databases . . . N of a database service over a network . For example the tenant may use the tenant device to operate application to query and or update the database running on a server e.g. a database server . In some embodiments the tenant may be a customer associated with a certain identifier ID that is mapped to certain queries and or updates associated with one or more databases. For example the tenant may be a user a certain user group and or an organization that has an ID mapping to one or more database operated by the database service .

In the computing environment the database service e.g. Microsoft Windows Azure SQL Database may offer database as a service DaaS functionalities in a cloud computing system i.e. a cloud . In some instances the database service may offer rational database functionalities that are designed to be a multiple tenant DaaS in which a database server process hosts databases of different tenants. In some embodiments multiple tenancy in DaaS may be associated with on premise clouds where databases of multiple independent applications within an enterprise are consolidated in a DBMS server.

Here the tenant accesses the database via network . Network may include any one or combination of multiple different types of networks such as cable networks the Internet and wireless networks. The tenant devices N meanwhile may be implemented as any number of computing devices including as a personal computer a laptop computer a portable digital assistant PDA a mobile phone a set top box a game console a personal media player PMP and so forth. The tenant device is equipped with one or more processors and memory to store applications and data. The applications N running on the tenant devices N may facilitate access to the database service over the network .

In the illustrated embodiment the database service may include a server configured to have database functionalities such as database storage and retrieval. In some embodiments the server may hold a database management system DBMS and or one or more databases mapping to the tenants N . For example the server may operate a database server process that hosts the databases N corresponding to the tenants N and effectively enables sharing resources of the server among the tenants N . In some instances each of the tenants N may access a corresponding database of the databases N .

The server may also include a performance isolator configured to provide and meter resource reservations. The resource may include a central processing unit CPU memory an I O throughput network bandwidth data instruction cache and other resources of the server . For example the performance isolator may provide a reservation of server resources to the tenant . Also to make the reservation auditable the performance isolator may determine that the reservation promise is violated and or the violation occurred because the database service fails to allocate the resource to the tenant . In some embodiments the performance isolator may determine that the reservation promise is violated and or the violation occurred because the tenant s workload has less demand for the resources that were reserved. The resource reservations and metering the resource reservations are discussed in greater detail in .

The reservation module may provide a reservation of one or more resources for the tenant in a database server process hosted by the server . In some embodiments the reservation module may promise a reservation of server resources to the tenant to assure how much resources the tenant will receive. In these instances the reservation is independent from other tenants. For example suppose that the tenant is promised a reservation of 100 I Os per second IOPS . As a result if the tenant s workload demands 100 IOPS or more the system may assume responsibility for granting 100 IOPS no matter which other tenants are executing concurrently on the server.

In some embodiments the resource reservations may be implemented without allocating a fixed amount of server resources to an individual tenant. In these instances the tenant may not receive the resources as promised for example due to overbooking. Therefore metering the promise may be performed to establish accountability.

In the illustrated embodiment the performance isolator may have the metering module configured to meter the promise of the reservation to isolate a performance of the tenant from other tenants that are served by the database service . In some embodiments the metering module may perform metering using a metering interval i.e. a window of time over which this metering is done . For example if the metering interval is 1 second then the promised reservation is assured to be met every second. In some embodiments the metering module may meter the promise of the reservation of individual server resources using a particular algorithm.

When the tenant is not allocated resources according to the promise the metering module may decide whether the tenant s workload does not have sufficient demand to consume the resources promised or whether the database service fails to allocate sufficient resources. Accordingly the metering module may maintain being fair to both the tenants N and the database service even when resource requests arrive in bursts.

Referring to the I O example above suppose that the tenant s workload actually achieves 80 IOPS when the reservation is 100 IOPS. There may be at least two reasons why this may happen a the tenant s queries do not generate sufficient I O requests b the tenant generates sufficient I O requests but the database service allocates IOPS to other tenants instead thereby depriving the tenant of some of the resource as promised. In some instances the metering is independent of the actual resource allocation mechanisms to provide performance assurances in a multiple tenant DBMS.

In some embodiments a SQL virtual machine SQLVM may be generated by reserving multiple server resources of the server for the tenant . In these instances the tenant is exposed the SQLVM with a specified set of resources such as CPU I O throughput and memory associated with the server . Inside of the SQLVM promise aware resource allocation mechanisms may exercise fine grained control to meter shared resources across the tenants N . In some embodiments the fine grained control may be performed without having to allocate a fixed amount of the resources for the tenant . If one tenant s resource reservation is not met the metering module may establish accountability for that resource.

In a multi tenant system the server consumes resources not only for the tenants tasks but also for system tasks necessary to achieve other properties such as high availability e.g. via replication to other machines check pointing to reduce recovery time and backup restore. In some embodiments SQLVM may isolate the tenant s resource reservation from the database service s management activities. In some instances these management activities may also be governed via the SQLVM by logically treating the database service as an internal tenant with certain resource requirements. In the cloud a SQLVM may be mapped to a logical server thus making the promise independent of the actual capacity of the physical server hosting the tenant.

In some embodiments the database server process may run on a processor with multiple cores. For example on a machine with two quad core processors the server may run up to 8 tasks i.e. threads concurrently or more if for example there is hyper threading. On each core the scheduling module decides which among the tasks queued on that core gets to run next. A task may be in one of the following states running runnable or blocked. For example the task may be in a state of running if the task is currently executed on the core. The task may in be a state of runnable if the task is ready to be executed. The task may be in a state of blocked if the task is waiting on other resources and hence is not ready to be executed.

For a tenant and a given core a CPU utilization over an interval of time may be defined as a percentage of time for which a task of that tenant is running on that core. Accordingly in a case of k cores as the total time for which tasks of that tenant run across all cores the CPU utilization is a percentage of a value of k multiplied by a time interval e.g. a metering interval .

In the illustrated embodiment the reservation module may include a CPU reservation module configured to provide for the tenant a reservation of a certain CPU utilization herein referred as ResCPU. Accordingly a slice of the CPU time on available core s is promised to the tenant . In some embodiments the promised CPU time may be reserved among multiple cores for the tenant . This may allow better consolidation of CPU utilizations for multiple tenants since the CPU reservation module may promise CPU utilizations to a number of tenants that is greater than the available cores. For example on a single core server if ResCPU 10 in a metering interval of 1 sec the tenant should be allocated a CPU time of at least 100 Microsecond msec unless the tenant does not have sufficient a workload. For example the tenant may have sufficient a workload when at least one task of the tenant utilizes the CPU during the metering interval.

Also the metering module may include a CPU metering module configured to meter a CPU reservation of the tenant on a core of the server . In some embodiments a task of the tenant may utilize the CPU if the tenant has at least one task that is running or is runnable on the server . In these instances the CPU metering module may determine whether the tenant receives at least ResCPU percentage of the CPU in the total time during which at least one task utilizes the CPU .

For example if the tenant was promised ResCPU 10 and if the tenant had at least one task ready to run or running for 500 ms the provider violates the promise only if the allocated CPU is less than 50 ms. In other words the tenant s effective utilization is less than 10 . This notion of metering is fair since the provider is not held accountable for the tenant being idle i.e. no tasks ready to run while ensuring that the database service cannot arbitrarily delay a tenant s task without violating the promise.

Achieving adequate I O throughput IOPS and or I O bandwidth bytes sec is important for many database workloads. As in the case of CPU statically dedicating a disk or set of disks per tenant to achieve acceptable I O throughput may limit the amount of consolidation. Thus fine grained sharing of the IOPS available from a disk may be beneficial. While the discussion below focus on I O throughput techniques disclosed in the discussion may be applied to I O bandwidth as well.

In the illustrated embodiment the reservation module may include an I O reservation module configured to provide a reservation for the tenant a certain IOPS herein referred as ResIOPS. This reservation may be a slice of the IOPS capacity available of the underlying physical disk drives. In some instances sequential and random I Os may be treated in a similar manner. The rationale is that even though DBMSs traditionally have developed optimizations for sequential I O the stream of I O requests in a server hosting independent tenant workloads may not be sequential due to the high degree of multiplexing across tenant workloads. However for tenants whose workloads require scanning large amounts of data e.g. decision support workloads the promise may be offered in terms of I O bandwidth.

Also the metering module may include an I O metering module configured to meter I O throughput to determine whether the tenant has sufficient I O requests to meet the reserved resources and whether the I O throughput achieved is commensurate with the promise. If the tenant has at least one I O request pending then the tenant may be deemed to have work to utilize the I O resources. In some instances the effective I O throughput may be defined as the IOPS achieved for the time when the tenant had at least one pending I O request in the given metering interval. The I O metering module may determine a violation if the effective I O throughput is less than ResIOPS. The rationale is that if requests arrive in bursts the provider should issue enough I O requests to meet the effective rate of ResIOPS thus preventing the provider from unnecessarily delaying the requests. However the service is not held accountable for periods when the tenant was idle i.e. having no pending I O request.

In a RDBMS uses of memory may include buffer pool and working memory. The buffer pool is a cache of database pages that is managed using a page replacement strategy e.g. LRU k . If a page is not found in the buffer pool the DBMS incurs I O to obtain it from secondary storage. Working memory is private to a physical operator used in a query execution plan such as Hash or Sort. If working memory is limited the operator may need to spill partitions of a hash table to secondary storage thus again incurring additional I O. Similar to static reservation of CPU and I O capacity statically allocating a tenant s memory may also limit consolidation of resource reservations for multiple tenants. Therefore the techniques disclosed herein dynamically distribute memory across tenants while providing a precise promise that exposes an illusion of statically allocated memory.

In the illustrated embodiment the reservation module may also include a memory reservation module configured to allow dynamic and fine grained sharing of memory among tenants. The memory reservation module may promise the tenant a number of I Os incurred in a multi tenant system is the same as though the system had dedicated a certain amount e.g. 1 GB of buffer pool memory for the tenant. Similarly promising a number of I Os to the tenant may also applicable for working memory reservation. In some embodiments Relative IO may be used to indicate whether the server is responsible for providing additional I O throughputs. For a given amount of memory M the Relative IO may be define as follows 

The memory reservation module promises the tenant Relative IO 0 for a given amount of memory. Similar to other resources a tenant is promised a memory reservation herein referred as ResMem. For example suppose the tenant is promised a 1 GB buffer pool memory reservation. In effect the promise is that the tenant s workload will see the same hit ratio as though a 1 GB buffer pool is reserved for the tenant. Similarly for working memory for example a promise of 500 MB implies that there would be no more I O to from disk for hash or sort operators in SQL query plans compared to 500 MB of working memory dedicated to that tenant.

Also the metering module may include a memory metering module configured to meter memory allocation to a tenant. In some embodiments memory is allocated dynamically and a tenant s actual memory allocation may differ from ResMem. Metering memory may include determining Baseline IOs M and measuring actual IOs. In some embodiments for both buffer pool memory and working memory the baseline simulation is feasible and accurate.

For example for buffer pool memory the relative I O is dependent on the page access order page replacement policy and page metadata such as dirty bit rather than the actual contents of the pages. The CPU overhead necessary to simulate this baseline buffer pool may be piggybacked on the actual buffer pool accesses and page replacement and is almost negligible in some embodiments. In some instances if the memory metering module determines RelativeIO 0 any such additional I Os incurred for the tenant are not charged to the tenant s ResIOPS but to the database service .

In general there are at least three challenges in implementing I O scheduling in a DBMS for meeting ResIOPS promised to each tenant. The first challenge is the accuracy and efficiency of the actual scheduling mechanism. The second challenge concerns accurately accounting all I O requests associated with the tenant irrespective of whether an I O request is directly issued during execution of a tenant s workload or issued by a background system activity on behalf of the tenant. The third challenge pertains to the fact that database systems often use multiple logical drives e.g. volumes e.g. one volume for storing data files and a separate volume for the log file or data striped across multiple volumes. In some embodiments an I O scheduling mechanism described herein may handle these scenarios.

The tenant may have multiple queries concurrently executing and issuing I O requests. These queries may run on multiple cores of the server and may issue I O requests independently of other queries belonging to the tenant. Furthermore in a multi core processor I O requests of the tenant are not guaranteed to be evenly balanced across cores. Thus a challenge in meeting ResIOPS accurately across multiple cores and queries is to synchronize a tenant s I O requests from different cores and from concurrent queries with a minimum reservation of server resources promised to the tenant .

For example if the tenant is promised 100 IOPS then the system meets the promise by issuing one I O of the tenant every 10 msec. Thus deadlines for I O requests of a particular tenant may be spaced 1 ResIOPS second apart. This deadline assignment may require synchronization across cores in a multi core processor. Thus this mechanism is scalable in terms of number of cores and number of concurrent tenants while providing accurate controls over I O throughput. Once assigned a deadline an I O request is queued in a pending I O queue to be issued by the scheduling module at an opportune moment.

In the illustrated embodiment the scheme may include an I O queue and I O queue which are associated with the tenant and the tenant N respectively. The server provides a reservation of 100 IOPS for the tenant and a reservation of 50 IOPS for the tenant N . The I O queue and I O queue may include multiple I O requests each having a request ID a deadline and an arrival time of the I O request. The scheduling module may de queue and issue an I O request based on a comparison between a current time and a deadline associated the I O request. For example suppose a current time is 110 i.e. now 110 the scheduling module may de queue and issue I O requests of a request ID 1 request ID 3 and request ID 4.

In some embodiments I O requests for the tenant are issued in the order of arrival times. Since I O requests may potentially be reordered by the disk controller the server may reorder I O requests of the tenant in queues to achieve higher level optimizations for tenant workloads. For example consider the tenant that has issued a short query requiring only a few I Os concurrently with another long running query requiring a large number of I Os that has already queued a number of I O requests. In this case reordering the I O requests issued by the queries of the tenant may significantly reduce latency of the short query while still achieving the ResIOPS for the tenant. In addition to meeting ResIOPS the above mechanism may shape a burst of I O traffic of the tenant by issuing these requests spaced apart over a period of time. Since a context switch on a scheduler may be frequent e.g. several hundred times a second a fine grained control over I O issuance may be implemented.

I Os issued by a tenant s workload may conceptually be categorized as direct i.e. issued during the execution of the workload or indirect i.e. issued by a system thread on behalf of the tenant as part of a background activity . Examples of direct I Os may be reads of data pages required for query execution log writes and reads and writes performed during a backup or restore database operation. Examples of indirect I Os may include flushing dirty data pages to the disk check pointing and data replication for availability. Direct I Os are readily accountable and may be directly associated with the tenant that issued the I O. Since indirect I Os are issued from a system thread additional information may be extracted from the context to identify which tenant the I O should be accounted to.

A logical drive or volume is a collection of disk spindles or an SSD that is exposed to the OS as single device. A file on that drive is typically striped across all spindles of that drive. Moreover DBMSs often use multiple volumes a typical configuration might be to use one volume for the data file s of a database and one volume for the log file. In some embodiments the performance isolator may govern each such volume independently. Accordingly an IOPS reservation for the tenant internally maps to an IOPS reservation per volume. In implementing I O scheduling one logical queue of I O requests per tenant per volume may be maintained.

A reservation of 100 IOPS may have two different interpretations and therefore two different metering schemes. One version is that as long as the tenant has at least one I O request pending the system will issue one I O every 10 msec i.e. 1 100 second . Such a promise might be attractive to applications striving for low latency in addition to low variability in I O throughput. For this interpretation the metering module computes the delay between when the I O should have been issued and when it is actually issued. The scheduling mechanism described above maintains a deadline for each I O that identifies the time by when the I O should be issued to achieve the desired ResIOPS. Thus when an I O request is actually issued the metering logic uses the deadline to compute the delay if any. At the end of the metering interval a distribution of these delays is reported e.g. maximum average percentiles that quantifies the violation of the promise. If delay is 0 for every I O request then ResIOPS promise is met.

Another version promises that the average I O throughput over the meeting interval is at least 100 IOPS. This interpretation relaxes the requirement to issue one I O every 1 ResIOPS second as long as the average rate for the interval meets the promised ResIOPS. Metering for the second version may also leverage the deadline. At the end of the interval each I O request whose deadline lies within the interval but is not issued represents a violation. If there are n such violations in a metering interval of t sec then the promise is violated by n t IOPS. Deadline assignment inherently factors out idle time and hence this metering logic is similar to that described in the section of Illustrative I O Reservation and Metering.

At the server may provide a reservation of one or more server resources for the tenant in the database server process that hosts multiple databases of the tenants N . The one or more server resources may include a predetermined amount of CPU utilization memory and I O throughput of the server operating the database server process . In some instances the CPU utilization may specify a percentage of CPU time for which a task of the tenant runs on a core of the CPU of the server . The reservation of the I O throughput may include a predetermined I O throughput amount of an IOPS capacity of the server . The reservation of memory may include at least one of a buffer pool and working memory of the server . In some embodiments the server may also enforce a maximum limit on resource usages of the one or more server resources for the tenant . In these instances a difference between an amount of actual resource usages and the amount of resource reservation e.g. the predetermined amount of CPU utilization may be determined based on a predetermined relative priority associated with the tenant .

At the server may meter the reservation to assure a performance isolation of the tenant from other tenants e.g. the tenant N . In some embodiments the server may meter the reservation based on a metering algorithm that is unique or specific to an individual resource of the one or more server resources. In some embodiments the metering reservation may be independent from an implementation of the reservation. At the server may determine that the tenant fails to receive a predetermined amount of a promised server resource and may establish at accountability in response to the determination.

In some embodiments the predetermined amount of the server resource includes a predetermined amount of I O throughput in a metering interval. The server may establish an accountability of the server after determining that an effective I O throughput associated with a pending I O request of the tenant is less than the predetermined amount of I O throughput.

In some embodiments the predetermined amount of the server resource includes a percentage of CPU time for which a task of the tenant in a metering interval runs on a core of a CPU of the server . The server may establish an accountability of the server based on whether a workload of the tenant has a sufficient demand to consume the percentage of CPU time in the metering interview and whether the server fails to allocate the percentage of CPU time in the metering interval.

Alternatively or in addition the functionally described herein may be performed at least in part by one or more hardware logic components. For example and without limitation illustrative types of hardware logic components that may be used include Field programmable Gate Arrays FPGAs Program specific Integrated Circuits ASICs Program specific Standard Products ASSPs System on a chip systems SOCs Complex Programmable Logic Devices CPLDs etc.

In a very basic configuration the computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device the system memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination of the two. The system memory typically includes an operating system one or more program modules and may include program data . For example the program modules may includes the reservation module the metering module and the scheduling module as discussed in the computing environment and architectures and and or the illustrative process .

The operating system includes a component based framework that supports components including properties and events objects inheritance polymorphism reflection and the operating system may provide an object oriented component based application programming interface API . Again a terminal may have fewer components but will interact with a computing device that may have such a basic configuration.

The computing device may have additional features or functionality. For example the computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer readable media may include at least two types of computer readable media namely computer storage media and communication media. Computer storage media may include volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. The system memory the removable storage and the non removable storage are all examples of computer storage media. Computer storage media includes RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that may be used to store the desired information and which may be accessed by the computing device . Any such computer storage media may be part of the computing device . Moreover the computer readable media may include computer executable instructions that when executed by the processor unit s cause the computing device to perform various functions and or operations described herein.

In contrast communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transmission mechanism. As defined herein computer storage media does not include communication media.

The computing device may also have input device s such as keyboard mouse pen voice input device touch input device etc. In some embodiments input methods may be implemented via Natural User Interface NUI . NUI may include any interface technology that enables a user to interact with a device in a natural manner free from artificial constraints imposed by input devices such as mice keyboards remote controls and the like. Examples of NUI methods may include those relying on speech recognition touch and stylus recognition gesture recognition both on screen and adjacent to the screen air gestures head and eye tracking voice and speech vision touch gestures and machine intelligence. Categories of NUI technologies may include touch sensitive displays voice and speech recognition intention and goal understanding motion gesture detection using depth cameras such as stereoscopic camera systems infrared camera systems RGB camera systems and combinations of these motion gesture detection using accelerometers gyroscopes facial recognition 3D displays head eye and gaze tracking immersive augmented reality and virtual reality systems all of which provide a more natural interface as well as technologies for sensing brain activity using electric field sensing electrodes EEG and related methods . Output device s such as a display speakers printer etc. may also be included. These devices are well known in the art and are not discussed at length here.

The computing device may also contain communication connections that allow the device to communicate with other computing devices such as over a network. These networks may include wired networks as well as wireless networks. The communication connections are one example of communication media.

It is appreciated that the illustrated computing device is only one example of a suitable device and is not intended to suggest any limitation as to the scope of use or functionality of the various embodiments described. Other well known computing devices systems environments and or configurations that may be suitable for use with the embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor base systems set top boxes game consoles programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and or the like. For example some or all of the components of the computing device may be implemented in a cloud computing environment such that resources and or services are made available via a computer network for selective use by mobile devices.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts are disclosed as example forms of implementing the claims.

