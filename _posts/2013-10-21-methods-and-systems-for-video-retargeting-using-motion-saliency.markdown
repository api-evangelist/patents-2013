---

title: Methods and systems for video retargeting using motion saliency
abstract: Methods and systems for video retargeting and view selection using motion saliency are described. Salient features in multiple videos may be extracted. Each video may be retargeted by modifying the video to preserve the salient features. A crop path may be estimated and applied to a video to retarget each video and generate a modified video preserving the salient features. An action score may be assigned to portions or frames of each modified video to represent motion content in the modified video. Selecting a view from one of the given modified videos may be formulated as an optimization subject to constraints. An objective function for the optimization may include maximizing the action score. This optimization may also be subject to constraints to take into consideration optimal transitioning from a view from a given video to another view from another given video, for example.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09167221&OS=09167221&RS=09167221
owner: Google Inc.
number: 09167221
owner_city: Mountain View
owner_country: US
publication_date: 20131021
---
The present application is a continuation of U.S. patent application Ser. No. 13 419 231 filed on Mar. 13 2012 and entitled Methods and Systems for Video Retargeting Using Motion Saliency which is herein incorporated by reference as if fully set forth in this description.

Content aware image editing involves several techniques aimed at displaying images without distortion on various media e.g. cell phones PDAs . Image editing may involve defining paths of least importance in an image and removing these paths to reduce image size or moving a crop window to cover salient objects within a frame. Editing may also involve manually defining areas in which pixels may not be modified and offer the ability to remove whole objects from photographs.

Similarly content aware video editing involves reconstructing or processing the video for better viewership. In sport events for example several cameras may be used to record a game. The operator of each camera may focus on action and also may attempt to anticipate future events. The operator may employ video techniques such as subtle zoom constant velocity panning and avoidance of sudden jerks to provide a pleasant experience for viewers. A director may determine which cameras should be broadcast live during the game in real time.

Alternatively the game may be recorded. Content of videos recorded by various cameras used for recording the event may be edited to produce a final video showing selected features and moments of the game. Editing the content of the videos may attempt to include moments of action and choose the camera that has a given view at a given moment in time. A final video may adhere to professional production techniques.

Systems and methods for video retargeting using motion saliency are disclosed. In one aspect a method is described. The method may comprise receiving a plurality of videos each video comprising a sequence of frames. The method also may comprise determining salient features in a content of each video that include features selected based on motion content of the features over the sequence of frames. The method further may comprise determining a camera crop path for each video. The camera crop path may comprise a sequence of crop windows and the sequence of crop windows may include the salient features. The method may further comprise applying the sequence of crop windows to the sequence of frames of each respective video to generate a modified video for each video including the salient features of each respective video. The method may further comprise determining an action score associated with a portion of each modified video. The action score may be based on an average motion magnitude of the salient features in the portion of each modified video. Based on the action score the method may further comprise selecting one of the modified videos.

In another aspect a non transitory computer readable medium having stored therein instructions that in response to execution by a computing device cause the computing device to perform operations is described. The operations may comprise receiving a plurality of videos each video comprising a sequence of frames. The operations also may comprise determining salient features in a content of each video that include features selected based on motion content of the features over the sequence of frames. The operations may also comprise determining a camera crop path for each video. The camera crop path may comprise a sequence of crop windows and the sequence of crop windows may include the salient features. The operations may further comprise applying the sequence of crop windows to the sequence of frames of each respective video to generate a modified video for each video including the salient features of each respective video. The operations may further comprise determining an action score associated with a portion of each modified video. The action score may be based on an average motion magnitude of the salient features in the portion of each modified video. Based on the action score the operations may further comprise selecting one of the modified videos.

In still another aspect a system is provided that comprises a motion saliency engine a video retargeting engine and a view selection engine. The motion saliency engine may be configured to receive a plurality of videos and to determine salient features in a content of each video that include features selected based on motion content of the features over the sequence of frames. The video retargeting engine may be in communication with the motion saliency engine and configured to determine a camera crop path for each video. The camera crop path may comprise a sequence of crop windows and the sequence of crop windows may include the salient features. The video retargeting engine may also be configured to apply the sequence of crop windows for each video to the sequence of frames of each video to generate a modified video for each video including the salient features of each respective video. The view selection engine may be in communication with the motion saliency engine and the video retargeting engine and configured to determine an action score associated with a portion of each modified video. The action score may be based on an average motion magnitude of the salient features in the portion of each modified video. Based on an action score the view selection engine may be configured to select one of the modified videos.

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the figures and the following detailed description.

The following details describe various features and functions of the disclosed systems and methods with reference to the accompanying figures. In the figures similar symbols identify similar components unless context dictates otherwise. The illustrative system and method embodiments described herein are not meant to be limiting. It may be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations all of which are contemplated herein.

This disclosure may disclose inter alia systems and methods for retargeting multiple synchronized recorded videos and selecting a view from the multiple videos to display. Salient features in multiple videos may be extracted. Each video may be retargeted by modifying the video to preserve the salient features. A crop path may be estimated and applied to a video to retarget each video and generate a modified video preserving the salient features. An action score may be assigned to portions or frames of each modified video to represent motion content in the modified video. Selecting a view from one of the given modified videos may be formulated as an optimization subject to constraints. An objective function for the optimization may include maximizing the action score. This optimization may also be subject to constraints to take into consideration optimal transitioning from a view from a given video to another view from another given video for example.

FIG is a block diagram illustrating an example multi video retargeting and view selection system . The multi video retargeting and view selection system includes a motion saliency engine a video retargeting engine and a view selection engine each coupled to or in communication with the other via wired or wireless links. The multi video retargeting and view selection system may be configured to receive multiple videos and to perform video retargeting and view selection processes on the multiple videos. For example the motion saliency engine may receive the videos and may determine salient features of each video or a group of videos. Salient features may include visually prominent features in a video determined based on motion of objects within the video. The video retargeting engine may then estimate a camera crop path that may be applied to each video to generate a modified video that preserves at least some of the salient features determined by the motion saliency engine . The view selection engine may select a view from one of the modified videos based on certain criteria and constraints.

One or more of the described functions or components of the system may be divided up into additional functional or physical components or combined into fewer functional or physical components. In some further examples additional functional and or physical components may be added to the examples illustrated by FIG . Still further any of the motion saliency engine the video retargeting engine and or the view selection engine may include or be provided in the form of a processor e.g. a microprocessor a digital signal processor DSP etc. configured to execute program code including one or more instructions for implementing logical functions described herein. The system may further include any type of computer readable medium e.g. non transitory medium for example such as a storage device including a disk or hard drive to store the program code.

FIG A is a block diagram of an example multi video processing system . FIG A includes cameras A N. Videos recorded by cameras A N are received by system . System may include saliency detection modules A N to determine salient features in a given received video. System may also include video retargeting modules A N that may produce modified videos by imposing constraints that require a modified video to preserve salient features and objects. System may further include view scoring modules A N that assign action scores to modified videos at a given time. An action score may represent an average motion magnitude of the salient features included in the content of each modified video at given time.

Turning to the individual entities illustrated on FIG A each received video from camera A N comprises a sequence of frames over time. The camera may be static e.g. on a tripod or dynamic e.g. moving with a camera operator or electronically controlled .

Saliency detection modules A N may be configured to determine salient features in a content of each video recorded by cameras A N. Salient features may include visually prominent features i.e. characteristic or notable features such as moving points of interest in a video . For example in a sports event a player moving with a ball may be considered as a salient feature in the content of the video.

Video retargeting modules A N may be configured to retarget each video by imposing constraints that require a modified video to preserve salient features and objects. To retarget a video in order to preserve and zoom in on the salient features a camera crop path may be estimated. The camera crop path may include a sequence of crop windows. Each crop window may be estimated to preserve and zoom in on the salient features in a respective video content. Estimating the sequence of crop windows associated with a crop path may be performed subject to constraints. An example of a constraint includes estimating the crop window to be of a pre defined scale less than one with respect to an original frame size. Crop paths and the associated sequences of crop windows may be applied through the video retargeting modules A N to videos to produce respective modified videos.

After video retargeting modules A N apply respective crop paths to original videos to produce respective modified videos view scoring modules A N may be configured to assign action scores to each modified video at a given time. An action score may represent action content which may be associated with the average motion magnitude of the salient features detected by the saliency detection modules A N.

A single video may be produced or selected from multiple modified videos. At a given point in time a view from one of the modified videos may be selected to be part of the single video. Based on action scores assigned by view scoring modules A N a view selection module may be configured to select a view from a modified video at a given time t. The view selection module may select the view according to certain criteria and constraints. An example of criteria may be the action scores assigned by modules A N. An example of a constraint may be limiting switching between views from different videos. If the single video contains views from different modified videos over time switching between the different modified videos in a short span of time may not provide viewers with a pleasant viewing experience. For example at a given time t the single video may contain a view from a given modified video. After a t time period the single video may contain a view from a different given video. After another t time period the single video may contain a view from yet another different given video. If t is a short amount of time e.g. less than a second switching between the different videos may not be desirable. Therefore a constraint may be imposed through the view selection module to not switch from a view associated with one video to a view associated with another video until a predetermined period of time has elapsed. Then switching to a view from a different video may be enabled for example.

One or more of the described functions or components of the system may be divided up into additional functional or physical components or combined into fewer functional or physical components. For example the embodiment in FIG A shows multiple saliency detection modules A N multiple video retargeting modules A N and multiple view scoring modules A N one for each video. In another embodiment shown in FIG B a single saliency detection module single video retargeting module and a single view scoring module may be applied to all videos. View selection module may be configured to select a view from a modified video at a given time t as described above. In some further examples additional functional and or physical components may be added to the examples illustrated by FIG A B. Still further any of the saliency detection modules and A N the video retargeting modules and A N and or the view scoring modules and A N may include or be provided in the form of a processor e.g. a microprocessor a digital signal processor DSP etc. configured to execute program code including one or more instructions for implementing logical functions described herein. The system may further include any type of computer readable medium e.g. non transitory medium for example such as a storage device including a disk or hard drive to store the program code.

FIG is a block diagram illustrates an example system view of a video hosting service that includes a multi video retargeting and view selection system . Multiple users viewers may use clients A N to send video hosting requests to the video hosting service such as to upload videos to a video hosting website and to receive the requested services from the video hosting service . The video hosting service may be configured to communicate with the one or more clients A N via a network . The video hosting service may receive the video hosting service requests from the clients A N over wired or wireless connections.

Turning to the individual entities illustrated on FIG each client A N may be used by a user to request video hosting services. For example users or camera operators can use the client A N to send requests for uploading videos for processing. The clients A N can include a camera or any type of computer device such as a personal computer e.g. desktop notebook tablet laptop computer as well as devices such as a mobile telephone personal digital assistant or IP enabled video player where videos are stored. The clients A N may include a processor a display device or output to a display device and a local storage such as a hard drive or flash memory device to which the clients A N store data used by the user in performing tasks and a network interface for coupling to the video hosting service via the network .

The clients A N may include a video player A N e.g. the Flash player from Adobe Systems Inc. or a proprietary one for playing a video stream. The video player A N may be a standalone application or a plug in to another application such as a network or Internet browser. Where the client A N is a general purpose device e.g. a desktop computer mobile phone the player A N may be implemented as software executed by the computer. Where the client A N is a dedicated device e.g. a dedicated video player the player A N may be implemented in hardware or a combination of hardware and software. The player A N may include user interface controls and corresponding application programming interfaces for selecting a video feed starting stopping and rewinding a video feed. Also the player A N can include in a user interface a video display format selection configured to indicate a video display format e.g. a standard definition TV or a high definition TV . Other types of user interface controls e.g. buttons keyboard controls can be used as well to control the playback and video format selection functionality of the player A N.

The network enables communications between the clients A N and the video hosting service . In one embodiment the network is the Internet and uses standardized internetworking communications technologies and protocols known now or subsequently developed that enable the clients A N to communicate with the video hosting service . In another embodiment the network may be a wireless cellular network that enables wireless communication between the clients A N and the video hosting service .

The video hosting service comprises the multi video retargeting and view selection system a video server an ingest server and a video database . The video server may be configured to serve videos from the video database in response to user video hosting service requests. The ingest server may be configured to receive user uploaded videos and store the videos in the video database . The video database may be configured to store user uploaded videos and videos processed by the multi video retargeting and view selection system . In one embodiment the video database stores a large video corpus.

The multi video retargeting and view selection system may include a motion saliency engine a video retargeting engine and a view selection engine . The multi video retargeting and view selection system may be configured to receive user uploaded videos from the ingest server and to perform video retargeting and view selection.

FIG is a block diagram of an example method to determine salient features in a video in accordance with at least some embodiments described herein. Method shown in FIG presents an embodiment of a method that for example could be used with the systems and and may be performed by a device a server or a combination of the device and the server. Method may include one or more operations functions or actions as illustrated by one or more of blocks and . Although the blocks are illustrated in a sequential order these blocks may in some instances be performed in parallel and or in a different order than those described herein. Also the various blocks may be combined into fewer blocks divided into additional blocks and or removed based upon the desired implementation.

In addition for the method and other processes and methods disclosed herein the flowchart shows functionality and operation of one possible implementation of present embodiments. In this regard each block may represent a module a segment or a portion of program code which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process. The program code may be stored on any type of computer readable medium for example such as a storage device including a disk or hard drive. The computer readable medium may include a non transitory computer readable medium for example such as computer readable media that stores data for short periods of time like register memory processor cache and Random Access Memory RAM . The computer readable medium may also include non transitory media such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. The computer readable medium may be considered a computer readable storage medium a tangible storage device or other article of manufacture for example. In addition for the method and other processes and methods disclosed herein each block in FIG may represent circuitry that is wired to perform the specific logical functions in the process.

At block the method includes receive a video. In one example the video may have been recorded by a camera uploaded to and received by a server to be processed. In other examples a video may be received and processed at a camera that is used to record the video. In still other examples any computing device may be configured to receive the video via wired or wireless communication links from a video recording device that is used to record the video.

At block the method includes divide frame into cells using grid binning technique. A video has a sequence of frames and each frame may be divided by a grid into multiple cells. Each cell can be considered as a cluster containing trackable features. Grids of varying resolutions and offsets can be used. For a grid of size X N cells having square bins of size

At block the method includes extract trackable feature matches in frames of the video. For example trackable features in each frame of the video are extracted or trackable features in substantially all frames of the video are extracted. Trackable features in frames of the video may be extracted using feature tracking software such as the pyramidal Lucas Kanade feature tracking Features may be tracked from frame to frame using any number of methods. For example if the video is a sequence of images I I . . . I video frame pairs may be I I and feature pairs between video frames may be extracted e.g. for each feature x in frame I a corresponding feature y at the same point in space as the feature x is found in frame I .

In another example a set of flow vectors for each frame pair may be obtained. If for example the video was recorded by a static camera flow vectors below a threshold e.g. less than 0.05 of a frame diameter can be removed. The remaining flow vectors may be considered as a set of trackable features f l v where lrefers to the spatial location of the feature fand vrefers to the feature s associated flow vector. In the case of a moving camera a fundamental matrix constraint could be employed to remove features that correspond to static background motion.

In another example small intra frame motions and changes in illumination or brightness values of a small image patch e.g. 7 7 pixels centered around the feature point x in Iand the matching point y in Imay be nearly identical. For each feature x in I a displacement vector d may be determined such that the I x I x d and therefore x d y using the previous notation e.g. that is feature matches xy . This expression can be linearized by Taylor Series expansion around x yielding DI x d I x I x which is linear in the unknown displacement vector d. An over determined linear system of equations may be determined of the form A d b that can be then solved by using normal equations i.e. solving the symmetric linear system AA d Ab by Gaussian Elimination where Adenotes the transpose of A . This process may be referred to as pyramidical Lucas Kanade Tracking This process may be performed for all video frames of the video to determine multiple pairs of feature correspondences i.e. each pair corresponding to a feature location in a first and a second frame respectively.

At block the method includes perform local outlier rejection to remove spurious feature matches. Some of the feature pair matches between video frames may be incorrect and can be removed. To remove feature pairs matches that may have been incorrectly identified as a corresponding pairs an algorithm such as random sample consensus RANSAC may be used. The algorithm may identify outliers within a set of observed data.

In one example for each cluster or bin of a given grid outlier sets may be rejected and inlier sets may be determined. One feature f l v may be picked randomly from the cluster. A set of feature flow vectors v . . . v may be determined within the cluster that agrees with vwithin a small threshold such that v f 

At decision block method includes reached number of grids KN . The described outlier rejection and inlier set determination method may be performed for all clusters of a grid and repeated for all grids until at total number of grids KN is reached. Examples of such grids are shown in FIG .

At block method includes merge inlier set. The inlier sets can be merged across all KN grids which can be performed in linear complexity using hashing or log linear complexity by lexicographically sorting feature locations. Merging inlier sets may include re evaluating cluster centers and salient features. In one example a grid G of fixed binning may be selected e.g. a grid with zero offsets and finest resolution Inliers sets obtained from all KN grids may be binned into the grid G. Cluster centers and motion magnitude may be determined for each bin by averaging inlier features locations and motion magnitudes. Averaging may result in tuples of the form cluster center motion magnitude . The tuples may be used as salient features. In another example inlier sets obtained from all KN grids may be binned into regions obtained from an image or a video segmentation algorithm. Cluster centers and motion magnitude may also be determined by averaging. In addition or alternatively a centroid of a region may be used as cluster center. In yet another example a clustering algorithm such as k means may be applied to inlier sets obtained from all KN grids to yield a pre defined number of k clusters. The pre defined number of k clusters may include k 1 clusters i.e. using a frame global average of inlier feature locations to yield a single saliency point.

At block method includes determine cluster centers as salient features. The merged inlier features are binned into a grid with zero offset in x and y of finest resolution X and the cluster centers are used as motion saliency points or salient features. In one example a center point of a cluster is determined to be a salient feature point. In other examples an area surrounding a center point of a cluster may be determined to include salient feature points and the area may be a circle square or other geometric shapes.

Video retargeting includes processing videos to generate modified videos that may zoom in on and or preserve the salient features. In one example video retargeting comprises estimating a crop path C t that comprises a sequence of crop windows to be applied to a video. The sequence of crop windows can be applied to a sequence of frames of the video to generate the modified video. The crop path for example may be estimated to preserve the salient features in a video content while adhering to cinematographic principles such as smoothness. Thus the crop path may comprise constant linear and parabolic segments that may ensure the smoothness of the resulting modified video.

FIG is a block diagram of an example method for video retargeting in accordance with at least some embodiments described herein. Retargeting a video may comprise estimating a crop path to be applied to a video to generate a modified video preserving the salient features in a content of the video. Method shown in FIG presents an embodiment of a method that for example could be used with the systems and and may be performed by a device a server or a combination of the device and the server. Method may include one or more operations functions or actions as illustrated by one or more of blocks . Although the blocks are illustrated in a sequential order these blocks may also be performed in parallel and or in a different order than those described herein. Also the various blocks may be combined into fewer blocks divided into additional blocks and or removed based upon the desired implementation.

A crop path C t t 1 . . . n with n being a total number of frames in a video may be described mathematically as a linear similarity transform Afor each frame t with Abeing unknown. Aapplied to a point x x x can be described by the following equation 

At block of FIG the method includes receive constraints limiting changes to an original video. The constraints may include forcing the crop windows that the crop path comprises to be included within original frames of a respective video. The crop windows may have a pre defined size. Also the crop windows may be constrained to include the salient features determined by the motion saliency method described in FIG .

At block the method includes receive cost function and perform the optimization. The cost function may be a weighted combination of the first to third derivatives of the crop path as mentioned above and can be described mathematically by the following equation 

Another constraint which may be received at block may comprise restricting the size of the crop windows to zoom in on action in frames of a respective video and include a first threshold number of salient features e.g. or less than a first threshold of salient features as opposed to zooming out away from action. The optimization may also attempt to determine crop windows large enough to include as many salient features as possible in the crop windows or to include a second threshold number of salient features. To balance an objective of zooming in on action with an objective of including as many salient features as possible a contraction objective may be added to the optimization problem. Adding the contraction objective may be accomplished by adding the scale factor ain equation 1 weighted by 0.5 or other values to the objective function in equation 2 .

At block method includes determine a crop path comprising a sequence of crop windows of a pre defined scale less than one with respect to the original frame size subject to constraints. The optimization can be performed and results in an optimal crop path subject to the constraints. The optimal crop path comprises a sequence of crop windows that fit inside original frames of the respective video.

At block the method includes apply the crop path to the original video. The optimal crop path may be applied to an original video to generate a modified video. The modified video includes the salient features and may zoom in on the salient features. The method in FIG may be performed on each original video received and a respective modified video may be generated for each original received video. In other example the method may be performed on portions of each video or on groups of videos to generated respective modified videos.

A single video may be generated from multiple modified videos. At a given time a view from the multiple modified videos may be selected to be part of the single video. The view may include a single frame or a portion of a respective video.

Selecting a view may comprise evaluating action content in a portion of a respective video and assigning an action score that represents an average motion magnitude of the salient features included in the given video. This selection may be subject to constraints. In one example if the selection comprises multiple switching between frames of different videos in a short span of time to produce a single video the single video may not represent a pleasant viewing experience. Transitioning between frames or views from multiple videos may be optimized to adhere to cinematographic principles and providing an acceptable viewing experience.

FIG illustrates a block diagram of an example method for view selection in accordance with at least some embodiments described herein. Method shown in FIG presents an embodiment of a method that for example could be used with the systems and for example and may be performed by a device a server or a combination of the device and server. Method may include one or more operations functions or actions as illustrated by one or more of blocks . Although the blocks are illustrated in a sequential order these blocks may also be performed in parallel and or in a different order than those described herein. Also the various blocks may be combined into fewer blocks divided into additional blocks and or removed based upon the desired implementation.

At block method includes receive multiple modified videos. The multiple modified videos may have been processed by the motion saliency and video retargeting methods of .

At block method includes assign action score to each view of an associated video. A view may be a single frame or a portion of respective video. Each of the multiple modified videos comprises a sequence of frames. For each frame i of a modified video v an action score a i is assigned. The action score a i may be an average motion magnitude of salient features in a content of a view from the modified video a i v .

In one example a camera used to record an original video which may be retargeted to generate one of the multiple modified videos may have had a biased view or a different perspective compared to other cameras. For example a camera that is closer to a sports field may have salient features with larger motion magnitude content than a camera that is not close to the sports field. To account for this bias method at block includes normalize action scores over each view to account for respective camera perspective. Normalizing action scores may include dividing the action scores by a common variable in order to negate the effect of camera perspective on the action scores. Action score normalization may include normalization by average motion magnitude summed over all frames or summed over a temporal window. Normalization may allow action scores of different views from different cameras with different perspectives to be compared on a common scale. In another example if prior knowledge about cameras locations setup exists a negative penalty can be added to an action score assigned to frame of a video recorded by a camera with a biased perspective of an event being recorded.

At block the method includes perform view selection and transitioning optimization subject to constraints. Selecting a frame from one of the multiple modified videos can be formulated as an optimization subjected to constraints. An objective function for the optimization may be maximizing the action score of the frame being selected. This optimization may be subject to constraints however to take into consideration for example optimal transitioning from one frame of a given video to another frame from another given video. Limiting switching between frames from different videos may be necessary for an acceptable viewing experience.

The optimization may employ a dynamic programming technique or other optimization algorithms such as sequential quadratic programming or genetic algorithms. A negative switching penalty wmay be associated with frames of each video v. Over time the negative switching penalty may decay and switching may become more acceptable. The decaying negative switching penalty can be described for a given frame i at a given point in time by the following equation 

The dynamic programming formulation of the optimization may compute an accumulated action score s i over frames of each video v while accounting for switching penalties. Assuming s j is computed for all j

Action scores may be assigned to frames of multiple given videos over time. FIG shows an example action score chart. The action score chart shows example normalized action scores assigned to frames of three videos over time. Line represents assigned action scores over time for frames of a first video. Line represents assigned action scores over time for frames of a second video. Line represents assigned action scores over time for frames of a third video. X axis of the action score chart in FIG shows frame numbers. For example the action score chart shows more than frames for each video. Y axis shows action scores assigned to frames of a given video. The three videos may be synchronized. For instance at a 300frame of each video an action score may be assigned. The action score chart in FIG shows that the 300frame of the third video has a higher action score line than action score of the second video line which has a higher action score than the first video line . Therefore at a given point in time represented by the 300frame of each video the third video has the highest action score.

FIG illustrates an example of applying a dynamic programming optimization method subject to constraints in order to select an optimal view. iframes and from three videos are shown as hatched circles. Previous frames e.g. i 1 are shown as black circles. An example action score calculation is shown for the iframe of the second video i.e. s i according to the dynamic programming technique described above. A similar calculation may be performed for all frames at a given point in time for all videos to select an optimal view at a given point in time.

This optimization can be implemented in real time as videos are being received. The optimization may also be applied to post process recorded videos. In the case of post processing recorded videos an accumulated score s i may be computed for all frames of a given video and optimal views and transitioning points are found by backtracking through the recorded videos.

FIG is a functional block diagram illustrating an example computing device used in a computing system that is arranged in accordance with at least some embodiments described herein. The computing device may be a personal computer mobile device cellular phone video game system or global positioning system and may be implemented as a client device a server a system a combination thereof or as a portion of components described in . In a basic configuration computing device may include one or more processors and system memory . A memory bus can be used for communicating between the processor and the system memory . Depending on the desired configuration processor can be of any type including but not limited to a microprocessor P a microcontroller C a digital signal processor DSP or any combination thereof. A memory controller can also be used with the processor or in some implementations the memory controller can be an internal part of the processor .

Depending on the desired configuration the system memory can be of any type including but not limited to volatile memory such as RAM non volatile memory such as ROM flash memory etc. or any combination thereof. System memory may include one or more applications and program data . Application may include a video retargeting and view selection algorithm that is arranged to provide inputs to the electronic circuits in accordance with the present disclosure. Program Data may include video content information that could be directed to any number of types of data. In some example embodiments application can be arranged to operate with program data on an operating system.

Computing device can have additional features or functionality and additional interfaces to facilitate communications between the basic configuration and any devices and interfaces. For example data storage devices can be provided including removable storage devices non removable storage devices or a combination thereof. Examples of removable storage and non removable storage devices include magnetic disk devices such as flexible disk drives and hard disk drives HDD optical disk drives such as compact disk CD drives or digital versatile disk DVD drives solid state drives SSD and tape drives to name a few. Computer storage media can include volatile and nonvolatile non transitory removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

System memory and storage devices are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media can be part of device .

Computing device can also include output interfaces that may include a graphics processing unit which can be configured to communicate to various external devices such as display devices or speakers via one or more A V ports or a communication interface . The communication interface may include a network controller which can be arranged to facilitate communications with one or more other computing devices over a network communication via one or more communication ports . The communication connection is one example of a communication media. Communication media may be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. A modulated data signal can be a signal that has one or more of characteristics set of the signal or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media can include wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency RF infrared IR and other wireless media.

Computing device can be implemented as a portion of a small form factor portable or mobile electronic device such as a cell phone a personal data assistant PDA a personal media player device a wireless web watch device a personal headset device an application specific device or a hybrid device that include any of the above functions. Computing device can also be implemented as a personal computer including both laptop computer and non laptop computer configurations.

In some embodiments the disclosed methods may be implemented as computer program instructions encoded on a computer readable storage media in a machine readable format or on other non transitory media or articles of manufacture. FIG is a schematic illustrating a conceptual partial view of an example computer program product that includes a computer program for executing a computer process on a computing device arranged according to at least some embodiments presented herein. In one embodiment the example computer program product is provided using a signal bearing medium . The signal bearing medium may include one or more program instructions that when executed by one or more processors may provide functionality or portions of the functionality described above with respect to . Thus for example referring to the embodiments shown in one or more features of blocks and or blocks may be undertaken by one or more instructions associated with the signal bearing medium . In addition the program instructions in FIG describe example instructions as well.

In some examples the signal bearing medium may encompass a computer readable medium such as but not limited to a hard disk drive a Compact Disc CD a Digital Video Disk DVD a digital tape memory etc. In some implementations the signal bearing medium may encompass a computer recordable medium such as but not limited to memory read write R W CDs R W DVDs etc. In some implementations the signal bearing medium may encompass a communications medium such as but not limited to a digital and or an analog communication medium e.g. a fiber optic cable a waveguide a wired communications link a wireless communication link etc. . Thus for example the signal bearing medium may be conveyed by a wireless form of the communications medium e.g. a wireless communications medium conforming to the IEEE 802.11 standard or other transmission protocol .

The one or more programming instructions may be for example computer executable and or logic implemented instructions. In some examples a computing device such as the computing device of FIG may be configured to provide various operations functions or actions in response to the programming instructions conveyed to the computing device by one or more of the computer readable medium the computer recordable medium and or the communications medium .

It should be understood that arrangements described herein are for purposes of example only. As such those skilled in the art will appreciate that other arrangements and other elements e.g. machines interfaces functions orders and groupings of functions etc. can be used instead and some elements may be omitted altogether according to the desired results. Further many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components in any suitable combination and location.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope being indicated by the following claims along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.

