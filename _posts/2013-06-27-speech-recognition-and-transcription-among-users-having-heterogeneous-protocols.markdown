---

title: Speech recognition and transcription among users having heterogeneous protocols
abstract: A system for facilitating free form dictation, including directed dictation and constrained recognition and/or structured transcription among users having heterogeneous protocols for generating, transcribing, and exchanging recognized and transcribed speech. The system includes a system transaction manager having a “system protocol,” to receive a speech information request from an authorized user. The speech information request is generated using a user interface capable of bi-directional communication with the system transaction manager and supporting dictation applications. A speech recognition and/or transcription engine (ASR), in communication with the system transaction manager, receives the speech information request, generates a transcribed response, and transmits the response to the system transaction manager. The system transaction manager routes the response to one or more of the users. In another embodiment, the system employs a virtual sound driver for streaming free form dictation to any ASR.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09142217&OS=09142217&RS=09142217
owner: Advanced Voice Recognition Systems, Inc.
number: 09142217
owner_city: Scottsdale
owner_country: US
publication_date: 20130627
---
The present application is a Continuation Application of U.S. application Ser. No. 13 115 105 filed May 24 2011 for DYNAMIC SPEECH RECOGNITION AND TRANSCRIPTION AMONG USERS HAVING HETEROGENEOUS PROTOCOLS which is a Continuation In Part Application of U.S. application Ser. No. 12 497 675 filed Jul. 5 2009 for SPEECH RECOGNITION AND TRANSCRIPTION AMONG USERS HAVING HETEROGENEOUS PROTOCOLS now U.S. Pat. No. 7 949 534 which is a Continuation Application of U.S. application Ser. No. 11 824 794 filed Jul. 3 2007 for SPEECH RECOGNITION AND TRANSCRIPTION AMONG USERS HAVING HETEROGENEOUS PROTOCOLS now U.S. Pat. No. 7 558 730 which is a Continuation Application of U.S. application Ser. No. 09 996 849 filed Nov. 27 2001 for SPEECH RECOGNITION AND TRANSCRIPTION AMONG USERS HAVING HETEROGENEOUS PROTOCOLS now abandoned .

The present application relates to electronic speech recognition and transcription and more particularly to processes and systems for facilitating free form dictation including directed dictation constrained recognition and or structured transcription among users having heterogeneous system protocols. The grandparent application Ser. No. 09 996 849 which is herein incorporated by reference presents a system and processes for facilitating electronic speech recognition and or transcription among users having heterogeneous system protocols.

As set forth in the parent application networked application service providers ASPs are the most efficient way to utilize sophisticated speech recognition and or transcription engines having robust dictionaries and vocabularies for large scale users especially in the professions. The networked application service provider also known as on demand software or software as a service interconnects application software to high accuracy speech recognition and or transcription engines which may exist on a centralized specific server application or one of the facilities in a peer to peer network computing peer node or networking as a distributed application architecture that partitions tasks and or workloads between peers to form a peer to peer network as well as the cloud computing network configuration.

However a barrier to implementation of these networked systems is the user s use of internal business and or system protocol legacy protocols which include in many cases both unique native communications and application protocols. These protocols are marked by their unique interface with the entities system and or organization and are therefore not universal in their interconnect capabilities or their application. Thus most network systems are unavailable to users employing legacy or native systems.

As set forth in the parent and grandparent applications seamlessly interfacing with network application service provider software that enables powerful speech recognition and or transcription engines to interface with legacy systems is required in order for these legacy systems to interface effectively with robust network based systems. Centralized databases or uniformly accessible databases that contain information for a number of users including the wide spread availability of specific vocabularies which include phraseology grammar and dictionaries as well as formatting structures for users of the system are usually more efficient than a network of mere direct point to point links between individual users.

But universally available recognition databases including vocabulary databases and dictionaries suffer from significant inefficiencies in facilitating communications between users of a more centralized database system especially if the dictation to be transcribed is free form or dynamic. Even though a recognition engine is very accurate in spoken word speech recognition the transcription may be filled with transcribed material which is out of context misinterpreted or not formatted correctly. Simply stated garbage in garbage out. 

Thus even though engine providers advertise in terms of recognition and transcription accuracy the real issue with these robust engines is ease of use user friendliness and the direct usability of the transcribed material without extensive editing correcting and or reformatting. Perhaps most significantly the content of a single database rarely contains every user s required information even when that database specializes in information regarding a particular field or expertise e.g. medicine.

A system for facilitating the exchange of speech which includes spoken text and verbal and non verbal commands and information among users having heterogeneous and or disparate internal system protocols which is safe secure and easy to use was set forth in the parent and grandparent applications. However seamless use of automated speech recognition and or transcription engines ASRs by one or more networked application server providers ASPs presents a system restriction which is inherent to this configuration. Even though the remotely located ASRs are more robust and provide for use of larger and more diverse dictionaries and vocabularies including specific dictionaries the ability of a remote user to properly select the needed system information for a specific application is restricted and complicated. This is especially true when ASRs and or different aspects of a single vocabulary or a specific dictionary need to be selected on the fly i.e. dynamically or during a free form streamed dictation session or in response to a streamed prerecorded session.

When a particular free form streamed dictated session requires access to a myriad of specialized functions such as medical information which must serve a number of specialized purposes these system restrictions may overshadow the usefulness of networked robust ASRs. Similar restrictions are present on these remote robust ASRs especially when certain formatting and vocabulary are necessary for very specialized application or functions which form a portion of otherwise normal dictation.

Although some prior art systems contain drop down menus which can be populated and thus create documents with predetermined word lists and or short phrases for the system these systems contain inherent restrictions and interruptions in the dictating session which limit the required functionality for free form streamed dictation. That is these menus lists do not provide the flexibility to accept the streaming of dictated sentences and phrases including jargon normally associated and or recognized by practitioners and or paraprofessional or administrative personnel in a specific trade or profession such as for example medicine or law.

Thus populating drop down menus lists with predetermined single words or short phrases has not proven adequate for these higher functionality uses and unduly constrains the speaker and or interrupts his her train of thought. Additionally these types of drop down menus lists are more easily populated by an administrator on a keyboard or with a mouse and do not require the capability or sophistication of a centrally controlled transcription system and robust recognition and or transcription engines ASRs . An example of complex free form dictation is a surgeon dictating notes during an open heart procedure or a radiologist reading an X ray film or an MRI scan.

Previous attempts to expand the flexibility of centrally controlled systems were to create large user files or databases which could be accessed only by a single user. These user files contained the needed user profile for dictation as well as the user specific vocabularies or dictionaries for the ASRs. Thus all the capability of the system for a single user had to be pre stored for that user alone. This limited the amount of new indexed data generally accessible to a specific user as well as the flexibility of using ASRs and or dynamically on the fly switching to specialized vocabularies as needed or directed by the user or the system. That is general databases for example dictionaries could not be universally updated without the necessity of updating each individual user s database associated with each specific ASR. Further as these databases grew the ability to navigate the different capabilities of these large databases in a short time frame on the fly became limiting especially during live complex transcription that required the ASR to dynamically switch among vocabularies of multiple specialties to obtain optimum recognition accuracy and or with multiple speakers such as for example legal depositions. This made certain uses impossible such as for example in a court room setting or in an operating theater.

Moreover previous systems did not provide dynamic system interface between the automated speech recognition and or transcription engine ASR and the legacy user such that the system could prompt the user to focus the dictation to provide a more structured set of recognition rules and or a constrained recognition and or a structured transcription. Such systems required cumbersome human machine system interface requiring the user to for example pause in order to command or instruct the system to accommodate the different scenarios and then pause until the system could locate and upload the database required to respond.

Additionally certain recognition speech engines by design process audio files on a batch bases. Although a design limitation not related to the accuracy or the speed of the engine this constraint heretofore foreclosed certain applications including limiting their capability to transcribe streamed dictation to an amount of information accepted by the recognition engine in a single batch. Other speech engines are only compatible with dictated text from a specific source such as for example live microphone or line input. This inhibits the ability of these engines to operate with digital systems or systems which digitize speech into data packets for system identification and processing. Thus even though the capability was provided to access networked and remote functionality the complete value of this capability was hindered by these inherent limitations.

A method and system for facilitating Free Form Dictation including Directed Dictation and Constrained Recognition and or Structured Transcription among Users having heterogeneous native legacy protocols is provided. The System includes at least one System Transaction Manager running on a microprocessor having a system protocol adapted to receive a verified streamed Speech Information Request SIR from at least one authorized User employing a first legacy User protocol and Routing a Response configured in a second legacy User protocol to one or more Users that employs a second legacy User protocol.

The Speech Information Request SIR is comprised of Free Form Dictation which can be Directed Dictation which is live dictation or from a previously recorded session which contains spoken text for transcription and Commands Speech including Audio and Non Audio Commands for directing the production of Constrained Recognition and or Structured Transcription and the Response is comprised of a transcription of the spoken text including Formatted Transcription in response to Commands whether from the SIR the System or the Automated Speech Recognition and or Transcription Engine ASR . The System Transaction Manager using a system protocol is in communication with all components and or elements of the System to enable Users to experience uninterrupted seamless Free Form Dictation using their own legacy User protocol.

The System includes at least one Automated Speech Recognition and or Transcription Engine ASR which can have a legacy engine protocol in communication with the System Transaction Manager for receiving the Speech Information Request SIR containing the Directed Dictation as well as System generated Commands from the User and or the System Transaction Manager which are processed by the Automated Speech Recognition and or Transcription Engine ASR to Constrain Recognition and generate Structured Transcription in Response to the SIR and for transmitting the structured transcribed Response to the System Transaction Manager.

In one aspect of the System at least one Application Service Adapter ASA configured to provide bi directional transmission between the first legacy User protocol and the System Transaction Manager s uniform system protocol and between the second legacy User protocol and the System Transaction Manager s uniform system protocol is provided. A Speech Recognition Service Adapter SRSA is utilized to provide when required bi directional translation between the System Transaction Manager s uniform protocol and the ASR s native engine protocol. A first legacy User protocol can be the same as or different than the second legacy User protocol.

The System components including the System Transaction Manager and the ASR can reside in a single location or the functionalities can be distributed throughout the Internet as in cloud applications or be included as a Peer Node in peer to peer networks which share functionalities by and through the System Transaction Manager. The ASR can reside on a remote Speech Recognition and or Transcription Server SRTS or at one or more nodes in a peer to peer configuration or within the cloud and is in communication with the System Transaction Manager through the network.

Directed Dictation can be provided directly by the User during a session by structuring the User Interface Device so as to prompt the User to constrain his dictation to specific subject matter and or content or it can be provided by the legacy User application or the System responding to the User s specific use of fields or segments of the User Interface Device or visual or audio prompts generated by the legacy User system applications running on the legacy User Interface Device. The legacy User Interface Devices can include remote stations e.g. PDAs cell phones phones tablets PCs digital recorders analog recorders and Internet devices and or Directed Dictation can be provided by employing communication between the legacy User interface and the System Transaction Manager such that the System Transaction Manager prompts the User to dictate using a specific format and or vocabulary either by prompt from the User Profile or in accordance with a predetermined User structured instructions and or from actions of a User such as selection of a field on the User interface which instructs the System Transaction Manager to select a specified Constrained Recognition and or Structured Transcription associated with a specific ASR.

In one embodiment the System employs a Buffer function to facilitate Free Form Dictation including the System s use of batch Automated Speech Recognition and or Transcription Engines ASRs and or Constrained Recognition and or Structured Transcription while providing the User with an uninterrupted seamless dictating experience.

In another embodiment the System employs a Virtual Sound Driver for streaming Free Form Dictation to any ASR regardless of the ASR s ability to recognize and or transcribe spoken text only from for example a live microphone or line input. The System Transaction Manager sends spoken text to the ASR by way of the Virtual Sound Driver. The Virtual Sound Driver outputs the spoken text in a data format which simulates or mimics that of the input from for example live microphone or line source. This results in the ASR upon receiving the spoken text from the Virtual Sound Driver processing it as if it were generated by for example a live microphone or line source regardless of the actual originating source.

A method for facilitating Free Form Dictation including Directed Dictation and Constrained Recognition and or Structured Transcription among Users having heterogeneous system protocols is also provided. The method comprises generating an authorized Speech Information Request SIR which is either live or pre recorded obtained through a first legacy User protocol the Speech Information Request SIR comprised of Directed Dictation translating the first legacy User protocol to the uniform System protocol used by a System Transaction Manager transmitting the translated Speech Information Request SIR through the System Transaction Manager that directs the SIR to an Automated Speech Recognition and or Transcription Engine ASR generating a Response to the SIR including transcription of spoken text using the ASR the Response comprised of Structured Transcription of the spoken text translating the uniform System protocol to a second legacy User protocol which may be the same as the first and transmitting the Response to a User via the System Transaction Manager to provide the Recipient User with a transcription of the spoken text including a Formatted Transcription if required.

The following terms and general definitions are used herein to describe various embodiments of a Speech Recognition and Transcription System the System .

Applications Programming Interface API shall mean a set of services or protocols provided by an operating system to applications computer programs running on microprocessors as well as a set of services the Application Service Adapter ASA provides to Native Application Protocols. The API may provide services or protocols geared to activities of a particular industry or group such as physicians engineers lawyers and the like.

Application Service Adapter ASA shall mean the application that provides the bi directional interface between a legacy User protocol and the System Transaction Manager s uniform System protocol. The ASA provides those aspects required by legacy application in order to make use of Directed Dictation including monitoring the User Interface Device for changes in output for example changes in caret position and conveying the relative information to the System Transaction Manager as well as the Constrained Recognition and or Structured Transcription of an ASR as well as interface among disparate Users by allowing a User s existing Native Application Protocol and or Native Communications Protocol to communicate with the System Transaction Manager and ultimately a specific Automated Speech Recognition and or Transcription Engine ASR .

Application Service Provider ASP or Network Application Service Provider shall mean functionality or an entity that provides computer based services to customers over a network including interconnecting application software to high accuracy speech recognition and or transcription engines which may exist on a centralized specific server application or one of the facilities Peer Node in a peer to peer network or networking as a distributed application architecture that partitions functionality tasks or workloads between peers to form a peer to peer network of nodes as well as the cloud computing network configuration. In one aspect ASPs provide access to a particular application program using a standard protocol such as HTTP HTTPS and the like.

Audio Data shall mean sounds which are audible and non audible including verbal tones clicks and pauses distinguishable by the System from spoken text and usually the basis of an Audio Command. This Audio Data can be generated by utterances from the User or tactile generated by for example depression of a tone key on a mobile phone. The Audio Data is contained in an audio file.

Audio Preprocessor shall mean a processor capable of detecting Audio and Non Audio Commands in streamed Speech including verbal Commands and non verbal Commands. For example tones clicks silence or simple numeric patterns of strings as well as verbal Commands from the streamed text. Depending on the System action associated to the detected Command the Audio Preprocessor also segments the spoken text based upon Commands such that segments are able of separate and distinct processing by the System.

Automated Speech Recognition and or Transcription Engine ASR shall mean a process running on a microprocessor that recognizes spoken text and certain ASR directed Commands and performs Constrained Recognition and or Structured Transcription of this spoken text in accordance with instructions from the System Transaction Manager and Audio and Non Audio Commands.

Buffer shall mean a buffer function such as a temporary storage or retention device able of dynamically accumulating and or storing streamed data submitted by a User to allow the System Transaction Manager to perform System s functions seamlessly without loss of streamed User information and or to allow ASR to perform Constrained Recognition and or Structured Transcription functions seamlessly without loss of streamed User information while the User perceives no disruption in Free Form Dictation.

Command shall mean any type of prompt on User s application and or contained Embedded in a streamed dictated Speech audio file including Directed Dictation which is recognized by the System as an instruction for controlling and or configuring a System component but is not included in the text to be transcribed. For example Commands instruct the System on Formatted Transcription of the recognized transcribed spoken text from an ASR and can also instruct the disposition of a Response. For example a Command might instruct the System to place the recognized transcribed spoken text into a specified Microsoft Word format or a Command might instruct format of the recognized transcribed spoken text into segments in order to populate a template in a Microsoft Word format. Commands of many types e.g. Audio Commands and Non Audio Commands can be detected by the System Transaction Manager the ASR or various pre and sub components of the System. Audio Command shall mean a Command consisting of any Audio Data or signal in the streamed Speech which is distinguishable by the System from the spoken text. Non Audio Commands shall mean Commands Embedded into the audio file which are not part of the Audio Data and can be encoded by means such as interleaving. Non Audio commands can also be System generated for example in response to the input focus of Directed Dictation and can be contained in the non audio portion of the audio stream Meta Data to direct for example the ASR. Spoken Command shall mean a special Audio Command and generally includes verbiage having special meaning to the User application and or one or more components of the System but is not spoken text. A Spoken Command can include verbalized words or phrases uttered by the User during streamed dictation and Embedded into the Speech audio file . Tactile Commands shall mean Commands generated from the keyboard mouse foot pedal microphone keys and the like and can be audio as a touch tone phone or non audio as in an electronic key stroke. A Tactile Command can also include touch screen applications or positioning on a visual template including eye tracking software.

Constrained Recognition shall mean recognition by the Automated Speech Recognition and or Transcription Engine ASR which is constrained to the use of specific dictionaries and or vocabularies or the like by the System Transaction Manager through interaction with the legacy User Interface Device and or a remote station and or User interface actions and or User Profile settings or the like in the User Database to enhance recognition accuracy and or Dictation Context and or transcription formatting.

Correctionist shall mean a designated operator within the System for correcting the transcribed text produced by an ASR.

Correctionist Pool shall mean a pool of Correctionists having particular programming applications capabilities including for example skills for correcting legal medical and engineering documents within the System Transaction Manager.

Database shall mean an indexed data repository which indexed data may include previously transcribed Free Form or Directed Dictation. Databases include User Databases which are unique to a specific User including the User Profile and can include User specific pre programmed System responses to Commands for specifying spoken text to the System Transaction Manager to facilitate Directed Dictation for a specific User or group of Users a System Database operated upon by the System Transaction Manager containing general System responses to Commands including User Profiles as well as the application pre programmed Responses to the Commands related to the legacy User protocol and specific prompts application templates and the like needed to facilitate Free Form Dictation from the User and a Universal Database which is associated with Constrained Recognition and or Structured Transcription such as a dictionary or vocabulary and or Directed Dictation containing generic or specific prompts templates and the like to facilitate Free Form Dictation available for all Users or a specific group of Users of the System and an ASR Database which is associated with the ASR through for example the SRSA and contains information including User Profile vocabularies dictionaries and the like required by the ASR to process the SIR.

Dictation Context shall mean a change in the context of the dictation Constrained Recognition and or Structured Transcription of the spoken text in response to Commands which are usually Non Audio Commands.

Directed Dictation shall mean Free Form Dictation of Speech in a manner to enhance recognition accuracy by identifying differing types of Speech as initiated by the User and or the System Transaction Manager and or User interface including remote devices which encompasses Free Form Dictation either live or recorded wherein Commands either on User Interface Device for example a programmed PDA or prompted by communication with the System Transaction Manager prompt the User to dictate on a specific topic and or utilize a specific vocabulary or otherwise limit the subject matter or the context of the spoken text so that the content is limited and or the format structured by the System including the ASR prior to entry into the Correctionist Pool and or final document formatting. For example a medical interface may prompt the User to dictate a patient history and then when focus is shifted to the diagnosis by for example a User Interface Device prompt the User is reminded to dictate the diagnosis . Additionally the User by selection of a particular field or grid on the User Interface Device such as prognosis commands the System Transaction Manager to instruct the ASR to load a selected Constrained Recognition containing vocabularies and or dictionaries associated with prognosis for standard ASR process with selected vocabulary and or Structured Transcription of the subsequent spoken text.

Embedded Command shall mean a Command encoded into a Speech stream audio stream entered at the User interface either directly by dictation or pre programming in a legacy User application or prompted to the User by the System Transaction Manager or as a Non Audio Command encoded by one or more components of the System.

Enrollment shall mean the process of creating a set of interface data for a particular User with one or more Automated Speech Recognition and or Transcription Engines ASRs to establish a recognition interface between the specific User and ASR to provide accurate transcription.

Extensible Markup Language XML VOICE Extensible Markup Language VXML and Standardized Generalized Markup Language SGML shall mean self defining data streams that allow embedding of data descriptions using Commands tags and formatting. XML is a subset of SGML.

Formatted Transcription shall mean the formatting of the spoken text transcribed by a System component for example a Speech Recognition Service Adaptor SRSA in response to a Command. For example formatting may involve placing the transcribed spoken text into a Microsoft Word document with file name. Transcription formatting may refer to the internal representation of transcribed Speech within the System data structure or to the external representation of the transcribed Speech when viewed by Users visual appearance or to both or may be used to populate designated areas of for example a form document.

Free Form Dictation shall mean streamed Speech uninterrupted by pauses required for the System Transaction Manager to access System speech transcription and or recognition functions wherein the spoken text is a word stream which imparts a thought or concept to the listener or reader in contrast to words or stock phrases and verbiage used to populate the cells in a form or a drop down menu.

Job shall mean all information contained in a single Speech Information Request SIR which can be authenticated by a User ID which is treated by the System Transaction Manager as a single unit of information under a common system identification number even if the Speech is in the form of a continuous stream Free Form Dictation rather than a batch.

Meta Data shall mean a segment or block of data used by the System which contains Commands header data security data and identification verification data. For example a Resource Interchange File Format RIFF which is a meta format for storing labeled chunks of data.

Native Application Protocol shall mean a protocol which a User employs to support interaction with Speech Information Requests SIRs and Responses and is native to the legacy User protocol.

Native Communications Protocol shall mean a communications protocol that the User employs to support communication within its legacy system. For many transactions a User employs the Native Communications Protocol and the Native Application Protocol to access its core processes in total the legacy User s legacy protocol.

Peer Node shall mean a component a function or a layer existing on a User station in a peer to peer network accessible by at least the System Transaction Manager to perform System functions which components can include an Automated Speech Recognition and or Transcription Engine ASR .

Pre existing Public Communication System shall mean a communications link that is accessible to Users and can support electronic transmission of data. An example includes the Internet which is a cooperative message forwarding system linking computer networks worldwide.

Real Time Speech Information Request shall mean a User whose SIR transactions operate at the highest priority to allow for Real Time transcription of Speech or at least a streaming of the SIR. When the System Transaction Manager receives a Real Time SIR it immediately locates an available ASR capable of the request and establishes a bi directional bridge whereby spoken and transcribed text can be directly exchanged between a User and an ASR in Real Time or near Real Time.

Recipient or Receiving User shall mean a User that receives a transcription of a Job or portion thereof.

Requestor or Requesting User shall mean a User that submits Speech for transcription or a request for transcribed Speech within the System.

Response to a Speech Information Request SIR shall mean transcribed spoken text and Structured Transcription including Formatted Transcription of transcribed spoken text and System generated Commands for processing the spoken text for example on the legacy User interface.

Routing shall mean the process of transferring Speech prompts and templates that can employ either push technology or pull technology where push refers to the Requestor initiating the transfer and pull refers to the Recipient or the System initiating the transfer in response to a Command.

Speech shall mean spoken text and Audio and Non Audio Commands which the System can operate upon to provide a transcription of the spoken text including a Formatted Transcription.

Speech Information Request SIR shall mean Speech which can be acted upon by System components including the System Transaction Manager to provide a transcription of the spoken text including a Formatted Transcription.

Speech Recognition Service Adapter SRSA shall mean an application service adapter layer that communicates with the Automated Speech Recognition and or Transcription Engine ASR through the combined vendor independent ASR interface vendor specific ASR interface and retrieves data from the ASR Database including User Profile vocabularies dictionaries and the like required by the ASR to process the SIR. The SRSA can perform formatting transcription to yield a Formatted Transcription.

Speech Recognition and Transcription Server SRTS shall mean a server application within the System typically running on a separate microprocessor and encompassing any number of ASRs. The SRTS interfaces multiple ASRs with other System components through multiple links. Each link maintains a Job queue from the System Transaction Manager through one or more SRSAs. The SRSA typically includes two adapters an Audio Preprocess Adapter and a Speech Recognition Service Adapter SRSA .

Structured Transcription shall mean transcription of spoken text by the ASR which can be constrained to the use of specific dictionaries vocabularies or the like by the System Transaction Manager in response to User Commands e.g. Directed Dictation or System generated Commands such as from a User Profile to enhance transcription context. Structured Transcription can be processed through Constrained Recognition by a specific ASR which transcription can be formatted Formatted Transcription. For example Directed Dictation associated with a field in a Microsoft Word medical form for diagnosis Commands the System Transaction Manager to initiate Constrained Recognition using a diagnosis vocabulary and subsequently use Structured Transcription to structure the transcribed spoken text associated with the identified Directed Dictation in Microsoft Word format inserted into the appropriate medical form field for diagnosis. 

Subscriber shall mean an entity whether a User or not which is authorized to employ transactions on the System.

System Transaction Manager shall mean a System s application that provides a central interconnect point hub and a communications interface among System components and Users having disparate or heterogeneous protocols and an information router or bridge or switch within the System that manages the scheduling routing of Jobs audio streams the proper Automated Speech Recognition and or Transcription Engine ASR selection and managing of User Profiles and processing of feedback of Command actions as well as the Speech Information Request SIR and the Response.

Updating a User Profile shall mean a User Profile update from documents dictionaries Commands pronunciation files and further User training for the purpose of improving recognition accuracy and updating Databases containing specific User Commands.

User shall mean an entity that uses services provided by the System. A User may also be a Subscriber.

User Identification ID shall mean a System identifier which is used to uniquely identify a particular User and its legacy protocol.

User Interface Device shall mean a device hardware and software which provides the human machine interface between the User and the System. User Interface Device is part of the legacy User system.

User Profile shall mean a dataset generated by a User enrolling on a specific ASR and required by an ASR to process User s Speech recognition. The User Profile includes User specific dictionaries Commands pronunciation files User Command Database and the like.

User Service Adapter shall mean a specific Application Service Adapter ASA that handles formatting and Routing of Speech Information Requests SIRs and Responses to elements of a User s protocol within the System.

Virtual Sound Driver shall mean a System device or application which facilitates the use of ASRs regardless of the ASR s ability to recognize and or transcribe spoken text from any input source such as for example a live microphone or line input. The output of the spoken text from the Virtual Sound Driver is in a data format which simulates or mimics that of the input from any input source such as for example a live microphone or line source. This results in the ASR upon receiving the spoken text from the Virtual Sound Driver to process it as if it were generated by any input source such as for example a live microphone or line source regardless of the actual originating source.

Processes methods and systems herein disclosed and claimed facilitate Free Form Dictation including Directed Dictation as well as Constrained Recognition and or Structured Transcription among Users having heterogeneous System protocols legacy User protocol . The System comprises computer based components some of which run on a microprocessor s including indexed Databases and User Interface Devices application and protocols. Broadly the System and methods disclosed herein provide for seamlessly providing Commands Audio and Non Audio System or User generated including those generated as part of Directed Dictation which can be live streamed or stored allowing disparate Users to selectively use and command robust ASRs using Free Form Dictation while experiencing no system delay or dictation interruption for System input of the SIR and Response when using a legacy User protocol.

A System Transaction Manager identifies Commands in the User streamed or stored dictation and if necessary causes the Speech stream to be buffered or otherwise paused and rewound in order to execute the Commands and thereby transcribe the spoken text through very robust ASRs using Constrained Recognition in a seamless manner without perceived interruption of the dictating session by the User. The System provides seamless Constrained Recognition and Structured Transcription including Formatted Transcription of spoken text and other information among legacy Users while utilizing different indexed Databases and ASRs to interoperate complex Commands and uses stored data on the fly to structure the transcription and otherwise frame and cull the transcribed product such that it requires less User and or Correctionist time to clean up the product. Not only is the instant System more user friendly it reduces the human interface time required to render the transcribed product usable even by way of disparate legacy User systems.

The System thus provides seamless recognition and or transcription of Free Form Dictation including Directed Dictation and access among Users of verbal streamed and or transcribed spoken text and or other information wherein the initiation of Directed Dictation can be either User interface or System directed. By means of Commands Audio and Non Audio which are acted upon by the System Transaction Manager and or the ASR the System provides the legacy User a streamed seamless interface dictation experience while utilizing multiple and various highly functional and robust Automated Recognition and or Transcription engines ASRs as well as structured vocabularies and dictionaries which include providing information from various indexed Databases including User Databases and Universal Database. An authorized User using a legacy User protocol can seamlessly access User Profiles Subscriber information as well as affecting changes in response to Commands including ASRs vocabulary dictionaries and Directed Dictation prompts and templates as well as Enrollment including seamlessly Updating the User Profile.

The System further provides for authorized legacy Users and or Subscribers to access the System and route the transcribed spoken text Response to another User authorized or not or back to itself. Thus the User can seamlessly dictate Free Form receive transcription Response including Formatted Transcription in accordance with the Commands and Routing by the System to a designated Recipient irrespective of the disparity of the legacy User protocol and or the System protocol.

The System which can generally be classified as an ASP comprises a System Transaction Manager running on a microprocessor for receiving a verified streamed Speech Information Request SIR from at least one verified User who also may be a Subscriber. The entry of such SIR opens a Job. The SIR can take the form of Directed Dictation containing spoken text and or other information to be obtained or transcribed and disseminated to other Users on the System or a request for previously transcribed Speech and or other information assessable to the System such as a User Profile.

A Speech Information Request SIR comprises Free Form Dictation which can be Directed Dictation which includes spoken text and Audio and Non Audio Commands using a first legacy User protocol which may be processed through an ASA to the uniform System protocol. The System Transaction Manager upon receipt of the SIR creates a Job and in accordance with contained and stored Commands to configure the System to process the Job including the requirement for Directed Dictation and or Constrained Recognition and or Structured Transcription through prompts and or templates stored within a Database or on the legacy User system process the SIR.

The System Transaction Manager which in communication with all System ASRs generates a Speech Information Request SIR in a uniform System protocol which is processed if needed through an SRSA and forwarded to the Automated Speech Recognition and or Transcription Engine ASR . The ASR upon receiving the Speech Information Request SIR from the System Transaction Manager generates a transcription of the Speech which is returned in the form of a transcribed Response. If there is a requirement for Constrained Recognition and or Structured Transcription the ASR is directed to load a specific vocabulary and or dictionary for recognition and transcription either by the System Transaction Manager or Embedded Command in the Speech directed at the ASR. The SIR contains Commands which instruct the System dynamically regarding Constrained Recognition and or Structured Transcription. These Commands are either acted upon by the System Transaction Manager or the designated ASR depending upon the Commands.

The transcribed Response is transmitted to the System Transaction Manager through the Speech Recognition Service Adapter SRSA if necessary which routes the Response to one or more of the Users including without limitation the User that generated the SIR employing a second legacy User protocol which may be the same as or different than the first legacy User protocol. If a Formatted Response is required the System Transaction Manager directs a post processing System component to format the transcribed spoken text in accordance with the specified Command to produce the Formatted Dictation.

The System Transaction Manager utilizes a uniform System protocol for processing the SIR and the transcribed Response. Subscribers to the System who may also be Users have identifying codes carried in Meta Data which are recognizable by the System for authorizing a System transaction to create a Job. Thus for System security and or billing purposes at least one Subscriber through the Subscriber s User s ID is required by the System to be involved in creating a Job.

In accordance with the instant method for exchanging transcribed spoken text and or information captured by Free Form Dictation which includes Directed Dictation among Users who may employ disparate legacy User protocols a Speech Information Request SIR is generated and or a request for previously transcribed speech and or other information through a first legacy User protocol and conveyed to the System Transaction Manager. The SIR is transmitted to the ASR through the System Transaction Manager using a Speech Recognition Service Adapter SRSA compatible with an ASR. The method also includes generating a transcribed Response to the SIR using the ASR and transmitting the transcribed Response to a User via the System Transaction Manager including a Constrained Recognition and or Structured Transcription if required and providing the User with the transcription from the ASR or a Formatted Transcription from for example the SRSA. The Response is compatible with a second legacy User protocol that may be the same as or different than the first legacy User protocol.

According to the method the Speech Information Request SIR which can include a request for previously transcribed speech and or other information is generated using a first User Application Service Adapter ASA. The method includes transmitting the SIR to a Speech Recognition and or Transcription Engine ASR which may have yet a different Speech recognition protocol through a Speech Recognition Service Adapter SRSA via a System Transaction Manager and generating a transcribed Response to the Speech Information Request SIR using the ASR. The Formatted Transcription Response to the Speech Information Request SIR is transmitted to the System Transaction Manager via the SRSA and the Formatted Transcription Response is returned to the System Transaction Manager. The System Transaction Manager using a second ASA conveys the Formatted Transcription to the User included in the Response through a separate User Service Adapter. The Response containing the Formatted Transcription so transmitted is compatible with a second User protocol that may be the same as or different than the first User protocol.

Turning to the Figures there is shown in a schematic drawing showing the System as an Application Service Provider ASP or Network Application Service Provider which provides computer based services to Users over a network including interconnecting application software to high accuracy ASRs including ASRs providing Constrained Recognition and or Structured Transcription.

Individual Users having distinct legacy User protocols communicate with the Speech Recognition and Transcription System via a communications link . Any User who is authorized can request transcription of spoken text or other stored and generated System information and any User may be the Recipient of transcribed spoken text and such other stored and generated System information. As described in detail below the Speech Recognition and Transcription System includes a System Transaction Manager which transfers Meta Data and Speech spoken text and Commands among Users and one or more ASRs which may exist on a centralized specific server application such as a Speech Recognition and Transcription Server SRTS or one of the facilities Peer Node in a peer to peer network or networking as a distributed application architecture that partitions functionality tasks or workloads between peers to form a peer to peer network of nodes as well as the cloud computing network configuration. In one aspect ASPs provide access to a particular application program using a standard protocol such as HTTP.

The System Transaction Manager as a central element of the System may comprise more than one physical and or functional elements and a multi tiered System Transaction Manager may be practical in some applications. In one embodiment the System Transaction Manager communicates with at least one User Application Service Adapter ASA see which provides an interface between the System Transaction Manager and a protocol that a User employs to generate spoken text and Commands. The System may also include one or more User Service Adapters see that process formatting of information including Formatted Transcription and Routing of information between the Application Service Adapters and the System Transaction Manager bi directional . This bi directional communication facilitates for example System Transaction Manager s initiation of User interface prompts for Directed Dictation.

Communication links include communication interface between the Users and the System which can be for example a public communications system such as the Internet. Each User has a User Identification ID for authentication and identification purposes including identifying a Subscriber as fully explained below. According to one aspect at least one User in any SIR transaction Job must be a Subscriber to the System. Thus the Subscriber is an authorizing agent that permits the SIR transaction Job access to the System .

Speech to be transcribed containing spoken text and Audio and Non Audio Commands when generated as Free Form Dictation and captured by a suitable User Interface Device using the legacy User protocol Native Communications protocol and Native Communications protocol is communicated to the System Transaction Manager in a manner as set out in more detail below. In one embodiment the Speech can be generated by the User employing Directed Dictation which increases not only the Response time of the System but the accuracy and usefulness of the Response as set out below.

As part of at least one User Interface Device the Speech is input into the System using any well known methods and devices for capturing audio signals. For example spoken text can be acquired using a microphone coupled to an A D converter which converts an analog audio signal representing the spoken text and Commands Audio and Non Audio to a digital signal that is subsequently processed using for example a dedicated digital signal processor or a general purpose microprocessor. For a discussion of the acquisition of audio signals for Speech recognition transcriptions and editing see U.S. Pat. No. 5 960 447 to Holt et al. which is herein incorporated by reference in its entirety and for all purposes.

The skilled artisan will realize that many audio input sources can be used by the User in accordance with the instant System. These inputs are capable of processing aspects involving population of User Profiles both System and ASR Enrollment User and System Command Databases in addition to providing means of recording Speech and processing document retrieval including a Response. These include applications that provide the minimum capability of recording Speech and streaming audio to the System Transaction Manager telephony using a telephone line including wireless that provides audio and drop down menus that allow a User to navigate through choices such as those that allow a User to enter its ID record Speech review and edit the Speech submit the audio recording to the System Transaction Manager and update the User Profile and recorders including hand held which are capable of recording Speech and of transferring the recording to a computer directly as well as with the use of an A D converter.

As better seen in the System involves interface between a User and the System Transaction Manager as well as an interface between System Transaction Manager and ASR or multiple ASRs . The User System Transaction Manager interface is a bi directional link which allows User direct communication through an ASA interface with System Transaction Manager which is instrumental in facilitating Free Form Dictation and more importantly Directed Dictation. Communication link provides Real Time interaction and interface between System Transaction Manager and User such that System Transaction Manager can interact with the User Interface Device during Free Form Dictation. In this manner System Transaction Manager has hands on involvement in the structure and generation of the content of the SIR during actual dictation of Speech.

Likewise the bi directional communication link between the System Transaction Manager and the ASR s provides dynamic interface between the System Transaction Manager and one or more ASRs during recognition transcription of the SIR to afford System higher capability of series and or parallel utilization of ASRs having different input requirements and or recognition transcription capabilities.

In one embodiment an Applicant in order to become a User of the ASP System initially must subscribe to the service receiving a User ID account codes billing instructions and the like through legacy User protocol. Once the interaction between User and System Transaction Manager is established the User populates a User Profile which is used for a myriad of purposes within the System and may for example contain ASR Enrollment data if required pronunciation dictionary population User Command Database population and the like. This initial transaction is accomplished through a special SIR to facilitate the interface and is not to be transcribed even if populated by using vocal microphone or line input.

As part of this initial transaction various User Interface Devices are also registered so that during Directed Dictation the System Transaction Manager can efficiently for example use bi directional prompts directed to a specific User interface when the User interface logs on to the System.

In operation to produce a System transcription of the User generated Speech which comprises spoken text and Commands including Audio and Non Audio Commands using a User s existing legacy protocol a SIR is created. Through a first User Service Adapter the System Transaction Manager transfers the SIR to an appropriate ASR through an ASR ASA if necessary. The ASR generates a Response to the Speech Information Request SIR which includes a Formatted Transcription of the spoken text. Using the SRSA the Response is transferred to the System Transaction Manager. Through a second User Service Adapter which may be the same or different than the first the System Transaction Manager transfers the Response to one or more of the Users with a transcription that is compatible with its particular legacy protocol. The Requesting User and the Receiving User may be the same User or a different User or a number of Users may receive the Response. Likewise the SIR may be for Speech previously transcribed and stored in a Database. The System Transaction Manager employs a uniform or system protocol capable of processing SIRs and Responses expressed in a standard or normalized data format. The only requisite for this protocol is that it is convertible by an ASA into the legacy User protocol and or any System Speech Recognition and Transcription Engines ASRs protocol.

As set forth above the User and or Application Service Adapters are the same when the User requesting a transcription of spoken text also receives the transcribed spoken text provided the application recording the Speech is the same as the application receiving the transcribed spoken text. In many cases a User Application Service Adapter will reside on the User s workstation workgroup legacy computer system. In such cases the System can employ sets of different User Application Service Adapters ASAs and User Service Adapters to facilitate transfer of information between two Users even though they may use similar protocols.

Turning to there is shown a simplified block diagram containing processing and flow of information among Users and components of the System of . For clarity the System shown in includes a representative User System Transaction Manager Speech Recognition and Transcription Engine and communications links . It should be understood however that the System would ordinarily include multiple Users multiple SARs and communications links and would in certain embodiments include more than one System Transaction Manger i.e. a tiered server clustered system with System Transaction Mangers communicating among themselves in a tiered server clustered arrangement. The System includes numerous other System components applications and Databases. Users normally access the System Transaction Manager by sending a SIR which can include a request for stored Speech information that includes the User s identification ID which can also be a Subscriber s ID if the User is a Subscriber. Each transaction must include a Subscriber whether the Subscriber actually requests or receives information relating to that transaction or not. An authenticated SIR is processed by opening a Job by the System Transaction Manager as further described.

As shown in the System includes processes that enable a User to generate a dynamic streamed SIR and transmit the SIR to the System Transaction Manager . The System Transaction Manager receives the SIR processes the SIR and transmits the SIR to the appropriate Speech Recognition and Transcription Engine . The ASR includes processes for receiving the SIR for processing and generating a Response to the SIR e.g. for transcribing the Speech and for transmitting the Response e.g. transcribed Speech back to the System Transaction Manager . The System Transaction Manager receives the Response processes the Response and transmits the Response to the User which may access System processes that enable it to receive the Response and to process the Response to the SIR. This is all facilitated by use of authentication routines certain protocol adapters and User Profiles as will be further explained.

User inputs Speech and other information into the System via a User Interface Device. The majority of this input is accomplished through Free Form Dictation including population of Databases and the like. The System by means of the Transaction Manager has bi directional communication with the User through the User Interface Device. In this manner applications can run on the User Interface Device using legacy User protocol in order to provide dictation prompts to the User which are managed and maintained primarily within the legacy User protocol for example on a server or workstation. These prompts are intended as a human machine interface wherein the User is prompted to direct constrain and otherwise structure the subject matter and content of the dictation.

Contrawise using the bi directional communication through the ASA the System is able to populate the User Interface Device prompts with data retained stored or retrieved by the System Transaction Manager in response to a Command. For example when a User logs on using a User Interface Device an automatic handshake is established with the System Transaction Manager and the System Transaction Manager is instructed as to all of the retained aspects and requirements associated with that particular User Interface Device.

The User by combining prompts generated by legacy User protocol and the System Transaction Manager in response to either sent or stored Commands can use Free Form Dictation to enter Speech into the System via the User Interface Device.

Free Form Dictation is a concept and functionality that is viewed from the point of view of the User. The User by using the system of prompts and or guides described above can interact with the User Interface Device to create a stream of dictated Speech in a conversational manner to convey or impart a thought idea or concept to the listener or reader uninterrupted by pauses required for the system behind the User interface to access and carry out the functional instructions in a manner so that the speaker is virtually unaware of the workings and requirements of the System.

In addition the System Transaction Manager in order to process this Free Form Dictation and more specifically Directed Dictation must itself possess a set of capabilities and operate in a rather unique fashion with internal System components as well as the number of general and specialized ASRs able of interface with System Transaction Manager on the network. This is especially true when an ASP is able of seamless interface with Users using diverse legacy User protocols.

This interface between System Transaction Manager and one or more ASR enables the System to produce Constrained Recognition and or Structured Transcription solely using the spoken text and Commands of the SIR produced using Directed Dictation.

As stated above the Speech input to the System is accomplished by a User System interface User Interface Device . The ability of the System to recognize and transcribe Free Form Dictation depends upon two aspects of User System interface. The first is the interaction of the User with the User Interface Device and the second is the dynamic interaction of the User Interface Device with the System Transaction Manager through an ASA by means of bi directional communication. The first is accomplished by the User purposefully constraining the subject matter of the dictation as prompted by the legacy User protocol which is either statically hard wired or exists on an application running on the legacy User protocol. Thus in response to particular legacy User protocol prompts displayed on or communicated to the User by means of the User Interface Device the User can constrain the dictation in accordance with the prompts. The second involves interaction bi directional between the System Transaction Manager and the User Interface Device whereby the System Transaction Manager in response to for example the logon of a particular User Interface Device populated the User Interface Device by use of stored and or acquired System User information. Likewise the User by specific interaction through the User Interface Device is able to request from the System a specific prompt population display grid or the like which can be produced by way of the User Interface Device.

The above functionality is accomplished at least in the bi directional communication by Commands which are carried in the Speech audio stream and or are pre programmed into User s interface and or System files e.g. User s Database containing User Profiles or the like. As set forth above Audio Commands Spoken or Tactile generate an audio signal distinguishable by the User interface and or the System Transaction Manager and or the ASR from spoken text which are carried in the audio stream. Non Audio Commands are inserted into the audio stream but are not part of the Audio Data and can comprise encoded or interleaved data including Meta Data. The non Audio Data is stored in segments.

In addition the Free Form Dictation Speech contains various Commands which instruct the System Transaction Manager to institute a pre programmed set of actions directed at System components and not the User Interface Device. These actions may involve inclusion of User Databases Universal Database specific ASRs and or vocabulary and or dictionaries and the like selection of templates to facilitate the System s processing of the Directed Dictation Speech. In this manner the streamed SIR created by Directed Dictation contains Commands embedded therein which the System Transaction Manager reads and carries out on the fly to yield Constrained Recognition and or Structured Transcription including Formatted Transcription.

In operation the User s response to the prompts on the User Interface Device as well as the Speech generated in response to these prompts provide Commands such that the System Transaction Manager can configure the System to provide Constrained Recognition and or Structured Transcription of the spoken text. This eliminates superfluous spoken text normally associated with non constrained or Free Form Dictation and increases the efficiency of the System in processing the SIR containing Directed Dictation to provide a better transcribed work product which can also be formatted Formatted Transcription .

For example when a cursor on the User Interface Device is placed in a specific location on for example a form this action embeds a Command for the System to use a specific vocabulary Constrained Recognition . Further a 2 dimentional schematic diagram of an aircraft engine displayed on the User Interface Device can generate Tactile Commands by the User touching a location on the schematic diagram to generate specific templates and or vocabulary for the System. 3 dimentional models such as the human anatomy can also be used to constrain and direct dictation. For example sensors can be placed on portions of the 3 dimentional models that generate Commands when activated which specify for example specific ASRs and or vocabulary. Thus activating the sensors in the heart area of 3 dimentional model designates cardiac references for the System while activating sensors in the foot area designates for example podiatrist s vocabulary to the System. In this manner input is directed such that the User keying on the particular prompt can dictate Directed Dictation aimed at a diagnosis a treatment insurance record or the like. In this manner the structure of the dictation actually activates the System as well as provides structure for the dictation Directed Dictation. 

This embodiment provides even greater functionality for the System in that Embedded Commands can include instructions to the System Transaction Manager contained in the Speech stream of the SIR which allows the System Transaction Manager to segment the streamed Speech and process the Job either in series or in parallel through various ASRs vocabularies dictionaries and the like. For example an application on the User Interface Device which transmits a Command transmitted to the System upon the User Interface Device logon identifies the User Interface Device and allows the System to obtain the requisite profile and Enrollment data associated with that device for insertion into the SIR.

Directed Dictation uses Commands to not only structure the input SIR but also the output Response of the System. For example an Audio Command inserted by the legacy User protocol into the Speech after a User selects a new form field on the User Interface Device directs the System Transaction Manager to queue a particular ASR and or vocabulary Constrained Recognition and or particular processing of transcribed spoken text Structured Transcription and or placing the transcribed spoken text into a particular format Formatted Transcription . This is particularly useful for dictation using a touch tone phone where each number key can be assigned a function.

Thus the System is instructed to perform certain tasks or access certain functionalities upon reading a Command. The exact System component for carrying out the Command is contained within the Command. A Command can be carried out by the legacy User protocol and or the System Transaction Manager and or the ASR according to the instructions associated with a specific Command. A Command is associated with one instruction so as not to introduce ambiguity. Commands can also be defined for User groups and as a universal default that could be overridden by the User for specific applications. In one embodiment a Command is associated with an indexed Database. A lookup is made into the set of Commands in the updated Commands Database for a match. Once a match is found the instruction associated with the Command is processed.

As can be seen use of Directed Dictation reduces the garbage in garbage out problems associated with pure Free Form Dictation. Additionally Constrained Recognition enhances the recognition accuracy by matching the dictated words to the optimum ASR as well as vocabularies for that ASR resulting enhanced recognition accuracy.

Another advantage of Directed Dictation is that it provides heretofore not available System flexibility and autonomy in processing dictated Speech. Based on System s rules either within the System or existing in the legacy User protocol the System Transaction Manager can parse rout and instruct System components regarding a complete Job. For example selecting and processing the dictation using the most appropriate ASR for the subject matter being dictated selecting and processing the dictation with Constrained Recognition using a specialty vocabulary as directed by the User or the User Interface Device prompts proper processing of the Structured Transcription of the transcribed text and or formatting the transcribed text to produce a Formatted Transcription.

In another embodiment the System can be configured such that all Speech is recognized within a Dictation Context. In accordance with this aspect Directed Dictation and or Constrained Recognition and or Structured Transcription can be preset in Response to a specific set of Commands which are usually Non Audio. The Dictation Context includes elements from the legacy User protocol the User Interface Device User Profile associated with the recognition of the spoken text including vocabulary User Enrollment spoken language preferred Automated Speech Recognition and or Transcription Engine ASR Correctionist Correctionist Pool and the like. In this manner a preset set of conditions for recognition and transcription of spoken text can be instantly programmed into the System. This is particularly useful when forms or other repetitive documents must be populated by Speech dictation. This allows a User to engage in Directed Dictation Free Form for otherwise tedious transcription task.

It will be realized by the skilled artisan that a number of Commands can be used to narrowly direct dictation and yield a cleaner transcription product by use of these various input schemes.

As previously stated the System using the System Transaction Manager allows the operation of the system behind the User Interface Device to operate efficiently and process SIRs effectively to increase accuracy and utility of the transcribed Response. This System operation is in many respects separate and apart from the User interface and for the most part it is carried on without knowledge or interaction with the User. This is especially true for SIRs not requiring Real Time transcription processing.

ASRs have varying characteristics and requirements for their effective utilization. For example some ASRs will not accept other than microphone or line input. Others do not operate upon streamed Speech and require batching of the dictated Speech files. Further in order to effectively utilize all of the capability of the System the System Transaction Manager must be able to switch ASRs on the fly in response to Commands embedded in the streamed Speech as for example when the User is prompted to change the subject matter and or processing of the Speech by the User Interface Device. Further in order to process many prioritized Jobs SIRs the System Transaction Manager needs to be able to process large Jobs though a number of ASRs in parallel while retaining the exact location and progress of each of the segments parsed to a number of ASRs simultaneously in parallel .

When a single Job requires multiple ASRs in series the System Transaction Manager must have a way of marking the Speech stream and buffering the continuous stream while the set up and communication with a new ASR having for example new vocabulary is established.

In order to take advantage of particular and specific capabilities of various ASRs the System must interface with these engines in a dynamic manner which requires the change of use of a particular ASR and or a particular vocabulary on the fly. In one embodiment the System employs a Virtual Sound Driver for streaming Free Form Dictation from the System Transaction Manger to any ASR regardless of the ASR s inability to recognize and or transcribe spoken text other than from for example a live microphone or line as well as batched audio files. In this embodiment the System Transaction Manager sends spoken text and Commands to the ASR by way of the Virtual Sound Driver. The Virtual Sound Driver outputs the spoken text digitized in a data format which simulates or mimics that of the input from any input source such as for example a live microphone or line source. This results in the ASR upon receiving the spoken text from the Virtual Sound Driver processing it as if it were generated by any input source such as for example a live microphone or line source regardless of the actual originating source.

The Virtual Sound Driver can accept input audio data for example by streaming or reading from an audio file thus allowing any engine to process stored audio data even when the recognition engine s API does not directly support processing an audio file. Thus the Virtual Sound Driver advantageously can accept input audio data by receiving data from a live network connection using any protocol thereby allowing streaming of audio data directly without having to first store the data or from stored data. In this manner the audio data can be transcribed in Real Time or near Real Time as the speaker is dictating.

In another embodiment the ASR is commanded to configure such that it will accept constraints on recognition and or structures on transcriptions for information that is limited to a specific prompt on the User Interface Device. In accordance with this embodiment a dynamic vocabulary dictionary stored in the ASR Database is indexed to recognize the prompt. Thus when the User or the System activates the particular prompt on the User Interface Device the ASR recognizes the constraints and or structure required as well as the vocabulary in the SIR transferred to the ASR by the System Transaction Manager. The prompt can be activated by the User or the System using any means heretofore disclosed including for example eye movement into a grid or tone from a telephony device. Thus in accordance with this embodiment the ASR is able to provide dynamic Constrained Recognition and or Structured Transcription for Users of the System who employ the particular prompt.

The Buffer Buffer function of the instant System can be any of the devices or applications known in the art for storing and holding information on a temporary basis. The Buffer device or function is able of dynamically accumulating and or storing streamed data submitted by the User or the ASR in either Real Time or from storage to allow the System Transaction Manager to perform System s functions seamlessly without loss of streamed User information and or to allow ASR to perform Constrained Recognition and or Structured Transcription functions seamlessly without loss of streamed Real Time or near Real Time SIR User information while the online User perceives no disruption in Free Form Dictation.

The Buffer is activated by the System Transaction Manager s response to a Command either in a Database or embedded in the audio file. Upon activation the System Transaction Manager identifies the beginning of the storage such that the stored portion is seamlessly placed back into the SIR. In another embodiment the Buffer is used to retain Speech including that produced by Free Form Dictation for ASRs that are incapable of accepting continuous streamed Audio Data i.e. they are batch processors. This embodiment is extremely useful for processing long User sessions such as for example in a court room.

The User ASA provides a bi directional translation service between the User s Native Communications Protocols Native Application Protocols and a uniform System protocol used by the System Transaction Manager. Examples of the ASA include recording Audio Data inserting recognized text into the application document editor providing a User interface for editing the User Profiles transmitting the streamed Audio Data to the System Transaction Manager receiving the transcription document or recognition result User processing of Embedded Commands in the Response generated by the System Transaction Manager inserting Embedded Commands in the User system in support of Directed Dictation and the like.

To accommodate yet another System protocol used by the ASR a Speech Recognition Service Adapter SRSA communicates with the System Transaction Manager and the ASR to provide a designated engine with a SIR which is compatible with the engines and a Response compatible with the System Transaction Manager s protocol. This SRSA processes formatting the transcribed spoken text received from the System Transaction Manager for ASR interface as well as the Response received from an ASR into or from a System protocol or a legacy User protocol used by the User and or the System Transaction Manager. Formatting includes such items as converting raw text to RTF HTML and the like interpreting and applying Commands populating any specified forms or templates and or protocol conversion. SRSA also can be used to produce Formatted Transcription directly from the ASR.

The Databases used by the System without limitation comprise four general types each of which is an indexed information repository able of access by the System Transaction Manager and or other System components in response to specific Commands which can be User generated or System generated and can include previously transcribed Free Form Dictation and or Directed Dictation.

The ASR Database which is associated with the ASR through for example the SRSA contains information including User Profile Enrollment vocabularies dictionaries and the like required by the ASR to process a SIR or Real Time SIR.

System Database operated upon by the System Transaction Manager contains general System responses to Commands including User Profiles. A System Database maintained by the System and interfaced by the System Transaction Manager allows information to be obtained by the System to perform System oriented housekeeping administrative and various other System related tasks.

The Universal Database which can include for example language dictionaries phraseology and or vocabulary which are generic to specific professions such as for example medical or law is available for use by all Users and or all System components including the System Transaction Manager. This Database can contain a set of specific forms templates or the like to facilitate Free Form Dictation. In one embodiment the Universal Database is associated with Constrained Recognition and or Structured Transcription. In this embodiment specific dictionary or vocabulary associated with Directed Dictation is retained as well as generic or specific prompts templates and the like to facilitate Directed Dictation which is available for all Users or a specific group of Users of the System. The Universal Database can be populated with System Commands to implement a number of coordinated actions within the ASR. Universal databases are populated generally in coordination with the System administration or upon request of a User or group of Users.

User Databases which are unique to a specific User include the User Profile and can include User specific pre programmed System responses to Commands for facilitating Directed Dictation. The User Database is located on the legacy User System and or the System Transaction Manager but is available system wide to all System components which need access to User specific information. The User Database can also contain specific template instructions and prompts for use with Directed Dictation.

These formats may include specific templates which direct the User Free Form Dictation Speech to specific formats for Directed Dictation and or Structured Recognition instructing the System Transaction Manager to access particular ASRs and or specific dictionary and or vocabulary.

Using its preferred application the Correctionist operates within the workflow of the System such that after a Job is processed for transcription it remains in a Correctionist Pool queue maintained by the System Transaction Manager awaiting processing by a Correctionist. Following correction the Job is returned to the System Transaction Manager for transfer to a Requesting User or the Recipient User or any number of other specified Users. Other than having special permissions the Correctionist interacts with the System in the same manner as a User. Correctionist permissions are granted on the basis of Correctionist Pools. A Correctionist Pool maintains its own Job queue and is administered by a pool manager. The programming applications restrict which Jobs are accepted for processing by the Correctionist Pool. The Correctionist Pool manager adds or deletes Correctionists based upon the programming applications. Depending on how the Correctionist Pool is configured the Correctionist Pool manager may be involved in every Job processed by the Correctionists.

Turning again to the figures the User as shown in generates a Speech Information Request SIR which includes spoken text and Commands and may be a Real Time SIR. Alternatively the SIR can comprise a request for previously transcribed and stored information. As noted earlier the System preferably utilizes a Normalized Data Format which can be used as the System protocol by the System Transaction Manager . The Speech Information Request SIR includes an informational header and a formatted message portion Meta Data . The header the Meta Data or both the header and the Meta Data may contain system Routing information which includes for example the Requesting User s identification and meta addresses of a Recipient User or of a particular ASR . The System Transaction Manager uses the identification information to ensure that the User is authorized to use the System and preferably simultaneously verifies that a Subscriber has authorized the transaction.

Generation of the SIR is by Free Form Dictation which is produced using legacy User protocol. Alternatively the SIR can be stored on a System Database. The generation is a language independent configurable set of services written in a high level language such as C C Java and the like which allows a User to plug its existing application software and hardware into the System to generate the SIR. A User can generate the SIR in Real Time or offline for later submission as a batch Job. Likewise the User may employ a User Interface Device such as mobile wireless phone which provides for example a wireless connection to the System through the ASA.

The User transmits the SIR to the System Transaction Manager . An Updated User Profile can accompany the SIR which the ASR and other components of the System can use to increase the efficiency of the transaction Job as well as the accuracy of the Speech recognition transcription. As stated previously the content of the User Profile is specific to a User and more specific to an individual speaker who may be enrolled in a specific ASR although most ASRs no longer require Enrollment. The User Profile requirements can vary among ASRs but typically includes information derived from corrections of past Speech recognition and transcription sessions.

It will be realized that the User Profile can also be maintained on the User Database and retrieved by the System Transaction Manager or ASR . The legacy User Interface Device or User work group may contain a User Profile and or an Updated User Profile.

The System transmits the SIR to the System Transaction Manager via the communications link . The System may use any type of communication system including a pre existing public Communication System such as the Internet to connect the Requesting User with the System Transaction Manager . For example the Application Service Adapter ASA see is able of generating the SIR in the System Normalized Data Format using for example Extensible Markup Language XML which is transmitted to the System Transaction Manager via Hypertext Transfer Protocol HTTP Transmission Control Protocol Internet Protocol TCP IP File Transfer Protocol FTP and the like. Other useful data transmission protocols include Network Basic Input Output System protocol NetBIOS NetBIOS Extended User Interface Protocol NetBEUI Internet Packet Exchange Sequenced Packet Exchange protocol IPX SPX and Asynchronous Transfer Mode protocol ATM . The choice of transportation protocol is based on cost response times and the like.

As further seen in the System Transaction Manager receives the SIR from the Requesting User via the communications link . Receipt of the SIR activates the System Transaction Manager to create a Job. For example if the SIR is not in the appropriate format the System Transaction Manager translates the SIR into the System format for example Normalized Data Format thus acting as an ASA for the Requesting User . The System Transaction Manager can decrypt SIRs based on a decryption key previously supplied by the User . The System Transaction Manager also logs the receipt of the SIR and sends a message to the User via the communications link confirming receipt of the SIR. In addition the System Transaction Manager authenticates the User ID verifies a Subscriber authorization and assigns a Job ID to be used internally within the System to identify track and report on the Job as it is processed through the System.

To simplify this validation and to facilitate subsequent processing of the SIR the System Transaction Manager creates a data record by stripping off the informational header Meta Data and by extracting Speech data digitized audio and Commands from the SIR. The resulting data record can be complete for processing or can command the System Transaction Manager to populate the data file from one or more indexed files or entries in a Database. The total compilation of all the information needed to process the SIR comprises a Job with a Job ID ready for processing. A Job may also refer to a specific Constrained Recognition and or Structured Transcription including Formatted Transcription requirements to process the Job. SIRs containing Speech from Directed Dictation require more specific processing by the System Transaction Manager.

During validation of the SIR the System Transaction Manager examines the data record to ensure that the SIR meets certain criteria. Such criteria may include compatibility among interfaces which permit information exchange between the User and the System Transaction Manager . Other criteria may include the availability of a User Profile. Through the Virtual Sound Driver the System Transaction Manager may select any ASR compatible with the spoken text of the SIR. Since the System employing the Virtual Sound Driver is compatible with the input requirements of all ASRs the System Transaction Manager need not test for compatibility. Additional criteria may include those associated with the authentication of the User such as the User s status whether the User has the requisite permissions to access System services and so on.

If System Transaction Manager is unable to validate the SIR it logs the error and stores the data record of the SIR in the System Database. Additionally the System Transaction Manager returns the SIR to the User and informs the Requesting User of the validation criteria or criterion that the Requesting User failed to meet.

Following receipt of the SIR the System Transaction Manager processes the validated SIR Job prior to transmitting the spoken text and Commands from the SIR to the ASR . As part of the processing function the System Transaction Manager stores the SIR as an entry in an appropriate Job bin or bins for queued processing according to the System priority. The Job priority may be based in part on processing restrictions imposed by the Speech e.g. subject matter of spoken text Command structure and the like which limits the set of ASRs that are capable of processing the Speech.

Bins are further subdivided based on priority level. The System Transaction Manager assigns each Job a priority level that depends on a set of administrative rules imposed by the System . An individual SIR therefore resides in a Job bin until an ASR requests the next job. Because of the capabilities and flexibility of the System the System Transaction Manager can process Jobs through ASRs in series i.e. segments or in parallel i.e. numerous ASRs operating on segments of a single Job utilizing the Buffer function the System Transaction Manager upon detecting a Command in the audio file to switch vocabulary needed for Directed Dictation and or ASRs can spool and or rewind the streamed spoken text such that there is no apparent interruption in processing from a User viewpoint. In addition because the System has ability to process Free Form Dictation which inherently involves additional Commands in the Speech the System Transaction Manager is more closely involved in the processing of the SIR including segmenting a particular Job to a number of ASRs i.e. parallel while keeping track of the segments.

In this respect System Transaction Manager uses an Audio Preprocessor to read Audio and Non Audio Commands in the streamed Speech breaking the spoken text into segments such that the segments are able of separate and distinct processing by the System. This is important in processing Free Form Dictation and more specifically Directed Dictation.

The System Transaction Manager releases the next Job having the highest priority from a Job bin which contains SIRs that can be processed by the available ASR . Real Time SIRs operate at the highest priority to allow for Real Time or near Real Time transcription of Speech. In the Real Time SIR situation the System Transaction Manager immediately locates one or more available ASRs capable of processing the SIR and establishes a bi directional direct bridge such that spoken and transcribed spoken text can be directly exchanged between the requesting User and the ASRs for Real Time or near Real Time processing.

Processing also includes preparing the SIR for transmission to ASR by parsing the information header Meta Data . The System Transaction Manager may also execute operations or Commands embedded in the SIR by implementation during processing .

Transmission of the SIR from the System Transaction Manager to the Speech Recognition and Transcription Engine

Once the SIR has been processed the System Transaction Manager transmits the spoken text and Commands related to ASR operation to be read by the ASR to the selected ASR via the communications link . The System Transaction Manager prepares the SIR for transmission to the appropriate ASR . Following preparation of the SIR the System Transaction Manager transmits the SIR to the ASR via the communications link and using an acceptable communication protocol such as HTTP TCP IP FTP NetBIOS NetBEUI IPX SPX ATM and the like. The choice of transportation protocol is based on cost compatibility response times and the like.

The System Transaction Manager transmits the SIR to the ASR which has authority to access any information in any database needed to process the SIR. Further Audio or Non Audio Commands may be read by the ASR to specify transcription and or formatting. This is especially true with Directed Dictation requiring Constrained Recognition and or Structured Transcription. Additional information required to process the Job by the ASR may be accessed in various Databases by the ASR or such information can be retained in the ASR Database.

Receipt of the SIR activates the ASR or Speech Recognition and Transcription Server SRTS which logs and authenticates the receipt of the SIR to the System Transaction Manager. The ASR tests the System protocol to determine compatibility with the ASR protocol. If they are not compatible then System employs one or more Speech Application Service Adapters see FIG. to provide an interface between the System Transaction Manager and the ASR .

During processing the SIR and generating the Response the ASR is able to access the ASR Database to obtain User directed files such as User Profile Command dictionary Enrollment and the like. Alternatively the ASR may request from the System Transaction Manager to access Universal and User Databases to obtain the information required.

Following receipt of the SIR the ASR processes the SIR and generates a response . The Response comprises a transcription of the spoken text containing formatting which may refer to the internal representation of the transcribed Speech within the System i.e. its data structure or to the external representation of the transcribed Speech i.e. its visual appearance or to both.

The ASR transcribes the Speech and generates the Response. Like the SIR the Response comprises the transcribed Speech and Commands related to post processing and Meta Data. The ASR transmits the Response to the System Transaction Manager via the communications link .

As shown in if the ASR cannot write the Response in Normalized Data Format an ASR Application Service Adapter and or a Speech Service Adapter generates the Response from a transcription produced using the ASR existing ASR protocol. Once the Response has been generated it is queued for transmission to the System Transaction Manager .

As shown in following processing the SIR and generating the response the ASR transmits the Response to the System Transaction Manager via the communications link using an acceptable communication protocol such as HTTP TCP IP FTP NetBIOS NetBEUI IPX SPX ATM and the like. The choice of transportation protocol is based on cost compatibility response times and the like.

The System Transaction Manager logs its receipt of the Response and sends an acknowledgment to the ASR via the communications link . To prepare for transmission of the Response to the Receiving User as designated in the original SIR the System Transaction Manager can perform other processing including providing Formatted Transcription.

In addition the System Transaction Manager can place the Response or Job in a Correctionist Pool queue to await processing by a Correctionist. Following correction the Job is returned to the System Transaction Manager for transmission to the Requesting User or other Users.

Following correction or other processing the System Transaction Manager notifies the Requesting User and or other Receiving Users that a Response to the SIR is available. The System Transaction Manager ordinarily notifies the Recipient or Receiving User using electronic messaging via the Communications Link but in general may notify the User by any technique specified by the Requesting User or the Recipient or Receiving User. In any case the Response remains as a record in a Database maintained by the System until archived. The Response so maintained may be accessed by any authorized User at any time and comprises a separate Job.

Following processing the System Transaction Manager transmits the Response to the SIR to the Requesting User and or to any other Recipient Users as designated in the SIR. If necessary the System Transaction Manager appends the User ID and any additional Routing information and transmits the Response via the communications link using an appropriate protocol as described above.

The System Transaction Manager transmits the Response to the Recipient Users which usually includes the Requesting User . If the Recipient User can accept a Response expressed in the Normalized Data Format or if the Response is expressed in a format that is compatible with the Recipient User legacy User protocol then the Recipient User forwards the Response on for processing . As seen in if the format of the Response is incompatible with the Recipient User s legacy User protocol then the System may employ an ASA to provide an interface between the System Transaction Manager and the Recipient User. Ordinarily the Requesting User and any non requesting Users or passive Users will employ ASAs that reside on their respective legacy User systems. Wherever the ASA resides the Recipient User usually sends a message to the System Transaction Manager via the communications link acknowledging receipt of the Response.

After receiving a Response compatible with the Recipient User s legacy User protocol the Requesting User or any Recipient may process the Response as necessary. Any processing will depend on the particular needs of the Requesting User or Recipient and therefore may vary significantly among Recipients. Typical processing includes error correction formatting broadcasting computation and so on.

As described in more detail below the User communicates with the System Transaction Manager through a User Application Service Adapter and a User Service Adapter . Similarly the ASR communicates with the System Transaction Manager through an ASR Application Service Adapter and a Speech Service Adapter .

The User can initiate the transaction as a Requesting User as shown in and can utilize a legacy protocol a new protocol or a uniform System protocol which is compatible with the Normalized Data Format utilized by the System Transaction Manager . When using the legacy protocol the User communicates with an ASA interface in much the same manner as the System User of . However a User employing the new protocol communicates with an API which besides providing an interface between the User and the System Transaction Manager also allows the User to access services that an operating system makes available to applications running under its control. The API can provide services e.g. automatic generation of insurance forms engineering design templates pleadings and the like geared to activities of a particular industry or group such as for example physicians engineers lawyers and the like.

Like the System Transaction Manager the uniform System protocol processes information expressed in the Normalized Data Format. Therefore an ASA interface which links the uniform System protocol with the User Service Adapter and the System Transaction Manager provides minimal translation services and typically simply validates any SIR or Response.

As with the embodiment shown in the System depicted in provides Speech recognition and transcription services using SIRs and Responses. To initiate transcription of Speech a Requesting User thus generates a SIR using the legacy protocol or the new protocol or the uniform System protocol . It will be realized that if the Requesting User has the ability to generate a SIR in uniform System protocol there is no need to access an ASA as described below.

In addition to providing Speech for transcription the SIR includes Meta Data for example addresses or specific addresses of the ASR as well as Recipients of the Response and the like.

Once the Requesting User creates the SIR using its legacy protocol it transmits the SIR to the User ASA for processing which transforms if necessary the SIR so that it adheres to the System Transaction Manager s uniform System protocol.

As shown in following transformation of the SIR the Application Service Adapter forwards the SIR to the User Service Adapter . A Routing process within the User Service Adapter forwards the SIR to the System Transaction Manager over a communications link e.g. TCP IP link . The Routing process within the User Service Adapter does not operate on information in the header or data portions of the SIR destined for the System Transaction Manager .

Once the System Transaction Manager receives the SIR a parsing process obtains addresses provided in the Meta Data contained in the SIR which allows the System Transaction Manager to identify among other things the targeted ASR . When the parsing process obtains addresses of multiple ASRs and or ASRs having different capabilities for example to process using Constrained Recognition and Structured Transcription especially in response to SIRs created by Directed Dictation the System Transaction Manager distributes these SIRs and or segments as broken down by the Audio Preprocessor not shown for processing as described above. In this manner the Job can proceed through the System either in parallel or in series depending on particular requirements of the SIR. As set forth previously the System using the Virtual Sound Driver provides the System Transaction Manager with the ability to use various ASRs irrespective of their system input requirements. Other information such as the selected language vocabulary topic and the like when transmitted to an ASR can require the ASR to process the SIR using Constrained Recognition and or Structured Transcription as set forth above.

Following parsing of the addresses Meta Data the System Transaction Manager forwards the SIRs to an authorization process . By comparing information in the SIR with entries in a lookup table the authorization process verifies the identities of the Requesting User and other Recipients if any the identities of their protocols and the identities of the ASR as well as the Subscriber authorizing the transaction.

In conjunction with the authorization process the System Transaction Manager dispatches the SIR to a logging process which logs each SIR. If the authorization process determines that a SIR has failed authorization for any number of reasons lack of access to the ASR invalid Recipients unauthorized Requestor or the like the logging process notes the failure in the session control table and notifies an accumulator process . The accumulator process keeps track of the original SIR and all duplicates of the original SIR. After the SIR is logged it passes to a Routing process which directs the SIR to the Speech Service Adapter which is associated with the targeted ASR .

When the original SIR designates multiple ASRs the Routing process directs the duplicate SIRs to the appropriate Speech Service Adapters associated with the ASRs. The Routing process examines the address of the addressee in the SIR and then either routes the SIR to the appropriate Speech Service Adapter s using the ASR address in the header or places the SIR into a prioritized first in first out FIFO queue where it waits for the required ASR.

A Routing process within the Speech Service Adapter directs the SIR to an appropriate interface within the ASR Application Service Adapter . The choice of interface depends on whether the ASR utilizes a legacy protocol a new protocol or a uniform System protocol respectively. As noted above with respect to the Requesting User s protocols the ASR and the Speech Recognition and Transcription Server that supports the ASR employs only one of the protocols . Similarly the ASR Application Service Adapter has only one interface depending on the protocol utilized by the ASR .

Upon receipt of the SIR the interface stores the Job ID and Meta Data and translates the SIR into the Native Applications Protocol and Native Communications Protocol if necessary. Once the ASR transcribes SIRs expressed in the Normalized Data Format the interface validates the SIRs. In any event the interface forwards the translated or validated SIR to the ASR .

After receiving the SIR the ASR generates a Response which includes a transcription of spoken text and processing Commands such as to obtain a Formatted Transcription and transmits the Response to the System Transaction Manager via the ASR Application Service Adapter and the Speech Service Adapter . The ASR Application Service Adapter forwards the Response in Normalized Data Format to the Speech Service Adapter. The Routing process within the Speech Service Adapter forwards the Response to the System Transaction Manager again using a communications protocol compatible with the uniform System protocol.

Following receipt of the Response the Routing process within the System Transaction Manager notifies the accumulator process that a Response has been received. The accumulator process checks the session control table to determine if all Responses have been received for the original SIR. If any Responses are outstanding the accumulator process goes into a waiting condition. This process continues until all Responses to the original SIR and any duplicate Requests have been received have been timed out or have been rejected because of an authorization failure.

After the original SIR and all duplicate Requests have been processed the accumulator process emerges from its wait condition and creates a single Response to the original SIR by combining all of the Responses from the targeted ASRs. The accumulator process dispatches an asynchronous message to the logging process which logs the combined Response and forwards the combined Response to the Routing process . The Routing process reads the address of the Requesting User and the addresses of any additional or alternative Recipients of the Response and forwards the Response or Responses to the User Service Adapter and alternatively or optionally to other appropriate Recipient User Service Adapters.

Focusing on the Requesting User once the User Service Adapter receives the Response the Routing process within the User Service Adapter transmits the Response back to the User Application Service Adapter with the appropriate interface . The Routing process within the User Service Adapter determines the appropriate interface by examining the Response header or to whichever interface initiated the transaction. Continuing the earlier example the ASA interface reformats the Response which is expressed in the Normalized Data Format so that it is compatible with the legacy protocol of the Requesting User . As part of the translation process the ASA interface embeds the Job ID into the Meta Data contained in the Response as is required by the legacy protocol .

Turning to a typical User interface is shown. This interface permits bi directional communication between the User and the System Transaction Manager as shown in . In using an application running on a microprocessor the Requesting User generates a SIR as previously described. The application conforms to a Native Application Protocol which generates a SIR comprising dictated Speech which may be a Real Time or near Real Time SIR. As noted above in discussing the User also employs a Native Communications Protocol to enable transmission of the SIR to an Application Service Adapter .

In accordance with the embodiment containing Directed Dictation through the human machine interface HMI provided between the User and the User Interface Device not shown there is established by Application Service Adapter a bi directional communication link between User and the System Transaction Manager . In accordance with this embodiment the User by interface with the User Interface Device constrains or otherwise restricts parameters for the subject matter and content of the dictated Speech. For example prompts on the User Interface Device specify the type of dictation required. The prompts on the User Interface Device can be provided by the legacy User protocol System and or the System Transaction Manager. The ASA interface in this embodiment collects and stores appropriate data related to these prompts such as the position of the caret on the User Interface Device and translation of the relationship between caret placements to provide the System Transaction Manager with information concerning the requirements for Constrained Recognition and or Structured Transcription.

The Application Service Adapter is an application layer that provides among other things bi directional translation among the Native Application Protocol the Native Communications Protocol and a uniform System protocol utilized by the System Transaction Manager . A transport layer transfers the resulting SIR to the System Transaction Manager via for example streaming Real Time or near Real Time output.

As noted above an ASR responds to the SIR by generating a Response to the SIR. Following the generation and receipt of the Response from the System Transaction Manager the Application Service Adapter converts the Response so that it is compatible with the Native Application Protocol . The Requesting User can then employ the application to correct and to manipulate the Response which includes a transcription of the Speech in for example Rich Text Format RTF as well as the original Speech e.g. recorded voice wave data or modified Speech e.g. compressed and or filtered enhanced or the like recorded voice wave data . Following correction the User can submit the transcription to the Application Service Adapter for updating its User Profile for storing in a site specific document Database and so on.

The Application Service Adapter can convert SIRs Responses and the like using any mechanism including API services cutting and pasting information in a clipboard maintained by the application s operating system or transmitting characters in ASCII EBCDIC UNICODE formats and the like. Job information includes identifications of the User Profile and of the ASR . The Job information can also include preexisting and User defined language Commands.

The uniform System protocol also packages Jobs containing User corrected transcribed text and wave data which provide pronunciations of new vocabulary words or words that the ASR could not recognize and are stored in the User Profile for subsequent use by the User s use of the specified ASR. This information can be stored on the User Database and or Universal Database and or ASR Database.

The uniform System protocol compiles much of the Job in cooperation with the User Service Adapter . In addition to Job Routing services the User Service Adapter also provides an interface for maintaining the User Profile and for updating Job processing settings. The User Service Adapter thus provides services for finalizing a correction of the Response which allows updating of the User Profile with context information and with a pronunciation guide for words the ASR could not recognize. The User Service Adapter also provides services for creating new User Profiles for maintaining Commands for notifying the User of Job status for modifying the Correctionist Pool configuration and for archiving documents obtained from processing the Response.

The System Transaction Manager exchanges information bilaterally with the User interface of through their respective transport layers as set forth in detail above. Data exchange between the transport layers can occur in Real Time or near Real Time streaming or in batch mode and includes transmission of SIRs and Responses and any other Job related information.

Following receipt of Job information from the transport layer a uniform System protocol layer within the System Transaction Manager decodes the Job information SIRs into Meta Data Commands and spoken text. The System Transaction Manager routes the Job to an application portal a Correctionist portal or a Speech recognition and transcription portal depending upon processes required and the status of the Job routed i.e. incoming SIR Response to be corrected Response or the like. The uniform System protocol layer decodes and authenticates each Command in accordance with each specific portal s security requirements. The uniform System protocol layer logs and rejects any Jobs that fail authentication. The System Transaction Manager passes authenticated Jobs to a workflow component which converts Jobs into an instruction set as specified by a Job logic layer .

The System Transaction Manager includes a data access layer which stores or accesses any data in data source that is necessary to support a Job. The data access layer converts instructions requesting data into Commands that are specific to a given Database or Databases designated by the Job e.g. a SQL Server an Oracle dB OLE storage and the like .

As can be seen in a task manager handles instructions pertaining to submission and retrieval of Jobs which are placed into queued Job bins to await processing e.g. transcription of Speech . The task manager adds Jobs to a particular Job bin based on rules from the Job logic layer . These rules permit the task manager to match a Job s requirements with processing capabilities associated with a particular Job bin e.g. language base vocabulary topic User Commands ASR pre and post processing and the like . Each Job bin is associated with a set of ASRs. The System Transaction Manager creates or associates Job bins for each networked SRTS which may include one or more ASRs attached to the SRTS and transfers capability data.

The task manager releases Jobs based on priority rules including whether an available ASR or SRTS has access to a valid copy of the Requesting User s Profile. Based on rules from the Job logic layer the task manager determines a match between an available ASR and a Job awaiting processing in queued Job bins . The task manager releases Jobs for processing only when each of the rules is satisfied. Such rules include parameters detailing how to process a Job which the task manager compares with the capabilities of particular ASRs. The task manager also processes pre and post processing of Jobs and cleanup of error conditions resulting from network interruptions equipment failure poor dictation audio and the like.

In order to satisfy rules imposed by the Job logic layer or Commands submitted by the Requesting User the System Transaction Manager flags certain Jobs for post processing. Post processing allows for additional operations to be performed on a Job by for example allowing any User specific and or automated System processing of the Job including Formatted Transcription which can be for example carried out by the Audio Preprocessor. A post processing manager adds the flagged Jobs e.g. Responses to a post processing Job queue not shown . When a post processor which may be on any system in the network becomes available the post processing manager releases Jobs singly or in batch depending on the requirements of the post processor. For each post processor the post processing manager loads a component in the System which the post processing manager retains until the post processor detaches. Each post processor identifies what Jobs or Commands it will operate on by providing the System Transaction Manager with Job type specifications. As can be seen in a post processing Application Programming Interface API layer provides a common path for extracting Job data from the System Transaction Manager which the post processor can use for post processing.

The SRTS exchanges information with the System Transaction Manager of through their respective transport layers using a uniform System protocol . Data exchange between the transport layers can occur in Real Time or near Real Time streaming or in batch mode and includes transmission of SIRs Responses and any other Job related information including User Profile Updates.

The SRTS includes a pipeline connection interface manager which manages one or more workflow pipelines which control processing of Jobs. Each of the workflow pipelines is coupled to a specific ASR via a Speech Recognition Service Adapter . When a particular workflow pipeline becomes available to process a Job it notifies the System Transaction Manager via the transport layer . Upon its receipt within the appropriate workflow pipeline the Job is stored in the local Job queue while it undergoes processing.

Processing includes a pre process step which can comprise validation of the Job synchronization of a Job specific User Profile with a local cached version and synchronization of a User specific Database containing dictation Commands training information and the like.

The service adapter associated with the Audio Preprocessor is comprised of a vendor independent APE interface and a vendor dependent APE interface which provides the linkage to an external audio pre post process engine APE . The audio pre post process engine can reside on the SRTS or a peer to peer network and or the cloud as specifically described above. An audio preprocess adapter extracts the audio portion from the Job and loads an appropriate audio pre post process engine which prepares the audio stream in accordance with the Commands contained within the Job or the inserted into the audio stream itself.

The workflow controller operates on audio pre post preprocess engine output. In one embodiment the workflow controller loads configures and starts the automated Speech Recognition Service Adapter to process Audio Data as a single data stream. In other embodiments the workflow controller creates a task list which references ASR application service adapters associated with separate ASRs . In such embodiments the workflow controller configures each of the ASR application service adapters to process various segments that the audio pre post process engine has marked for processing by the separate ASR . The latter embodiment allows for selecting separate ASR for speech to text processing and for speech to command processing. Commands can be executed in Real Time or near Real Time or converted into a script for batch mode post processing.

In any case the workflow controller loads configures and starts the ASR Application Service Adapter to begin processing a Job. As can be seen in the ASR Application Service Adapter includes a vendor independent ASR interface which provides the System Transaction Manager with ASR settings and with Job information to assist in determining the appropriate ASR to process a given Job. The vendor independent ASR interface also creates a vendor dependent ASR interface object and passes the ASR settings as well as any other data necessary to process the Job to the System Transaction Manager . The vendor dependent ASR interface initializes the ASR with ASR specific process settings and with preprocessed audio data from the audio pre post process engine which the ASR transcribes in accordance with the process settings.

The above description is intended to be illustrative and not restrictive. Many embodiments and many applications besides the examples provided would be apparent to those of skill in the art upon reading the above description. The scope of the invention should therefore be determined not with reference to the above description but should instead be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled. The disclosures of all articles and references including patents patent applications and publications are incorporated by reference in their entirety and for all purposes.

